"Journal Article"	"Z. Abaid; M. A. Kâafar; S. Jha"	"2017"	"Quantifying the impact of adversarial evasion attacks on machine learning based android malware classifiers"	""	"2017 IEEE 16th International Symposium on Network Computing and Applications (NCA)"	""	""	""	""	""	"1-10"	""	""	""	""	""	""	""	"Quantifying the impact of adversarial evasion attacks on machine learning based android malware classifiers"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"M. Abdar; M. Z. Moghadam; R. Das; I.-H. Ting"	"2017"	"Performance analysis of classification algorithms on early detection of liver disease"	""	"Expert Syst. Appl."	""	""	"67"	""	""	"239-251"	""	""	""	""	""	""	""	"Performance analysis of classification algorithms on early detection of liver disease"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"G. Ács; L. Melis; C. Castelluccia; E. De Cristofaro"	"2017"	"Differentially Private Mixture of Generative Neural Networks"	""	"2017 IEEE International Conference on Data Mining (ICDM)"	""	""	""	""	""	"715-720"	""	""	""	""	""	""	""	"Differentially Private Mixture of Generative Neural Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"A. Andoni; P. Indyk; T. Laarhoven; I. P. Razenshteyn; L. Schmidt"	"2015"	"Practical and Optimal LSH for Angular Distance"	""	"ArXiv"	""	""	"abs/1509.02897"	""	""	""	""	""	""	""	""	""	""	"Practical and Optimal LSH for Angular Distance"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"F. Angiulli; L. Argento; A. Furfaro"	"2014"	"PCkAD: an unsupervised intrusion detection technique exploiting within payload n-gram location distribution"	""	"ArXiv"	""	""	"abs/1412.3664"	""	""	""	""	""	""	""	""	""	""	"PCkAD: an unsupervised intrusion detection technique exploiting within payload n-gram location distribution"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"P. S. Aravind; J. Shah; D. G. Kurup"	"2018"	"Bit Error Rate (BER) Performance Analysis of DASH7 Protocol in Rayleigh Fading Channel"	""	"2018 International Conference on Advances in Computing, Communications and Informatics (ICACCI)"	""	""	""	""	""	"695-698"	""	""	""	""	""	""	""	"Bit Error Rate (BER) Performance Analysis of DASH7 Protocol in Rayleigh Fading Channel"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"M. Arjovsky; L. Bottou"	"2017"	"Towards Principled Methods for Training Generative Adversarial Networks"	""	"ArXiv"	""	""	"abs/1701.04862"	""	""	""	""	""	""	""	""	""	""	"Towards Principled Methods for Training Generative Adversarial Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"M. Arjovsky; S. Chintala; L. Bottou"	"2017"	"Wasserstein Generative Adversarial Networks"	""	"ICML"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Wasserstein Generative Adversarial Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"M. Arjovsky; S. Chintala; L. Bottou"	"2017"	"Wasserstein GAN"	""	"ArXiv"	""	""	"abs/1701.07875"	""	""	""	""	""	""	""	""	""	""	"Wasserstein GAN"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"S. Arora; R. Ge; Y. Liang; T. Ma; Y. Zhang"	"2017"	"Generalization and equilibrium in generative adversarial nets (GANs) (invited talk)"	""	"Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Generalization and equilibrium in generative adversarial nets (GANs) (invited talk)"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"S. Arora; Y. Zhang"	"2017"	"Do GANs actually learn the distribution? An empirical study"	""	"ArXiv"	""	""	"abs/1706.08224"	""	""	""	""	""	""	""	""	""	""	"Do GANs actually learn the distribution? An empirical study"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"G. Ateniese; L. V. Mancini; A. Spognardi; A. Villani; D. Vitali; G. Felici"	"2015"	"Hacking smart machines with smarter ones: How to extract meaningful data from machine learning classifiers"	""	"Int. J. Secur. Networks"	""	""	"10"	""	""	"137-150"	""	""	""	""	""	""	""	"Hacking smart machines with smarter ones: How to extract meaningful data from machine learning classifiers"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"A. Athalye; N. Carlini"	"2018"	"On the Robustness of the CVPR 2018 White-Box Adversarial Example Defenses"	""	"ArXiv"	""	""	"abs/1804.03286"	""	""	""	""	""	""	""	""	""	""	"On the Robustness of the CVPR 2018 White-Box Adversarial Example Defenses"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"M. Backes; P. Berrang; M. Humbert; P. Manoharan"	"2016"	"Membership Privacy in MicroRNA-based Studies"	""	"Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Membership Privacy in MicroRNA-based Studies"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"M. Backes; M. Humbert; J. Pang; Y. Zhang"	"2017"	"walk2friends: Inferring Social Links from Mobility Profiles"	""	"Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security"	""	""	""	""	""	""	""	""	""	""	""	""	""	"walk2friends: Inferring Social Links from Mobility Profiles"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"E. Bagdasaryan; V. Shmatikov"	"2019"	"Differential Privacy Has Disparate Impact on Model Accuracy"	""	"NeurIPS"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Differential Privacy Has Disparate Impact on Model Accuracy"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"D. Bahdanau; K. Cho; Y. Bengio"	"2015"	"Neural Machine Translation by Jointly Learning to Align and Translate"	""	"CoRR"	""	""	"abs/1409.0473"	""	""	""	""	""	""	""	""	""	""	"Neural Machine Translation by Jointly Learning to Align and Translate"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"J. Ballesteros; M. Rahman; B. Carbunar; N. Rishe"	"2012"	"Safe cities. A participatory sensing approach"	""	"37th Annual IEEE Conference on Local Computer Networks"	""	""	""	""	""	"626-634"	""	""	""	""	""	""	""	"Safe cities. A participatory sensing approach"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"D. Baltrunas; A. M. Elmokashfi; A. Kvalbein"	"2014"	"Measuring the Reliability of Mobile Broadband Networks"	""	"Proceedings of the 2014 Conference on Internet Measurement Conference"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Measuring the Reliability of Mobile Broadband Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"N. Baracaldo; B. Chen; H. Ludwig; J. A. Safavi"	"2017"	"Mitigating Poisoning Attacks on Machine Learning Models: A Data Provenance Based Approach"	""	"Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Mitigating Poisoning Attacks on Machine Learning Models: A Data Provenance Based Approach"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"B. K. Beaulieu-Jones; Z. S. Wu; C. J. Williams; R. Lee; S. P. Bhavnani; J. B. Byrd; C. S. Greene"	"2018"	"Privacy-preserving generative deep neural networks support clinical data sharing"	""	"bioRxiv"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Privacy-preserving generative deep neural networks support clinical data sharing"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"U. M. Bergmann; N. Jetchev; R. Vollgraf"	"2017"	"Learning Texture Manifolds with the Periodic Spatial GAN"	""	"ICML"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Learning Texture Manifolds with the Periodic Spatial GAN"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"D. Berthelot; T. Schumm; L. Metz"	"2017"	"BEGAN: Boundary Equilibrium Generative Adversarial Networks"	""	"ArXiv"	""	""	"abs/1703.10717"	""	""	""	""	""	""	""	""	""	""	"BEGAN: Boundary Equilibrium Generative Adversarial Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"A. Bhattacharyya; M. Fritz; B. Schiele"	"2019"	""Best-of-Many-Samples" Distribution Matching"	""	"ArXiv"	""	""	"abs/1909.12598"	""	""	""	""	""	""	""	""	""	""	""Best-of-Many-Samples" Distribution Matching"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"A. Bhattacharyya; B. Schiele; M. Fritz"	"2018"	"Accurate and Diverse Sampling of Sequences Based on a "Best of Many" Sample Objective"	""	"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"	""	""	""	""	""	"8485-8493"	""	""	""	""	""	""	""	"Accurate and Diverse Sampling of Sequences Based on a "Best of Many" Sample Objective"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"B. Biggio; I. Corona; Z.-M. He; P. P. K. Chan; G. Giacinto; D. S. Yeung; F. Roli"	"2015"	"One-and-a-Half-Class Multiple Classifier Systems for Secure Learning Against Evasion Attacks at Test Time"	""	"MCS"	""	""	""	""	""	""	""	""	""	""	""	""	""	"One-and-a-Half-Class Multiple Classifier Systems for Secure Learning Against Evasion Attacks at Test Time"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"B. Biggio; I. Corona; D. Maiorca; B. Nelson; N. Srndic; P. Laskov; G. Giacinto; F. Roli"	"2013"	"Evasion Attacks against Machine Learning at Test Time"	""	"ECML/PKDD"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Evasion Attacks against Machine Learning at Test Time"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"B. Biggio; I. Corona; B. Nelson; B. I. P. Rubinstein; D. Maiorca; G. Fumera; G. Giacinto; F. Roli"	"2014"	"Security Evaluation of Support Vector Machines in Adversarial Environments"	""	"ArXiv"	""	""	"abs/1401.7727"	""	""	""	""	""	""	""	""	""	""	"Security Evaluation of Support Vector Machines in Adversarial Environments"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"B. Biggio; G. Fumera; F. Roli"	"2014"	"Security Evaluation of Pattern Classifiers under Attack"	""	"IEEE Transactions on Knowledge and Data Engineering"	""	""	"26"	""	""	"984-996"	""	""	""	""	""	""	""	"Security Evaluation of Pattern Classifiers under Attack"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"B. Biggio; B. Nelson; P. Laskov"	"2012"	"Poisoning Attacks against Support Vector Machines"	""	"ICML"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Poisoning Attacks against Support Vector Machines"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"B. Biggio; I. Pillai; S. R. Bulò; D. Ariu; M. Pelillo; F. Roli"	"2013"	"Is data clustering in adversarial settings secure?"	""	"Proceedings of the 2013 ACM workshop on Artificial intelligence and security"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Is data clustering in adversarial settings secure?"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"L. Bilge; D. Balzarotti; W. K. Robertson; E. Kirda; C. Krügel"	"2012"	"Disclosure: detecting botnet command and control servers through large-scale NetFlow analysis"	""	"ACSAC '12"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Disclosure: detecting botnet command and control servers through large-scale NetFlow analysis"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"L. Bilge; S. Sen; D. Balzarotti; E. Kirda; C. Krügel"	"2014"	"Exposure: A Passive DNS Analysis Service to Detect and Report Malicious Domains"	""	"ACM Trans. Inf. Syst. Secur."	""	""	"16"	""	""	"14"	""	""	""	""	""	""	""	"Exposure: A Passive DNS Analysis Service to Detect and Report Malicious Domains"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"Z. S. Bischof; F. E. Bustamante; N. Feamster"	"2017"	"Characterizing and Improving the Reliability of Broadband Internet Access"	""	"ArXiv"	""	""	"abs/1709.09349"	""	""	""	""	""	""	""	""	""	""	"Characterizing and Improving the Reliability of Broadband Internet Access"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"M. K. Blowers; J. Williams"	"2014"	"Machine Learning Applied to Cyber Operations"	""	"Network Science and Cybersecurity"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Machine Learning Applied to Cyber Operations"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"N. Boggs; S. Du; S. Stolfo"	"2014"	"Measuring Drive-by Download Defense in Depth"	""	"RAID"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Measuring Drive-by Download Defense in Depth"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"N. Boggs; H. Zhao; S. Du; S. Stolfo"	"2014"	"Synthetic Data Generation and Defense in Depth Measurement of Web Applications"	""	"RAID"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Synthetic Data Generation and Defense in Depth Measurement of Web Applications"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"A. Brock; J. Donahue; K. Simonyan"	"2019"	"Large Scale GAN Training for High Fidelity Natural Image Synthesis"	""	"ArXiv"	""	""	"abs/1809.11096"	""	""	""	""	""	""	""	""	""	""	"Large Scale GAN Training for High Fidelity Natural Image Synthesis"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"G. Brown; A. C. Pocock; M.-J. Zhao; M. Luján"	"2012"	"Conditional Likelihood Maximisation: A Unifying Framework for Information Theoretic Feature Selection"	""	"J. Mach. Learn. Res."	""	""	"13"	""	""	"27-66"	""	""	""	""	""	""	""	"Conditional Likelihood Maximisation: A Unifying Framework for Information Theoretic Feature Selection"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"M. Brückner; C. Kanzow; T. Scheffer"	"2012"	"Static prediction games for adversarial learning problems"	""	"J. Mach. Learn. Res."	""	""	"13"	""	""	"2617-2654"	""	""	""	""	""	""	""	"Static prediction games for adversarial learning problems"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"BrücknerMichael; KanzowChristian; SchefferTobias"	"2012"	"Static prediction games for adversarial learning problems"	""	"Journal of Machine Learning Research"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Static prediction games for adversarial learning problems"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"J. Buckman; A. Roy; C. Raffel; I. J. Goodfellow"	"2018"	"Thermometer Encoding: One Hot Way To Resist Adversarial Examples"	""	"ICLR"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Thermometer Encoding: One Hot Way To Resist Adversarial Examples"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"H. Bühler; B. Horvath; T. Lyons; I. P. Arribas; B. Wood"	"2020"	"A Data-Driven Market Simulator for Small Data Environments"	""	"ERN: Neural Networks & Related Topics (Topic)"	""	""	""	""	""	""	""	""	""	""	""	""	""	"A Data-Driven Market Simulator for Small Data Environments"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"T. T. Cai; Z. Ren; H. H. Zhou"	"2016"	"Estimating structured high-dimensional covariance and precision matrices: Optimal rates and adaptive estimation"	""	"Electronic Journal of Statistics"	""	""	"10"	""	""	"1-59"	""	""	""	""	""	""	""	"Estimating structured high-dimensional covariance and precision matrices: Optimal rates and adaptive estimation"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"M. Calzarossa; L. Massari; D. Tessera"	"2016"	"Workload Characterization"	""	"ACM Computing Surveys (CSUR)"	""	""	"48"	""	""	"1 - 43"	""	""	""	""	""	""	""	"Workload Characterization"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"N. Carlini; C. Liu; Ú. Erlingsson; J. Kos; D. X. Song"	"2019"	"The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks"	""	"USENIX Security Symposium"	""	""	""	""	""	""	""	""	""	""	""	""	""	"The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"N. Carlini; D. A. Wagner"	"2016"	"Defensive Distillation is Not Robust to Adversarial Examples"	""	"ArXiv"	""	""	"abs/1607.04311"	""	""	""	""	""	""	""	""	""	""	"Defensive Distillation is Not Robust to Adversarial Examples"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"N. Carlini; D. A. Wagner"	"2017"	"Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods"	""	"Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"S. Chaisiri; B.-S. Lee; D. T. Niyato"	"2012"	"Optimization of Resource Provisioning Cost in Cloud Computing"	""	"IEEE Transactions on Services Computing"	""	""	"5"	""	""	"164-177"	""	""	""	""	""	""	""	"Optimization of Resource Provisioning Cost in Cloud Computing"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"D. Chen; T. Orekondy; M. Fritz"	"2020"	"GS-WGAN: A Gradient-Sanitized Approach for Learning Differentially Private Generators"	""	"ArXiv"	""	""	"abs/2006.08265"	""	""	""	""	""	""	""	""	""	""	"GS-WGAN: A Gradient-Sanitized Approach for Learning Differentially Private Generators"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"D. Chen; N. Yu; Y. Zhang; M. Fritz"	"2019"	"GAN-Leaks: A Taxonomy of Membership Inference Attacks against GANs"	""	"ArXiv"	""	""	"abs/1909.03935"	""	""	""	""	""	""	""	""	""	""	"GAN-Leaks: A Taxonomy of Membership Inference Attacks against GANs"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"F. Chen; P. Deng; J. Wan; D. Zhang; A. V. Vasilakos; X. Rong"	"2015"	"Data Mining for the Internet of Things: Literature Review and Challenges"	""	"International Journal of Distributed Sensor Networks"	""	""	"11"	""	""	""	""	""	""	""	""	""	""	"Data Mining for the Internet of Things: Literature Review and Challenges"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"G. Chen; Y. Gong; P. Xiao; J. A. Chambers"	"2015"	"Physical Layer Network Security in the Full-Duplex Relay System"	""	"IEEE Transactions on Information Forensics and Security"	""	""	"10"	""	""	"574-583"	""	""	""	""	""	""	""	"Physical Layer Network Security in the Full-Duplex Relay System"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"H. Chen; H. Zhang; P.-Y. Chen; J. Yi; C.-J. Hsieh"	"2017"	"Show-and-Fool: Crafting Adversarial Examples for Neural Image Captioning"	""	"ArXiv"	""	""	"abs/1712.02051"	""	""	""	""	""	""	""	""	""	""	"Show-and-Fool: Crafting Adversarial Examples for Neural Image Captioning"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"I.-T. Chen"	"2018"	"A Comparative Study of Autoencoders against Adversarial Attacks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	"A Comparative Study of Autoencoders against Adversarial Attacks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"L. Chen; J. Lingys; K. Chen; F. Liu"	"2018"	"AuTO: scaling deep reinforcement learning for datacenter-scale automatic traffic optimization"	""	"Proceedings of the 2018 Conference of the ACM Special Interest Group on Data Communication"	""	""	""	""	""	""	""	""	""	""	""	""	""	"AuTO: scaling deep reinforcement learning for datacenter-scale automatic traffic optimization"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"M. Cheng; T. Le; P.-Y. Chen; J. Yi; H. Zhang; C.-J. Hsieh"	"2019"	"Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach"	""	"ArXiv"	""	""	"abs/1807.04457"	""	""	""	""	""	""	""	""	""	""	"Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"M. Cheng; J. Yi; H. Zhang; P.-Y. Chen; C.-J. Hsieh"	"2020"	"Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples"	""	"AAAI"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"K. Cho; B. v. Merrienboer; Ç. Gülçehre; D. Bahdanau; F. Bougares; H. Schwenk; Y. Bengio"	"2014"	"Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation"	""	"EMNLP"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"E. Choi; S. Biswal; B. A. Malin; J. D. Duke; W. F. Stewart; J. Sun"	"2017"	"Generating Multi-label Discrete Patient Records using Generative Adversarial Networks"	""	"MLHC"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Generating Multi-label Discrete Patient Records using Generative Adversarial Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"M. Cissé; P. Bojanowski; E. Grave; Y. Dauphin; N. Usunier"	"2017"	"Parseval Networks: Improving Robustness to Adversarial Examples"	""	"ArXiv"	""	""	"abs/1704.08847"	""	""	""	""	""	""	""	""	""	""	"Parseval Networks: Improving Robustness to Adversarial Examples"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"P. Cochat; L. Vaucoret; J. Sarles"	"2012"	"[Et al]"	""	"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie"	""	""	"19 3"	""	""	"228-30"	""	""	""	""	""	""	""	"[Et al]"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"H. Dai; H. Li; T. Tian; X. Huang; L. Wang; J. Zhu; L. Song"	"2018"	"Adversarial Attack on Graph Structured Data"	""	"ICML"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Adversarial Attack on Graph Structured Data"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"E. L. Denton; S. Chintala; A. D. Szlam; R. Fergus"	"2015"	"Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks"	""	"NIPS"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"G. S. Dhillon; K. Azizzadenesheli; Z. C. Lipton; J. Bernstein; J. Kossaifi; A. Khanna; A. Anandkumar"	"2018"	"Stochastic Activation Pruning for Robust Adversarial Defense"	""	"ArXiv"	""	""	"abs/1803.01442"	""	""	""	""	""	""	""	""	""	""	"Stochastic Activation Pruning for Robust Adversarial Defense"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"S. Di; F. Cappello"	"2015"	"GloudSim: Google trace based cloud simulator with virtual machines"	""	"Software: Practice and Experience"	""	""	"45"	""	""	"1571 - 1590"	""	""	""	""	""	""	""	"GloudSim: Google trace based cloud simulator with virtual machines"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"S. Di; D. Kondo; F. Cappello"	"2014"	"Characterizing and modeling cloud applications/jobs on a Google data center"	""	"The Journal of Supercomputing"	""	""	"69"	""	""	"139-160"	""	""	""	""	""	""	""	"Characterizing and modeling cloud applications/jobs on a Google data center"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"L. Dinh; D. Krueger; Y. Bengio"	"2015"	"NICE: Non-linear Independent Components Estimation"	""	"CoRR"	""	""	"abs/1410.8516"	""	""	""	""	""	""	""	""	""	""	"NICE: Non-linear Independent Components Estimation"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"L. Dinh; J. Sohl-Dickstein; S. Bengio"	"2017"	"Density estimation using Real NVP"	""	"ArXiv"	""	""	"abs/1605.08803"	""	""	""	""	""	""	""	""	""	""	"Density estimation using Real NVP"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"C. Dong; C. C. Loy; K. He; X. Tang"	"2016"	"Image Super-Resolution Using Deep Convolutional Networks"	""	"IEEE Transactions on Pattern Analysis and Machine Intelligence"	""	""	"38"	""	""	"295-307"	""	""	""	""	""	""	""	"Image Super-Resolution Using Deep Convolutional Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"H.-W. Dong; W.-Y. Hsiao; L.-C. Yang; Y.-H. Yang"	"2018"	"MuseGAN: Multi-track Sequential Generative Adversarial Networks for Symbolic Music Generation and Accompaniment"	""	"AAAI"	""	""	""	""	""	""	""	""	""	""	""	""	""	"MuseGAN: Multi-track Sequential Generative Adversarial Networks for Symbolic Music Generation and Accompaniment"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"A. Dosovitskiy; J. T. Springenberg; M. Tatarchenko; T. Brox"	"2017"	"Learning to Generate Chairs, Tables and Cars with Convolutional Networks"	""	"IEEE Transactions on Pattern Analysis and Machine Intelligence"	""	""	"39"	""	""	"692-705"	""	""	""	""	""	""	""	"Learning to Generate Chairs, Tables and Cars with Convolutional Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"C. Dwork; A. Roth"	"2014"	"The Algorithmic Foundations of Differential Privacy"	""	"Found. Trends Theor. Comput. Sci."	""	""	"9"	""	""	"211-407"	""	""	""	""	""	""	""	"The Algorithmic Foundations of Differential Privacy"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"C. Dwork; A. D. Smith; T. Steinke; J. Ullman; S. P. Vadhan"	"2015"	"Robust Traceability from Trace Amounts"	""	"2015 IEEE 56th Annual Symposium on Foundations of Computer Science"	""	""	""	""	""	"650-669"	""	""	""	""	""	""	""	"Robust Traceability from Trace Amounts"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"S. Dörner; S. Cammerer; J. Hoydis; S. t. Brink"	"2018"	"Deep Learning Based Communication Over the Air"	""	"IEEE Journal of Selected Topics in Signal Processing"	""	""	"12"	""	""	"132-143"	""	""	""	""	""	""	""	"Deep Learning Based Communication Over the Air"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"L. Engstrom; D. Tsipras; L. Schmidt; A. Madry"	"2017"	"A Rotation and a Translation Suffice: Fooling CNNs with Simple Transformations"	""	"ArXiv"	""	""	"abs/1712.02779"	""	""	""	""	""	""	""	""	""	""	"A Rotation and a Translation Suffice: Fooling CNNs with Simple Transformations"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"C. Esteban; S. L. Hyland; G. Rätsch"	"2017"	"Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs"	""	"ArXiv"	""	""	"abs/1706.02633"	""	""	""	""	""	""	""	""	""	""	"Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"S. Fang; Y. Liu; P. Ning"	"2016"	"Wireless Communications under Broadband Reactive Jamming Attacks"	""	"IEEE Transactions on Dependable and Secure Computing"	""	""	"13"	""	""	"394-408"	""	""	""	""	""	""	""	"Wireless Communications under Broadband Reactive Jamming Attacks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"W. Fedus; I. J. Goodfellow; A. M. Dai"	"2018"	"MaskGAN: Better Text Generation via Filling in the ______"	""	"ArXiv"	""	""	"abs/1801.07736"	""	""	""	""	""	""	""	""	""	""	"MaskGAN: Better Text Generation via Filling in the ______"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"R. Feinman; R. R. Curtin; S. Shintre; A. B. Gardner"	"2017"	"Detecting Adversarial Samples from Artifacts"	""	"ArXiv"	""	""	"abs/1703.00410"	""	""	""	""	""	""	""	""	""	""	"Detecting Adversarial Samples from Artifacts"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"Z. Feng; Y. Zhu"	"2016"	"A Survey on Trajectory Data Mining: Techniques and Applications"	""	"IEEE Access"	""	""	"4"	""	""	"2056-2067"	""	""	""	""	""	""	""	"A Survey on Trajectory Data Mining: Techniques and Applications"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"M. Figurnov; S. Mohamed; A. Mnih"	"2018"	"Implicit Reparameterization Gradients"	""	"NeurIPS"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Implicit Reparameterization Gradients"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"M. Fredrikson; E. Lantz; S. Jha; S. M. Lin; D. Page; T. Ristenpart"	"2014"	"Privacy in Pharmacogenetics: An End-to-End Case Study of Personalized Warfarin Dosing"	""	"Proceedings of the ... USENIX Security Symposium. UNIX Security Symposium"	""	""	"2014"	""	""	"17-32"	""	""	""	""	""	""	""	"Privacy in Pharmacogenetics: An End-to-End Case Study of Personalized Warfarin Dosing"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"M. Frid-Adar; E. Klang; M. M. Amitai; J. Goldberger; H. Greenspan"	"2018"	"Synthetic data augmentation using GAN for improved liver lesion classification"	""	"2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)"	""	""	""	""	""	"289-293"	""	""	""	""	""	""	""	"Synthetic data augmentation using GAN for improved liver lesion classification"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"R. Fu; J. Chen; S. Zeng; Y. Zhuang; A. Sudjianto"	"2019"	"Time Series Simulation by Conditional Generative Adversarial Net"	""	"ERN: Time-Series Models (Single) (Topic)"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Time Series Simulation by Conditional Generative Adversarial Net"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"L. A. Gatys; A. S. Ecker; M. Bethge"	"2015"	"A Neural Algorithm of Artistic Style"	""	"ArXiv"	""	""	"abs/1508.06576"	""	""	""	""	""	""	""	""	""	""	"A Neural Algorithm of Artistic Style"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"T. Giannetsos; S. Gisdakis; P. Papadimitratos"	"2014"	"Trustworthy People-Centric Sensing: Privacy, security and user incentives road-map"	""	"2014 13th Annual Mediterranean Ad Hoc Networking Workshop (MED-HOC-NET)"	""	""	""	""	""	"39-46"	""	""	""	""	""	""	""	"Trustworthy People-Centric Sensing: Privacy, security and user incentives road-map"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"R. B. Girshick"	"2015"	"Fast R-CNN"	""	"2015 IEEE International Conference on Computer Vision (ICCV)"	""	""	""	""	""	"1440-1448"	""	""	""	""	""	""	""	"Fast R-CNN"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"S. Gisdakis; T. Giannetsos; P. Papadimitratos"	"2014"	"SPPEAR: security & privacy-preserving architecture for participatory-sensing applications"	""	"WiSec '14"	""	""	""	""	""	""	""	""	""	""	""	""	""	"SPPEAR: security & privacy-preserving architecture for participatory-sensing applications"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"S. Gisdakis; T. Giannetsos; P. Papadimitratos"	"2015"	"SHIELD: a data verification framework for participatory sensing systems"	""	"Proceedings of the 8th ACM Conference on Security & Privacy in Wireless and Mobile Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	"SHIELD: a data verification framework for participatory sensing systems"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"S. Gisdakis; V. Manolopoulos; S. Tao; A. Rusu; P. Papadimitratos"	"2015"	"Secure and Privacy-Preserving Smartphone-Based Traffic Information Systems"	""	"IEEE Transactions on Intelligent Transportation Systems"	""	""	"16"	""	""	"1428-1438"	""	""	""	""	""	""	""	"Secure and Privacy-Preserving Smartphone-Based Traffic Information Systems"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"I. J. Goodfellow; Y. Bengio; A. C. Courville"	"2015"	"Deep Learning"	""	"Nature"	""	""	"521"	""	""	"436-444"	""	""	""	""	""	""	""	"Deep Learning"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"I. J. Goodfellow; J. Pouget-Abadie; M. Mirza; B. Xu; D. Warde-Farley; S. Ozair; A. C. Courville; Y. Bengio"	"2014"	"Generative Adversarial Nets"	""	"NIPS"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Generative Adversarial Nets"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"I. J. Goodfellow; J. Shlens; C. Szegedy"	"2015"	"Explaining and Harnessing Adversarial Examples"	""	"CoRR"	""	""	"abs/1412.6572"	""	""	""	""	""	""	""	""	""	""	"Explaining and Harnessing Adversarial Examples"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"R. Grandl; G. Ananthanarayanan; S. Kandula; S. Rao; A. Akella"	"2014"	"Multi-resource packing for cluster schedulers"	""	"ACM SIGCOMM Computer Communication Review"	""	""	"44"	""	""	"455 - 466"	""	""	""	""	""	""	""	"Multi-resource packing for cluster schedulers"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"K. Grosse; P. Manoharan; N. Papernot; M. Backes; P. Mcdaniel"	"2017"	"On the (Statistical) Detection of Adversarial Examples"	""	"ArXiv"	""	""	"abs/1702.06280"	""	""	""	""	""	""	""	""	""	""	"On the (Statistical) Detection of Adversarial Examples"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"M. Großhans; C. Sawade; M. Brückner; T. Scheffer"	"2013"	"Bayesian Games for Adversarial Regression Problems"	""	"ICML"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Bayesian Games for Adversarial Regression Problems"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"J. Gu; Y. Shen; B. Zhou"	"2020"	"Image Processing Using Multi-Code GAN Prior"	""	"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)"	""	""	""	""	""	"3009-3018"	""	""	""	""	""	""	""	"Image Processing Using Multi-Code GAN Prior"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"J. Guibas; T. S. Virdi; P. S. Li"	"2017"	"Synthetic Medical Images from Dual Generative Adversarial Networks"	""	"ArXiv"	""	""	"abs/1709.01872"	""	""	""	""	""	""	""	""	""	""	"Synthetic Medical Images from Dual Generative Adversarial Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"I. Gulrajani; F. Ahmed; M. Arjovsky; V. Dumoulin; A. C. Courville"	"2017"	"Improved Training of Wasserstein GANs"	""	"NIPS"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Improved Training of Wasserstein GANs"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"P. Haider; L. Chiarandini; U. Brefeld"	"2012"	"Discriminative clustering for market segmentation"	""	"KDD"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Discriminative clustering for market segmentation"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"C. Han; H. Hayashi; L. Rundo; R. Araki; W. Shimoda; S. Muramatsu; Y. Furukawa; G. Mauri; H. Nakayama"	"2018"	"GAN-based synthetic brain MR image generation"	""	"2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)"	""	""	""	""	""	"734-738"	""	""	""	""	""	""	""	"GAN-based synthetic brain MR image generation"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"S. Hanna; L. Huang; E. X. Wu; S. Li; C. Chen; D. X. Song"	"2012"	"Juxtapp: A Scalable System for Detecting Code Reuse among Android Applications"	""	"DIMVA"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Juxtapp: A Scalable System for Detecting Code Reuse among Android Applications"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"X. Hao; G. Zhang; S. Ma"	"2016"	"Deep Learning"	""	"Int. J. Semantic Comput."	""	""	"10"	""	""	"417-"	""	""	""	""	""	""	""	"Deep Learning"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"J. Hayes; L. Melis; G. Danezis; E. De Cristofaro"	"2017"	"LOGAN: Evaluating Privacy Leakage of Generative Models Using Generative Adversarial Networks"	""	"ArXiv"	""	""	"abs/1705.07663"	""	""	""	""	""	""	""	""	""	""	"LOGAN: Evaluating Privacy Leakage of Generative Models Using Generative Adversarial Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"J. Hayes; L. Melis; G. Danezis; E. De Cristofaro"	"2019"	"LOGAN: Membership Inference Attacks Against Generative Models"	""	"Proceedings on Privacy Enhancing Technologies"	""	""	"2019"	""	""	"133 - 152"	""	""	""	""	""	""	""	"LOGAN: Membership Inference Attacks Against Generative Models"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"E. Hazan; T. Koren"	"2016"	"A linear-time algorithm for trust region problems"	""	"Mathematical Programming"	""	""	"158"	""	""	"363-381"	""	""	""	""	""	""	""	"A linear-time algorithm for trust region problems"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"H. He; S. Jin; C.-K. Wen; F. Gao; G. Y. Li; Z. Xu"	"2019"	"Model-Driven Deep Learning for Physical Layer Communications"	""	"IEEE Wireless Communications"	""	""	"26"	""	""	"77-83"	""	""	""	""	""	""	""	"Model-Driven Deep Learning for Physical Layer Communications"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"H. He; C.-K. Wen; S. Jin; G. Y. Li"	"2018"	"Deep Learning-Based Channel Estimation for Beamspace mmWave Massive MIMO Systems"	""	"IEEE Wireless Communications Letters"	""	""	"7"	""	""	"852-855"	""	""	""	""	""	""	""	"Deep Learning-Based Channel Estimation for Beamspace mmWave Massive MIMO Systems"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"K. He; A. Fisher; L. Wang; A. Gember; A. Akella; T. Ristenpart"	"2013"	"Next stop, the cloud: understanding modern web service deployment in EC2 and azure"	""	"Proceedings of the 2013 conference on Internet measurement conference"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Next stop, the cloud: understanding modern web service deployment in EC2 and azure"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"K. He; X. Zhang; S. Ren; J. Sun"	"2016"	"Deep Residual Learning for Image Recognition"	""	"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"	""	""	""	""	""	"770-778"	""	""	""	""	""	""	""	"Deep Residual Learning for Image Recognition"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"Z. He; W. Zuo; M. Kan; S. Shan; X. Chen"	"2019"	"AttGAN: Facial Attribute Editing by Only Changing What You Want"	""	"IEEE Transactions on Image Processing"	""	""	"28"	""	""	"5464-5478"	""	""	""	""	""	""	""	"AttGAN: Facial Attribute Editing by Only Changing What You Want"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"D. Hendrycks; T. G. Dietterich"	"2018"	"Benchmarking Neural Network Robustness to Common Corruptions and Surface Variations"	""	"arXiv: Learning"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Benchmarking Neural Network Robustness to Common Corruptions and Surface Variations"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"D. Hendrycks; K. Gimpel"	"2016"	"Visible Progress on Adversarial Images and a New Saliency Map"	""	"ArXiv"	""	""	"abs/1608.00530"	""	""	""	""	""	""	""	""	""	""	"Visible Progress on Adversarial Images and a New Saliency Map"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"M. Heusel; H. Ramsauer; T. Unterthiner; B. Nessler; S. Hochreiter"	"2017"	"GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium"	""	"NIPS"	""	""	""	""	""	""	""	""	""	""	""	""	""	"GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"B. Hilprecht; M. Härterich; D. Bernau"	"2019"	"Monte Carlo and Reconstruction Membership Inference Attacks against Generative Models"	""	"Proceedings on Privacy Enhancing Technologies"	""	""	"2019"	""	""	"232 - 249"	""	""	""	""	""	""	""	"Monte Carlo and Reconstruction Membership Inference Attacks against Generative Models"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"G. E. Hinton; L. Deng; D. Yu; G. E. Dahl; A.-r. Mohamed; N. Jaitly; A. W. Senior; V. Vanhoucke; P. Nguyen; T. N. Sainath; B. Kingsbury"	"2012"	"Deep Neural Networks for Acoustic Modeling in Speech Recognition"	""	"IEEE Signal Processing Magazine"	""	""	"29"	""	""	"82"	""	""	""	""	""	""	""	"Deep Neural Networks for Acoustic Modeling in Speech Recognition"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"L. C.-J. Hsieh"	""	"Rob-GAN : Generator , Discriminator , and Adversarial Attacker Xuanqing"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	"Rob-GAN : Generator , Discriminator , and Adversarial Attacker Xuanqing"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"D. Hu; P. Hong; Y. Chen"	"2017"	"FADM: DDoS Flooding Attack Detection and Mitigation System in Software-Defined Networking"	""	"GLOBECOM 2017 - 2017 IEEE Global Communications Conference"	""	""	""	""	""	"1-7"	""	""	""	""	""	""	""	"FADM: DDoS Flooding Attack Detection and Mitigation System in Software-Defined Networking"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"X. Hu; K. G. Shin"	"2013"	"DUET: integration of dynamic and static analyses for malware clustering with cluster ensembles"	""	"Proceedings of the 29th Annual Computer Security Applications Conference"	""	""	""	""	""	""	""	""	""	""	""	""	""	"DUET: integration of dynamic and static analyses for malware clustering with cluster ensembles"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"R. Huang; B. Xu; D. Schuurmans; C. Szepesvari"	"2015"	"Learning with a Strong Adversary"	""	"ArXiv"	""	""	"abs/1511.03034"	""	""	""	""	""	""	""	""	""	""	"Learning with a Strong Adversary"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"X. Huang; Y. Li; O. Poursaeed; J. E. Hopcroft; S. J. Belongie"	"2017"	"Stacked Generative Adversarial Networks"	""	"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"	""	""	""	""	""	"1866-1875"	""	""	""	""	""	""	""	"Stacked Generative Adversarial Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"A. Ilyas; S. Santurkar; D. Tsipras; L. Engstrom; B. Tran; A. Madry"	"2019"	"Adversarial Examples Are Not Bugs, They Are Features"	""	"NeurIPS"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Adversarial Examples Are Not Bugs, They Are Features"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"H. Inoue"	"2018"	"Data Augmentation by Pairing Samples for Images Classification"	""	"ArXiv"	""	""	"abs/1801.02929"	""	""	""	""	""	""	""	""	""	""	"Data Augmentation by Pairing Samples for Images Classification"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"P. Isola; J.-Y. Zhu; T. Zhou; A. A. Efros"	"2017"	"Image-to-Image Translation with Conditional Adversarial Networks"	""	"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"	""	""	""	""	""	"5967-5976"	""	""	""	""	""	""	""	"Image-to-Image Translation with Conditional Adversarial Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"A. Jahanian; L. Chai; P. Isola"	"2020"	"On the "steerability" of generative adversarial networks"	""	"ArXiv"	""	""	"abs/1907.07171"	""	""	""	""	""	""	""	""	""	""	"On the "steerability" of generative adversarial networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"J. Jia; A. Salem; M. Backes; Y. Zhang; N. Z. Gong"	"2019"	"MemGuard"	""	"Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security"	""	""	""	""	""	""	""	""	""	""	""	""	""	"MemGuard"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"J. Jiang; R. Das; G. Ananthanarayanan; P. A. Chou; V. N. Padmanabhan; V. Sekar; E. Dominique; M. Goliszewski; D. Kukoleca; R. Vafin; H. Zhang"	"2016"	"Via: Improving Internet Telephony Call Quality Using Predictive Relay Selection"	""	"Proceedings of the 2016 ACM SIGCOMM Conference"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Via: Improving Internet Telephony Call Quality Using Predictive Relay Selection"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"J. Jiang; V. Sekar; H. Milner; D. Shepherd; I. Stoica; H. Zhang"	"2016"	"CFA: A Practical Prediction System for Video QoE Optimization"	""	"NSDI"	""	""	""	""	""	""	""	""	""	""	""	""	""	"CFA: A Practical Prediction System for Video QoE Optimization"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"A. E. W. Johnson; T. J. Pollard; L. Shen; L.-w. H. Lehman; M. Feng; M. M. Ghassemi; B. Moody; P. Szolovits; L. A. Celi; R. G. Mark"	"2016"	"MIMIC-III, a freely accessible critical care database"	""	"Scientific Data"	""	""	"3"	""	""	""	""	""	""	""	""	""	""	"MIMIC-III, a freely accessible critical care database"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"J. Jordon; J. Yoon; M. v. d. Schaar"	"2019"	"PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees"	""	"ICLR"	""	""	""	""	""	""	""	""	""	""	""	""	""	"PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"A. D. Joseph; P. Laskov; F. Roli; J. D. Tygar; B. Nelson"	"2012"	"Machine Learning Methods for Computer Security (Dagstuhl Perspectives Workshop 12371)"	""	"Dagstuhl Reports"	""	""	"2"	""	""	"109-130"	""	""	""	""	""	""	""	"Machine Learning Methods for Computer Security (Dagstuhl Perspectives Workshop 12371)"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"D.-C. Juan; L. Li; H.-K. Peng; D. Marculescu; C. Faloutsos"	"2014"	"Beyond Poisson: Modeling Inter-Arrival Time of Requests in a Datacenter"	""	"PAKDD"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Beyond Poisson: Modeling Inter-Arrival Time of Requests in a Datacenter"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"N. Kalchbrenner; A. v. d. Oord; K. Simonyan; I. Danihelka; O. Vinyals; A. Graves; K. Kavukcuoglu"	"2017"	"Video Pixel Networks"	""	"ArXiv"	""	""	"abs/1610.00527"	""	""	""	""	""	""	""	""	""	""	"Video Pixel Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"A. Kantchelian; S. Afroz; L. Huang; A. Caliskan; B. Miller; M. C. Tschantz; R. Greenstadt; A. D. Joseph; J. D. Tygar"	"2013"	"Approaches to adversarial drift"	""	"Proceedings of the 2013 ACM workshop on Artificial intelligence and security"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Approaches to adversarial drift"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"T. Karras; T. Aila; S. Laine; J. Lehtinen"	"2018"	"Progressive Growing of GANs for Improved Quality, Stability, and Variation"	""	"ArXiv"	""	""	"abs/1710.10196"	""	""	""	""	""	""	""	""	""	""	"Progressive Growing of GANs for Improved Quality, Stability, and Variation"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"T. Karras; S. Laine; T. Aila"	"2019"	"A Style-Based Generator Architecture for Generative Adversarial Networks"	""	"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)"	""	""	""	""	""	"4396-4405"	""	""	""	""	""	""	""	"A Style-Based Generator Architecture for Generative Adversarial Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"T. Karras; S. Laine; M. Aittala; J. Hellsten; J. Lehtinen; T. Aila"	"2020"	"Analyzing and Improving the Image Quality of StyleGAN"	""	"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)"	""	""	""	""	""	"8107-8116"	""	""	""	""	""	""	""	"Analyzing and Improving the Image Quality of StyleGAN"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"H. Kim; J. Shin; S. Kim; Y. Ko; K. Lee; H. Cha; S.-i. Hahm; T. Kwon"	"2016"	"Collaborative classification for daily activity recognition with a smartwatch"	""	"2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)"	""	""	""	""	""	"003707-003712"	""	""	""	""	""	""	""	"Collaborative classification for daily activity recognition with a smartwatch"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"J. Kim; J. F. Canny"	"2017"	"Interpretable Learning for Self-Driving Cars by Visualizing Causal Attention"	""	"2017 IEEE International Conference on Computer Vision (ICCV)"	""	""	""	""	""	"2961-2969"	""	""	""	""	""	""	""	"Interpretable Learning for Self-Driving Cars by Visualizing Causal Attention"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"J. Kim; J. K. Lee; K. M. Lee"	"2016"	"Deeply-Recursive Convolutional Network for Image Super-Resolution"	""	"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"	""	""	""	""	""	"1637-1645"	""	""	""	""	""	""	""	"Deeply-Recursive Convolutional Network for Image Super-Resolution"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"D. P. Kingma; J. Ba"	"2015"	"Adam: A Method for Stochastic Optimization"	""	"CoRR"	""	""	"abs/1412.6980"	""	""	""	""	""	""	""	""	""	""	"Adam: A Method for Stochastic Optimization"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"D. P. Kingma; P. Dhariwal"	"2018"	"Glow: Generative Flow with Invertible 1x1 Convolutions"	""	"ArXiv"	""	""	"abs/1807.03039"	""	""	""	""	""	""	""	""	""	""	"Glow: Generative Flow with Invertible 1x1 Convolutions"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"D. P. Kingma; M. Welling"	"2014"	"Auto-Encoding Variational Bayes"	""	"CoRR"	""	""	"abs/1312.6114"	""	""	""	""	""	""	""	""	""	""	"Auto-Encoding Variational Bayes"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"L. Koc; T. A. Mazzuchi; S. Sarkani"	"2012"	"A network intrusion detection system based on a Hidden Naïve Bayes multiclass classifier"	""	"Expert Syst. Appl."	""	""	"39"	""	""	"13492-13500"	""	""	""	""	""	""	""	"A network intrusion detection system based on a Hidden Naïve Bayes multiclass classifier"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"P. W. Koh; P. Liang"	"2017"	"Understanding Black-box Predictions via Influence Functions"	""	"ArXiv"	""	""	"abs/1703.04730"	""	""	""	""	""	""	""	""	""	""	"Understanding Black-box Predictions via Influence Functions"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"J. Konecný; H. B. McMahan; F. X. Yu; P. Richtárik; A. T. Suresh; D. Bacon"	"2016"	"Federated Learning: Strategies for Improving Communication Efficiency"	""	"ArXiv"	""	""	"abs/1610.05492"	""	""	""	""	""	""	""	""	""	""	"Federated Learning: Strategies for Improving Communication Efficiency"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"A. Krizhevsky; I. Sutskever; G. E. Hinton"	"2012"	"ImageNet classification with deep convolutional neural networks"	""	"Communications of the ACM"	""	""	"60"	""	""	"84 - 90"	""	""	""	""	""	""	""	"ImageNet classification with deep convolutional neural networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"T. D. Kulkarni; W. F. Whitney; P. Kohli; J. B. Tenenbaum"	"2015"	"Deep Convolutional Inverse Graphics Network"	""	"NIPS"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Deep Convolutional Inverse Graphics Network"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"A. Kurakin; I. J. Goodfellow; S. Bengio"	"2017"	"Adversarial examples in the physical world"	""	"ArXiv"	""	""	"abs/1607.02533"	""	""	""	""	""	""	""	""	""	""	"Adversarial examples in the physical world"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"A. Kurakin; I. J. Goodfellow; S. Bengio"	"2017"	"Adversarial Machine Learning at Scale"	""	"ArXiv"	""	""	"abs/1611.01236"	""	""	""	""	""	""	""	""	""	""	"Adversarial Machine Learning at Scale"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"A. B. L. Larsen; S. K. Sønderby; H. Larochelle; O. Winther"	"2016"	"Autoencoding beyond pixels using a learned similarity metric"	""	"ArXiv"	""	""	"abs/1512.09300"	""	""	""	""	""	""	""	""	""	""	"Autoencoding beyond pixels using a learned similarity metric"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"C. Ledig; L. Theis; F. Huszár; J. Caballero; A. P. Aitken; A. Tejani; J. Totz; Z. Wang; W. Shi"	"2017"	"Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network"	""	"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"	""	""	""	""	""	"105-114"	""	""	""	""	""	""	""	"Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"B. Li; Y. Vorobeychik"	"2014"	"Feature Cross-Substitution in Adversarial Classification"	""	"NIPS"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Feature Cross-Substitution in Adversarial Classification"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"C. Li; M. Wand"	"2016"	"Precomputed Real-Time Texture Synthesis with Markovian Generative Adversarial Networks"	""	"ArXiv"	""	""	"abs/1604.04382"	""	""	""	""	""	""	""	""	""	""	"Precomputed Real-Time Texture Synthesis with Markovian Generative Adversarial Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"T. Li; J. Liu"	"2015"	"Cluster-Based Spatiotemporal Background Traffic Generation for Network Simulation"	""	"ACM Transactions on Modeling and Computer Simulation (TOMACS)"	""	""	"25"	""	""	"1 - 25"	""	""	""	""	""	""	""	"Cluster-Based Spatiotemporal Background Traffic Generation for Network Simulation"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"Y. Li; T. Shen; X. Sun; X. Pan; B. Mao"	"2015"	"Detection, Classification and Characterization of Android Malware Using API Data Dependency"	""	"SecureComm"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Detection, Classification and Characterization of Android Malware Using API Data Dependency"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"Y. Li; K. Swersky; R. S. Zemel"	"2015"	"Generative Moment Matching Networks"	""	"ArXiv"	""	""	"abs/1502.02761"	""	""	""	""	""	""	""	""	""	""	"Generative Moment Matching Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"Z. Li; Z. Ge; A. Mahimkar; J. Wang; B. Y. Zhao; H. Zheng; J. Emmons; L. Ogden"	"2018"	"Predictive Analysis in Network Function Virtualization"	""	"Proceedings of the Internet Measurement Conference 2018"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Predictive Analysis in Network Function Virtualization"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"Z. Li; Y. Zhang"	"2020"	"Label-Leaks: Membership Inference Attack with Label"	""	"ArXiv"	""	""	"abs/2007.15528"	""	""	""	""	""	""	""	""	""	""	"Label-Leaks: Membership Inference Attack with Label"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"F. Liang; C. Shen; F. Wu"	"2018"	"An Iterative BP-CNN Architecture for Channel Decoding"	""	"IEEE Journal of Selected Topics in Signal Processing"	""	""	"12"	""	""	"144-159"	""	""	""	""	""	""	""	"An Iterative BP-CNN Architecture for Channel Decoding"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"T.-Y. Lin; M. Maire; S. J. Belongie; J. Hays; P. Perona; D. Ramanan; P. Dollár; C. L. Zitnick"	"2014"	"Microsoft COCO: Common Objects in Context"	""	"ECCV"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Microsoft COCO: Common Objects in Context"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"Z. Lin; A. Khetan; G. C. Fanti; S. Oh"	"2020"	"PacGAN: The Power of Two Samples in Generative Adversarial Networks"	""	"IEEE Journal on Selected Areas in Information Theory"	""	""	"1"	""	""	"324-335"	""	""	""	""	""	""	""	"PacGAN: The Power of Two Samples in Generative Adversarial Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"G. J. S. Litjens; T. Kooi; B. E. Bejnordi; A. A. A. Setio; F. Ciompi; M. Ghafoorian; J. v. d. Laak; B. v. Ginneken; C. I. Sánchez"	"2017"	"A survey on deep learning in medical image analysis"	""	"Medical image analysis"	""	""	"42"	""	""	"60-88"	""	""	""	""	""	""	""	"A survey on deep learning in medical image analysis"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"N. Liu; Z. Li; Z. Xu; J. Xu; S. Lin; Q. Qiu; J. Tang; Y. Wang"	"2017"	"A Hierarchical Framework of Cloud Resource Allocation and Power Management Using Deep Reinforcement Learning"	""	"2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS)"	""	""	""	""	""	"372-382"	""	""	""	""	""	""	""	"A Hierarchical Framework of Cloud Resource Allocation and Power Management Using Deep Reinforcement Learning"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"X. Liu; Y. Xu; L. Jia; Q.-h. Wu; A. Anpalagan"	"2018"	"Anti-Jamming Communications Using Spectrum Waterfall: A Deep Reinforcement Learning Approach"	""	"IEEE Communications Letters"	""	""	"22"	""	""	"998-1001"	""	""	""	""	""	""	""	"Anti-Jamming Communications Using Spectrum Waterfall: A Deep Reinforcement Learning Approach"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"Z. Liu; P. Luo; X. Wang; X. Tang"	"2015"	"Deep Learning Face Attributes in the Wild"	""	"2015 IEEE International Conference on Computer Vision (ICCV)"	""	""	""	""	""	"3730-3738"	""	""	""	""	""	""	""	"Deep Learning Face Attributes in the Wild"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"M. Lucic; K. Kurach; M. Michalski; S. Gelly; O. Bousquet"	"2018"	"Are GANs Created Equal? A Large-Scale Study"	""	"NeurIPS"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Are GANs Created Equal? A Large-Scale Study"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"X. Ma; B. Li; Y. Wang; S. M. Erfani; S. N. R. Wijewickrema; M. E. Houle; G. R. Schoenebeck; D. X. Song; J. Bailey"	"2018"	"Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality"	""	"ArXiv"	""	""	"abs/1801.02613"	""	""	""	""	""	""	""	""	""	""	"Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"A. Madry; A. Makelov; L. Schmidt; D. Tsipras; A. Vladu"	"2018"	"Towards Deep Learning Models Resistant to Adversarial Attacks"	""	"ArXiv"	""	""	"abs/1706.06083"	""	""	""	""	""	""	""	""	""	""	"Towards Deep Learning Models Resistant to Adversarial Attacks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"D. M. V. Magalhães; R. N. Calheiros; R. Buyya; D. G. Gomes"	"2015"	"Workload modeling for resource usage analysis and simulation in cloud computing"	""	"Comput. Electr. Eng."	""	""	"47"	""	""	"69-81"	""	""	""	""	""	""	""	"Workload modeling for resource usage analysis and simulation in cloud computing"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"D. Maiorca; I. Corona; G. Giacinto"	"2013"	"Looking at the bag is not enough to find the bomb: an evasion of structural methods for malicious PDF files detection"	""	"ASIA CCS '13"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Looking at the bag is not enough to find the bomb: an evasion of structural methods for malicious PDF files detection"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"D. Maiorca; G. Giacinto; I. Corona"	"2012"	"A Pattern Recognition System for Malicious PDF Files Detection"	""	"MLDM"	""	""	""	""	""	""	""	""	""	""	""	""	""	"A Pattern Recognition System for Malicious PDF Files Detection"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"H. Mao; M. Alizadeh; I. Menache; S. Kandula"	"2016"	"Resource Management with Deep Reinforcement Learning"	""	"Proceedings of the 15th ACM Workshop on Hot Topics in Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Resource Management with Deep Reinforcement Learning"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"M. Maqableh; H. Karajeh; R. e. Masa’deh"	"2014"	"Job Scheduling for Cloud Computing Using Neural Networks"	""	"Communications and Network"	""	""	"06"	""	""	"191-200"	""	""	""	""	""	""	""	"Job Scheduling for Cloud Computing Using Neural Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"G. Marti"	"2020"	"CORRGAN: Sampling Realistic Financial Correlation Matrices Using Generative Adversarial Networks"	""	"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"	""	""	""	""	""	"8459-8463"	""	""	""	""	""	""	""	"CORRGAN: Sampling Realistic Financial Correlation Matrices Using Generative Adversarial Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"M. Mathieu; C. Couprie; Y. LeCun"	"2016"	"Deep multi-scale video prediction beyond mean square error"	""	"CoRR"	""	""	"abs/1511.05440"	""	""	""	""	""	""	""	""	""	""	"Deep multi-scale video prediction beyond mean square error"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"A. Mavrogiorgou; A. Kiourtis; D. Kyriazis"	"2017"	"A Comparative Study of Classification Techniques for Managing IoT Devices of Common Specifications"	""	"GECON"	""	""	""	""	""	""	""	""	""	""	""	""	""	"A Comparative Study of Classification Techniques for Managing IoT Devices of Common Specifications"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"H. B. McMahan; E. Moore; D. Ramage; S. Hampson; B. A. y. Arcas"	"2017"	"Communication-Efficient Learning of Deep Networks from Decentralized Data"	""	"AISTATS"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Communication-Efficient Learning of Deep Networks from Decentralized Data"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"S. Mehri; K. Kumar; I. Gulrajani; R. Kumar; S. Jain; J. M. R. Sotelo; A. C. Courville; Y. Bengio"	"2017"	"SampleRNN: An Unconditional End-to-End Neural Audio Generation Model"	""	"ArXiv"	""	""	"abs/1612.07837"	""	""	""	""	""	""	""	""	""	""	"SampleRNN: An Unconditional End-to-End Neural Audio Generation Model"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"S. Mei; X. Zhu"	"2015"	"Using Machine Teaching to Identify Optimal Training-Set Attacks on Machine Learners"	""	"AAAI"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Using Machine Teaching to Identify Optimal Training-Set Attacks on Machine Learners"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"S. Mei; X. Zhu"	"2015"	"The Security of Latent Dirichlet Allocation"	""	"AISTATS"	""	""	""	""	""	""	""	""	""	""	""	""	""	"The Security of Latent Dirichlet Allocation"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"M. Mirza; S. Osindero"	"2014"	"Conditional Generative Adversarial Nets"	""	"ArXiv"	""	""	"abs/1411.1784"	""	""	""	""	""	""	""	""	""	""	"Conditional Generative Adversarial Nets"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"T. Miyato; T. Kataoka; M. Koyama; Y. Yoshida"	"2018"	"Spectral Normalization for Generative Adversarial Networks"	""	"ArXiv"	""	""	"abs/1802.05957"	""	""	""	""	""	""	""	""	""	""	"Spectral Normalization for Generative Adversarial Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"T. Miyato; M. Koyama"	"2018"	"cGANs with Projection Discriminator"	""	"ArXiv"	""	""	"abs/1802.05637"	""	""	""	""	""	""	""	""	""	""	"cGANs with Projection Discriminator"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"V. Mnih; K. Kavukcuoglu; D. Silver; A. Graves; I. Antonoglou; D. Wierstra; M. A. Riedmiller"	"2013"	"Playing Atari with Deep Reinforcement Learning"	""	"ArXiv"	""	""	"abs/1312.5602"	""	""	""	""	""	""	""	""	""	""	"Playing Atari with Deep Reinforcement Learning"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"O. Mogren"	"2016"	"C-RNN-GAN: Continuous recurrent neural networks with adversarial training"	""	"ArXiv"	""	""	"abs/1611.09904"	""	""	""	""	""	""	""	""	""	""	"C-RNN-GAN: Continuous recurrent neural networks with adversarial training"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"B. Montazeri; Y. Li; M. Alizadeh; J. K. Ousterhout"	"2018"	"Homa: a receiver-driven low-latency transport protocol using network priorities"	""	"Proceedings of the 2018 Conference of the ACM Special Interest Group on Data Communication"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Homa: a receiver-driven low-latency transport protocol using network priorities"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"B. Montazeri; Y. Li; M. Alizadeh; J. K. Ousterhout"	"2018"	"Homa"	""	"Proceedings of the 2018 Conference of the ACM Special Interest Group on Data Communication"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Homa"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"I. S. Moreno; P. Garraghan; P. Townend; J. Xu"	"2014"	"Analysis, Modeling and Simulation of Workload Patterns in a Large-Scale Utility Cloud"	""	"IEEE Transactions on Cloud Computing"	""	""	"2"	""	""	"208-221"	""	""	""	""	""	""	""	"Analysis, Modeling and Simulation of Workload Patterns in a Large-Scale Utility Cloud"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"A. Mukherjee; S. A. A. Fakoorian; J. Huang; A. L. Swindlehurst"	"2014"	"Principles of Physical Layer Security in Multiuser Wireless Networks: A Survey"	""	"IEEE Communications Surveys & Tutorials"	""	""	"16"	""	""	"1550-1573"	""	""	""	""	""	""	""	"Principles of Physical Layer Security in Multiuser Wireless Networks: A Survey"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"S. Mund"	"2015"	"Microsoft Azure Machine Learning"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	"Microsoft Azure Machine Learning"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"E. Nachmani; E. Marciano; L. Lugosch; W. J. Gross; D. Burshtein; Y. Be’ery"	"2018"	"Deep Learning Methods for Improved Decoding of Linear Codes"	""	"IEEE Journal of Selected Topics in Signal Processing"	""	""	"12"	""	""	"119-131"	""	""	""	""	""	""	""	"Deep Learning Methods for Improved Decoding of Linear Codes"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"D. W. K. Ng; E. S. Lo; R. Schober"	"2014"	"Robust Beamforming for Secure Communication in Systems With Wireless Information and Power Transfer"	""	"IEEE Transactions on Wireless Communications"	""	""	"13"	""	""	"4599-4615"	""	""	""	""	""	""	""	"Robust Beamforming for Secure Communication in Systems With Wireless Information and Power Transfer"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"N. H. Nguyen; T. D. Tran"	"2013"	"Robust Lasso With Missing and Grossly Corrupted Observations"	""	"IEEE Transactions on Information Theory"	""	""	"59"	""	""	"2036-2058"	""	""	""	""	""	""	""	"Robust Lasso With Missing and Grossly Corrupted Observations"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"T. T. S. Nguyen; H. H. Lu; J. Lu"	"2014"	"Web-Page Recommendation Based on Web Usage and Domain Knowledge"	""	"IEEE Transactions on Knowledge and Data Engineering"	""	""	"26"	""	""	"2574-2587"	""	""	""	""	""	""	""	"Web-Page Recommendation Based on Web Usage and Domain Knowledge"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"N. A. Nystrom; M. J. Levine; R. Roskies; J. R. Scott"	"2015"	"Bridges: a uniquely flexible HPC resource for new communities and data analytics"	""	"Proceedings of the 2015 XSEDE Conference: Scientific Advancements Enabled by Enhanced Cyberinfrastructure"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Bridges: a uniquely flexible HPC resource for new communities and data analytics"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"T. O'Shea; J. Hoydis"	"2017"	"An Introduction to Deep Learning for the Physical Layer"	""	"IEEE Transactions on Cognitive Communications and Networking"	""	""	"3"	""	""	"563-575"	""	""	""	""	""	""	""	"An Introduction to Deep Learning for the Physical Layer"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"A. Odena; C. Olah; J. Shlens"	"2017"	"Conditional Image Synthesis with Auxiliary Classifier GANs"	""	"ICML"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Conditional Image Synthesis with Auxiliary Classifier GANs"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"A. v. d. Oord; S. Dieleman; H. Zen; K. Simonyan; O. Vinyals; A. Graves; N. Kalchbrenner; A. W. Senior; K. Kavukcuoglu"	"2016"	"WaveNet: A Generative Model for Raw Audio"	""	"SSW"	""	""	""	""	""	""	""	""	""	""	""	""	""	"WaveNet: A Generative Model for Raw Audio"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"A. v. d. Oord; N. Kalchbrenner; L. Espeholt; K. Kavukcuoglu; O. Vinyals; A. Graves"	"2016"	"Conditional Image Generation with PixelCNN Decoders"	""	"ArXiv"	""	""	"abs/1606.05328"	""	""	""	""	""	""	""	""	""	""	"Conditional Image Generation with PixelCNN Decoders"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"N. Ouyang; X. Jiang; E. Bai; H. Wang"	"2017"	"Destination Assisted Jamming and Beamforming for Improving the Security of AF Relay Systems"	""	"IEEE Access"	""	""	"5"	""	""	"4125-4131"	""	""	""	""	""	""	""	"Destination Assisted Jamming and Beamforming for Improving the Security of AF Relay Systems"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"N. Papernot; F. Faghri; N. Carlini; I. J. Goodfellow; R. Feinman; A. Kurakin; C. Xie; Y. Sharma; T. B. Brown; A. Roy; A. Matyasko; V. Behzadan; K. Hambardzumyan; Z. Zhang; Y.-L. Juang; Z. Li; R. Sheatsley; A. Garg; J. Uesato; W. Gierke; Y. Dong; D. Berthelot; P. N. J. Hendricks; J. Rauber; R. Long; P. Mcdaniel"	"2016"	"Technical Report on the CleverHans v2.1.0 Adversarial Examples Library"	""	"arXiv: Learning"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Technical Report on the CleverHans v2.1.0 Adversarial Examples Library"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"N. Papernot; P. Mcdaniel"	"2018"	"Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust Deep Learning"	""	"ArXiv"	""	""	"abs/1803.04765"	""	""	""	""	""	""	""	""	""	""	"Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust Deep Learning"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"N. Papernot; P. Mcdaniel; I. J. Goodfellow"	"2016"	"Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples"	""	"ArXiv"	""	""	"abs/1605.07277"	""	""	""	""	""	""	""	""	""	""	"Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"N. Papernot; P. Mcdaniel; I. J. Goodfellow; S. Jha; Z. B. Celik; A. Swami"	"2016"	"Practical Black-Box Attacks against Deep Learning Systems using Adversarial Examples"	""	"ArXiv"	""	""	"abs/1602.02697"	""	""	""	""	""	""	""	""	""	""	"Practical Black-Box Attacks against Deep Learning Systems using Adversarial Examples"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"D. Pathak; P. Krähenbühl; J. Donahue; T. Darrell; A. A. Efros"	"2016"	"Context Encoders: Feature Learning by Inpainting"	""	"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"	""	""	""	""	""	"2536-2544"	""	""	""	""	""	""	""	"Context Encoders: Feature Learning by Inpainting"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"R. Perdisci; D. Ariu; G. Giacinto"	"2013"	"Scalable fine-grained behavioral clustering of HTTP-based malware"	""	"Comput. Networks"	""	""	"57"	""	""	"487-500"	""	""	""	""	""	""	""	"Scalable fine-grained behavioral clustering of HTTP-based malware"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"R. Perdisci; U. ManChon"	"2012"	"VAMO: towards a fully automated malware clustering validity analysis"	""	"ACSAC '12"	""	""	""	""	""	""	""	""	""	""	""	""	""	"VAMO: towards a fully automated malware clustering validity analysis"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"L. T. Phong; Y. Aono; T. Hayashi; L. Wang; S. Moriai"	"2017"	"Privacy-Preserving Deep Learning: Revisited and Enhanced"	""	"ATIS"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Privacy-Preserving Deep Learning: Revisited and Enhanced"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"A. D. Pozzolo; G. Boracchi; O. Caelen; C. Alippi; G. Bontempi"	"2015"	"Credit card fraud detection and concept-drift adaptation with delayed supervised information"	""	"2015 International Joint Conference on Neural Networks (IJCNN)"	""	""	""	""	""	"1-8"	""	""	""	""	""	""	""	"Credit card fraud detection and concept-drift adaptation with delayed supervised information"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"A. Pyrgelis; C. Troncoso; E. De Cristofaro"	"2017"	"What Does The Crowd Say About You? Evaluating Aggregation-based Location Privacy"	""	"Proceedings on Privacy Enhancing Technologies"	""	""	"2017"	""	""	"156 - 176"	""	""	""	""	""	""	""	"What Does The Crowd Say About You? Evaluating Aggregation-based Location Privacy"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"Z. Qin; H. Ye; G. Y. Li; B.-H. Juang"	"2019"	"Deep Learning in Physical Layer Communications"	""	"IEEE Wireless Communications"	""	""	"26"	""	""	"93-99"	""	""	""	""	""	""	""	"Deep Learning in Physical Layer Communications"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"A. Radford; L. Metz; S. Chintala"	"2016"	"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks"	""	"CoRR"	""	""	"abs/1511.06434"	""	""	""	""	""	""	""	""	""	""	"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"S. S. Rahman; R. Heartfield; W. Oliff; G. Loukas; A. Filippoupolitis"	"2017"	"Assessing the cyber-trustworthiness of human-as-a-sensor reports from mobile devices"	""	"2017 IEEE 15th International Conference on Software Engineering Research, Management and Applications (SERA)"	""	""	""	""	""	"387-394"	""	""	""	""	""	""	""	"Assessing the cyber-trustworthiness of human-as-a-sensor reports from mobile devices"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"M. Rezaei; H. Yang; C. Meinel"	"2017"	"Deep Learning for Medical Image Analysis"	""	"ArXiv"	""	""	"abs/1708.08987"	""	""	""	""	""	""	""	""	""	""	"Deep Learning for Medical Image Analysis"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"M. T. Ribeiro; S. Singh; C. Guestrin"	"2016"	""Why Should I Trust You?": Explaining the Predictions of Any Classifier"	""	"Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining"	""	""	""	""	""	""	""	""	""	""	""	""	""	""Why Should I Trust You?": Explaining the Predictions of Any Classifier"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"G. Rontidis; E. A. Panaousis; A. Laszka; T. Dagiuklas; P. Malacaria; T. Alpcan"	"2015"	"A game-theoretic approach for minimizing security risks in the Internet-of-Things"	""	"2015 IEEE International Conference on Communication Workshop (ICCW)"	""	""	""	""	""	"2639-2644"	""	""	""	""	""	""	""	"A game-theoretic approach for minimizing security risks in the Internet-of-Things"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"O. Russakovsky; J. Deng; H. Su; J. Krause; S. Satheesh; S. Ma; Z. Huang; A. Karpathy; A. Khosla; M. S. Bernstein; A. C. Berg; L. Fei-Fei"	"2015"	"ImageNet Large Scale Visual Recognition Challenge"	""	"International Journal of Computer Vision"	""	""	"115"	""	""	"211-252"	""	""	""	""	""	""	""	"ImageNet Large Scale Visual Recognition Challenge"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"A. Sablayrolles; M. Douze; C. Schmid; Y. Ollivier; H. Jégou"	"2019"	"White-box vs Black-box: Bayes Optimal Strategies for Membership Inference"	""	"ICML"	""	""	""	""	""	""	""	""	""	""	""	""	""	"White-box vs Black-box: Bayes Optimal Strategies for Membership Inference"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"S. Sabour; Y. Cao; F. Faghri; D. J. Fleet"	"2016"	"Adversarial Manipulation of Deep Representations"	""	"CoRR"	""	""	"abs/1511.05122"	""	""	""	""	""	""	""	""	""	""	"Adversarial Manipulation of Deep Representations"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"T. Salimans; D. P. Kingma"	"2016"	"Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks"	""	"NIPS"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"P. Samangouei; M. Kabkab; R. Chellappa"	"2018"	"Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models"	""	"ArXiv"	""	""	"abs/1805.06605"	""	""	""	""	""	""	""	""	""	""	"Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"L. Sankar; S. R. Rajagopalan; H. V. Poor"	"2013"	"Utility-Privacy Tradeoffs in Databases: An Information-Theoretic Approach"	""	"IEEE Transactions on Information Forensics and Security"	""	""	"8"	""	""	"838-852"	""	""	""	""	""	""	""	"Utility-Privacy Tradeoffs in Databases: An Information-Theoretic Approach"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"R. Shokri; V. Shmatikov"	"2015"	"Privacy-preserving deep learning"	""	"2015 53rd Annual Allerton Conference on Communication, Control, and Computing (Allerton)"	""	""	""	""	""	"909-910"	""	""	""	""	""	""	""	"Privacy-preserving deep learning"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"D. Silver; T. Hubert; J. Schrittwieser; I. Antonoglou; M. Lai; A. Guez; M. Lanctot; L. Sifre; D. Kumaran; T. Graepel; T. P. Lillicrap; K. Simonyan; D. Hassabis"	"2017"	"Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm"	""	"ArXiv"	""	""	"abs/1712.01815"	""	""	""	""	""	""	""	""	""	""	"Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"D. Silver; J. Schrittwieser; K. Simonyan; I. Antonoglou; A. Huang; A. Guez; T. Hubert; L. baker; M. Lai; A. Bolton; Y. Chen; T. P. Lillicrap; F. Hui; L. Sifre; G. v. d. Driessche; T. Graepel; D. Hassabis"	"2017"	"Mastering the game of Go without human knowledge"	""	"Nature"	""	""	"550"	""	""	"354-359"	""	""	""	""	""	""	""	"Mastering the game of Go without human knowledge"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"K. Simonyan; A. Vedaldi; A. Zisserman"	"2014"	"Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps"	""	"CoRR"	""	""	"abs/1312.6034"	""	""	""	""	""	""	""	""	""	""	"Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"K. Simonyan; A. Zisserman"	"2015"	"Very Deep Convolutional Networks for Large-Scale Image Recognition"	""	"CoRR"	""	""	"abs/1409.1556"	""	""	""	""	""	""	""	""	""	""	"Very Deep Convolutional Networks for Large-Scale Image Recognition"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"A. Sinha; H. Namkoong; J. C. Duchi"	"2017"	"Certifiable Distributional Robustness with Principled Adversarial Training"	""	"ArXiv"	""	""	"abs/1710.10571"	""	""	""	""	""	""	""	""	""	""	"Certifiable Distributional Robustness with Principled Adversarial Training"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"A. Sinha; H. Namkoong; J. C. Duchi"	"2018"	"Certifying Some Distributional Robustness with Principled Adversarial Training"	""	"arXiv: Machine Learning"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Certifying Some Distributional Robustness with Principled Adversarial Training"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"L. Sliwko; V. Getov"	"2016"	"AGOCS — Accurate Google Cloud Simulator Framework"	""	"2016 Intl IEEE Conferences on Ubiquitous Intelligence & Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People, and Smart World Congress (UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld)"	""	""	""	""	""	"550-558"	""	""	""	""	""	""	""	"AGOCS — Accurate Google Cloud Simulator Framework"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"V. Smith; C.-K. Chiang; M. Sanjabi; A. S. Talwalkar"	"2017"	"Federated Multi-Task Learning"	""	"NIPS"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Federated Multi-Task Learning"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"C. Smutz; A. Stavrou"	"2012"	"Malicious PDF detection using metadata and structural features"	""	"ACSAC '12"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Malicious PDF detection using metadata and structural features"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"M. Soltani; V. Pourahmadi; A. Mirzaei; H. Sheikhzadeh"	"2019"	"Deep Learning-Based Channel Estimation"	""	"IEEE Communications Letters"	""	""	"23"	""	""	"652-655"	""	""	""	""	""	""	""	"Deep Learning-Based Channel Estimation"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"S. Song; K. Chaudhuri; A. D. Sarwate"	"2015"	"Learning from Data with Heterogeneous Noise using SGD"	""	"JMLR workshop and conference proceedings"	""	""	"2015"	""	""	"894-902"	""	""	""	""	""	""	""	"Learning from Data with Heterogeneous Noise using SGD"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"Y. Song; T. Kim; S. Nowozin; S. Ermon; N. Kushman"	"2018"	"PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples"	""	"ArXiv"	""	""	"abs/1710.10766"	""	""	""	""	""	""	""	""	""	""	"PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"A. Srivastava; L. Valkov; C. Russell; M. U. Gutmann; C. Sutton"	"2017"	"VEEGAN: Reducing Mode Collapse in GANs using Implicit Variational Learning"	""	"NIPS"	""	""	""	""	""	""	""	""	""	""	""	""	""	"VEEGAN: Reducing Mode Collapse in GANs using Implicit Variational Learning"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"M. Srivatsa; M. W. Hicks"	"2012"	"Deanonymizing mobility traces: using social network as a side-channel"	""	"Proceedings of the 2012 ACM conference on Computer and communications security"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Deanonymizing mobility traces: using social network as a side-channel"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"N. Srndic; P. Laskov"	"2013"	"Detection of Malicious PDF Files Based on Hierarchical Document Structure"	""	"NDSS"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Detection of Malicious PDF Files Based on Hierarchical Document Structure"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"S. Sundaresan; X. Deng; Y. Feng; D. H. Lee; A. Dhamdhere"	"2017"	"Challenges in inferring internet congestion using throughput measurements"	""	"Proceedings of the 2017 Internet Measurement Conference"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Challenges in inferring internet congestion using throughput measurements"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"I. Sutskever; O. Vinyals; Q. V. Le"	"2014"	"Sequence to Sequence Learning with Neural Networks"	""	"NIPS"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Sequence to Sequence Learning with Neural Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"R. Swami; M. Dave; V. Ranga"	"2019"	"Software-defined Networking-based DDoS Defense Mechanisms"	""	"ACM Computing Surveys (CSUR)"	""	""	"52"	""	""	"1 - 36"	""	""	""	""	""	""	""	"Software-defined Networking-based DDoS Defense Mechanisms"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"C. Szegedy; W. Liu; Y. Jia; P. Sermanet; S. E. Reed; D. Anguelov; D. Erhan; V. Vanhoucke; A. Rabinovich"	"2015"	"Going deeper with convolutions"	""	"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"	""	""	""	""	""	"1-9"	""	""	""	""	""	""	""	"Going deeper with convolutions"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"C. Szegedy; W. Zaremba; I. Sutskever; J. Bruna; D. Erhan; I. J. Goodfellow; R. Fergus"	"2014"	"Intriguing properties of neural networks"	""	"CoRR"	""	""	"abs/1312.6199"	""	""	""	""	""	""	""	""	""	""	"Intriguing properties of neural networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"P. Tabacof; J. Tavares; E. Valle"	"2016"	"Adversarial Images for Variational Autoencoders"	""	"ArXiv"	""	""	"abs/1612.00155"	""	""	""	""	""	""	""	""	""	""	"Adversarial Images for Variational Autoencoders"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"V. Tarasov; E. Zadok; S. Shepler"	"2016"	"Filebench: A Flexible Framework for File System Benchmarking"	""	"login Usenix Mag."	""	""	"41"	""	""	""	""	""	""	""	""	""	""	"Filebench: A Flexible Framework for File System Benchmarking"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"J. Thies; M. Zollhöfer; M. Nießner; L. Valgaerts; M. Stamminger; C. Theobalt"	"2015"	"Real-time expression transfer for facial reenactment"	""	"ACM Transactions on Graphics (TOG)"	""	""	"34"	""	""	"1 - 14"	""	""	""	""	""	""	""	"Real-time expression transfer for facial reenactment"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"G. Toderici; S. M. O'Malley; S. J. Hwang; D. Vincent; D. C. Minnen; S. Baluja; M. Covell; R. Sukthankar"	"2016"	"Variable Rate Image Compression with Recurrent Neural Networks"	""	"CoRR"	""	""	"abs/1511.06085"	""	""	""	""	""	""	""	""	""	""	"Variable Rate Image Compression with Recurrent Neural Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"G. Toderici; D. Vincent; N. Johnston; S. J. Hwang; D. C. Minnen; J. Shor; M. Covell"	"2017"	"Full Resolution Image Compression with Recurrent Neural Networks"	""	"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"	""	""	""	""	""	"5435-5443"	""	""	""	""	""	""	""	"Full Resolution Image Compression with Recurrent Neural Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"Y. Tokozume; Y. Ushiku; T. Harada"	"2018"	"Learning from Between-class Examples for Deep Sound Recognition"	""	"ArXiv"	""	""	"abs/1711.10282"	""	""	""	""	""	""	""	""	""	""	"Learning from Between-class Examples for Deep Sound Recognition"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"J. Towns; T. M. Cockerill; M. Dahan; I. T. Foster; K. P. Gaither; A. S. Grimshaw; V. Hazlewood; S. D. Lathrop; D. A. Lifka; G. D. Peterson; R. Roskies; J. R. Scott; N. Wilkins-Diehr"	"2014"	"XSEDE: Accelerating Scientific Discovery"	""	"Computing in Science & Engineering"	""	""	"16"	""	""	"62-74"	""	""	""	""	""	""	""	"XSEDE: Accelerating Scientific Discovery"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"F. Tramèr; F. Zhang; A. Juels; M. K. Reiter; T. Ristenpart"	"2016"	"Stealing Machine Learning Models via Prediction APIs"	""	"ArXiv"	""	""	"abs/1609.02943"	""	""	""	""	""	""	""	""	""	""	"Stealing Machine Learning Models via Prediction APIs"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"P. Trifonov"	"2015"	"Design of polar codes for Rayleigh fading channel"	""	"2015 International Symposium on Wireless Communication Systems (ISWCS)"	""	""	""	""	""	"331-335"	""	""	""	""	""	""	""	"Design of polar codes for Rayleigh fading channel"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"D. Tsipras; S. Santurkar; L. Engstrom; A. Turner; A. Madry"	"2019"	"Robustness May Be at Odds with Accuracy"	""	"arXiv: Machine Learning"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Robustness May Be at Odds with Accuracy"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"G. Tucker; A. Mnih; C. J. Maddison; J. Lawson; J. Sohl-Dickstein"	"2017"	"REBAR: Low-variance, unbiased gradient estimates for discrete latent variable models"	""	"NIPS"	""	""	""	""	""	""	""	""	""	""	""	""	""	"REBAR: Low-variance, unbiased gradient estimates for discrete latent variable models"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"T. Unterthiner; B. Nessler; G. Klambauer; M. Heusel; H. Ramsauer; S. Hochreiter"	"2018"	"Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields"	""	"ArXiv"	""	""	"abs/1708.08819"	""	""	""	""	""	""	""	""	""	""	"Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"R. Vedantam; C. L. Zitnick; D. Parikh"	"2015"	"CIDEr: Consensus-based image description evaluation"	""	"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"	""	""	""	""	""	"4566-4575"	""	""	""	""	""	""	""	"CIDEr: Consensus-based image description evaluation"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"O. Vinyals; A. Toshev; S. Bengio; D. Erhan"	"2015"	"Show and tell: A neural image caption generator"	""	"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"	""	""	""	""	""	"3156-3164"	""	""	""	""	""	""	""	"Show and tell: A neural image caption generator"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"X. Wang; J. Eaton; C.-J. Hsieh; S. F. Wu"	"2018"	"Attack Graph Convolutional Networks by Adding Fake Nodes"	""	"ArXiv"	""	""	"abs/1810.10751"	""	""	""	""	""	""	""	""	""	""	"Attack Graph Convolutional Networks by Adding Fake Nodes"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"Y. Wang; S. Jha; K. Chaudhuri"	"2018"	"Analyzing the Robustness of Nearest Neighbors to Adversarial Examples"	""	"ICML"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Analyzing the Robustness of Nearest Neighbors to Adversarial Examples"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"M. Wozniak; M. Graña; E. S. Corchado"	"2014"	"A survey of multiple classifier systems as hybrid systems"	""	"Inf. Fusion"	""	""	"16"	""	""	"3-17"	""	""	""	""	""	""	""	"A survey of multiple classifier systems as hybrid systems"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"Y. Wu; F. Yang; H. Ling"	"2018"	"Privacy-Protective-GAN for Face De-identification"	""	"ArXiv"	""	""	"abs/1806.08906"	""	""	""	""	""	""	""	""	""	""	"Privacy-Protective-GAN for Face De-identification"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"C. Xie; J. Wang; Z. Zhang; Z. Ren; A. L. Yuille"	"2018"	"Mitigating adversarial effects through randomization"	""	"ArXiv"	""	""	"abs/1711.01991"	""	""	""	""	""	""	""	""	""	""	"Mitigating adversarial effects through randomization"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"L. Xie; K. Lin; S. Wang; F. Wang; J. Zhou"	"2018"	"Differentially Private Generative Adversarial Network"	""	"ArXiv"	""	""	"abs/1802.06739"	""	""	""	""	""	""	""	""	""	""	"Differentially Private Generative Adversarial Network"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"K. Xu; J. Ba; R. Kiros; K. Cho; A. C. Courville; R. Salakhutdinov; R. S. Zemel; Y. Bengio"	"2015"	"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention"	""	"ICML"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"Q. Xu; G. Huang; Y. Yuan; C. Guo; Y. Sun; F. Wu; K. Q. Weinberger"	"2018"	"An empirical study on evaluation metrics of generative adversarial networks"	""	"ArXiv"	""	""	"abs/1806.07755"	""	""	""	""	""	""	""	""	""	""	"An empirical study on evaluation metrics of generative adversarial networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"X. Xu; X. Chen; C. Liu; A. Rohrbach; T. Darrell; D. X. Song"	"2017"	"Can you fool AI with adversarial examples on a visual Turing test?"	""	"ArXiv"	""	""	"abs/1709.08693"	""	""	""	""	""	""	""	""	""	""	"Can you fool AI with adversarial examples on a visual Turing test?"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"X. Yan; J. Yang; K. Sohn; H. Lee"	"2016"	"Attribute2Image: Conditional Image Generation from Visual Attributes"	""	"ArXiv"	""	""	"abs/1512.00570"	""	""	""	""	""	""	""	""	""	""	"Attribute2Image: Conditional Image Generation from Visual Attributes"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"Q. Yang; Y. Liu; T. Chen; Y. Tong"	"2019"	"Federated Machine Learning"	""	"ACM Transactions on Intelligent Systems and Technology (TIST)"	""	""	"10"	""	""	"1 - 19"	""	""	""	""	""	""	""	"Federated Machine Learning"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"H. Ye; L. Liang; G. Y. Li; B.-H. Juang"	"2020"	"Deep Learning-Based End-to-End Wireless Communication Systems With Conditional GANs as Unknown Channels"	""	"IEEE Transactions on Wireless Communications"	""	""	"19"	""	""	"3133-3143"	""	""	""	""	""	""	""	"Deep Learning-Based End-to-End Wireless Communication Systems With Conditional GANs as Unknown Channels"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"X. Yi; E. Walia; P. S. Babyn"	"2019"	"Generative Adversarial Network in Medical Imaging: A Review"	""	"Medical image analysis"	""	""	"58"	""	""	"101552"	""	""	""	""	""	""	""	"Generative Adversarial Network in Medical Imaging: A Review"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"J. Yin; X. Lu; X. Zhao; H. Chen; X. Liu"	"2015"	"BURSE: A Bursty and Self-Similar Workload Generator for Cloud Computing"	""	"IEEE Transactions on Parallel and Distributed Systems"	""	""	"26"	""	""	"668-680"	""	""	""	""	""	""	""	"BURSE: A Bursty and Self-Similar Workload Generator for Cloud Computing"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"Z. Yin; F. Wang; W. Liu; S. Chawla"	"2014"	"Sparse Feature Attacks in Adversarial Learning"	""	"IEEE Transactions on Knowledge and Data Engineering"	""	""	"30"	""	""	"1164-1177"	""	""	""	""	""	""	""	"Sparse Feature Attacks in Adversarial Learning"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"J. Yoon; D. Jarrett; M. v. d. Schaar"	"2019"	"Time-series Generative Adversarial Networks"	""	"NeurIPS"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Time-series Generative Adversarial Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"L. Yu; W. Zhang; J. Wang; Y. Yu"	"2017"	"SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient"	""	"ArXiv"	""	""	"abs/1609.05473"	""	""	""	""	""	""	""	""	""	""	"SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"N. Yu; C. Barnes; E. Shechtman; S. Amirghodsi; M. Lukác"	"2019"	"Texture Mixer: A Network for Controllable Synthesis and Interpolation of Texture"	""	"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)"	""	""	""	""	""	"12156-12165"	""	""	""	""	""	""	""	"Texture Mixer: A Network for Controllable Synthesis and Interpolation of Texture"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"N. Yu; K. Li; P. Zhou; J. Malik; L. Davis; M. Fritz"	"2020"	"Inclusive GAN: Improving Data and Minority Coverage in Generative Models"	""	"ArXiv"	""	""	"abs/2004.03355"	""	""	""	""	""	""	""	""	""	""	"Inclusive GAN: Improving Data and Minority Coverage in Generative Models"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"E. L. Zec; H. Arnelid; N. Mohammadiha"	"2019"	"Recurrent Conditional GANs for Time Series Sensor Modelling"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	"Recurrent Conditional GANs for Time Series Sensor Modelling"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"H. Zhang; M. Cissé; Y. Dauphin; D. Lopez-Paz"	"2018"	"mixup: Beyond Empirical Risk Minimization"	""	"ArXiv"	""	""	"abs/1710.09412"	""	""	""	""	""	""	""	""	""	""	"mixup: Beyond Empirical Risk Minimization"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"H. Zhang; J. Wang"	"2019"	"Defense Against Adversarial Attacks Using Feature Scattering-based Adversarial Training"	""	"NeurIPS"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Defense Against Adversarial Attacks Using Feature Scattering-based Adversarial Training"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"P. Zhang; F. Wang; J. Hu; R. Sorrentino"	"2015"	"Label Propagation Prediction of Drug-Drug Interactions Based on Clinical Side Effects"	""	"Scientific Reports"	""	""	"5"	""	""	""	""	""	""	""	""	""	""	"Label Propagation Prediction of Drug-Drug Interactions Based on Clinical Side Effects"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"Q. Zhang; Y. N. Wu; S.-C. Zhu"	"2018"	"Interpretable Convolutional Neural Networks"	""	"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"	""	""	""	""	""	"8827-8836"	""	""	""	""	""	""	""	"Interpretable Convolutional Neural Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"R. Zhang; P. Isola; A. A. Efros; E. Shechtman; O. Wang"	"2018"	"The Unreasonable Effectiveness of Deep Features as a Perceptual Metric"	""	"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"	""	""	""	""	""	"586-595"	""	""	""	""	""	""	""	"The Unreasonable Effectiveness of Deep Features as a Perceptual Metric"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"X. Zhang; S. Ji; T. Wang"	"2018"	"Differentially Private Releasing via Deep Generative Model"	""	"ArXiv"	""	""	"abs/1801.01594"	""	""	""	""	""	""	""	""	""	""	"Differentially Private Releasing via Deep Generative Model"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"Y. Zhang; Y. Zhang; J. Zhang; Q. Dai"	"2016"	"CCR: Clustering and Collaborative Representation for Fast Single Image Super-Resolution"	""	"IEEE Transactions on Multimedia"	""	""	"18"	""	""	"405-417"	""	""	""	""	""	""	""	"CCR: Clustering and Collaborative Representation for Fast Single Image Super-Resolution"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"Y. Zhang; Y. Zhang; J. Zhang; D. Xu; Y. R. Fu; Y. Wang; X. Ji; Q. Dai"	"2019"	"Collaborative Representation Cascade for Single-Image Super-Resolution"	""	"IEEE Transactions on Systems, Man, and Cybernetics: Systems"	""	""	"49"	""	""	"845-860"	""	""	""	""	""	""	""	"Collaborative Representation Cascade for Single-Image Super-Resolution"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"G. Zheng; I. Krikidis; J. Li; A. P. Petropulu; B. E. Ottersten"	"2013"	"Improving Physical Layer Secrecy Using Full-Duplex Jamming Receivers"	""	"IEEE Transactions on Signal Processing"	""	""	"61"	""	""	"4962-4974"	""	""	""	""	""	""	""	"Improving Physical Layer Secrecy Using Full-Duplex Jamming Receivers"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"Y. Zhou; M. Kantarcioglu; B. M. Thuraisingham; B. Xi"	"2012"	"Adversarial support vector machine learning"	""	"KDD"	""	""	""	""	""	""	""	""	""	""	""	""	""	"Adversarial support vector machine learning"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"Y. Zhou; Z. Zhu; X. Bai; D. Lischinski; D. Cohen-Or; H. Huang"	"2018"	"Non-stationary texture synthesis by adversarial expansion"	""	"ACM Transactions on Graphics (TOG)"	""	""	"37"	""	""	"1 - 13"	""	""	""	""	""	""	""	"Non-stationary texture synthesis by adversarial expansion"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"J.-Y. Zhu; T. Park; P. Isola; A. A. Efros"	"2017"	"Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks"	""	"2017 IEEE International Conference on Computer Vision (ICCV)"	""	""	""	""	""	"2242-2251"	""	""	""	""	""	""	""	"Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"J.-Y. Zhu; R. Zhang; D. Pathak; T. Darrell; A. A. Efros; O. Wang; E. Shechtman"	"2017"	"Toward Multimodal Image-to-Image Translation"	""	"ArXiv"	""	""	"abs/1711.11586"	""	""	""	""	""	""	""	""	""	""	"Toward Multimodal Image-to-Image Translation"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Conference Proceedings"	"D. Zügner; A. Akbarnejad; S. Günnemann"	"2018"	"Adversarial Attacks on Classification Models for Graphs"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	"Adversarial Attacks on Classification Models for Graphs"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"R. C. Cavalcante; L. L. Minku; A. L. I. Oliveira"	"2016"	"FEDD: Feature Extraction for Explicit Concept Drift Detection in Time Series"	""	"2016 International Joint Conference on Neural Networks (Ijcnn)"	""	""	""	""	""	"740-747"	""	""	""	""	""	""	""	"FEDD: Feature Extraction for Explicit Concept Drift Detection in Time Series"	"Ieee Ijcnn"	"2161-4393"	""	""	""	""	""	""	""	""	""	""	""	""	"WOS:000399925500102"	""	""	"change-point"	"A time series is a sequence of observations collected over fixed sampling intervals. Several real-world dynamic processes can be modeled as a time series, such as stock price movements, exchange rates, temperatures, among others. As a special kind of data stream, a time series may present concept drift, which affects negatively time series analysis and forecasting. Explicit drift detection methods based on monitoring the time series features may provide a better understanding of how concepts evolve over time than methods based on monitoring the forecasting error of a base predictor. In this paper, we propose an online explicit drift detection method that identifies concept drifts in time series by monitoring time series features, called Feature Extraction for Explicit Concept Drift Detection (FEDD). Computational experiments showed that FEDD performed better than error-based approaches in several linear and nonlinear artificial time series with abrupt and gradual concept drifts."	"Bh3qm
Times Cited:18
Cited References Count:32
IEEE International Joint Conference on Neural Networks (IJCNN)"	""	"<Go to ISI>://WOS:000399925500102"	""	"Univ Fed Alagoas, Nucleo Ciencias Exatas, Arapiraca, Alagoas, Brazil
Univ Leicester, Dept Comp Sci, Univ Rd, Leicester, Leics, England
Univ Fed Pernambuco, Ctr Informat, Recife, PE, Brazil"	""	""	""	""	""	""	""	"English"
"Journal Article"	"H. Y. Chen; J. H. Liang; S. C. Chang; J. Y. Pan; Y. T. Chen; W. Wei; D. C. Juan"	"2019"	"Improving Adversarial Robustness via Guided Complement Entropy"	""	"2019 Ieee/Cvf International Conference on Computer Vision (Iccv 2019)"	""	""	""	""	""	"4880-4888"	""	""	""	""	""	""	""	"Improving Adversarial Robustness via Guided Complement Entropy"	"Ieee I Conf Comp Vis"	"1550-5499"	"10.1109/Iccv.2019.00498"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000531438105004"	""	""	""	"Adversarial robustness has emerged as an important topic in deep learning as carefully crafted attack samples can significantly disturb the performance of a model. Many recent methods have proposed to improve adversarial robustness by utilizing adversarial training or model distillation, which adds additional procedures to model training. In this paper, we propose a new training paradigm called Guided Complement Entropy (GCE) that is capable of achieving "adversarial defense for free," which involves no additional procedures in the process of improving adversarial robustness. In addition to maximizing model probabilities on the ground-truth class like cross-entropy, we neutralize its probabilities on the incorrect classes along with a "guided" term to balance between these two terms. We show in the experiments that our method achieves better model robustness with even better performance compared to the commonly used cross-entropy training objective. We also show that our method can be used orthogonal to adversarial training across well-known methods with noticeable robustness gain. To the best of our knowledge, our approach is the first one that improves model robustness without compromising performance."	"Bo9jw
Times Cited:12
Cited References Count:22
IEEE International Conference on Computer Vision"	""	"<Go to ISI>://WOS:000531438105004"	""	"Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu, Taiwan
ITRI, Elect & Optoelect Syst Res Labs, Hsinchu, Taiwan
Google Res, Mountain View, CA USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"W. L. Xu; D. Evans; Y. J. Qi"	"2018"	"Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks"	""	"25th Annual Network and Distributed System Security Symposium (Ndss 2018)"	""	""	"abs/1704.01155"	""	""	""	""	""	""	""	""	""	""	"Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks"	""	""	"10.14722/ndss.2018.23198"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000722005800020"	""	""	""	"Although deep neural networks (DNNs) have achieved great success in many tasks, they can often be fooled by adversarial examples that are generated by adding small but purposeful distortions to natural examples. Previous studies to defend against adversarial examples mostly focused on refining the DNN models, but have either shown limited success or required expensive computation. We propose a new strategy, feature squeezing, that can be used to harden DNN models by detecting adversarial examples. Feature squeezing reduces the search space available to an adversary by coalescing samples that correspond to many different feature vectors in the original space into a single sample. By comparing a DNN model's prediction on the original input with that on squeezed inputs, feature squeezing detects adversarial examples with high accuracy and few false positives. This paper explores two feature squeezing methods: reducing the color bit depth of each pixel and spatial smoothing. These simple strategies are inexpensive and complementary to other defenses, and can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks."	"Bs4qo
Times Cited:194
Cited References Count:44"	""	"<Go to ISI>://WOS:000722005800020"	""	"Univ Virginia, evadeML Org, Charlottesville, VA 22903 USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"T. Erpek; Y. E. Sagduyu; Y. Shi"	"2019"	"Deep Learning for Launching and Mitigating Wireless Jamming Attacks"	""	"Ieee Transactions on Cognitive Communications and Networking"	""	""	"5"	""	"1"	"2-14"	""	""	""	""	"Mar"	""	""	"Deep Learning for Launching and Mitigating Wireless Jamming Attacks"	"Ieee T Cogn Commun"	"2332-7731"	"10.1109/Tccn.2018.2884910"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000460672300002"	""	""	"cognitive radio
jammer
adversarial machine learning
deep learning
generative adversarial network
power control"	"An adversarial machine learning approach is introduced to launch jamming attacks on wireless communications and a defense strategy is presented. A cognitive transmitter uses a pre-trained classifier to predict the current channel status based on recent sensing results and decides whether to transmit or not, whereas a jammer collects channel status and ACKs to build a deep learning classifier that reliably predicts the next successful transmissions and effectively jams them. This jamming approach is shown to reduce the transmitter's performance much more severely compared with random or sensing-based jamming. The deep learning classification scores are used by the jammer for power control subject to an average power constraint. Next, a generative adversarial network is developed for the jammer to reduce the time to collect the training dataset by augmenting it with synthetic samples. As a defense scheme, the transmitter deliberately takes a small number of wrong actions in spectrum access (in form of a causative attack against the jammer) and therefore prevents the jammer from building a reliable classifier. The transmitter systematically selects when to take wrong actions and adapts the level of defense to mislead the jammer into making prediction errors and consequently increase its throughput."	"Ho1mx
Times Cited:62
Cited References Count:40"	""	"<Go to ISI>://WOS:000460672300002"	""	"Virginia Tech, Bradley Dept Elect & Comp Engn, Res Ctr Arlington, Arlington, VA 22203 USA
Intelligent Automat Inc, Rockville, MD 20855 USA
Virginia Tech, Bradley Dept Elect & Comp Engn, Blacksburg, VA USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"Z. Y. Li; W. J. Xing; S. Khamaiseh; D. X. Xu"	"2020"	"Detecting Saturation Attacks Based on Self-Similarity of OpenFlow Traffic"	""	"Ieee Transactions on Network and Service Management"	""	""	"17"	""	"1"	"607-621"	""	""	""	""	"Mar"	""	""	"Detecting Saturation Attacks Based on Self-Similarity of OpenFlow Traffic"	"Ieee T Netw Serv Man"	"1932-4537"	"10.1109/Tnsm.2019.2959268"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000520507200044"	""	""	"software-defined networking
security
saturation attack
anomaly detection
self-similar characteristic of openflow traffic"	"As a new networking paradigm, Software-Defined Networking (SDN) separates data and control planes to facilitate programmable functions and improve the efficiency of packet delivery. Recent studies have shown that there exist various security threats in SDN. For example, a saturation attack may disturb the normal delivery of packets and even make the SDN system out of service by flooding the data plane, the control plane, or both. The existing research has focused on saturation attacks caused by SYN flooding. This paper presents an anomaly detection method, called SA-Detector, for dealing with a family of saturation attacks through IP spoofing, ICMP flooding, UDP flooding, and other types of TCP flooding, in addition to SYN flooding. SA-Detector builds upon the study of self-similarity characteristics of OpenFlow traffic between the control and data planes. Our work has shown that the normal and abnormal traffic flows through the OpenFlow communication channel have different statistical properties. Specifically, normal OpenFlow traffic has a low self-similarity degree whereas the occurrences of saturation attacks typically imply a higher degree of self-similarity. Therefore, SA-Detector exploits statistical results and self-similarity degrees of OpenFlow traffic, measured by Hurst exponents, for anomaly detection. We have evaluated our approach in both physical and simulation SDN environments with various time intervals, network topologies and applications, Internet protocols, and traffic generation tools. For the physical SDN environment, the average accuracy of detection is 97.68% and the average precision is 94.67%. For the simulation environment, the average accuracy is 96.54% and the average precision is 92.06%. In addition, we have compared SA-Detector with the existing saturation attack detection methods in terms of the aforementioned performance metrics and controller's CPU utilization. The experiment results indicate that SA-Detector is effective for the detection of saturation attacks in SDN."	"Kv5fb
Times Cited:12
Cited References Count:31"	""	"<Go to ISI>://WOS:000520507200044"	""	"Jiangsu Univ, Dept Cybersecur, Zhenjiang 212013, Jiangsu, Peoples R China
Univ Calif Davis, Dept Comp Sci, Davis, CA 95618 USA
Midwestern State Univ, Dept Comp Sci, Wichita Falls, TX 76308 USA
Univ Missouri, Dept Comp Sci & Elect Engn, Kansas City, MO 64110 USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"B. K. Beaulieu-Jones; Z. S. Wu; C. Williams; R. Lee; S. P. Bhavnani; J. B. Byrd; C. S. Greene"	"2019"	"Privacy-Preserving Generative Deep Neural Networks Support Clinical Data Sharing"	""	"Circ Cardiovasc Qual Outcomes"	""	""	"12"	""	"7"	"e005122"	""	""	""	"2019/07/10"	"Jul"	""	""	"Privacy-Preserving Generative Deep Neural Networks Support Clinical Data Sharing"	""	"1941-7705 (Electronic)
1941-7713 (Linking)"	"10.1161/CIRCOUTCOMES.118.005122"	""	""	""	""	"PMC7041894"	""	""	""	""	""	""	"31284738"	""	""	"Antihypertensive Agents/therapeutic use
Blood Pressure/drug effects
*Computer Security
Computer Simulation
*Confidentiality
Data Collection
*Deep Learning
Humans
Hypertension/diagnosis/drug therapy/physiopathology
Information Dissemination/*methods
Randomized Controlled Trials as Topic
Treatment Outcome
*blood pressure
*machine learning
*privacy
*propensity score"	"BACKGROUND: Data sharing accelerates scientific progress but sharing individual-level data while preserving patient privacy presents a barrier. METHODS AND RESULTS: Using pairs of deep neural networks, we generated simulated, synthetic participants that closely resemble participants of the SPRINT trial (Systolic Blood Pressure Trial). We showed that such paired networks can be trained with differential privacy, a formal privacy framework that limits the likelihood that queries of the synthetic participants' data could identify a real a participant in the trial. Machine learning predictors built on the synthetic population generalize to the original data set. This finding suggests that the synthetic data can be shared with others, enabling them to perform hypothesis-generating analyses as though they had the original trial data. CONCLUSIONS: Deep neural networks that generate synthetic participants facilitate secondary analyses and reproducible investigation of clinical data sets by enhancing data sharing while preserving participant privacy."	"Beaulieu-Jones, Brett K
Wu, Zhiwei Steven
Williams, Chris
Lee, Ran
Bhavnani, Sanjeev P
Byrd, James Brian
Greene, Casey S
eng
K23 HL128909/HL/NHLBI NIH HHS/
Research Support, N.I.H., Extramural
Research Support, Non-U.S. Gov't
Research Support, U.S. Gov't, Non-P.H.S.
Circ Cardiovasc Qual Outcomes. 2019 Jul;12(7):e005122. doi: 10.1161/CIRCOUTCOMES.118.005122. Epub 2019 Jul 9."	""	"https://www.ncbi.nlm.nih.gov/pubmed/31284738"	""	"Genomics and Computational Biology Graduate Group, Perelman School of Medicine, University of Pennsylvania, Philadelphia. (B.K.B.-J.).
Computer Science and Electrical Engineering Department, University of Minnesota, Minneapolis (Z.S.W.).
Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania, Philadelphia. (C.W., C.S.G.).
Division of Cardiovascular Medicine, Department of Medicine, University of Michigan Medical School, Ann Arbor (R.L., J.B.B.).
Scripps Clinic and Research Foundation, San Diego, CA (S.P.B.)."	""	""	""	""	""	""	""	""
"Journal Article"	"C. G. Xu; J. Ren; D. Y. Zhang; Y. X. Zhang; Z. Qin; K. Ren"	"2019"	"GANobfuscator: Mitigating Information Leakage Under GAN via Differential Privacy"	""	"Ieee Transactions on Information Forensics and Security"	""	""	"14"	""	"9"	"2358-2371"	""	""	""	""	"Sep"	""	""	"GANobfuscator: Mitigating Information Leakage Under GAN via Differential Privacy"	"Ieee T Inf Foren Sec"	"1556-6013"	"10.1109/Tifs.2019.2897874"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000469836900009"	""	""	"information leakage
generative adversarial network
deep learning
differential privacy
noise"	"By learning generative models of semantic-rich data distributions from samples, generative adversarial network (GAN) has recently attracted intensive research interests due to its excellent empirical performance as a generative model. The model is used to estimate the underlying distribution of a dataset and randomly generate realistic samples according to their estimated distribution. However, GANs can easily remember training samples due to the high model complexity of deep networks. When GANs are applied to private or sensitive data, the concentration of distribution may divulge some critical information. It consequently requires new technological advances to mitigate the information leakage under GANs. To address this issue, we propose GANobfuscator, a differentially private GAN, which can achieve differential privacy under GANs by adding carefully designed noise to gradients during the learning procedure. With GANobfuscator, analysts are able to generate an unlimited amount of synthetic data for arbitrary analysis tasks without disclosing the privacy of training data. Moreover, we theoretically prove that GANobfuscator can provide strict privacy guarantee with differential privacy. In addition, we develop a gradient-pruning strategy for GANobfuscator to improve the scalability and stability of data training. Through extensive experimental evaluation on benchmark datasets, we demonstrate that GANobfuscator can produce high-quality generated data and retain desirable utility under practical privacy budgets."	"Ia8vp
Times Cited:56
Cited References Count:44"	""	"<Go to ISI>://WOS:000469836900009"	""	"Cent South Univ, Sch Comp Sci & Engn, Changsha 410083, Hunan, Peoples R China
Zhejiang Univ, Inst Cyberspace Res, Hangzhou 310058, Zhejiang, Peoples R China"	""	""	""	""	""	""	""	"English"
"Journal Article"	"C. Reiss; J. Wilkes; J. L. Hellerstein"	"2012"	"Obfuscatory obscanturism: making workload traces of commercially-sensitive systems safe to release"	""	"2012 Ieee Network Operations and Management Symposium (Noms)"	""	""	""	""	""	"1279-1286"	""	""	""	""	""	""	""	"Obfuscatory obscanturism: making workload traces of commercially-sensitive systems safe to release"	"Ieee Ifip Netw Oper"	"1542-1201"	""	""	""	""	""	""	""	""	""	""	""	""	"WOS:000309517000188"	""	""	""	"Cloud providers such as Google are interested in fostering research on the daunting technical challenges they face in supporting planetary-scale distributed systems, but no academic organizations have similar scale systems on which to experiment. Fortunately, good research can still be done using traces of real-life production workloads, but there are risks in releasing such data, including inadvertently disclosing confidential or proprietary information, as happened with the Netflix Prize data. This paper discusses these risks, and our approach to them, which we call systematic obfuscation. It protects proprietary and personal data while leaving it possible to answer interesting research questions. We explain and motivate some of the risks and concerns and propose how they can best be mitigated, using as an example our recent publication of a month-long trace of a production system workload on a 11k-machine cluster."	"Bca90
Times Cited:18
Cited References Count:30
IEEE IFIP Network Operations and Management Symposium"	""	"<Go to ISI>://WOS:000309517000188"	""	"Univ Calif Berkeley, Berkeley, CA 94720 USA
Google Inc, Mountain, CA USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"L. Melis; C. Z. Song; E. De Cristofaro; V. Shmatikov"	"2019"	"Exploiting Unintended Feature Leakage in Collaborative Learning"	""	"2019 Ieee Symposium on Security and Privacy (Sp 2019)"	""	""	""	""	""	"691-706"	""	""	""	""	""	""	""	"Exploiting Unintended Feature Leakage in Collaborative Learning"	"P Ieee S Secur Priv"	"1081-6011"	"10.1109/Sp.2019.00029"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000510006100041"	""	""	"model"	"Collaborative machine learning and related techniques such as federated learning allow multiple participants, each with his own training dataset, to build a joint model by training locally and periodically exchanging model updates.
We demonstrate that these updates leak unintended information about participants' training data and develop passive and active inference attacks to exploit this leakage. First, we show that an adversarial participant can infer the presence of exact data points-for example, specific locations-in others' training data (i.e., membership inference). Then, we show how this adversary can infer properties that hold only for a subset of the training data and are independent of the properties that the joint model aims to capture. For example, he can infer when a specific person first appears in the photos used to train a binary gender classifier.
We evaluate our attacks on a variety of tasks, datasets, and learning configurations, analyze their limitations, and discuss possible defenses."	"Bo3ed
Times Cited:199
Cited References Count:66
IEEE Symposium on Security and Privacy"	""	"<Go to ISI>://WOS:000510006100041"	""	"UCL, London, England
Cornell Univ, Ithaca, NY 14853 USA
Alan Turing Inst, London, England"	""	""	""	""	""	""	""	"English"
"Journal Article"	"M. Sadeghi; E. G. Larsson"	"2019"	"Adversarial Attacks on Deep-Learning Based Radio Signal Classification"	""	"Ieee Wireless Communications Letters"	""	""	"8"	""	"1"	"213-216"	""	""	""	""	"Feb"	""	""	"Adversarial Attacks on Deep-Learning Based Radio Signal Classification"	"Ieee Wirel Commun Le"	"2162-2337"	"10.1109/Lwc.2018.2867459"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000459510200053"	""	""	"adversarial attacks
deep learning
wireless security
modulation classification
neural networks"	"Deep learning (DL), despite its enormous success in many computer vision and language processing applications, is exceedingly vulnerable to adversarial attacks. We consider the use of DL for radio signal (modulation) classification tasks, and present practical methods for the crafting of white-box and universal black-box adversarial attacks in that application. We show that these attacks can considerably reduce the classification performance, with extremely small perturbations of the input. In particular, these attacks are significantly more powerful than classical jamming attacks, which raises significant security and robustness concerns in the use of DL-based algorithms for the wireless physical layer."	"Hm5iu
Times Cited:61
Cited References Count:11"	""	"<Go to ISI>://WOS:000459510200053"	""	"Linkoping Univ, Dept Elect Engn ISY, S-58183 Linkoping, Sweden"	""	""	""	""	""	""	""	"English"
"Journal Article"	"A. S. Chivukula; W. Liu"	"2017"	"Adversarial Learning Games with Deep Learning Models"	""	"2017 International Joint Conference on Neural Networks (Ijcnn)"	""	""	""	""	""	"2758-2767"	""	""	""	""	""	""	""	"Adversarial Learning Games with Deep Learning Models"	"Ieee Ijcnn"	"2161-4393"	""	""	""	""	""	""	""	""	""	""	""	""	"WOS:000426968703002"	""	""	"supervised learning
data mining and knowledge discovery
evolutionary learning
adversarial learning
deep learning
genetic algorithms
game theory"	"Deep learning has been found to be vulnerable to changes in the data distribution. This means that inputs that have an imperceptibly and immeasurably small difference from training data correspond to a completely different class label in deep learning. Thus an existing deep learning network like a Convolutional Neural Network (CNN) is vulnerable to adversarial examples. We design an adversarial learning algorithm for supervised learning in general and CNNs in particular. Adversarial examples are generated by a game theoretic formulation on the performance of deep learning. In the game, the interaction between an intelligent adversary and deep learning model is a two-person sequential noncooperative Stackelberg game with stochastic payoff functions. The Stackelberg game is solved by the Nash equilibrium which is a pair of strategies (learner weights and genetic operations) from which there is no incentive for either learner or adversary to deviate. The algorithm performance is evaluated under different strategy spaces on MNIST handwritten digits data. We show that the Nash equilibrium leads to solutions robust to subsequent adversarial data manipulations. Results suggest that game theory and stochastic optimization algorithms can be used to study performance vulnerabilities in deep learning models."	"Bj6wl
Times Cited:9
Cited References Count:23
IEEE International Joint Conference on Neural Networks (IJCNN)"	""	"<Go to ISI>://WOS:000426968703002"	""	"Univ Technol Sydney, Adv Analyt Inst, Sydney, NSW, Australia"	""	""	""	""	""	""	""	"English"
"Journal Article"	"X. Li; F. X. Li"	"2017"	"Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics"	""	"2017 Ieee International Conference on Computer Vision (Iccv)"	""	""	""	""	""	"5775-5783"	""	""	""	""	""	""	""	"Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics"	"Ieee I Conf Comp Vis"	"1550-5499"	"10.1109/Iccv.2017.615"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000425498405090"	""	""	""	"Deep learning has greatly improved visual recognition in recent years. However, recent research has shown that there exist many adversarial examples that can negatively impact the performance of such an architecture. This paper focuses on detecting those adversarial examples by analyzing whether they come from the same distribution as the normal examples. Instead of directly training a deep neural network to detect adversarials, a much simpler approach was proposed based on statistics on outputs from convolutional layers. A cascade classifier was designed to efficiently detect adversarials. Furthermore, trained from one particular adversarial generating mechanism, the resulting classifier can successfully detect adversarials from a completely different mechanism as well. The resulting classifier is non-subdifferentiable, hence creates a difficulty for adversaries to attack by using the gradient of the classifier. After detecting adversarial examples, we show that many of them can be recovered by simply performing a small average filter on the image. Those findings should lead to more insights about the classification mechanisms in deep convolutional neural networks."	"Bj4tw
Times Cited:104
Cited References Count:32
IEEE International Conference on Computer Vision"	""	"<Go to ISI>://WOS:000425498405090"	""	"Oregon State Univ, Sch Elect Engn & Comp Sci, Corvallis, OR 97331 USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"S. Q. Shen; S. Tople; P. Saxena"	"2016"	"AUROR: Defending Against Poisoning Attacks in Collaborative Deep Learning Systems"	""	"32nd Annual Computer Security Applications Conference (Acsac 2016)"	""	""	""	""	""	"508-519"	""	""	""	""	""	""	""	"AUROR: Defending Against Poisoning Attacks in Collaborative Deep Learning Systems"	"Ann Comput Security"	"1063-9527"	"10.1145/291079.2991125"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000630180100042"	""	""	"machine
algorithms"	"Deep learning in a collaborative setting is emerging as a cornerstone of many upcoming applications, wherein untrusted users collaborate to generate more accurate models. From the security perspective, this opens collaborative deep learning to poisoning attacks, wherein adversarial users deliberately alter their inputs to mis-train the model. These attacks are known for machine learning systems in general, but their impact on new deep learning systems is not well-established.
We investigate the setting of indirect collaborative deep learning - a form of practical deep learning wherein users submit masked features rather titan direct data. Indirect collaborative deep learning is preferred over direct, because it distributes the cost of computation and can be made privacy-preserving. In this paper, we study the susceptibility of collaborative deep learning systems to adversarial poisoning attacks. Specifically, we obtain the following empirical results on 2 popular datasets for handwritten images (MNIST) and traffic signs (GTSRB) used in auto-driving cars. For collaborative deep learning systems, we demonstrate that the attacks have 99% success rate for misclassifying specific target data while poisoning only 10% of the entire training dataset.
As a defense, we propose AUROR, a system that detects malicious users and generates an accurate model. The accuracy under the deployed defense on practical datasets is nearly unchanged when operating in the absence of attacks. The accuracy of a model trained using AUROR drops by only 3% even when 30% of all the users are adversarial. AUROR provides a strong guarantee against evasion; if the attacker tries to evade, its attack effectiveness is hounded."	"Br0qm
Times Cited:56
Cited References Count:34
Annual Computer Security Applications Conference - Proceedings"	""	"<Go to ISI>://WOS:000630180100042"	""	"Natl Univ Singapore, Singapore, Singapore"	""	""	""	""	""	""	""	"English"
"Journal Article"	"C. W. Xiao; B. Li; J. Y. Zhu; W. He; M. Y. Liu; D. Song"	"2018"	"Generating Adversarial Examples with Adversarial Networks"	""	"Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence"	""	""	"abs/1801.02610"	""	""	"3905-3911"	""	""	""	""	""	""	""	"Generating Adversarial Examples with Adversarial Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	"WOS:000764175404008"	""	""	""	"Deep neural networks (DNNs) have been found to be vulnerable to adversarial examples resulting from adding small-magnitude perturbations to inputs. Such adversarial examples can mislead DNNs to produce adversary-selected results. Different attack strategies have been proposed to generate adversarial examples, but how to produce them with high perceptual quality and more efficiently requires more research efforts. In this paper, we propose AdvGAN to generate adversarial examples with generative adversarial networks (GANs), which can learn and approximate the distribution of original instances. For AdvGAN, once the generator is trained, it can generate perturbations efficiently for any instance, so as to potentially accelerate adversarial training as defenses. We apply AdvGAN in both semi-whitebox and black-box attack settings. In semi-whitebox attacks, there is no need to access the original target model after the generator is trained, in contrast to traditional white-box attacks. In black-box attacks, we dynamically train a distilled model for the black-box model and optimize the generator accordingly. Adversarial examples generated by AdvGAN on different target models have high attack success rate under state-of-the-art defenses compared to other attacks. Our attack has placed the first with 92.76% accuracy on a public MNIST black-box attack challenge.(1)"	"Bs7mq
Times Cited:147
Cited References Count:25"	""	"<Go to ISI>://WOS:000764175404008"	""	"Univ Michigan, Ann Arbor, MI 48109 USA
Univ Calif Berkeley, Berkeley, CA 94720 USA
MIT, Cambridge, MA 02139 USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"A. Nguyen; J. Yosinski; J. Clune"	"2015"	"Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images"	""	"2015 Ieee Conference on Computer Vision and Pattern Recognition (Cvpr)"	""	""	""	""	""	"427-436"	""	""	""	""	""	""	""	"Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images"	"Proc Cvpr Ieee"	"1063-6919"	"DOI 10.1109/cvpr.2015.7298640"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000387959200047"	""	""	""	"Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between computer and human vision. A recent study [30] revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-the-art DNNs believe to be recognizable objects with 99.99% confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neural networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possible to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call "fooling images" (more generally, fooling examples). Our results shed light on interesting differences between human vision and current DNNs, and raise questions about the generality of DNN computer vision."	"Bg3ka
Times Cited:899
Cited References Count:32
IEEE Conference on Computer Vision and Pattern Recognition"	""	"<Go to ISI>://WOS:000387959200047"	""	"Univ Wyoming, Laramie, WY 82071 USA
Cornell Univ, Ithaca, NY 14853 USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"M. Nasr; R. Shokri; A. Houmansadr"	"2019"	"Comprehensive Privacy Analysis of Deep Learning Passive and Active White-box Inference Attacks against Centralized and Federated Learning"	""	"2019 Ieee Symposium on Security and Privacy (Sp 2019)"	""	""	""	""	""	"739-753"	""	""	""	""	""	""	""	"Comprehensive Privacy Analysis of Deep Learning Passive and Active White-box Inference Attacks against Centralized and Federated Learning"	"P Ieee S Secur Priv"	"1081-6011"	"10.1109/Sp.2019.00065"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000510006100044"	""	""	""	"Deep neural networks are susceptible to various inference attacks as they remember information about their training data. We design white-box inference attacks to perform a comprehensive privacy analysis of deep learning models. We measure the privacy leakage through parameters of fully trained models as well as the parameter updates of models during training. We design inference algorithms for both centralized and federated learning, with respect to passive and active inference attackers, and assuming different adversary prior knowledge.
We evaluate our novel white-box membership inference attacks against deep learning algorithms to trace their training data records. We show that a straightforward extension of the known black-box attacks to the white-box setting (through analyzing the outputs of activation functions) is ineffective. We therefore design new algorithms tailored to the white-box setting by exploiting the privacy vulnerabilities of the stochastic gradient descent algorithm, which is the algorithm used to train deep neural networks. We investigate the reasons why deep learning models may leak information about their training data. We then show that even well-generalized models are significantly susceptible to white-box membership inference attacks, by analyzing state-of-the-art pre-trained and publicly available models for the CIFAR dataset. We also show how adversarial participants, in the federated learning setting, can successfully run active membership inference attacks against other participants, even when the global model achieves high prediction accuracies."	"Bo3ed
Times Cited:165
Cited References Count:37
IEEE Symposium on Security and Privacy"	""	"<Go to ISI>://WOS:000510006100044"	""	"Univ Massachusetts, Amherst, MA 01003 USA
Natl Univ Singapore, Singapore, Singapore"	""	""	""	""	""	""	""	"English"
"Journal Article"	"U. Hwang; J. Park; H. Jang; S. Yoon; N. I. Cho"	"2019"	"PuVAE: A Variational Autoencoder to Purify Adversarial Examples"	""	"Ieee Access"	""	""	"7"	""	""	"126582-126593"	""	""	""	""	""	""	""	"PuVAE: A Variational Autoencoder to Purify Adversarial Examples"	"Ieee Access"	"2169-3536"	"10.1109/Access.2019.2939352"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000487666800009"	""	""	"adversarial attack
variational autoencoder
deep learning"	"Deep neural networks are widely used and exhibit excellent performance in many areas. However, they are vulnerable to adversarial attacks that compromise networks at inference time by applying elaborately designed perturbations to input data. Although several defense methods have been proposed to address specific attacks, other types of attacks can circumvent these defense mechanisms. Therefore, we propose Purifying Variational AutoEncoder (PuVAE), a method to purify adversarial examples. The proposed method eliminates an adversarial perturbation by projecting an adversarial example on the manifold of each class and determining the closest projection as a purified sample. We experimentally illustrate the robustness of PuVAE against various attack methods without any prior knowledge about the attacks. In our experiments, the proposed method exhibits performances that are competitive with state-of-the-art defense methods, and the inference time is approximately 130 times faster than that of Defense-GAN which is a state-of-the art purifier method."	"Ja2sg
Times Cited:17
Cited References Count:38"	""	"<Go to ISI>://WOS:000487666800009"	""	"Seoul Natl Univ, Elect & Comp Engn, Seoul 08826, South Korea
Seoul Natl Univ, INMC, Dept Elect & Comp Engn, Seoul 08826, South Korea"	""	""	""	""	""	""	""	"English"
"Journal Article"	"S. Song; K. Chaudhuri; A. D. Sarwate"	"2013"	"Stochastic gradient descent with differentially private updates"	""	"2013 Ieee Global Conference on Signal and Information Processing (Globalsip)"	""	""	""	""	""	"245-248"	""	""	""	""	""	""	""	"Stochastic gradient descent with differentially private updates"	"Ieee Glob Conf Sig"	"2376-4066"	""	""	""	""	""	""	""	""	""	""	""	""	"WOS:000350825600066"	""	""	""	"Differential privacy is a recent framework for computation on sensitive data, which has shown considerable promise in the regime of large datasets. Stochastic gradient methods are a popular approach for learning in the data-rich regime because they are computationally tractable and scalable. In this paper, we derive differentially private versions of stochastic gradient descent, and test them empirically. Our results show that standard SGD high variability due to differential privacy, but a moderate increase in the batch size can improve performance significantly."	"Bc2fe
Times Cited:134
Cited References Count:18
IEEE Global Conference on Signal and Information Processing"	""	"<Go to ISI>://WOS:000350825600066"	""	"Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA
Toyota Technol Inst, Chicago, IL USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"T. Q. Zhu; G. Li; W. L. Zhou; P. S. Yu"	"2017"	"Differentially Private Data Publishing and Analysis: A Survey"	""	"Ieee Transactions on Knowledge and Data Engineering"	""	""	"29"	""	"8"	"1619-1638"	""	""	""	""	"Aug 1"	""	""	"Differentially Private Data Publishing and Analysis: A Survey"	"Ieee T Knowl Data En"	"1041-4347"	"10.1109/Tkde.2017.2697856"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000405378900004"	""	""	"differential privacy
privacy preserving data publishing
privacy preserving data analysis
algorithms
complexity
framework
queries"	"Differential privacy is an essential and prevalent privacy model that has been widely explored in recent decades. This survey provides a comprehensive and structured overview of two research directions: differentially private data publishing and differentially private data analysis. We compare the diverse release mechanisms of differentially private data publishing given a variety of input data in terms of query type, the maximum number of queries, efficiency, and accuracy. We identify two basic frameworks for differentially private data analysis and list the typical algorithms used within each framework. The results are compared and discussed based on output accuracy and efficiency. Further, we propose several possible directions for future research and possible applications."	"Fa3xu
Times Cited:129
Cited References Count:128"	""	"<Go to ISI>://WOS:000405378900004"	""	"Deakin Univ, Sch Informat Technol, Burwood 3125, Australia
Univ Illinois, Dept Comp Sci, Chicago, IL 60607 USA
Tsinghua Univ, Inst Data Sci, Beijing 100084, Peoples R China"	""	""	""	""	""	""	""	"English"
"Journal Article"	"E. Bagdasaryan; A. Veit; Y. Q. Hua; D. Estrin; V. Shmatikov"	"2020"	"How To Backdoor Federated Learning"	""	"International Conference on Artificial Intelligence and Statistics, Vol 108"	""	""	"108"	""	""	"2938-2947"	""	""	""	""	""	""	""	"How To Backdoor Federated Learning"	"Pr Mach Learn Res"	"2640-3498"	""	""	""	""	""	""	""	""	""	""	""	""	"WOS:000559931300094"	""	""	""	"Federated models are created by aggregating model updates submitted by participants. To protect confidentiality of the training data,the aggregator by design has no visibility into how these updates are generated. We show that this makes federated learning vulnerable to a model-poisoning attack that is significantly more powerful than poisoning attacks that target only the training data.
A single or multiple malicious participants can use model replacement to introduce backdoor functionality into the joint model,e.g., modify an image classifier so that it assigns an attacker-chosen label to images with certain features, or force a word predictor to complete certain sentences with an attacker-chosen word. We evaluate model replacement under different assumptions for the standard federated-learning tasks and show that it greatly outperform straining-data poisoning.
Federated learning employs secure aggregation to protect confidentiality of participants local models and thus cannot detect anomalies in participants' contributions to the joint model. To demonstrate that anomaly detection would not have been effective in any case, we also develop and evaluate a generic constrain-and-scale technique that incorporates the evasion of defenses into the attackers loss function during training."	"Bp6lu
Times Cited:122
Cited References Count:54
Proceedings of Machine Learning Research"	""	"<Go to ISI>://WOS:000559931300094"	""	"Cornell Tech, New York, NY 10044 USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"S. M. Moosavi-Dezfooli; A. Fawzi; O. Fawzi; P. Frossard"	"2017"	"Universal adversarial perturbations"	""	"30th Ieee Conference on Computer Vision and Pattern Recognition (Cvpr 2017)"	""	""	""	""	""	"86-94"	""	""	""	""	""	""	""	"Universal adversarial perturbations"	"Proc Cvpr Ieee"	"1063-6919"	"10.1109/Cvpr.2017.17"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000418371400010"	""	""	""	"Given a state-of-the-art deep neural network classifier, we show the existence of a universal (image-agnostic) and very small perturbation vector that causes natural images to be misclassified with high probability. We propose a systematic algorithm for computing universal perturbations, and show that state-of-the-art deep neural networks are highly vulnerable to such perturbations, albeit being quasi-imperceptible to the human eye. We further empirically analyze these universal perturbations and show, in particular, that they generalize very well across neural networks. The surprising existence of universal perturbations reveals important geometric correlations among the high-dimensional decision boundary of classifiers. It further outlines potential security breaches with the existence of single directions in the input space that adversaries can possibly exploit to break a classifier on most natural images.(1)"	"Bj1xg
Times Cited:557
Cited References Count:22
IEEE Conference on Computer Vision and Pattern Recognition"	""	"<Go to ISI>://WOS:000418371400010"	""	"Ecole Polytech Fed Lausanne, Lausanne, Switzerland
Univ Lyon, ENS Lyon, CNRS, UCBL,INRIA,LIP,UMR 5668, Lyon, France"	""	""	""	""	""	""	""	"English"
"Journal Article"	"J. Y. Jia; A. Salem; M. Backes; Y. Zhang; N. Z. Q. Gong"	"2019"	"MemGuard: Defending against Black-Box Membership Inference Attacks via Adversarial Examples"	""	"Proceedings of the 2019 Acm Sigsac Conference on Computer and Communications Security (Ccs'19)"	""	""	""	""	""	"259-274"	""	""	""	""	""	""	""	"MemGuard: Defending against Black-Box Membership Inference Attacks via Adversarial Examples"	""	""	"10.1145/3319535.3363201"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000509760700017"	""	""	"membership inference attacks
adversarial examples
privacy-preserving machine learning"	"In a membership inference attack, an attacker aims to infer whether a data sample is in a target classifier's training dataset or not. Specifically, given a black-box access to the target classifier, the attacker trains a binary classifier, which takes a data sample's confidence score vector predicted by the target classifier as an input and predicts the data sample to be a member or non-member of the target classifier's training dataset. Membership inference attacks pose severe privacy and security threats to the training dataset. Most existing defenses leverage differential privacy when training the target classifier or regularize the training process of the target classifier. These defenses suffer from two key limitations: 1) they do not have formal utility-loss guarantees of the confidence score vectors, and 2) they achieve suboptimal privacy-utility tradeoffs.
In this work, we propose MemGuard, the first defense with formal utility-loss guarantees against black-box membership inference attacks. Instead of tampering the training process of the target classifier, MemGuard adds noise to each confidence score vector predicted by the target classifier. Our key observation is that attacker uses a classifier to predict member or non-member and classifier is vulnerable to adversarial examples. Based on the observation, we propose to add a carefully crafted noise vector to a confidence score vector to turn it into an adversarial example that misleads the attacker's classifier. Specifically, MemGuard works in two phases. In Phase I, MemGuard finds a carefully crafted noise vector that can turn a confidence score vector into an adversarial example, which is likely to mislead the attacker's classifier to make a random guessing at member or non-member. We find such carefully crafted noise vector via a new method that we design to incorporate the unique utility-loss constraints on the noise vector. In Phase II, MemGuard adds the noise vector to the confidence score vector with a certain probability, which is selected to satisfy a given utility-loss budget on the confidence score vector. Our experimental results on three datasets show that MemGuard can effectively defend against membership inference attacks and achieve better privacy-utility tradeoffs than existing defenses. Our work is the first one to show that adversarial examples can be used as defensive mechanisms to defend against membership inference attacks."	"Bo2zy
Times Cited:42
Cited References Count:73"	""	"<Go to ISI>://WOS:000509760700017"	""	"Duke Univ, ECE Dept, Durham, NC 27706 USA
CISPA Helmholtz Ctr Informat Secur, Saarbrucken, Germany"	""	""	""	""	""	""	""	"English"
"Journal Article"	"R. Perdisci; I. Corona; G. Giacinto"	"2012"	"Early Detection of Malicious Flux Networks via Large-Scale Passive DNS Traffic Analysis"	""	"Ieee Transactions on Dependable and Secure Computing"	""	""	"9"	""	"5"	"714-726"	""	""	""	""	"Sep-Oct"	""	""	"Early Detection of Malicious Flux Networks via Large-Scale Passive DNS Traffic Analysis"	"Ieee T Depend Secure"	"1545-5971"	"10.1109/Tdsc.2012.35"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000306557900008"	""	""	"flux networks
dns
passive traffic analysis
clustering
classification
internet security"	"In this paper, we present FluxBuster, a novel passive DNS traffic analysis system for detecting and tracking malicious flux networks. FluxBuster applies large-scale monitoring of DNS traffic traces generated by recursive DNS (RDNS) servers located in hundreds of different networks scattered across several different geographical locations. Unlike most previous work, our detection approach is not limited to the analysis of suspicious domain names extracted from spam emails or precompiled domain blacklists. Instead, FluxBuster is able to detect malicious flux service networks in-the-wild, i.e., as they are "accessed" by users who fall victim of malicious content, independently of how this malicious content was advertised. We performed a long-term evaluation of our system spanning a period of about five months. The experimental results show that FluxBuster is able to accurately detect malicious flux networks with a low false positive rate. Furthermore, we show that in many cases FluxBuster is able to detect malicious flux domains several days or even weeks before they appear in public domain blacklists."	"976ck
Times Cited:63
Cited References Count:20"	""	"<Go to ISI>://WOS:000306557900008"	""	"Univ Georgia, Dept Comp Sci, Boyd Grad Studies Res Ctr 415, Athens, GA 30602 USA
Univ Cagliari, Dept Elect & Elect Engn, I-09123 Cagliari, Italy"	""	""	""	""	""	""	""	"English"
"Journal Article"	"J. Whitefield; L. Q. Chen; T. Giannetsos; S. Schneider; H. Treharne"	"2017"	"Privacy-Enhanced Capabilities for VANETs using Direct Anonymous Attestation"	""	"2017 Ieee Vehicular Networking Conference (Vnc)"	""	""	""	""	""	"123-130"	""	""	""	""	""	""	""	"Privacy-Enhanced Capabilities for VANETs using Direct Anonymous Attestation"	"Ieee Vehic Netw Conf"	"2157-9857"	""	""	""	""	""	""	""	""	""	""	""	""	"WOS:000426903100029"	""	""	"security
privacy
trusted computing
direct anonymous attestation
vehicle-2-x"	"In this paper, we propose a novel secure and privacy-preserving solution for V2X systems leveraging widely accepted trusted computing technologies. Our approach systematically addresses all key aspects, i.e., security, privacy and accountability (revocation). By reflecting on state-of-the-art pseudonym architectures, we identify their limitations focusing on pseudonym reusage policies and revocation mechanisms. We propose the use of Direct Anonymous Attestation (DAA) algorithms to enhance existing V2X security architectures. The novelty of our proposed solution is its decentralized approach in shifting trust from the infrastructure to vehicles. Applying DAA in V2X enables enhanced privacy protection than is possible in current architectures through user-controlled linkability. The paper presents the incorporation of DAA algorithms within V2X together with rigorous security and privacy arguments."	"Bj6pi
Times Cited:15
Cited References Count:36
IEEE Vehicular Networking Conference"	""	"<Go to ISI>://WOS:000426903100029"	""	"Univ Surrey, Surrey Ctr Cyber Secur, Guildford, Surrey, England"	""	""	""	""	""	""	""	"English"
"Journal Article"	"C. H. Xie; J. Y. Wang; Z. S. Zhang; Y. Y. Zhou; L. X. Xie; A. Yuille"	"2017"	"Adversarial Examples for Semantic Segmentation and Object Detection"	""	"2017 Ieee International Conference on Computer Vision (Iccv)"	""	""	""	""	""	"1378-1387"	""	""	""	""	""	""	""	"Adversarial Examples for Semantic Segmentation and Object Detection"	"Ieee I Conf Comp Vis"	"1550-5499"	"10.1109/Iccv.2017.153"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000425498401046"	""	""	""	"It has been well demonstrated that adversarial examples, i.e., natural images with visually imperceptible perturbations added, cause deep networks to fail on image classification. In this paper, we extend adversarial examples to semantic segmentation and object detection which are much more difficult. Our observation is that both segmentation and detection are based on classifying multiple targets on an image (e.g., the target is a pixel or a receptive field in segmentation, and an object proposal in detection). This inspires us to optimize a loss function over a set of targets for generating adversarial perturbations. Based on this, we propose a novel algorithm named Dense Adversary Generation (DAG), which applies to the state-of-the-art networks for segmentation and detection. We find that the adversarial perturbations can be transferred across networks with different training data, based on different architectures, and even for different recognition tasks. In particular, the transfer ability across networks with the same architecture is more significant than in other cases. Besides, we show that summing up heterogeneous perturbations often leads to better transfer performance, which provides an effective method of black-box adversarial attack."	"Bj4tw
Times Cited:218
Cited References Count:37
IEEE International Conference on Computer Vision"	""	"<Go to ISI>://WOS:000425498401046"	""	"Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA
Baidu Res USA, Sunnyvale, CA 94089 USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"B. L. Wang; Y. S. Yao; S. Shan; H. Y. Li; B. Viswanath; H. T. Zheng; B. Y. Zhao"	"2019"	"Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks"	""	"2019 Ieee Symposium on Security and Privacy (Sp 2019)"	""	""	""	""	""	"707-723"	""	""	""	""	""	""	""	"Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks"	"P Ieee S Secur Priv"	"1081-6011"	"10.1109/Sp.2019.00031"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000510006100042"	""	""	""	"Lack of transparency in deep neural networks (DNNs) make them susceptible to backdoor attacks, where hidden associations or triggers override normal classification to produce unexpected results. For example, a model with a backdoor always identifies a face as Bill Gates if a specific symbol is present in the input. Backdoors can stay hidden indefinitely until activated by an input, and present a serious security risk to many security or safety related applications, e.g., biometric authentication systems or self-driving cars.
We present the first robust and generalizable detection and mitigation system for DNN backdoor attacks. Our techniques identify backdoors and reconstruct possible triggers. We identify multiple mitigation techniques via input filters, neuron pruning and unlearning. We demonstrate their efficacy via extensive experiments on a variety of DNNs, against two types of backdoor injection methods identified by prior work. Our techniques also prove robust against a number of variants of the backdoor attack."	"Bo3ed
Times Cited:142
Cited References Count:50
IEEE Symposium on Security and Privacy"	""	"<Go to ISI>://WOS:000510006100042"	""	"UC Santa Barbara, Santa Barbara, CA 93106 USA
Univ Chicago, Chicago, IL 60637 USA
Virginia Tech, Blacksburg, VA USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"A. Salem; Y. Zhang; M. Humbert; P. Berrang; M. Fritz; M. Backes"	"2019"	"ML-Leaks: Model and Data Independent Membership Inference Attacks and Defenses on Machine Learning Models"	""	"26th Annual Network and Distributed System Security Symposium (Ndss 2019)"	""	""	"abs/1806.01246"	""	""	""	""	""	""	""	""	""	""	"ML-Leaks: Model and Data Independent Membership Inference Attacks and Defenses on Machine Learning Models"	""	""	"10.14722/ndss.2019.23119"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000680713300024"	""	""	""	"Machine learning (ML) has become a core component of many real-world applications and training data is a key factor that drives current progress. This huge success has led Internet companies to deploy machine learning as a service (MLaaS). Recently, the first membership inference attack has shown that extraction of information on the training set is possible in such MLaaS settings, which has severe security and privacy implications.
However, the early demonstrations of the feasibility of such attacks have many assumptions on the adversary, such as using multiple so-called shadow models, knowledge of the target model structure, and having a dataset from the same distribution as the target model's training data. We relax all these key assumptions, thereby showing that such attacks are very broadly applicable at low cost and thereby pose a more severe risk than previously thought. We present the most comprehensive study so far on this emerging and developing threat using eight diverse datasets which show the viability of the proposed attacks across domains.
In addition, we propose the first effective defense mechanisms against such broader class of membership inference attacks that maintain a high level of utility of the ML model."	"Bs0ba
Times Cited:56
Cited References Count:50"	""	"<Go to ISI>://WOS:000680713300024"	""	"CISPA Helmholtz Ctr Informat Secur, Saarbrucken, Germany
Swiss Fed Inst Technol, Swiss Data Sci Ctr, Zurich, Switzerland
Ecole Polytech Fed Lausanne, Lausanne, Switzerland"	""	""	""	""	""	""	""	"English"
"Journal Article"	"T. N. Nguyen"	"2018"	"The Challenges in ML-based Security for SDN"	""	"2018 2nd Cyber Security in Networking Conference (Csnet)"	""	""	""	""	""	"1-9"	""	""	""	""	""	""	""	"The Challenges in ML-based Security for SDN"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	"WOS:000458684000002"	""	""	""	"Machine learning (ML) is gaining popularity in the network security domain as more network-enabled devices get connected, as malicious activities become stealthier, and as new technologies like Software Defined Networking (SDN) emerge. From the application layer, ML-based SDN security models control the routing/switching of an entire Software Defined Network. Compromising the models is hackers' desirable goal. Previous works have been done on either adversarial machine learning without the context of secure networking environment or on the general vulnerabilities of SDNs without much consideration of the defending ML models. Through examination of the latest ML-based SDN security applications, a good look at ML/ SDN specific vulnerabilities accompanied by a successful attack on StratosphereIPS, this paper makes a case for more secure developments of ML-based SDN security applications."	"Bm0ed
Times Cited:5
Cited References Count:43"	""	"<Go to ISI>://WOS:000458684000002"	""	"North Carolina State Univ, Raleigh, NC 27695 USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"N. Papernot; P. McDaniel; I. Goodfellow; S. Jha; Z. B. Celik; A. Swami"	"2017"	"Practical Black-Box Attacks against Machine Learning"	""	"Proceedings of the 2017 Acm Asia Conference on Computer and Communications Security (Asia Ccs'17)"	""	""	""	""	""	"506-519"	""	""	""	""	""	""	""	"Practical Black-Box Attacks against Machine Learning"	""	""	"10.1145/3052973.3053009"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000539858200047"	""	""	""	"Machine learning (ML) models, e.g., deep neural networks (DNNs), are vulnerable to adversarial examples: malicious inputs modified to yield erroneous model outputs, while appearing unmodified to human observers. Potential attacks include having malicious content like malware identified as legitimate or controlling vehicle behavior. Yet, all existing adversarial example attacks require knowledge of either the model internals or its training data. We introduce the first practical demonstration of an attacker controlling a remotely hosted DNN with no such knowledge. Indeed, the only capability of our black-box adversary is to observe labels given by the DNN to chosen inputs. Our attack strategy consists in training a local model to substitute for the target DNN. using inputs synthetically generated by an adversary and labeled by the target DNN. We use the local substitute to craft adversarial examples. and find that they are misclassified by the targeted DNN. To perform a real-world and properly-blinded evaluation, we attack a DNN hosted by MetaMind, an online deep learning API. We find that their DNN misclassifies 84.24% of the adversarial examples crafted with our substitute. We demonstrate the general applicability of our strategy to many ML techniques by conducting the same attack against models hosted by Amazon and Google, using logistic regression substitutes. They yield adversarial examples misclassified by Amazon and Google at rates of 96.19% and 88,94%. We also find that this black-box attack strategy is capable of evading defense strategies previously found to make adversarial example crafting harder."	"Bp1kh
Times Cited:891
Cited References Count:18"	""	"<Go to ISI>://WOS:000539858200047"	""	"Penn State Univ, University Pk, PA 16802 USA
OpenAI, San Francisco, CA 94110 USA
Univ Wisconsin, Madison, WI USA
US Army, Res Lab, Adelphi, MD USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"S. Yeom; I. Giacomelli; M. Fredrikson; S. Jha"	"2018"	"Privacy Risk in Machine Learning: Analyzing the Connection to Overfitting"	""	"Ieee 31st Computer Security Foundations Symposium (Csf 2018)"	""	""	""	""	""	"268-282"	""	""	""	""	""	""	""	"Privacy Risk in Machine Learning: Analyzing the Connection to Overfitting"	"P Ieee Comput Secur"	"1940-1434"	"10.1109/Csf.2018.00027"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000483568200020"	""	""	"privacy
machine learning
inference attacks"	"Machine learning algorithms, when applied to sensitive data, pose a distinct threat to privacy. A growing body of prior work demonstrates that models produced by these algorithms may leak specific private information in the training data to an attacker, either through the models' structure or their observable behavior. However, the underlying cause of this privacy risk is not well understood beyond a handful of anecdotal accounts that suggest overfilling and influence might. play a role.
This paper examines the effect that overfilling and influence have on the ability of an attacker to learn information about the training data from machine learning models, either through training set membership inference or attribute inference attacks. Using both formal and empirical analyses, we illustrate a clear relationship between these factors and the privacy risk that. arises in several popular machine learning algorithms. We find that overfilling is sufficient to allow an attacker to perform membership inference and, when the target attribute meets certain conditions about its influence, attribute inference attacks. Interestingly, our formal analysis also shows that overfilling is not necessary for these attacks and begins to shed light on what. other factors may be in play. Finally, we explore the connection between membership inference and attribute inference, showing that there are deep connections between the two that lead to effective new attacks."	"Bn5lz
Times Cited:110
Cited References Count:54
Proceedings IEEE Computer Security Foundations Symposium"	""	"<Go to ISI>://WOS:000483568200020"	""	"Carnegie Mellon Univ, Pittsburgh, PA 15213 USA
Univ Wisconsin, Madison, WI 53706 USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"M. Sharif; S. Bhagavatula; M. K. Reiter; L. Bauer"	"2016"	"Accessorize to a Crime: Real and Stealthy Attacks on State-of-the-Art Face Recognition"	""	"Ccs'16: Proceedings of the 2016 Acm Sigsac Conference on Computer and Communications Security"	""	""	""	""	""	"1528-1540"	""	""	""	""	""	""	""	"Accessorize to a Crime: Real and Stealthy Attacks on State-of-the-Art Face Recognition"	""	""	"10.1145/2976749.2978392"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000387820900078"	""	""	"optimization"	"Machine learning is enabling a myriad innovations, including new algorithms for cancer diagnosis and self-driving cars. The broad use of machine learning makes it important to understand the extent to which machine-learning algorithms are subject to attack, particularly when used in applications where physical security or safety is at risk.
In this paper, we focus on facial biometric systems, which are widely used in surveillance and access control. We define and investigate a novel class of attacks: attacks that are physically realizable and inconspicuous,and allow an attacker to evade recognition or impersonate another individual. We develop a systematic method to automatically generate such attacks, which are realized through printing a pair of eyeglass frames. When worn by the attacker whose image is supplied to a state-of-the-art face-recognition algorithm, the eyeglasses allow her to evade being recognized or to impersonate another individual. Our investigation focuses on white-box face-recognition systems, but we also demonstrate how similar techniques can be used in black-box scenarios, as well as to avoid face detection."	"Bg2zw
Times Cited:418
Cited References Count:40"	""	"<Go to ISI>://WOS:000387820900078"	""	"Carnegie Mellon Univ, Pittsburgh, PA 15213 USA
Univ N Carolina, Chapel Hill, NC USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"N. Papernot; P. McDaniel; A. Swami; R. Harang"	"2016"	"Crafting Adversarial Input Sequences for Recurrent Neural Networks"	""	"Milcom 2016 - 2016 Ieee Military Communications Conference"	""	""	""	""	""	"49-54"	""	""	""	""	""	""	""	"Crafting Adversarial Input Sequences for Recurrent Neural Networks"	"Ieee Milit Commun C"	"2155-7578"	""	""	""	""	""	""	""	""	""	""	""	""	"WOS:000391433600009"	""	""	""	"Machine learning models are frequently used to solve complex security problems, as well as to make decisions in sensitive situations like guiding autonomous vehicles or predicting financial market behaviors. Previous efforts have shown that numerous machine learning models are vulnerable to adversarial manipulations of their inputs taking the form of adversarial samples. Such inputs are crafted by adding carefully selected perturbations to legitimate inputs so as to force the machine learning model to misbehave, for instance by outputting a wrong class if the machine learning task of interest is classification. In fact, to the best of our knowledge, all previous work on adversarial samples crafting for neural networks considered models used to solve classification tasks, most frequently in computer vision applications. In this paper, we investigate adversarial input sequences for recurrent neural networks processing sequential data. We show that the classes of algorithms introduced previously to craft adversarial samples misclassified by feed-forward neural networks can be adapted to recurrent neural networks. In a experiment, we show that adversaries can craft adversarial sequences misleading both categorical and sequential recurrent neural networks."	"Bg7lx
Times Cited:119
Cited References Count:25
IEEE Military Communications Conference"	""	"<Go to ISI>://WOS:000391433600009"	""	"Penn State Univ, University Pk, PA 16802 USA
US Army, Res Lab, Adelphi, MD USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"R. Sahay; R. Mahfuz; A. El Gamal"	"2019"	"Combatting Adversarial Attacks through Denoising and Dimensionality Reduction: A Cascaded Autoencoder Approach"	""	"2019 53rd Annual Conference on Information Sciences and Systems (Ciss)"	""	""	""	""	""	"1-6"	""	""	""	""	""	""	""	"Combatting Adversarial Attacks through Denoising and Dimensionality Reduction: A Cascaded Autoencoder Approach"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	"WOS:000493551600058"	""	""	""	"Machine Learning models are vulnerable to adversarial attacks that rely on perturbing the input data. This work proposes a novel strategy using Autoencoder Deep Neural Networks to defend a machine learning model against two gradient-based attacks: The Fast Gradient Sign attack and the Fast Gradient attack. First we use an autoencoder to denoise the test data, which is trained with both clean and corrupted data. Then, we reduce the dimension of the denoised data using the hidden layer representation of another autoencoder. We perform this experiment for multiple values of the bound of adversarial perturbations, and consider different numbers of reduced dimensions. When the test data is preprocessed using this cascaded pipeline, the tested deep neural network classifier yields a much higher accuracy, thus mitigating the effect of the adversarial perturbation."	"Bo0wl
Times Cited:1
Cited References Count:13"	""	"<Go to ISI>://WOS:000493551600058"	""	"Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"M. Abadi; A. Chu; I. Goodfellow; H. B. McMahan; I. Mironov; K. Talwar; L. Zhang"	"2016"	"Deep Learning with Differential Privacy"	""	"Ccs'16: Proceedings of the 2016 Acm Sigsac Conference on Computer and Communications Security"	""	""	""	""	""	"308-318"	""	""	""	""	""	""	""	"Deep Learning with Differential Privacy"	""	""	"10.1145/2976749.2978318"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000387820900014"	""	""	""	"Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. Often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information. The models should not expose private information in these datasets. Addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality."	"Bg2zw
Times Cited:970
Cited References Count:56"	""	"<Go to ISI>://WOS:000387820900014"	""	"Google, Mountain View, CA 94043 USA
OpenAI, San Francisco, CA USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"J. Aiken; S. Scott-Hayward"	"2019"	"Investigating Adversarial Attacks against Network Intrusion Detection Systems in SDNs"	""	"2019 Ieee Conference on Network Function Virtualization and Software Defined Networks (Ieee Nfv-Sdn)"	""	""	""	""	""	"1-7"	""	""	""	""	""	""	""	"Investigating Adversarial Attacks against Network Intrusion Detection Systems in SDNs"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	"WOS:000685214600015"	""	""	"network security
software-defined networks
intrusion detection systems
machine learning
adversarial attacks"	"Machine-learning based network intrusion detection systems (ML-NIDS) are increasingly popular in the fight against network attacks. In particular, promising detection results have been demonstrated in conjunction with Software-Defined Net-works (SDN), in which the logically centralized control plane provides access to data from across the network. However, research into adversarial attacks against machine learning classifiers has highlighted vulnerabilities in a number of fields. These vulnerabilities raise concerns about the implementation of similar classifiers in anomaly-based NIDSs within SDNs. In this work, we investigate the viability of adversarial attacks against classifiers in this field. We implement an anomaly-based NIDS, Neptune, as a target platform that utilises a number of different machine learning classifiers and traffic flow features. We develop an adversarial test tool, Hydra, to evaluate the impact of adversarial evasion classifier attacks against Neptune with the goal of lowering the detection rate of malicious network traffic. The results demonstrate that with the perturbation of a few features, the detection accuracy of a specific SYN flood Distributed Denial of Service (DDoS) attack by Neptune decreases from 100% to 0% across a number of classifiers. Based on these results, recommendations are made as to how to increase the robustness of classifiers against the demonstrated attacks."	"Bs0xz
Times Cited:8
Cited References Count:27"	""	"<Go to ISI>://WOS:000685214600015"	""	"Queens Univ Belfast, Ctr Secure Informat Technol, Belfast BT3 9DT, Antrim, North Ireland"	""	""	""	""	""	""	""	"English"
"Journal Article"	"F. Z. Liao; M. Liang; Y. P. Dong; T. Y. Pang; X. L. Hu; J. Zhu"	"2018"	"Defense against Adversarial Attacks Using High-Level Representation Guided Denoiser"	""	"2018 Ieee/Cvf Conference on Computer Vision and Pattern Recognition (Cvpr)"	""	""	""	""	""	"1778-1787"	""	""	""	""	""	""	""	"Defense against Adversarial Attacks Using High-Level Representation Guided Denoiser"	"Proc Cvpr Ieee"	"1063-6919"	"10.1109/Cvpr.2018.00191"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000457843601094"	""	""	""	"Neural networks are vulnerable to adversarial examples, which poses a threat to their application in security sensitive systems. We propose high-level representation guided denoiser (HGD) as a defense for image classification. Standard denoiser suffers from the error amplification effect, in which small residual adversarial noise is progressively amplified and leads to wrong classifications. HGD overcomes this problem by using a loss function defined as the difference between the target model's outputs activated by the clean image and denoised image. Compared with ensemble adversarial training which is the state-of-the-art defending method on large images, HGD has three advantages. First, with HGD as a defense, the target model is more robust to either white-box or black-box adversarial attacks. Second, HGD can be trained on a small subset of the images and generalizes well to other images and unseen classes. Third, HGD can be transferred to defend models other than the one guiding it. In NIPS competition on defense against adversarial attacks, our HGD solution won the first place and outperformed other models by a large margin."	"Bl9nz
Times Cited:168
Cited References Count:32
IEEE Conference on Computer Vision and Pattern Recognition"	""	"<Go to ISI>://WOS:000457843601094"	""	"Tsinghua Univ, Dept Comp Sci & Technol, Beijing Natl Res Ctr Informat Sci & Technol, Tsinghua Lab Brain & Intelligence,BNRist Lab, Beijing 100084, Peoples R China"	""	""	""	""	""	""	""	"English"
"Journal Article"	"N. Carlini; D. Wagner"	"2017"	"Towards Evaluating the Robustness of Neural Networks"	""	"2017 Ieee Symposium on Security and Privacy (Sp)"	""	""	""	""	""	"39-57"	""	""	""	""	""	""	""	"Towards Evaluating the Robustness of Neural Networks"	"P Ieee S Secur Priv"	"1081-6011"	"10.1109/Sp.2017.49"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000413081300003"	""	""	""	"Neural networks provide state-of-the-art results for most machine learning tasks. Unfortunately, neural networks are vulnerable to adversarial examples: given an input x and any target classification t, it is possible to find a new input x' that is similar to x but classified as t. This makes it difficult to apply neural networks in security-critical areas. Defensive distillation is a recently proposed approach that can take an arbitrary neural network, and increase its robustness, reducing the success rate of current attacks' ability to find adversarial examples from 95% to 0.5%.
In this paper, we demonstrate that defensive distillation does not significantly increase the robustness of neural networks by introducing three new attack algorithms that are successful on both distilled and undistilled neural networks with 100% probability. Our attacks are tailored to three distance metrics used previously in the literature, and when compared to previous adversarial example generation algorithms, our attacks are often much more effective (and never worse). Furthermore, we propose using high-confidence adversarial examples in a simple transferability test we show can also be used to break defensive distillation. We hope our attacks will be used as a benchmark in future defense attempts to create neural networks that resist adversarial examples."	"Bi6cu
Times Cited:1811
Cited References Count:48
IEEE Symposium on Security and Privacy"	""	"<Go to ISI>://WOS:000413081300003"	""	"Univ Calif Berkeley, Berkeley, CA 94720 USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"E. Principi; F. Vesperini; S. Squartini; F. Piazza"	"2017"	"Acoustic Novelty Detection with Adversarial Autoencoders"	""	"2017 International Joint Conference on Neural Networks (Ijcnn)"	""	""	""	""	""	"3324-3330"	""	""	""	""	""	""	""	"Acoustic Novelty Detection with Adversarial Autoencoders"	"Ieee Ijcnn"	"2161-4393"	""	""	""	""	""	""	""	""	""	""	""	""	"WOS:000426968703079"	""	""	"recognition
speech
separation
system"	"Novelty detection is the task of recognising events the differ from a model of normality. This paper proposes an acoustic novelty detector based on neural networks trained with an adversarial training strategy. The proposed approach is composed of a feature extraction stage that calculates Log-Mel spectral features from the input signal. Then, an autoencoder network, trained on a corpus of "normal" acoustic signals, is employed to detect whether a segment contains an abnormal event or not. A novelty is detected if the Euclidean distance between the input and the output of the autoencoder exceeds a certain threshold. The innovative contribution of the proposed approach resides in the training procedure of the autoencoder network: instead of using the conventional training procedure that minimises only the Minimum Mean Squared Error loss function, here we adopt an adversarial strategy, where a discriminator network is trained to distinguish between the output of the autoencoder and data sampled from the training corpus. The autoencoder, then, is trained also by using the binary cross-entropy loss calculated at the output of the discriminator network.
The performance of the algorithm has been assessed on a corpus derived from the PASCAL CHiME dataset. The results showed that the proposed approach provides a relative performance improvement equal to 0.26% compared to the standard autoencoder. The significance of the improvement has been evaluated with a one-tailed z-test and resulted significant with p < 0.001. The presented approach thus showed promising results on this task and it could be extended as a general training strategy for autoencoders if confirmed by additional experiments."	"Bj6wl
Times Cited:23
Cited References Count:39
IEEE International Joint Conference on Neural Networks (IJCNN)"	""	"<Go to ISI>://WOS:000426968703079"	""	"Univ Politecn Marche, Dept Informat Engn, Via Brecce Bianche, I-60131 Ancona, Italy"	""	""	""	""	""	""	""	"English"
"Journal Article"	"L. Frigerio; A. S. de Oliveira; L. Gomez; P. Duverger"	"2019"	"Differentially Private Generative Adversarial Networks for Time Series, Continuous, and Discrete Open Data"	""	"Ict Systems Security and Privacy Protection, Sec 2019"	""	""	"562"	""	""	"151-164"	""	""	""	""	""	""	""	"Differentially Private Generative Adversarial Networks for Time Series, Continuous, and Discrete Open Data"	"Ifip Adv Inf Comm Te"	"1868-4238"	"10.1007/978-3-030-22312-0_11"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000560392300011"	""	""	"differential privacy
generative adversarial networks"	"Open data plays a fundamental role in the 21st century by stimulating economic growth and by enabling more transparent and inclusive societies. However, it is always difficult to create new high-quality datasets with the required privacy guarantees for many use cases. In this paper, we developed a differential privacy framework for privacy preserving data publishing using Generative Adversarial Networks. It can be easily adapted to different use cases, from the generation of time-series, to continuous, and discrete data. We demonstrate the efficiency of our approach on real datasets from the French public administration and classic benchmark datasets. Our results maintain both the original distribution of the features and the correlations among them, at the same time providing a good level of privacy."	"Bp6qe
Times Cited:7
Cited References Count:21
IFIP Advances in Information and Communication Technology"	""	"<Go to ISI>://WOS:000560392300011"	""	"Polytech Nice, Biot, France
SAP Labs France, Mougins, France
Ville Antibes, Antibes, France"	""	""	""	""	""	""	""	"English"
"Journal Article"	"F. Zhang; P. P. Chan; B. Biggio; D. S. Yeung; F. Roli"	"2016"	"Adversarial Feature Selection Against Evasion Attacks"	""	"IEEE Trans Cybern"	""	""	"46"	""	"3"	"766-77"	""	""	""	"2015/04/25"	"Mar"	""	""	"Adversarial Feature Selection Against Evasion Attacks"	""	"2168-2275 (Electronic)
2168-2267 (Linking)"	"10.1109/TCYB.2015.2415032"	""	""	""	""	""	""	""	""	""	""	""	"25910268"	""	""	""	"Pattern recognition and machine learning techniques have been increasingly adopted in adversarial settings such as spam, intrusion, and malware detection, although their security against well-crafted attacks that aim to evade detection by manipulating data at test time has not yet been thoroughly assessed. While previous work has been mainly focused on devising adversary-aware classification algorithms to counter evasion attempts, only few authors have considered the impact of using reduced feature sets on classifier security against the same attacks. An interesting, preliminary result is that classifier security to evasion may be even worsened by the application of feature selection. In this paper, we provide a more detailed investigation of this aspect, shedding some light on the security properties of feature selection against evasion attacks. Inspired by previous work on adversary-aware classifiers, we propose a novel adversary-aware feature selection model that can improve classifier security against evasion attacks, by incorporating specific assumptions on the adversary's data manipulation strategy. We focus on an efficient, wrapper-based implementation of our approach, and experimentally validate its soundness on different application examples, including spam and malware detection."	"Zhang, Fei
Chan, Patrick P K
Biggio, Battista
Yeung, Daniel S
Roli, Fabio
eng
Research Support, Non-U.S. Gov't
IEEE Trans Cybern. 2016 Mar;46(3):766-77. doi: 10.1109/TCYB.2015.2415032. Epub 2015 Apr 21."	""	"https://www.ncbi.nlm.nih.gov/pubmed/25910268"	""	""	""	""	""	""	""	""	""	""
"Journal Article"	"P. Y. Chen; Y. Sharma; H. Zhang; J. F. Yi; C. J. Hsieh"	"2018"	"EAD: Elastic-Net Attacks to Deep Neural Networks via Adversarial Examples"	""	"Thirty-Second Aaai Conference on Artificial Intelligence / Thirtieth Innovative Applications of Artificial Intelligence Conference / Eighth Aaai Symposium on Educational Advances in Artificial Intelligence"	""	""	"abs/1709.04114"	""	""	"10-17"	""	""	""	""	""	""	""	"EAD: Elastic-Net Attacks to Deep Neural Networks via Adversarial Examples"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	"WOS:000485488900002"	""	""	""	"Recent studies have highlighted the vulnerability of deep neural networks (DNNs) to adversarial examples - a visually indistinguishable adversarial image can easily be crafted to cause a well-trained model to misclassify. Existing methods for crafting adversarial examples are based on L-2 and L-infinity distortion metrics. However, despite the fact that L-1 distortion accounts for the total variation and encourages sparsity in the perturbation, little has been developed for crafting L-1-based adversarial examples.
In this paper, we formulate the process of attacking DNNs via adversarial examples as an elastic-net regularized optimization problem. Our elastic-net attacks to DNNs (EAD) feature L-1-L-2 oriented adversarial examples and include the state-of-the-art attack as a special case. Experimental results OD MNIST, GIFAR10 and ImageNet show that FAD can yield a distinct set of adversarial examples with small L-1 distortion and attains similar attack performance to the state-of-the-art methods in different attack scenarios. More importantly, EAD leads to improved attack transferability and complements adversarial training for DNNs, suggesting novel insights on leveraging L-1 distortion in adversarial machine learning and security implications of DNNs."	"Bn6jj
Times Cited:121
Cited References Count:32"	""	"<Go to ISI>://WOS:000485488900002"	""	"IBM TJ Watson Res Ctr, IAI Foundat Lab, Yorktown Hts, NY 10598 USA
Cooper Union Adv Sci & Art, New York, NY 10003 USA
Univ Calif Davis, Davis, CA 95616 USA
Tencent AI Lab, Bellevue, WA 98004 USA
IBM TJ Watson Res Ctr, Yorktown Hts, NY USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"W. Z. Shi; J. Caballero; F. Huszar; J. Totz; A. P. Aitken; R. Bishop; D. Rueckert; Z. H. Wang"	"2016"	"Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network"	""	"2016 Ieee Conference on Computer Vision and Pattern Recognition (Cvpr)"	""	""	""	""	""	"1874-1883"	""	""	""	""	""	""	""	"Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network"	"Proc Cvpr Ieee"	"1063-6919"	"10.1109/Cvpr.2016.207"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000400012301099"	""	""	"dictionary"	"Recently, several models based on deep neural networks have achieved great success in terms of both reconstruction accuracy and computational performance for single image super-resolution. In these methods, the low resolution (LR) input image is upscaled to the high resolution (HR) space using a single filter, commonly bicubic interpolation, before reconstruction. This means that the super-resolution (SR) operation is performed in HR space. We demonstrate that this is sub-optimal and adds computational complexity. In this paper, we present the first convolutional neural network (CNN) capable of real-time SR of 1080p videos on a single K2 GPU. To achieve this, we propose a novel CNN architecture where the feature maps are extracted in the LR space. In addition, we introduce an efficient sub-pixel convolution layer which learns an array of upscaling filters to upscale the final LR feature maps into the HR output. By doing so, we effectively replace the handcrafted bicubic filter in the SR pipeline with more complex upscaling filters specifically trained for each feature map, whilst also reducing the computational complexity of the overall SR operation. We evaluate the proposed approach using images and videos from publicly available datasets and show that it performs significantly better (+0.15dB on Images and +0.39dB on Videos) and is an order of magnitude faster than previous CNN-based methods."	"Bh3tw
Times Cited:2169
Cited References Count:54
IEEE Conference on Computer Vision and Pattern Recognition"	""	"<Go to ISI>://WOS:000400012301099"	""	""	""	""	""	""	""	""	""	"English"
"Journal Article"	"M. H. Fang; G. L. Yang; N. Z. Gong; J. Liu"	"2018"	"Poisoning Attacks to Graph-Based Recommender Systems"	""	"34th Annual Computer Security Applications Conference (Acsac 2018)"	""	""	""	""	""	"381-392"	""	""	""	""	""	""	""	"Poisoning Attacks to Graph-Based Recommender Systems"	""	""	"10.1145/3274694.3274706"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000455393700031"	""	""	"adversarial recommender systems
poisoning attacks
adversarial machine learning"	"Recommender system is an important component of many web services to help users locate items that match their interests. Several studies showed that recommender systems are vulnerable to poisoning attacks, in which an attacker injects fake data to a recommender system such that the system makes recommendations as the attacker desires. However, these poisoning attacks are either agnostic to recommendation algorithms or optimized to recommender systems (e.g., association-rule-based or matrix-factorization-based recommender systems) that are not graph-based. Like association-rule-based and matrix-factorization-based recommender systems, graph-based recommender system is also deployed in practice, e.g., eBay, Huawei App Store (a big app store in China). However, how to design optimized poisoning attacks for graph-based recommender systems is still an open problem.
In this work, we perform a systematic study on poisoning attacks to graph-based recommender systems. We consider an attacker's goal is to promote a target item to be recommended to as many users as possible. To achieve this goal, our attacks inject fake users with carefully crafted rating scores to the recommender system. Due to limited resources and to avoid detection, we assume the number of fake users that can be injected into the system is bounded. The key challenge is how to assign rating scores to the fake users such that the target item is recommended to as many normal users as possible. To address the challenge, we formulate the poisoning attacks as an optimization problem, solving which determines the rating scores for the fake users. We also propose techniques to solve the optimization problem. We evaluate our attacks and compare them with existing attacks under white-box (recommendation algorithm and its parameters are known), gray-box (recommendation algorithm is known but its parameters are unknown), and black-box (recommendation algorithm is unknown) settings using two real-world datasets. Our results show that our attack is effective and outperforms existing attacks for graph-based recommender systems. For instance, when 1% of users are injected fake users, our attack can make a target item recommended to 580 times more normal users in certain scenarios."	"Bl7sc
Times Cited:48
Cited References Count:34"	""	"<Go to ISI>://WOS:000455393700031"	""	"Iowa State Univ, Ames, IA 50011 USA
Facebook Inc, Menlo Pk, CA USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"A. Graves; A. R. Mohamed; G. Hinton"	"2013"	"Speech Recognition with Deep Recurrent Neural Networks"	""	"2013 Ieee International Conference on Acoustics, Speech and Signal Processing (Icassp)"	""	""	""	""	""	"6645-6649"	""	""	""	""	""	""	""	"Speech Recognition with Deep Recurrent Neural Networks"	"Int Conf Acoust Spee"	"1520-6149"	""	""	""	""	""	""	""	""	""	""	""	""	"WOS:000329611506162"	""	""	"recurrent neural networks
deep neural networks
speech recognition"	"Recurrent neural networks (RNNs) are a powerful model for sequential data. End-to-end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input-output alignment is unknown. The combination of these methods with the Long Short-term Memory RNN architecture has proved particularly fruitful, delivering state-of-the-art results in cursive handwriting recognition. However RNN performance in speech recognition has so far been disappointing, with better results returned by deep feedforward networks. This paper investigates deep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs. When trained end-to-end with suitable regularisation, we find that deep Long Short-term Memory RNNs achieve a test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to our knowledge is the best recorded score."	"Bjq19
Times Cited:3712
Cited References Count:27
International Conference on Acoustics Speech and Signal Processing ICASSP"	""	"<Go to ISI>://WOS:000329611506162"	""	"Univ Toronto, Dept Comp Sci, Toronto, ON M5S 1A1, Canada"	""	""	""	""	""	""	""	"English"
"Journal Article"	"L. A. Gatys; A. S. Ecker; M. Bethge"	"2016"	"Image Style Transfer Using Convolutional Neural Networks"	""	"2016 Ieee Conference on Computer Vision and Pattern Recognition (Cvpr)"	""	""	""	""	""	"2414-2423"	""	""	""	""	""	""	""	"Image Style Transfer Using Convolutional Neural Networks"	"Proc Cvpr Ieee"	"1063-6919"	"10.1109/Cvpr.2016.265"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000400012302051"	""	""	"texture synthesis"	"Rendering the semantic content of an image in different styles is a difficult image processing task. Arguably, a major limiting factor for previous approaches has been the lack of image representations that explicitly represent semantic information and, thus, allow to separate image content from style. Here we use image representations derived from Convolutional Neural Networks optimised for object recognition, which make high level image information explicit. We introduce A Neural Algorithm of Artistic Style that can separate and recombine the image content and style of natural images. The algorithm allows us to produce new images of high perceptual quality that combine the content of an arbitrary photograph with the appearance of numerous well-known artworks. Our results provide new insights into the deep image representations learned by Convolutional Neural Networks and demonstrate their potential for high level image synthesis and manipulation."	"Bh3tw
Times Cited:823
Cited References Count:30
IEEE Conference on Computer Vision and Pattern Recognition"	""	"<Go to ISI>://WOS:000400012302051"	""	"Univ Tubingen, Ctr Integrat Neurosci, Tubingen, Germany
Bernstein Ctr Computat Neurosci, Tubingen, Germany
Univ Tubingen, Grad Sch Neural Informat Proc, Tubingen, Germany
Max Planck Inst Biol Cybernet, Tubingen, Germany
Baylor Coll Med, Houston, TX 77030 USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"F. Angiulli; L. Argento; A. Furfaro"	"2015"	"Exploiting n-gram location for intrusion detection"	""	"2015 Ieee 27th International Conference on Tools with Artificial Intelligence (Ictai 2015)"	""	""	""	""	""	"1093-1098"	""	""	""	""	""	""	""	"Exploiting n-gram location for intrusion detection"	"Proc Int C Tools Art"	"1082-3409"	"10.1109/Ictai.2015.155"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000374592500141"	""	""	"intrusion detection systems
semi-supervised learning
n-grams
anomaly detection
ftp traffic"	"Signature-based and protocol-based intrusion detection systems (IDS) are employed as means to reveal content-based network attacks. Such systems have proven to be effective in identifying known intrusion attempts and exploits but they fail to recognize new types of attacks or carefully crafted variants of well known ones. This paper presents the design and the development of an anomaly-based IDS technique which is able to detect content-based attacks carried out over application level protocols, like HTTP and FTP. In order to identify anomalous packets, the payload is split up in chunks of equal length and the n-gram technique is used to learn which byte sequences usually appear in each chunk. The devised technique builds a different model for each pair < protocol of interest, packet length > and uses them to classify the incoming traffic. Models are build by means of a semi-supervised approach. Experimental results witness that the technique achieves an excellent accuracy with a very low false positive rate."	"Be6qd
Times Cited:6
Cited References Count:10
Proceedings-International Conference on Tools With Artificial Intelligence"	""	"<Go to ISI>://WOS:000374592500141"	""	"Univ Calabria, DIMES, P Bucci 41C, I-87036 Arcavacata Di Rende, CS, Italy"	""	""	""	""	""	""	""	"English"
"Journal Article"	"S. Khamaiseh; E. Serra; Z. Y. Li; D. X. Xu"	"2019"	"Detecting Saturation Attacks in SDN via Machine Learning"	""	"2019 4th International Conference on Computing, Communications and Security (Icccs)"	""	""	""	""	""	"1-8"	""	""	""	""	""	""	""	"Detecting Saturation Attacks in SDN via Machine Learning"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	"WOS:000533373800004"	""	""	"software-defined networking
openflow
saturation attack
anomaly detection
machine learning"	"Software Defined Networking (SDN) is a new network paradigm that facilitates network management by separating the control plane from the data plane. Studies have shown that an SDN may experience a high packet loss rate and a long delay in forwarding messages when the OpenFlow channel is ovenvhelmed by a saturation attack. The existing approaches have focused on the detection of saturation attacks caused by TCP-SYN flooding through periodic analysis of network traffic. However, there are two issues. First, previous approaches are incapable of detecting other types, especially unknown types, of saturation attacks. Second, they rely on predetermined time-window of network traffic and thus are unable to determine what time window of traffic data would be appropriate for effective attack detection. To tackle these problems, this paper first investigates the impact of different time-windows of OpenFlow traffic on the detection performance of three classification algorithms: the Support Vector Machine (SVM), the Naive Bayes (NB) classifier, and the K-Nearest Neighbors (K-NN) classifier. We have built and analyzed a total of 150 models on OpenFlow traffic datasets generated from both physical and simulated SDN environments. The experiment results show that the chosen time-interval of OpenFlow traffic heavily influences the detection performance - larger time-windows may result in decreased detection performance. In addition, we were able to achieve reasonable accuracy on detection of unknown attacks by applying proper time-windows of OpenFlow traffic."	"Bo9yz
Times Cited:3
Cited References Count:19"	""	"<Go to ISI>://WOS:000533373800004"	""	"Boise State Univ, Dept Comp Sci, Boise, ID 83725 USA
Jiangsu Univ, Dept Cybersecur, Zhenjiang 212013, Jiangsu, Peoples R China
Univ Missouri Kansas City, Dept Comp Sci Elect Engn, Kansas City, MO 64110 USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"N. Sultana; N. Chilamkurti; W. Peng; R. Alhadad"	"2019"	"Survey on SDN based network intrusion detection system using machine learning approaches"	""	"Peer-to-Peer Networking and Applications"	""	""	"12"	""	"2"	"493-501"	""	""	""	""	"Mar"	""	""	"Survey on SDN based network intrusion detection system using machine learning approaches"	"Peer Peer Netw Appl"	"1936-6442"	"10.1007/s12083-017-0630-0"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000458997900018"	""	""	"nids
machine learning
deep learning
sdn
software-defined networking"	"Software Defined Networking Technology (SDN) provides a prospect to effectively detect and monitor network security problems ascribing to the emergence of the programmable features. Recently, Machine Learning (ML) approaches have been implemented in the SDN-based Network Intrusion Detection Systems (NIDS) to protect computer networks and to overcome network security issues. A stream of advanced machine learning approaches - the deep learning technology (DL) commences to emerge in the SDN context. In this survey, we reviewed various recent works on machine learning (ML) methods that leverage SDN to implement NIDS. More specifically, we evaluated the techniques of deep learning in developing SDN-based NIDS. In the meantime, in this survey, we covered tools that can be used to develop NIDS models in SDN environment. This survey is concluded with a discussion of ongoing challenges in implementing NIDS using ML/DL and future works."	"Sp. Iss. SI
Hl8mw
Times Cited:133
Cited References Count:50"	""	"<Go to ISI>://WOS:000458997900018"	""	"La Trobe Univ, Dept Comp Sci & IT, Melbourne, Vic, Australia
La Trobe Univ, Dept Accounting & Business Analyt, Melbourne, Vic, Australia"	""	""	""	""	""	""	""	"English"
"Journal Article"	"R. Wang; Z. P. Jia; L. Ju"	"2015"	"An Entropy-Based Distributed DDoS Detection Mechanism in Software-Defined Networking"	""	"2015 Ieee Trustcom/Bigdatase/Ispa, Vol 1"	""	""	"1"	""	""	"310-317"	""	""	""	""	""	""	""	"An Entropy-Based Distributed DDoS Detection Mechanism in Software-Defined Networking"	""	""	"10.1109/Trustcom-2015.389"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000399004200040"	""	""	"sdn
openflow
ddos
entropy
anomaly detection
mitigation"	"Software-Defined Networking (SDN) and OpenFlow (OF) protocol have brought a promising architecture for the future networks. However, the centralized control and programmable characteristics also bring a lot of security challenges. Distributed denial-of-service (DDoS) attack is still a security threat to SDN. To detect the DDoS attack in SDN, many researches collect the flow tables from the switch and do the anomaly detection in the controller. But in the large scale network, the collecting process burdens the communication overload between the switches and the controller. Sampling technology may relieve this overload, but it brings a new tradeoff between sampling rate and detection accuracy. In this paper, we first extend a copy of the packet number counter of the flow entry in the OpenFlow table. Based on the flow-based nature of SDN, we design a flow statistics process in the switch. Then, we propose an entropy-based lightweight DDoS flooding attack detection model running in the OF edge switch. This achieves a distributed anomaly detection in SDN and reduces the flow collection overload to the controller. We also give the detailed algorithm which has a small calculation overload and can be easily implemented in SDN software or programmable switch, such as Open vSwitch and NetFPGA. The experimental results show that our detection mechanism can detect the attack quickly and achieve a high detection accuracy with a low false positive rate."	"Bh2kd
Times Cited:99
Cited References Count:25"	""	"<Go to ISI>://WOS:000399004200040"	""	"Shandong Univ, Sch Comp Sci & Technol, Jinan, Peoples R China"	""	""	""	""	""	""	""	"English"
"Journal Article"	"S. M. Moosavi-Dezfooli; A. Fawzi; P. Frossard"	"2016"	"DeepFool: a simple and accurate method to fool deep neural networks"	""	"2016 Ieee Conference on Computer Vision and Pattern Recognition (Cvpr)"	""	""	""	""	""	"2574-2582"	""	""	""	""	""	""	""	"DeepFool: a simple and accurate method to fool deep neural networks"	"Proc Cvpr Ieee"	"1063-6919"	"10.1109/Cvpr.2016.282"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000400012302068"	""	""	""	"State-of-the-art deep neural networks have achieved impressive results on many image classification tasks. However, these same architectures have been shown to be unstable to small, well sought, perturbations of the images. Despite the importance of this phenomenon, no effective methods have been proposed to accurately compute the robustness of state-of-the-art deep classifiers to such perturbations on large-scale datasets. In this paper, we fill this gap and propose the DeepFool algorithm to efficiently compute perturbations that fool deep networks, and thus reliably quantify the robustness of these classifiers. Extensive experimental results show that our approach outperforms recent methods in the task of computing adversarial perturbations and making classifiers more robust.(1)"	"Bh3tw
Times Cited:1233
Cited References Count:21
IEEE Conference on Computer Vision and Pattern Recognition"	""	"<Go to ISI>://WOS:000400012302068"	""	"Ecole Polytech Fed Lausanne, Lausanne, Switzerland"	""	""	""	""	""	""	""	"English"
"Journal Article"	"A. Rozsa; E. M. Rudd; T. E. Boult"	"2016"	"Adversarial Diversity and Hard Positive Generation"	""	"Proceedings of 29th Ieee Conference on Computer Vision and Pattern Recognition Workshops, (Cvprw 2016)"	""	""	""	""	""	"410-417"	""	""	""	""	""	""	""	"Adversarial Diversity and Hard Positive Generation"	"Ieee Comput Soc Conf"	"2160-7508"	"10.1109/Cvprw.2016.58"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000391572100051"	""	""	""	"State-of-the-art deep neural networks suffer from a fundamental problem - they misclassify adversarial examples formed by applying small perturbations to inputs. In this paper, we present a new psychometric perceptual adversarial similarity score (PASS) measure for quantifying adversarial images, introduce the notion of hard positive generation, and use a diverse set of adversarial perturbations - not just the closest ones - for data augmentation. We introduce a novel hot/cold approach for adversarial example generation, which provides multiple possible adversarial perturbations for every single image. The perturbations generated by our novel approach often correspond to semantically meaningful image structures, and allow greater flexibility to scale perturbation-amplitudes, which yields an increased diversity of adversarial images. We present adversarial images on several network topologies and datasets, including LeNet on the MNIST dataset, and GoogLeNet and ResidualNet on the ImageNet dataset. Finally, we demonstrate on LeNet and GoogLeNet that fine-tuning with a diverse set of hard positives improves the robustness of these networks compared to training with prior methods of generating adversarial images."	"Bg7pp
Times Cited:61
Cited References Count:21
IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops"	""	"<Go to ISI>://WOS:000391572100051"	""	"Univ Colorado Colorado Springs, Vis & Secur Technol VAST Lab, Colorado Springs, CO 80918 USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"I. Hagestedt; Y. Zhang; M. Humbert; P. Berrang; H. X. Tang; X. F. Wang; M. Backes"	"2019"	"MBeacon: Privacy-Preserving Beacons for DNA Methylation Data"	""	"26th Annual Network and Distributed System Security Symposium (Ndss 2019)"	""	""	""	""	""	""	""	""	""	""	""	""	""	"MBeacon: Privacy-Preserving Beacons for DNA Methylation Data"	""	""	"10.14722/ndss.2019.23064"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000680713300025"	""	""	"expression
mutations
subgroups
genotype
acvr1"	"The advancement of molecular profiling techniques fuels biomedical research with a deluge of data. To facilitate data sharing, the Global Alliance for Genomics and Health established the Beacon system, a search engine designed to help researchers find datasets of interest. While the current Beacon system only supports genomic data, other types of biomedical data, such as DNA methylation, are also essential for advancing our understanding in the field. In this paper, we propose the first Beacon system for DNA methylation data sharing: MBeacon. As the current genomic Beacon is vulnerable to privacy attacks, such as membership inference, and DNA methylation data is highly sensitive, we take a privacy-by-design approach to construct MBeacon.
First, we demonstrate the privacy threat, by proposing a membership inference attack tailored specifically to unprotected methylation Beacons. Our experimental results show that 100 queries are sufficient to achieve a successful attack with AUC (area under the ROC curve) above 0.9. To remedy this situation, we propose a novel differential privacy mechanism, namely SVT2, which is the core component of MBeacon. Extensive experiments over multiple datasets show that SVT2 can successfully mitigate membership privacy risks without significantly harming utility. We further implement a fully functional prototype of MBeacon which we make available to the research community."	"Bs0ba
Times Cited:10
Cited References Count:47"	""	"<Go to ISI>://WOS:000680713300025"	""	"CISPA Helmholtz Ctr Informat Secur, Saarbrucken, Germany
Swiss Fed Inst Technol, Wiss Data Sci Ctr, Zurich, Switzerland
Ecole Polytech Fed Lausanne, Lausanne, Switzerland
Indiana Univ, Bloomington, IN USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"Y. H. Li; J. B. Xia; S. L. Zhang; J. K. Yan; X. C. Ai; K. B. Dai"	"2012"	"An efficient intrusion detection system based on support vector machines and gradually feature removal method"	""	"Expert Systems with Applications"	""	""	"39"	""	"1"	"424-430"	""	""	""	""	"Jan"	""	""	"An efficient intrusion detection system based on support vector machines and gradually feature removal method"	"Expert Syst Appl"	"0957-4174"	"10.1016/j.eswa.2011.07.032"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000296214900045"	""	""	"intrusion detection
support vector machine
feature reduction
selection
design"	"The efficiency of the intrusion detection is mainly depended on the dimension of data features. By using the gradually feature removal method, 19 critical features are chosen to represent for the various network visit. With the combination of clustering method, ant colony algorithm and support vector machine (SVM), an efficient and reliable classifier is developed to judge a network visit to be normal or not. Moreover, the accuracy achieves 98.6249% in 10-fold cross validation and the average Matthews correlation coefficient (MCC) achieves 0.861161. (C) 2011 Elsevier Ltd. All rights reserved."	"837pe
Times Cited:185
Cited References Count:21"	""	"<Go to ISI>://WOS:000296214900045"	""	"Huazhong Agr Univ, Coll Sci, Wuhan, Hubei, Peoples R China
Navy Engn Univ, Coll Sci, Wuhan, Hubei, Peoples R China
Huanggang Normal Univ, Coll Math & Info Sci, Huanggang, Hubei, Peoples R China"	""	""	""	""	""	""	""	"English"
"Journal Article"	"D. P. Kingma; D. J. Rezende; S. Mohamed; M. Welling"	"2014"	"Semi-supervised Learning with Deep Generative Models"	""	"Advances in Neural Information Processing Systems 27 (Nips 2014)"	""	""	"27"	""	""	""	""	""	""	""	""	""	""	"Semi-supervised Learning with Deep Generative Models"	"Adv Neur In"	"1049-5258"	""	""	""	""	""	""	""	""	""	""	""	""	"WOS:000452647101023"	""	""	""	"The ever-increasing size of modem data sets combined with the difficulty of obtaining label information has made semi-supervised learning one of the problems of significant practical importance in modern data analysis. We revisit the approach to semi-supervised learning with generative models and develop new models that allow for effective generalisation from small labelled data sets to large unlabelled ones. Generative approaches have thus far been either inflexible, inefficient or non-scalable. We show that deep generative models and approximate Bayesian inference exploiting recent advances in variational methods can be used to provide significant improvements, making generative approaches highly competitive for semi-supervised learning."	"Bl5sr
Times Cited:225
Cited References Count:26
Advances in Neural Information Processing Systems"	""	"<Go to ISI>://WOS:000452647101023"	""	"Univ Amsterdam, Machine Learning Grp, Amsterdam, Netherlands
Google Deepmind, London, England"	""	""	""	""	""	""	""	"English"
"Journal Article"	"H. Ye; G. Y. Li; B. H. Juang"	"2018"	"Power of Deep Learning for Channel Estimation and Signal Detection in OFDM Systems"	""	"Ieee Wireless Communications Letters"	""	""	"7"	""	"1"	"114-117"	""	""	""	""	"Feb"	""	""	"Power of Deep Learning for Channel Estimation and Signal Detection in OFDM Systems"	"Ieee Wirel Commun Le"	"2162-2337"	"10.1109/Lwc.2017.2757490"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000425620400029"	""	""	"deep learning
channel estimation
ofdm"	"This letter presents our initial results in deep learning for channel estimation and signal detection in orthogonal frequency-division multiplexing (OFDM) systems. In this letter, we exploit deep learning to handle wireless OFDM channels in an end-to-end manner. Different from existing OFDM receivers that first estimate channel state information (CSI) explicitly and then detect/recover the transmitted symbols using the estimated CSI, the proposed deep learning-based approach estimates CSI implicitly and recovers the transmitted symbols directly. To address channel distortion, a deep learning model is first trained offline using the data generated from simulation based on channel statistics and then used for recovering the online transmitted data directly. From our simulation results, the deep learning based approach can address channel distortion and detect the transmitted symbols with performance comparable to the minimum mean-square error estimator. Furthermore, the deep learning-based approach is more robust than conventional methods when fewer training pilots are used, the cyclic prefix is omitted, and nonlinear clipping noise exists. In summary, deep learning is a promising tool for channel estimation and signal detection in wireless communications with complicated channel distortion and interference."	"Fw8xn
Times Cited:649
Cited References Count:10"	""	"<Go to ISI>://WOS:000425620400029"	""	"Georgia Inst Technol, Dept Elect & Comp Engn, Atlanta, GA 30332 USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"J. Uesato; B. O'Donoghue; A. van den Oord; P. Kohli"	"2018"	"Adversarial Risk and the Dangers of Evaluating Against Weak Attacks"	""	"International Conference on Machine Learning, Vol 80"	""	""	"80"	""	""	""	""	""	""	""	""	""	""	"Adversarial Risk and the Dangers of Evaluating Against Weak Attacks"	"Pr Mach Learn Res"	"2640-3498"	""	""	""	""	""	""	""	""	""	""	""	""	"WOS:000683379205016"	""	""	""	"This paper investigates recently proposed approaches for defending against adversarial examples and evaluating adversarial robustness. We motivate adversarial risk as an objective for achieving models robust to worst-case inputs. We then frame commonly used attacks and evaluation metrics as defining a tractable surrogate objective to the true adversarial risk. This suggests that models may optimize this surrogate rather than the true adversarial risk. We formalize this notion as obscurity to an adversary, and develop tools and heuristics for identifying obscured models and designing transparent models. We demonstrate that this is a significant problem in practice by repurposing gradient-free optimization techniques into adversarial attacks, which we use to decrease the accuracy of several recently proposed defenses to near zero. Our hope is that our formulations and results will help researchers to develop more powerful defenses."	"Bs0mk
Times Cited:74
Cited References Count:54
Proceedings of Machine Learning Research"	""	"<Go to ISI>://WOS:000683379205016"	""	"DeepMind, London, England"	""	""	""	""	""	""	""	"English"
"Journal Article"	"C. Y. Chen; A. Seff; A. Kornhauser; J. X. Xiao"	"2015"	"DeepDriving: Learning Affordance for Direct Perception in Autonomous Driving"	""	"2015 Ieee International Conference on Computer Vision (Iccv)"	""	""	""	""	""	"2722-2730"	""	""	""	""	""	""	""	"DeepDriving: Learning Affordance for Direct Perception in Autonomous Driving"	"Ieee I Conf Comp Vis"	"1550-5499"	"10.1109/Iccv.2015.312"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000380414100304"	""	""	""	"Today, there are two major paradigms for vision-based autonomous driving systems: mediated perception approaches that parse an entire scene to make a driving decision, and behavior reflex approaches that directly map an input image to a driving action by a regressor. In this paper, we propose a third paradigm: a direct perception approach to estimate the affordance for driving. We propose to map an input image to a small number of key perception indicators that directly relate to the affordance of a road/traffic state for driving. Our representation provides a set of compact yet complete descriptions of the scene to enable a simple controller to drive autonomously. Falling in between the two extremes of mediated perception and behavior reflex, we argue that our direct perception representation provides the right level of abstraction. To demonstrate this, we train a deep Convolutional Neural Network using recording from 12 hours of human driving in a video game and show that our model can work well to drive a car in a very diverse set of virtual environments. We also train a model for car distance estimation on the KITTI dataset. Results show that our direct perception approach can generalize well to real driving images. Source code and data are available on our project website."	"Bf1nz
Times Cited:738
Cited References Count:21
IEEE International Conference on Computer Vision"	""	"<Go to ISI>://WOS:000380414100304"	""	"Princeton Univ, Princeton, NJ 08544 USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"S. Ahmad; A. Lavin; S. Purdy; Z. Agha"	"2017"	"Unsupervised real-time anomaly detection for streaming data"	""	"Neurocomputing"	""	""	"262"	""	""	"134-147"	""	""	""	""	"Nov 1"	""	""	"Unsupervised real-time anomaly detection for streaming data"	"Neurocomputing"	"0925-2312"	"10.1016/j.neucom.2017.04.070"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000407407800011"	""	""	"anomaly detection
hierarchical temporal memory
streaming data
unsupervised learning
concept drift
benchmark dataset"	"We are seeing an enormous increase in the availability of streaming, time-series data. Largely driven by the rise of connected real-time data sources, this data presents technical challenges and opportunities. One fundamental capability for streaming analytics is to model each stream in an unsupervised fashion and detect unusual, anomalous behaviors in real-time. Early anomaly detection is valuable, yet it can be difficult to execute reliably in practice. Application constraints require systems to process data in real-time, not batches. Streaming data inherently exhibits concept drift, favoring algorithms that learn continuously. Furthermore, the massive number of independent streams in practice requires that anomaly detectors be fully automated. In this paper we propose a novel anomaly detection algorithm that meets these constraints. The technique is based on an online sequence memory algorithm called Hierarchical Temporal Memory (HTM). We also present results using the Numenta Anomaly Benchmark (NAB), a benchmark containing real-world data streams with labeled anomalies. The benchmark, the first of its kind, provides a controlled open-source environment for testing anomaly detection algorithms on streaming data. We present results and analysis for a wide range of algorithms on this benchmark, and discuss future challenges for the emerging field of streaming analytics. (C) 2017 The Author(s). Published by Elsevier B.V."	"Sp. Iss. SI
Fd3bf
Times Cited:287
Cited References Count:58"	""	"<Go to ISI>://WOS:000407407800011"	""	"Numenta, Redwood City, CA 94063 USA
Univ Pittsburgh, Dept Comp Sci, Pittsburgh, PA 15260 USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"J. Johnson; A. Alahi; F. F. Li"	"2016"	"Perceptual Losses for Real-Time Style Transfer and Super-Resolution"	""	"Computer Vision - Eccv 2016, Pt Ii"	""	""	"9906"	""	""	"694-711"	""	""	""	""	""	""	""	"Perceptual Losses for Real-Time Style Transfer and Super-Resolution"	"Lect Notes Comput Sc"	"0302-9743"	"10.1007/978-3-319-46475-6_43"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000389383900043"	""	""	"style transfer
super-resolution
deep learning
image superresolution"	"We consider image transformation problems, where an input image is transformed into an output image. Recent methods for such problems typically train feed-forward convolutional neural networks using a per-pixel loss between the output and ground-truth images. Parallel work has shown that high-quality images can be generated by defining and optimizing perceptual loss functions based on high-level features extracted from pretrained networks. We combine the benefits of both approaches, and propose the use of perceptual loss functions for training feed-forward networks for image transformation tasks. We show results on image style transfer, where a feed-forward network is trained to solve the optimization problem proposed by Gatys et al. in real-time. Compared to the optimization-based method, our network gives similar qualitative results but is three orders of magnitude faster. We also experiment with single-image super-resolution, where replacing a per-pixel loss with a perceptual loss gives visually pleasing results."	"Bg5df
Times Cited:1207
Cited References Count:65
Lecture Notes in Computer Science"	""	"<Go to ISI>://WOS:000389383900043"	""	"Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"K. Bonawitz; V. Ivanov; B. Kreuter; A. Marcedone; H. B. McMahan; S. Patel; D. Ramage; A. Segal; K. Seth"	"2017"	"Practical Secure Aggregation for Privacy-Preserving Machine Learning"	""	"Ccs'17: Proceedings of the 2017 Acm Sigsac Conference on Computer and Communications Security"	""	""	""	""	""	"1175-1191"	""	""	""	""	""	""	""	"Practical Secure Aggregation for Privacy-Preserving Machine Learning"	""	""	"10.1145/3133956.3133982"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000440307700074"	""	""	"privacy-preserving protocols
secure aggregation
machine learning
federated learning"	"We design a novel, communication-efficient, failure-robust protocol for secure aggregation of high-dimensional data. Our protocol allows a server to compute the sum of large, user-held data vectors from mobile devices in a secure manner (i.e. without learning each user's individual contribution), and can be used, for example, in a federated learning setting, to aggregate user-provided model updates for a deep neural network. We prove the security of our protocol in the honest-but-curious and active adversary settings, and show that security is maintained even if an arbitrarily chosen subset of users drop out at any time. We evaluate the efficiency of our protocol and show, by complexity analysis and a concrete implementation, that its runtime and communication overhead remain low even on large data sets and client pools. For 16-bit input values, our protocol offers 1.73x communication expansion for 210 users and 220-dimensional vectors, and 1.98x expansion for 214 users and 224-dimensional vectors over sending data in the clear."	"Bk6gz
Times Cited:487
Cited References Count:54"	""	"<Go to ISI>://WOS:000440307700074"	""	"Google, 1600 Amphitheatre Pkwy, Mountain View, CA 94043 USA
Cornell Tech, 2 West Loop Rd, New York, NY 10044 USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"A. Athalye; N. Carlini; D. Wagner"	"2018"	"Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples"	""	"International Conference on Machine Learning, Vol 80"	""	""	"80"	""	""	""	""	""	""	""	""	""	""	"Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples"	"Pr Mach Learn Res"	"2640-3498"	""	""	""	""	""	""	""	""	""	""	""	""	"WOS:000683379200029"	""	""	""	"We identify obfuscated gradients, a kind of gradient masking, as a phenomenon that leads to a false sense of security in defenses against adversarial examples. While defenses that cause obfuscated gradients appear to defeat iterative optimization-based attacks, we find defenses relying on this effect can be circumvented. We describe characteristic behaviors of defenses exhibiting the effect, and for each of the three types of obfuscated gradients we discover, we develop attack techniques to overcome it. In a case study, examining non-certified white-box-secure defenses at ICLR 2018, we find obfuscated gradients are a common occurrence, with 7 of 9 defenses relying on obfuscated gradients. Our new attacks successfully circumvent 6 completely, and 1 partially, in the original threat model each paper considers."	"Bs0mk
Times Cited:442
Cited References Count:31
Proceedings of Machine Learning Research"	""	"<Go to ISI>://WOS:000683379200029"	""	"MIT, Cambridge, MA 02139 USA
Univ Calif Berkeley, Berkeley, CA 94720 USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"L. T. Phong; Y. Aono; T. Hayashi; L. H. Wang; S. Moriai"	"2018"	"Privacy-Preserving Deep Learning via Additively Homomorphic Encryption"	""	"Ieee Transactions on Information Forensics and Security"	""	""	"13"	""	"5"	"1333-1345"	""	""	""	""	"May"	""	""	"Privacy-Preserving Deep Learning via Additively Homomorphic Encryption"	"Ieee T Inf Foren Sec"	"1556-6013"	"10.1109/Tifs.2017.2787987"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000424043800018"	""	""	"privacy
deep learning
neural network
additively homomorphic encryption
lwe-based encryption
paillier encryption"	"We present a privacy-preserving deep learning system in which many learning participants perform neural network-based deep learning over a combined dataset of all, without revealing the participants' local data to a central server. To that end, we revisit the previous work by Shokri and Shmatikov (ACM CCS 2015) and show that, with their method, local data information may be leaked to an honest-but-curious server. We then fix that problem by building an enhanced system with the following properties: 1) no information is leaked to the server and 2) accuracy is kept intact, compared with that of the ordinary deep learning system also over the combined dataset. Our system bridges deep learning and cryptography: we utilize asynchronous stochastic gradient descent as applied to neural networks, in combination with additively homomorphic encryption. We show that our usage of encryption adds tolerable overhead to the ordinary deep learning system."	"Fu7pe
Times Cited:304
Cited References Count:23"	""	"<Go to ISI>://WOS:000424043800018"	""	"Natl Inst Informat & Commun Technol, Tokyo 1848795, Japan
Kobe Univ, Kobe, Hyogo 6578501, Japan"	""	""	""	""	""	""	""	"English"
"Journal Article"	"T. Salimans; I. Goodfellow; W. Zaremba; V. Cheung; A. Radford; X. Chen"	"2016"	"Improved Techniques for Training GANs"	""	"Advances in Neural Information Processing Systems 29 (Nips 2016)"	""	""	"29"	""	""	""	""	""	""	""	""	""	""	"Improved Techniques for Training GANs"	"Adv Neur In"	"1049-5258"	""	""	""	""	""	""	""	""	""	""	""	""	"WOS:000458973700089"	""	""	""	"We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21:3%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes."	"Bm0pg
Times Cited:0
Cited References Count:28
Advances in Neural Information Processing Systems"	""	"<Go to ISI>://WOS:000458973700089"	""	""	""	""	""	""	""	""	""	"English"
"Journal Article"	"R. Shokri; M. Stronati; C. Z. Song; V. Shmatikov"	"2017"	"Membership Inference Attacks Against Machine Learning Models"	""	"2017 Ieee Symposium on Security and Privacy (Sp)"	""	""	""	""	""	"3-18"	""	""	""	""	""	""	""	"Membership Inference Attacks Against Machine Learning Models"	"P Ieee S Secur Priv"	"1081-6011"	"10.1109/Sp.2017.41"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000413081300001"	""	""	"privacy"	"We quantitatively investigate how machine learning models leak information about the individual data records on which they were trained. We focus on the basic membership inference attack: given a data record and black-box access to a model, determine if the record was in the model's training dataset. To perform membership inference against a target model, we make adversarial use of machine learning and train our own inference model to recognize differences in the target model's predictions on the inputs that it trained on versus the inputs that it did not train on.
We empirically evaluate our inference techniques on classification models trained by commercial "machine learning as a service" providers such as Google and Amazon. Using realistic datasets and classification tasks, including a hospital discharge dataset whose membership is sensitive from the privacy perspective, we show that these models can be vulnerable to membership inference attacks. We then investigate the factors that influence this leakage and evaluate mitigation strategies."	"Bi6cu
Times Cited:584
Cited References Count:38
IEEE Symposium on Security and Privacy"	""	"<Go to ISI>://WOS:000413081300001"	""	"Cornell Tech, New York, NY 10044 USA
INRIA, Rocquencourt, France"	""	""	""	""	""	""	""	"English"
"Journal Article"	"M. Sadeghi; E. G. Larsson"	"2019"	"Physical Adversarial Attacks Against End-to-End Autoencoder Communication Systems"	""	"Ieee Communications Letters"	""	""	"23"	""	"5"	"847-850"	""	""	""	""	"May"	""	""	"Physical Adversarial Attacks Against End-to-End Autoencoder Communication Systems"	"Ieee Commun Lett"	"1089-7798"	"10.1109/Lcomm.2019.2901469"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000467552900019"	""	""	"adversarial attacks
autoencoder systems
deep learning
wireless security
end-to-end learning"	"We show that end-to-end learning of communication systems through deep neural network autoencoders can be extremely vulnerable to physical adversarial attacks. Specifically, we elaborate how an attacker can craft effective physical black-box adversarial attacks. Due to the openness (broadcast nature) of the wireless channel, an adversary transmitter can increase the block-error-rate of a communication system by orders of magnitude by transmitting a well-designed perturbation signal over the channel. We reveal that the adversarial attacks are more destructive than the jamming attacks. We also show that classical coding schemes are more robust than the autoencoders against both adversarial and jamming attacks."	"Hx6zl
Times Cited:34
Cited References Count:9"	""	"<Go to ISI>://WOS:000467552900019"	""	"Linkoping Univ, Dept Elect Engn ISY, S-58183 Linkoping, Sweden"	""	""	""	""	""	""	""	"English"
"Journal Article"	"X. Q. Liu; C. J. Hsieh"	"2019"	"Rob-GAN: Generator, Discriminator, and Adversarial Attacker"	""	"2019 Ieee/Cvf Conference on Computer Vision and Pattern Recognition (Cvpr 2019)"	""	""	""	""	""	"11226-11235"	""	""	""	""	""	""	""	"Rob-GAN: Generator, Discriminator, and Adversarial Attacker"	"Proc Cvpr Ieee"	"1063-6919"	"10.1109/Cvpr.2019.01149"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000542649304085"	""	""	""	"We study two important concepts in adversarial deep learning-adversarial training and generative adversarial network (GAN). Adversarial training is the technique used to improve the robustness of discriminator by combining adversarial attacker and discriminator in the training phase. GAN is commonly used for image generation by jointly optimizing discriminator and generator. We show these two concepts are indeed closely related and can be used to strengthen each other-adding a generator to the adversarial training procedure can improve the robustness of discriminators, and adding an adversarial attack to GAN training can improve the convergence speed and lead to better generators. Combining these two insights, we develop a framework called Rob-GAN to jointly optimize generator and discriminator in the presence of adversarial attacks-the generator generates fake images to fool discriminator; the adversarial attacker perturbs real images to fool discriminator, and the discriminator wants to minimize loss under fake and adversarial images. Through this end-to-end training procedure, we are able to simultaneously improve the convergence speed of GAN training, the quality of synthetic images, and the robustness of discriminator under strong adversarial attacks. Experimental results demonstrate that the obtained classifier is more robust than state-of-the-art adversarial training approach [23], and the generator out-performs SN-GAN on ImageNet-143."	"Bp2ib
Times Cited:13
Cited References Count:38
IEEE Conference on Computer Vision and Pattern Recognition"	""	"<Go to ISI>://WOS:000542649304085"	""	"Univ Calif Los Angeles, Los Angeles, CA 90095 USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"W. B. Guo; D. L. Mu; J. Xu; P. R. Su; G. Wang; X. Y. Xing"	"2018"	"LEMNA: Explaining Deep Learning based Security Applications"	""	"Proceedings of the 2018 Acm Sigsac Conference on Computer and Communications Security (Ccs'18)"	""	""	""	""	""	"364-379"	""	""	""	""	""	""	""	"LEMNA: Explaining Deep Learning based Security Applications"	""	""	"10.1145/3243734.3243792"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000461315900024"	""	""	"explainable ai
binary analysis
deep recurrent neural networks"	"While deep learning has shown a great potential in various domains, the lack of transparency has limited its application in security or safety-critical areas. Existing research has attempted to develop explanation techniques to provide interpretable explanations for each classification decision. Unfortunately, current methods are optimized for non-security tasks (e.g., image analysis). Their key assumptions are often violated in security applications, leading to a poor explanation fidelity.
In this paper, we propose LEMNA, a high-fidelity explanation method dedicated for security applications. Given an input data sample, LEMNA generates a small set of interpretable features to explain how the input sample is classified. The core idea is to approximate a local area of the complex deep learning decision boundary using a simple interpretable model. The local interpretable model is specially designed to (1) handle feature dependency to better work with security applications (e.g., binary code analysis); and (2) handle nonlinear local boundaries to boost explanation fidelity. We evaluate our system using two popular deep learning applications in security (a malware classifier, and a function start detector for binary reverse-engineering). Extensive evaluations show that LEMNA's explanation has a much higher fidelity level compared to existing methods. In addition, we demonstrate practical use cases of LEMNA to help machine learning developers to validate model behavior, troubleshoot classification errors, and automatically patch the errors of the target models."	"Bm2qn
Times Cited:65
Cited References Count:75"	""	"<Go to ISI>://WOS:000461315900024"	""	"Penn State Univ, University Pk, PA 16802 USA
JD Secur Res Ctr, State Coll, PA 16801 USA
Virginia Tech, Blacksburg, VA USA
Stevens Inst Technol, Hoboken, NJ 07030 USA
Nanjing Univ, Nanjing, Jiangsu, Peoples R China
Chinese Acad Sci, Beijing, Peoples R China"	""	""	""	""	""	""	""	"English"
"Journal Article"	"S. Y. Khamaiseh; E. Serra; D. X. Xu"	"2020"	"vSwitchGuard: Defending OpenFlow Switches against Saturation Attacks"	""	"2020 Ieee 44th Annual Computers, Software, and Applications Conference (Compsac 2020)"	""	""	""	""	""	"851-860"	""	""	""	""	""	""	""	"vSwitchGuard: Defending OpenFlow Switches against Saturation Attacks"	"P Int Comp Softw App"	"0730-3157"	"10.1109/Compsac48688.2020.0-157"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000629086600112"	""	""	"software-defined networking
openflow
saturation attack
machine learning
dos attacks"	"While the decoupling of control and data planes in software-defined networking (SDN) facilitates orchestrating network traffic, it suffers from security threats. For example, saturation attacks can make SDN out of service by exhausting the controller' and switch's computational resources. The existing research has focused on defense against limited types of saturation attacks. In this paper, we propose vSwitchGuard, a framework for detection and countermeasure of known and unknown saturation attacks in SDN. vSwitchGuard aims to identify the victim switches targeted by known or unknown types of saturation attacks with machine learning classifiers and restore the victim switches to their safe state through deep packet inspection. We have evaluated three supervised classifiers and four semi-supervised classifiers for five types of saturation attacks (TCP-SYN, UDP, ICMP, IP-Spoofing, and TCP-SARFU) and their combinations. The results suggest that supervised and semi-supervised classifiers can be combined to deal with known and unknown attacks for better performance. We have also implemented the countermeasure and evaluated it with all combinations of the five types of attacks. The results demonstrate that vSwitchGuard can effectively defend against the attacks without significant performance overhead."	"Br0hx
Times Cited:4
Cited References Count:17
Proceedings International Computer Software and Applications Conference"	""	"<Go to ISI>://WOS:000629086600112"	""	"Midwestern State Univ, Dept Comp Sci, Wichita Falls, TX 76308 USA
Boise State Univ, Dept Comp Sci, Boise, ID 83725 USA
Univ Missouri, Dept Comp Sci Elect Engn, Kansas City, MO 64110 USA"	""	""	""	""	""	""	""	"English"
"Journal Article"	"A. Abusnaina; A. Khormali; D. Nyang; M. Yuksel; A. Mohaisen"	"2019"	"Examining the Robustness of Learning-Based DDoS Detection in Software Defined Networks"	""	"2019 Ieee Conference on Dependable and Secure Computing (Dsc)"	""	""	""	""	""	"17-24"	""	""	""	""	""	""	""	"Examining the Robustness of Learning-Based DDoS Detection in Software Defined Networks"	""	""	""	""	""	""	""	""	""	""	""	""	""	""	"WOS:000533371800003"	""	""	"intrusion detection systems
deep learning
adversarial machine learning
software defined networking"	"With the rapid development of Software-Defined Networking (SDN) advocating a centralized view of networks, efficient and reliable Distributed Denial of Service (DDoS) defenses are necessary to protect the centralized SDN controller. Recently, an amalgamation of work has realized such defenses using Deep Learning (DL) based algorithms. Although DL-based algorithms are generally prone to adversarial learning attacks, the extent to which those attacks are applicable to DDoS defenses in SDN is unexamined. In this work, we explore the robustness of DL-based DDoS defenses in SDN against adversarial learning attacks. First, we investigate generic off-the-shelf adversarial attacks to test the robustness of DDoS defenses in SDN, and demonstrate that while they lead to misclassification, these attacks do not preserve the characteristics of flows. As a result, we propose Flow-Merge for realistic adversarial flows while achieving a high evasion rate, with both targeted and untargeted misclassification attacks. The proposed Flow-Merge is able to force the DL-based DDoS defenses to misclassify 100% of benign flows as malicious, while preserving original characteristics of flows. Using state-of-the-art defenses, we show that the adversarial flows generated using Flow-Merge are difficult to detect, with only 49.31% detection rate when using adversarial training."	"Bo9yy
Times Cited:3
Cited References Count:27"	""	"<Go to ISI>://WOS:000533371800003"	""	"Univ Cent Florida, Orlando, FL 32816 USA
Inha Univ, Incheon, South Korea"	""	""	""	""	""	""	""	"English"
"Journal Article"	"K. K. Nguyen; D. T. Hoang; D. Niyato; P. Wang; D. Nguyen; E. Dutkiewicz"	"2018"	"Cyberattack Detection in Mobile Cloud Computing: A Deep Learning Approach"	""	"2018 Ieee Wireless Communications and Networking Conference (Wcnc)"	""	""	""	""	""	"1-6"	""	""	""	""	""	""	""	"Cyberattack Detection in Mobile Cloud Computing: A Deep Learning Approach"	"Ieee Wcnc"	"1525-3511"	"10.1109/Wcnc.2018.8376973"	""	""	""	""	""	""	""	""	""	""	""	"WOS:000435542400027"	""	""	"cybersecurity
cyberattack
intrusion detection
mobile cloud
deep learning"	"With the rapid growth of mobile applications and cloud computing, mobile cloud computing has attracted great interest from both academia and industry. However, mobile cloud applications are facing security issues such as data integrity, users' confidentiality, and service availability. A preventive approach to such problems is to detect and isolate cyber threats before they can cause serious impacts to the mobile cloud computing system. In this paper, we propose a novel framework that leverages a deep learning approach to detect cyberattacks in mobile cloud environment. Through experimental results, we show that our proposed framework not only recognizes diverse cyberattacks, but also achieves a high accuracy (up to 97.11%) in detecting the attacks. Furthermore, we present the comparisons with current machine learning-based approaches to demonstrate the effectiveness of our proposed solution."	"Bk3su
Times Cited:37
Cited References Count:22
IEEE Wireless Communications and Networking Conference"	""	"<Go to ISI>://WOS:000435542400027"	""	"Hanoi Univ Sci & Technol, Sch Informat & Commun Technol, Hanoi, Vietnam
Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore
Univ Technol Sydney, Sch Comp & Commun, Sydney, NSW, Australia"	""	""	""	""	""	""	""	"English"
