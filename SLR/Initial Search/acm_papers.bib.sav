% Encoding: UTF-8
@inproceedings{10.1145/3412841.3441892,
author = {Kravchik, Moshe and Biggio, Battista and Shabtai, Asaf},
title = {Poisoning Attacks on Cyber Attack Detectors for Industrial Control Systems},
year = {2021},
isbn = {9781450381048},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3412841.3441892},
doi = {10.1145/3412841.3441892},
abstract = {Recently, neural network (NN)-based methods, including autoencoders, have been proposed
for the detection of cyber attacks targeting industrial control systems (ICSs). Such
detectors are often retrained, using data collected during system operation, to cope
with the natural evolution (i.e., concept drift) of the monitored signals. However,
by exploiting this mechanism, an attacker can fake the signals provided by corrupted
sensors at training time and poison the learning process of the detector such that
cyber attacks go undetected at test time. With this research, we are the first to
demonstrate such poisoning attacks on ICS cyber attack online NN detectors. We propose
two distinct attack algorithms, namely, interpolation- and back-gradient based poisoning,
and demonstrate their effectiveness on both synthetic and real-world ICS data. We
also discuss and analyze some potential mitigation strategies.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on Applied Computing},
pages = {116–125},
numpages = {10},
keywords = {adversarial machine learning, autoencoders, adversarial robustness, industrial control systems, anomaly detection, poisoning attacks},
location = {Virtual Event, Republic of Korea},
series = {SAC '21}
}

@inproceedings{10.1145/3320269.3384715,
author = {Chan, Patrick P. K. and Wang, Yaxuan and Yeung, Daniel S.},
title = {Adversarial Attack against Deep Reinforcement Learning with Static Reward Impact Map},
year = {2020},
isbn = {9781450367509},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3320269.3384715},
doi = {10.1145/3320269.3384715},
abstract = {Security problems of deep reinforcement learning draw much attention recently. Previous
works on adversary attack mainly focus on preventing the targeted agent from choosing
the most desirable action at each step, which may not reduce the cumulative reward
effectively. In this paper, we first investigate how changing features affect the
cumulative reward achieved by an agent. The static reward impact map is introduced
to quantify the influence on the reward of each feature experimentally. By focusing
on tasks with the static reward impact map, an adversarial attack method against deep
reinforcement learning aiming to minimize the cumulative reward is proposed. Features
with the large reward impact are perturbed in crafting an adversarial sample. Deep
Q-network is selected to demonstrate the performance of our attack method in the experiments.
The results indicate that our proposed method achieves better performance than the
existing one-time attack method and the random attack in terms of the cumulative reward
and the successful attack rate under both white-box and black-box settings.},
booktitle = {Proceedings of the 15th ACM Asia Conference on Computer and Communications Security},
pages = {334–343},
numpages = {10},
keywords = {static reward impact map, adversarial attack, reinforcement learning},
location = {Taipei, Taiwan},
series = {ASIA CCS '20}
}

@inproceedings{10.1145/3319535.3354259,
author = {Zhao, Yue and Zhu, Hong and Liang, Ruigang and Shen, Qintao and Zhang, Shengzhi and Chen, Kai},
title = {Seeing Isn't Believing: Towards More Robust Adversarial Attack Against Real World Object Detectors},
year = {2019},
isbn = {9781450367479},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3319535.3354259},
doi = {10.1145/3319535.3354259},
abstract = {Recently Adversarial Examples (AEs) that deceive deep learning models have been a
topic of intense research interest. Compared with the AEs in the digital space, the
physical adversarial attack is considered as a more severe threat to the applications
like face recognition in authentication, objection detection in autonomous driving
cars, etc. In particular, deceiving the object detectors practically, is more challenging
since the relative position between the object and the detector may keep changing.
Existing works attacking object detectors are still very limited in various scenarios,
e.g., varying distance and angles, etc. In this paper, we presented systematic solutions
to build robust and practical AEs against real world object detectors. Particularly,
for Hiding Attack (HA), we proposed thefeature-interference reinforcement (FIR) method
and theenhanced realistic constraints generation (ERG) to enhance robustness, and
for Appearing Attack (AA), we proposed thenested-AE, which combines two AEs together
to attack object detectors in both long and short distance. We also designed diverse
styles of AEs to make AA more surreptitious. Evaluation results show that our AEs
can attack the state-of-the-art real-time object detectors (i.e., YOLO V3 and faster-RCNN)
at the success rate up to 92.4% with varying distance from 1m to 25m and angles from
-60º to 60º. Our AEs are also demonstrated to be highly transferable, capable of attacking
another three state-of-the-art black-box models with high success rate.},
booktitle = {Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1989–2004},
numpages = {16},
keywords = {neural networks, object detectors, physical adversarial attack},
location = {London, United Kingdom},
series = {CCS '19}
}

@inproceedings{10.1145/3366423.3379992,
author = {Zhang, Hengtong and Li, Yaliang and Ding, Bolin and Gao, Jing},
title = {Practical Data Poisoning Attack against Next-Item Recommendation},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3379992},
doi = {10.1145/3366423.3379992},
abstract = {Online recommendation systems make use of a variety of information sources to provide
users the items that users are potentially interested in. However, due to the openness
of the online platform, recommendation systems are vulnerable to data poisoning attacks.
Existing attack approaches are either based on simple heuristic rules or designed
against specific recommendations approaches. The former often suffers unsatisfactory
performance, while the latter requires strong knowledge of the target system. In this
paper, we focus on a general next-item recommendation setting and propose a practical
poisoning attack approach named LOKI against blackbox recommendation systems. The
proposed LOKI utilizes the reinforcement learning algorithm to train the attack agent,
which can be used to generate user behavior samples for data poisoning. In real-world
recommendation systems, the cost of retraining recommendation models is high, and
the interaction frequency between users and a recommendation system is restricted.
Given these real-world restrictions, we propose to let the agent interact with a recommender
simulator instead of the target recommendation system and leverage the transferability
of the generated adversarial samples to poison the target system. We also propose
to use the influence function to efficiently estimate the influence of injected samples
on the recommendation results, without re-training the models within the simulator.
Extensive experiments on two datasets against four representative recommendation models
show that the proposed LOKI achieves better attacking performance than existing methods.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {2458–2464},
numpages = {7},
keywords = {Data Poisoning, Recommendation System, Adversarial Learning},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/3055378.3055382,
author = {Humayed, Abdulmalik and Luo, Bo},
title = {Using ID-Hopping to Defend Against Targeted DoS on CAN},
year = {2017},
isbn = {9781450349765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3055378.3055382},
doi = {10.1145/3055378.3055382},
abstract = {With the exponential growth of automotive security research, new security vulnerabilities
and attacks have been revealed and new challenges have emerged. In recent years, various
attacks ranging from replay attacks, through false information injection, to Denial
of Service (DoS), have shown how fragile automotive security is. As a result, a number
of security solutions have been proposed that rely on techniques like encryption and
firewalls. However, most proposals require performance and computational overheads
that would become an additional burden rather than a solution. In this paper, we propose
a new automotive network algorithm, called ID-Hopping, that aims to prevent targeted
DoS attacks in which attackers target certain functions by injecting special frames
that would prevent a car's normal operations. We aim to raise the bar for attackers
by randomizing the expected patterns in the automotive network. Such randomization
hinders the attacker's ability to launch targeted DoS attacks. We built a testing
platform and implemented the randomization mechanism to evaluate the algorithm's effectiveness.
Based on the evaluation, the algorithm holds a promising solution for targeted DoS,
and even reverse engineering, which automotive networks are most vulnerable to.},
booktitle = {Proceedings of the 1st International Workshop on Safe Control of Connected and Autonomous Vehicles},
pages = {19–26},
numpages = {8},
keywords = {DoS, Alternative IDs, CAN, ID-Hopping, Smart Cars, Original IDs, Denial of Service, Security},
location = {Pittsburgh, PA, USA},
series = {SCAV'17}
}

@InProceedings{10.1145/3427228.3427230,
  author    = {Rosenberg, Ishai and Shabtai, Asaf and Elovici, Yuval and Rokach, Lior},
  booktitle = {Annual Computer Security Applications Conference},
  title     = {Query-Efficient Black-Box Attack Against Sequence-Based Malware Classifiers},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {611–626},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '20},
  abstract  = {In this paper, we present a generic, query-efficient black-box attack against API
call-based machine learning malware classifiers. We generate adversarial examples
by modifying the malware’s API call sequences and non-sequential features (printable
strings), and these adversarial examples will be misclassified by the target malware
classifier without affecting the malware’s functionality. In contrast to previous
studies, our attack minimizes the number of malware classifier queries required. In
addition, in our attack, the attacker must only know the class predicted by the malware
classifier; attacker knowledge of the malware classifier’s confidence score is optional.
We evaluate the attack effectiveness when attacks are performed against a variety
of malware classifier architectures, including recurrent neural network (RNN) variants,
deep neural networks, support vector machines, and gradient boosted decision trees.
Our attack success rate is around 98% when the classifier’s confidence score is known
and 64% when just the classifier’s predicted class is known. We implement four state-of-the-art
query-efficient attacks and show that our attack requires fewer queries and less knowledge
about the attacked model’s architecture than other existing query-efficient attacks,
making it practical for attacking cloud-based malware classifiers at a minimal cost.},
  doi       = {10.1145/3427228.3427230},
  isbn      = {9781450388580},
  keywords  = {Score-Based Attack, Malware Classification, Recurrent Neural Networks, Adversarial Example, Decision-Based Attack, Machine Learning as a Service},
  location  = {Austin, USA},
  numpages  = {16},
  url       = {https://doi.org/10.1145/3427228.3427230},
}

@inproceedings{10.1145/3368926.3369683,
author = {Toan, Tran Viet and Nishikawa, Rin and Thanh, Le Tien and Takemoto, Masashi and Van Hoai, Tran and Binh, Huynh Thi Thanh and Nakajo, Hironori},
title = {Cow Estrus Detection with Low-Frequency Accelerometer Sensor by Unsupervised Learning},
year = {2019},
isbn = {9781450372459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368926.3369683},
doi = {10.1145/3368926.3369683},
abstract = {In recent years, Internet of Things (IoT) and Machine Learning (ML) has been applied
successfully in agriculture. These technologies increase productivity as well as reduce
labor significantly. In this paper, we focus on improving the autonomous cow estrus
detection system in terms of energy consumption and precision. In previous detection
pipelines, an accelerometer is mounted to the neck of cows to capture motion data
with high frequency, followed by the ML algorithm to check the data and determine
whether it is in estrus or not. Instead, we configured the accelerometer to sample
with low frequency for minimizing its energy consumption. However, low-sampling rate
as input of ML pipeline leads to an undesirable higher false alarm rate. To solve
this problems, we designed a pipeline of unsupervised learning with a new heuristic
post-processing algorithm. The proposed post-processing algorithm is a backtracking
algorithm that incorporates the timing constraint of the period obtained by agriculture
knowledge. With the constraint, the post-processing algorithm facilitates a significantly
higher precision than simple adaptive threshold techniques in previous studies on
a simulated dataset. Finally, the overall result of the pipeline with the proposed
algorithm is visualized on real-world data captured on the farm in our agriculture
department.},
booktitle = {Proceedings of the Tenth International Symposium on Information and Communication Technology},
pages = {342–349},
numpages = {8},
keywords = {internet of things, unsupervised learning, estrus detection},
location = {Hanoi, Ha Long Bay, Viet Nam},
series = {SoICT 2019}
}

@inproceedings{10.1145/3366423.3380166,
author = {Tian, Sheng and Xiong, Tao},
title = {A Generic Solver Combining Unsupervised Learning and Representation Learning for Breaking Text-Based Captchas},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380166},
doi = {10.1145/3366423.3380166},
abstract = {Although there are many alternative captcha schemes available, text-based captchas
are still one of the most popular security mechanism to maintain Internet security
and prevent malicious attacks, due to the user preferences and ease of design. Over
the past decade, different methods of breaking captchas have been proposed, which
helps captcha keep evolving and become more robust. However, these previous works
generally require heavy expert involvement and gradually become ineffective with the
introduction of new security features. This paper proposes a generic solver combining
unsupervised learning and representation learning to automatically remove the noisy
background of captchas and solve text-based captchas. We introduce a new training
scheme for constructing mini-batches, which contain a large number of unlabeled hard
examples, to improve the efficiency of representation learning. Unlike existing deep
learning algorithms, our method requires significantly fewer labeled samples and surpasses
the recognition performance of a fully-supervised model with the same network architecture.
Moreover, extensive experiments show that the proposed method outperforms state-of-the-art
by delivering a higher accuracy on various captcha schemes. We provide further discussions
of potential applications of the proposed unified framework. We hope that our work
can inspire the community to enhance the security of text-based captchas.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {860–871},
numpages = {12},
keywords = {representation Learning, text-based captchas, unsupervised learning, Internet security},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/3240508.3240603,
author = {Yin, Minghao and Zhang, Yongbing and Li, Xiu and Wang, Shiqi},
title = {When Deep Fool Meets Deep Prior: Adversarial Attack on Super-Resolution Network},
year = {2018},
isbn = {9781450356657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3240508.3240603},
doi = {10.1145/3240508.3240603},
abstract = {This paper investigates the vulnerability of the deep prior used in deep learning
based image restoration. In particular, the image super-resolution, which relies on
the strong prior information to regularize the solution space and plays important
roles in the image pre-processing for future viewing and analysis, is shown to be
vulnerable to the well-designed adversarial examples. We formulate the adversarial
example generation process as an optimization problem, and given super-resolution
model three different types of attack are designed based on the subsequent tasks:
(i) style transfer attack; (ii) classification attack; (iii) caption attack. Another
interesting property of our design is that the attack is hidden behind the super-resolution
process, such that the utilization of low resolution images is not significantly influenced.
We show that the vulnerability to adversarial examples could bring risks to the pre-processing
modules such as super-resolution deep neural network, which is also of paramount significance
for the security of the whole system. Our results also shed light on the potential
security issues of the pre-processing modules, and raise concerns regarding the corresponding
countermeasures for adversarial examples.},
booktitle = {Proceedings of the 26th ACM International Conference on Multimedia},
pages = {1930–1938},
numpages = {9},
keywords = {style transfer, deep prior, super-resolution, adversarial attack, image classification, caption},
location = {Seoul, Republic of Korea},
series = {MM '18}
}

@inproceedings{10.1145/3098954.3103156,
author = {Frumento, Enrico and Freschi, Federica and Andreoletti, Davide and Consoli, Angelo},
title = {Victim Communication Stack (VCS): A Flexible Model to Select the Human Attack Vector},
year = {2017},
isbn = {9781450352574},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3098954.3103156},
doi = {10.1145/3098954.3103156},
abstract = {Information security has rapidly grown to meet the requirements of today services.
A solid discipline has been developed as far as technical security is concerned. However,
the human layer plays an increasingly decisive role in the managing of Information
Technology (IT) systems. The research field that studies the vulnerabilities of the
human layer is referred to as Social Engineering, and has not received the same attention
of its technical counterpart. We try to partially fill this gap by studying the selection
of the Human Attack Vector (HAV), i.e., the path or the means that the attacker uses
to compromise the human layer. To this aim, we propose a multilayer model, named Victim
Communication Stack (VCS), that provides the key elements to facilitate the choice
of the HAV. This work has been carried out under the DOGANA European project.},
booktitle = {Proceedings of the 12th International Conference on Availability, Reliability and Security},
articleno = {50},
numpages = {6},
keywords = {Human Layer, Security Models, Security, Human Attack Vector, Social Engineering},
location = {Reggio Calabria, Italy},
series = {ARES '17}
}

@inbook{10.1145/3340531.3411884,
author = {Lin, Chen and Chen, Si and Li, Hui and Xiao, Yanghua and Li, Lianyun and Yang, Qian},
title = {Attacking Recommender Systems with Augmented User Profiles},
year = {2020},
isbn = {9781450368599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340531.3411884},
abstract = {Recommendation Systems (RS) have become an essential part of many online services.
Due to its pivotal role in guiding customers towards purchasing, there is a natural
motivation for unscrupulous parties to spoof RS for profits. In this paper, we study
the shilling attack: a subsistent and profitable attack where an adversarial party
injects a number of user profiles to promote or demote a target item. Conventional
shilling attack models are based on simple heuristics that can be easily detected,
or directly adopt adversarial attack methods without a special design for RS. Moreover,
the study on the attack impact on deep learning based RS is missing in the literature,
making the effects of shilling attack against real RS doubtful. We present a novel
Augmented Shilling Attack framework (AUSH) and implement it with the idea of Generative
Adversarial Network. AUSH is capable of tailoring attacks against RS according to
budget and complex attack goals, such as targeting a specific user group. We experimentally
show that the attack impact of AUSH is noticeable on a wide range of RS including
both classic and modern deep learning based RS, while it is virtually undetectable
by the state-of-the-art attack detection model.},
booktitle = {Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management},
pages = {855–864},
numpages = {10}
}

@inproceedings{10.1145/3444370.3444589,
author = {Chen, Jinyin and Zhang, Longyuan and Zheng, Haibin and Xuan, Qi},
title = {SPA: Stealthy Poisoning Attack},
year = {2020},
isbn = {9781450387828},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3444370.3444589},
doi = {10.1145/3444370.3444589},
abstract = {Deep neural networks are susceptible to trojan attacks due to the lack of their interpretability
in training process. The trained models can be purposely polluted by the attackers
using training data with special patterns called trojan triggers, which are also called
poisoned samples. When the model is put in use, the trojan trigger will be stamped
on the testing samples to manipulate the output so as to achieve trojan attack. In
previous work that achieved high attack success rate, the fixed patterns of the trojan
trigger in poisoned samples make them easily detected and eliminated by defense algorithms.
We propose a novel stealthy trojan attack approach called SPA, which exploits the
generative adversarial network to generate poisoned samples and models that can be
triggered by benign samples without trojan triggers. The generated poisoned samples
are stealthy, namely, look natural thus are less likely to be detected easily. Our
experiments have shown that SPA can achieve trojan attack success rate as high as
91.74%, with only 7% poisoned samples in public dataset LFW and CASIA. We have experimented
with a few defense algorithms such as autodecoder defense and DBSCAN cluster detection
and showed the resilience of SPA.},
booktitle = {Proceedings of the 2020 International Conference on Cyberspace Innovation of Advanced Technologies},
pages = {303–309},
numpages = {7},
keywords = {Generative adversarial network, component, Stealthiness, Deep neural networks, Trojan attack},
location = {Guangzhou, China},
series = {CIAT 2020}
}

@inproceedings{10.1145/3372278.3390689,
author = {Chen, Yanjie and Cai, Likun and Cheng, Wei and Wang, Hao},
title = {Super-Resolution Coding Defense Against Adversarial Examples},
year = {2020},
isbn = {9781450370875},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3372278.3390689},
doi = {10.1145/3372278.3390689},
abstract = {Deep neural networks have achieved state-of-the-art performance in many fields including
image classification. However, recent studies show these models are vulnerable to
adversarial examples formed by adding small but intentional perturbations to clean
examples. In this paper, we introduce a significant defense method against adversarial
examples. The key idea is to leverage a super-resolution coding (SR-coding) network
to eliminate noise from adversarial examples. Furthermore, to boost the effect of
defending noise, we propose a novel hybrid approach that incorporates SR-coding and
adversarial training to train robust neural networks. Experiments on benchmark datasets
demonstrate the effectiveness of our method against both the state-of-the-art white-box
attacks and black-box attacks. The proposed approach significantly improves defense
performance and achieves up to 41.26% improvement based on the accuracy by ResNet18
on PGD white-box attack.},
booktitle = {Proceedings of the 2020 International Conference on Multimedia Retrieval},
pages = {189–197},
numpages = {9},
keywords = {adversarial attack, super-resolution, deep learning, generative adversarial network},
location = {Dublin, Ireland},
series = {ICMR '20}
}

@inproceedings{10.1145/3316781.3323470,
author = {Zizzo, Giulio and Hankin, Chris and Maffeis, Sergio and Jones, Kevin},
title = {Adversarial Machine Learning Beyond the Image Domain},
year = {2019},
isbn = {9781450367257},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3316781.3323470},
doi = {10.1145/3316781.3323470},
abstract = {Machine learning systems have had enormous success in a wide range of fields from
computer vision, natural language processing, and anomaly detection. However, such
systems are vulnerable to attackers who can cause deliberate misclassification by
introducing small perturbations. With machine learning systems being proposed for
cyber attack detection such attackers are cause for serious concern. Despite this
the vast majority of adversarial machine learning security research is focused on
the image domain. This work gives a brief overview of adversarial machine learning
and machine learning used in cyber attack detection and suggests key differences between
the traditional image domain of adversarial machine learning and the cyber domain.
Finally we show an adversarial machine learning attack on an industrial control system.},
booktitle = {Proceedings of the 56th Annual Design Automation Conference 2019},
articleno = {176},
numpages = {4},
keywords = {adversarial machine learning, intrusion detection, neural networks},
location = {Las Vegas, NV, USA},
series = {DAC '19}
}

@inproceedings{10.1145/2666652.2666666,
author = {Biggio, Battista and Rieck, Konrad and Ariu, Davide and Wressnegger, Christian and Corona, Igino and Giacinto, Giorgio and Roli, Fabio},
title = {Poisoning Behavioral Malware Clustering},
year = {2014},
isbn = {9781450331531},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2666652.2666666},
doi = {10.1145/2666652.2666666},
abstract = {Clustering algorithms have become a popular tool in computer security to analyze the
behavior of malware variants, identify novel malware families, and generate signatures
for antivirus systems. However, the suitability of clustering algorithms for security-sensitive
settings has been recently questioned by showing that they can be significantly compromised
if an attacker can exercise some control over the input data. In this paper, we revisit
this problem by focusing on behavioral malware clustering approaches, and investigate
whether and to what extent an attacker may be able to subvert these approaches through
a careful injection of samples with poisoning behavior. To this end, we present a
case study on Malheur, an open-source tool for behavioral malware clustering. Our
experiments not only demonstrate that this tool is vulnerable to poisoning attacks,
but also that it can be significantly compromised even if the attacker can only inject
a very small percentage of attacks into the input data. As a remedy, we discuss possible
countermeasures and highlight the need for more secure clustering algorithms.},
booktitle = {Proceedings of the 2014 Workshop on Artificial Intelligent and Security Workshop},
pages = {27–36},
numpages = {10},
keywords = {adversarial machine learning, security evaluation, clustering, unsupervised learning, malware detection, computer security},
location = {Scottsdale, Arizona, USA},
series = {AISec '14}
}

@inproceedings{10.1145/2979779.2979848,
author = {Kumar, Vimal and Kumar, Satish and Gupta, Avadhesh Kumar},
title = {Real-Time Detection of Botnet Behavior in Cloud Using Domain Generation Algorithm},
year = {2016},
isbn = {9781450342131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2979779.2979848},
doi = {10.1145/2979779.2979848},
abstract = {In the last few years, the high acceptability of service computing delivered over
the internet has exponentially created immense security challenges for the services
providers. Cyber criminals are using advanced malware such as polymorphic botnets
for participating in our everyday online activities and trying to access the desired
information in terms of personal details, credit card numbers and banking credentials.
Polymorphic botnet attack is one of the biggest attacks in the history of cybercrime
and currently, millions of computers are infected by the botnet clients over the world.
Botnet attack is an intelligent and highly coordinated distributed attack which consists
of a large number of bots that generates big volumes of spamming e-mails and launching
distributed denial of service (DDoS) attacks on the victim machines in a heterogeneous
network environment. Therefore, it is necessary to detect the malicious bots and prevent
their planned attacks in the cloud environment. A number of techniques have been developed
for detecting the malicious bots in a network in the past literature. This paper recognize
the ineffectiveness exhibited by the singnature based detection technique and networktraffic
based detection such as NetFlow or traffic flow detection and Anomaly based detection.
We proposed a real time malware detection methodology based on Domain Generation Algorithm.
It increasesthe throughput in terms of early detection of malicious bots and high
accuracy of identifying the suspicious behavior.},
booktitle = {Proceedings of the International Conference on Advances in Information Communication Technology &amp; Computing},
articleno = {69},
numpages = {3},
keywords = {Botnet, DGA, Cyber Attack, NetFlow, DNS, C&amp;C Server},
location = {Bikaner, India},
series = {AICTC '16}
}

@inproceedings{10.1145/3394171.3413544,
author = {Wang, Run and Juefei-Xu, Felix and Guo, Qing and Huang, Yihao and Xie, Xiaofei and Ma, Lei and Liu, Yang},
title = {Amora: Black-Box Adversarial Morphing Attack},
year = {2020},
isbn = {9781450379885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394171.3413544},
doi = {10.1145/3394171.3413544},
abstract = {Nowadays, digital facial content manipulation has become ubiquitous and realistic
with the success of generative adversarial networks (GANs), making face recognition
(FR) systems suffer from unprecedented security concerns. In this paper, we investigate
and introduce a new type of adversarial attack to evade FR systems by manipulating
facial content, called adversarial morphing attack (a.k.a. Amora). In contrast to
adversarial noise attack that perturbs pixel intensity values by adding human-imperceptible
noise, our proposed adversarial morphing attack works at the semantic level that perturbs
pixels spatially in a coherent manner. To tackle the black-box attack problem, we
devise a simple yet effective joint dictionary learning pipeline to obtain a proprietary
optical flow field for each attack. Our extensive evaluation on two popular FR systems
demonstrates the effectiveness of our adversarial morphing attack at various levels
of morphing intensity with smiling facial expression manipulations. Both open-set
and closed-set experimental results indicate that a novel black-box adversarial attack
based on local deformation is possible, and is vastly different from additive noise
attacks. The findings of this work potentially pave a new research direction towards
a more thorough understanding and investigation of image-based adversarial attacks
and defenses.},
booktitle = {Proceedings of the 28th ACM International Conference on Multimedia},
pages = {1376–1385},
numpages = {10},
keywords = {black-box adversarial attack, face recognition, morphing},
location = {Seattle, WA, USA},
series = {MM '20}
}

@article{10.1145/3439729,
author = {Deldjoo, Yashar and Noia, Tommaso Di and Merra, Felice Antonio},
title = {A Survey on Adversarial Recommender Systems: From Attack/Defense Strategies to Generative Adversarial Networks},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3439729},
doi = {10.1145/3439729},
abstract = {Latent-factor models (LFM) based on collaborative filtering (CF), such as matrix factorization
(MF) and deep CF methods, are widely used in modern recommender systems (RS) due to
their excellent performance and recommendation accuracy. However, success has been
accompanied with a major new arising challenge: Many applications of machine learning
(ML) are adversarial in nature [146]. In recent years, it has been shown that these
methods are vulnerable to adversarial examples, i.e., subtle but non-random perturbations
designed to force recommendation models to produce erroneous outputs.The goal of this
survey is two-fold: (i) to present recent advances on adversarial machine learning
(AML) for the security of RS (i.e., attacking and defense recommendation models) and
(ii) to show another successful application of AML in generative adversarial networks
(GANs) for generative applications, thanks to their ability for learning (high-dimensional)
data distributions. In this survey, we provide an exhaustive literature review of
76 articles published in major RS and ML journals and conferences. This review serves
as a reference for the RS community working on the security of RS or on generative
models using GANs to improve their quality.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {35},
numpages = {38},
keywords = {Recommender systems, adversarial machine learning, adversarial perturbation, generative adversarial network, robustness, security, min-max game, privacy}
}

@inproceedings{10.1145/3368089.3409754,
author = {Harel-Canada, Fabrice and Wang, Lingxiao and Gulzar, Muhammad Ali and Gu, Quanquan and Kim, Miryung},
title = {Is Neuron Coverage a Meaningful Measure for Testing Deep Neural Networks?},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409754},
doi = {10.1145/3368089.3409754},
abstract = {Recent effort to test deep learning systems has produced an intuitive and compelling
test criterion called neuron coverage (NC), which resembles the notion of traditional
code coverage. NC measures the proportion of neurons activated in a neural network
and it is implicitly assumed that increasing NC improves the quality of a test suite.
In an attempt to automatically generate a test suite that increases NC, we design
a novel diversity promoting regularizer that can be plugged into existing adversarial
attack algorithms. We then assess whether such attempts to increase NC could generate
a test suite that (1) detects adversarial attacks successfully, (2) produces natural
inputs, and (3) is unbiased to particular class predictions. Contrary to expectation,
our extensive evaluation finds that increasing NC actually makes it harder to generate
an effective test suite: higher neuron coverage leads to fewer defects detected, less
natural inputs, and more biased prediction preferences. Our results invoke skepticism
that increasing neuron coverage may not be a meaningful objective for generating tests
for deep neural networks and call for a new test generation technique that considers
defect detection, naturalness, and output impartiality in tandem.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {851–862},
numpages = {12},
keywords = {Adversarial Attack, Machine Learning, Software Engineering, Neuron Coverage, Testing},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@article{10.1145/3051473.3051476,
author = {Hovav, Anat and Han, JinYoung and Kim, Joonghyuk},
title = {Market Reaction to Security Breach Announcements: Evidence from South Korea},
year = {2017},
issue_date = {February 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0095-0033},
url = {https://doi.org/10.1145/3051473.3051476},
doi = {10.1145/3051473.3051476},
abstract = {Event studies have been used to assess the financial impact of cyber incidents on
firms since the methodology is believed to reflect tangible, intangible and potential
gains/losses. While most prior studies examined the impact of security breach announcements
on the United States? market reaction, our study examines the South Korean market's
reaction to similar events. Investor protection theory suggests that different markets
react differently to similar events. Specifically stronger investor protection leads
to lower information asymmetry, which in turn results in a more efficient market valuation.
Korea's investor protection index is lower than that of the U.S., suggesting higher
information asymmetry and less efficient market valuation. Our study found that the
Korean market reaction to cyber incidents was relatively slow, supporting the above
assertion. In addition, regulated industries experienced significant negative abnormal
returns post-2007 when privacy laws were enacted in South Korea. The study also found
that Korea?s market reaction to security incident announcements varied over time as
the nature of cyber attacks and attackers changed. For example, while the negative
market reaction to denial-of-service and corruption of data events were significant
pre-2007, the negative reaction to disclosure of private information was significant
post-2007.},
journal = {SIGMIS Database},
month = feb,
pages = {11–52},
numpages = {42},
keywords = {internet security breaches, cyber attack event study, market reaction}
}

@inproceedings{10.1145/3133956.3134083,
author = {Chen, Yizheng and Nadji, Yacin and Kountouras, Athanasios and Monrose, Fabian and Perdisci, Roberto and Antonakakis, Manos and Vasiloglou, Nikolaos},
title = {Practical Attacks Against Graph-Based Clustering},
year = {2017},
isbn = {9781450349468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3133956.3134083},
doi = {10.1145/3133956.3134083},
abstract = {Graph modeling allows numerous security problems to be tackled in a general way, however,
little work has been done to understand their ability to withstand adversarial attacks.
We design and evaluate two novel graph attacks against a state-of-the-art network-level,
graph-based detection system. Our work highlights areas in adversarial machine learning
that have not yet been addressed, specifically: graph-based clustering techniques,
and a global feature space where realistic attackers without perfect knowledge must
be accounted for (by the defenders) in order to be practical. Even though less informed
attackers can evade graph clustering with low cost, we show that some practical defenses
are possible.},
booktitle = {Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1125–1142},
numpages = {18},
keywords = {dga, unsupervised learning, adversarial machine learning, network security},
location = {Dallas, Texas, USA},
series = {CCS '17}
}

@inproceedings{10.1145/3394171.3413703,
author = {Wang, Lina and Yang, Kang and Wang, Wenqi and Wang, Run and Ye, Aoshuang},
title = {MGAAttack: Toward More Query-Efficient Black-Box Attack by Microbial Genetic Algorithm},
year = {2020},
isbn = {9781450379885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394171.3413703},
doi = {10.1145/3394171.3413703},
abstract = {Recent studies have shown that deep neural networks (DNNs) are susceptible to adversarial
attacks even in the black-box settings. However, previous studies on creating black-box
based adversarial examples by merely solving the traditional continuous problem, which
suffer query efficiency issues. To address the efficiency of querying in black-box
attack, we propose a novel attack, called MGAAttack, which is a query-efficient and
gradient-free black-box attack without obtaining any knowledge of the target model.
In our approach, we leverage the advantages of both transfer-based and scored-based
methods, two typical techniques in black-box attack, and solve a discretized problem
by using a simple yet effective microbial genetic algorithm (MGA). Experimental results
show that our approach dramatically reduces the number of queries on CIFAR-10 and
ImageNet and significantly outperforms previous work. In the untargeted attack, we
can attack a VGG19 classifier with only 16 queries and give an attack success rate
more than 99.90% on ImageNet. Our code is available at https://github.com/kangyangWHU/MGAAttack.},
booktitle = {Proceedings of the 28th ACM International Conference on Multimedia},
pages = {2229–2236},
numpages = {8},
keywords = {microbial genetic algorithm, black-box adversarial attack, deep neural networks},
location = {Seattle, WA, USA},
series = {MM '20}
}

@inproceedings{10.1145/3133956.3134012,
author = {Hitaj, Briland and Ateniese, Giuseppe and Perez-Cruz, Fernando},
title = {Deep Models Under the GAN: Information Leakage from Collaborative Deep Learning},
year = {2017},
isbn = {9781450349468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3133956.3134012},
doi = {10.1145/3133956.3134012},
abstract = {Deep Learning has recently become hugely popular in machine learning for its ability
to solve end-to-end learning systems, in which the features and the classifiers are
learned simultaneously, providing significant improvements in classification accuracy
in the presence of highly-structured and large databases.Its success is due to a combination
of recent algorithmic breakthroughs, increasingly powerful computers, and access to
significant amounts of data.Researchers have also considered privacy implications
of deep learning. Models are typically trained in a centralized manner with all the
data being processed by the same training algorithm. If the data is a collection of
users' private data, including habits, personal pictures, geographical positions,
interests, and more, the centralized server will have access to sensitive information
that could potentially be mishandled. To tackle this problem, collaborative deep learning
models have recently been proposed where parties locally train their deep learning
structures and only share a subset of the parameters in the attempt to keep their
respective training sets private. Parameters can also be obfuscated via differential
privacy (DP) to make information extraction even more challenging, as proposed by
Shokri and Shmatikov at CCS'15.Unfortunately, we show that any privacy-preserving
collaborative deep learning is susceptible to a powerful attack that we devise in
this paper. In particular, we show that a distributed, federated, or decentralized
deep learning approach is fundamentally broken and does not protect the training sets
of honest participants. The attack we developed exploits the real-time nature of the
learning process that allows the adversary to train a Generative Adversarial Network
(GAN) that generates prototypical samples of the targeted training set that was meant
to be private (the samples generated by the GAN are intended to come from the same
distribution as the training data). Interestingly, we show that record-level differential
privacy applied to the shared parameters of the model, as suggested in previous work,
is ineffective (i.e., record-level DP is not designed to address our attack).},
booktitle = {Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
pages = {603–618},
numpages = {16},
keywords = {privacy, security, collaborative learning, deep learning},
location = {Dallas, Texas, USA},
series = {CCS '17}
}

@inproceedings{10.1145/3318216.3363338,
author = {Roy, Abhishek and Chhabra, Anshuman and Kamhoua, Charles A. and Mohapatra, Prasant},
title = {A Moving Target Defense against Adversarial Machine Learning},
year = {2019},
isbn = {9781450367332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318216.3363338},
doi = {10.1145/3318216.3363338},
abstract = {Adversarial Machine Learning has become the latest threat with the ubiquitous presence
of machine learning. In this paper we propose a Moving Target Defense approach to
defend against adversarial machine learning, i.e., instead of manipulating the machine
learning algorithms, we suggest a switching scheme among machine learning algorithms
to defend against adversarial attack. We model the problem as a Stackelberg game between
the attacker and the defender. We propose a switching strategy which is the Stackelberg
equilibrium of the game. We test our method against rational, and boundedly rational
attackers. We show that designing a method against a rational attacker is enough in
most scenarios. We show that even under very harsh constraints, e.g., no attack-cost,
and availability of attacks which can bring down the accuracy to 0, it is possible
to achieve reasonable accuracy in the context of classification. This work shows,
that in addition to switching among algorithms, one can think of introducing randomness
in tuning parameters, and model choices to achieve better defense against adversarial
machine learning.},
booktitle = {Proceedings of the 4th ACM/IEEE Symposium on Edge Computing},
pages = {383–388},
numpages = {6},
keywords = {moving target defense, adversarial machine learning, cybersecurity, bounded rationality},
location = {Arlington, Virginia},
series = {SEC '19}
}

@InProceedings{10.1145/3427228.3427264,
  author    = {Doan, Bao Gia and Abbasnejad, Ehsan and Ranasinghe, Damith C.},
  booktitle = {Annual Computer Security Applications Conference},
  title     = {Februus: Input Purification Defense Against Trojan Attacks on Deep Neural Network Systems},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {897–912},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '20},
  abstract  = {We propose Februus; a new idea to neutralize highly potent and insidious Trojan attacks
on Deep Neural Network (DNN) systems at run-time. In Trojan attacks, an adversary
activates a backdoor crafted in a deep neural network model using a secret trigger,
a Trojan, applied to any input to alter the model’s decision to a target prediction—a
target determined by and only known to the attacker. Februus sanitizes the incoming
input by surgically removing the potential trigger artifacts and restoring the input
for the classification task. Februus enables effective Trojan mitigation by sanitizing
inputs with no loss of performance for sanitized inputs, Trojaned or benign. Our extensive
evaluations on multiple infected models based on four popular datasets across three
contrasting vision applications and trigger types demonstrate the high efficacy of
Februus. We dramatically reduced attack success rates from 100% to near 0% for all
cases (achieving 0% on multiple cases) and evaluated the generalizability of Februus
to defend against complex adaptive attacks; notably, we realized the first defense
against the advanced partial Trojan attack. To the best of our knowledge, Februus
is the first backdoor defense method for operation at run-time capable of sanitizing
Trojaned inputs without requiring anomaly detection methods, model retraining or costly
labeled data.},
  doi       = {10.1145/3427228.3427264},
  isbn      = {9781450388580},
  keywords  = {Trojan attacks on Neural Networks, Backdoor Attack Defenses},
  location  = {Austin, USA},
  numpages  = {16},
  url       = {https://doi.org/10.1145/3427228.3427264},
}

@inproceedings{10.1145/3394171.3413546,
author = {Zhu, Liuwan and Ning, Rui and Wang, Cong and Xin, Chunsheng and Wu, Hongyi},
title = {GangSweep: Sweep out Neural Backdoors by GAN},
year = {2020},
isbn = {9781450379885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394171.3413546},
doi = {10.1145/3394171.3413546},
abstract = {This work proposes GangSweep, a new backdoor detection framework that leverages the
super reconstructive power of Generative Adversarial Networks (GAN) to detect and ''sweep out'' neural backdoors. It is motivated by a series of intriguing empirical
investigations, revealing that the perturbation masks generated by GAN are persistent
and exhibit interesting statistical properties with low shifting variance and large
shifting distance in feature space. Compared with the previous solutions, the proposed
approach eliminates the reliance on the access to training data, and shows a high
degree of robustness and efficiency for detecting and mitigating a wide range of backdoored
models with various settings. Moreover, this is the first work that successfully leverages
generative networks to defend against advanced neural backdoors with multiple triggers
and their polymorphic forms.},
booktitle = {Proceedings of the 28th ACM International Conference on Multimedia},
pages = {3173–3181},
numpages = {9},
keywords = {neural backdoor, model verification, deep neural network},
location = {Seattle, WA, USA},
series = {MM '20}
}

@inproceedings{10.1145/3171592.3171641,
author = {Wen, Senhao and He, Nengqiang and Yan, Hanbing},
title = {Detecting and Predicting APT Based on the Study of Cyber Kill Chain with Hierarchical Knowledge Reasoning},
year = {2017},
isbn = {9781450353663},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3171592.3171641},
doi = {10.1145/3171592.3171641},
abstract = {It has been discovered that quite a few organizations have become the victims of APT,
which is a deliberate and malicious espionage threat to military, political, infrastructure
targets for the purpose of stealing the core data or thwarting the normal operation
of the organizations. Thus, working out a solution for detecting and predicting APT
is a major goal for scientific research. But APT has a characteristic feature of good
concealment which prevent we capturing it just in time by existing solutions. In this
paper, through a deep study of Cyber Kill Chain, we proposed a solution to detect
and predict APTs with hierarchical Knowledge reasoning on the basis of cyber-security-monitoring,
intelligence-gathering, etc. The solution seeks for connections between real-time
alarms and the intelligence from Hacker Profile, Cyber Resources Profile, Social Engineering
Database, Cyber Attack Tool Fingerprint Database, Vulnerability Database, Malicious
Code Genome Map, etc. According to our experiments, it is effective and has high accuracy.},
booktitle = {Proceedings of the 2017 VI International Conference on Network, Communication and Computing},
pages = {115–119},
numpages = {5},
keywords = {Cyber Kill Chain, knowledge-based, APT},
location = {Kunming, China},
series = {ICNCC 2017}
}

@inproceedings{10.1145/3324921.3328789,
author = {Doshi, Keval and Mozaffari, Mahsa and Yilmaz, Yasin},
title = {RAPID: Real-Time Anomaly-Based Preventive Intrusion Detection},
year = {2019},
isbn = {9781450367691},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3324921.3328789},
doi = {10.1145/3324921.3328789},
abstract = {Intrusion detection systems (IDSs) today face key limitations with respect to detection
and prevention of challenging IoT-empowered attacks. We address these limitations
by proposing a novel IDS called RAPID, which is based on an online scalable anomaly
detection and localization approach. We show that the anomaly detection algorithm
is asymptotically optimal under certain conditions, and comprehensively analyze its
computational complexity. Considering a real dataset and an IoT testbed we demonstrate
the use of RAPID in two different IoT-empowered cyber-attack scenarios, namely high-rate
DDoS attacks and low-rate DDoS attacks. The experiment results show the quick and
accurate detection and prevention performance of the proposed IDS.},
booktitle = {Proceedings of the ACM Workshop on Wireless Security and Machine Learning},
pages = {49–54},
numpages = {6},
keywords = {nonparametric method, sequential detection, IoT networks, anomaly detection, DDoS attacks},
location = {Miami, FL, USA},
series = {WiseML 2019}
}

@article{10.1145/3453158,
author = {Rosenberg, Ishai and Shabtai, Asaf and Elovici, Yuval and Rokach, Lior},
title = {Adversarial Machine Learning Attacks and Defense Methods in the Cyber Security Domain},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3453158},
doi = {10.1145/3453158},
abstract = {In recent years, machine learning algorithms, and more specifically deep learning
algorithms, have been widely used in many fields, including cyber security. However,
machine learning systems are vulnerable to adversarial attacks, and this limits the
application of machine learning, especially in non-stationary, adversarial environments,
such as the cyber security domain, where actual adversaries (e.g., malware developers)
exist. This article comprehensively summarizes the latest research on adversarial
attacks against security solutions based on machine learning techniques and illuminates
the risks they pose. First, the adversarial attack methods are characterized based
on their stage of occurrence, and the attacker’ s goals and capabilities. Then, we
categorize the applications of adversarial attack and defense methods in the cyber
security domain. Finally, we highlight some characteristics identified in recent research
and discuss the impact of recent advancements in other adversarial learning domains
on future research directions in the cyber security domain. To the best of our knowledge,
this work is the first to discuss the unique challenges of implementing end-to-end
adversarial attacks in the cyber security domain, map them in a unified taxonomy,
and use the taxonomy to highlight future research directions.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {108},
numpages = {36},
keywords = {adversarial examples, poisoning attacks, adversarial machine learning, cyber security, Adversarial learning, deep learning, evasion attacks}
}

@inproceedings{10.1145/3327962.3331456,
author = {Zhang, Jiajie and Zhang, Bingsheng and Zhang, Bincheng},
title = {Defending Adversarial Attacks on Cloud-Aided Automatic Speech Recognition Systems},
year = {2019},
isbn = {9781450367882},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3327962.3331456},
doi = {10.1145/3327962.3331456},
abstract = {With the advancement of deep learning based speech recognition technology, an increasing
number of cloud-aided automatic voice assistant applications, such as Google Home,
Amazon Echo, and cloud AI services, such as IBM Watson, are emerging in our daily
life. In a typical usage scenario, after keyword activation, the user's voice will
be recorded and submitted to the cloud for automatic speech recognition (ASR) and
then further action(s) might be triggered depending on the user's command(s). However,
recent researches show that the deep learning based systems could be easily attacked
by adversarial examples. Subsequently, the ASR systems are found being vulnerable
to audio adversarial examples. Unfortunately, very few works about defending audio
adversarial attack are known in the literature. Constructing a generic and robust
defense mechanism to resolve this issue remains an open problem. In this work, we
propose several proactive defense mechanisms against targeted audio adversarial examples
in the ASR systems via code modulation and audio compression. We then show the effectiveness
of the proposed strategies through extensive evaluation on natural dataset.},
booktitle = {Proceedings of the Seventh International Workshop on Security in Cloud Computing},
pages = {23–31},
numpages = {9},
keywords = {adversarial examples, cloud-aided speech recognition, deep learning},
location = {Auckland, New Zealand},
series = {SCC '19}
}

@inproceedings{10.1145/3395352.3402618,
author = {Shu, Dule and Leslie, Nandi O. and Kamhoua, Charles A. and Tucker, Conrad S.},
title = {Generative Adversarial Attacks against Intrusion Detection Systems Using Active Learning},
year = {2020},
isbn = {9781450380072},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3395352.3402618},
doi = {10.1145/3395352.3402618},
abstract = {Intrusion Detection Systems (IDS) are increasingly adopting machine learning (ML)-based
approaches to detect threats in computer networks due to their ability to learn underlying
threat patterns/features. However, ML-based models are susceptible to adversarial
attacks, attacks wherein slight perturbations of the input features, cause misclassifications.
We propose a method that uses active learning and generative adversarial networks
to evaluate the threat of adversarial attacks on ML-based IDS. Existing adversarial
attack methods require a large amount of training data or assume knowledge of the
IDS model itself (e.g., loss function), which may not be possible in real-world settings.
Our method overcomes these limitations by demonstrating the ability to compromise
an IDS using limited training data and assuming no prior knowledge of the IDS model
other than its binary classification (i.e., benign or malicious). Experimental results
demonstrate the ability of our proposed model to achieve a 98.86% success rate in
bypassing the IDS model using only 25 labeled data points during model training. The
knowledge gained by compromising the ML-based IDS, can be integrated into the IDS
in order to enhance its robustness against similar ML-based adversarial attacks.},
booktitle = {Proceedings of the 2nd ACM Workshop on Wireless Security and Machine Learning},
pages = {1–6},
numpages = {6},
keywords = {active learning, intrusion detection, neural networks},
location = {Linz, Austria},
series = {WiseML '20}
}

@inproceedings{10.1145/2947626.2951954,
author = {Basan, Alexander and Basan, Elena and Makarevich, Oleg},
title = {Development of the Hierarchal Trust Management System for Mobile Cluster-Based Wireless Sensor Network},
year = {2016},
isbn = {9781450347648},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2947626.2951954},
doi = {10.1145/2947626.2951954},
abstract = {In this paper a model of secure wireless sensor network (WSN) was developed. This
model is able to defend against most of known network attacks and don't significantly
reduce the energy power of sensor nodes (SN). We propose clustering as a way of network
organization, which allows reducing energy consumption. Network protection is based
on the trust level calculation and the establishment of trusted relationships between
trusted nodes. The primary purpose of the hierarchical trust management system (HTMS)
is to protect the WSN from malicious actions of an attacker. The developed system
should combine the properties of energy efficiency and reliability. To achieve this
goal the following tasks are performed: detection of illegal actions of an intruder;
blocking of malicious nodes; avoiding of malicious attacks; determining the authenticity
of nodes; the establishment of trusted connections between authentic nodes; detection
of defective nodes and the blocking of their work. The HTMS operation based on the
use of Bayes' theorem and calculation of direct and centralized trust values.},
booktitle = {Proceedings of the 9th International Conference on Security of Information and Networks},
pages = {116–122},
numpages = {7},
keywords = {clustering, authenticity, Wireless sensor networks, attacks, trust, intrusion detection, anomaly detection},
location = {Newark, NJ, USA},
series = {SIN '16}
}

@inproceedings{10.1145/3453688.3461751,
author = {Zhang, Jiliang and Hou, Junjie},
title = {Unpaired Image-to-Image Translation Network for Semantic-Based Face Adversarial Examples Generation},
year = {2021},
isbn = {9781450383936},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3453688.3461751},
doi = {10.1145/3453688.3461751},
abstract = {Recent studies have shown that neural networks are vulnerable to adversarial example
(AE) attacks. However, the existing AE generation techniques restrict the pixel perturbation
to improve imperceptibility, resulting in low attack success rates. Although increasing
perturbations can improve the attack success rate, the imperceptibility of AEs will
be reduced. In order to mitigate this contradiction, we propose a new attack method,
named AttAdvGAN, which uses adversarial-consistency loss for unpaired image-to-image
translation to generate semantic-based AEs for faces, encouraging the generated image
contains important features of the original image and hiding adversarial perturbations
into shared feature in the target domain. Experiment results show that the proposed
approach can generate imperceptible face AEs on the CelebA dataset with high attack
success rate in fooling the state-of-the-art face recognition model. In addition,
our proposed method can also be used for facial privacy protection.},
booktitle = {Proceedings of the 2021 on Great Lakes Symposium on VLSI},
pages = {449–454},
numpages = {6},
keywords = {face recognition, adversarial examples, neural networks},
location = {Virtual Event, USA},
series = {GLSVLSI '21}
}

@inproceedings{10.1145/3372297.3417238,
author = {Chen, Dingfan and Yu, Ning and Zhang, Yang and Fritz, Mario},
title = {GAN-Leaks: A Taxonomy of Membership Inference Attacks against Generative Models},
year = {2020},
isbn = {9781450370899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3372297.3417238},
doi = {10.1145/3372297.3417238},
abstract = {Deep learning has achieved overwhelming success, spanning from discriminative models
to generative models. In particular, deep generative models have facilitated a new
level of performance in a myriad of areas, ranging from media manipulation to sanitized
dataset generation. Despite the great success, the potential risks of privacy breach
caused by generative models have not been analyzed systematically. In this paper,
we focus on membership inference attack against deep generative models that reveals
information about the training data used for victim models. Specifically, we present
the first taxonomy of membership inference attacks, encompassing not only existing
attacks but also our novel ones. In addition, we propose the first generic attack
model that can be instantiated in a large range of settings and is applicable to various
kinds of deep generative models. Moreover, we provide a theoretically grounded attack
calibration technique, which consistently boosts the attack performance in all cases,
across different attack settings, data modalities, and training configurations. We
complement the systematic analysis of attack performance by a comprehensive experimental
study, that investigates the effectiveness of various attacks w.r.t. model type and
training configurations, over three diverse application scenarios (i.e., images, medical
data, and location data).},
booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
pages = {343–362},
numpages = {20},
keywords = {privacy-preserving, membership inference attacks, deep learning, machine learning, generative models},
location = {Virtual Event, USA},
series = {CCS '20}
}

@inproceedings{10.1145/3240765.3243493,
author = {Liu, Yanqi and Costantini, Alessandro and Bahar, R. Iris and Sui, Zhiqiang and Ye, Zhefan and Lu, Shiyang and Jenkins, Odest Chadwicke},
title = {Robust Object Estimation Using Generative-Discriminative Inference for Secure Robotics Applications},
year = {2018},
isbn = {9781450359504},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3240765.3243493},
doi = {10.1145/3240765.3243493},
abstract = {Convolutional neural networks (CNNs) are of increasing widespread use in robotics,
especially for object recognition. However, such CNNs still lack several critical
properties necessary for robots to properly perceive and function autonomously in
uncertain, and potentially adversarial, environments. In this paper, we investigate
factors for accurate, reliable, and resource-efficient object and pose recognition
suitable for robotic manipulation in adversarial clutter. Our exploration is in the
context of a three-stage pipeline of discriminative CNN-based recognition, generative
probabilistic estimation, and robot manipulation. This pipeline proposes using a SAmpling
Network Density filter, or SAND filter, to recover from potentially erroneous decisions
produced by a CNN through generative probabilistic inference. We present experimental
results from SAND filter perception for robotic manipulation in tabletop scenes with
both benign and adversarial clutter. These experiments vary CNN model complexity for
object recognition and evaluate levels of inaccuracy that can be recovered by generative
pose inference. This scenario is extended to consider adversarial environmental modifications
with varied lighting, occlusions, and surface modifications.},
booktitle = {Proceedings of the International Conference on Computer-Aided Design},
articleno = {75},
numpages = {8},
keywords = {robot perception, DNN adversarial attack, robust machine learning},
location = {San Diego, California},
series = {ICCAD '18}
}

@inproceedings{10.1145/3374135.3385282,
author = {Phillips, Brandon and Gamess, Eric and Krishnaprasad, Sri},
title = {An Evaluation of Machine Learning-Based Anomaly Detection in a SCADA System Using the Modbus Protocol},
year = {2020},
isbn = {9781450371056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3374135.3385282},
doi = {10.1145/3374135.3385282},
abstract = {Supervisory Control and Data Acquisition (SCADA) systems have been designed with the
assumption that the system would run within a closed environment. They have only generated
concerns for security issues that may appear during system deployment, and there are
no clear methods to assess security threats when considered. Recent technological
and economic trends have driven SCADA systems from serial communication networks to
networks based on TCP/IP. This exposes legacy SCADA systems to new security threats
they were not designed to defend against. This work examines the viability of machine
learning techniques in detecting new security threats specific to SCADA systems and
the Modbus protocol. Machine learning-based anomaly detection algorithms were used
to detect malicious traffic in a generated dataset of Remote Terminal Unit (RTU) communications
using the Modbus protocol. The implemented algorithms are Support Vector Machines,
decision trees, k-nearest neighbors, and k-means clustering. While the algorithms
performed well overall, Support Vector Machine, Decision Trees, and K-nearest Neighbors
algorithms had the best performance with individual attack types. K-means clustering
did not perform satisfactorily with specific attack types.},
booktitle = {Proceedings of the 2020 ACM Southeast Conference},
pages = {188–196},
numpages = {9},
keywords = {SCADA, Industrial Control Systems, Anomaly Detection, Modbus, Machine Learning},
location = {Tampa, FL, USA},
series = {ACM SE '20}
}

@inproceedings{10.1145/3338501.3357365,
author = {Alperin, Kenneth and Wollaber, Allan and Ross, Dennis and Trepagnier, Pierre and Leonard, Leslie},
title = {Risk Prioritization by Leveraging Latent Vulnerability Features in a Contested Environment},
year = {2019},
isbn = {9781450368339},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338501.3357365},
doi = {10.1145/3338501.3357365},
abstract = {Cyber network defenders face an overwhelming volume of software vulnerabilities. Resource
limitations preclude them mitigating all but a small number of vulnerabilities on
an enterprise network, so proper prioritization of defensive actions are of paramount
importance. Current methods of risk prioritization are predominantly expert-based,
and many include leveraging Common Vulnerability Scoring System (CVSS) risk scores.
These scores are assigned by subject matter experts according to conventional methods
of qualifying risk. Vulnerability mitigation strategies are then often applied in
CVSS score order. Our vulnerability assessment system, in contrast, takes a predominantly
data-driven approach. In general, we associate a risk metric of vulnerabilities with
existence of corresponding exploits. Our assumption is that if an entity has invested
time and money to exploit a particular vulnerability, this is a critical gauge of
that vulnerability's importance, and hence risk.Prior work presented a model that
allows for the creation of prioritized vulnerabilities based on their association-likelihood
with exploits, outperforming then-current methods. Because the initial approach only
leveraged one vulnerability feature, we extended the vulnerability feature space by
incorporating additional features derived from natural language processing. The importance
metric is still given by a vulnerability-exploit relationship, but by processing text
descriptions and other available information, our system became significantly more
accurate and predictive. We next propose a mechanism that customizes vulnerability
risks according to their exploitation likelihood in a contested environment given
site-specific threat intelligence information, namely, attacks by an Advanced Persistent
Threat (APT) group. Utilizing held-back data, we then demonstrate that latently similar
vulnerabilities, which could be targeted by the same adversary, see higher risk ratings.},
booktitle = {Proceedings of the 12th ACM Workshop on Artificial Intelligence and Security},
pages = {49–57},
numpages = {9},
keywords = {natural language processing, exploit, risk model, vulnerability, machine learning},
location = {London, United Kingdom},
series = {AISec'19}
}

@inproceedings{10.1145/3411495.3421359,
author = {Zhang, Chaoyun and Costa-Perez, Xavier and Patras, Paul},
title = {Tiki-Taka: Attacking and Defending Deep Learning-Based Intrusion Detection Systems},
year = {2020},
isbn = {9781450380843},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411495.3421359},
doi = {10.1145/3411495.3421359},
abstract = {Neural networks are increasingly important in the development of Network Intrusion
Detection Systems (NIDS), as they have the potential to achieve high detection accuracy
while requiring limited feature engineering. Deep learning-based detectors can be
however vulnerable to adversarial examples, by which attackers that may be oblivious
to the precise mechanics of the targeted NIDS add subtle perturbations to malicious
traffic features, with the aim of evading detection and disrupting critical systems
in a cost-effective manner. Defending against such adversarial attacks is therefore
of high importance, but requires to address daunting challenges.In this paper, we
introduce Tiki-Taka, a general framework for (i) assessing the robustness of state-of-the-art
deep learning-based NIDS against adversarial manipulations, and which (ii) incorporates
our proposed defense mechanisms to increase the NIDS' resistance to attacks employing
such evasion techniques. Specifically, we select five different cutting-edge adversarial
attack mechanisms to subvert three popular malicious traffic detectors that employ
neural networks. We experiment with a publicly available dataset and consider both
one-to-all and one-to-one classification scenarios, i.e., discriminating illicit vs
benign traffic and respectively identifying specific types of anomalous traffic among
many observed. The results obtained reveal that, under realistic constraints, attackers
can evade NIDS with up to 35.7% success rates, by only altering time-based features
of the traffic generated. To counteract these weaknesses, we propose three defense
mechanisms, namely: model voting ensembling, ensembling adversarial training, and
query detection. To the best of our knowledge, our work is the first to propose defenses
against adversarial attacks targeting NIDS. We demonstrate that when employing the
proposed methods, intrusion detection rates can be improved to nearly 100% against
most types of malicious traffic, and attacks with potentially catastrophic consequences
(e.g., botnet) can be thwarted. This confirms the effectiveness of our solutions and
makes the case for their adoption when designing robust and reliable deep anomaly
detectors.},
booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Cloud Computing Security Workshop},
pages = {27–39},
numpages = {13},
keywords = {network intrusion detection systems, deep learning, adversarial attacks},
location = {Virtual Event, USA},
series = {CCSW'20}
}

@inproceedings{10.1145/3394171.3413906,
author = {Zhang, Jiaming and Sang, Jitao and Zhao, Xian and Huang, Xiaowen and Sun, Yanfeng and Hu, Yongli},
title = {Adversarial Privacy-Preserving Filter},
year = {2020},
isbn = {9781450379885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394171.3413906},
doi = {10.1145/3394171.3413906},
abstract = {While widely adopted in practical applications, face recognition has been critically
discussed regarding the malicious use of face images and the potential privacy problems,
e.g., deceiving payment system and causing personal sabotage. Online photo sharing
services unintentionally act as the main repository for malicious crawler and face
recognition applications. This work aims to develop a privacy-preserving solution,
called Adversarial Privacy-preserving Filter (APF), to protect the online shared face
images from being maliciously used. We propose an end-cloud collaborated adversarial
attack solution to satisfy requirements of privacy, utility and non-accessibility.
Specifically, the solutions consist of three modules: (1) image-specific gradient
generation, to extract image-specific gradient in the user end with a compressed probe
model; (2) adversarial gradient transfer, to fine-tune the image-specific gradient
in the server cloud; and (3) universal adversarial perturbation enhancement, to append
image-independent perturbation to derive the final adversarial noise. Extensive experiments
on three datasets validate the effectiveness and efficiency of the proposed solution.
A prototype application is also released for further evaluation. We hope the end-cloud
collaborated attack framework could shed light on addressing the issue of online multimedia
sharing privacy-preserving issues from user side.},
booktitle = {Proceedings of the 28th ACM International Conference on Multimedia},
pages = {1423–1431},
numpages = {9},
keywords = {face recognition, adversarial example, privacy-preserving, photo sharing},
location = {Seattle, WA, USA},
series = {MM '20}
}

@inproceedings{10.1145/3450569.3463560,
author = {Zhang, Zaixi and Jia, Jinyuan and Wang, Binghui and Gong, Neil Zhenqiang},
title = {Backdoor Attacks to Graph Neural Networks},
year = {2021},
isbn = {9781450383653},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3450569.3463560},
doi = {10.1145/3450569.3463560},
abstract = {In this work, we propose the first backdoor attack to graph neural networks (GNN).
Specifically, we propose a subgraph based backdoor attack to GNN for graph classification.
In our backdoor attack, a GNN classifier predicts an attacker-chosen target label
for a testing graph once a predefined subgraph is injected to the testing graph. Our
empirical results on three real-world graph datasets show that our backdoor attacks
are effective with a small impact on a GNN's prediction accuracy for clean testing
graphs. Moreover, we generalize a randomized smoothing based certified defense to
defend against our backdoor attacks. Our empirical results show that the defense is
effective in some cases but ineffective in other cases, highlighting the needs of
new defenses for our backdoor attacks.},
booktitle = {Proceedings of the 26th ACM Symposium on Access Control Models and Technologies},
pages = {15–26},
numpages = {12},
keywords = {graph neural networks, backdoor attack},
location = {Virtual Event, Spain},
series = {SACMAT '21}
}

@inproceedings{10.1145/3238147.3238202,
author = {Ma, Lei and Juefei-Xu, Felix and Zhang, Fuyuan and Sun, Jiyuan and Xue, Minhui and Li, Bo and Chen, Chunyang and Su, Ting and Li, Li and Liu, Yang and Zhao, Jianjun and Wang, Yadong},
title = {DeepGauge: Multi-Granularity Testing Criteria for Deep Learning Systems},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3238202},
doi = {10.1145/3238147.3238202},
abstract = {Deep learning (DL) defines a new data-driven programming paradigm that constructs
the internal system logic of a crafted neuron network through a set of training data.
We have seen wide adoption of DL in many safety-critical scenarios. However, a plethora
of studies have shown that the state-of-the-art DL systems suffer from various vulnerabilities
which can lead to severe consequences when applied to real-world applications. Currently,
the testing adequacy of a DL system is usually measured by the accuracy of test data.
Considering the limitation of accessible high quality test data, good accuracy performance
on test data can hardly provide confidence to the testing adequacy and generality
of DL systems. Unlike traditional software systems that have clear and controllable
logic and functionality, the lack of interpretability in a DL system makes system
analysis and defect detection difficult, which could potentially hinder its real-world
deployment. In this paper, we propose DeepGauge, a set of multi-granularity testing
criteria for DL systems, which aims at rendering a multi-faceted portrayal of the
testbed. The in-depth evaluation of our proposed testing criteria is demonstrated
on two well-known datasets, five DL systems, and with four state-of-the-art adversarial
attack techniques against DL. The potential usefulness of DeepGauge sheds light on
the construction of more generic and robust DL systems.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {120–131},
numpages = {12},
keywords = {Software testing, Deep learning, Testing criteria, Deep neural networks},
location = {Montpellier, France},
series = {ASE 2018}
}

@inproceedings{10.1145/3190619.3190636,
author = {Potteiger, Bradley and Zhang, Zhenkai and Koutsoukos, Xenofon},
title = {Integrated Instruction Set Randomization and Control Reconfiguration for Securing Cyber-Physical Systems},
year = {2018},
isbn = {9781450364553},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3190619.3190636},
doi = {10.1145/3190619.3190636},
abstract = {Cyber-Physical Systems (CPS) have been increasingly subject to cyber-attacks including
code injection attacks. Zero day attacks further exasperate the threat landscape by
requiring a shift to defense in depth approaches. With the tightly coupled nature
of cyber components with the physical domain, these attacks have the potential to
cause significant damage if safety-critical applications such as automobiles are compromised.
Moving target defense techniques such as instruction set randomization (ISR) have
been commonly proposed to address these types of attacks. However, under current implementations
an attack can result in system crashing which is unacceptable in CPS. As such, CPS
necessitate proper control reconfiguration mechanisms to prevent a loss of availability
in system operation. This paper addresses the problem of maintaining system and security
properties of a CPS under attack by integrating ISR, detection, and recovery capabilities
that ensure safe, reliable, and predictable system operation. Specifically, we consider
the problem of detecting code injection attacks and reconfiguring the controller in
real-time. The developed framework is demonstrated with an autonomous vehicle case
study.},
booktitle = {Proceedings of the 5th Annual Symposium and Bootcamp on Hot Topics in the Science of Security},
articleno = {5},
numpages = {10},
keywords = {instruction set randomization, resilient architectures, cyber-physical systems, moving target defenses},
location = {Raleigh, North Carolina},
series = {HoTSoS '18}
}

@inproceedings{10.1145/3139923.3139927,
author = {Kul, Gokhan and Upadhyaya, Shambhu and Hughes, Andrew},
title = {Complexity of Insider Attacks to Databases},
year = {2017},
isbn = {9781450351775},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3139923.3139927},
doi = {10.1145/3139923.3139927},
abstract = {Insider attacks are one of the most dangerous threats to an organization. Unfortunately,
they are very difficult to foresee, detect, and defend against due to the trust and
responsibilities placed on the employees. In this paper, we first define the notion
of user intent, and construct a model for the most common threat scenario used in
the literature that poses a very high risk for sensitive data stored in the organization's
database. We show that the complexity of identifying pseudo-intents of a user is coNP-Complete
in this domain, and launching a harvester insider attack within the boundaries of
the defined threat model takes linear time while a targeted threat model is an NP-Complete
problem. We also discuss about the general defense mechanisms against the modeled
threats, and show that countering against the harvester insider attack model takes
quadratic time while countering against the targeted insider attack model can take
linear to quadratic time depending on the strategy chosen. Finally, we analyze the
adversarial behavior, and show that launching an attack with minimum risk is also
an NP-Complete problem.},
booktitle = {Proceedings of the 2017 International Workshop on Managing Insider Security Threats},
pages = {25–32},
numpages = {8},
keywords = {threat modeling, insider threat, query logs, complexity analysis, query intent},
location = {Dallas, Texas, USA},
series = {MIST '17}
}

@inproceedings{10.1145/3387940.3391483,
author = {Mekala, Rohan Reddy and Porter, Adam and Lindvall, Mikael},
title = {Metamorphic Filtering of Black-Box Adversarial Attacks on Multi-Network Face Recognition Models},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3391483},
doi = {10.1145/3387940.3391483},
abstract = {Adversarial examples pose a serious threat to the robustness of machine learning models
in general and of deep learning models in particular. These carefully designed perturbations
of input images can cause targeted misclassifications to a label of the attacker's
choice, without being detectable to the naked eye. A particular class of adversarial
attacks called black box attacks can be used to fool a target model despite not having
access to the model parameters or to the input data used to train the model. In this
paper, we first build a black box attack against robust multi-model face recognition
pipelines and then test it against Google's FaceNet. We then present a novel metamorphic
defense pipeline relying on nonlinear image transformations to detect adversarial
attacks with a high degree of accuracy. We further use the results to create probabilistic
metamorphic relations that define efficient decision boundaries between the safe and
adversarial examples; achieving adversarial classification accuracy of up to 96%.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {410–417},
numpages = {8},
keywords = {machine learning, adversarial attacks, computer vision, deep learning},
location = {Seoul, Republic of Korea},
series = {ICSEW'20}
}

@inproceedings{10.1145/3374664.3375751,
author = {Zhong, Haoti and Liao, Cong and Squicciarini, Anna Cinzia and Zhu, Sencun and Miller, David},
title = {Backdoor Embedding in Convolutional Neural Network Models via Invisible Perturbation},
year = {2020},
isbn = {9781450371070},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3374664.3375751},
doi = {10.1145/3374664.3375751},
abstract = {Deep learning models have consistently outperformed traditional machine learning models
in various classification tasks, including image classification. As such, they have
become increasingly prevalent in many real world applications including those where
security is of great concern. Such popularity, however, may attract attackers to exploit
the vulnerabilities of the deployed deep learning models and launch attacks against
security-sensitive applications. In this paper, we focus on a specific type of data
poisoning attack, which we refer to as a em backdoor injection attack. The main goal
of the adversary performing such attack is to generate and inject a backdoor into
a deep learning model that can be triggered to recognize certain embedded patterns
with a target label of the attacker's choice. Additionally, a backdoor injection attack
should occur in a stealthy manner, without undermining the efficacy of the victim
model. Specifically, we propose two approaches for generating a backdoor that is hardly
perceptible yet effective in poisoning the model. We consider two attack settings,
with backdoor injection carried out either before model training or during model updating.
We carry out extensive experimental evaluations under various assumptions on the adversary
model, and demonstrate that such attacks can be effective and achieve a high attack
success rate (above 90%) at a small cost of model accuracy loss with a small injection
rate, even under the weakest assumption wherein the adversary has no knowledge either
of the original training data or the classifier model.},
booktitle = {Proceedings of the Tenth ACM Conference on Data and Application Security and Privacy},
pages = {97–108},
numpages = {12},
keywords = {stealthy attacks, adversarial machine learning},
location = {New Orleans, LA, USA},
series = {CODASPY '20}
}

@article{10.1145/3391231,
author = {Kul, G\"{o}khan and Upadhyaya, Shambhu and Hughes, Andrew},
title = {An Analysis of Complexity of Insider Attacks to Databases},
year = {2020},
issue_date = {March 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {1},
issn = {2158-656X},
url = {https://doi.org/10.1145/3391231},
doi = {10.1145/3391231},
abstract = {Insider attacks are one of the most dangerous threats to an organization. Unfortunately,
they are very difficult to foresee, detect, and defend against due to the trust and
responsibilities placed on the employees. In this article, we first define the notion
of user intent and construct a model for a common scenario that poses a very high
risk for sensitive data stored in the organization’s database. We show that the complexity
of identifying pseudo-intents of a user in this scenario is coNP-Complete, and launching
a harvester insider attack within the boundaries of the defined threat model takes
linear time while a targeted threat model is an NP-Complete problem. We also discuss
the general defense mechanisms against the modeled threats and show that countering
the harvester insider attack takes quadratic time while countering the targeted insider
attack can take linear to quadratic time, depending on the strategy chosen. We analyze
the adversarial behavior and show that launching an attack with minimum risk is also
an NP-Complete problem. Finally, we perform timing experiments with the defense mechanisms
on SQL query workloads collected from a national bank to test the feasibility of using
these systems in real time.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = dec,
articleno = {4},
numpages = {18},
keywords = {insider threat, query logs, Complexity analysis, query intent, threat modeling}
}

@inproceedings{10.1145/3407023.3409201,
author = {Markiewicz, Robert P. and Sgandurra, Daniele},
title = {Clust-IT: Clustering-Based Intrusion Detection in IoT Environments},
year = {2020},
isbn = {9781450388337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3407023.3409201},
doi = {10.1145/3407023.3409201},
abstract = {Low-powered and resource-constrained devices are forming a greater part of our smart
networks. For this reason, they have recently been the target of various cyber-attacks.
However, these devices often cannot implement traditional intrusion detection systems
(IDS), or they can not produce or store the audit trails needed for inspection. Therefore,
it is often necessary to adapt existing IDS systems and malware detection approaches
to cope with these constraints.We explore the application of unsupervised learning
techniques, specifically clustering, to develop a novel IDS for networks composed
of low-powered devices. We describe our solution, called Clust-IT (Clustering of IoT),
to manage heterogeneous data collected from cooperative and distributed networks of
connected devices and searching these data for indicators of compromise while remaining
protocol agnostic. We outline a novel application of OPTICS to various available IoT
datasets, composed of both packet and flow captures, to demonstrate the capabilities
of the proposed techniques and evaluate their feasibility in developing an IoT IDS.},
booktitle = {Proceedings of the 15th International Conference on Availability, Reliability and Security},
articleno = {81},
numpages = {9},
location = {Virtual Event, Ireland},
series = {ARES '20}
}

@inproceedings{10.1145/3386901.3388946,
author = {Mo, Fan and Shamsabadi, Ali Shahin and Katevas, Kleomenis and Demetriou, Soteris and Leontiadis, Ilias and Cavallaro, Andrea and Haddadi, Hamed},
title = {DarkneTZ: Towards Model Privacy at the Edge Using Trusted Execution Environments},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388946},
doi = {10.1145/3386901.3388946},
abstract = {We present DarkneTZ, a framework that uses an edge device's Trusted Execution Environment
(TEE) in conjunction with model partitioning to limit the attack surface against Deep
Neural Networks (DNNs). Increasingly, edge devices (smartphones and consumer IoT devices)
are equipped with pre-trained DNNs for a variety of applications. This trend comes
with privacy risks as models can leak information about their training data through
effective membership inference attacks (MIAs).We evaluate the performance of DarkneTZ,
including CPU execution time, memory usage, and accurate power consumption, using
two small and six large image classification models. Due to the limited memory of
the edge device's TEE, we partition model layers into more sensitive layers (to be
executed inside the device TEE), and a set of layers to be executed in the untrusted
part of the operating system. Our results show that even if a single layer is hidden,
we can provide reliable model privacy and defend against state of the art MIAs, with
only 3% performance overhead. When fully utilizing the TEE, DarkneTZ provides model
protections with up to 10% overhead.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {161–174},
numpages = {14},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3411495.3421355,
author = {Aloufi, Ranya and Haddadi, Hamed and Boyle, David},
title = {Privacy-Preserving Voice Analysis via Disentangled Representations},
year = {2020},
isbn = {9781450380843},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411495.3421355},
doi = {10.1145/3411495.3421355},
abstract = {Voice User Interfaces (VUIs) are increasingly popular and built into smartphones,
home assistants, and Internet of Things (IoT) devices. Despite offering an always-on
convenient user experience, VUIs raise new security and privacy concerns for their
users. In this paper, we focus on attribute inference attacks in the speech domain,
demonstrating the potential for an attacker to accurately infer a target user's sensitive
and private attributes (e.g. their emotion, sex, or health status) from deep acoustic
models. To defend against this class of attacks, we design, implement, and evaluate
a user-configurable, privacy-aware framework for optimizing speech-related data sharing
mechanisms. Our objective is to enable primary tasks such as speech recognition and
user identification, while removing sensitive attributes in the raw speech data before
sharing it with a cloud service provider. We leverage disentangled representation
learning to explicitly learn independent factors in the raw data. Based on a user's
preferences, a supervision signal informs the filtering out of invariant factors while
retaining the factors reflected in the selected preference. Our experimental evaluation
over five datasets shows that the proposed framework can effectively defend against
attribute inference attacks by reducing their success rates to approximately that
of guessing at random, while maintaining accuracy in excess of 99% for the tasks of
interest. We conclude that negotiable privacy settings enabled by disentangled representations
can bring new opportunities for privacy-preserving applications.},
booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Cloud Computing Security Workshop},
pages = {1–14},
numpages = {14},
keywords = {voice synthesis, speech analysis, internet of things (iot), voice privacy},
location = {Virtual Event, USA},
series = {CCSW'20}
}

@inproceedings{10.1145/3311790.3396652,
author = {Yao, Philip and So, Andrew and Chen, Tingting and Ji, Hao},
title = {On Multiview Robustness of 3D Adversarial Attacks},
year = {2020},
isbn = {9781450366892},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3311790.3396652},
doi = {10.1145/3311790.3396652},
abstract = {Nowadays deep neural networks have been applied widely in many applications of computer
vision including medical diagnosis and self-driving cars. However, deep neural networks
are threatened by adversarial examples usually in which image pixels were perturbed
unnoticeable to humans but enough to fool the deep networks. Compared to 2D image
adversarial examples, 3D adversarial models are less invasive in the process of attacks,
and thus more realistic. There have been many research works on generating 3D adversarial
examples. In this paper, we study the robustness of 3D adversarial attacks when the
victim camera is placed at different viewpoints. In particular, we find a method to
create 3D adversarial examples that can achieve 100% attack success rate from all
viewpoints with any integer spherical coordinates. Our method is simple as we only
perturb the texture space. We create 3D models with realistic textures using 3D reconstruction
from multiple uncalibrated images. With the help of a differentiable renderer, we
then apply gradient based optimization to compute texture perturbations based on a
set of rendered images, i.e., training dataset. Our extensive experiments show that
even only including 1% of all possible rendered images in training, we can still achieve
99.9% attack success rate with the trained texture perturbations. Furthermore, our
thorough experiments show high transferability of the multiview robustness of our
3D adversraial attacks across various state-of-the-art deep neural network models.},
booktitle = {Practice and Experience in Advanced Research Computing},
pages = {372–378},
numpages = {7},
keywords = {deep neural networks, multiview robustness, 3D adversarial examples},
location = {Portland, OR, USA},
series = {PEARC '20}
}

@inproceedings{10.1145/3339252.3339266,
author = {Kuppa, Aditya and Grzonkowski, Slawomir and Asghar, Muhammad Rizwan and Le-Khac, Nhien-An},
title = {Black Box Attacks on Deep Anomaly Detectors},
year = {2019},
isbn = {9781450371643},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3339252.3339266},
doi = {10.1145/3339252.3339266},
abstract = {The process of identifying the true anomalies from a given set of data instances is
known as anomaly detection. It has been applied to address a diverse set of problems
in multiple application domains including cybersecurity. Deep learning has recently
demonstrated state-of-the-art performance on key anomaly detection applications, such
as intrusion detection, Denial of Service (DoS) attack detection, security log analysis,
and malware detection. Despite the great successes achieved by neural network architectures,
models with very low test error have been shown to be consistently vulnerable to small,
adversarially chosen perturbations of the input. The existence of evasion attacks
during the test phase of machine learning algorithms represents a significant challenge
to both their deployment and understanding.Recent approaches in the literature have
focused on three different areas: (a) generating adversarial examples in supervised
machine learning in multiple domains; (b) countering the attacks with various defenses;
(c) theoretical guarantees on the robustness of machine learning models by understanding
their security properties. However, they have not covered, from the perspective of
the anomaly detection task in a black box setting. The exploration of black box attack
strategies, which reduce the number of queries for finding adversarial examples with
high probability, is an important problem.In this paper, we study the security of
black box deep anomaly detectors with a realistic threat model. We propose a novel
black box attack in query constraint settings. First, we run manifold approximation
on samples collected at attacker end for query reduction and understanding various
thresholds set by underlying anomaly detector, and use spherical adversarial subspaces
to generate attack samples. This method is well suited for attacking anomaly detectors
where decision boundaries of nominal and abnormal classes are not very well defined
and decision process is done with a set of thresholds on anomaly scores. We validate
our attack on state-of-the-art deep anomaly detectors and show that the attacker goal
is achieved under constraint settings. Our evaluation of the proposed approach shows
promising results and demonstrates that our strategy can be successfully used against
other anomaly detectors.},
booktitle = {Proceedings of the 14th International Conference on Availability, Reliability and Security},
articleno = {21},
numpages = {10},
keywords = {Neural networks, Anomaly detection, Black box attacks},
location = {Canterbury, CA, United Kingdom},
series = {ARES '19}
}

@article{10.1145/3351261,
author = {Shen, Meng and Liao, Zelin and Zhu, Liehuang and Xu, Ke and Du, Xiaojiang},
title = {VLA: A Practical Visible Light-Based Attack on Face Recognition Systems in Physical World},
year = {2019},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {3},
url = {https://doi.org/10.1145/3351261},
doi = {10.1145/3351261},
abstract = {Adversarial example attacks have become a growing menace to neural network-based face
recognition systems. Generated by composing facial images with pixel-level perturbations,
adversarial examples change key features of inputs and thereby lead to misclassification
of neural networks. However, the perturbation loss caused by complex physical environments
sometimes prevents existing attack methods from taking effect.In this paper, we focus
on designing new attacks that are effective and inconspicuous in the physical world.
Motivated by the differences in image-forming principles between cameras and human
eyes, we propose VLA, a novel attack against black-box face recognition systems using
visible light. In VLA, visible light-based adversarial perturbations are crafted and
projected on human faces, which allows an adversary to conduct targeted or un-targeted
attacks. VLA decomposes adversarial perturbations into a perturbation frame and a
concealing frame, where the former adds modifications on human facial images while
the latter makes these modifications inconspicuous to human eyes. We conduct extensive
experiments to demonstrate the effectiveness, inconspicuousness, and robustness of
the adversarial examples crafted by VLA in physical scenarios.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {103},
numpages = {19},
keywords = {visible light attack, adversarial example}
}

@inproceedings{10.1145/3314058.3314064,
author = {Potteiger, Bradley and Zhang, Zhenkai and Koutsoukos, Xenofon},
title = {Integrated Data Space Randomization and Control Reconfiguration for Securing Cyber-Physical Systems},
year = {2019},
isbn = {9781450371476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3314058.3314064},
doi = {10.1145/3314058.3314064},
abstract = {Non-control data attacks have become widely popular for circumventing authentication
mechanisms in websites, servers, and personal computers. Moreover, in the context
of Cyber-Physical Systems (CPS) attacks can be executed against not only authentication
but also safety. With the tightly coupled nature between the cyber components and
physical dynamics, any unauthorized change to safety-critical variables may cause
damage or even catastrophic consequences. Moving target defense (MTD) techniques such
as data space randomization (DSR) can be effective for protecting against various
types of memory corruption attacks including non-control data attacks. However, in
terms of CPS it is also critical to ensure the timely Cyber-Physical interactions
after attacks thwarted by MTD. This paper addresses the problem of maintaining system
stability and security properties of a CPS in the face of non-control data attacks
by developing a DSR approach for randomizing binaries at runtime, creating a variable
redundancy based detection algorithm for identifying variable integrity violations,
and integrating a control reconfiguration architecture for maintaining safe and reliable
operation. Our security framework is demonstrated utilizing an autonomous vehicle
case study.},
booktitle = {Proceedings of the 6th Annual Symposium on Hot Topics in the Science of Security},
articleno = {3},
numpages = {10},
keywords = {moving target defenses, resilient architectures, cyber-physical systems, data space randomization},
location = {Nashville, Tennessee, USA},
series = {HotSoS '19}
}

@inproceedings{10.1145/3384217.3385622,
author = {Potteiger, Bradley and Mills, Jacob and Cohen, Daniel and Velez, Paul},
title = {RUCKUS: A Cybersecurity Engine for Performing Autonomous Cyber-Physical System Vulnerability Discovery at Scale},
year = {2020},
isbn = {9781450375610},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384217.3385622},
doi = {10.1145/3384217.3385622},
abstract = {In 2016, the Cyber Grand Challenge (CGC) provided key foundations and motivations
for navigating towards an autonomous cybersecurity approach. Since that time, novel
strides have been made in the areas of static analysis, vulnerability discovery, patching,
and exploit generation. However, a majority of these efforts have been focused on
enterprise systems, leaving a gap in the Cyber-Physical System (CPS) domain. With
the rise of connected infrastructure and the introduction of 5G communications, CPS
are becoming more ingrained within present-day society. Due to a large amount of legacy
software, and control of safety-critical actuation, CPS are and will continue to be
a huge attack vector for our adversaries to remotely deploy devastating attacks against
our country with low economic cost and at scale. To combat this threat, we propose
the need to apply the most beneficial concepts from the CGC to create more secure
and resilient CPS. In this paper, we introduce a CPS security assessment architecture
RUCKUS for autonomously identifying and analyzing CPS firmware, identifying vulnerabilities,
and developing exploits. Further, our approach considers how to integrate graph analytics
to extrapolate findings to firmware at scale, allowing for measuring the potential
widespread impact of attacks. Our architecture is demonstrated using an automotive
case study, leveraging firmware from the most popular automotive and router manufacturers
to assess the real-world potential impact of CPS attacks.},
booktitle = {Proceedings of the 7th Symposium on Hot Topics in the Science of Security},
articleno = {4},
numpages = {10},
keywords = {cyber-physical systems, autonomous vulnerability discovery, cyber grand challenge, firmware},
location = {Lawrence, Kansas},
series = {HotSoS '20}
}

@inproceedings{10.1145/3422337.3447836,
author = {Li, Jiacheng and Li, Ninghui and Ribeiro, Bruno},
title = {Membership Inference Attacks and Defenses in Classification Models},
year = {2021},
isbn = {9781450381437},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3422337.3447836},
doi = {10.1145/3422337.3447836},
abstract = {We study the membership inference (MI) attack against classifiers, where the attacker's
goal is to determine whether a data instance was used for training the classifier.
Through systematic cataloging of existing MI attacks and extensive experimental evaluations
of them, we find that a model's vulnerability to MI attacks is tightly related to
the generalization gap---the difference between training accuracy and test accuracy.
We then propose a defense against MI attacks that aims to close the gap by intentionally
reduces the training accuracy. More specifically, the training process attempts to
match the training and validation accuracies, by means of a new set regularizer using
the Maximum Mean Discrepancy between the softmax output empirical distributions of
the training and validation sets. Our experimental results show that combining this
approach with another simple defense (mix-up training) significantly improves state-of-the-art
defense against MI attacks, with minimal impact on testing accuracy.},
booktitle = {Proceedings of the Eleventh ACM Conference on Data and Application Security and Privacy},
pages = {5–16},
numpages = {12},
keywords = {image classification, neural networks, membership inference},
location = {Virtual Event, USA},
series = {CODASPY '21}
}

@inproceedings{10.1145/3338466.3358923,
author = {Jana, Indranil and Oprea, Alina},
title = {AppMine: Behavioral Analytics for Web Application Vulnerability Detection},
year = {2019},
isbn = {9781450368261},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338466.3358923},
doi = {10.1145/3338466.3358923},
abstract = {Web applications in widespread use have always been the target of large-scale attacks,
leading to massive disruption of services and financial loss, as in the Equifax data
breach. It has become common practice to deploy web applications in containers like
Docker for better portability and ease of deployment. We design a system called AppMine
for lightweight monitoring of web applications running in Docker containers and detection
of unknown web vulnerabilities. AppMine is an unsupervised learning system, trained
only on legitimate workloads of web applications, to detect anomalies based on either
traditional models (PCA and one-class SVM), or more advanced neural-network architectures
(LSTM). In our evaluation, we demonstrate that the neural network model outperforms
more traditional methods on a range of web applications and recreated exploits. For
instance, AppMine achieves average AUC scores as high as 0.97 for the Apache Struts
application (with the CVE-2017-5638 exploit used in the Equifax breach), while the
AUC scores for PCA and one-class SVM are 0.81 and 0.83, respectively.},
booktitle = {Proceedings of the 2019 ACM SIGSAC Conference on Cloud Computing Security Workshop},
pages = {69–80},
numpages = {12},
keywords = {web vulnerabilities, deep learning, docker containers, anomaly detection},
location = {London, United Kingdom},
series = {CCSW'19}
}

@inproceedings{10.1145/2905055.2905295,
author = {Bates, Andrew and Kalita, Jugal},
title = {Counting Clusters in Twitter Posts},
year = {2016},
isbn = {9781450339629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2905055.2905295},
doi = {10.1145/2905055.2905295},
abstract = {The Internet is full of information contained in short texts. These texts, sometimes
called microblogs, can include a wealth of useful data. Twitter is a well known microblogging
platform and has been mined for everything from earthquake detection to suicide prevention.
One approach to nding information in Twitter posts is to cluster the tweets. The clustering
associates posts that are common in some way. When using K-Means clustering, a major
challenge is simply in determining a good value for the number of clusters. Our research
has shown that using simple term based statistics can be used to choose the number
of clusters. This approach is signi cantly faster and produces better clusters when
compared to other cluster counting techniques. Additionally, the term based approach
itself produces groupings of tweets that have similar quality when compared to clusters
produced with K-Means.},
booktitle = {Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies},
articleno = {85},
numpages = {9},
keywords = {Clustering, Zipf's Law, Twitter},
location = {Udaipur, India},
series = {ICTCS '16}
}

@inproceedings{10.1145/2991079.2991125,
author = {Shen, Shiqi and Tople, Shruti and Saxena, Prateek},
title = {A<span class="smallcaps SmallerCapital">uror</span>: Defending against Poisoning Attacks in Collaborative Deep Learning Systems},
year = {2016},
isbn = {9781450347716},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2991079.2991125},
doi = {10.1145/2991079.2991125},
abstract = {Deep learning in a collaborative setting is emerging as a corner-stone of many upcoming
applications, wherein untrusted users collaborate to generate more accurate models.
From the security perspective, this opens collaborative deep learning to poisoning
attacks, wherein adversarial users deliberately alter their inputs to mis-train the
model. These attacks are known for machine learning systems in general, but their
impact on new deep learning systems is not well-established.We investigate the setting
of indirect collaborative deep learning --- a form of practical deep learning wherein
users submit masked features rather than direct data. Indirect collaborative deep
learning is preferred over direct, because it distributes the cost of computation
and can be made privacy-preserving. In this paper, we study the susceptibility of
collaborative deep learning systems to adversarial poisoning attacks. Specifically,
we obtain the following empirical results on 2 popular datasets for handwritten images
(MNIST) and traffic signs (GTSRB) used in auto-driving cars. For collaborative deep
learning systems, we demonstrate that the attacks have 99% success rate for misclassifying
specific target data while poisoning only 10% of the entire training dataset.As a
defense, we propose Auror, a system that detects malicious users and generates an
accurate model. The accuracy under the deployed defense on practical datasets is nearly
unchanged when operating in the absence of attacks. The accuracy of a model trained
using Auror drops by only 3% even when 30% of all the users are adversarial. Auror
provides a strong guarantee against evasion; if the attacker tries to evade, its attack
effectiveness is bounded.},
booktitle = {Proceedings of the 32nd Annual Conference on Computer Security Applications},
pages = {508–519},
numpages = {12},
location = {Los Angeles, California, USA},
series = {ACSAC '16}
}

@inproceedings{10.1145/3372297.3417231,
author = {Shan, Shawn and Wenger, Emily and Wang, Bolun and Li, Bo and Zheng, Haitao and Zhao, Ben Y.},
title = {Gotta Catch'Em All: Using Honeypots to Catch Adversarial Attacks on Neural Networks},
year = {2020},
isbn = {9781450370899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3372297.3417231},
doi = {10.1145/3372297.3417231},
abstract = {Deep neural networks (DNN) are known to be vulnerable to adversarial attacks. Numerous
efforts either try to patch weaknesses in trained models, or try to make it difficult
or costly to compute adversarial examples that exploit them. In our work, we explore
a new "honeypot" approach to protect DNN models. We intentionally inject trapdoors,
honeypot weaknesses in the classification manifold that attract attackers searching
for adversarial examples. Attackers' optimization algorithms gravitate towards trapdoors,
leading them to produce attacks similar to trapdoors in the feature space. Our defense
then identifies attacks by comparing neuron activation signatures of inputs to those
of trapdoors.In this paper, we introduce trapdoors and describe an implementation
of a trapdoor-enabled defense. First, we analytically prove that trapdoors shape the
computation of adversarial attacks so that attack inputs will have feature representations
very similar to those of trapdoors. Second, we experimentally show that trapdoor-protected
models can detect, with high accuracy, adversarial examples generated by state-of-the-art
attacks (PGD, optimization-based CW, Elastic Net, BPDA), with negligible impact on
normal classification. These results generalize across classification domains, including
image, facial, and traffic-sign recognition. We also present significant results measuring
trapdoors' robustness against customized adaptive attacks (countermeasures).},
booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
pages = {67–83},
numpages = {17},
keywords = {honeypots, adversarial examples, neural networks},
location = {Virtual Event, USA},
series = {CCS '20}
}

@InProceedings{10.1145/3427228.3427660,
  author    = {Erba, Alessandro and Taormina, Riccardo and Galelli, Stefano and Pogliani, Marcello and Carminati, Michele and Zanero, Stefano and Tippenhauer, Nils Ole},
  booktitle = {Annual Computer Security Applications Conference},
  title     = {Constrained Concealment Attacks against Reconstruction-Based Anomaly Detectors in Industrial Control Systems},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {480–495},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '20},
  abstract  = {Recently, reconstruction-based anomaly detection was proposed as an effective technique
to detect attacks in dynamic industrial control networks. Unlike classical network
anomaly detectors that observe the network traffic, reconstruction-based detectors
operate on the measured sensor data, leveraging physical process models learned a
priori. In this work, we investigate different approaches to evade prior-work reconstruction-based
anomaly detectors by manipulating sensor data so that the attack is concealed. We
find that replay attacks (commonly assumed to be very strong) show bad performance
(i.e., increasing the number of alarms) if the attacker is constrained to manipulate
less than 95% of all features in the system, as hidden correlations between the features
are not replicated well. To address this, we propose two novel attacks that manipulate
a subset of the sensor readings, leveraging learned physical constraints of the system.
Our attacks feature two different attacker models: A white box attacker, which uses
an optimization approach with a detection oracle, and a black box attacker, which
uses an autoencoder to translate anomalous data into normal data. We evaluate our
implementation on two different datasets from the water distribution domain, showing
that the detector’s Recall drops from 0.68 to 0.12 by manipulating 4 sensors out of
82 in WADI dataset. In addition, we show that our black box attacks are transferable
to different detectors: They work against autoencoder-, LSTM-, and CNN-based detectors.
Finally, we implement and demonstrate our attacks on a real industrial testbed to
demonstrate their feasibility in real-time.},
  doi       = {10.1145/3427228.3427660},
  isbn      = {9781450388580},
  keywords  = {Multivariate Time Series, Evasion Attack, Adversarial Machine Learning, Deep Learning, Mean Squared Error, Classifier Evasion, Intrusion Detection, Autoencoder, Industrial Control System},
  location  = {Austin, USA},
  numpages  = {16},
  url       = {https://doi.org/10.1145/3427228.3427660},
}

@inproceedings{10.1145/3326285.3329042,
author = {Hou, Jiahui and Qian, Jianwei and Wang, Yu and Li, Xiang-Yang and Du, Haohua and Chen, Linlin},
title = {ML Defense: Against Prediction API Threats in Cloud-Based Machine Learning Service},
year = {2019},
isbn = {9781450367783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326285.3329042},
doi = {10.1145/3326285.3329042},
abstract = {Machine learning (ML) has shown its impressive performance in the modern world, and
many corporations leverage the technique of machine learning to improve their service
quality, e.g., Facebook's DeepFace. Machine learning models with a collection of private
data being processed by a training algorithm are deemed to be increasingly confidential.
Confidential models are typically trained in a centralized cloud server but publicly
accessible. ML-as-a-service (MLaaS) system is one of running examples, where users
are allowed to access trained models and are charged on a pay-per-query basis.Unfortunately,
recent researchers have shown the tension between public access and confidential models,
where adversarial access to a model is abused to duplicate the functionality of the
model or even learn sensitive information about individuals (known to be in the training
dataset). We conclude these attacks as prediction API threats for simplicity.In this
work, we propose ML defense, a framework to defend against prediction API threats,
which works as an add-on to existing MLaaS systems. To the best of our knowledge,
this is the first work to propose a technical countermeasure to attacks trumped by
excessive query accesses. Our methodology neither modifies any classifier nor degrades
the model functionality (e.g., rounds results). The framework consists of one or more
simulators and one auditor. The simulator learns the hidden knowledge of adversaries.
The auditor then detects whether there exists a privacy breach. We discuss the intrinsic
difficulties and empirically state the efficiency and feasibility of our mechanisms
in different models and datasets.},
booktitle = {Proceedings of the International Symposium on Quality of Service},
articleno = {7},
numpages = {10},
keywords = {privacy and security, machine learning as a service},
location = {Phoenix, Arizona},
series = {IWQoS '19}
}

@inproceedings{10.1145/3341105.3373867,
author = {Mbarek, Bacem and Ge, Mouzhi and Pitner, Tom\'{a}s},
title = {Enhanced Network Intrusion Detection System Protocol for Internet of Things},
year = {2020},
isbn = {9781450368667},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341105.3373867},
doi = {10.1145/3341105.3373867},
abstract = {With the emergence of the Internet of Things (IoT), different IoT nodes such as 6LoWPAN
devices can be connected as a network to provide integrated services. Since security
and intrusion detection are becoming crucial among IoT devices, real-time detection
of the attacks are critical to protect the IoT networks. However, there exists limited
research for efficient network intrusion detection systems (NIDS) in the IoT networks.
This paper therefore proposes a new NIDS protocol with an efficient replica detection
algorithm to increase the utility and performance of existing NIDS, where a number
of replica test nodes are intentionally inserted into the network to test the reliability
and response of witness nodes. The proposed protocol, Enhanced NIDS, can address the
vulnerability of NIDS and improve IoT network security to detect severe compromise
attacks such as clone attacks. The simulation study shows that compared to the state-of-the-art
SVELTE protocol, the proposed protocol can significantly increase the detection probability
and reduce the energy consumption for detecting clone attacks in IoT networks.},
booktitle = {Proceedings of the 35th Annual ACM Symposium on Applied Computing},
pages = {1156–1163},
numpages = {8},
keywords = {security, intrusion detection systems, network protocol, clone attacks, internet of things, replica detection},
location = {Brno, Czech Republic},
series = {SAC '20}
}

@inproceedings{10.1145/3433210.3453090,
author = {Chen, Kangjie and Guo, Shangwei and Zhang, Tianwei and Xie, Xiaofei and Liu, Yang},
title = {Stealing Deep Reinforcement Learning Models for Fun and Profit},
year = {2021},
isbn = {9781450382878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3433210.3453090},
doi = {10.1145/3433210.3453090},
abstract = {This paper presents the first model extraction attack against Deep Reinforcement Learning
(DRL), which enables an external adversary to precisely recover a black-box DRL model
only from its interaction with the environment. Model extraction attacks against supervised
Deep Learning models have been widely studied. However, those techniques cannot be
applied to the reinforcement learning scenario due to DRL models' high complexity,
stochasticity and limited observable information. We propose a novel methodology to
overcome the above challenges. The key insight of our approach is that the process
of DRL model extraction is equivalent to imitation learning, a well-established solution
to learn sequential decision-making policies. Based on this observation, our methodology
first builds a classifier to reveal the training algorithm family of the targeted
black-box DRL model only based on its predicted actions, and then leverages state-of-the-art
imitation learning techniques to replicate the model from the identified algorithm
family. Experimental results indicate that our methodology can effectively recover
the DRL models with high fidelity and accuracy. We also demonstrate two use cases
to show that our model extraction attack can (1) significantly improve the success
rate of adversarial attacks, and (2) steal DRL models stealthily even they are protected
by DNN watermarks. These pose a severe threat to the intellectual property and privacy
protection of DRL applications.},
booktitle = {Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security},
pages = {307–319},
numpages = {13},
keywords = {model extraction, deep reinforcement learning, imitation learning},
location = {Virtual Event, Hong Kong},
series = {ASIA CCS '21}
}

@inproceedings{10.1145/3137003.3137014,
author = {Alanwar, Amr and Balaji, Bharathan and Tian, Yuan and Yang, Shuo and Srivastava, Mani},
title = {EchoSafe: Sonar-Based Verifiable Interaction with Intelligent Digital Agents},
year = {2017},
isbn = {9781450355452},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3137003.3137014},
doi = {10.1145/3137003.3137014},
abstract = {Voice controlled interactive smart speakers, such as Google Home, Amazon Echo, and
Apple HomePod are becoming commonplace in today's homes. These devices listen continually
for the user commands, that are triggered by special keywords, such as "Alexa" and
"Hey Siri". Recent research has shown that these devices are vulnerable to attacks
through malicious voice commands from nearby devices. The commands can be sent easily
during unoccupied periods, so that the user may be unaware of such attacks. We present
EchoSafe, a user-friendly sonar-based defense against these attacks. When the user
sends a critical command to the smart speaker, EchoSafe sends an audio pulse followed
by post processing to determine if the user is present in the room. We can detect
the user's presence during critical commands with 93.13% accuracy, and our solution
can be extended to defend against other attack scenarios, as well.},
booktitle = {Proceedings of the 1st ACM Workshop on the Internet of Safe Things},
pages = {38–43},
numpages = {6},
keywords = {alexa, Security, siri, echo, smart home, smart speakers, internet of things},
location = {Delft, Netherlands},
series = {SafeThings'17}
}

@inproceedings{10.1145/3374664.3375728,
author = {Chen, Jiyu and Wang, David and Chen, Hao},
title = {Explore the Transformation Space for Adversarial Images},
year = {2020},
isbn = {9781450371070},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3374664.3375728},
doi = {10.1145/3374664.3375728},
abstract = {Deep learning models are vulnerable to adversarial examples. Most of current adversarial
attacks add pixel-wise perturbations restricted to some (L^p)-norm, and defense
models are evaluated also on adversarial examples restricted inside (L^p)-norm balls.
However, we wish to explore adversarial examples exist beyond (L^p)-norm balls and
their implications for attacks and defenses. In this paper, we focus on adversarial
images generated by transformations. We start with color transformation and propose
two gradient-based attacks. Since (L^p)-norm is inappropriate for measuring image
quality in the transformation space, we use the similarity between transformations
and the Structural Similarity Index. Next, we explore a larger transformation space
consisting of combinations of color and affine transformations. We evaluate our transformation
attacks on three data sets --- CIFAR10, SVHN, and ImageNet --- and their corresponding
models. Finally, we perform retraining defenses to evaluate the strength of our attacks.
The results show that transformation attacks are powerful. They find high-quality
adversarial images that have higher transferability and misclassification rates than
C&amp;W's (L^p ) attacks, especially at high confidence levels. They are also significantly
harder to defend against by retraining than C&amp;W's (L^p ) attacks. More importantly,
exploring different attack spaces makes it more challenging to train a universally
robust model.},
booktitle = {Proceedings of the Tenth ACM Conference on Data and Application Security and Privacy},
pages = {109–120},
numpages = {12},
keywords = {image transformation, deep learning security, adversarial attacks},
location = {New Orleans, LA, USA},
series = {CODASPY '20}
}

@inproceedings{10.1145/2808128.2808131,
author = {Appala, Syam and Cam-Winget, Nancy and McGrew, David and Verma, Jyoti},
title = {An Actionable Threat Intelligence System Using a Publish-Subscribe Communications Model},
year = {2015},
isbn = {9781450338226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2808128.2808131},
doi = {10.1145/2808128.2808131},
abstract = {We designed a system for securely distributing Threat Intelligence and recommended
Courses of Action (CoAs), combining that information with local contextual information,
determining which response system(s) can carry it out, and then putting the course
of action into effect. Our system uses STIX to express threat information, including
CoAs. We identified the problem of matching CoAs with the actions that a response
system can carry out as a major design challenge, and found a robust and scalable
decentralized solution to that challenge by adopting a publish-subscribe model. We
built a solution based on the Extensible Messaging and Presence Protocol (XMPP) architecture
and communications protocol as it provided the right security properties as well as
the needed extensibility for both data model and transport protocols. We motivate
and describe our system, and the use cases of Cyber Threat Prevention, Cyber Threat
Detection, and Incident Response.},
booktitle = {Proceedings of the 2nd ACM Workshop on Information Sharing and Collaborative Security},
pages = {61–70},
numpages = {10},
keywords = {courses of action, incident response, publish-subscribe, authentication and authorization, application programming interfaces, threat incidents, indicators of compromise, secure transport},
location = {Denver, Colorado, USA},
series = {WISCS '15}
}

@inproceedings{10.1145/3190619.3190637,
author = {Madani, Pooria and Vlajic, Natalija},
title = {Robustness of Deep Autoencoder in Intrusion Detection under Adversarial Contamination},
year = {2018},
isbn = {9781450364553},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3190619.3190637},
doi = {10.1145/3190619.3190637},
abstract = {The existing state-of-the-art in the field of intrusion detection systems (IDSs) generally
involves some use of machine learning algorithms. However, the computer security community
is growing increasingly aware that a sophisticated adversary could target the learning
module of these IDSs in order to circumvent future detections. Consequently, going
forward, robustness of machine-learning based IDSs against adversarial manipulation
(i.e., poisoning) will be the key factor for the overall success of these systems
in the real world. In our work, we focus on adaptive IDSs that use anomaly-based detection
to identify malicious activities in an information system. To be able to evaluate
the susceptibility of these IDSs to deliberate adversarial poisoning, we have developed
a novel framework for their performance testing under adversarial contamination. We
have also studied the viability of using deep autoencoders in the detection of anomalies
in adaptive IDSs, as well as their overall robustness against adversarial poisoning.
Our experimental results show that our proposed autoencoder-based IDS outperforms
a generic PCA-based counterpart by more than 15% in terms of detection accuracy. The
obtained results concerning the detection ability of the deep autoencoder IDS under
adversarial contamination, compared to that of the PCA-based IDS, are also encouraging,
with the deep autoencoder IDS maintaining a more stable detection in parallel to limiting
the contamination of its training dataset to just bellow 2%.},
booktitle = {Proceedings of the 5th Annual Symposium and Bootcamp on Hot Topics in the Science of Security},
articleno = {1},
numpages = {8},
location = {Raleigh, North Carolina},
series = {HoTSoS '18}
}

@InProceedings{10.1145/3433667.3433670,
  author    = {Park, Daniel and Yener, B\"{u}lent},
  booktitle = {Reversing and Offensive-Oriented Trends Symposium},
  title     = {A Survey on Practical Adversarial Examples for Malware Classifiers},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {23–35},
  publisher = {Association for Computing Machinery},
  series    = {ROOTS'20},
  abstract  = {Machine learning based solutions have been very helpful in solving problems that
deal with immense amounts of data, such as malware detection and classification. However,
deep neural networks have been found to be vulnerable to adversarial examples, or
inputs that have been purposefully perturbed to result in an incorrect label. Researchers
have shown that this vulnerability can be exploited to create evasive malware samples.
However, many proposed attacks do not generate an executable and instead generate
a feature vector. To fully understand the impact of adversarial examples on malware
detection, we review practical attacks against malware classifiers that generate executable
adversarial malware examples. We also discuss current challenges in this area of research,
as well as suggestions for improvement and future research directions.},
  doi       = {10.1145/3433667.3433670},
  isbn      = {9781450389747},
  keywords  = {SoK, machine learning, survey, adversarial examples, malware},
  location  = {Vienna, Austria},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3433667.3433670},
}

@inproceedings{10.1145/3422337.3447833,
author = {Herath, J. Dinal and Yang, Ping and Yan, Guanhua},
title = {Real-Time Evasion Attacks against Deep Learning-Based Anomaly Detection from Distributed System Logs},
year = {2021},
isbn = {9781450381437},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3422337.3447833},
doi = {10.1145/3422337.3447833},
abstract = {Distributed system logs, which record states and events that occurred during the execution
of a distributed system, provide valuable information for troubleshooting and diagnosis
of its operational issues. Due to the complexity of such systems, there have been
some recent research efforts on automating anomaly detection from distributed system
logs using deep learning models. As these anomaly detection models can also be used
to detect malicious activities inside distributed systems, it is important to understand
their robustness against evasive manipulations in adversarial environments. Although
there are various attacks against deep learning models in domains such as natural
language processing and image classification, they cannot be applied directly to evade
anomaly detection from distributed system logs. In this work, we explore the adversarial
robustness of deep learning-based anomaly detection models on distributed system logs.
We propose a real-time attack method called LAM (Log Anomaly Mask) to perturb streaming
logs with minimal modifications in an online fashion so that the attacks can evade
anomaly detection by even the state-of-the-art deep learning models. To overcome the
search space complexity challenge, LAM models the perturber as a reinforcement learning
agent that operates in a partially observable environment to predict the best perturbation
action. We have evaluated the effectiveness of LAM on two log-based anomaly detection
systems for distributed systems: DeepLog and an AutoEncoder-based anomaly detection
system. Our experimental results show that LAM significantly reduces the true positive
rate of these two models while achieving attack imperceptibility and real-time responsiveness.},
booktitle = {Proceedings of the Eleventh ACM Conference on Data and Application Security and Privacy},
pages = {29–40},
numpages = {12},
keywords = {reinforcement learning, real-time evasion attacks, distributed system logs},
location = {Virtual Event, USA},
series = {CODASPY '21}
}

@inproceedings{10.1145/2556315.2556318,
author = {Schnarz, Pierre and Wietzke, Joachim and Stengel, Ingo},
title = {Towards Attacks on Restricted Memory Areas through Co-Processors in Embedded Multi-OS Environments via Malicious Firmware Injection},
year = {2014},
isbn = {9781450324847},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556315.2556318},
doi = {10.1145/2556315.2556318},
abstract = {Multi-operating systems have been introduced to manage the manifold requirements of
embedded systems. Especially in safety critical environments like the automotive domain
the system's security must be guaranteed. Despite the state-of-the-art virtualization
mechanisms, the idea of asymmetric-multi-processing can be used to split a system's
hardware resources, which makes the virtualization of hardware obsolete. However,
this special technique to implement a multi-operating system might add special demands
to security objectives like isolation. In this paper an attack vector is shown, which
utilizes a co-processor to break through the isolation of an operating system domain.
Using a multi-operating system environment, we inject a malicious firmware into the
co-processor in order to circumvent isolation mechanisms on behalf of an attacking
operating system. Our attack vector demonstrates weaknesses in CPU centric isolation
mechanisms, which will be further presented in the remainder of the document.},
booktitle = {Proceedings of the First Workshop on Cryptography and Security in Computing Systems},
pages = {25–30},
numpages = {6},
location = {Vienna, Austria},
series = {CS2 '14}
}

@inproceedings{10.1145/3264877.3264878,
author = {Wang, Ge and Qian, Chen and Cai, Haofan and Han, Jinsong and Zhao, Jizhong},
title = {Replay-Resilient Authentication for IoT},
year = {2018},
isbn = {9781450359320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3264877.3264878},
doi = {10.1145/3264877.3264878},
abstract = {We provide the first solution to an important question, "how a physical-layer RFID
authentication method can defend against signal replay attacks". It was believed that
if the attacker has a device that can replay the exact same reply signal of a legitimate
tag, any physical-layer authentication method will fail. This paper presents Hu-Fu,
the first physical layer RFID authentication protocol that is resilient to the major
attacks including tag counterfeiting, signal replay, signal compensation, and brute-force
feature reply. Hu-Fu is built on two fundamental ideas, namely inductive coupling
of two tags and signal randomization. Hu-Fu does not require any hardware or protocol
modification on COTS passive tags and can be implemented with COTS devices. We implement
a prototype of Hu-Fu and demonstrate that it is accurate and robust to device diversity
and environmental changes.},
booktitle = {Proceedings of the 10th on Wireless of the Students, by the Students, and for the Students Workshop},
pages = {3–5},
numpages = {3},
keywords = {internet of things, device authentication, RFID},
location = {New Delhi, India},
series = {S3 '18}
}

@inproceedings{10.1145/2030112.2030139,
author = {Peddinti, Sai Teja and Saxena, Nitesh},
title = {On the Limitations of Query Obfuscation Techniques for Location Privacy},
year = {2011},
isbn = {9781450306300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2030112.2030139},
doi = {10.1145/2030112.2030139},
abstract = {A promising approach to location privacy is query obfuscation, which involves reporting
k -- 1 false locations along with the real location. In this paper, we examine the
level of privacy protection provided by the current query obfuscation techniques against
adversarial location service providers. As a representative and realistic implementation
of query obfuscation, we focus on SybilQuery. We present two types of attacks depending
upon whether or not a short-term query history is available. When history is available,
using machine learning, we were able to identify 93.67% of user trips, with only 2.02%
of fake trips misclassified, for the security parameter k = 5. In the absence of history,
we used trip correlations to form a smaller set of trips effectively increasing the
user query identification probability from 20% to about 40%. Our work demonstrates
that the use of aggregate statistical information alone is not sufficient to generate
simulated trips. We identify areas for improvement in the existing query obfuscation
techniques.},
booktitle = {Proceedings of the 13th International Conference on Ubiquitous Computing},
pages = {187–196},
numpages = {10},
keywords = {anonymity, query obfuscation, machine learning, location privacy},
location = {Beijing, China},
series = {UbiComp '11}
}

@inproceedings{10.1145/3319535.3354230,
author = {Bijmans, Hugo L. J. and Booij, Tim M. and Doerr, Christian},
title = {Just the Tip of the Iceberg: Internet-Scale Exploitation of Routers for Cryptojacking},
year = {2019},
isbn = {9781450367479},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3319535.3354230},
doi = {10.1145/3319535.3354230},
abstract = {The release of an efficient browser-based cryptominer, as introduced by Coinhive in
2017, has quickly spread throughout the web either as a new source of revenue for
websites or exploited within the context of hacks and malicious advertisements. Several
studies have analyzed the Alexa Top 1M and found 380 - 3,200 (0.038% - 0.32%) to be
actively mining, with an estimated $41,000 per month revenue for the top 10 perpetrators.
While placing a cryptominer on a popular website supplies considerable returns from
its visitors' web browsers, it only generates revenue while a client is visiting the
page. Even though large popular websites attract millions of visitors, the relatively
low number of exploiting websites limits the total revenue that can be made. In this
paper, we report on a new attack vector that drastically overshadows all existing
cryptojacking activity discovered to date. Through a firmware vulnerability in MikroTik
routers, cyber criminals are able to rewrite outgoing user traffic and embed cryptomining
code in every outgoing web connection. Thus, every web page visited by any user behind
an infected router would mine to profit the criminals. Based on NetFlows recorded
in a Tier 1 network, semiweekly crawls and telescope traffic, we followed their activities
over a period of 10 months, and report on the modus operandi and coordinating infrastructure
of the perpetrators, which were during this period in control of up to 1.4M routers,
approximately 70% of all MikroTik devices deployed worldwide. We observed different
levels of sophistication among adversaries, ranging from individual installations
to campaigns involving large numbers of routers. Our results show that cryptojacking
through MITM attacks is highly lucrative, a factor of 30 more than previous attack
vectors.},
booktitle = {Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security},
pages = {449–464},
numpages = {16},
keywords = {cyber threat intelligence, mikrotik, cryptojacking, MITM, router},
location = {London, United Kingdom},
series = {CCS '19}
}

@inproceedings{10.1145/3264746.3264786,
author = {Kim, Gihoon and Choi, Chang and Choi, Junho},
title = {Ontology Modeling for APT Attack Detection in an IoT-Based Power System},
year = {2018},
isbn = {9781450358859},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3264746.3264786},
doi = {10.1145/3264746.3264786},
abstract = {Smart grid technology is the core technology for the next-generation power grid system
with enhanced energy efficiency through decision-making communication between suppliers
and consumers enabled by integrating the IoT into the existing grid. This open architecture
allowing bilateral information exchange makes it vulnerable to various types of cyberattack.
APT attacks, one of the most common cyberattacks, are highly tricky and sophisticated
attacks that can circumvent the existing detection technology and attack the targeted
system after a certain latent period after intrusion. This paper proposes an ontology-based
attack detection system capable of early detection of and response to APT attacks
by analyzing their attacking patterns.},
booktitle = {Proceedings of the 2018 Conference on Research in Adaptive and Convergent Systems},
pages = {160–164},
numpages = {5},
keywords = {smart grid, IoT, ontology, APT attack},
location = {Honolulu, Hawaii},
series = {RACS '18}
}

@inproceedings{10.1145/3448300.3467827,
author = {Wang, Han and Mu\~{n}oz-Gonz\'{a}lez, Luis and Eklund, David and Raza, Shahid},
title = {Non-IID Data Re-Balancing at IoT Edge with Peer-to-Peer Federated Learning for Anomaly Detection},
year = {2021},
isbn = {9781450383493},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448300.3467827},
doi = {10.1145/3448300.3467827},
abstract = {The increase of the computational power in edge devices has enabled the penetration
of distributed machine learning technologies such as federated learning, which allows
to build collaborative models performing the training locally in the edge devices,
improving the efficiency and the privacy for training of machine learning models,
as the data remains in the edge devices. However, in some IoT networks the connectivity
between devices and system components can be limited, which prevents the use of federated
learning, as it requires a central node to orchestrate the training of the model.
To sidestep this, peer-to-peer learning appears as a promising solution, as it does
not require such an orchestrator. On the other side, the security challenges in IoT
deployments have fostered the use of machine learning for attack and anomaly detection.
In these problems, under supervised learning approaches, the training datasets are
typically imbalanced, i.e. the number of anomalies is very small compared to the number
of benign data points, which requires the use of re-balancing techniques to improve
the algorithms' performance. In this paper, we propose a novel peer-to-peer algorithm,P2PK-SMOTE,
to train supervised anomaly detection machine learning models in non-IID scenarios,
including mechanisms to locally re-balance the training datasets via synthetic generation
of data points from the minority class. To improve the performance in non-IID scenarios,
we also include a mechanism for sharing a small fraction of synthetic data from the
minority class across devices, aiming to reduce the risk of data de-identification.
Our experimental evaluation in real datasets for IoT anomaly detection across a different
set of scenarios validates the benefits of our proposed approach.},
booktitle = {Proceedings of the 14th ACM Conference on Security and Privacy in Wireless and Mobile Networks},
pages = {153–163},
numpages = {11},
keywords = {anomaly detection, imbalanced data, non-IID data, federated learning},
location = {Abu Dhabi, United Arab Emirates},
series = {WiSec '21}
}

@inproceedings{10.1145/3241539.3241541,
author = {Wang, Ge and Cai, Haofan and Qian, Chen and Han, Jinsong and Li, Xin and Ding, Han and Zhao, Jizhong},
title = {Towards Replay-Resilient RFID Authentication},
year = {2018},
isbn = {9781450359030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3241539.3241541},
doi = {10.1145/3241539.3241541},
abstract = {We provide the first solution to an important question, "how a physical-layer authentication
method can defend against signal replay attacks''. It was believed that if an attacker
can replay the exact same reply signal of a legitimate authentication object (such
as an RFID tag), any physical-layer authentication method will fail. This paper presents
Hu-Fu, the first physical layer RFID authentication protocol that is resilient to
the major attacks including tag counterfeiting, signal replay, signal compensation,
and brute-force feature reply. Hu-Fu is built on two fundamental ideas, namely inductive
coupling of two tags and signal randomization. Hu-Fu does not require any hardware
or protocol modification on COTS passive tags and can be implemented with COTS devices.
We implement a prototype of Hu-Fu and demonstrate that it is accurate and robust to
device diversity and environmental changes, including locations, distance, and temperature.
Hu-Fu provides a new direction of battery-free/low-power device authentication that
enables numerous IoT applications.},
booktitle = {Proceedings of the 24th Annual International Conference on Mobile Computing and Networking},
pages = {385–399},
numpages = {15},
keywords = {device authentication, rfid, internet of things},
location = {New Delhi, India},
series = {MobiCom '18}
}

@article{10.1145/3007787.3001189,
author = {Li, Chao and Wang, Zhenhua and Hou, Xiaofeng and Chen, Haopeng and Liang, Xiaoyao and Guo, Minyi},
title = {Power Attack Defense: Securing Battery-Backed Data Centers},
year = {2016},
issue_date = {June 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {3},
issn = {0163-5964},
url = {https://doi.org/10.1145/3007787.3001189},
doi = {10.1145/3007787.3001189},
abstract = {Battery systems are crucial components for mission-critical data centers. Without
secure energy backup, existing under-provisioned data centers are largely unguarded
targets for cyber criminals. Particularly for today's scale-out servers, power oversubscription
unavoidably taxes a data center's backup energy resources, leaving very little room
for dealing with emergency. Besides, the emerging trend towards deploying distributed
energy storage architecture causes the associated energy backup of each rack to shrink,
making servers vulnerable to power anomalies. As a result, an attacker can generate
power peaks to easily crash or disrupt a power-constrained system. This study aims
at securing data centers from malicious loads that seek to drain their precious energy
storage and overload server racks without prior detection. We term such load as Power
Virus (PV) and demonstrate its basic two-phase attacking model and characterize its
behaviors on real systems. The PV can learn the victim rack's battery characteristics
by disguising as benign loads. Once gaining enough information, the PV can be mutated
to generate hidden power spikes that have a high chance to overload the system. To
defend against PV, we propose power attack defense (PAD), a novel energy management
patch built on lightweight software and hardware mechanisms. PAD not only increases
the attacking cost considerably by hiding vulnerable racks from visible spikes, it
also strengthens the last line of defense against hidden spikes. Using Google cluster
traces we show that PAD can effectively raise the bar of a successful power attack:
compared to prior arts, it increases the data center survival time by 1.6~11X and
provides better performance guarantee. It enables modern data centers to safely exploit
the benefits that power oversubscription may provide, with the slightest cost overhead.},
journal = {SIGARCH Comput. Archit. News},
month = jun,
pages = {493–505},
numpages = {13},
keywords = {defense, battery, power attack, data center}
}

@inproceedings{10.1109/ISCA.2016.50,
author = {Li, Chao and Wang, Zhenhua and Hou, Xiaofeng and Chen, Haopeng and Liang, Xiaoyao and Guo, Minyi},
title = {Power Attack Defense: Securing Battery-Backed Data Centers},
year = {2016},
isbn = {9781467389471},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ISCA.2016.50},
doi = {10.1109/ISCA.2016.50},
abstract = {Battery systems are crucial components for mission-critical data centers. Without
secure energy backup, existing under-provisioned data centers are largely unguarded
targets for cyber criminals. Particularly for today's scale-out servers, power oversubscription
unavoidably taxes a data center's backup energy resources, leaving very little room
for dealing with emergency. Besides, the emerging trend towards deploying distributed
energy storage architecture causes the associated energy backup of each rack to shrink,
making servers vulnerable to power anomalies. As a result, an attacker can generate
power peaks to easily crash or disrupt a power-constrained system. This study aims
at securing data centers from malicious loads that seek to drain their precious energy
storage and overload server racks without prior detection. We term such load as Power
Virus (PV) and demonstrate its basic two-phase attacking model and characterize its
behaviors on real systems. The PV can learn the victim rack's battery characteristics
by disguising as benign loads. Once gaining enough information, the PV can be mutated
to generate hidden power spikes that have a high chance to overload the system. To
defend against PV, we propose power attack defense (PAD), a novel energy management
patch built on lightweight software and hardware mechanisms. PAD not only increases
the attacking cost considerably by hiding vulnerable racks from visible spikes, it
also strengthens the last line of defense against hidden spikes. Using Google cluster
traces we show that PAD can effectively raise the bar of a successful power attack:
compared to prior arts, it increases the data center survival time by 1.6~11X and
provides better performance guarantee. It enables modern data centers to safely exploit
the benefits that power oversubscription may provide, with the slightest cost overhead.},
booktitle = {Proceedings of the 43rd International Symposium on Computer Architecture},
pages = {493–505},
numpages = {13},
keywords = {power attack, data center, battery, defense},
location = {Seoul, Republic of Korea},
series = {ISCA '16}
}

@inproceedings{10.1145/3338501.3357372,
author = {Sehwag, Vikash and Bhagoji, Arjun Nitin and Song, Liwei and Sitawarin, Chawin and Cullina, Daniel and Chiang, Mung and Mittal, Prateek},
title = {Analyzing the Robustness of Open-World Machine Learning},
year = {2019},
isbn = {9781450368339},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338501.3357372},
doi = {10.1145/3338501.3357372},
abstract = {When deploying machine learning models in real-world applications, an open-world learning
framework is needed to deal with both normal in-distribution inputs and undesired
out-of-distribution (OOD) inputs. Open-world learning frameworks include OOD detectors
that aim to discard input examples which are not from the same distribution as the
training data of machine learning classifiers. However, our understanding of current
OOD detectors is limited to the setting of benign OOD data, and an open question is
whether they are robust in the presence of adversaries. In this paper, we present
the first analysis of the robustness of open-world learning frameworks in the presence
of adversaries by introducing and designing \o{}odAdvExamples. Our experimental results
show that current OOD detectors can be easily evaded by slightly perturbing benign
OOD inputs, revealing a severe limitation of current open-world learning frameworks.
Furthermore, we find that \o{}odAdvExamples also pose a strong threat to adversarial
training based defense methods in spite of their effectiveness against in-distribution
adversarial attacks. To counteract these threats and ensure the trustworthy detection
of OOD inputs, we outline a preliminary design for a robust open-world machine learning
framework.},
booktitle = {Proceedings of the 12th ACM Workshop on Artificial Intelligence and Security},
pages = {105–116},
numpages = {12},
keywords = {adversarial example, open world recognition, deep learning},
location = {London, United Kingdom},
series = {AISec'19}
}

@inproceedings{10.1145/3394486.3403064,
author = {Tang, Ruixiang and Du, Mengnan and Liu, Ninghao and Yang, Fan and Hu, Xia},
title = {An Embarrassingly Simple Approach for Trojan Attack in Deep Neural Networks},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403064},
doi = {10.1145/3394486.3403064},
abstract = {With the widespread use of deep neural networks (DNNs) in high-stake applications,
the security problem of the DNN models has received extensive attention. In this paper,
we investigate a specific security problem called trojan attack, which aims to attack
deployed DNN systems relying on the hidden trigger patterns inserted by malicious
hackers. We propose a training-free attack approach which is different from previous
work, in which trojaned behaviors are injected by retraining model on a poisoned dataset.
Specifically, we do not change parameters in the original model but insert a tiny
trojan module (TrojanNet) into the target model. The infected model with a malicious
trojan can misclassify inputs into a target label when the inputs are stamped with
the special trigger. The proposed TrojanNet has several nice properties including
(1) it activates by tiny trigger patterns and keeps silent for other signals, (2)
it is model-agnostic and could be injected into most DNNs, dramatically expanding
its attack scenarios, and (3) the training-free mechanism saves massive training efforts
comparing to conventional trojan attack methods. The experimental results show that
TrojanNet can inject the trojan into all labels simultaneously (all-label trojan attack)
and achieves 100% attack success rate without affecting model accuracy on original
tasks. Experimental analysis further demonstrates that state-of-the-art trojan detection
algorithms fail to detect TrojanNet attack. The code is available at https://github.com/trx14/TrojanNet.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {218–228},
numpages = {11},
keywords = {anomaly detection, deep learning security, Trojan attack},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@inproceedings{10.1145/3270101.3270111,
author = {Hashemi, Mohammad and Cusack, Greg and Keller, Eric},
title = {Stochastic Substitute Training: A Gray-Box Approach to Craft Adversarial Examples Against Gradient Obfuscation Defenses},
year = {2018},
isbn = {9781450360043},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3270101.3270111},
doi = {10.1145/3270101.3270111},
abstract = {It has been shown that adversaries can craft example inputs to neural networks which
are similar to legitimate inputs but have been created to purposely cause the neural
network to misclassify the input. These adversarial examples are crafted, for example,
by calculating gradients of a carefully defined loss function with respect to the
input. As a countermeasure, some researchers have tried to design robust models by
blocking or obfuscating gradients, even in white-box settings. Another line of research
proposes introducing a separate detector to attempt to detect adversarial examples.
This approach also makes use of gradient obfuscation techniques, for example, to prevent
the adversary from trying to fool the detector. In this paper, we introduce stochastic
substitute training, a gray-box approach that can craft adversarial examples for defenses
which obfuscate gradients. For those defenses that have tried to make models more
robust, with our technique, an adversary can craft adversarial examples with no knowledge
of the defense. For defenses that attempt to detect the adversarial examples, with
our technique, an adversary only needs very limited information about the defense
to craft adversarial examples. We demonstrate our technique by applying it against
two defenses which make models more robust and two defenses which detect adversarial
examples.},
booktitle = {Proceedings of the 11th ACM Workshop on Artificial Intelligence and Security},
pages = {25–36},
numpages = {12},
keywords = {substitute training, adversarial example, gray-box attack, gradients obfuscation},
location = {Toronto, Canada},
series = {AISec '18}
}

@inproceedings{10.1145/3394486.3403052,
author = {Wang, Yue and Wang, Ke and Miao, Chunyan},
title = {Truth Discovery against Strategic Sybil Attack in Crowdsourcing},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403052},
doi = {10.1145/3394486.3403052},
abstract = {Crowdsourcing is an information system for recruiting online workers to perform human
intelligent tasks (HITs) that are hard for computers. Due to the openness of crowdsourcing,
dynamic online workers with different knowledge backgrounds might give conflicting
labels to a task. With the assumption that workers provide their labels independently,
most existing works aggregate worker labels in a voting manner, which is vulnerable
to Sybil attack where the attacker earns easy rewards by coordinating several Sybil
workers to share a randomized label on each task for dominating the aggregation result.
A strategic Sybil attacker also attempts to evade Sybil detection. In this paper,
we propose a novel approach, called TDSSA (Truth Discovery against Strategic Sybil
Attack), to defend against strategic Sybil attack. Experimental results on real-world
and synthetic datasets indicate that TDSSA ensures more accurate inference of true
labels under various Sybil attacking scenarios, as compared to state-of-the-art methods.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {95–104},
numpages = {10},
keywords = {quality control, Sybil defense, crowdsourcing},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@inproceedings{10.1145/3203422.3203433,
author = {Liu, Chen and Yang, Zhiliu and Blasingame, Zander and Torres, Gildo and Bruska, James},
title = {Detecting Data Exploits Using Low-Level Hardware Information: A Short Time Series Approach},
year = {2018},
isbn = {9781450357579},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3203422.3203433},
doi = {10.1145/3203422.3203433},
abstract = {In recent years, scale, frequency and complexity of cyber-attacks have been continuously
on the rise. As a result, it has significantly impacted our daily lives and society
as a whole. Never before have we had such an urgent need to defend against cyber-attacks.
Previous studies suggest that it is possible to detect rootkits and control-flow attacks
with high accuracy using information collected from hardware level. For data-only
exploits, however, where the control-flow of the victim application is strictly conserved
while its behavior may only be slightly modified, high accuracy detection is much
more difficult to achieve. In this study, we propose the use of low-level hardware
information collected as a short time series for the detection of data-only malware
attacks. We employed several representative classification algorithms, e.g., linear
regression (LR), autoencoder (AE), stacked denoising autoencoder (SDA), and echo state
network (ESN). We build one-class classifiers that either use individual samples collected
via monitoring hardware-level events or use multiple samples of hardware events collected
at different time during execution, but all with only the knowledge from regular behavior.
Using several real-life attacks as case studies, we examined their detection accuracy
when confronted with malicious behavior. Our experimental results show that our SDA-
and ESN-based approaches can achieve an average detection accuracy of 97.75% and 98.36%
for the exploits studied, respectively. Our study suggests that when the hardware
events are monitored at different time spots during the execution of the vulnerable
application, our SDA- and ESN-based approaches have the potential to boost the detection
accuracy for data exploits.},
booktitle = {Proceedings of the First Workshop on Radical and Experiential Security},
pages = {41–47},
numpages = {7},
keywords = {anomaly detection, machine learning, data-only exploits, hardware performance counters},
location = {Incheon, Republic of Korea},
series = {RESEC '18}
}

@inproceedings{10.1145/2906388.2906420,
author = {Wang, Gang and Wang, Bolun and Wang, Tianyi and Nika, Ana and Zheng, Haitao and Zhao, Ben Y.},
title = {Defending against Sybil Devices in Crowdsourced Mapping Services},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906420},
doi = {10.1145/2906388.2906420},
abstract = {Real-time crowdsourced maps such as Waze provide timely updates on traffic, congestion,
accidents and points of interest. In this paper, we demonstrate how lack of strong
location authentication allows creation of software-based Sybil devices that expose
crowdsourced map systems to a variety of security and privacy attacks. Our experiments
show that a single Sybil device with limited resources can cause havoc on Waze, reporting
false congestion and accidents and automatically rerouting user traffic. More importantly,
we describe techniques to generate Sybil devices at scale, creating armies of virtual
vehicles capable of remotely tracking precise movements for large user populations
while avoiding detection. We propose a new approach to defend against Sybil devices
based on co-location edges, authenticated records that attest to the one-time physical
co-location of a pair of devices. Over time, co-location edges combine to form large
proximity graphs that attest to physical interactions between devices, allowing scalable
detection of virtual vehicles. We demonstrate the efficacy of this approach using
large-scale simulations, and discuss how they can be used to dramatically reduce the
impact of attacks against crowdsourced mapping services.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {179–191},
numpages = {13},
keywords = {crowdsourcing, sybil attack, mobile maps},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/3337167.3337168,
author = {Torres, Gildo and Yang, Zhiliu and Blasingame, Zander and Bruska, James and Liu, Chen},
title = {Detecting Non-Control-Flow Hijacking Attacks Using Contextual Execution Information},
year = {2019},
isbn = {9781450372268},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3337167.3337168},
doi = {10.1145/3337167.3337168},
abstract = {In recent years, we see a rise of non-control-flow hijacking attacks, which manipulate
key data elements to corrupt the integrity of a victim application while upholding
a valid control-flow during its execution. Consequently, they are more difficult to
be detected hence prevented with traditional mitigation techniques that target control-oriented
attacks. In this work, we propose a methodology for the detection of non-control-flow
hijacking attacks via employing low-level hardware information formatted as time series.
Using architectural and micro-architectural hardware event counts, we model the regular
execution behavior of the application(s) of interest, in an effort to detect abnormal
execution behavior taking place at the vicinity of the vulnerability. We employed
three distinct anomaly detection models: a traditional support vector machine (SVM),
an echo state network (ESN), and a heavily modified k-nearest neighbors (KNN) model.
We evaluated the proposed methodology using seven real-world non-control-flow hijacking
exploits that target two vulnerabilities in modern web servers and three vulnerabilities
in the OpenSSL library. Because our proposed detection methodology employs the contextual
information across the temporal domain, we are able to achieve an average classification
accuracy of 99.36%, with a false positive rate (FPR) of 0.79% and false negative rate
(FNR) of 0.53%, respectively.},
booktitle = {Proceedings of the 8th International Workshop on Hardware and Architectural Support for Security and Privacy},
articleno = {1},
numpages = {8},
keywords = {Anomaly Detection, Hardware Performance Counters, Machine Learning, Encryption-Downgrade Attacks, Data-Only Attacks},
location = {Phoenix, AZ, USA},
series = {HASP '19}
}

@article{10.1145/1952982.1952989,
author = {Dong, Jing and Curtmola, Reza and Nita-Rotaru, Cristina},
title = {Practical Defenses against Pollution Attacks in Wireless Network Coding},
year = {2011},
issue_date = {May 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {1},
issn = {1094-9224},
url = {https://doi.org/10.1145/1952982.1952989},
doi = {10.1145/1952982.1952989},
abstract = {Recent studies have shown that network coding can provide significant benefits to
network protocols, such as increased throughput, reduced network congestion, higher
reliability, and lower power consumption. The core principle of network coding is
that intermediate nodes actively mix input packets to produce output packets. This
mixing subjects network coding systems to a severe security threat, known as a pollution
attack, where attacker nodes inject corrupted packets into the network. Corrupted
packets propagate in an epidemic manner, depleting network resources and significantly
decreasing throughput. Pollution attacks are particularly dangerous in wireless networks,
where attackers can easily inject packets or compromise devices due to the increased
network vulnerability.In this article, we address pollution attacks against network
coding systems in wireless mesh networks. We demonstrate that previous solutions are
impractical in wireless networks, incurring an unacceptable high degradation of throughput.
We propose a lightweight scheme, DART, that uses time-based authentication in combination
with random linear transformations to defend against pollution attacks. We further
improve system performance and propose EDART, which enhances DART with an optimistic
forwarding scheme. We also propose efficient attacker identification schemes for both
DART and EDART that enable quick attacker isolation and the selection of attacker-free
paths, achieving additional performance improvement. A detailed security analysis
shows that the probability of a polluted packet passing our verification procedure
is very low (less than 0.002% in typical settings). Performance results using the
well-known MORE protocol and realistic link quality measurements from the Roofnet
experimental testbed show that our schemes improve system performance over 20 times
compared with previous solutions.},
journal = {ACM Trans. Inf. Syst. Secur.},
month = jun,
articleno = {7},
numpages = {31},
keywords = {wireless network security, security, network coding security, pollution attacks, Network coding}
}

@inbook{10.1145/3447786.3456235,
author = {Ngoc, Tu Dinh and Teabe, Boris and Tchana, Alain and Muller, Gilles and Hagimont, Daniel},
title = {Mitigating Vulnerability Windows with Hypervisor Transplant},
year = {2021},
isbn = {9781450383349},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447786.3456235},
abstract = {The vulnerability window of a hypervisor regarding a given security flaw is the time
between the identification of the flaw and the integration of a correction/patch in
the running hypervisor. Most vulnerability windows, regardless of severity, are long
enough (several days) that attackers have time to perform exploits. Nevertheless,
the number of critical vulnerabilities per year is low enough to allow an exceptional
solution. This paper introduces hypervisor transplant, a solution for addressing vulnerability
window of critical flaws. It involves temporarily replacing the current datacenter
hypervisor (e.g., Xen) which is subject to a critical security flaw, by a different
hypervisor (e.g., KVM) which is not subject to the same vulnerability.We build HyperTP,
a generic framework which combines in a unified way two approaches: in-place server
micro-reboot-based hypervisor transplant (noted InPlaceTP) and live VM migration-based
hypervisor transplant (noted MigrationTP). We describe the implementation of HyperTP
and its extension for transplanting Xen with KVM and vice versa. We also show that
HyperTP is easy to integrate with the OpenStack cloud computing platform. Our evaluation
results show that HyperTP delivers satisfactory performance: (1) MigrationTP takes
the same time and impacts virtual machines (VMs) with the same performance degradation
as normal live migration. (2) the downtime imposed by InPlaceTP on VMs is in the same
order of magnitude (1.7 seconds for a VM with 1 vCPU and 1 GB of RAM) as in-place
upgrade of homogeneous hypervisors based on server micro-reboot.},
booktitle = {Proceedings of the Sixteenth European Conference on Computer Systems},
pages = {162–177},
numpages = {16}
}

@inproceedings{10.1145/3411508.3421381,
author = {Shumailov, Ilia and Zhao, Yiren and Mullins, Robert and Anderson, Ross},
title = {Towards Certifiable Adversarial Sample Detection},
year = {2020},
isbn = {9781450380942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411508.3421381},
doi = {10.1145/3411508.3421381},
abstract = {Convolutional Neural Networks (CNNs) are deployed in more and more classification
systems, but adversarial samples can be maliciously crafted to trick them, and are
becoming a real threat. There have been various proposals to improve CNNs' adversarial
robustness but these all suffer performance penalties or have other limitations. In
this paper, we offer a new approach in the form of a certifiable adversarial detection
scheme, the Certifiable Taboo Trap (CTT). This system, in theory, can provide certifiable
guarantees of detectability of a range of adversarial inputs for certain l-∞ sizes.
We develop and evaluate several versions of CTT with different defense capabilities,
training overheads and certifiability on adversarial samples. In practice, against
adversaries with various l-p norms, CTT outperforms existing defense methods that
focus purely on improving network robustness. We show that CTT has small false positive
rates on clean test data, minimal compute overheads when deployed, and can support
complex security policies.},
booktitle = {Proceedings of the 13th ACM Workshop on Artificial Intelligence and Security},
pages = {13–24},
numpages = {12},
keywords = {machine learning security, anomaly detection, certifiable robustness, detection, robustness, adversarial detection, certifiable detection},
location = {Virtual Event, USA},
series = {AISec'20}
}

@inproceedings{10.1145/3372297.3417258,
author = {Shi, Chenghui and Ji, Shouling and Liu, Qianjun and Liu, Changchang and Chen, Yuefeng and He, Yuan and Liu, Zhe and Beyah, Raheem and Wang, Ting},
title = {Text Captcha Is Dead? A Large Scale Deployment and Empirical Study},
year = {2020},
isbn = {9781450370899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3372297.3417258},
doi = {10.1145/3372297.3417258},
abstract = {The development of deep learning techniques has significantly increased the ability
of computers to recognize CAPTCHA (Completely Automated Public Turing test to tell
Computers and Humans Apart), thus breaking or mitigating the security of existing
captcha schemes. To protect against these attacks, recent works have been proposed
to leverage adversarial machine learning to perturb captcha pictures. However, they
either require the prior knowledge of captcha solving models or lack adaptivity to
the evolving behaviors of attackers. Most importantly, none of them has been deployed
in practical applications, and their practical applicability and effectiveness are
unknown.In this work, we introduce advCAPTCHA, a practical adversarial captcha generation
system that can defend against deep learning based captcha solvers, and deploy it
on a large-scale online platform with near billion users. To the best of our knowledge,
this is the first such work that has been deployed on international large-scale online
platforms. By applying adversarial learning techniques in a novel manner, advCAPTCHA
can generate effective adversarial captchas to significantly reduce the success rate
of attackers, which has been demonstrated by a large-scale online study. Furthermore,
we also validate the feasibility of advCAPTCHA in practical applications, as well
as its robustness in defending against various attacks. We leverage the existing user
risk analysis system to identify potential attackers and serve advCAPTCHA to them.
We then use their answers as queries to the attack model. In this manner, advCAPTCHA
can be adapted/fine-tuned to accommodate the attack model evolution. Overall, advCAPTCHA
can serve as a key enabler for generating robust captchas in practice and providing
useful guidelines for captcha developers and practitioners.},
booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1391–1406},
numpages = {16},
keywords = {adversarial learning, usable study, text captcha},
location = {Virtual Event, USA},
series = {CCS '20}
}

@inproceedings{10.1145/3419394.3423644,
author = {Alice and Bob and Carol and Beznazwy, Jan and Houmansadr, Amir},
title = {How China Detects and Blocks Shadowsocks},
year = {2020},
isbn = {9781450381383},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3419394.3423644},
doi = {10.1145/3419394.3423644},
abstract = {Shadowsocks is one of the most popular circumvention tools in China. Since May 2019,
there have been numerous anecdotal reports of the blocking of Shadowsocks from Chinese
users. In this study, we reveal how the Great Firewall of China (GFW) detects and
blocks Shadowsocks and its variants. Using measurement experiments, we find that the
GFW uses the length and entropy of the first data packet in each connection to identify
probable Shadowsocks traffic, then sends seven different types of active probes, in
different stages, to the corresponding servers to test whether its guess is correct.We
developed a prober simulator to analyze the effect of different types of probes on
various Shadowsocks implementations, and used it to infer what vulnerabilities are
exploited by the censor. We fingerprinted the probers and found differences relative
to previous work on active probing. A network-level side channel reveals that the
probers, which use thousands of IP addresses, are likely controlled by a set of centralized
structures.Based on our gained understanding, we present a temporary workaround that
successfully mitigates the traffic analysis attack by the GFW. We further discuss
essential strategies to defend against active probing. We responsibly disclosed our
findings and suggestions to Shadowsocks developers, which has led to more censorship-resistant
tools.},
booktitle = {Proceedings of the ACM Internet Measurement Conference},
pages = {111–124},
numpages = {14},
keywords = {active probing, Shadowsocks, censorship circumvention, Great Firewall of China},
location = {Virtual Event, USA},
series = {IMC '20}
}

@inproceedings{10.1145/3407023.3409312,
author = {Bendiab, Gueltoum and Grammatikakis, Konstantinos-Panagiotis and Koufos, Ioannis and Kolokotronis, Nicholas and Shiaeles, Stavros},
title = {Advanced Metering Infrastructures: Security Risks and Mitigation},
year = {2020},
isbn = {9781450388337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3407023.3409312},
doi = {10.1145/3407023.3409312},
abstract = {Energy providers are moving to the smart meter era, encouraging consumers to install,
free of charge, these devices in their homes, automating consumption readings submission
and making consumers life easier. However, the increased deployment of such smart
devices brings a lot of security and privacy risks. In order to overcome such risks,
Intrusion Detection Systems are presented as pertinent tools that can provide network-level
protection for smart devices deployed in home environments. In this context, this
paper is exploring the problems of Advanced Metering Infrastructures (AMI) and proposing
a novel Machine Learning (ML) Intrusion Prevention System (IPS) to get optimal decisions
based on a variety of factors and graphical security models able to tackle zero-day
attacks.},
booktitle = {Proceedings of the 15th International Conference on Availability, Reliability and Security},
articleno = {113},
numpages = {8},
keywords = {power grid, attack mitigation, graphical security models, intrusion detection, cyber-security, malware detection},
location = {Virtual Event, Ireland},
series = {ARES '20}
}

@inproceedings{10.1145/3243734.3243768,
author = {Sirinam, Payap and Imani, Mohsen and Juarez, Marc and Wright, Matthew},
title = {Deep Fingerprinting: Undermining Website Fingerprinting Defenses with Deep Learning},
year = {2018},
isbn = {9781450356930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3243734.3243768},
doi = {10.1145/3243734.3243768},
abstract = {Website fingerprinting enables a local eavesdropper to determine which websites a
user is visiting over an encrypted connection. State-of-the-art website fingerprinting
attacks have been shown to be effective even against Tor. Recently, lightweight website
fingerprinting defenses for Tor have been proposed that substantially degrade existing
attacks: WTF-PAD and Walkie-Talkie. In this work, we present Deep Fingerprinting (DF),
a new website fingerprinting attack against Tor that leverages a type of deep learning
called Convolutional Neural Networks (CNN) with a sophisticated architecture design,
and we evaluate this attack against WTF-PAD and Walkie-Talkie. The DF attack attains
over 98% accuracy on Tor traffic without defenses, better than all prior attacks,
and it is also the only attack that is effective against WTF-PAD with over 90% accuracy.
Walkie-Talkie remains effective, holding the attack to just 49.7% accuracy. In the
more realistic open-world setting, our attack remains effective, with 0.99 precision
and 0.94 recall on undefended traffic. Against traffic defended with WTF-PAD in this
setting, the attack still can get 0.96 precision and 0.68 recall. These findings highlight
the need for effective defenses that protect against this new attack and that could
be deployed in Tor.},
booktitle = {Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1928–1943},
numpages = {16},
keywords = {privacy, deep learning, Tor, website fingerprinting},
location = {Toronto, Canada},
series = {CCS '18}
}

@inproceedings{10.1145/3319535.3339815,
author = {Cao, Yulong and Xiao, Chaowei and Cyr, Benjamin and Zhou, Yimeng and Park, Won and Rampazzi, Sara and Chen, Qi Alfred and Fu, Kevin and Mao, Z. Morley},
title = {Adversarial Sensor Attack on LiDAR-Based Perception in Autonomous Driving},
year = {2019},
isbn = {9781450367479},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3319535.3339815},
doi = {10.1145/3319535.3339815},
abstract = {In Autonomous Vehicles (AVs), one fundamental pillar is perception,which leverages
sensors like cameras and LiDARs (Light Detection and Ranging) to understand the driving
environment. Due to its direct impact on road safety, multiple prior efforts have
been made to study its the security of perception systems. In contrast to prior work
that concentrates on camera-based perception, in this work we perform the first security
study of LiDAR-based perception in AV settings, which is highly important but unexplored.
We consider LiDAR spoofing attacks as the threat model and set the attack goal as
spoofing obstacles close to the front of a victim AV. We find that blindly applying
LiDAR spoofing is insufficient to achieve this goal due to the machine learning-based
object detection process.Thus, we then explore the possibility of strategically controlling
the spoofed attack to fool the machine learning model. We formulate this task as an
optimization problem and design modeling methods for the input perturbation function
and the objective function.We also identify the inherent limitations of directly solving
the problem using optimization and design an algorithm that combines optimization
and global sampling, which improves the attack success rates to around 75%. As a case
study to understand the attack impact at the AV driving decision level, we construct
and evaluate two attack scenarios that may damage road safety and mobility.We also
discuss defense directions at the AV system, sensor, and machine learning model levels.},
booktitle = {Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security},
pages = {2267–2281},
numpages = {15},
keywords = {adversarial machine learning, sensor attack, autonomous driving},
location = {London, United Kingdom},
series = {CCS '19}
}

@inproceedings{10.1145/3018896.3056791,
author = {Rizvi, Syed and Willett, Jonathan and Perino, Donte and Vasbinder, Tyler and Marasco, Seth},
title = {Protecting an Automobile Network Using Distributed Firewall System},
year = {2017},
isbn = {9781450347747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3018896.3056791},
doi = {10.1145/3018896.3056791},
abstract = {As the automobile industry continues to incorporate more technology into cars, the
security of the "automobile network" portion of that technology is in need of tremendous
improvement. The communications between the in-vehicle infotainment (IVI) systems
and the essential safety systems (e.g., anti-lock brake systems) should remain secure.
However, there are few to no security measures currently implemented in an automobile
network. This implies that if an attacker could break into a modern vehicle's IVI
system, they could possibly endanger drivers, passengers, and others. Any of the integral
mechanisms of the vehicle connected to the IVI system could be open to vulnerabilities.
To protect automobile networks from threats, we present a novel Hybrid Security System
(HSS). The proposed HSS uses the distributed firewalls to filter malicious content
(e.g., data packets) placed at each module and an electronic control unit (ECU). The
HSS creates two layers of defense within an automobile network that allows flexibility
for manufactures who want extra security for their cars without causing abandonment
or redesigning their current security architectures. Our proposed HSS is unique from
other existing solutions in that it operates on a universal platform that can reach
across all automobile manufacturers.},
booktitle = {Proceedings of the Second International Conference on Internet of Things, Data and Cloud Computing},
articleno = {174},
numpages = {6},
keywords = {attacks, CAR security, firewalls, automobile security, packet filtering, network security, threats},
location = {Cambridge, United Kingdom},
series = {ICC '17}
}

@inproceedings{10.1145/3264888.3264894,
author = {Narayanan, Vedanth and Bobba, Rakesh B.},
title = {Learning Based Anomaly Detection for Industrial Arm Applications},
year = {2018},
isbn = {9781450359924},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3264888.3264894},
doi = {10.1145/3264888.3264894},
abstract = {Smart Manufacturing (SM) is envisioned to make manufacturing processes more efficient
through automation and integration of networked information systems. Robotic arms
are integral to this vision. However the benefits of SM, enabled by automation and
networking, also come with cyber risks. In this work, we propose an anomaly detection
framework for robotic arms in a manufacturing pipeline and integrate it into Robot
Operating System (ROS), a middleware framework whose variants are being considered
for deployment in industrial environments for flexible automation. In particular,
we explore whether the repetitive behavior of an industrial arm can be leveraged to
detect anomalous behaviour that may indicate an intrusion. Based on a learned model,
we classify a robot's actions as anomalous or benign. We introduce the notion of a 'tolerance envelope' to train a supervised learning model. Our empirical evaluation
shows that anomalies that take the robot out of pre-determined tolerance levels can
be detected with high accuracy.},
booktitle = {Proceedings of the 2018 Workshop on Cyber-Physical Systems Security and PrivaCy},
pages = {13–23},
numpages = {11},
keywords = {smart manufacturing, robot operating system, robotics, tolerance envelope, anomaly detection},
location = {Toronto, Canada},
series = {CPS-SPC '18}
}

@inproceedings{10.1145/3378936.3378938,
author = {Kwon, Hyun and Yoon, Hyunsoo and Park, Ki-Woong},
title = {FriendNet Backdoor: Indentifying Backdoor Attack That is Safe for Friendly Deep Neural Network},
year = {2020},
isbn = {9781450376907},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3378936.3378938},
doi = {10.1145/3378936.3378938},
abstract = {Deep neural networks (DNNs) provide good performance in image recognition, speech
recognition and pattern analysis. However, DNNs are vulnerable to backdoor attacks.
Backdoor attacks allow attackers to proactively access training data of DNNs to train
additional malicious data, including the specific trigger. In normal times, DNNs correctly
classify the normal data, but the malicious data with the specific trigger trained
by attackers can cause misclassification of DNNs. For example, if an attacker sets
up a road sign that includes a specific trigger, an autonomous vehicle equipped with
a DNN may misidentify the road sign and cause an accident. Thus, an attacker can use
a backdoor attack to threaten the DNN at any time. However, this backdoor attack can
be useful in certain situations, such as in military situations. Since there is a
mixture of enemy and friendly force in the military situations, it is necessary to
cause misclassification of the enemy equipment and classification of the friendly
equipment. Therefore, it is necessary to make backdoor attacks that are correctly
recognized by friendly equipment and misrecognized by the enemy equipment. In this
paper, we propose a friendnet backdoor that is correctly recognized by friendly classifier
and misclassified by the enemy classifier. This method additionally trains the friendly
and enemy classifier with the proposed data, including the specific trigger that is
correctly recognized by friendly classifier and misclassified by enemy classifier.
We used MNIST and Fashion-MNIST as experimental datasets and Tensorflow as a machine
learning library. Experimental results show that the proposed method in MNIST and
Fashion-MNIST has 100% attack success rate of the enemy classifier and the 99.21%
and 92.3% accuracy of the friendly classifier, respectively.},
booktitle = {Proceedings of the 3rd International Conference on Software Engineering and Information Management},
pages = {53–57},
numpages = {5},
keywords = {deep neural network, poisoning attack, adversarial example, backdoor attack, Machine learning},
location = {Sydney, NSW, Australia},
series = {ICSIM '20}
}

@inproceedings{10.1145/3195970.3195979,
author = {Chaudhuri, Sumanta},
title = {A Security Vulnerability Analysis of SoCFPGA Architectures},
year = {2018},
isbn = {9781450357005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3195970.3195979},
doi = {10.1145/3195970.3195979},
abstract = {SoCFPGAs or FPGAs integrated on the same die with chip multi processors have made
it to the market in the past years. In this article we analyse various security loopholes,
existing precautions and countermeasures in these architectures. We consider Intel
Cyclone/Arria devices and Xilinx Zynq/Ultrascale devices. We present an attacker model
and we highlight three different types of attacks namely direct memory attacks, cache
timing attacks, and rowhammer attacks that can be used on inadequately protected systems.
We present and compare existing security mechanisms in this architectures, and their
shortfalls. We present real life example of these attacks and further countermeasures
to secure systems based on SoCFPGAs.},
booktitle = {Proceedings of the 55th Annual Design Automation Conference},
articleno = {139},
numpages = {6},
location = {San Francisco, California},
series = {DAC '18}
}

@inproceedings{10.1145/2068816.2068841,
author = {Yang, Zhi and Wilson, Christo and Wang, Xiao and Gao, Tingting and Zhao, Ben Y. and Dai, Yafei},
title = {Uncovering Social Network Sybils in the Wild},
year = {2011},
isbn = {9781450310130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2068816.2068841},
doi = {10.1145/2068816.2068841},
abstract = {Sybil accounts are fake identities created to unfairly increase the power or resources
of a single user. Researchers have long known about the existence of Sybil accounts
in online communities such as file-sharing systems, but have not been able to perform
large scale measurements to detect them or measure their activities. In this paper,
we describe our efforts to detect, characterize and understand Sybil account activity
in the Renren online social network (OSN). We use ground truth provided by Renren
Inc. to build measurement based Sybil account detectors, and deploy them on Renren
to detect over 100,000 Sybil accounts. We study these Sybil accounts, as well as an
additional 560,000 Sybil accounts caught by Renren, and analyze their link creation
behavior. Most interestingly, we find that contrary to prior conjecture, Sybil accounts
in OSNs do not form tight-knit communities. Instead, they integrate into the social
graph just like normal users. Using link creation timestamps, we verify that the large
majority of links between Sybil accounts are created accidentally, unbeknownst to
the attacker. Overall, only a very small portion of Sybil accounts are connected to
other Sybils with social links. Our study shows that existing Sybil defenses are unlikely
to succeed in today's OSNs, and we must design new techniques to effectively detect
and defend against Sybil attacks.},
booktitle = {Proceedings of the 2011 ACM SIGCOMM Conference on Internet Measurement Conference},
pages = {259–268},
numpages = {10},
keywords = {sybil accounts, online social networks},
location = {Berlin, Germany},
series = {IMC '11}
}

@inproceedings{10.1145/2976749.2978361,
author = {Holzinger, Philipp and Triller, Stefan and Bartel, Alexandre and Bodden, Eric},
title = {An In-Depth Study of More Than Ten Years of Java Exploitation},
year = {2016},
isbn = {9781450341394},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2976749.2978361},
doi = {10.1145/2976749.2978361},
abstract = {When created, the Java platform was among the first runtimes designed with security
in mind. Yet, numerous Java versions were shown to contain far-reaching vulnerabilities,
permitting denial-of-service attacks or even worse allowing intruders to bypass the
runtime's sandbox mechanisms, opening the host system up to many kinds of further
attacks.This paper presents a systematic in-depth study of 87 publicly available Java
exploits found in the wild. By collecting, minimizing and categorizing those exploits,
we identify their commonalities and root causes, with the goal of determining the
weak spots in the Java security architecture and possible countermeasures.Our findings
reveal that the exploits heavily rely on a set of nine weaknesses, including unauthorized
use of restricted classes and confused deputies in combination with caller-sensitive
methods. We further show that all attack vectors implemented by the exploits belong
to one of three categories: single-step attacks, restricted-class attacks, and information
hiding attacks.The analysis allows us to propose ideas for improving the security
architecture to spawn further research in this area.},
booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
pages = {779–790},
numpages = {12},
keywords = {access control, java security, security analysis, exploits},
location = {Vienna, Austria},
series = {CCS '16}
}

@inproceedings{10.1145/3372297.3423351,
author = {De la Cadena, Wladimir and Mitseva, Asya and Hiller, Jens and Pennekamp, Jan and Reuter, Sebastian and Filter, Julian and Engel, Thomas and Wehrle, Klaus and Panchenko, Andriy},
title = {TrafficSliver: Fighting Website Fingerprinting Attacks with Traffic Splitting},
year = {2020},
isbn = {9781450370899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3372297.3423351},
doi = {10.1145/3372297.3423351},
abstract = {Website fingerprinting (WFP) aims to infer information about the content of encrypted
and anonymized connections by observing patterns of data flows based on the size and
direction of packets. By collecting traffic traces at a malicious Tor entry node ---
one of the weakest adversaries in the attacker model of Tor --- a passive eavesdropper
can leverage the captured meta-data to reveal the websites visited by a Tor user.
As recently shown, WFP is significantly more effective and realistic than assumed.
Concurrently, former WFP defenses are either infeasible for deployment in real-world
settings or defend against specific WFP attacks only.To limit the exposure of Tor
users to WFP, we propose novel lightweight WFP defenses, TrafficSliver, which successfully
counter today's WFP classifiers with reasonable bandwidth and latency overheads and,
thus, make them attractive candidates for adoption in Tor. Through user-controlled
splitting of traffic over multiple Tor entry nodes, TrafficSliver limits the data
a single entry node can observe and distorts repeatable traffic patterns exploited
by WFP attacks. We first propose a network-layer defense, in which we apply the concept
of multipathing entirely within the Tor network. We show that our network-layer defense
reduces the accuracy from more than 98% to less than 16% for all state-of-the-art
WFP attacks without adding any artificial delays or dummy traffic. We further suggest
an elegant client-side application-layer defense, which is independent of the underlying
anonymization network. By sending single HTTP requests for different web objects over
distinct Tor entry nodes, our application-layer defense reduces the detection rate
of WFP classifiers by almost 50 percentage points. Although it offers lower protection
than our network-layer defense, it provides a security boost at the cost of a very
low implementation overhead and is fully compatible with today's Tor network.},
booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1971–1985},
numpages = {15},
keywords = {website fingerprinting, traffic analysis, onion routing, web privacy, privacy, anonymous communication},
location = {Virtual Event, USA},
series = {CCS '20}
}

@inproceedings{10.1145/3355402.3355420,
author = {Rodtook, Annupan and Chucherd, Sirikan},
title = {Automated Optic Disc Localization Algorithm by Combining A Blob of Corner Patterns, Brightness and Circular Structures Models},
year = {2019},
isbn = {9781450372282},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3355402.3355420},
doi = {10.1145/3355402.3355420},
abstract = {Automatic localization of optic disc (OD) is an important step of diabetic retinopathy
(DR) detection. This paper presents a methodology to locate the optic disc within
the field of view (FOV) of retina image. The information taken from corner patterns
of branching and cross-over points of blood vessels, the brightness and circular structure
are combined to identify the location of OD. Moreover, a step of the FOV background
estimation is designed to increase robustness of the proposed method due to the incomplete
circular shape of OD caused by vascular tortuosity effect. The method was evaluated
on the three public datasets as DIARETDB0, DIARETDB1, and MESSIDOR. The accuracy rate
was 99.23%, 100%, and 99.25%, respectively. It obtained valid locations of OD in 615
out of the 619 images of the three datasets.},
booktitle = {Proceedings of the 2019 International Conference on Information Technology and Computer Communications},
pages = {6–12},
numpages = {7},
keywords = {circular-like filtering, Vessel approximation, skeleton, optic disc localization, blob detection},
location = {Singapore, Singapore},
series = {ITCC 2019}
}

@article{10.1145/3374749,
author = {Tian, Zhihong and Luo, Chaochao and Lu, Hui and Su, Shen and Sun, Yanbin and Zhang, Man},
title = {User and Entity Behavior Analysis under Urban Big Data},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {3},
issn = {2691-1922},
url = {https://doi.org/10.1145/3374749},
doi = {10.1145/3374749},
abstract = {Recently, the urban network infrastructure has undergone a rapid expansion that is
increasingly generating a large quantity of data and transforming our cities into
smart cities. However, serious security problems arise with this development with
more and more smart devices collecting private information under smart city scenario.
In this article, we investigate the task of detecting insiders’ anomalous behaviors
to prevent urban big data leakage. Specifically, we characterize a user's daily activities
from four perspectives and use several deep learning algorithms (long short-term memory
(LSTM) and convolutional LSTM (convLSTM)) to calculate deviations between realistic
actions and normalcy of daily behaviors and use multilayer perceptron (MLP) to identify
abnormal behaviors according to those deviations. To evaluate the proposed multimodel-based
system (MBS), we conducted experiments on the CERT (United States Computer Emergency
Readiness Team) dataset. The experimental results show that our proposed MBS has a
remarkable ability to learn the normal pattern of users’ daily activities and detect
anomalous behaviors.},
journal = {ACM/IMS Trans. Data Sci.},
month = sep,
articleno = {16},
numpages = {19},
keywords = {security, UEBA, anomaly detection, deep learning}
}

@article{10.1145/3154793,
author = {Gong, Neil Zhenqiang and Liu, Bin},
title = {Attribute Inference Attacks in Online Social Networks},
year = {2018},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1},
issn = {2471-2566},
url = {https://doi.org/10.1145/3154793},
doi = {10.1145/3154793},
abstract = {We propose new privacy attacks to infer attributes (e.g., locations, occupations,
and interests) of online social network users. Our attacks leverage seemingly innocent
user information that is publicly available in online social networks to infer missing
attributes of targeted users. Given the increasing availability of (seemingly innocent)
user information online, our results have serious implications for Internet privacy—private
attributes can be inferred from users’ publicly available data unless we take steps
to protect users from such inference attacks. To infer attributes of a targeted user,
existing inference attacks leverage either the user’s publicly available social friends
or the user’s behavioral records (e.g., the web pages that the user has liked on Facebook,
the apps that the user has reviewed on Google Play), but not both. As we will show,
such inference attacks achieve limited success rates. However, the problem becomes
qualitatively different if we consider both social friends and behavioral records.
To address this challenge, we develop a novel model to integrate social friends and
behavioral records, and design new attacks based on our model. We theoretically and
experimentally demonstrate the effectiveness of our attacks. For instance, we observe
that, in a real-world large-scale dataset with 1.1 million users, our attack can correctly
infer the cities a user lived in for 57% of the users; via confidence estimation,
we are able to increase the attack success rate to over 90% if the attacker selectively
attacks half of the users. Moreover, we show that our attack can correctly infer attributes
for significantly more users than previous attacks.},
journal = {ACM Trans. Priv. Secur.},
month = jan,
articleno = {3},
numpages = {30},
keywords = {privacy attack, Attribute inference, social-behavior-attribute network}
}

@inproceedings{10.1145/3385209.3385216,
author = {Kwon, Hyun and Roh, Jungmin and Yoon, Hyunsoo and Park, Ki-Woong},
title = {TargetNet Backdoor: Attack on Deep Neural Network with Use of Different Triggers},
year = {2020},
isbn = {9781450376594},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3385209.3385216},
doi = {10.1145/3385209.3385216},
abstract = {Deep neural networks (DNNs) provide good performance in image recognition, speech
recognition, and pattern analysis. However, DNNs are vulnerable to backdoor attacks.
Backdoor attacks allow attackers to proactively access DNN training data to train
it on additional data that are malicious, including a specific trigger. Normally,
DNNs correctly classify normal data, but malicious data with a specific trigger trained
by attackers can cause misclassification by DNNs. For example, if an attacker sets
up a road sign that includes a specific trigger, an autonomous vehicle equipped with
a DNN may misidentify the road sign and cause an accident. Thus, an attacker can use
a backdoor attack to threaten the DNN at any time. However, in certain cases, when
an attacker wants to perform a targeted attack, it may be desirable for the data introduced
through the backdoor to be misrecognized as a particular class chosen by the attacker
according to the position of a trigger. For example, if a specific trigger is attached
to the top right side of the road sign, it may be misunderstood as a left-turn sign;
if a specific trigger is attached to the top left side of the road sign, it may be
misunderstood as a right-turn sign; and if a specific trigger is attached to the bottom
left side of the road sign, it may be misunderstood as a U-turn sign. In this paper,
we propose the TargetNet backdoor, which is designed to be misidentified as a particular
target class chosen by the attacker according to a specific trigger location. The
proposed method additionally trains the target classifier on the TargetNet backdoor
data so that data with a trigger at a specific location will be misidentified as the
target class selected by the attacker. We used MNIST and Fashion-MNIST as experimental
datasets and Tensor-flow as a machine learning library. Experimental results show
that the proposed method applied to MNIST and Fashion-MNIST has a 100% attack success
rate for the TargetNet backdoor and 99.17% and 91.4% accuracy rates on normal test
data, respectively.},
booktitle = {Proceedings of the 2020 5th International Conference on Intelligent Information Technology},
pages = {140–145},
numpages = {6},
keywords = {adversarial example, poisoning attack, backdoor attack, deep neural network, Machine learning, targeted attack},
location = {Hanoi, Viet Nam},
series = {ICIIT 2020}
}

@inproceedings{10.1145/2746266.2746267,
author = {Carsten, Paul and Andel, Todd R. and Yampolskiy, Mark and McDonald, Jeffrey T.},
title = {In-Vehicle Networks: Attacks, Vulnerabilities, and Proposed Solutions},
year = {2015},
isbn = {9781450333450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2746266.2746267},
doi = {10.1145/2746266.2746267},
abstract = {Vehicles made within the past years have gradually become more and more complex. As
a result, the embedded computer systems that monitor and control these systems have
also grown in size and complexity. Unfortunately, the technology that protects them
from external attackers has not improved at a similar rate. In this paper we discuss
the vulnerabilities of modern in-vehicle networks, focusing on the Controller Area
Network (CAN) communications protocol as a primary attack vector. We discuss the vulnerabilities
of CAN, the types of attacks that can be used against it, and some of the solutions
that have been proposed to overcome these attacks.},
booktitle = {Proceedings of the 10th Annual Cyber and Information Security Research Conference},
articleno = {1},
numpages = {8},
keywords = {Automotive Vulnerabilities, In-Vehicle Networks, CAN bus},
location = {Oak Ridge, TN, USA},
series = {CISR '15}
}

@inproceedings{10.1145/3282373.3282400,
author = {Shaaban, Abdelkader Magdy and Schmittner, Christoph and Gruber, Thomas and Mohamed, A. Baith and Quirchmayr, Gerald and Schikuta, Erich},
title = {CloudWoT - A Reference Model for Knowledge-Based IoT Solutions},
year = {2018},
isbn = {9781450364799},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282373.3282400},
doi = {10.1145/3282373.3282400},
abstract = {Internet technology has changed how people work, live, communicate, learn and entertain.
The internet adoption is rising rapidly, thus creating a new industrial revolution
named "Industry 4.0". Industry 4.0 is the use of automation and data transfer in manufacturing
technologies. It fosters several technological concepts, one of these is the Internet
of Things (IoT). IoT technology is based on a big network of machines, objects, or
people called "things" interacting together to achieve a common goal. These things
are continuously generating vast amounts of data. Data understanding, processing,
securing and storing are significant challenges in the IoT technology which restricts
its development. This paper presents a new reference IoT model for future smart IoT
solutions called Cloud Web of Things (CloudWoT). CloudWoT aims to overcome these limitations
by combining IoT with edge computing, semantic web, and cloud computing. Additionally,
this work is concerned with the security issues which threatens data in IoT application
domains.},
booktitle = {Proceedings of the 20th International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {272–281},
numpages = {10},
keywords = {CloudWoT, IACS, Semantic Web, Cloud Computing, IoT, Edge Computing, CPPS},
location = {Yogyakarta, Indonesia},
series = {iiWAS2018}
}

@inproceedings{10.1145/3453688.3461760,
author = {Roshanisefat, Shervin and Mardani Kamali, Hadi and Homayoun, Houman and Sasan, Avesta},
title = {RANE: An Open-Source Formal De-Obfuscation Attack for Reverse Engineering of Logic Encrypted Circuits},
year = {2021},
isbn = {9781450383936},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3453688.3461760},
doi = {10.1145/3453688.3461760},
abstract = {To enable trust in the IC supply chain, logic locking as an IP protection technique
received significant attention in recent years. Over the years, by utilizing Boolean
satisfiability (SAT) solver and its derivations, many de-obfuscation attacks have
undermined the security of logic locking. Nonetheless, all these attacks receive the
inputs (locked circuits) in a very simplified format (Bench or remapped and translated
Verilog) with many limitations. This raises the bar for the usage of the existing
attacks for modeling and assessing new logic locking techniques, forcing the designers
to undergo many troublesome translations and simplifications. This paper introduces
the RANE Attack, an open-source CAD-based toolbox for evaluating the security of logic
locking mechanisms that implement a unique interface to use formal verification tools
without a need for any translation or simplification. The RANE attack not only performs
better compared to the existing de-obfuscation attacks, but it can also receive the
library-dependent logic-locked circuits with no limitation in written, elaborated,
or synthesized standard HDL, such as Verilog. We evaluated the capability/performance
of RANE on FOUR case studies, one is the first de-obfuscation attack model on FSM
locking solutions (e.g., HARPOON) in which the key is not a static bit-vector but
a sequence of input patterns.},
booktitle = {Proceedings of the 2021 on Great Lakes Symposium on VLSI},
pages = {221–228},
numpages = {8},
keywords = {de-obfuscation, logic locking, formal verification},
location = {Virtual Event, USA},
series = {GLSVLSI '21}
}

@inproceedings{10.1145/1966913.1966939,
author = {Yan, Guanhua and Chen, Guanling and Eidenbenz, Stephan and Li, Nan},
title = {Malware Propagation in Online Social Networks: Nature, Dynamics, and Defense Implications},
year = {2011},
isbn = {9781450305648},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1966913.1966939},
doi = {10.1145/1966913.1966939},
abstract = {Online social networks, which have been expanding at a blistering speed recently,
have emerged as a popular communication infrastructure for Internet users. Meanwhile,
malware that specifically target these online social networks are also on the rise.
In this work, we aim to investigate the characteristics of malware propagation in
online social networks. Our study is based on a dataset collected from a real-world
location-based online social network, which includes not only the social graph formed
by its users but also the users' activity events. We analyze the social structure
and user activity patterns of this network, and confirm that it is a typical online
social network, suggesting that conclusions drawn from this specific network can be
translated to other online social networks. We use extensive trace-driven simulation
to study the impact of initial infection, user click probability, social structure,
and activity patterns on malware propagation in online social networks. We also investigate
the performance of a few user-oriented and server-oriented defense schemes against
malware spreading in online social networks and identify key factors that affect their
effectiveness. We believe that this comprehensive study has deepened our understanding
of the nature of online social network malware and also shed light on how to defend
against them effectively.},
booktitle = {Proceedings of the 6th ACM Symposium on Information, Computer and Communications Security},
pages = {196–206},
numpages = {11},
keywords = {defense, malware propagation, online social networks},
location = {Hong Kong, China},
series = {ASIACCS '11}
}

@InProceedings{10.1145/3427228.3427285,
  author    = {Pu, Jiameng and Mangaokar, Neal and Wang, Bolun and Reddy, Chandan K and Viswanath, Bimal},
  booktitle = {Annual Computer Security Applications Conference},
  title     = {NoiseScope: Detecting Deepfake Images in a Blind Setting},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {913–927},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '20},
  abstract  = {Recent advances in Generative Adversarial Networks (GANs) have significantly improved
the quality of synthetic images or deepfakes. Photorealistic images generated by GANs
start to challenge the boundary of human perception of reality, and brings new threats
to many critical domains, e.g., journalism, and online media. Detecting whether an
image is generated by GAN or a real camera has become an important yet under-investigated
area. In this work, we propose a blind detection approach called NoiseScope for discovering
GAN images among other real images. A blind approach requires no a priori access to
GAN images for training, and demonstrably generalizes better than supervised detection
schemes. Our key insight is that, similar to images from cameras, GAN images also
carry unique patterns in the noise space. We extract such patterns in an unsupervised
manner to identify GAN images. We evaluate NoiseScope on 11 diverse datasets containing
GAN images, and achieve up to 99.68% F1 score in detecting GAN images. We test the
limitations of NoiseScope against a variety of countermeasures, observing that NoiseScope
holds robust or is easily adaptable.},
  doi       = {10.1145/3427228.3427285},
  isbn      = {9781450388580},
  keywords  = {Clustering, Blind Detection, Machine Learning, Deepfakes},
  location  = {Austin, USA},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3427228.3427285},
}

@inproceedings{10.1145/3374664.3375736,
author = {Ge, Huangyi and Chau, Sze Yiu and Ribeiro, Bruno and Li, Ninghui},
title = {Random Spiking and Systematic Evaluation of Defenses Against Adversarial Examples},
year = {2020},
isbn = {9781450371070},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3374664.3375736},
doi = {10.1145/3374664.3375736},
abstract = {Image classifiers often suffer from adversarial examples, which are generated by strategically
adding a small amount of noise to input images to trick classifiers into misclassification.
Over the years, many defense mechanisms have been proposed, and different researchers
have made seemingly contradictory claims on their effectiveness. We present an analysis
of possible adversarial models, and propose an evaluation framework for comparing
different defense mechanisms. As part of the framework, we introduce a more powerful
and realistic adversary strategy. Furthermore, we propose a new defense mechanism
called Random Spiking (RS), which generalizes dropout and introduces random noises
in the training process in a controlled manner. Evaluations under our proposed framework
suggest RS delivers better protection against adversarial examples than many existing
schemes.},
booktitle = {Proceedings of the Tenth ACM Conference on Data and Application Security and Privacy},
pages = {85–96},
numpages = {12},
keywords = {adversarial example, neural network, random spiking},
location = {New Orleans, LA, USA},
series = {CODASPY '20}
}

@inproceedings{10.1145/3386263.3407599,
author = {Zhang, Jiliang and Li, Chen and Ye, Jing and Qu, Gang},
title = {Privacy Threats and Protection in Machine Learning},
year = {2020},
isbn = {9781450379441},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386263.3407599},
doi = {10.1145/3386263.3407599},
abstract = {With the improvement of computing power and storage level, Machine Learning (ML),
especially Deep Learning (DL), has shown its capabilities beyond humans in areas such
as image recognition, speech processing, and content recommendation. However, the
data collected to build ML models often contains sensitive information, and models
may have high commercial value. Compared with the security problem of model prediction
errors caused by malicious external influences, privacy threats have not attracted
widespread attention, and they have characteristics that are difficult to define and
detect. This article reviews recent research progress on ML privacy. First, the privacy
threats on data and models in different scenarios are described in detail. Then, typical
privacy protection methods are introduced. Finally, the limitations and future development
trends of ML privacy research are discussed.},
booktitle = {Proceedings of the 2020 on Great Lakes Symposium on VLSI},
pages = {531–536},
numpages = {6},
keywords = {privacy protection, machine learning, privacy threats},
location = {Virtual Event, China},
series = {GLSVLSI '20}
}

@inproceedings{10.1145/3372297.3417270,
author = {Song, Congzheng and Raghunathan, Ananth},
title = {Information Leakage in Embedding Models},
year = {2020},
isbn = {9781450370899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3372297.3417270},
doi = {10.1145/3372297.3417270},
abstract = {Embeddings are functions that map raw input data to low-dimensional vector representations,
while preserving important semantic information about the inputs. Pre-training embeddings
on a large amount of unlabeled data and fine-tuning them for downstream tasks is now
a de facto standard in achieving state of the art learning in many domains.We demonstrate
that embeddings, in addition to encoding generic semantics, often also present a vector
that leaks sensitive information about the input data. We develop three classes of
attacks to systematically study information that might be leaked by embeddings. First,
embedding vectors can be inverted to partially recover some of the input data. As
an example, we show that our attacks on popular sentence embeddings recover between
50%--70% of the input words (F1 scores of 0.5--0.7). Second, embeddings may reveal
sensitive attributes inherent in inputs and independent of the underlying semantic
task at hand. Attributes such as authorship of text can be easily extracted by training
an inference model on just a handful of labeled embedding vectors. Third, embedding
models leak moderate amount of membership information for infrequent training data
inputs. We extensively evaluate our attacks on various state-of-the-art embedding
models in the text domain. We also propose and evaluate defenses that can prevent
the leakage to some extent at a minor cost in utility.},
booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
pages = {377–390},
numpages = {14},
keywords = {machine learning, privacy, embeddings},
location = {Virtual Event, USA},
series = {CCS '20}
}

@InProceedings{10.1145/3383313.3412243,
  author    = {Tang, Jiaxi and Wen, Hongyi and Wang, Ke},
  booktitle = {Fourteenth ACM Conference on Recommender Systems},
  title     = {Revisiting Adversarially Learned Injection Attacks Against Recommender Systems},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {318–327},
  publisher = {Association for Computing Machinery},
  series    = {RecSys '20},
  abstract  = {Recommender systems play an important role in modern information and e-commerce applications.
While increasing research is dedicated to improving the relevance and diversity of
the recommendations, the potential risks of state-of-the-art recommendation models
are under-explored, that is, these models could be subject to attacks from malicious
third parties, through injecting fake user interactions to achieve their purposes.
This paper revisits the adversarially-learned injection attack problem, where the
injected fake user ‘behaviors’ are learned locally by the attackers with their own
model – one that is potentially different from the model under attack, but shares
similar properties to allow attack transfer. We found that most existing works in
literature suffer from two major limitations: (1) they do not solve the optimization
problem precisely, making the attack less harmful than it could be, (2) they assume
perfect knowledge for the attack, causing the lack of understanding for realistic
attack capabilities. We demonstrate that the exact solution for generating fake users
as an optimization problem could lead to a much larger impact. Our experiments on
a real-world dataset reveal important properties of the attack, including attack transferability
and its limitations. These findings can inspire useful defensive methods against this
possible existing attack.},
  doi       = {10.1145/3383313.3412243},
  isbn      = {9781450375832},
  keywords  = {Security and Privacy, Adversarial Machine Learning, Recommender System},
  location  = {Virtual Event, Brazil},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3383313.3412243},
}

@inproceedings{10.1145/3359789.3359830,
author = {Wang, Chen and Anand, S Abhishek and Liu, Jian and Walker, Payton and Chen, Yingying and Saxena, Nitesh},
title = {Defeating Hidden Audio Channel Attacks on Voice Assistants via Audio-Induced Surface Vibrations},
year = {2019},
isbn = {9781450376280},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359789.3359830},
doi = {10.1145/3359789.3359830},
abstract = {Voice access technologies are widely adopted in mobile devices and voice assistant
systems as a convenient way of user interaction. Recent studies have demonstrated
a potentially serious vulnerability of the existing voice interfaces on these systems
to "hidden voice commands". This attack uses synthetically rendered adversarial sounds
embedded within a voice command to trick the speech recognition process into executing
malicious commands, without being noticed by legitimate users.In this paper, we employ
low-cost motion sensors, in a novel way, to detect these hidden voice commands. In
particular, our proposed system extracts and examines the unique audio signatures
of the issued voice commands in the vibration domain. We show that such signatures
of normal commands vs. synthetic hidden voice commands are distinctive, leading to
the detection of the attacks. The proposed system, which benefits from a speaker-motion
sensor setup, can be easily deployed on smartphones by reusing existing on-board motion
sensors or utilizing a cloud service that provides the relevant setup environment.
The system is based on the premise that while the crafted audio features of the hidden
voice commands may fool an authentication system in the audio domain, their unique
audio-induced surface vibrations captured by the motion sensor are hard to forge.
Our proposed system creates a harder challenge for the attacker as now it has to forge
the acoustic features in both the audio and vibration domains, simultaneously. We
extract the time and frequency domain statistical features, and the acoustic features
(e.g., chroma vectors and MFCCs) from the motion sensor data and use learning-based
methods for uniquely determining both normal commands and hidden voice commands. The
results show that our system can detect hidden voice commands vs. normal commands
with 99.9% accuracy by simply using the low-cost motion sensors that have very low
sampling frequencies.},
booktitle = {Proceedings of the 35th Annual Computer Security Applications Conference},
pages = {42–56},
numpages = {15},
keywords = {surface vibrations, voice access, hidden voice command detection, motion sensor},
location = {San Juan, Puerto Rico, USA},
series = {ACSAC '19}
}

@inproceedings{10.1145/3279755.3279762,
author = {Bakar, Abu and Hester, Josiah},
title = {Making Sense of Intermittent Energy Harvesting},
year = {2018},
isbn = {9781450360470},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3279755.3279762},
doi = {10.1145/3279755.3279762},
abstract = {Batteryless, energy harvesting sensing devices enable new applications and deployment
scenarios with their promise of zero maintenance, long lifetime, and small size. These
devices fail often and for variable lengths of time because of the unpredictability
of the energy harvesting source; be it solar, thermal, RF, or kinetic, making prediction
and planning difficult. This paper explores ways to make sense of energy harvesting
behaviors. We take known energy harvesting datasets, and create a few of our own,
then classify energy harvesting behavior into modes. Modes are periodic or repeated
elements caused by systematic or fundamental attributes of the energy harvesting environment.
We show the existence of these Energy Harvesting Modes using real world data and IV
surfaces created with the Ekho emulator, and then discuss how this powerful abstraction
could increase robustness and efficiency of design and development on intermittently
powered and energy harvesting computing devices.},
booktitle = {Proceedings of the 6th International Workshop on Energy Harvesting &amp; Energy-Neutral Sensing Systems},
pages = {32–37},
numpages = {6},
keywords = {intermittent computing, energy harvesting, IV surface},
location = {Shenzhen, China},
series = {ENSsys '18}
}

@inproceedings{10.1145/3371676.3371680,
author = {Chen, Biqiong and Liu, Yanhua and Li, Shijin and Gao, Xiaoling},
title = {Attack Intent Analysis Method Based on Attack Path Graph},
year = {2019},
isbn = {9781450376624},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3371676.3371680},
doi = {10.1145/3371676.3371680},
abstract = {With the rapid development of network technology, network security problems are gradually
increasing, and the network attack situation is very severe. In a complex attack scenario,
timely detection of potential attack behaviors and timely identification and pre-judgment
of attack intentions are important components of security risks. However, the attack
behavior in the network presents complexity, multi-step and uncertainty, which brings
new technical challenges to attack intent analysis. Aiming at the problem that the
attack intention of multi-step complex attack is difficult to identify, this paper
proposes an attack intention analysis method based on attack path graph. Firstly,
aiming at the multi-step complex attack behavior analysis problem, the key asset assessment
technology is used to find out the key assets in the network system, and the hypothetical
attack intention is generated according to the security protection requirements of
the network system. Then, it is difficult to manually construct the attack path map
in the large-scale network, and the automatic generation of the attack path map is
realized. Finally, a method of network attack intent identification is proposed and
a calculation method of attack intent probability is designed, which improves the
efficiency and accuracy of attack intent recognition.},
booktitle = {Proceedings of the 2019 the 9th International Conference on Communication and Network Security},
pages = {97–102},
numpages = {6},
keywords = {Vulnerability, Attack Path Graph, Key Asset, Vulnerability Exploitation, Attack Intention},
location = {Chongqing, China},
series = {ICCNS 2019}
}

@article{10.1145/3436755,
author = {Liu, Bo and Ding, Ming and Shaham, Sina and Rahayu, Wenny and Farokhi, Farhad and Lin, Zihuai},
title = {When Machine Learning Meets Privacy: A Survey and Outlook},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3436755},
doi = {10.1145/3436755},
abstract = {The newly emerged machine learning (e.g., deep learning) methods have become a strong
driving force to revolutionize a wide range of industries, such as smart healthcare,
financial technology, and surveillance systems. Meanwhile, privacy has emerged as
a big concern in this machine learning-based artificial intelligence era. It is important
to note that the problem of privacy preservation in the context of machine learning
is quite different from that in traditional data privacy protection, as machine learning
can act as both friend and foe. Currently, the work on the preservation of privacy
and machine learning are still in an infancy stage, as most existing solutions only
focus on privacy problems during the machine learning process. Therefore, a comprehensive
study on the privacy preservation problems and machine learning is required. This
article surveys the state of the art in privacy issues and solutions for machine learning.
The survey covers three categories of interactions between privacy and machine learning:
(i) private machine learning, (ii) machine learning-aided privacy protection, and
(iii) machine learning-based privacy attack and corresponding protection schemes.
The current research progress in each category is reviewed and the key challenges
are identified. Finally, based on our in-depth analysis of the area of privacy and
machine learning, we point out future research directions in this field.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {31},
numpages = {36},
keywords = {differential privacy, deep learning, privacy, Machine learning}
}

@inproceedings{10.1145/2976749.2978384,
author = {Pan, Xiang and Cao, Yinzhi and Liu, Shuangping and Zhou, Yu and Chen, Yan and Zhou, Tingzhe},
title = {CSPAutoGen: Black-Box Enforcement of Content Security Policy upon Real-World Websites},
year = {2016},
isbn = {9781450341394},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2976749.2978384},
doi = {10.1145/2976749.2978384},
abstract = {Content security policy (CSP) which has been standardized by W3C and adopted by all
major commercial browsers-is one of the most promising approaches for defending against
cross-site scripting (XSS) attacks. Although client-side adoption of CSP is successful,
server-side adoption is far behind the client side: according to a large-scale survey,
less than 0.002% of Alexa Top 1M websites enabled CSP. To facilitate the adoption
of CSP, we propose CSPAutoGen to enable CSP in real-time, without server modifications,
and being compatible with real-world websites. Specifically, CSPAutoGen trains so-called
templates for each domain, generates CSPs based on the templates, rewrites incoming
webpages on the fly to apply those generated CSPs, and then serves those rewritten
webpages to client browsers. CSPAutoGen is designed to automatically enforce the most
secure and strict version of CSP without enabling "unsafe-inline" and "unsafe-eval",
i.e., CSPAutoGen can handle all the inline and dynamic scripts.We have implemented
a prototype of CSPAutoGen, and our evaluation shows that CSPAutoGen can correctly
render all the Alexa Top 50 websites. Moreover, we conduct extensive case studies
on five popular websites, indicating that CSPAutoGen can preserve the behind-the-login
functionalities, such as sending emails and posting comments. Our security analysis
shows that CSPAutoGen is able to defend against all the tested real-world XSS attacks.},
booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
pages = {653–665},
numpages = {13},
keywords = {content security policy, javascript, cross-site scripting, web security},
location = {Vienna, Austria},
series = {CCS '16}
}

@inproceedings{10.1145/3433210.3453101,
author = {Piskozub, Michal and De Gaspari, Fabio and Barr-Smith, Freddie and Mancini, Luigi and Martinovic, Ivan},
title = {MalPhase: Fine-Grained Malware Detection Using Network Flow Data},
year = {2021},
isbn = {9781450382878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3433210.3453101},
doi = {10.1145/3433210.3453101},
abstract = {Economic incentives encourage malware authors to constantly develop new, increasingly
complex malware to steal sensitive data or blackmail individuals and companies into
paying large ransoms. In 2017, the worldwide economic impact of cyberattacks is estimated
to be between 445 and 600 billion USD, or 0.8% of global GDP. Traditionally, one of
the approaches used to defend against malware is network traffic analysis, which relies
on network data to detect the presence of potentially malicious software. However,
to keep up with increasing network speeds and amount of traffic, network analysis
is generally limited to work on aggregated network data, which is traditionally challenging
and yields mixed results. In this paper we present MalPhase, a system that was designed
to cope with the limitations of aggregated flows. MalPhase features a multi-phase
pipeline for malware detection, type and family classification. The use of an extended
set of network flow features and a simultaneous multi-tier architecture facilitates
a performance improvement for deep learning models, making them able to detect malicious
flows (&gt;98% F1) and categorize them to a respective malware type (&gt;93% F1) and family
(&gt;91% F1). Furthermore, the use of robust features and denoising autoencoders allows
MalPhase to perform well on samples with varying amounts of benign traffic mixed in.
Finally, MalPhase detects unseen malware samples with performance comparable to that
of known samples, even when interlaced with benign flows to reflect realistic network
environments.},
booktitle = {Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security},
pages = {774–786},
numpages = {13},
keywords = {network traffic analysis, malware detection, neural networks},
location = {Virtual Event, Hong Kong},
series = {ASIA CCS '21}
}

@inproceedings{10.1145/3433210.3437513,
author = {Li, Jiangnan and Yang, Yingyuan and Sun, Jinyuan Stella and Tomsovic, Kevin and Qi, Hairong},
title = {ConAML: Constrained Adversarial Machine Learning for Cyber-Physical Systems},
year = {2021},
isbn = {9781450382878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3433210.3437513},
doi = {10.1145/3433210.3437513},
abstract = {Recent research demonstrated that the superficially well-trained machine learning
(ML) models are highly vulnerable to adversarial examples. As ML techniques are becoming
a popular solution for cyber-physical systems (CPSs) applications in research literatures,
the security of these applications is of concern. However, current studies on adversarial
machine learning (AML) mainly focus on pure cyberspace domains. The risks the adversarial
examples can bring to the CPS applications have not been well investigated. In particular,
due to the distributed property of data sources and the inherent physical constraints
imposed by CPSs, the widely-used threat models and the state-of-the-art AML algorithms
in previous cyberspace research become infeasible.We study the potential vulnerabilities
of ML applied in CPSs by proposing Constrained Adversarial Machine Learning (ConAML),
which generates adversarial examples that satisfy the intrinsic constraints of the
physical systems. We first summarize the difference between AML in CPSs and AML in
existing cyberspace systems and propose a general threat model for ConAML. We then
design a best-effort search algorithm to iteratively generate adversarial examples
with linear physical constraints. We evaluate our algorithms with simulations of two
typical CPSs, the power grids and the water treatment system. The results show that
our ConAML algorithms can effectively generate adversarial examples which significantly
decrease the performance of the ML models even under practical constraints.},
booktitle = {Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security},
pages = {52–66},
numpages = {15},
keywords = {cyber-physical system, intrusion detection, adversarial machine learning},
location = {Virtual Event, Hong Kong},
series = {ASIA CCS '21}
}

@article{10.1145/3001836,
author = {Altawy, Riham and Youssef, Amr M.},
title = {Security, Privacy, and Safety Aspects of Civilian Drones: A Survey},
year = {2016},
issue_date = {February 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {2},
issn = {2378-962X},
url = {https://doi.org/10.1145/3001836},
doi = {10.1145/3001836},
abstract = {The market for civilian unmanned aerial vehicles, also known as drones, is expanding
rapidly as new applications are emerging to incorporate the use of civilian drones
in our daily lives. On one hand, the convenience of offering certain services via
drones is attractive. On the other hand, the mere operation of these airborne machines,
which rely heavily on their cyber capabilities, poses great threats to people and
property. Also, while the Federal Aviation Administration NextGen project aims to
integrate civilian drones into the national airspace, the regulation is still a work-in-progress
and does not cope with their threats. This article surveys the main security, privacy,
and safety aspects associated with the use of civilian drones in the national airspace.
In particular, we identify both the physical and cyber threats of such systems and
discuss the security properties required by their critical operation environment.
We also identify the research challenges and possible future directions in the fields
of civilian drone security, safety, and privacy. Based on our investigation, we forecast
that security will be a central enabling technology for the next generation of civilian
unmanned aerial vehicles.},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = nov,
articleno = {7},
numpages = {25},
keywords = {Unmanned aerial vehicles, cyber-physical systems, civilain drones, security, safety, privacy, parcelcopters}
}

@article{10.1145/3442181,
author = {Sabir, Bushra and Ullah, Faheem and Babar, M. Ali and Gaire, Raj},
title = {Machine Learning for Detecting Data Exfiltration: A Review},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3442181},
doi = {10.1145/3442181},
abstract = {Context: Research at the intersection of cybersecurity, Machine Learning (ML), and
Software Engineering (SE) has recently taken significant steps in proposing countermeasures
for detecting sophisticated data exfiltration attacks. It is important to systematically
review and synthesize the ML-based data exfiltration countermeasures for building
a body of knowledge on this important topic. Objective: This article aims at systematically
reviewing ML-based data exfiltration countermeasures to identify and classify ML approaches,
feature engineering techniques, evaluation datasets, and performance metrics used
for these countermeasures. This review also aims at identifying gaps in research on
ML-based data exfiltration countermeasures. Method: We used Systematic Literature
Review (SLR) method to select and review 92 papers. Results: The review has enabled
us to: (a) classify the ML approaches used in the countermeasures into data-driven,
and behavior-driven approaches; (b) categorize features into six types: behavioral,
content-based, statistical, syntactical, spatial, and temporal; (c) classify the evaluation
datasets into simulated, synthesized, and real datasets; and (d) identify 11 performance
measures used by these studies. Conclusion: We conclude that: (i) The integration
of data-driven and behavior-driven approaches should be explored; (ii) There is a
need of developing high quality and large size evaluation datasets; (iii) Incremental
ML model training should be incorporated in countermeasures; (iv) Resilience to adversarial
learning should be considered and explored during the development of countermeasures
to avoid poisoning attacks; and (v) The use of automated feature engineering should
be encouraged for efficiently detecting data exfiltration attacks.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {50},
numpages = {47},
keywords = {advanced persistent threat, machine learning, Data exfiltration, data leakage, data breach}
}

@inproceedings{10.1145/3366423.3380173,
author = {Datta, Pubali and Kumar, Prabuddha and Morris, Tristan and Grace, Michael and Rahmati, Amir and Bates, Adam},
title = {Valve: Securing Function Workflows on Serverless Computing Platforms},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380173},
doi = {10.1145/3366423.3380173},
abstract = {Serverless Computing has quickly emerged as a dominant cloud computing paradigm, allowing
developers to rapidly prototype event-driven applications using a composition of small
functions that each perform a single logical task. However, many such application
workflows are based in part on publicly-available functions developed by third-parties,
creating the potential for functions to behave in unexpected, or even malicious, ways.
At present, developers are not in total control of where and how their data is flowing,
creating significant security and privacy risks in growth markets that have embraced
serverless (e.g., IoT). As a practical means of addressing this problem, we present
Valve, a serverless platform that enables developers to exert complete fine-grained
control of information flows in their applications. Valve enables workflow developers
to reason about function behaviors, and specify restrictions, through auditing of
network-layer information flows. By proxying network requests and propagating taint
labels across network flows, Valve is able to restrict function behavior without code
modification. We demonstrate that Valve is able defend against known serverless attack
behaviors including container reuse-based persistence and data exfiltration over cloud
platform APIs with less than 2.8% runtime overhead, 6.25% deployment overhead and
2.35% teardown overhead.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {939–950},
numpages = {12},
keywords = {Information Flow, Security, Serverless Computing},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/3351917.3351987,
author = {Jiang, Lingyun and Qiao, Kai and Qin, Ruoxi and Chen, Jian and Bu, Haibing and Yan, Bin},
title = {Unsupervised Adversarial Perturbation Eliminating via Disentangled Representations},
year = {2019},
isbn = {9781450371865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3351917.3351987},
doi = {10.1145/3351917.3351987},
abstract = {Although deep neural networks (DNNs) could achieve state-of-the-art performance while
recognizing images, they often vulnerable to adversarial examples where input intended
to be added the small magnitude perturbations may mislead them to incorrect results.
It is worth researching on defending against adversarial examples due to the potential
security threats. In this paper, we propose an unsupervised method for eliminating
adversarial perturbation based on disentangled representations. To achieve adversarial
defense, we propose extracting the content and perturbation features of adversarial
examples by content encoders and perturbation encoders. Meanwhile, to handle the unpaired
training data, we introduce a cross-cycle consistency loss based on disentangled representations
and a perturbation branch. We also add an adversarial loss on recovered images to
make DNNs predict right. Qualitative results show that our method can eliminate adversarial
perturbation without paired training data. We perform extensive experiments on two
public datasets MNIST and CIFAR10, which is shown the efficiency of resisting adversarial
examples.},
booktitle = {Proceedings of the 2019 4th International Conference on Automation, Control and Robotics Engineering},
articleno = {46},
numpages = {6},
keywords = {adversarial example, Deep learning, adversarial perturbation, disentangled representations},
location = {Shenzhen, China},
series = {CACRE2019}
}

@inproceedings{10.1145/3180465.3180466,
author = {Stoecklin, Marc Ph. and Zhang, Jialong and Araujo, Frederico and Taylor, Teryl},
title = {Dressed up: Baiting Attackers through Endpoint Service Projection},
year = {2018},
isbn = {9781450356350},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180465.3180466},
doi = {10.1145/3180465.3180466},
abstract = {Honeypots have been widely employed to track attackers' activities and divert potential
threats against real assets. A critical challenge of honeypot research is how to better
integrate deceptive honeypots as part of an overall production network. Conventional
honeypots are typically deployed as separate assets near those they are protecting---they
are not in the direct line of fire. Such a setup does not effectively protect real
assets since attackers do not require a full network scan to identify certain production
hosts.In this paper, we present a novel framework to transparently project vulnerable
honey services atop real production systems without interfering the production system.
The key idea is to use SDN technology to divide a production network into segments
of production and decoy servers. Traffic intended for production workloads is redirected
to decoys based on port or service information. The decoy servers run "vulnerable"
services that are heavily monitored. From the attackers' perspective, these vulnerable
services run on production systems, but traffic is instead relayed to a honeypot with
the same configuration (e.g., IP address, MAC address, running services) of the protected
production system. In this way, our approach capitalizes on capturing attacks before
they reach protected assets. We demonstrate its feasibility with a prototype implementation
and practical deployment model. Evaluation shows that our approach incurs negligible
overhead and resists potential side channel fingerprinting attacks.},
booktitle = {Proceedings of the 2018 ACM International Workshop on Security in Software Defined Networks &amp; Network Function Virtualization},
pages = {23–28},
numpages = {6},
keywords = {service projection, honeypot, cyber deception, honeynet, software-defined networking},
location = {Tempe, AZ, USA},
series = {SDN-NFV Sec'18}
}

@inproceedings{10.1145/2700171.2791038,
author = {Schulz, Axel and Schmidt, Benedikt and Strufe, Thorsten},
title = {Small-Scale Incident Detection Based on Microposts},
year = {2015},
isbn = {9781450333955},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2700171.2791038},
doi = {10.1145/2700171.2791038},
abstract = {Detecting large-scale incidents based on microposts has successfully been proposed
and shown. However, the detection of small-scale incidents was not satisfyingly possible
so far, though the information that is shared during such local events could improve
the situational awareness of both citizens and decision makers alike.In this paper,
we propose an approach for small-scale incident detection based on spatial-temporal-type
clustering. In contrast to existing work, (1) we employ three distinct properties
that define an incident, (2) we use a hybrid approach to reduce the computational
overhead, and (3) we extract generalized features to increase robustness towards previously
unseen data. Our evaluation in the domain of emergency first response shows that our
approach identifies 32.14% of all real world incidents recorded for the city of Seattle
just using on tweets. This result greatly outperforms the state of the art, which
only detects about 6% of the real-world incidents. Also, a precision of 77% shows
that we efficiently discard irrelevant information.},
booktitle = {Proceedings of the 26th ACM Conference on Hypertext &amp; Social Media},
pages = {3–12},
numpages = {10},
keywords = {event detection, microblogs},
location = {Guzelyurt, Northern Cyprus},
series = {HT '15}
}

@article{10.1145/3365573,
author = {Edwards, Chris},
title = {Malevolent Machine Learning},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {62},
number = {12},
issn = {0001-0782},
url = {https://doi.org/10.1145/3365573},
doi = {10.1145/3365573},
abstract = {AI attacks throw light on the nature of deep learning.},
journal = {Commun. ACM},
month = nov,
pages = {13–15},
numpages = {3}
}

@inproceedings{10.1145/3240765.3240854,
author = {Linscott, Timothy and Ehrett, Pete and Bertacco, Valeria and Austin, Todd},
title = {SWAN: Mitigating Hardware Trojans with Design Ambiguity},
year = {2018},
isbn = {9781450359504},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3240765.3240854},
doi = {10.1145/3240765.3240854},
abstract = {For the past decade, security experts have warned that malicious engineers could modify
hardware designs to include hardware backdoors (trojans), which, in turn, could grant
attackers full control over a system. Proposed defenses to detect these attacks have
been outpaced by the development of increasingly small, but equally dangerous, trojans.
To thwart trojan-based attacks, we propose a novel architecture that maps the security-critical
portions of a processor design to a one-time programmable, LUT-free fabric. The programmable
fabric is automatically generated by analyzing the HDL of targeted modules. We present
our tools to generate the fabric and map functionally equivalent designs onto the
fabric. By having a trusted party randomly select a mapping and configure each chip,
we prevent an attacker from knowing the physical location of targeted signals at manufacturing
time. In addition, we provide decoy options (canaries) for the mapping of security-critical
signals, such that hardware trojans hitting a decoy are thwarted and exposed. Using
this defense approach, any trojan capable of analyzing the entire configurable fabric
must employ complex logic functions with a large silicon footprint, thus exposing
it to detection by inspection. We evaluated our solution on a RISC-V BOOM processor
and demonstrated that, by providing the ability to map each critical signal to 6 distinct
locations on the chip, we can reduce the chance of attack success by an undetectable
trojan by 99%, incurring only a 27% area overhead.},
booktitle = {Proceedings of the International Conference on Computer-Aided Design},
articleno = {91},
numpages = {7},
location = {San Diego, California},
series = {ICCAD '18}
}

@inproceedings{10.1145/2462096.2462105,
author = {Adhikarla, Shrikant and Kang, Min Suk and Tague, Patrick},
title = {Selfish Manipulation of Cooperative Cellular Communications via Channel Fabrication},
year = {2013},
isbn = {9781450319980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2462096.2462105},
doi = {10.1145/2462096.2462105},
abstract = {In today's cellular networks, user equipment (UE) have suffered from low spectral
efficiency at cell-edge region due to high interference from adjacent base stations
(BSs), which share the same spectral radio resources. In the recently proposed cooperative
cellular networks, geographically separated multiple BSs cooperate on transmission
in order to improve the UE's signal-to-interference-plus-noise-ratio (SINR) at cell-edge
region. The service provider of the system dynamically assigns the cluster of BSs
to achieve higher SINR for the UE while optimizing the use of system radio resources.
Although it is the service provider that makes the the clustering decision for the
UE, the service provider relies on the UE's input to the decision; i.e., the channel
states from the adjacent BSs to the UE. In essence, the operation of the cooperative
cellular netwokrs heavily relies on the trust in the UEs. In this paper, we propose
a new selfish attack against the cooperative cellular networks; an adversary reprograms
her UE to report fabricated channel information to cause the service provider to make
a decision that benefits the adversary while wasting its system resources. We evaluate
the proposed attack in a cooperative cellular network having various performance goals
on the simulation-based experiments and show that the adversary can trick the service
provider into expending 3.7 times more radio resources for the adversary and, accordingly,
the adversary achieves up to 16 dB SINR gain. Finally, we propose a threshold-based
countermeasure for the service provider to detect the attack with approximately 90%
of accuracy.},
booktitle = {Proceedings of the Sixth ACM Conference on Security and Privacy in Wireless and Mobile Networks},
pages = {49–54},
numpages = {6},
keywords = {cooperative cellular networks, anomaly detection, heuristic attack strategies, channel fabrication},
location = {Budapest, Hungary},
series = {WiSec '13}
}

@inproceedings{10.1145/1989656.1989664,
author = {Stein, Tao and Chen, Erdong and Mangla, Karan},
title = {Facebook Immune System},
year = {2011},
isbn = {9781450307284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1989656.1989664},
doi = {10.1145/1989656.1989664},
abstract = {Popular Internet sites are under attack all the time from phishers, fraudsters, and
spammers. They aim to steal user information and expose users to unwanted spam. The
attackers have vast resources at their disposal. They are well-funded, with full-time
skilled labor, control over compromised and infected accounts, and access to global
botnets. Protecting our users is a challenging adversarial learning problem with extreme
scale and load requirements. Over the past several years we have built and deployed
a coherent, scalable, and extensible realtime system to protect our users and the
social graph. This Immune System performs realtime checks and classifications on every
read and write action. As of March 2011, this is 25B checks per day, reaching 650K
per second at peak. The system also generates signals for use as feedback in classifiers
and other components. We believe this system has contributed to making Facebook the
safest place on the Internet for people and their information. This paper outlines
the design of the Facebook Immune System, the challenges we have faced and overcome,
and the challenges we continue to face.},
booktitle = {Proceedings of the 4th Workshop on Social Network Systems},
articleno = {8},
numpages = {8},
keywords = {machine learning, social network security, security, adversarial learning},
location = {Salzburg, Austria},
series = {SNS '11}
}

@inproceedings{10.1145/3298689.3347031,
author = {Christakopoulou, Konstantina and Banerjee, Arindam},
title = {Adversarial Attacks on an Oblivious Recommender},
year = {2019},
isbn = {9781450362436},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3298689.3347031},
doi = {10.1145/3298689.3347031},
abstract = {Can machine learning models be easily fooled? Despite the recent surge of interest
in learned adversarial attacks in other domains, in the context of recommendation
systems this question has mainly been answered using hand-engineered fake user profiles.
This paper attempts to reduce this gap. We provide a formulation for learning to attack
a recommender as a repeated general-sum game between two players, i.e., an adversary
and a recommender oblivious to the adversary's existence. We consider the challenging
case of poisoning attacks, which focus on the training phase of the recommender model.
We generate adversarial user profiles targeting subsets of users or items, or generally
the top-K recommendation quality. Moreover, we ensure that the adversarial user profiles
remain unnoticeable by preserving proximity of the real user rating/interaction distribution
to the adversarial fake user distribution. To cope with the challenge of the adversary
not having access to the gradient of the recommender's objective with respect to the
fake user profiles, we provide a non-trivial algorithm building upon zero-order optimization
techniques. We offer a wide range of experiments, instantiating the proposed method
for the case of the classic popular approach of a low-rank recommender, and illustrating
the extent of the recommender's vulnerability to a variety of adversarial intents.
These results can serve as a motivating point for more research into recommender defense
strategies against machine learned attacks.},
booktitle = {Proceedings of the 13th ACM Conference on Recommender Systems},
pages = {322–330},
numpages = {9},
keywords = {learned adversarial attacks, recommender systems},
location = {Copenhagen, Denmark},
series = {RecSys '19}
}

@inproceedings{10.1145/3198458.3198461,
author = {Siddiqi, Ahnaf and Tippenhauer, Nils Ole and Mashima, Daisuke and Chen, Binbin},
title = {On Practical Threat Scenario Testing in an Electric Power ICS Testbed},
year = {2018},
isbn = {9781450357555},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3198458.3198461},
doi = {10.1145/3198458.3198461},
abstract = {Industrial control system networks in real world usually require a complex composition
of many different devices, protocols, and services. Unfortunately, such practical
setups are rarely documented publicly in sufficient technical detail to allow third
parties to use the system as reference for their research. As a result, security researchers
often have to work with abstract and simplified system assumptions, which might not
translate well to practice. In this work, we provide a comprehensive overview of the
network services provided by industrial devices found in the EPIC (Electric Power
and Intelligent Control) system at SUTD. We provide a detailed network topology of
the different network segments, enumerate hosts, models, protocols, and services provided.
We argue that such a detailed system description can serve as an enabler for more
practical security research. In particular, we discuss how the reported information
can be used for emulating a diverse set of important threat scenarios in the smart
grid domain. In addition, the provided details allow other researchers to build more
detailed models or simulations.},
booktitle = {Proceedings of the 4th ACM Workshop on Cyber-Physical System Security},
pages = {15–21},
numpages = {7},
keywords = {ics, industrial protocols, testbed, threat scenario testing},
location = {Incheon, Republic of Korea},
series = {CPSS '18}
}

@inproceedings{10.1145/3395351.3399357,
author = {Wang, Chenggang and Kennedy, Sean and Li, Haipeng and Hudson, King and Atluri, Gowtham and Wei, Xuetao and Sun, Wenhai and Wang, Boyang},
title = {Fingerprinting Encrypted Voice Traffic on Smart Speakers with Deep Learning},
year = {2020},
isbn = {9781450380065},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3395351.3399357},
doi = {10.1145/3395351.3399357},
abstract = {This paper investigates the privacy leakage of smart speakers under an encrypted traffic
analysis attack, referred to as voice command fingerprinting. In this attack, an adversary
can eavesdrop both outgoing and incoming encrypted voice traffic of a smart speaker,
and infers which voice command a user says over encrypted traffic. We first built
an automatic voice traffic collection tool and collected two large-scale datasets
on two smart speakers, Amazon Echo and Google Home. Then, we implemented proof-of-concept
attacks by leveraging deep learning. Our experimental results over the two datasets
indicate disturbing privacy concerns. Specifically, compared to 1% accuracy with random
guess, our attacks can correctly infer voice commands over encrypted traffic with
92.89% accuracy on Amazon Echo.Despite variances that human voices may cause on outgoing
traffic, our proof-of-concept attacks remain effective even only leveraging incoming
traffic (i.e., the traffic from the server). This is because the AI-based voice services
running on the server side response commands in the same voice and with a deterministic
or predictable manner in text, which leave distinguishable pattern over encrypted
traffic. We also built a proof-of-concept defense to obfuscate encrypted traffic.
Our results show that the defense can effectively mitigate attack accuracy on Amazon
Echo to 32.18%.},
booktitle = {Proceedings of the 13th ACM Conference on Security and Privacy in Wireless and Mobile Networks},
pages = {254–265},
numpages = {12},
keywords = {machine learning, encrypted traffic analysis, smart speaker},
location = {Linz, Austria},
series = {WiSec '20}
}

@inproceedings{10.1145/3338503.3357723,
author = {Ahmadvand, Mohsen and Below, Daniel and Banescu, Sebastian and Pretschner, Alexander},
title = {VirtSC: Combining Virtualization Obfuscation with Self-Checksumming},
year = {2019},
isbn = {9781450368353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338503.3357723},
doi = {10.1145/3338503.3357723},
abstract = {Self-checksumming (SC) is a tamper-proofing technique that ensures certain program
segments (code) in memory hash to known values at runtime. SC has few restrictions
on application and hence can protect a vast majority of programs. The code verification
in SC requires computation of the expected hashes after compilation, as the machine-code
is not known before. This means the expected hash values need to be adjusted in the
binary executable, hence combining SC with other protections is limited due to this
adjustment step. However, obfuscation protections are often necessary, as SC protections
can be otherwise easily detected and disabled via pattern matching. In this paper,
we present a layered protection using virtualization obfuscation, yielding an architecture-agnostic
SC protection that requires no post-compilation adjustment. We evaluate the performance
of our scheme using a dataset of 25 real-world programs (MiBench and 3 CLI games).
Our results show that the SC scheme induces an average overhead of 43% for a complete
protection (100% coverage). The overhead is tolerable for less CPU-intensive programs
(e.g. games) and when only parts of programs (e.g. license checking) are protected.
However, large overheads stemming from the virtualization obfuscation were encountered.},
booktitle = {Proceedings of the 3rd ACM Workshop on Software Protection},
pages = {53–63},
numpages = {11},
keywords = {virtualization obfuscation, integrity protection, software protection, self-checksumming, mate},
location = {London, United Kingdom},
series = {SPRO'19}
}

@inproceedings{10.1145/3411508.3421379,
author = {Novo, Carlos and Morla, Ricardo},
title = {Flow-Based Detection and Proxy-Based Evasion of Encrypted Malware C2 Traffic},
year = {2020},
isbn = {9781450380942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411508.3421379},
doi = {10.1145/3411508.3421379},
abstract = {State of the art deep learning techniques are known to be vulnerable to evasion attacks
where an adversarial sample is generated from a malign sample and misclassified as
benign. Detection of encrypted malware command and control traffic based on TCP/IP
flow features can be framed as a learning task and is thus vulnerable to evasion attacks.
However, unlike e.g. in image processing where generated adversarial samples can be
directly mapped to images, going from flow features to actual TCP/IP packets requires
crafting the sequence of packets, with no established approach for such crafting and
a limitation on the set of modifiable features that such crafting allows.In this paper
we discuss learning and evasion consequences of the gap between generated and crafted
adversarial samples. We exemplify with a deep neural network detector trained on a
public C2 traffic dataset, white-box adversarial learning, and a proxy-based approach
for crafting longer flows. Our results show 1) the high evasion rate obtained by using
generated adversarial samples on the detector can be significantly reduced when using
crafted adversarial samples; 2) robustness against adversarial samples by model hardening
varies according to the crafting approach and corresponding set of modifiable features
that the attack allows for; 3) incrementally training hardened models with adversarial
samples can produce a level playing field where no detector is best against all attacks
and no attack is best against all detectors, in a given set of attacks and detectors.
To the best of our knowledge this is the first time that level playing field feature
set- and iteration-hardening are analyzed in encrypted C2 malware traffic detection.},
booktitle = {Proceedings of the 13th ACM Workshop on Artificial Intelligence and Security},
pages = {83–91},
numpages = {9},
keywords = {malware command and control, adversarial learning, intrusion detection},
location = {Virtual Event, USA},
series = {AISec'20}
}

@inproceedings{10.1145/3422337.3447832,
author = {Hu, Yiwen and Wang, Sihan and Tu, Guan-Hua and Xiao, Li and Xie, Tian and Lei, Xinyu and Li, Chi-Yu},
title = {Security Threats from Bitcoin Wallet Smartphone Applications: Vulnerabilities, Attacks, and Countermeasures},
year = {2021},
isbn = {9781450381437},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3422337.3447832},
doi = {10.1145/3422337.3447832},
abstract = {Nowadays, Bitcoin is the most popular cryptocurrency. With the proliferation of smartphones
and the high-speed mobile Internet, more and more users have started accessing their
Bitcoin wallets on their smartphones. Users can download and install a variety of
Bitcoin wallet applications (e.g., Coinbase, Luno, Bitcoin Wallet) on their smartphones
and access their Bitcoin wallets anytime and anywhere. However, it is still unknown
whether these Bitcoin wallet smartphone applications are secure or if they are new
attack surfaces for adversaries to attack these application users. In this work, we
explored the insecurity of the 10 most popular Bitcoin wallet smartphone applications
and discovered three security vulnerabilities. By exploiting them, adversaries can
launch various attacks including Bitcoin deanonymization, reflection and amplification
spamming, and wallet fraud attacks. To address the identified security vulnerabilities,
we developed a phone-side Bitcoin Security Rectifier to secure Bitcoin wallet smartphone
application users. The developed rectifier does not require any modifications to current
wallet applications and is compliant with Bitcoin standards.},
booktitle = {Proceedings of the Eleventh ACM Conference on Data and Application Security and Privacy},
pages = {89–100},
numpages = {12},
keywords = {mobile networks, blockchain, security, bitcoin wallets},
location = {Virtual Event, USA},
series = {CODASPY '21}
}

@inproceedings{10.1145/3337821.3337856,
author = {Hou, Xiaofeng and Liang, Mingyu and Li, Chao and Zheng, Wenli and Chen, Quan and Guo, Minyi},
title = {When Power Oversubscription Meets Traffic Flood Attack: Re-Thinking Data Center Peak Load Management},
year = {2019},
isbn = {9781450362955},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3337821.3337856},
doi = {10.1145/3337821.3337856},
abstract = {The state-of-the-art techniques on data center peak power management are too optimistic;
they overestimate their benefits in a potentially insecure operating environment.
Especially in data centers that oversubscribe power infrastructure, it is likely that
unexpected traffics can violate power budget before an effective network DoS attack
is observed. In this work, we take the first to investigate the joint effect of power
throttling and traffic flooding. We characterize a special operating region in which
DoS attacks can provoke undesirable power peaks without exhibiting network traffic
anomalies. In this region, an attacker can trigger power emergency by sending normal
traffics throughout the Internet. We term this new type of threat as DOPE (Denial
of Power and Energy). We show that existing technologies are insufficient for eliminating
DOPE without negative performance effects on legitimate users. To enhance data center
resiliency, we propose a request-aware power management framework called Anti-DOPE.
The key feature of Anti-DOPE is bridging the gap between network traffic controlling
and server power management. Specifically, it pre-processes of incoming requests to
isolate malicious power attacks on the network load balancer side and then post-processes
of compute node performance to minimize the collateral damage it may cause. Anti-DOPE
is orthogonal to prior power management schemes and requires minute system modification.
Using Alibaba container trace we show that Anti-DOPE allows 44% shorter average response
time. It also improves the 90th percentile tail latency by 68.1% compared to the other
power controlling methods.},
booktitle = {Proceedings of the 48th International Conference on Parallel Processing},
articleno = {13},
numpages = {10},
location = {Kyoto, Japan},
series = {ICPP 2019}
}

@InProceedings{10.1145/3442381.3450044,
  author    = {Li, Heng and Zhou, Shiyao and Yuan, Wei and Luo, Xiapu and Gao, Cuiying and Chen, Shuiyan},
  booktitle = {Proceedings of the Web Conference 2021},
  title     = {Robust Android Malware Detection against Adversarial Example Attacks},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {3603–3612},
  publisher = {Association for Computing Machinery},
  series    = {WWW '21},
  abstract  = {Adversarial examples pose severe threats to Android malware detection because they
can render the machine learning based detection systems useless. How to effectively
detect Android malware under various adversarial example attacks becomes an essential
but very challenging issue. Existing adversarial example defense mechanisms usually
rely heavily on the instances or the knowledge of adversarial examples, and thus their
usability and effectiveness are significantly limited because they often cannot resist
the unseen-type adversarial examples. In this paper, we propose a novel robust Android
malware detection approach that can resist adversarial examples without requiring
their instances or knowledge by jointly investigating malware detection and adversarial
example defenses. More precisely, our approach employs a new VAE (variational autoencoder)
and an MLP (multi-layer perceptron) to detect malware, and combines their detection
outcomes to make the final decision. In particular, we share a feature extraction
network between the VAE and the MLP to reduce model complexity and design a new loss
function to disentangle the features of different classes, hence improving detection
performance. Extensive experiments confirm our model’s advantage in accuracy and robustness.
Our method outperforms 11 state-of-the-art robust Android malware detection models
when resisting 7 kinds of adversarial example attacks.},
  doi       = {10.1145/3442381.3450044},
  isbn      = {9781450383127},
  keywords  = {Android Malware Detection, Mobile Security, Adversarial Example},
  location  = {Ljubljana, Slovenia},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3442381.3450044},
}

@inproceedings{10.1145/2664243.2664258,
author = {Yang, Chao and Zhang, Jialong and Gu, Guofei},
title = {A Taste of Tweets: Reverse Engineering Twitter Spammers},
year = {2014},
isbn = {9781450330053},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2664243.2664258},
doi = {10.1145/2664243.2664258},
abstract = {In this paper, through reverse engineering Twitter spammers' tastes (their preferred
targets to spam), we aim at providing guidelines for building more effective social
honeypots, and generating new insights to defend against social spammers. Specifically,
we first perform a measurement study by deploying "benchmark" social honeypots on
Twitter with diverse and fine-grained social behavior patterns to trap spammers. After
five months' data collection, we make a deep analysis on how Twitter spammers find
their targets. Based on the analysis, we evaluate our new guidelines for building
effective social honeypots by implementing "advanced" honeypots. Particularly, within
the same time period, using those advanced honeypots can trap spammers around 26 times
faster than using "traditional" honeypots.In the second part of our study, we investigate
new active collection approaches to complement the fundamentally passive procedure
of using honeypots to slowly attract spammers. Our goal is that, given limited resources/time,
instead of blindly crawling all possible (or randomly sampling) Twitter accounts at
the first place (for later spammer analysis), we need a lightweight strategy to prioritize
the active crawling/sampling of more likely spam accounts from the huge Twittersphere.
Applying what we have learned about the tastes of spammers, we design two new, active
and guided sampling approaches for collecting most likely spammer accounts during
the crawling. According to our evaluation, our strategies could efficiently crawl/sample
over 17,000 spam accounts within a short time with a considerably high "Hit Ratio",
i.e., collecting 6 correct spam accounts in every 10 sampled accounts.},
booktitle = {Proceedings of the 30th Annual Computer Security Applications Conference},
pages = {86–95},
numpages = {10},
keywords = {online social network websites, Twitter, spam},
location = {New Orleans, Louisiana, USA},
series = {ACSAC '14}
}

@inproceedings{10.1145/3321707.3321771,
author = {Friedrich, Markus and Fayolle, Pierre-Alain and Gabor, Thomas and Linnhoff-Popien, Claudia},
title = {Optimizing Evolutionary CSG Tree Extraction},
year = {2019},
isbn = {9781450361118},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3321707.3321771},
doi = {10.1145/3321707.3321771},
abstract = {The extraction of 3D models represented by Constructive Solid Geometry (CSG) trees
from point clouds is a common problem in reverse engineering pipelines as used by
Computer Aided Design (CAD) tools. We propose three independent enhancements on state-of-the-art
Genetic Algorithms (GAs) for CSG tree extraction: (1) A deterministic point cloud
filtering mechanism that significantly reduces the computational effort of objective
function evaluations without loss of geometric precision, (2) a graph-based partitioning
scheme that divides the problem domain in smaller parts that can be solved separately
and thus in parallel and (3) a 2-level improvement procedure that combines a recursive
CSG tree redundancy removal technique with a local search heuristic, which significantly
improves GA running times. We show in an extensive evaluation that our optimized GA-based
approach provides faster running times and scales better with problem size compared
to state-of-the-art GA-based approaches.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1183–1191},
numpages = {9},
keywords = {CAD, evolutionary algorithms, 3D-reconstruction, 3D geometry processing, CSG},
location = {Prague, Czech Republic},
series = {GECCO '19}
}

@inproceedings{10.1145/3243734.3243744,
author = {Islam, Mohammad A. and Ren, Shaolei},
title = {Ohm's Law in Data Centers: A Voltage Side Channel for Timing Power Attacks},
year = {2018},
isbn = {9781450356930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3243734.3243744},
doi = {10.1145/3243734.3243744},
abstract = {Maliciously-injected power load, a.k.a. power attack, has recently surfaced as a new
egregious attack vector for dangerously compromising the data center availability.
This paper focuses on the emerging threat of power attacks in a multi-tenant colocation
data center, an important type of data center where multiple tenants house their own
servers and share the power distribution system. Concretely, we discover a novel physical
side channel --- a voltage side channel --- which leaks the benign tenants' power
usage information at runtime and helps an attacker precisely time its power attacks.
The key idea we exploit is that, due to the Ohm's Law, the high-frequency switching
operation (40~100kHz) of the power factor correction circuit universally built in
today's server power supply units creates voltage ripples in the data center power
lines. Importantly, without overlapping the grid voltage in the frequency domain,
the voltage ripple signals can be easily sensed by the attacker to track the benign
tenants' runtime power usage and precisely time its power attacks. We evaluate the
timing accuracy of the voltage side channel in a real data center prototype, demonstrating
that the attacker can extract benign tenants' power pattern with a great accuracy
(correlation coefficient = 0.90+) and utilize 64% of all the attack opportunities
without launching attacks randomly or consecutively. Finally, we highlight a few possible
defense strategies and extend our study to more complex three-phase power distribution
systems used in large multi-tenant data centers.},
booktitle = {Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security},
pages = {146–162},
numpages = {17},
keywords = {power attack, data center, voltage side channel},
location = {Toronto, Canada},
series = {CCS '18}
}

@inproceedings{10.1145/2660267.2660367,
author = {Gervais, Arthur and Shokri, Reza and Singla, Adish and Capkun, Srdjan and Lenders, Vincent},
title = {Quantifying Web-Search Privacy},
year = {2014},
isbn = {9781450329576},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2660267.2660367},
doi = {10.1145/2660267.2660367},
abstract = {Web search queries reveal extensive information about users' personal lives to the
search engines and Internet eavesdroppers. Obfuscating search queries through adding
dummy queries is a practical and user-centric protection mechanism to hide users'
search intentions and interests. Despite few such obfuscation methods and tools, there
is no generic quantitative methodology for evaluating users' web-search privacy. In
this paper, we provide such a methodology. We formalize adversary's background knowledge
and attacks, the users' privacy objectives, and the algorithms to evaluate effectiveness
of query obfuscation mechanisms. We build upon machine-learning algorithms to learn
the linkability between user queries. This encompasses the adversary's knowledge about
the obfuscation mechanism and the users' web-search behavior. Then, we quantify privacy
of users with respect to linkage attacks. Our generic attack can run against users
for which the adversary does not have any background knowledge, as well as for the
cases where some prior queries from the target users are already observed. We quantify
privacy at the query level (the link between user's queries) and the semantic level
(user's topics of interest). We design a generic tool that can be used for evaluating
generic obfuscation mechanisms, and users with different web search behavior. To illustrate
our approach in practice, we analyze and compare privacy of users for two example
obfuscation mechanisms on a set of real web-search logs.},
booktitle = {Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security},
pages = {966–977},
numpages = {12},
keywords = {quantification framework, web search, obfuscation, machine learning, query privacy, privacy, semantic privacy},
location = {Scottsdale, Arizona, USA},
series = {CCS '14}
}

@inproceedings{10.1145/3132747.3132769,
author = {Bittau, Andrea and Erlingsson, \'{U}lfar and Maniatis, Petros and Mironov, Ilya and Raghunathan, Ananth and Lie, David and Rudominer, Mitch and Kode, Ushasree and Tinnes, Julien and Seefeld, Bernhard},
title = {Prochlo: Strong Privacy for Analytics in the Crowd},
year = {2017},
isbn = {9781450350853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3132747.3132769},
doi = {10.1145/3132747.3132769},
abstract = {The large-scale monitoring of computer users' software activities has become commonplace,
e.g., for application telemetry, error reporting, or demographic profiling. This paper
describes a principled systems architecture---Encode, Shuffle, Analyze (ESA)---for
performing such monitoring with high utility while also protecting user privacy. The
ESA design, and its Prochlo implementation, are informed by our practical experiences
with an existing, large deployment of privacy-preserving software monitoring.With
ESA, the privacy of monitored users' data is guaranteed by its processing in a three-step
pipeline. First, the data is encoded to control scope, granularity, and randomness.
Second, the encoded data is collected in batches subject to a randomized threshold,
and blindly shuffled, to break linkability and to ensure that individual data items
get "lost in the crowd" of the batch. Third, the anonymous, shuffled data is analyzed
by a specific analysis engine that further prevents statistical inference attacks
on analysis results.ESA extends existing best-practice methods for sensitive-data
analytics, by using cryptography and statistical techniques to make explicit how data
is elided and reduced in precision, how only common-enough, anonymous data is analyzed,
and how this is done for only specific, permitted purposes. As a result, ESA remains
compatible with the established workflows of traditional database analysis.Strong
privacy guarantees, including differential privacy, can be established at each processing
step to defend against malice or compromise at one or more of those steps. Prochlo
develops new techniques to harden those steps, including the Stash Shuffle, a novel
scalable and efficient oblivious-shuffling algorithm based on Intel's SGX, and new
applications of cryptographic secret sharing and blinding. We describe ESA and Prochlo,
as well as experiments that validate their ability to balance utility and privacy.},
booktitle = {Proceedings of the 26th Symposium on Operating Systems Principles},
pages = {441–459},
numpages = {19},
location = {Shanghai, China},
series = {SOSP '17}
}

@inproceedings{10.1145/3205651.3208270,
author = {Harris, Sean and Michalak, Eric and Schoonover, Kevin and Gausmann, Adam and Reinbolt, Hannah and Herman, Joshua and Tauritz, Daniel and Rawlings, Chris and Pope, Aaron Scott},
title = {Evolution of Network Enumeration Strategies in Emulated Computer Networks},
year = {2018},
isbn = {9781450357647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3205651.3208270},
doi = {10.1145/3205651.3208270},
abstract = {Successful attacks on computer networks today do not often owe their victory to directly
overcoming strong security measures set up by the defender. Rather, most attacks succeed
because the number of possible vulnerabilities are too large for humans to fully protect
without making a mistake. Regardless of the security elsewhere, a skilled attacker
can exploit a single vulnerability in a defensive system and negate the benefits of
those security measures. This paper presents an evolutionary framework for evolving
attacker agents in a real, emulated network environment using genetic programming,
as a foundation for coevolutionary systems which can automatically discover and mitigate
network security flaws. We examine network enumeration, an initial network reconnaissance
step, through our framework and present results demonstrating its success, indicating
a broader applicability to further cyber-security tasks.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1640–1647},
numpages = {8},
keywords = {network emulation, network security, genetic programming},
location = {Kyoto, Japan},
series = {GECCO '18}
}

@inproceedings{10.1145/3274694.3274727,
author = {Demoulin, Henri Maxime and Vaidya, Tavish and Pedisich, Isaac and DiMaiolo, Bob and Qian, Jingyu and Shah, Chirag and Zhang, Yuankai and Chen, Ang and Haeberlen, Andreas and Loo, Boon Thau and Phan, Linh Thi Xuan and Sherr, Micah and Shields, Clay and Zhou, Wenchao},
title = {DeDoS: Defusing DoS with Dispersion Oriented Software},
year = {2018},
isbn = {9781450365697},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3274694.3274727},
doi = {10.1145/3274694.3274727},
abstract = {This paper presents DeDoS, a novel platform for mitigating asymmetric DoS attacks.
These attacks are particularly challenging since even attackers with limited resources
can exhaust the resources of well-provisioned servers. DeDoS offers a framework to
deploy code in a highly modular fashion. If part of the application stack is experiencing
a DoS attack, DeDoS can massively replicate only the affected component, potentially
across many machines. This allows scaling of the impacted resource separately from
the rest of the application stack, so that resources can be precisely added where
needed to combat the attack. Our evaluation results show that DeDoS incurs reasonable
overheads in normal operations, and that it significantly outperforms standard replication
techniques when defending against a range of asymmetric attacks.},
booktitle = {Proceedings of the 34th Annual Computer Security Applications Conference},
pages = {712–722},
numpages = {11},
keywords = {Distributed Systems, Denial-of-Service},
location = {San Juan, PR, USA},
series = {ACSAC '18}
}

@inproceedings{10.1145/2611286.2611295,
author = {Aniello, Leonardo and Baldoni, Roberto and Ciccotelli, Claudio and Di Luna, Giuseppe Antonio and Frontali, Francesco and Querzoni, Leonardo},
title = {The Overlay Scan Attack: Inferring Topologies of Distributed Pub/Sub Systems through Broker Saturation},
year = {2014},
isbn = {9781450327374},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2611286.2611295},
doi = {10.1145/2611286.2611295},
abstract = {While pub/sub communication middleware has become main-stream in many application
domains, little has been done to assess its weaknesses from a security standpoint.
Complex attacks are usually planned by attackers by carefully analyzing the victim
to identify those systems that, if successfully targeted, could provide the most effective
result. In this paper we show that some pub/sub middleware are inherently vulnerable
to a specific kind of preparatory attack, namely the Overlay Scan Attack, that a malicious
user could exploit to infer the internal topology of a system, a sensible information
that could be used to plan future attacks. The topology inference is performed by
only using the standard primitives provided by the pub/sub middleware and assuming
minimal knowledge on the target system. The practicality of this attack has been shown
both in a simulated environment and through a test performed on a SIENA pub/sub deployment.},
booktitle = {Proceedings of the 8th ACM International Conference on Distributed Event-Based Systems},
pages = {107–117},
numpages = {11},
keywords = {network tomography, publish/subscribe, security, topology inference},
location = {Mumbai, India},
series = {DEBS '14}
}

@InProceedings{10.1145/3442381.3449891,
  author    = {Liu, Zhuoran and Larson, Martha},
  booktitle = {Proceedings of the Web Conference 2021},
  title     = {Adversarial Item Promotion: Vulnerabilities at the Core of Top-N Recommenders That Use Images to Address Cold Start},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {3590–3602},
  publisher = {Association for Computing Machinery},
  series    = {WWW '21},
  abstract  = {E-commerce platforms provide their customers with ranked lists of recommended items
matching the customers’ preferences. Merchants on e-commerce platforms would like
their items to appear as high as possible in the top-N of these ranked lists. In this
paper, we demonstrate how unscrupulous merchants can create item images that artificially
promote their products, improving their rankings. Recommender systems that use images
to address the cold start problem are vulnerable to this security risk. We describe
a new type of attack, Adversarial Item Promotion (AIP), that strikes directly at the
core of Top-N recommenders: the ranking mechanism itself. Existing work on adversarial
images in recommender systems investigates the implications of conventional attacks,
which target deep learning classifiers. In contrast, our AIP attacks are embedding
attacks that seek to push features representations in a way that fools the ranker
(not a classifier) and directly leads to item promotion. We introduce three AIP attacks
insider attack, expert attack, and semantic attack, which are defined with respect
to three successively more realistic attack models. Our experiments evaluate the danger
of these attacks when mounted against three representative visually-aware recommender
algorithms in a framework that uses images to address cold start. We also evaluate
potential defenses, including adversarial training and find that common, currently-existing,
techniques do not eliminate the danger of AIP attacks. In sum, we show that using
images to address cold start opens recommender systems to potential threats with clear
practical implications.},
  doi       = {10.1145/3442381.3449891},
  isbn      = {9781450383127},
  location  = {Ljubljana, Slovenia},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3442381.3449891},
}

@inproceedings{10.1145/3372297.3417279,
author = {Rochet, Florentin and Wails, Ryan and Johnson, Aaron and Mittal, Prateek and Pereira, Olivier},
title = {CLAPS: Client-Location-Aware Path Selection in Tor},
year = {2020},
isbn = {9781450370899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3372297.3417279},
doi = {10.1145/3372297.3417279},
abstract = {Much research has investigated improving the security and performance of Tor by having
Tor clients choose paths through the network in a way that depends on the client's
location. However, this approach has been demonstrated to lead to serious deanonymization
attacks. Moreover, we show how in some scenarios it can lead to significant performance
degradation. For example, we demonstrate that using the recently-proposed Counter-RAPTOR
system when guard bandwidth isn't abundant could increase median download times by
28.7%. We propose the CLAPS system for performing client-location-aware path selection,
which fixes the known security and performance issues of existing designs. We experimentally
compare the security and performance of CLAPS to Counter-RAPTOR and DeNASA. CLAPS
puts a strict bound on the leakage of information about the client's location, where
the other systems could completely reveal it after just a few connections. It also
guarantees a limit on the advantage that an adversary can obtain by strategic relay
placement, which we demonstrate to be overwhelming against the other systems. Finally,
due to a powerful formalization of path selection as an optimization problem, CLAPS
is approaching or even exceeding the original goals of algorithms to which it is applied,
while solving their known deficiencies.},
booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
pages = {17–34},
numpages = {18},
keywords = {anonymity, tor, onion routing},
location = {Virtual Event, USA},
series = {CCS '20}
}

@inproceedings{10.1145/3385003.3410925,
author = {Chen, Steven and Carlini, Nicholas and Wagner, David},
title = {Stateful Detection of Black-Box Adversarial Attacks},
year = {2020},
isbn = {9781450376112},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3385003.3410925},
doi = {10.1145/3385003.3410925},
abstract = {The problem of adversarial examples, evasion attacks on machine learning classifiers,
has proven extremely difficult to solve. This is true even in the black-box threat
model, as is the case in many practical settings. Here, the classifier is hosted as
a remote service and the adversary does not have direct access to the model parameters.This
paper argues that in such settings, defenders have a larger space of actions than
previously studied. Specifically, we deviate from the implicit assumption made by
prior work that a defense must be a stateless function that operates on individual
examples, and evaluate the space of stateful defenses.We develop a defense designed
to detect the process of generating adversarial examples. By keeping a history of
the past queries, a defender can try to identify when a sequence of queries appears
to be for the purpose of generating an adversarial example. We then introduce query
blinding, a new class of attacks designed to bypass defenses that rely on such a defense
approach. We believe that expanding the study of adversarial examples from stateless
classifiers to stateful systems is not only more realistic for many black-box settings,
but also gives the defender a much-needed advantage in responding to the adversary.},
booktitle = {Proceedings of the 1st ACM Workshop on Security and Privacy on Artificial Intelligence},
pages = {30–39},
numpages = {10},
keywords = {neural networks, adversarial examples, detection, black box attack},
location = {Taipei, Taiwan},
series = {SPAI '20}
}

@inproceedings{10.1145/3377929.3398119,
author = {Truong, Thanh Cong and Huynh, Tan-Phuoc and Zelinka, Ivan},
title = {Applications of Swarm Intelligence Algorithms Countering the Cyber Threats},
year = {2020},
isbn = {9781450371278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377929.3398119},
doi = {10.1145/3377929.3398119},
abstract = {In recent years, swarm intelligence in particular, and bio-inspired computing, in
general, have successfully utilized in a number of majors from science, engineering
to industry. Therefore, it is logical to investigate how such techniques might contribute
in the field of cybersecurity. This paper covers swarm-based intelligence techniques
for enhancing cybersecurity as well as replenish the literature with fresh reviews
on swarm-based methods. Furthermore, challenges and possible future directions when
applying swam-based methods in the field of cybersecurity are also discussed, which
will offer useful insights for researchers and practitioners.},
booktitle = {Proceedings of the 2020 Genetic and Evolutionary Computation Conference Companion},
pages = {1476–1485},
numpages = {10},
keywords = {parameter opimization, cybersecurity, swarm intelligence, feature selection, SI algorithms},
location = {Canc\'{u}n, Mexico},
series = {GECCO '20}
}

@inproceedings{10.1145/3015135.3015136,
author = {Salem, Aleieldin and Banescu, Sebastian},
title = {Metadata Recovery from Obfuscated Programs Using Machine Learning},
year = {2016},
isbn = {9781450348416},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3015135.3015136},
doi = {10.1145/3015135.3015136},
abstract = {Obfuscation is a mechanism used to hinder reverse engineering of programs. To cope
with the large number of obfuscated programs, especially malware, reverse engineers
automate the process of deobfuscation i.e. extracting information from obfuscated
programs. Deobfuscation techniques target specific obfuscation transformations, which
requires reverse engineers to manually identify the transformations used by a program,
in what is known as metadata recovery attack. In this paper, we present Oedipus, a
Python framework that uses machine learning classifiers viz., decision trees and naive
Bayes, to automate metadata recovery attacks against obfuscated programs. We evaluated
Oedipus' performance using two datasets totaling 1960 unobfuscated C programs, which
were used to generate 11.075 programs obfuscated using 30 configurations of 6 different
obfuscation transformations. Our results empirically show the feasibility of using
machine learning to implement the metadata recovery attacks with classification accuracies
of 100% in some cases.},
booktitle = {Proceedings of the 6th Workshop on Software Security, Protection, and Reverse Engineering},
articleno = {1},
numpages = {11},
keywords = {reverse engineering, obfuscation, machine learning},
location = {Los Angeles, California, USA},
series = {SSPREW '16}
}

@inproceedings{10.1145/3394486.3403241,
author = {Pang, Ren and Zhang, Xinyang and Ji, Shouling and Luo, Xiapu and Wang, Ting},
title = {AdvMind: Inferring Adversary Intent of Black-Box Attacks},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403241},
doi = {10.1145/3394486.3403241},
abstract = {Deep neural networks (DNNs) are inherently susceptible to adversarial attacks even
under black-box settings, in which the adversary only has query access to the target
models. In practice, while it may be possible to effectively detect such attacks (e.g.,
observing massive similar but non-identical queries), it is often challenging to exactly
infer the adversary intent (e.g., the target class of the adversarial example the
adversary attempts to craft) especially during early stages of the attacks, which
is crucial for performing effective deterrence and remediation of the threats in many
scenarios.In this paper, we present AdvMind, a new class of estimation models that
infer the adversary intent of black-box adversarial attacks in a robust and prompt
manner. Specifically, to achieve robust detection, AdvMind accounts for the adversary
adaptiveness such that her attempt to conceal the target will significantly increase
the attack cost (e.g., in terms of the number of queries); to achieve prompt detection,
AdvMind proactively synthesizes plausible query results to solicit subsequent queries
from the adversary that maximally expose her intent. Through extensive empirical evaluation
on benchmark datasets and state-of-the-art black-box attacks, we demonstrate that
on average AdvMind detects the adversary intent with over 75% accuracy after observing
less than 3 query batches and meanwhile increases the cost of adaptive attacks by
over 60%. We further discuss the possible synergy between AdvMind and other defense
methods against black-box adversarial attacks, pointing to several promising research
directions.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {1899–1907},
numpages = {9},
keywords = {intent inference, neural networks, black-box, defense, adversarial examples},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@inproceedings{10.1145/3394171.3413898,
author = {Dai, Tao and Feng, Yan and Wu, Dongxian and Chen, Bin and Lu, Jian and Jiang, Yong and Xia, Shu-Tao},
title = {DIPDefend: Deep Image Prior Driven Defense against Adversarial Examples},
year = {2020},
isbn = {9781450379885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394171.3413898},
doi = {10.1145/3394171.3413898},
abstract = {Deep neural networks (DNNs) have shown serious vulnerability to adversarial examples
with imperceptible perturbation to clean images. Most existing input-transformation
based defense methods (e.g., ComDefend) rely heavily on the learned external priors
from an external large training dataset, while neglecting the rich image internal
priors of the input itself, thus limiting the generalization of the defense models
against the adversarial examples with biased image statistics from the external training
dataset. Motivated by deep image prior that can capture rich image statistics from
a single image, we propose an effective Deep Image Prior Driven Defense (DIPDefend)
method against adversarial examples. With a DIP generator to fit the target/adversarial
input, we find that our image reconstruction exhibits quite interesting learning preference
from a feature learning perspectives, i.e., the early stage primarily learns the robust
features resistant to adversarial perturbation, followed by learning non-robust features
that are sensitive to adversarial perturbation. Besides, we develop an adaptive stopping
strategy that adapts our method to diverse images. In this way, the proposed model
obtains a unique defender for each individual adversarial input, thus being robust
to various attackers. Experimental results demonstrate the superiority of our method
over the state-of-the-art defense methods against white-box and black-box adversarial
attacks.},
booktitle = {Proceedings of the 28th ACM International Conference on Multimedia},
pages = {1404–1412},
numpages = {9},
keywords = {adversarial example, deep neural network, defense, image prior},
location = {Seattle, WA, USA},
series = {MM '20}
}

@inproceedings{10.1145/3299874.3318031,
author = {Tehranipoor, Fatemeh and Karimian, Nima and Mozaffari Kermani, Mehran and Mahmoodi, Hamid},
title = {Deep RNN-Oriented Paradigm Shift through BOCANet: Broken Obfuscated Circuit Attack},
year = {2019},
isbn = {9781450362528},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3299874.3318031},
doi = {10.1145/3299874.3318031},
abstract = {Logic encryption obfuscation has been used for thwarting counterfeiting, overproduction,
and reverse engineering but vulnerable to attacks. However, it was recently shown
that satisfiability - checking (SAT) can potentially compromise hardware obfuscation
circuits. In this paper, we develop a novel attack called BOCANet that can be beneficial
from deep learning architecture to compromise hardware obfuscation circuits's key.
Our approach involves exploiting deep recurrent neural network (D-RNN) model, and
developing attack model to compromise the obfuscated hardware at least an order-of
magnitude more efficiently and under resource-constrained scenarios. In our experiments,
the BOCANet approach achieves an average success rate of 100% for 32 bit key size,
93.4% for 64 bit key size, 92.2% and 91.7% for 128 and 256 bit key size, respectively.},
booktitle = {Proceedings of the 2019 on Great Lakes Symposium on VLSI},
pages = {335–338},
numpages = {4},
keywords = {hardware obfuscation, deep recurrent neural network, logic encryption},
location = {Tysons Corner, VA, USA},
series = {GLSVLSI '19}
}

@article{10.1145/3417987,
author = {Waheed, Nazar and He, Xiangjian and Ikram, Muhammad and Usman, Muhammad and Hashmi, Saad Sajid and Usman, Muhammad},
title = {Security and Privacy in IoT Using Machine Learning and Blockchain: Threats and Countermeasures},
year = {2020},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3417987},
doi = {10.1145/3417987},
abstract = {Security and privacy of users have become significant concerns due to the involvement
of the Internet of Things (IoT) devices in numerous applications. Cyber threats are
growing at an explosive pace making the existing security and privacy measures inadequate.
Hence, everyone on the Internet is a product for hackers. Consequently, Machine Learning
(ML) algorithms are used to produce accurate outputs from large complex databases,
where the generated outputs can be used to predict and detect vulnerabilities in IoT-based
systems. Furthermore, Blockchain (BC) techniques are becoming popular in modern IoT
applications to solve security and privacy issues. Several studies have been conducted
on either ML algorithms or BC techniques. However, these studies target either security
or privacy issues using ML algorithms or BC techniques, thus posing a need for a combined
survey on efforts made in recent years addressing both security and privacy issues
using ML algorithms and BC techniques. In this article, we provide a summary of research
efforts made in the past few years, from 2008 to 2019, addressing security and privacy
issues using ML algorithms and BC techniques in the IoT domain. First, we discuss
and categorize various security and privacy threats reported in the past 12 years
in the IoT domain. We then classify the literature on security and privacy efforts
based on ML algorithms and BC techniques in the IoT domain. Finally, we identify and
illuminate several challenges and future research directions using ML algorithms and
BC techniques to address security and privacy issues in the IoT domain.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {122},
numpages = {37},
keywords = {machine learning, cybersecurity, Internet of Things, Blockchain}
}

@inproceedings{10.1145/2488388.2488474,
author = {Nikiforakis, Nick and Van Acker, Steven and Meert, Wannes and Desmet, Lieven and Piessens, Frank and Joosen, Wouter},
title = {Bitsquatting: Exploiting Bit-Flips for Fun, or Profit?},
year = {2013},
isbn = {9781450320351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2488388.2488474},
doi = {10.1145/2488388.2488474},
abstract = {Over the last fifteen years, several types of attacks against domain names and the
companies relying on them have been observed. The well-known cybersquatting of domain
names gave way to typosquatting, the abuse of a user's mistakes when typing a URL
in her browser's address bar. Recently, a new attack against domain names surfaced,
namely bitsquatting. In bitsquatting, an attacker leverages random bit-errors occurring
in the memory of commodity computers and smartphones, to redirect Internet traffic
to attacker-controlled domains.In this paper, we report on a large-scale experiment,
measuring the adoption of bitsquatting by the domain-squatting community through the
tracking of registrations of bitsquatting domains targeting popular web sites over
a 9-month period. We show how new bitsquatting domains are registered daily and how
attackers are trying to monetize their domains through the use of ads, abuse of affiliate
programs and even malware installations. Lastly, given the discovered prevalence of
bitsquatting, we review possible defense measures that companies, software developers
and Internet Service Providers can use to protect against it.},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {989–998},
numpages = {10},
keywords = {bitsquatting, cybersquatting, affiliate abuse, domain name},
location = {Rio de Janeiro, Brazil},
series = {WWW '13}
}

@inproceedings{10.1145/3380446.3430628,
author = {Ashrafiamiri, Marzieh and Manoj Pudukotai Dinakarrao, Sai and Afandizadeh Zargari, Amir Hosein and Seo, Minjun and Kurdahi, Fadi and Homayoun, Houman},
title = {R2AD: Randomization and Reconstructor-Based Adversarial Defense on Deep Neural Network},
year = {2020},
isbn = {9781450375191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3380446.3430628},
doi = {10.1145/3380446.3430628},
abstract = {Machine learning (ML) has been widely adopted in a plethora of applications ranging
from simple time-series forecasting to computer security and autonomous systems. Despite
the robustness by the ML algorithms against random noise, it has been shown that inclusion
of specially crafted perturbations to the input data termed as adversarial samples
can lead to a significant degradation in the ML performance. Existing defenses to
mitigate or minimize the impact of adversarial samples including adversarial training
or randomization are confined to specific categories of adversaries, compute-intensive
and/or often lead to reduce performance even without adversaries. To overcome the
shortcomings of the existing works on adversarial defense, we propose a two-stage
adversarial defense technique (R2AD). To thwart the exploitation of the deep neural
network by the attacker, we first include a random nullification (RNF) layer. The
RNF nullifies/removes some of the features from the input randomly to reduce the impact
of adversarial noise and minimizes attacker's feasibility to extract the model parameters.
However, the removal of input features through RNF leads to a reduction in the performance
of the ML. As an antidote, we equip the network with a Reconstructor. The Reconstructor
primarily contributes to reconstructing the input data by utilizing an autoencoder
network, but based on the distribution of the normal samples, thereby improving the
performance, and also being robust to the adversarial noise. We evaluated the performance
of proposed multi-stage R^2AD on the MNIST digits and Fashion-MNIST datasets against
multiple adversarial attacks including FGSM, JSMA, BIM, Deepfool, and CW attacks.
Our findings report improvements as high as 80% in the performance compared to the
existing defenses such as adversarial training and randomization-based defense.},
booktitle = {Proceedings of the 2020 ACM/IEEE Workshop on Machine Learning for CAD},
pages = {21–26},
numpages = {6},
keywords = {computer vision, randomization, adversarial learning, data augmentation, machine learning},
location = {Virtual Event, Iceland},
series = {MLCAD '20}
}

@article{10.1145/3410447,
author = {Ahmed, Chuadhry Mujeeb and Mathur, Aditya P. and Ochoa, Mart\'{\i}n},
title = {<i>NoiSense Print</i>: Detecting Data Integrity Attacks on Sensor Measurements Using Hardware-Based Fingerprints},
year = {2020},
issue_date = {January 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {1},
issn = {2471-2566},
url = {https://doi.org/10.1145/3410447},
doi = {10.1145/3410447},
abstract = {Fingerprinting of various physical and logical devices has been proposed for uniquely
identifying users or devices of mainstream IT systems such as PCs, laptops, and smart
phones. However, the application of such techniques in Industrial Control Systems
(ICS) is less explored for reasons such as a lack of direct access to such systems
and the cost of faithfully reproducing realistic threat scenarios. This work addresses
the feasibility of using fingerprinting techniques in the context of realistic ICS
related to water treatment and distribution systems. A model-free sensor fingerprinting
scheme (NoiSense) and a model-based sensor fingerprinting scheme (NoisePrint) are
proposed. Using extensive experimentation with sensors, it is shown that noise patterns
due to microscopic imperfections in hardware manufacturing can uniquely identify sensors
with accuracy as high as 97%. The proposed technique can be used to detect physical
attacks, such as the replacement of legitimate sensors by faulty or manipulated sensors.
For NoisePrint, a combined fingerprint for sensor and process noise is created. The
difference (called residual), between expected and observed values, i.e., noise, is
used to derive a model of the system. It was found that in steady state the residual
vector is a function of process and sensor noise. Data from experiments reveals that
a multitude of sensors can be uniquely identified with a minimum accuracy of 90% based
on NoisePrint. Also proposed is a novel challenge-response protocol that exposes more
powerful cyber-attacks, including replay attacks.},
journal = {ACM Trans. Priv. Secur.},
month = sep,
articleno = {2},
numpages = {35},
keywords = {sensors security, device fingerprinting, sensor fingerprinting, machine learning-based intrusion detection, ICS security, sensor noise, CPS security, attack detection, challenge response protocol, CPS threat modeling, process noise, Cyber physical systems, physical attacks}
}

@inproceedings{10.1145/3341161.3345026,
author = {Avram, Mihai Valentin and Mishra, Shubhanshu and Parulian, Nikolaus Nova and Diesner, Jana},
title = {Adversarial Perturbations to Manipulate the Perception of Power and Influence in Networks},
year = {2019},
isbn = {9781450368681},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341161.3345026},
doi = {10.1145/3341161.3345026},
abstract = {Observed social networks are often considered as proxies for underlying social networks.
The analysis of observed networks oftentimes involves the identification of influential
nodes via various centrality metrics. Our work is motivated by recent research on
the investigation and design of adversarial attacks on machine learning systems. We
apply the concept of adversarial attacks to social networks by studying strategies
by which an adversary can minimally perturb the observed network structure to achieve
their target function of modifying the ranking of nodes according to centrality measures.
This can represent the attempts of an adversary to boost or demote the degree to which
others perceive them as influential or powerful. It also allows us to study the impact
of adversarial attacks on targets and victims, and to design metrics and security
measures that help to identify and mitigate adversarial network attacks. We conduct
a series of experiments on synthetic network data to identify attacks that allow the
adversarial node to achieve their objective with a single move. We test this approach
on different common network topologies and for common centrality metrics. We find
that there is a small set of moves that result in the adversary achieving their objective,
and this set is smaller for decreasing centrality metrics than for increasing them.
These results can help with assessing the robustness of centrality measures. The notion
of changing social network data to yield adversarial outcomes has practical implications,
e.g., for information diffusion on social media, influence and power dynamics in social
systems, and improving network security.},
booktitle = {Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {986–994},
numpages = {9},
keywords = {centrality measures, network robustness, social network analysis, adversarial attacks},
location = {Vancouver, British Columbia, Canada},
series = {ASONAM '19}
}

@inproceedings{10.1145/3442188.3445879,
author = {Cheng, Victoria and Suriyakumar, Vinith M. and Dullerud, Natalie and Joshi, Shalmali and Ghassemi, Marzyeh},
title = {Can You Fake It Until You Make It? Impacts of Differentially Private Synthetic Data on Downstream Classification Fairness},
year = {2021},
isbn = {9781450383097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442188.3445879},
doi = {10.1145/3442188.3445879},
abstract = {The recent adoption of machine learning models in high-risk settings such as medicine
has increased demand for developments in privacy and fairness. Rebalancing skewed
datasets using synthetic data created by generative adversarial networks (GANs) has
shown potential to mitigate disparate impact on minoritized subgroups. However, such
generative models are subject to privacy attacks that can expose sensitive data from
the training dataset. Differential privacy (DP) is the current leading solution for
privacy-preserving machine learning. Differentially private GANs (DP GANs) are often
considered a potential solution for improving model fairness while maintaining privacy
of sensitive training data. We investigate the impact of using synthetic images from
DP GANs on downstream classification model utility and fairness. We demonstrate that
existing DP GANs cannot simultaneously maintain model utility, privacy, and fairness.
The images generated from GAN models trained with DP exhibit extreme decreases in
image quality and utility which leads to poor downstream classification model performance.
Our evaluation highlights the friction between privacy, fairness, and utility and
how this directly translates into real loss of performance and representation in common
machine learning settings. Our results show that additional work improving the utility
and fairness of DP generative models is required before they can be utilized as a
potential solution to privacy and fairness issues stemming from lack of diversity
in the training dataset.},
booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
pages = {149–160},
numpages = {12},
location = {Virtual Event, Canada},
series = {FAccT '21}
}

@inproceedings{10.1145/3338468.3356828,
author = {G\'{o}mez-Boix, Alejandro and Frey, Davide and Bromberg, Y\'{e}rom-David and Baudry, Benoit},
title = {A Collaborative Strategy for Mitigating Tracking through Browser Fingerprinting},
year = {2019},
isbn = {9781450368285},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338468.3356828},
doi = {10.1145/3338468.3356828},
abstract = {Browser fingerprinting is a technique that collects information about the browser
configuration and the environment in which it is running. This information is so diverse
that it can partially or totally identify users online. Over time, several countermeasures
have emerged to mitigate tracking through browser fingerprinting. However, these measures
do not offer full coverage in terms of privacy protection, as some of them may introduce
inconsistencies or unusual behaviors, making these users stand out from the rest.We
address these limitations by proposing a novel approach that minimizes both the identifiability
of users and the required changes to browser configuration. To this end, we exploit
clustering algorithms to identify the devices that are prone to share the same or
similar fingerprints and to provide them with a new non-unique fingerprint. We then
use this fingerprint to automatically assemble and run web browsers through virtualization
within a docker container. Thus all the devices in the same cluster will end up running
a web browser with an indistinguishable and consistent fingerprint.},
booktitle = {Proceedings of the 6th ACM Workshop on Moving Target Defense},
pages = {67–78},
numpages = {12},
keywords = {browser fingerprinting, software diversity, privacy protection},
location = {London, United Kingdom},
series = {MTD'19}
}

@inproceedings{10.1145/3411495.3421356,
author = {Liu, Yuntao and Srivastava, Ankur},
title = {GANRED: GAN-Based Reverse Engineering of DNNs via Cache Side-Channel},
year = {2020},
isbn = {9781450380843},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411495.3421356},
doi = {10.1145/3411495.3421356},
abstract = {In recent years, deep neural networks (DNN) have become an important type of intellectual
property due to their high performance on various classification tasks. As a result,
DNN stealing attacks have emerged. Many attack surfaces have been exploited, among
which cache timing side-channel attacks are hugely problematic because they do not
need physical probing or direct interaction with the victim to estimate the DNN model.
However, existing cache-side-channel-based DNN reverse engineering attacks rely on
analyzing the binary code of the DNN library that must be shared between the attacker
and the victim in the main memory. In reality, the DNN library code is often inaccessible
because 1) the code is proprietary, or 2) memory sharing has been disabled by the
operating system. In our work, we propose GANRED, an attack approach based on the
generative adversarial nets (GAN) framework which utilizes cache timing side-channel
information to accurately recover the structure of DNNs without memory sharing or
code access. The benefit of GANRED is four-fold. 1) There is no need for DNN library
code analysis. 2) No shared main memory segment between the victim and the attacker
is needed. 3) Our attack locates the exact structure of the victim model, unlike existing
attacks which only narrow down the structure search space. 4) Our attack efficiently
scales to deeper DNNs, exhibiting only linear growth in the number of layers in the
victim DNN.},
booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Cloud Computing Security Workshop},
pages = {41–52},
numpages = {12},
keywords = {prime+probe, deep neural netorks, reverse engineering, cache side-channel, generative adversarial nets},
location = {Virtual Event, USA},
series = {CCSW'20}
}

@inproceedings{10.1145/2991079.2991112,
author = {Alrwais, Sumayah and Yuan, Kan and Alowaisheq, Eihal and Liao, Xiaojing and Oprea, Alina and Wang, XiaoFeng and Li, Zhou},
title = {Catching Predators at Watering Holes: Finding and Understanding Strategically Compromised Websites},
year = {2016},
isbn = {9781450347716},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2991079.2991112},
doi = {10.1145/2991079.2991112},
abstract = {Unlike a random, run-of-the-mill website infection, in a strategic web attack, the
adversary carefully chooses the target frequently visited by an organization or a
group of individuals to compromise, for the purpose of gaining a step closer to the
organization or collecting information from the group. This type of attacks, called
"watering hole", have been increasingly utilized by APT actors to get into the internal
networks of big companies and government agencies or monitor politically oriented
groups. With its importance, little has been done so far to understand how the attack
works, not to mention any concrete step to counter this threat.In this paper, we report
our first step toward better understanding this emerging threat, through systematically
discovering and analyzing new watering hole instances and attack campaigns. This was
made possible by a carefully designed methodology, which repeatedly monitors a large
number potential watering hole targets to detect unusual changes that could be indicative
of strategic compromises. Running this system on the HTTP traffic generated from visits
to 61K websites for over 5 years, we are able to discover and confirm 17 watering
holes and 6 campaigns never reported before. Given so far there are merely 29 watering
holes reported by blogs and technical reports, the findings we made contribute to
the research on this attack vector, by adding 59% more attack instances and information
about how they work to the public knowledge.Analyzing the new watering holes allows
us to gain deeper understanding of these attacks, such as repeated compromises of
political websites, their long lifetimes, unique evasion strategy (leveraging other
compromised sites to serve attack payloads) and new exploit techniques (no malware
delivery, web only information gathering). Also, our study brings to light interesting
new observations, including the discovery of a recent JSONP attack on an NGO website
that has been widely reported and apparently forced the attack to stop.},
booktitle = {Proceedings of the 32nd Annual Conference on Computer Security Applications},
pages = {153–166},
numpages = {14},
location = {Los Angeles, California, USA},
series = {ACSAC '16}
}

@inproceedings{10.1145/3319535.3354209,
author = {Yao, Yuanshun and Li, Huiying and Zheng, Haitao and Zhao, Ben Y.},
title = {Latent Backdoor Attacks on Deep Neural Networks},
year = {2019},
isbn = {9781450367479},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3319535.3354209},
doi = {10.1145/3319535.3354209},
abstract = {Recent work proposed the concept of backdoor attacks on deep neural networks (DNNs),
where misclassification rules are hidden inside normal models, only to be triggered
by very specific inputs. However, these "traditional" backdoors assume a context where
users train their own models from scratch, which rarely occurs in practice. Instead,
users typically customize "Teacher" models already pretrained by providers like Google,
through a process called transfer learning. This customization process introduces
significant changes to models and disrupts hidden backdoors, greatly reducing the
actual impact of backdoors in practice. In this paper, we describe latent backdoors,
a more powerful and stealthy variant of backdoor attacks that functions under transfer
learning. Latent backdoors are incomplete backdoors embedded into a "Teacher" model,
and automatically inherited by multiple "Student" models through transfer learning.
If any Student models include the label targeted by the backdoor, then its customization
process completes the backdoor and makes it active. We show that latent backdoors
can be quite effective in a variety of application contexts, and validate its practicality
through real-world attacks against traffic sign recognition, iris identification of
volunteers, and facial recognition of public figures (politicians). Finally, we evaluate
4 potential defenses, and find that only one is effective in disrupting latent backdoors,
but might incur a cost in classification accuracy as tradeoff.},
booktitle = {Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security},
pages = {2041–2055},
numpages = {15},
keywords = {neural networks, artificial intelligence, machine learning},
location = {London, United Kingdom},
series = {CCS '19}
}

@article{10.1145/2542049,
author = {Mitchell, Robert and Chen, Ing-Ray},
title = {A Survey of Intrusion Detection Techniques for Cyber-Physical Systems},
year = {2014},
issue_date = {April 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2542049},
doi = {10.1145/2542049},
abstract = {Pervasive healthcare systems, smart grids, and unmanned aircraft systems are examples
of Cyber-Physical Systems (CPSs) that have become highly integrated in the modern
world. As this integration deepens, the importance of securing these systems increases.
In order to identify gaps and propose research directions in CPS intrusion detection
research, we survey the literature of this area. Our approach is to classify modern
CPS Intrusion Detection System (IDS) techniques based on two design dimensions: detection
technique and audit material. We summarize advantages and drawbacks of each dimension’s
options. We also summarize the most and least studied CPS IDS techniques in the literature
and provide insight on the effectiveness of IDS techniques as they apply to CPSs.
Finally, we identify gaps in CPS IDS research and suggest future research areas.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {55},
numpages = {29},
keywords = {security, intrusion detection, Cyber-physical systems, classification}
}

@article{10.1145/3361147,
author = {Hoque, Tamzidul and Yang, Kai and Karam, Robert and Tajik, Shahin and Forte, Domenic and Tehranipoor, Mark and Bhunia, Swarup},
title = {Hidden in Plaintext: An Obfuscation-Based Countermeasure against FPGA Bitstream Tampering Attacks},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {1},
issn = {1084-4309},
url = {https://doi.org/10.1145/3361147},
doi = {10.1145/3361147},
abstract = {Field Programmable Gate Arrays (FPGAs) have become an attractive choice for diverse
applications due to their reconfigurability and unique security features. However,
designs mapped to FPGAs are prone to malicious modifications or tampering of critical
functions. Besides, targeted modifications have demonstrably compromised FPGA implementations
of various cryptographic primitives. Existing security measures based on encryption
and authentication can be bypassed using their side-channel vulnerabilities to execute
bitstream tampering attacks. Furthermore, numerous resource-constrained applications
are now equipped with low-end FPGAs, which may not support power-hungry cryptographic
solutions. In this article, we propose a novel obfuscation-based approach to achieve
strong resistance against both random and targeted pre-configuration tampering of
critical functions in an FPGA design. Our solution first identifies the unique structural
and functional features that separate the critical function from the rest of the design
using a machine learning guided framework. The selected features are eliminated by
applying appropriate obfuscation techniques, many of which take advantage of “FPGA
dark silicon”—unused lookup table resources—to mask the critical functions. Furthermore,
following the same obfuscation principle, a redundancy-based technique is proposed
to thwart targeted, rule-based, and random tampering. We have developed a complete
methodology and custom software toolflow that integrates with commercial tools. By
applying the masking technique on a design containing AES, we show the effectiveness
of the proposed framework in hiding the critical S-Box function. We implement the
redundancy integrated solution in various cryptographic designs to analyze the overhead.
To protect 16.2% critical component of a design, the proposed approach incurs an average
area overhead of only 2.4% over similar redundancy-based approaches, while achieving
strong security.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = nov,
articleno = {4},
numpages = {32},
keywords = {FPGA security, FPGA bitstream tampering, Trojan prevention}
}

@inproceedings{10.1145/2508859.2516733,
author = {Weiner, Michael and Massar, Maurice and Tews, Erik and Giese, Dennis and Wieser, Wolfgang},
title = {Security Analysis of a Widely Deployed Locking System},
year = {2013},
isbn = {9781450324779},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2508859.2516733},
doi = {10.1145/2508859.2516733},
abstract = {Electronic locking systems are rather new products in the physical access control
market. In contrast to mechanical locking systems, they provide several convenient
features such as more flexible access rights management, the possibility to revoke
physical keys and the claim that electronic keys cannot be cloned as easily as their
mechanical counterparts. While for some electronic locks, mechanical flaws have been
found, only a few publications analyzed the cryptographic security of electronic locking
systems. In this paper, we analyzed the electronic security of an electronic locking
system which is still widely deployed in the field.We reverse-engineered the radio
protocol and cryptographic primitives used in the system. While we consider the system
concepts to be well-designed, we discovered some implementation flaws that allow the
extraction of a system-wide master secret with a brute force attack or by performing
a Differential Power Analysis attack to any electronic key. In addition, we discovered
a weakness in the Random Number Generator that allows opening a door without breaking
cryptography under certain circumstances. We suggest administrative and technical
countermeasures against all proposed attacks.Finally, we give an examination of electronic
lock security standards and recommend changes to one widely used standard that can
help to improve the security of newly developed products.},
booktitle = {Proceedings of the 2013 ACM SIGSAC Conference on Computer &amp; Communications Security},
pages = {929–940},
numpages = {12},
keywords = {des, power analysis, side-channel attack, physical security, prng, embedded security, cryptography, locking system},
location = {Berlin, Germany},
series = {CCS '13}
}

@inproceedings{10.1145/2976749.2978342,
author = {Wang, Kai and Zhang, Yuqing and Liu, Peng},
title = {Call Me Back! Attacks on System Server and System Apps in Android through Synchronous Callback},
year = {2016},
isbn = {9781450341394},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2976749.2978342},
doi = {10.1145/2976749.2978342},
abstract = {Android is the most commonly used mobile device operation system. The core of Android,
the System Server (SS), is a multi-threaded process that provides most of the system
services. Based on a new understanding of the security risks introduced by the callback
mechanism in system services, we have discovered a general type of design flaw. A
vulnerability detection tool has been designed and implemented based on static taint
analysis. We applied the tool on all the 80 system services in the SS of Android 5.1.0.
With its help, we have discovered six previously unknown vulnerabilities, which are
further confirmed on Android 2.3.7-6.0.1. According to our analysis, about 97.3% of
the entire 1.4 billion real-world Android devices are vulnerable. Our proof-of-concept
attack proves that the vulnerabilities can enable a malicious app to freeze critical
system functionalities or soft-reboot the system immediately. It is a neat type of
denial-of-service at-tack. We also proved that the attacks can be conducted at mission
critical moments to achieve meaningful goals, such as anti anti-virus, anti process-killer,
hindering app updates or system patching. After being informed, Google confirmed our
findings promptly. Several suggestions on how to use callbacks safely are also proposed
to Google.},
booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
pages = {92–103},
numpages = {12},
keywords = {mobile security, taint analysis, synchronous callback, vulnerability detection, denial of service},
location = {Vienna, Austria},
series = {CCS '16}
}

@inproceedings{10.1145/3359789.3359790,
author = {Gao, Yansong and Xu, Change and Wang, Derui and Chen, Shiping and Ranasinghe, Damith C. and Nepal, Surya},
title = {STRIP: A Defence against Trojan Attacks on Deep Neural Networks},
year = {2019},
isbn = {9781450376280},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359789.3359790},
doi = {10.1145/3359789.3359790},
abstract = {A recent trojan attack on deep neural network (DNN) models is one insidious variant
of data poisoning attacks. Trojan attacks exploit an effective backdoor created in
a DNN model by leveraging the difficulty in interpretability of the learned model
to misclassify any inputs signed with the attacker's chosen trojan trigger. Since
the trojan trigger is a secret guarded and exploited by the attacker, detecting such
trojan inputs is a challenge, especially at run-time when models are in active operation.
This work builds <u>STR</u>ong <u>I</u>ntentional <u>P</u>erturbation (STRIP) based
run-time trojan attack detection system and focuses on vision system. We intentionally
perturb the incoming input, for instance by superimposing various image patterns,
and observe the randomness of predicted classes for perturbed inputs from a given
deployed model---malicious or benign. A low entropy in predicted classes violates
the input-dependence property of a benign model and implies the presence of a malicious
input---a characteristic of a trojaned input. The high efficacy of our method is validated
through case studies on three popular and contrasting datasets: MNIST, CIFAR10 and
GTSRB. We achieve an overall false acceptance rate (FAR) of less than 1%, given a
preset false rejection rate (FRR) of 1%, for different types of triggers. Using CIFAR10
and GTSRB, we have empirically achieved result of 0% for both FRR and FAR. We have
also evaluated STRIP robustness against a number of trojan attack variants and adaptive
attacks.},
booktitle = {Proceedings of the 35th Annual Computer Security Applications Conference},
pages = {113–125},
numpages = {13},
keywords = {trojan attack, deep learning, input-agnostic, backdoor attack},
location = {San Juan, Puerto Rico, USA},
series = {ACSAC '19}
}

@inproceedings{10.1145/3339252.3340497,
author = {Parker, Luke R. and Yoo, Paul D. and Asyhari, Taufiq A. and Chermak, Lounis and Jhi, Yoonchan and Taha, Kamal},
title = {DEMISe: Interpretable Deep Extraction and Mutual Information Selection Techniques for IoT Intrusion Detection},
year = {2019},
isbn = {9781450371643},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3339252.3340497},
doi = {10.1145/3339252.3340497},
abstract = {Recent studies have proposed that traditional security technology -- involving pattern-matching
algorithms that check predefined pattern sets of intrusion signatures -- should be
replaced with sophisticated adaptive approaches that combine machine learning and
behavioural analytics. However, machine learning is performance driven, and the high
computational cost is incompatible with the limited computing power, memory capacity
and energy resources of portable IoT-enabled devices. The convoluted nature of deep-structured
machine learning means that such models also lack transparency and interpretability.
The knowledge obtained by interpretable learners is critical in security software
design. We therefore propose two novel models featuring a common Deep Extraction and
Mutual Information Selection (DEMISe) element which extracts features using a deep-structured
stacked autoencoder, prior to feature selection based on the amount of mutual information
(MI) shared between each feature and the class label. An entropy-based tree wrapper
is used to optimise the feature subsets identified by the DEMISe element, yielding
the DEMISe with Tree Evaluation and Regression Detection (DETEReD) model. This affords 'white box' insight, and achieves a time to build of 603 seconds, a 99.07% detection
rate, and 98.04% model accuracy. When tested against AWID, the best-referenced intrusion
detection dataset, the new models achieved a test error comparable to or better than
state-of-the-art machine-learning models, with a lower computational cost and higher
levels of transparency and interpretability.},
booktitle = {Proceedings of the 14th International Conference on Availability, Reliability and Security},
articleno = {98},
numpages = {10},
keywords = {deep learning, mutual information, Security mobility applications, lightweight intrusion detection, IoT, feature engineering, security of resource constrained devices, white-box modelling},
location = {Canterbury, CA, United Kingdom},
series = {ARES '19}
}

@inproceedings{10.1145/3144457.3144505,
author = {Riaz, Zohaib and D\"{u}rr, Frank and Rothermel, Kurt},
title = {Understanding Vulnerabilities of Location Privacy Mechanisms against Mobility Prediction Attacks},
year = {2017},
isbn = {9781450353687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3144457.3144505},
doi = {10.1145/3144457.3144505},
abstract = {In today's online social networks such as Facebook, users increasingly share their
location information as a popular type of personal information. However, since location
data can leak privacy-sensitive information about individuals such as the type of
places they like to visit, a number of location obfuscation mechanisms have been proposed
to avoid such disclosure. These mechanisms publish bigger regions containing the actual
user location in order to make it imprecise. Thus an attacker may find it hard to
precisely locate the user in a privacy-sensitive place such as a hospital.In this
paper, we show that state-of-the-art location obfuscation mechanisms do not provide
privacy guarantees against attacks based on mobility prediction. In this regard, we
design and demonstrate a mobility prediction attack that exploits location history
information of users and show its effectiveness on a year-long real-world location
dataset. In particular, our results show that such an attack can successfully de-obfuscate
up to 50% of sensitive user visits with high precision (≥ 80%), even when the location
history data used for the attack is already obfuscated. We also analyze the success
of our mobility prediction attacks and suggest important design improvements for future
location privacy mechanisms.},
booktitle = {Proceedings of the 14th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services},
pages = {252–261},
numpages = {10},
keywords = {mobility prediction, hidden Markov models, location privacy, attack algorithms, semantic location information},
location = {Melbourne, VIC, Australia},
series = {MobiQuitous 2017}
}

@inproceedings{10.1145/3302509.3311041,
author = {Chung, Keywhan and Kalbarczyk, Zbigniew T. and Iyer, Ravishankar K.},
title = {Availability Attacks on Computing Systems through Alteration of Environmental Control: Smart Malware Approach},
year = {2019},
isbn = {9781450362856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302509.3311041},
doi = {10.1145/3302509.3311041},
abstract = {In this paper, we demonstrate the feasibility of smart malware that advances state-of-the-art
attacks by (i) indirectly attacking a computing infrastructure through a cyber-physical
system (CPS) that manages the environment in which the computing enterprise operates,
(ii) disguising its malicious actions as accidental failures, and (iii) self-learning
attack strategies from cyber-physical system measurement data. We address all aspects
of the malware, including the construction of the self-learning malware and the launch
of a failure injection attack. We validate the attacks in a data-driven CPS simulation
environment developed as part of this study.},
booktitle = {Proceedings of the 10th ACM/IEEE International Conference on Cyber-Physical Systems},
pages = {1–12},
numpages = {12},
keywords = {cyber security, malware, CPS, cyber physical systems},
location = {Montreal, Quebec, Canada},
series = {ICCPS '19}
}

@inproceedings{10.1145/3406085.3409011,
author = {F\"{o}rd\H{o}s, Vikt\'{o}ria},
title = {Secure Design and Verification of Erlang Systems},
year = {2020},
isbn = {9781450380492},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3406085.3409011},
doi = {10.1145/3406085.3409011},
abstract = {Security is a critical part of software development, companies have the utmost responsibility
to protect their customers data against any threat. Secure design is a key enabler,
since it cultivates security awareness in software projects from day zero. In this
paper it is shown how to apply the principles of secure design to Erlang software
projects. An Erlang specific method to identify trust zones is presented. The high
risk vulnerabilities of the Erlang ecosystem are reviewed and grouped together using
the CIA triad model. A dataflow based static analysis together with a prototype to
verify security posture of a trust zone are introduced and evaluated using Riak Core
as a case study.},
booktitle = {Proceedings of the 19th ACM SIGPLAN International Workshop on Erlang},
pages = {31–40},
numpages = {10},
keywords = {Secure design, Security posture verification, Erlang, Static analysis, Trust zones},
location = {Virtual Event, USA},
series = {Erlang 2020}
}

@inproceedings{10.1145/3297067.3297096,
author = {Kaur, Gurpreet and Malik, Yasir and Samuel, Hamman and Jaafar, Fehmi},
title = {Detecting Blind Cross-Site Scripting Attacks Using Machine Learning},
year = {2018},
isbn = {9781450366052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297067.3297096},
doi = {10.1145/3297067.3297096},
abstract = {Cross-site scripting (XSS) is a scripting attack targeting web applications by injecting
malicious scripts into web pages. Blind XSS is a subset of stored XSS, where an attacker
blindly deploys malicious payloads in web pages that are stored in a persistent manner
on target servers. Most of the XSS detection techniques used to detect the XSS vulnerabilities
are inadequate to detect blind XSS attacks. In this research, we present machine learning
based approach to detect blind XSS attacks. Testing results help to identify malicious
payloads that are likely to get stored in databases through web applications.},
booktitle = {Proceedings of the 2018 International Conference on Signal Processing and Machine Learning},
pages = {22–25},
numpages = {4},
keywords = {Web Security, Vulnerability Detection, Cross-Site Scripting (XSS), Software Security, Machine Learning},
location = {Shanghai, China},
series = {SPML '18}
}

@article{10.1145/2897368,
author = {Kim, Yubin and Collins-Thompson, Kevyn and Teevan, Jaime},
title = {Using the Crowd to Improve Search Result Ranking and the Search Experience},
year = {2016},
issue_date = {July 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {4},
issn = {2157-6904},
url = {https://doi.org/10.1145/2897368},
doi = {10.1145/2897368},
abstract = {Despite technological advances, algorithmic search systems still have difficulty with
complex or subtle information needs. For example, scenarios requiring deep semantic
interpretation are a challenge for computers. People, on the other hand, are well
suited to solving such problems. As a result, there is an opportunity for humans and
computers to collaborate during the course of a search in a way that takes advantage
of the unique abilities of each. While search tools that rely on human intervention
will never be able to respond as quickly as current search engines do, recent research
suggests that there are scenarios where a search engine could take more time if it
resulted in a much better experience. This article explores how crowdsourcing can
be used at query time to augment key stages of the search pipeline. We first explore
the use of crowdsourcing to improve search result ranking. When the crowd is used
to replace or augment traditional retrieval components such as query expansion and
relevance scoring, we find that we can increase robustness against failure for query
expansion and improve overall precision for results filtering. However, the gains
that we observe are limited and unlikely to make up for the extra cost and time that
the crowd requires. We then explore ways to incorporate the crowd into the search
process that more drastically alter the overall experience. We find that using crowd
workers to support rich query understanding and result processing appears to be a
more worthwhile way to make use of the crowd during search. Our results confirm that
crowdsourcing can positively impact the search experience but suggest that significant
changes to the search process may be required for crowdsourcing to fulfill its potential
in search systems.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jul,
articleno = {50},
numpages = {24},
keywords = {Slow search, crowdsourcing, information retrieval}
}

@inproceedings{10.1145/2810103.2813654,
author = {Shu, Xiaokui and Yao, Danfeng and Ramakrishnan, Naren},
title = {Unearthing Stealthy Program Attacks Buried in Extremely Long Execution Paths},
year = {2015},
isbn = {9781450338325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2810103.2813654},
doi = {10.1145/2810103.2813654},
abstract = {Modern stealthy exploits can achieve attack goals without introducing illegal control
flows, e.g., tampering with non-control data and waiting for the modified data to
propagate and alter the control flow legally. Existing program anomaly detection systems
focusing on legal control flow attestation and short call sequence verification are
inadequate to detect such stealthy attacks. In this paper, we point out the need to
analyze program execution paths and discover event correlations in large-scale execution
windows among millions of instructions. We propose an anomaly detection approach with
two-stage machine learning algorithms to recognize diverse normal call-correlation
patterns and detect program attacks at both inter- and intra-cluster levels. We implement
a prototype of our approach and demonstrate its effectiveness against three real-world
attacks and four synthetic anomalies with less than 0.01% false positive rates and
0.1~1.3 ms analysis overhead per behavior instance (1k to 50k function or system calls).},
booktitle = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security},
pages = {401–413},
numpages = {13},
keywords = {intrusion detection, function call, long execution path, machine learning, program attack, event correlation},
location = {Denver, Colorado, USA},
series = {CCS '15}
}

@inproceedings{10.1145/3219819.3219910,
author = {Das, Nilaksh and Shanbhogue, Madhuri and Chen, Shang-Tse and Hohman, Fred and Li, Siwei and Chen, Li and Kounavis, Michael E. and Chau, Duen Horng},
title = {SHIELD: Fast, Practical Defense and Vaccination for Deep Learning Using JPEG Compression},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3219910},
doi = {10.1145/3219819.3219910},
abstract = {The rapidly growing body of research in adversarial machine learning has demonstrated
that deep neural networks (DNNs) are highly vulnerable to adversarially generated
images. This underscores the urgent need for practical defense techniques that can
be readily deployed to combat attacks in real-time. Observing that many attack strategies
aim to perturb image pixels in ways that are visually imperceptible, we place JPEG
compression at the core of our proposed SHIELD defense framework, utilizing its capability
to effectively "compress away" such pixel manipulation. To immunize a DNN model from
artifacts introduced by compression, SHIELD "vaccinates" the model by retraining it
with compressed images, where different compression levels are applied to generate
multiple vaccinated models that are ultimately used together in an ensemble defense.
On top of that, SHIELD adds an additional layer of protection by employing randomization
at test time that compresses different regions of an image using random compression
levels, making it harder for an adversary to estimate the transformation performed.
This novel combination of vaccination, ensembling, and randomization makes SHIELD
a fortified multi-pronged defense. We conducted extensive, large-scale experiments
using the ImageNet dataset, and show that our approaches eliminate up to 98% of gray-box
attacks delivered by strong adversarial techniques such as Carlini-Wagner's L2 attack
and DeepFool. Our approaches are fast and work without requiring knowledge about the
model.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {196–204},
numpages = {9},
keywords = {deep learning, JPEG compression, machine learning security, adversarial machine learning, ensemble defense},
location = {London, United Kingdom},
series = {KDD '18}
}

@inproceedings{10.1145/2046707.2046761,
author = {Moore, Tyler and Leontiadis, Nektarios and Christin, Nicolas},
title = {Fashion Crimes: Trending-Term Exploitation on the Web},
year = {2011},
isbn = {9781450309486},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2046707.2046761},
doi = {10.1145/2046707.2046761},
abstract = {Online service providers are engaged in constant conflict with miscreants who try
to siphon a portion of legitimate traffic to make illicit profits. We study the abuse
of "trending" search terms, in which miscreants place links to malware-distributing
or ad-filled web sites in web search and Twitter results, by collecting and analyzing
measurements over nine months from multiple sources. We devise heuristics to identify
ad-filled sites, report on the prevalence of malware and ad-filled sites in trending-term
search results, and measure the success in blocking such content. We uncover collusion
across offending domains using network analysis, and use regression analysis to conclude
that both malware and ad-filled sites thrive on less popular, and less profitable
trending terms. We build an economic model informed by our measurements and conclude
that ad-filled sites and malware distribution may be economic substitutes. Finally,
because our measurement interval spans February 2011, when Google announced changes
to its ranking algorithm to root out low-quality sites, we can assess the impact of
search-engine intervention on the profits miscreants can achieve.},
booktitle = {Proceedings of the 18th ACM Conference on Computer and Communications Security},
pages = {455–466},
numpages = {12},
keywords = {advertisements, search engines, online crime, malware},
location = {Chicago, Illinois, USA},
series = {CCS '11}
}

@article{10.1145/3178370,
author = {Carminati, Michele and Polino, Mario and Continella, Andrea and Lanzi, Andrea and Maggi, Federico and Zanero, Stefano},
title = {Security Evaluation of a Banking Fraud Analysis System},
year = {2018},
issue_date = {June 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {3},
issn = {2471-2566},
url = {https://doi.org/10.1145/3178370},
doi = {10.1145/3178370},
abstract = {The significant growth of banking fraud, fueled by the underground economy of malware,
has raised the need for effective detection systems. Therefore, in the last few years,
banks have upgraded their security to protect transactions from fraud. State-of-the-art
solutions detect fraud as deviations from customers’ spending habits. To the best
of our knowledge, almost all existing approaches do not provide an in-depth model’s
granularity and security analysis against elusive attacks.In this article, we examine
Banksealer, a decision support system for banking fraud analysis that evaluates the
influence on detection performance of the granularity at which spending habits are
modeled and its security against evasive attacks. First, we compare user-centric modeling,
which builds a model for each user, with system-centric modeling, which builds a model
for the entire system, from the point of view of detection performance. Then, we assess
the robustness of Banksealer against malicious attackers that are aware of the structure
of the models in use. To this end, we design and implement a proof-of-concept attack
tool that performs mimicry attacks, emulating a sophisticated attacker that cloaks
frauds to avoid detection. We experimentally confirm the feasibility of such attacks,
their cost, and the effort required by an attacker in order to perform them. In addition,
we discuss possible countermeasures.We provide a comprehensive evaluation on a large
real-world dataset obtained from one of the largest Italian banks.},
journal = {ACM Trans. Priv. Secur.},
month = apr,
articleno = {11},
numpages = {31},
keywords = {fraud and anomaly detection, mimicry attack, spending pattern granularity analysis, Online banking}
}

@inproceedings{10.1145/3372297.3421761,
author = {Hassan, Sohaib ul and Gridin, Iaroslav and Delgado-Lozano, Ignacio M. and Garc\'{\i}a, Cesar Pereida and Chi-Dom\'{\i}nguez, Jes\'{u}s-Javier and Aldaya, Alejandro Cabrera and Brumley, Billy Bob},
title = {D\'{e}J\`{a} Vu: Side-Channel Analysis of Mozilla's NSS},
year = {2020},
isbn = {9781450370899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3372297.3421761},
doi = {10.1145/3372297.3421761},
abstract = {Recent work on Side Channel Analysis (SCA) targets old, well-known vulnerabilities,
even previously exploited, reported, and patched in high-profile cryptography libraries.
Nevertheless, researchers continue to find and exploit the same vulnerabilities in
old and new products, highlighting a big issue among vendors: effectively tracking
and fixing security vulnerabilities when disclosure is not done directly to them.
In this work, we present another instance of this issue by performing the first library-wide
SCA security evaluation of Mozilla's NSS security library. We use a combination of
two independently-developed SCA security frameworks to identify and test security
vulnerabilities. Our evaluation uncovers several new vulnerabilities in NSS affecting
DSA, ECDSA, and RSA cryptosystems. We exploit said vulnerabilities and implement key
recovery attacks using signals---extracted through different techniques such as timing,
microarchitecture, and EM---and improved lattice methods.},
booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1887–1902},
numpages = {16},
keywords = {public key cryptography, applied cryptography, NSS, side-channel analysis, RSA, DSA, ECDSA, CVE-2020-12402, CVE-2020-6829, lattice-based cryptanalysis, CVE-2020-12399, software security, CVE-2020-12401},
location = {Virtual Event, USA},
series = {CCS '20}
}

@inproceedings{10.1145/3240765.3274560,
author = {Riazi, M. Sadegh and Koushanfar, Farinaz},
title = {Privacy-Preserving Deep Learning and Inference},
year = {2018},
isbn = {9781450359504},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3240765.3274560},
doi = {10.1145/3240765.3274560},
abstract = {We provide a systemization of knowledge of the recent progress made in addressing
the crucial problem of deep learning on encrypted data. The problem is important due
to the prevalence of deep learning models across various applications, and privacy
concerns over the exposure of deep learning IP and user's data. Our focus is on provably
secure methodologies that rely on cryptographic primitives and not trusted third parties/platforms.
Computational intensity of the learning models, together with the complexity of realization
of the cryptography algorithms hinder the practical implementation a challenge. We
provide a summary of the state-of-the-art, comparison of the existing solutions, as
well as future challenges and opportunities.},
booktitle = {Proceedings of the International Conference on Computer-Aided Design},
articleno = {18},
numpages = {4},
keywords = {privacy-preserving deep learning, deep learning, security, homomorphic encryption, secret sharing, artificial intelligence, machine learning, secure function evaluation, privacy},
location = {San Diego, California},
series = {ICCAD '18}
}

@inproceedings{10.1145/3317549.3319724,
author = {OConnor, TJ and Enck, William and Reaves, Bradley},
title = {Blinded and Confused: Uncovering Systemic Flaws in Device Telemetry for Smart-Home Internet of Things},
year = {2019},
isbn = {9781450367264},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3317549.3319724},
doi = {10.1145/3317549.3319724},
abstract = {The always-on, always-connected nature of smart home devices complicates Internet-of-Things
(IoT) security and privacy. Unlike traditional hosts, IoT devices constantly send
sensor, state, and heartbeat data to cloud-based servers. These data channels require
reliable, routine communication, which is often at odds with an IoT device's storage
and power constraints. Although recent efforts such as pervasive encryption have addressed
protecting data intransit, there remains little insight into designing mechanisms
for protecting integrity and availability for always-connected devices. This paper
seeks to better understand smart home device security by studying the vendor design
decisions surrounding IoT telemetry messaging protocols, specifically, the behaviors
taken when an IoT device loses connectivity. To understand this, we hypothesize and
evaluate sensor blinding and state confusion attacks, measuring their effectiveness
against an array of smart home IoT device types. Our analysis uncovers pervasive failure
in designing telemetry that reports data to the cloud, and buffering that fails to
properly cache undelivered data. We uncover that 22 of 24 studied devices suffer from
critical design flaws that (1) enable attacks to transparently disrupt the reporting
of device status alerts or (2) prevent the uploading of content integral to the device's
core functionality. We conclude by considering the implications of these findings
and offer directions for future defense. While the state of the art is rife with implementation
flaws, there are several countermeasures IoT vendors could take to reduce their exposure
to attacks of this nature.},
booktitle = {Proceedings of the 12th Conference on Security and Privacy in Wireless and Mobile Networks},
pages = {140–150},
numpages = {11},
location = {Miami, Florida},
series = {WiSec '19}
}

@inproceedings{10.1145/3090354.3090405,
author = {Toumi, H. and Marzak, B. and Khazri, Y. and Talea, A. and Eddaoui, A. and Talea, M.},
title = {Mobiles Agents and Virtual Firewall to Secure the Shared Network for Virtual Machines in IaaS Cloud},
year = {2017},
isbn = {9781450348522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3090354.3090405},
doi = {10.1145/3090354.3090405},
abstract = {Cloud computing is a new paradigm based on distributed services. It allows to reduce
costs and simplify the management of resources. Positioning the cloud in an operational
environment provides easy and quick access to computing resources anywhere, anytime,
with any device. However, it is deployed in virtual resources to provide services
to public customers and private organizations. In fact, without security measures,
distributed cloud services are vulnerable. It acquires knowledge about vulnerabilities,
attacks, activities of attackers and tools to secure it. In this paper, we will propose
a framework for detecting and repairing distributed intrusions in private cloud. However,
we focus on the security of virtual network in virtualized environment. In order to
secure inside or outside communication of virtual machines, we suggest using our framework
based on snort, mobile agents and virtual firewall. This framework allows to reach
three objectives: the first, detection intrusion in a virtual environment using mobile
agents for collecting malicious data. The second, generating new signatures from malicious
data, which were collected in the first phase. Finally, dynamic deployment of remote
response actions using virtual firewall. By this type of close-loop control, the collaborative
network security management framework can identify and address new distributed attacks
more quickly and effectively.},
booktitle = {Proceedings of the 2nd International Conference on Big Data, Cloud and Applications},
articleno = {50},
numpages = {6},
keywords = {Vulnerability, Virtual Firewall, Mobile Agent, Snort},
location = {Tetouan, Morocco},
series = {BDCA'17}
}

@article{10.1145/3168446,
author = {Iannucci, Stefano and Abdelwahed, Sherif},
title = {Model-Based Response Planning Strategies for Autonomic Intrusion Protection},
year = {2018},
issue_date = {May 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {1556-4665},
url = {https://doi.org/10.1145/3168446},
doi = {10.1145/3168446},
abstract = {The continuous increase in the quantity and sophistication of cyberattacks is making
it more difficult and error prone for system administrators to handle the alerts generated
by intrusion detection systems (IDSs). To deal with this problem, several intrusion
response systems (IRSs) have been proposed lately. IRSs extend the IDSs by providing
an automatic response to the detected attack. Such a response is usually selected
either with a static attack-response mapping or by quantitatively evaluating all available
responses, given a set of predefined criteria. In this article, we introduce a probabilistic
model-based IRS built on the Markov decision process (MDP) framework. In contrast
to most existing approaches to intrusion response, the proposed IRS effectively captures
the dynamics of both the defended system and the attacker and is able to compose atomic
response actions to plan optimal multiobjective long-term response policies to protect
the system. We evaluate the effectiveness of the proposed IRS by showing that long-term
response planning always outperforms short-term planning, and we conduct a thorough
performance assessment to show that the proposed IRS can be adopted to protect large
distributed systems at runtime.},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = apr,
articleno = {4},
numpages = {23},
keywords = {autonomic intrusion protection, Intrusion response system}
}

@inproceedings{10.1145/2739480.2754816,
author = {Greensmith, Julie},
title = {Securing the Internet of Things with Responsive Artificial Immune Systems},
year = {2015},
isbn = {9781450334723},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2739480.2754816},
doi = {10.1145/2739480.2754816},
abstract = {The Internet of Things is a network of `smart' objects, transforming everyday objects
into entities which can measure, sense and understand their environment. The devices
are uniquely identifiable, rely on near field connectivity, often in embedded devices.
The Internet of Things is designed to be deployed without human intervention or interaction.
One application is the `smart house', with components including household appliances,
networked with the user able to control devices remotely. However, the security inherent
in these systems is added as somewhat of an afterthought. One hypothetical scenario
is where a malicious party could exploit this technology with potentially disastrous
consequences, turning on a cooker remotely leading to digital arson. Reliance on standard
methods is insufficient to provide the user with adequate levels of security, an area
where AIS may be extremely useful. There are currently limitations with AIS applied
in security, focussing on detection without providing automatic responses. This problem
provides an opportunity to advance AIS in providing both an ideal scenario for testing
their real-world application and to develop novel responsive AIS. A responsive version
of the deterministic Dendritic Cell Algorithm will be proposed to demonstrate how
responsive AIS will need to be developed to meet these future challenges through proposing
the incorporation of a model of T-cell responses.},
booktitle = {Proceedings of the 2015 Annual Conference on Genetic and Evolutionary Computation},
pages = {113–120},
numpages = {8},
keywords = {security, artificial immune systems, dendritic cell algorithm, internet of things, automated responses},
location = {Madrid, Spain},
series = {GECCO '15}
}

@inproceedings{10.1145/3458864.3466628,
author = {Mo, Fan and Haddadi, Hamed and Katevas, Kleomenis and Marin, Eduard and Perino, Diego and Kourtellis, Nicolas},
title = {PPFL: Privacy-Preserving Federated Learning with Trusted Execution Environments},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466628},
doi = {10.1145/3458864.3466628},
abstract = {We propose and implement a Privacy-preserving Federated Learning (PPFL) framework
for mobile systems to limit privacy leakages in federated learning. Leveraging the
widespread presence of Trusted Execution Environments (TEEs) in high-end and mobile
devices, we utilize TEEs on clients for local training, and on servers for secure
aggregation, so that model/gradient updates are hidden from adversaries. Challenged
by the limited memory size of current TEEs, we leverage greedy layer-wise training
to train each model's layer inside the trusted area until its convergence. The performance
evaluation of our implementation shows that PPFL can significantly improve privacy
while incurring small system overheads at the client-side. In particular, PPFL can
successfully defend the trained model against data reconstruction, property inference,
and membership inference attacks. Furthermore, it can achieve comparable model utility
with fewer communication rounds (0.54\texttimes{}) and a similar amount of network traffic (1.002\texttimes{})
compared to the standard federated learning of a complete model. This is achieved
while only introducing up to ~15% CPU time, ~18% memory usage, and ~21% energy consumption
overhead in PPFL's client-side.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {94–108},
numpages = {15},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3240765.3240791,
author = {Rouhani, Bita Darvish and Samragh, Mohammad and Javaheripi, Mojan and Javidi, Tara and Koushanfar, Farinaz},
title = {DeepFense: Online Accelerated Defense against Adversarial Deep Learning},
year = {2018},
isbn = {9781450359504},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3240765.3240791},
doi = {10.1145/3240765.3240791},
abstract = {Recent advances in adversarial Deep Learning (DL) have opened up a largely unexplored
surface for malicious attacks jeopardizing the integrity of autonomous DL systems.
With the wide-spread usage of DL in critical and time-sensitive applications, including
unmanned vehicles, drones, and video surveillance systems, online detection of malicious
inputs is of utmost importance. We propose DeepFense, the first end-to-end automated
framework that simultaneously enables efficient and safe execution of DL models. DeepFense
formalizes the goal of thwarting adversarial attacks as an optimization problem that
minimizes the rarely observed regions in the latent feature space spanned by a DL
network. To solve the aforementioned minimization problem, a set of complementary
but disjoint modular redundancies are trained to validate the legitimacy of the input
samples in parallel with the victim DL model. DeepFense leverages hardware/software/algorithm
co-design and customized acceleration to achieve just-in-time performance in resource-constrained
settings. The proposed countermeasure is unsupervised, meaning that no adversarial
sample is leveraged to train modular redundancies. We further provide an accompanying
API to reduce the non-recurring engineering cost and ensure automated adaptation to
various platforms. Extensive evaluations on FPGAs and GPUs demonstrate up to two orders
of magnitude performance improvement while enabling online adversarial sample detection.},
booktitle = {Proceedings of the International Conference on Computer-Aided Design},
articleno = {134},
numpages = {8},
keywords = {real-time computing, adversarial attacks, model reliability, deep learning, FPGA acceleration},
location = {San Diego, California},
series = {ICCAD '18}
}

@inproceedings{10.1145/3211890.3211899,
author = {Bel, Oceane and Chang, Kenneth and Bittman, Daniel and Long, Darrell D. E. and Isozaki, Hiroshi and Miller, Ethan L.},
title = {Inkpack: A Secure, Data-Exposure Resistant Storage System},
year = {2018},
isbn = {9781450358491},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3211890.3211899},
doi = {10.1145/3211890.3211899},
abstract = {Removing hard drives from a data center may expose sensitive data, such as encryption
keys or passwords. To prevent exposure, data centers have security policies in place
to physically secure drives in the system, and securely delete data from drives that
are removed. Despite advances in security technology and best practices, implementation
of these security measures is often done incorrectly. We anticipate that physical
security will fail, and fixing the issue after the failure is costly and ineffective.We
propose Inkpack, a protocol that prevents an attacker from reading data from a drive
removed from the data center even if the attacker has the user key linked to the data.
An implementation of this protocol encrypts data, and secret splits the key over a
number of drives. Recovering the key requires communicating with other drives, thereby
denying access to the data if a few drives have been removed. Inkpack also requires
the system to verify the validity of individual drives before normal operation. A
prototype created within the Ceph storage system executed individual key split, key
rebuild, and drive validation operations in 100--150 μs. We also show that our protocol
is sensitive to small data write overheads, demonstrating potential performance gains
if implemented on smart solid state storage devices, and propose a solution to increase
performance.},
booktitle = {Proceedings of the 11th ACM International Systems and Storage Conference},
pages = {89–100},
numpages = {12},
keywords = {access control, systems security, vulnerability management},
location = {Haifa, Israel},
series = {SYSTOR '18}
}

@inproceedings{10.1145/3291842.3291893,
author = {Han, Daoqi and Lu, Yueming and Du, Xiaofeng and Gan, Jiefu},
title = {Offline Authentication Scheme Based on Blockchain Technology for Smart Lock},
year = {2018},
isbn = {9781450365857},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3291842.3291893},
doi = {10.1145/3291842.3291893},
abstract = {Driven by the technology of mobile Internet of things and the wide demand of sharing
economy, the development of smart locks is changing with each passing day. Current
schemes rely on the open network architecture which has security vulnerabilities,
privacy leaks, vulnerability to various attacks and other security risks. We propose
an end-to-end succinct non-interactive offline authentication scheme based on blockchain
technology(BC-SNOA). Using blockchain techniques such as anonymity, ellipticcurve
cryptography, workload consensus, and privacy-preserving zero-knowledge proof, the
BC-SNOA implements one-time pad to improve confidentiality, offline authentication
to avoid network remote intrusions and the risk of network services interruptions.
It is difficult to replicate and crack because of the in chip calculation of workloads
and mathematical problems. Compared with current smart locks which extract biometric
verification information and control by network services, the BC-SNOA scheme is likely
to accomplish beneficial properties such as high verification performance and more
secure, and also makes simple hardware implementations possible.},
booktitle = {Proceedings of the 2nd International Conference on Telecommunications and Communication Engineering},
pages = {384–390},
numpages = {7},
keywords = {Smart lock, offline authentication, blockchain, consensus mechanism},
location = {Beijing, China},
series = {ICTCE 2018}
}

@inproceedings{10.1145/3419394.3423643,
author = {Lin, Zinan and Jain, Alankar and Wang, Chen and Fanti, Giulia and Sekar, Vyas},
title = {Using GANs for Sharing Networked Time Series Data: Challenges, Initial Promise, and Open Questions},
year = {2020},
isbn = {9781450381383},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3419394.3423643},
doi = {10.1145/3419394.3423643},
abstract = {Limited data access is a longstanding barrier to data-driven research and development
in the networked systems community. In this work, we explore if and how generative
adversarial networks (GANs) can be used to incentivize data sharing by enabling a
generic framework for sharing synthetic datasets with minimal expert knowledge. As
a specific target, our focus in this paper is on time series datasets with metadata
(e.g., packet loss rate measurements with corresponding ISPs). We identify key challenges
of existing GAN approaches for such workloads with respect to fidelity (e.g., long-term
dependencies, complex multidimensional relationships, mode collapse) and privacy (i.e.,
existing guarantees are poorly understood and can sacrifice fidelity). To improve
fidelity, we design a custom workflow called DoppelGANger (DG) and demonstrate that
across diverse real-world datasets (e.g., bandwidth measurements, cluster requests,
web sessions) and use cases (e.g., structural characterization, predictive modeling,
algorithm comparison), DG achieves up to 43% better fidelity than baseline models.
Although we do not resolve the privacy problem in this work, we identify fundamental
challenges with both classical notions of privacy and recent advances to improve the
privacy properties of GANs, and suggest a potential roadmap for addressing these challenges.
By shedding light on the promise and challenges, we hope our work can rekindle the
conversation on workflows for data sharing.},
booktitle = {Proceedings of the ACM Internet Measurement Conference},
pages = {464–483},
numpages = {20},
keywords = {generative adversarial networks, synthetic data generation, time series, privacy},
location = {Virtual Event, USA},
series = {IMC '20}
}

@inproceedings{10.1145/3368089.3409671,
author = {Yan, Shenao and Tao, Guanhong and Liu, Xuwei and Zhai, Juan and Ma, Shiqing and Xu, Lei and Zhang, Xiangyu},
title = {Correlations between Deep Neural Network Model Coverage Criteria and Model Quality},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409671},
doi = {10.1145/3368089.3409671},
abstract = {Inspired by the great success of using code coverage as guidance in software testing,
a lot of neural network coverage criteria have been proposed to guide testing of neural
network models (e.g., model accuracy under adversarial attacks). However, while the
monotonic relation between code coverage and software quality has been supported by
many seminal studies in software engineering, it remains largely unclear whether similar
monotonicity exists between neural network model coverage and model quality. This
paper sets out to answer this question. Specifically, this paper studies the correlation
between DNN model quality and coverage criteria, effects of coverage guided adversarial
example generation compared with gradient decent based methods, effectiveness of coverage
based retraining compared with existing adversarial training, and the internal relationships
among coverage criteria.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {775–787},
numpages = {13},
keywords = {Deep Neural Networks, Software Testing},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.1145/2435349.2435351,
author = {Beato, Filipe and Ion, Iulia and \v{C}apkun, Srdjan and Preneel, Bart and Langheinrich, Marc},
title = {For Some Eyes Only: Protecting Online Information Sharing},
year = {2013},
isbn = {9781450318907},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2435349.2435351},
doi = {10.1145/2435349.2435351},
abstract = {End-users have become accustomed to the ease with which online systems allow them
to exchange messages, pictures, and other files with colleagues, friends, and family.
This con- venience, however, sometimes comes at the expense of hav- ing their data
be viewed by a number of unauthorized par- ties, such as hackers, advertisement companies,
other users, or governmental agencies. A number of systems have been proposed to protect
data shared online; yet these solutions typically just shift trust to another third
party server, are platform specific (e.g., work for Facebook only), or fail to hide
that confidential communication is taking place. In this paper, we present a novel
system that enables users to exchange data over any web-based sharing platform, while
both keeping the communicated data confidential and hiding from a casual observer
that an exchange of confidential data is taking place. We provide a proof-of-concept
implementa- tion of our system in the form of a publicly available Fire- fox plugin,
and demonstrate the viability of our approach through a performance evaluation.},
booktitle = {Proceedings of the Third ACM Conference on Data and Application Security and Privacy},
pages = {1–12},
numpages = {12},
keywords = {usability, privacy, online sharing, security, steganography},
location = {San Antonio, Texas, USA},
series = {CODASPY '13}
}

@article{10.1145/3458510,
author = {Agate, Vincenzo and Paola, Alessandra De and Re, Giuseppe Lo and Morana, Marco},
title = {A Simulation Software for the Evaluation of Vulnerabilities in Reputation Management Systems},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {1–4},
issn = {0734-2071},
url = {https://doi.org/10.1145/3458510},
doi = {10.1145/3458510},
abstract = {Multi-agent distributed systems are characterized by autonomous entities that interact
with each other to provide, and/or request, different kinds of services. In several
contexts, especially when a reward is offered according to the quality of service,
individual agents (or coordinated groups) may act in a selfish way. To prevent such
behaviours, distributed Reputation Management Systems (RMSs) provide every agent with
the capability of computing the reputation of the others according to direct past
interactions, as well as indirect opinions reported by their neighbourhood. This last
point introduces a weakness on gossiped information that makes RMSs vulnerable to
malicious agents’ intent on disseminating false reputation values. Given the variety
of application scenarios in which RMSs can be adopted, as well as the multitude of
behaviours that agents can implement, designers need RMS evaluation tools that allow
them to predict the robustness of the system to security attacks, before its actual
deployment. To this aim, we present a simulation software for the vulnerability evaluation
of RMSs and illustrate three case studies in which this tool was effectively used
to model and assess state-of-the-art RMSs.},
journal = {ACM Trans. Comput. Syst.},
month = jun,
articleno = {6},
numpages = {30},
keywords = {Agent-based simulation, distributed reputation management systems, multi-agent systems}
}

@inproceedings{10.1145/2517312.2517320,
author = {Kantchelian, Alex and Afroz, Sadia and Huang, Ling and Islam, Aylin Caliskan and Miller, Brad and Tschantz, Michael Carl and Greenstadt, Rachel and Joseph, Anthony D. and Tygar, J. D.},
title = {Approaches to Adversarial Drift},
year = {2013},
isbn = {9781450324885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517312.2517320},
doi = {10.1145/2517312.2517320},
abstract = {In this position paper, we argue that to be of practical interest, a machine-learning
based security system must engage with the human operators beyond feature engineering
and instance labeling to address the challenge of drift in adversarial environments.
We propose that designers of such systems broaden the classification goal into an
explanatory goal, which would deepen the interaction with system's operators.To provide
guidance, we advocate for an approach based on maintaining one classifier for each
class of unwanted activity to be filtered. We also emphasize the necessity for the
system to be responsive to the operators constant curation of the training set. We
show how this paradigm provides a property we call isolation and how it relates to
classical causative attacks.In order to demonstrate the effects of drift on a binary
classification task, we also report on two experiments using a previously unpublished
malware data set where each instance is timestamped according to when it was seen.},
booktitle = {Proceedings of the 2013 ACM Workshop on Artificial Intelligence and Security},
pages = {99–110},
numpages = {12},
keywords = {malware classification, concept drift, adversarial machine learning},
location = {Berlin, Germany},
series = {AISec '13}
}

@article{10.1145/2542182.2542185,
author = {Tang, Lu-An and Zheng, Yu and Yuan, Jing and Han, Jiawei and Leung, Alice and Peng, Wen-Chih and Porta, Thomas La},
title = {A Framework of Traveling Companion Discovery on Trajectory Data Streams},
year = {2014},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {1},
issn = {2157-6904},
url = {https://doi.org/10.1145/2542182.2542185},
doi = {10.1145/2542182.2542185},
abstract = {The advance of mobile technologies leads to huge volumes of spatio-temporal data collected
in the form of trajectory data streams. In this study, we investigate the problem
of discovering object groups that travel together (i.e., traveling companions) from
trajectory data streams. Such technique has broad applications in the areas of scientific
study, transportation management, and military surveillance. To discover traveling
companions, the monitoring system should cluster the objects of each snapshot and
intersect the clustering results to retrieve moving-together objects. Since both clustering
and intersection steps involve high computational overhead, the key issue of companion
discovery is to improve the efficiency of algorithms. We propose the models of closed
companion candidates and smart intersection to accelerate data processing. A data
structure termed traveling buddy is designed to facilitate scalable and flexible companion
discovery from trajectory streams. The traveling buddies are microgroups of objects
that are tightly bound together. By only storing the object relationships rather than
their spatial coordinates, the buddies can be dynamically maintained along the trajectory
stream with low cost. Based on traveling buddies, the system can discover companions
without accessing the object details. In addition, we extend the proposed framework
to discover companions on more complicated scenarios with spatial and temporal constraints,
such as on the road network and battlefield. The proposed methods are evaluated with
extensive experiments on both real and synthetic datasets. Experimental results show
that our proposed buddy-based approach is an order of magnitude faster than the baselines
and achieves higher accuracy in companion discovery.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jan,
articleno = {3},
numpages = {34},
keywords = {data stream, Trajectory, clustering}
}

@inproceedings{10.1145/2602945.2602955,
author = {Fink, Glenn A. and McKinnon, A. David},
title = {Effects of Network Delays on Swarming in a Multi-Agent Security System},
year = {2014},
isbn = {9781450327282},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2602945.2602955},
doi = {10.1145/2602945.2602955},
abstract = {In testing our multi-agent cyber security system, Ant-Based Cyber Defense (ABCD) we
have found that pheromone efficacy, swarm formation, and cyber-security properties
of a multi-agent system can be affected by non-uniform delay times experienced by
the ant agents as they traverse on large-scale, real-world networks. This led to tests
where we artificially induced delay on large sections of a network to experiment with
swarms under different delay conditions.As predicted by queuing theory, we found that
more agents gathered in grid sections with longer inter-node propagation/transmission
delays and that the population of agents in the sections with longer delays was proportional
to the delay times in that network section relative to the rest of the network. We
verified the observed operational behavior via both simulation and queuing theoretic
analysis and found that there may be no closed-form solution to the steady state of
a system without static transition probabilities. In ABCD, transition probabilities
are dynamic, arising from non-deterministic pheromone deposition rates.Without careful
tuning of multi-agent security systems to a given network's delay characteristics
the security provided may be significantly less than desired because agents may not
be distributed as needed or required by the designers. We have used the findings in
this study to discover parameters to help make this tuning possible.},
booktitle = {Proceedings of the 1st International Workshop on Agents and CyberSecurity},
articleno = {11},
numpages = {8},
keywords = {multi-agent systems, random walks, ant algorithms, cyber security},
location = {Paris, France},
series = {ACySE '14}
}

@article{10.1145/3447556.3447566,
author = {Jin, Wei and Li, Yaxing and Xu, Han and Wang, Yiqi and Ji, Shuiwang and Aggarwal, Charu and Tang, Jiliang},
title = {Adversarial Attacks and Defenses on Graphs},
year = {2021},
issue_date = {December 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {2},
issn = {1931-0145},
url = {https://doi.org/10.1145/3447556.3447566},
doi = {10.1145/3447556.3447566},
abstract = {Deep neural networks (DNNs) have achieved significant performance in various tasks.
However, recent studies have shown that DNNs can be easily fooled by small perturbation
on the input, called adversarial attacks.},
journal = {SIGKDD Explor. Newsl.},
month = jan,
pages = {19–34},
numpages = {16}
}

@inproceedings{10.1145/3243127.3243130,
author = {Ognawala, Saahil and Amato, Ricardo Nales and Pretschner, Alexander and Kulkarni, Pooja},
title = {Automatically Assessing Vulnerabilities Discovered by Compositional Analysis},
year = {2018},
isbn = {9781450359726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3243127.3243130},
doi = {10.1145/3243127.3243130},
abstract = {Testing is the most widely employed method to find vulnerabilities in real-world software
programs. Compositional analysis, based on symbolic execution, is an automated testing
method to find vulnerabilities in medium- to large-scale programs consisting of many
interacting components. However, existing compositional analysis frameworks do not
assess the severity of reported vulnerabilities. In this paper, we present a framework
to analyze vulnerabilities discovered by an existing compositional analysis tool and
assign CVSS3 (Common Vulnerability Scoring System v3.0) scores to them, based on various
heuristics such as interaction with related components, ease of reachability, complexity
of design and likelihood of accepting unsanitized input. By analyzing vulnerabilities
reported with CVSS3 scores in the past, we train simple machine learning models. By
presenting our interactive framework to developers of popular open-source software
and other security experts, we gather feedback on our trained models and further improve
the features to increase the accuracy of our predictions. By providing qualitative
(based on community feedback) and quantitative (based on prediction accuracy) evidence
from 21 open-source programs, we show that our severity prediction framework can effectively
assist developers with assessing vulnerabilities.},
booktitle = {Proceedings of the 1st International Workshop on Machine Learning and Software Engineering in Symbiosis},
pages = {16–25},
numpages = {10},
keywords = {software testing, symbolic execution, vulnerability assessment, compositional analysis},
location = {Montpellier, France},
series = {MASES 2018}
}

@article{10.1145/3369816,
author = {Liu, Sicong and Du, Junzhao and Shrivastava, Anshumali and Zhong, Lin},
title = {Privacy Adversarial Network: Representation Learning for Mobile Data Privacy},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {4},
url = {https://doi.org/10.1145/3369816},
doi = {10.1145/3369816},
abstract = {The remarkable success of machine learning has fostered a growing number of cloud-based
intelligent services for mobile users. Such a service requires a user to send data,
e.g. image, voice and video, to the provider, which presents a serious challenge to
user privacy. To address this, prior works either obfuscate the data, e.g. add noise
and remove identity information, or send representations extracted from the data,
e.g. anonymized features. They struggle to balance between the service utility and
data privacy because obfuscated data reduces utility and extracted representation
may still reveal sensitive information.This work departs from prior works in methodology:
we leverage adversarial learning to better balance between privacy and utility. We
design a representation encoder that generates the feature representations to optimize
against the privacy disclosure risk of sensitive information (a measure of privacy)
by the privacy adversaries, and concurrently optimize with the task inference accuracy
(a measure of utility) by the utility discriminator. The result is the privacy adversarial
network (PAN), a novel deep model with the new training algorithm, that can automatically
learn representations from the raw data. And the trained encoder can be deployed on
the user side to generate representations that satisfy the task-defined utility requirements
and the user-specified/agnostic privacy budgets.Intuitively, PAN adversarially forces
the extracted representations to only convey information required by the target task.
Surprisingly, this constitutes an implicit regularization that actually improves task
accuracy. As a result, PAN achieves better utility and better privacy at the same
time! We report extensive experiments on six popular datasets, and demonstrate the
superiority of PAN compared with alternative methods reported in prior work.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = dec,
articleno = {144},
numpages = {18}
}

@inproceedings{10.1145/3372297.3417289,
author = {G\"{o}ktas, Enes and Razavi, Kaveh and Portokalidis, Georgios and Bos, Herbert and Giuffrida, Cristiano},
title = {Speculative Probing: Hacking Blind in the Spectre Era},
year = {2020},
isbn = {9781450370899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3372297.3417289},
doi = {10.1145/3372297.3417289},
abstract = {To defeat ASLR or more advanced fine-grained and leakage-resistant code randomization
schemes, modern software exploits rely on information disclosure to locate gadgets
inside the victim's code. In the absence of such info-leak vulnerabilities, attackers
can still hack blind and derandomize the address space by repeatedly probing the victim's
memory while observing crash side effects, but doing so is only feasible for crash-resistant
programs. However, high-value targets such as the Linux kernel are not crash-resistant.
Moreover, the anomalously large number of crashes is often easily detectable. In this
paper, we show that the Spectre era enables an attacker armed with a single memory
corruption vulnerability to hack blind without triggering any crashes. Using speculative
execution for crash suppression allows the elevation of basic memory write vulnerabilities
into powerful speculative probing primitives that leak through microarchitectural
side effects. Such primitives can repeatedly probe victim memory and break strong
randomization schemes without crashes and bypass all deployed mitigations against
Spectre-like attacks. The key idea behind speculative probing is to break Spectre
mitigations using memory corruption and resurrect Spectre-style disclosure primitives
to mount practical blind software exploits. To showcase speculative probing, we target
the Linux kernel, a crash-sensitive victim that has so far been out of reach of blind
attacks, mount end-to-end exploits that compromise the system with just-in-time code
reuse and data-only attacks from a single memory write vulnerability, and bypass strong
Spectre and strong randomization defenses. Our results show that it is crucial to
consider synergies between different (Spectre vs. code reuse) threat models to fully
comprehend the attack surface of modern systems.},
booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1871–1885},
numpages = {15},
keywords = {speculative execution, code-reuse attacks},
location = {Virtual Event, USA},
series = {CCS '20}
}

@inproceedings{10.1145/2976749.2978315,
author = {Liao, Xiaojing and Yuan, Kan and Wang, XiaoFeng and Li, Zhou and Xing, Luyi and Beyah, Raheem},
title = {Acing the IOC Game: Toward Automatic Discovery and Analysis of Open-Source Cyber Threat Intelligence},
year = {2016},
isbn = {9781450341394},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2976749.2978315},
doi = {10.1145/2976749.2978315},
abstract = {To adapt to the rapidly evolving landscape of cyber threats, security professionals
are actively exchanging Indicators of Compromise (IOC) (e.g., malware signatures,
botnet IPs) through public sources (e.g. blogs, forums, tweets, etc.). Such information,
often presented in articles, posts, white papers etc., can be converted into a machine-readable
OpenIOC format for automatic analysis and quick deployment to various security mechanisms
like an intrusion detection system. With hundreds of thousands of sources in the wild,
the IOC data are produced at a high volume and velocity today, which becomes increasingly
hard to manage by humans. Efforts to automatically gather such information from unstructured
text, however, is impeded by the limitations of today's Natural Language Processing
(NLP) techniques, which cannot meet the high standard (in terms of accuracy and coverage)
expected from the IOCs that could serve as direct input to a defense system. In this
paper, we present iACE, an innovation solution for fully automated IOC extraction.
Our approach is based upon the observation that the IOCs in technical articles are
often described in a predictable way: being connected to a set of context terms (e.g.,
"download") through stable grammatical relations. Leveraging this observation, iACE
is designed to automatically locate a putative IOC token (e.g., a zip file) and its
context (e.g., "malware", "download") within the sentences in a technical article,
and further analyze their relations through a novel application of graph mining techniques.
Once the grammatical connection between the tokens is found to be in line with the
way that the IOC is commonly presented, these tokens are extracted to generate an
OpenIOC item that describes not only the indicator (e.g., a malicious zip file) but
also its context (e.g., download from an external source). Running on 71,000 articles
collected from 45 leading technical blogs, this new approach demonstrates a remarkable
performance: it generated 900K OpenIOC items with a precision of 95% and a coverage
over 90%, which is way beyond what the state-of-the-art NLP technique and industry
IOC tool can achieve, at a speed of thousands of articles per hour. Further, by correlating
the IOCs mined from the articles published over a 13-year span, our study sheds new
light on the links across hundreds of seemingly unrelated attack instances, particularly
their shared infrastructure resources, as well as the impacts of such open-source
threat intelligence on security protection and evolution of attack strategies.},
booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
pages = {755–766},
numpages = {12},
keywords = {cyber threat intelligence, IOC},
location = {Vienna, Austria},
series = {CCS '16}
}

@InProceedings{Bernieri2019,
  author    = {Bernieri, Giuseppe and Conti, Mauro and Turrin, Federico},
  booktitle = {Proceedings of the 1st Workshop on Machine Learning on Edge in Sensor Systems},
  title     = {KingFisher: An Industrial Security Framework Based on Variational Autoencoders},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {7–12},
  publisher = {Association for Computing Machinery},
  series    = {SenSys-ML 2019},
  abstract  = {The recent evolution of edge computing favored the Industrial Internet of Things (IIoT)
growth, opening dangerous surfaces of vulnerabilities. In this distributed sensor
system scenario, due to the insecure interactions between Information Technology (IT)
and Operational Technology (OT) networks, cyber-physical threats could lead to destructive
consequences for environments and population safety. To deal with industrial cyber-physical
security, modern anomaly detection systems implement innovative Machine Learning (ML)
techniques. Unfortunately, current solutions still fail to provide an effective prevention
to complex industrial threats.In this paper, we present KingFisher, an Intrusion Detection
System (IDS) framework based on ML. KingFisher is, to the best of our knowledge, the
first solution that looks independently at IT and OT traffic, but also from sensors
deployed to capture side-channel physical processes data (e.g., vibrations, background
noise). Thanks to this feature, KingFisher can detect attacks that other systems would
ignore. As our tests report, the correlation of inferred physical processes status
with OT-network and IT-network data can give insights into suspicious and anomalous
activities targeting industrial networks. For our framework, we use the Variational
Autoencoders (VAEs), an unsupervised neural network model, to categorize data without
a priori knowledge of the dataset. We evaluate the detection capabilities and performances
of KingFisher in a proof of concept simulated industrial scenario under cyber-physical
attacks. Our preliminary results show that KingFisher identifies attacks on both network
and physical layers.},
  doi       = {10.1145/3362743.3362961},
  isbn      = {9781450370110},
  keywords  = {Machine Learning, Industrial Control System, Security, Cyber-Physical System, Anomaly Detection},
  location  = {New York, NY, USA},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3362743.3362961},
}

@Article{Lu2014,
  author     = {Lu, Lanyue and Arpaci-Dusseau, Andrea C. and Arpaci-Dusseau, Remzi H. and Lu, Shan},
  journal    = {ACM Trans. Storage},
  title      = {A Study of Linux File System Evolution},
  year       = {2014},
  issn       = {1553-3077},
  month      = jan,
  number     = {1},
  volume     = {10},
  abstract   = {We conduct a comprehensive study of file-system code evolution. By analyzing eight
years of Linux file-system changes across 5079 patches, we derive numerous new (and
sometimes surprising) insights into the file-system development process; our results
should be useful for both the development of file systems themselves as well as the
improvement of bug-finding tools.},
  address    = {New York, NY, USA},
  articleno  = {3},
  doi        = {10.1145/2560012},
  issue_date = {January 2014},
  keywords   = {reliability, File systems, failure, bug, patch, performance},
  numpages   = {32},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2560012},
}

@InProceedings{Chen2021,
  author    = {Chen, Xinyun and Wang, Wenxiao and Bender, Chris and Ding, Yiming and Jia, Ruoxi and Li, Bo and Song, Dawn},
  booktitle = {Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security},
  title     = {REFIT: A Unified Watermark Removal Framework For Deep Learning Systems With Limited Data},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {321–335},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '21},
  abstract  = {Training deep neural networks from scratch could be computationally expensive and
requires a lot of training data. Recent work has explored different watermarking techniques
to protect the pre-trained deep neural networks from potential copyright infringements.
However, these techniques could be vulnerable to watermark removal attacks. In this
work, we propose REFIT, a unified watermark removal framework based on fine-tuning,
which does not rely on the knowledge of the watermarks, and is effective against a
wide range of watermarking schemes. In particular, we conduct a comprehensive study
of a realistic attack scenario where the adversary has limited training data, which
has not been emphasized in prior work on attacks against watermarking schemes. To
effectively remove the watermarks without compromising the model functionality under
this weak threat model, we propose two techniques that are incorporated into our fine-tuning
framework: (1) an adaption of the elastic weight consolidation (EWC) algorithm, which
is originally proposed for mitigating the catastrophic forgetting phenomenon; and
(2) unlabeled data augmentation (AU), where we leverage auxiliary unlabeled data from
other sources. Our extensive evaluation shows the effectiveness of REFIT against diverse
watermark embedding schemes. In particular, both EWC and AU significantly decrease
the amount of labeled training data needed for effective watermark removal, and the
unlabeled data samples used for AU do not necessarily need to be drawn from the same
distribution as the benign data for model evaluation. The experimental results demonstrate
that our fine-tuning based watermark removal attacks could pose real threats to the
copyright of pre-trained models, and thus highlight the importance of further investigating
the watermarking problem and proposing more robust watermark embedding schemes against
the attacks.},
  doi       = {10.1145/3433210.3453079},
  isbn      = {9781450382878},
  keywords  = {neural networks, fine-tuning, watermark removal},
  location  = {Virtual Event, Hong Kong},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3433210.3453079},
}

@InProceedings{Khodaei2019,
  author    = {Khodaei, Mohammad and Noroozi, Hamid and Papadimitratos, Panos},
  booktitle = {Proceedings of the 12th Conference on Security and Privacy in Wireless and Mobile Networks},
  title     = {Scaling Pseudonymous Authentication for Large Mobile Systems},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {174–184},
  publisher = {Association for Computing Machinery},
  series    = {WiSec '19},
  abstract  = {The central building block of secure and privacy-preserving Vehicular Communication
(VC) systems is a Vehicular Public-Key Infrastructure (VPKI), which provides vehicles
with multiple anonymized credentials, termed pseudonyms. These pseudonyms are used
to ensure message authenticity and integrity while preserving vehicle (thus passenger)
privacy. In the light of emerging large-scale multi-domain VC environments, the efficiency
of the VPKI and, more broadly, its scalability are paramount. By the same token, preventing
misuse of the credentials, in particular, Sybil-based misbehavior, and managing "honest-but-curious"
insiders are other facets of a challenging problem. In this paper, we leverage the
state-of-the-art VPKI system and enhance its functionality towards a highly-available,
dynamically-scalable, and resilient design; this ensures that the system remains operational
in the presence of benign failures or resource depletion attacks, and that it dynamically
scales out, or possibly scales in, according to request arrival rates. Our full-blown
implementation on the Google Cloud Platform shows that deploying large-scale and efficient
VPKI can be cost-effective.},
  doi       = {10.1145/3317549.3323410},
  isbn      = {9781450367264},
  keywords  = {VANETs, resilient, container orchestration, availability, cloud, scalability, privacy, VPKI, micro-service, security},
  location  = {Miami, Florida},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3317549.3323410},
}

@InProceedings{Halevi2011,
  author    = {Halevi, Shai and Harnik, Danny and Pinkas, Benny and Shulman-Peleg, Alexandra},
  booktitle = {Proceedings of the 18th ACM Conference on Computer and Communications Security},
  title     = {Proofs of Ownership in Remote Storage Systems},
  year      = {2011},
  address   = {New York, NY, USA},
  pages     = {491–500},
  publisher = {Association for Computing Machinery},
  series    = {CCS '11},
  abstract  = {Cloud storage systems are becoming increasingly popular. A promising technology that
keeps their cost down is deduplication, which stores only a single copy of repeating
data. Client-side deduplication attempts to identify deduplication opportunities already
at the client and save the bandwidth of uploading copies of existing files to the
server. In this work we identify attacks that exploit client-side deduplication, allowing
an attacker to gain access to arbitrary-size files of other users based on a very
small hash signatures of these files. More specifically, an attacker who knows the
hash signature of a file can convince the storage service that it owns that file,
hence the server lets the attacker download the entire file. (In parallel to our work,
a subset of these attacks were recently introduced in the wild with respect to the
Dropbox file synchronization service.) To overcome such attacks, we introduce the
notion of proofs-of-ownership (PoWs), which lets a client efficiently prove to a server
that that the client holds a file, rather than just some short information about it.
We formalize the concept of proof-of-ownership, under rigorous security definitions,
and rigorous efficiency requirements of Petabyte scale storage systems. We then present
solutions based on Merkle trees and specific encodings, and analyze their security.
We implemented one variant of the scheme. Our performance measurements indicate that
the scheme incurs only a small overhead compared to naive client-side deduplication.},
  doi       = {10.1145/2046707.2046765},
  isbn      = {9781450309486},
  keywords  = {deduplication, cloud storage, proofs of ownership, merkle trees},
  location  = {Chicago, Illinois, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2046707.2046765},
}

@InProceedings{Chen2018,
  author    = {Chen, Qian and Sowan, Azizeh Khaled and Xu, Shouhuai},
  booktitle = {Proceedings of the International Conference on Computer-Aided Design},
  title     = {A Safety and Security Architecture for Reducing Accidents in Intelligent Transportation Systems},
  year      = {2018},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ICCAD '18},
  abstract  = {The Internet of Things (IoT) technology is transforming the world into Smart Cities,
which have a huge impact on future societal lifestyle, economy and business. Intelligent
Transportation Systems (ITS), especially IoT-enabled Electric Vehicles (EVs), are
anticipated to be an integral part of future Smart Cities. Assuring ITS safety and
security is critical to the success of Smart Cities because human lives are at stake.
The state-of-the-art understanding of this matter is very superficial because there
are many new problems that have yet to be investigated. For example, the cyber-physical
nature of ITS requires considering human-in-the-loop (i.e., drivers and pedestrians)
and imposes many new challenges. In this paper, we systematically explore the threat
model against ITS safety and security (e.g., malfunctions of connected EVs/transportation
infrastructures, driver misbehavior and unexpected medical conditions, and cyber attacks).
Then, we present a novel and systematic ITS safety and security architecture, which
aims to reduce accidents caused or amplified by a range of threats. The architecture
has appealing features: (i) it is centered at proactive cyber-physical-human defense;
(ii) it facilitates the detection of early-warning signals of accidents; (iii) it
automates effective defense against a range of threats.},
  articleno = {95},
  doi       = {10.1145/3240765.3243462},
  isbn      = {9781450359504},
  keywords  = {internet of things, connected vehicles, intelligent transportation system, safety and security architecture, human factor},
  location  = {San Diego, California},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3240765.3243462},
}

@InProceedings{Beaver2013,
  author    = {Beaver, Justin M. and Symons, Christopher T. and Gillen, Robert E.},
  booktitle = {Proceedings of the Eighth Annual Cyber Security and Information Intelligence Research Workshop},
  title     = {A Learning System for Discriminating Variants of Malicious Network Traffic},
  year      = {2013},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {CSIIRW '13},
  abstract  = {Modern computer network defense systems rely primarily on signature-based intrusion
detection tools, which generate alerts when patterns that are pre-determined to be
malicious are encountered in network data streams. Signatures are created reactively,
and only after in-depth manual analysis of a network intrusion. There is little ability
for signature-based detectors to identify intrusions that are new or even variants
of an existing attack, and little ability to adapt the detectors to the patterns unique
to a network environment. Due to these limitations, the need exists for network intrusion
detection techniques that can more comprehensively address both known and unknown
network-based attacks and can be optimized for the target environment.This work describes
a system that leverages machine learning to provide a network intrusion detection
capability that analyzes behaviors in channels of communication between individual
computers. Using examples of malicious and non-malicious traffic in the target environment,
the system can be trained to discriminate between traffic types. The machine learning
provides insight that would be difficult for a human to explicitly code as a signature
because it evaluates many interdependent metrics simultaneously. With this approach,
zero day detection is possible by focusing on similarity to known traffic types rather
than mining for specific bit patterns or conditions. This also reduces the burden
on organizations to account for all possible attack variant combinations through signatures.
The approach is presented along with results from a third-party evaluation of its
performance.},
  articleno = {23},
  doi       = {10.1145/2459976.2460003},
  isbn      = {9781450316873},
  keywords  = {computer network defense, machine learning, intrusion detection},
  location  = {Oak Ridge, Tennessee, USA},
  numpages  = {4},
  url       = {https://doi.org/10.1145/2459976.2460003},
}

@Article{Gao2012,
  author     = {Gao, Xifeng and Zhang, Caiming and Huang, Yan and Deng, Zhigang},
  journal    = {ACM Trans. Multimedia Comput. Commun. Appl.},
  title      = {A Robust High-Capacity Affine-Transformation-Invariant Scheme for Watermarking 3D Geometric Models},
  year       = {2012},
  issn       = {1551-6857},
  month      = sep,
  number     = {2S},
  volume     = {8},
  abstract   = {In this article we propose a novel, robust, and high-capacity watermarking method
for 3D meshes with arbitrary connectivities in the spatial domain based on affine
invariants. Given a 3D mesh model, a watermark is embedded as affine-invariant length
ratios of one diagonal segment to the residing diagonal intersected by the other one
in a coplanar convex quadrilateral. In the extraction process, a watermark is recovered
by combining all the watermark pieces embedded in length ratios through majority voting.
Extensive experimental results demonstrate the robustness, high computational efficiency,
high capacity, and affine-transformation-invariant characteristics of the proposed
approach.},
  address    = {New York, NY, USA},
  articleno  = {34},
  doi        = {10.1145/2344436.2344440},
  issue_date = {September 2012},
  keywords   = {3D model watermarking, affine transformation invariant, 3D model authentication, high capacity, copyright protection},
  numpages   = {21},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2344436.2344440},
}

@InProceedings{Ivanova2021,
  author    = {Ivanova, Malinka and Rozeva, Anna},
  booktitle = {2021 The 5th International Conference on Machine Learning and Soft Computing},
  title     = {Detection of XSS Attack and Defense of REST Web Service – Machine Learning Perspective},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {22–28},
  publisher = {Association for Computing Machinery},
  series    = {ICMLSC'21},
  abstract  = {The paper presents a machine learning approach for detection of stored XSS attack
and for defense of REST web service. For this purpose, a XML-based REST web service
is developed in JAVA, which is tested and attacked in specially created test-bed simulation
environment, consisting of IntelliJ IDEA environment, Postman and web browser. The
obtained data sets are processed resulting in the selection of 30 out of 171 features
for further treatment. Supervised machine learning classifiers: Random Forest, Random
Tree, Decision Tree and Gradient Boosted Tree are used for the detection of known
attacks and clustering algorithm k-Means for the identification of unknown threats.
The efficiency of implementing machine learning algorithms is evaluated and the results
confirm their high accuracy. In addition fuzzy sets and fuzzy logic theory is utilized
for solving multi-criteria task in support of decision making for web service defense.},
  doi       = {10.1145/3453800.3453805},
  isbn      = {9781450387613},
  keywords  = {XSS stored attack, fuzzy logic, REST web service defense, machine learning},
  location  = {Da Nang, Viet Nam},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3453800.3453805},
}

@InProceedings{Fraunholz2018,
  author    = {Fraunholz, Daniel and Schneider, Daniel and Zemitis, Janis and Schotten, Hans Dieter},
  booktitle = {Proceedings of the Central European Cybersecurity Conference 2018},
  title     = {Hack My Company: An Empirical Assessment of Post-Exploitation Behavior and Lateral Movement in Cloud Environments},
  year      = {2018},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {CECC 2018},
  abstract  = {Cloud infrastructures and services are of essential importance for enterprise operations.
They form a central point for data storage, processing and exchange. Their information
security properties are strongly associated with the protection of the most confidential
and important data of enterprises. In this work a credential leak on different platforms
is simulated, revealing authentication information for several accounts on a cloud
application service. Each account associated with the leaks provides more authentication
information for further infrastructures such as an e-mail server, an industrial control
system and an enterprise-related streaming server. Additionally, a homepage was launched
with information on the fictitious persons associated with the leaked accounts. Interaction
with those servers is closely monitored. It was found that around one third of all
trespassers conducted lateral movement and successful authentications frequently result
in system enumeration and file operations.},
  articleno = {3},
  doi       = {10.1145/3277570.3277573},
  isbn      = {9781450365154},
  keywords  = {Information Security, Honeypots, Cloud, Deception},
  location  = {Ljubljana, Slovenia},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3277570.3277573},
}

@InProceedings{Martin2017,
  author    = {Martin, Vincentius and Cao, Qiang and Benson, Theophilus},
  booktitle = {Proceedings of the 2nd Workshop on Cloud-Assisted Networking},
  title     = {Fending off IoT-Hunting Attacks at Home Networks},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {67–72},
  publisher = {Association for Computing Machinery},
  series    = {CAN '17},
  abstract  = {Many attacks target vulnerabilities of home IoT devices, such as bugs in outdated
software and weak passwords. The home network is at a vantage point for deploying
security appliances to deal with such IoT attacks. We propose a comprehensive home
network defense, Pot2DPI, and use it to raise an attacker's uncertainty about devices
and enable the home network to monitor traffic, detect anomalies, and filter malicious
packets. The security offered by Pot2DPI comes from a synthesis of practical techniques:
honeypot, deep packet inspection (DPI), and a realization of moving target defense
(MTD) in port forwarding. In particular, Pot2DPI has a chain of honeypot and DPI that
collects suspicious packet traces, acquires attack signatures, and installs filtering
rules at a home router timely. Meanwhile, Pot2DPI shuffles the mapping of ports between
the router and the devices connected to it, making a targeted attack difficult and
defense more effective. Pot2DPI is our first step towards securing a smart home.},
  doi       = {10.1145/3155921.3160640},
  isbn      = {9781450354233},
  keywords  = {moving target defense, home network, honeypot, IoT},
  location  = {Incheon, Republic of Korea},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3155921.3160640},
}

@Article{Ashmore2021,
  author     = {Ashmore, Rob and Calinescu, Radu and Paterson, Colin},
  journal    = {ACM Comput. Surv.},
  title      = {Assuring the Machine Learning Lifecycle: Desiderata, Methods, and Challenges},
  year       = {2021},
  issn       = {0360-0300},
  month      = may,
  number     = {5},
  volume     = {54},
  abstract   = {Machine learning has evolved into an enabling technology for a wide range of highly
successful applications. The potential for this success to continue and accelerate
has placed machine learning (ML) at the top of research, economic, and political agendas.
Such unprecedented interest is fuelled by a vision of ML applicability extending to
healthcare, transportation, defence, and other domains of great societal importance.
Achieving this vision requires the use of ML in safety-critical applications that
demand levels of assurance beyond those needed for current ML applications. Our article
provides a comprehensive survey of the state of the art in the assurance of ML, i.e.,
in the generation of evidence that ML is sufficiently safe for its intended use. The
survey covers the methods capable of providing such evidence at different stages of
the machine learning lifecycle, i.e., of the complex, iterative process that starts
with the collection of the data used to train an ML component for a system, and ends
with the deployment of that component within the system. The article begins with a
systematic presentation of the ML lifecycle and its stages. We then define assurance
desiderata for each stage, review existing methods that contribute to achieving these
desiderata, and identify open challenges that require further research.},
  address    = {New York, NY, USA},
  articleno  = {111},
  doi        = {10.1145/3453444},
  issue_date = {June 2021},
  keywords   = {safety-critical systems, assurance, Machine learning lifecycle, machine learning workflow, assurance evidence},
  numpages   = {39},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3453444},
}

@InProceedings{Naval2014,
  author    = {Naval, Smita and Laxmi, Vijay and Gupta, Neha and Gaur, Manoj Singh and Rajarajan, Muttukrishnan},
  booktitle = {Proceedings of the 7th International Conference on Security of Information and Networks},
  title     = {Exploring Worm Behaviors Using DTW},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {379–384},
  publisher = {Association for Computing Machinery},
  series    = {SIN '14},
  abstract  = {Worms are becoming a potential threat to Internet users across the globe. The financial
damages due to computer worms increased significantly in past few years. Analyzing
these hazardous worm attacks has become a crucial issue to be addressed. Given the
fact that worm analysts would prefer to analyze classes of worms rather than individual
files, their task will be significantly reduced. In this paper, we have proposed a
dynamic host--based worm categorization approach to segregate worms. These groups
indicate that worm samples constitute different behavior according to their infection
and anti--detection vectors. Our proposed approach utilizes system--call traces and
computes a distance matrix using Dynamic Time Warping (DTW) algorithm to form these
groups. In conjunction to that, the proposed approach also discriminates worm and
benign executables. The constructed model is further evaluated with unknown instances
of real--world worms.},
  doi       = {10.1145/2659651.2659737},
  isbn      = {9781450330336},
  keywords  = {Behavior Monitoring, DTW, System--calls},
  location  = {Glasgow, Scotland, UK},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2659651.2659737},
}

@InProceedings{Song2021,
  author    = {Song, Qun and Tan, Rui and Ren, Chao and Xu, Yan},
  booktitle = {Proceedings of the Twelfth ACM International Conference on Future Energy Systems},
  title     = {Understanding Credibility of Adversarial Examples against Smart Grid: A Case Study for Voltage Stability Assessment},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {95–106},
  publisher = {Association for Computing Machinery},
  series    = {e-Energy '21},
  abstract  = {Stability assessment is an important task for maintaining reliable operations of power
grids. With increased system complexity, deep learning-based stability assessment
approaches are promising to address the shortfalls of the traditional time-domain
simulation-based approaches. However, in the field of computer vision, the deep learning
models are shown vulnerable to adversarial examples. Although this vulnerability has
been noticed by the energy informatics research, the domain-specific analysis on the
requirements imposed for implementing effective adversarial examples is still lacking.
These attack requirements, albeit reasonable in computer vision tasks, can be too
stringent in the context of power grids. In this paper, we systematically investigate
the requirements and discuss the credibility of six representative adversarial example
attacks for a case study of voltage stability assessment for the New England 10-machine
39-bus system. We show that (1) compromising the voltage traces of half of transmission
system buses is a rule of thumb requirement; (2) the universal adversarial perturbations
that are independent of the original clean voltage trajectory have the same credibility
as the widely studied false data injection attacks on power grid state estimation,
while other adversarial example attacks are less credible; (3) the universal perturbations
can be effectively defended with strong adversarial training.},
  doi       = {10.1145/3447555.3464859},
  isbn      = {9781450383332},
  keywords  = {cybersecurity, machine learning, smart grid, voltage stability assessment, Adversarial example},
  location  = {Virtual Event, Italy},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3447555.3464859},
}

@InProceedings{Tabrizi2016,
  author    = {Tabrizi, Farid Molazem and Pattabiraman, Karthik},
  booktitle = {Proceedings of the 32nd Annual Conference on Computer Security Applications},
  title     = {Formal Security Analysis of Smart Embedded Systems},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {1–15},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '16},
  abstract  = {Smart embedded systems are core components of Internet of Things (IoT). Many vulnerabilities
and attacks have been discovered against different classes of IoT devices. Therefore,
developing a systematic mechanism to analyze the security of smart embedded systems
will help developers discover new attacks, and improve the design and implementation
of the system. In this paper, we formally model the functionalitiy of smart meters,
as an example of a widely used smart embedded device, using rewriting logic. We also
define a formal set of actions for attackers. Our formal model enables us to automatically
analyze the system, and using model-checking, find all the sequences of attacker actions
that transition the system to any undesirable state. We evaluate the analysis results
of our model on a real smart meter, and find that a sizeable set of the attacks found
by the model can be applied to the smart meter, using only inexpensive, commodity
off-the-shelf hardware.},
  doi       = {10.1145/2991079.2991085},
  isbn      = {9781450347716},
  keywords  = {formal model, IoT, security analysis, smart meters},
  location  = {Los Angeles, California, USA},
  numpages  = {15},
  url       = {https://doi.org/10.1145/2991079.2991085},
}

@InProceedings{Bo2016,
  author    = {Bo, Li and Jinzhen, Wang and Ping, Zhao and Zhongjiang, Yan and Mao, Yang},
  booktitle = {Proceedings of the Fifth International Conference on Network, Communication and Computing},
  title     = {Research of Recognition System of Web Intrusion Detection Based on Storm},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {98–102},
  publisher = {Association for Computing Machinery},
  series    = {ICNCC '16},
  abstract  = {Based on Storm, a distributed, reliable, fault-tolerant real-time data stream processing
system, we propose a recognition system of web intrusion detection. The system is
based on machine learning, feature selection algorithm by TF-IDF(Term Frequency--Inverse
Document Frequency) and the optimised cosine similarity algorithm, at low false positive
rate and a higher detection rate of attacks and malicious behavior in real-time to
protect the security of user data. From comparative analysis of experiments we find
that the system for intrusion recognition rate and false positive rate has improved
to some extent, it can be better to complete the intrusion detection work.},
  doi       = {10.1145/3033288.3033319},
  isbn      = {9781450347938},
  keywords  = {Web Intrusion Detection System, TF-IDF, Strom, Big Data, cosine similarity},
  location  = {Kyoto, Japan},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3033288.3033319},
}

@InProceedings{Gilad2013,
  author    = {Gilad, Yossi and Herzberg, Amir},
  booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
  title     = {When Tolerance Causes Weakness: The Case of Injection-Friendly Browsers},
  year      = {2013},
  address   = {New York, NY, USA},
  pages     = {435–446},
  publisher = {Association for Computing Machinery},
  series    = {WWW '13},
  abstract  = {We present a practical off-path TCP-injection attack for connections between current,
non-buggy browsers and web-servers. The attack allows web-cache poisoning with malicious
objects; these objects can be cached for long time period, exposing any user of that
cache to XSS, CSRF and phishing attacks.In contrast to previous TCP-injection attacks,
we assume neither vulnerabilities such as client-malware nor predictable choice of
client port or IP-ID. We only exploit subtle details of HTTP and TCP specifications,
and features of legitimate (and common) browser implementations. An empirical evaluation
of our techniques with current versions of browsers shows that connections with popular
websites are vulnerable. Our attack is modular, and its modules may improve other
off-path attacks on TCP communication.We present practical patches against the attack;
however, the best defense is surely adoption of TLS, that ensures security even against
the stronger Man-in-the-Middle attacker.},
  doi       = {10.1145/2488388.2488427},
  isbn      = {9781450320351},
  keywords  = {web and network security, off-path attacks, browser security},
  location  = {Rio de Janeiro, Brazil},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2488388.2488427},
}

@InProceedings{Verwer2020,
  author    = {Verwer, Sicco and Nadeem, Azqa and Hammerschmidt, Christian and Bliek, Laurens and Al-Dujaili, Abdullah and O'Reilly, Una-May},
  booktitle = {Proceedings of the 13th ACM Workshop on Artificial Intelligence and Security},
  title     = {The Robust Malware Detection Challenge and Greedy Random Accelerated Multi-Bit Search},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {61–70},
  publisher = {Association for Computing Machinery},
  series    = {AISec'20},
  abstract  = {Training classifiers that are robust against adversarially modified examples is becoming
increasingly important in practice. In the field of malware detection, adversaries
modify malicious binary files to seem benign while preserving their malicious behavior.
We report on the results of a recently held robust malware detection challenge. There
were two tracks in which teams could participate: the attack track asked for adversarially
modified malware samples and the defend track asked for trained neural network classifiers
that are robust to such modifications. The teams were unaware of the attacks/defenses
they had to detect/evade. Although only 9 teams participated, this unique setting
allowed us to make several interesting observations.We also present the challenge
winner: GRAMS, a family of novel techniques to train adversarially robust networks
that preserve the intended (malicious) functionality and yield high-quality adversarial
samples. These samples are used to iteratively train a robust classifier. We show
that our techniques, based on discrete optimization techniques, beat purely gradient-based
methods. GRAMS obtained first place in both the attack and defend tracks of the competition.},
  doi       = {10.1145/3411508.3421374},
  isbn      = {9781450380942},
  keywords  = {discrete optimization, adversarial malware, robust malware detection, neural networks, adversarial learning, saddle-point optimization},
  location  = {Virtual Event, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3411508.3421374},
}

@InProceedings{Cao2018,
  author    = {Cao, Yinzhi and Yu, Alexander Fangxiao and Aday, Andrew and Stahl, Eric and Merwine, Jon and Yang, Junfeng},
  booktitle = {Proceedings of the 2018 on Asia Conference on Computer and Communications Security},
  title     = {Efficient Repair of Polluted Machine Learning Systems via Causal Unlearning},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {735–747},
  publisher = {Association for Computing Machinery},
  series    = {ASIACCS '18},
  abstract  = {Machine learning systems, though being successful in many real-world applications,
are known to remain prone to errors and attacks. A major attack, called data pollution,
injects maliciously crafted training data samples into the training set, causing the
system to learn an incorrect model and subsequently misclassify testing samples. A
natural solution to a data pollution attack is to remove the polluted data from the
training set and relearn a clean model. Unfortunately, the training set of a real-world
machine learning system can contain millions of samples; it is thus hopeless for an
administrator to manually inspect all of them to weed out the polluted ones.This paper
presents an approach called causal unlearning and a corresponding system called KARMA
to efficiently repair a polluted learning system. KARMA dramatically reduces the manual
effort of administrators by automatically detecting the set of polluted training data
samples with high precision and recall. Evaluation on three learning systems show
that KARMA greatly reduces manual effort for repair, and has high precision and recall.},
  doi       = {10.1145/3196494.3196517},
  isbn      = {9781450355766},
  keywords  = {causality, machine unlearning, data pollution attacks},
  location  = {Incheon, Republic of Korea},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3196494.3196517},
}

@InProceedings{Wang2021,
  author    = {Wang, Tianhao and Kerschbaum, Florian},
  booktitle = {Proceedings of the Web Conference 2021},
  title     = {RIGA: Covert and Robust White-Box Watermarking of Deep Neural Networks},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {993–1004},
  publisher = {Association for Computing Machinery},
  series    = {WWW '21},
  abstract  = {Watermarking of deep neural networks (DNN) can enable their tracing once released
by a data owner to an online platform. In this paper, we generalize white-box watermarking
algorithms for DNNs, where the data owner needs white-box access to the model to extract
the watermark. White-box watermarking algorithms have the advantage that they do not
impact the accuracy of the watermarked model. We propose Robust whIte-box GAn watermarking
(RIGA), a novel white-box watermarking algorithm that uses adversarial training. Our
extensive experiments demonstrate that the proposed watermarking algorithm not only
does not impact accuracy, but also significantly improves the covertness and robustness
over the current state-of-art.},
  doi       = {10.1145/3442381.3450000},
  isbn      = {9781450383127},
  location  = {Ljubljana, Slovenia},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3442381.3450000},
}

@InProceedings{Garcia2019,
  author    = {Garcia, Miguel and Bessani, Alysson and Neves, Nuno},
  booktitle = {Proceedings of the 20th International Middleware Conference},
  title     = {Lazarus: Automatic Management of Diversity in BFT Systems},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {241–254},
  publisher = {Association for Computing Machinery},
  series    = {Middleware '19},
  abstract  = {A long-standing promise of Byzantine Fault-Tolerant (BFT) replication is to maintain
the service correctness despite the presence of malicious failures. The key challenge
here is how to ensure replicas fail independently, i.e., avoid that a single attack
compromises more than f replicas at once. The obvious answer for this is the use of
diverse replicas, but most works in BFT simply assume such diversity without supporting
mechanisms to substantiate this assumption. Lazarus is a control plane for managing
the deployment and execution of diverse replicas in BFT systems. Lazarus continuously
monitors the current vulnerabilities of the system replicas (reported in security
feeds such as NVD and ExploitDB) and employs a metric to measure the risk of having
a common weakness in the replicas set. If such risk is high, the set of replicas is
reconfigured. Our evaluation shows that the devised strategy reduces the number of
executions where the system becomes compromised and that our prototype supports the
execution of full-fledged BFT systems in diverse configurations with 17 OS versions,
reaching a performance close to a homogeneous bare-metal setup.},
  doi       = {10.1145/3361525.3361550},
  isbn      = {9781450370097},
  keywords  = {diversity, Byzantine fault tolerance, BFT, vulnerability management, state machine replication},
  location  = {Davis, CA, USA},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3361525.3361550},
}

@Article{Bernaschi2017,
  author     = {Bernaschi, Massimo and Celestini, Alessandro and Guarino, Stefano and Lombardi, Flavio},
  journal    = {ACM Trans. Web},
  title      = {Exploring and Analyzing the Tor Hidden Services Graph},
  year       = {2017},
  issn       = {1559-1131},
  month      = jul,
  number     = {4},
  volume     = {11},
  abstract   = {The exploration and analysis of Web graphs has flourished in the recent past, producing
a large number of relevant and interesting research results. However, the unique characteristics
of the Tor network limit the applicability of standard techniques and demand for specific
algorithms to explore and analyze it. The attention of the research community has
focused on assessing the security of the Tor infrastructure (i.e., its ability to
actually provide the intended level of anonymity) and on discussing what Tor is currently
being used for. Since there are no foolproof techniques for automatically discovering
Tor hidden services, little or no information is available about the topology of the
Tor Web graph. Even less is known on the relationship between content similarity and
topological structure. The present article aims at addressing such lack of information.
Among its contributions: a study on automatic Tor Web exploration/data collection
approaches; the adoption of novel representative metrics for evaluating Tor data;
a novel in-depth analysis of the hidden services graph; a rich correlation analysis
of hidden services’ semantics and topology. Finally, a broad interesting set of novel
insights/considerations over the Tor Web organization and content are provided.},
  address    = {New York, NY, USA},
  articleno  = {24},
  doi        = {10.1145/3008662},
  issue_date = {September 2017},
  keywords   = {automatic web exploration, correlation analysis, network topology, Web graphs},
  numpages   = {26},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3008662},
}

@InProceedings{Wang2016,
  author    = {Wang, Bolun and Zhang, Xinyi and Wang, Gang and Zheng, Haitao and Zhao, Ben Y.},
  booktitle = {Proceedings of the 2016 Internet Measurement Conference},
  title     = {Anatomy of a Personalized Livestreaming System},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {485–498},
  publisher = {Association for Computing Machinery},
  series    = {IMC '16},
  abstract  = {With smartphones making video recording easier than ever, new apps like Periscope
and Meerkat brought personalized interactive video streaming to millions. With a touch,
viewers can switch between first person perspectives across the globe, and interact
in real-time with broadcasters. Unlike traditional video streaming, these services
require low-latency video delivery to support high interactivity between broadcasters
and audiences.We perform a detailed analysis into the design and performance of Periscope,
the most popular personal livestreaming service with 20 million users. Using detailed
measurements of Periscope (3 months, 19M streams, 705M views) and Meerkat (1 month,
164K streams, 3.8M views), we ask the critical question: ``Can personalized livestreams
continue to scale, while allowing their audiences to experience desired levels of
interactivity?' We analyze the network path of each stream and break down components
of its end-to-end delay. We find that much of each stream's delay is the direct result
of decisions to improve scalability, from chunking video sequences to selective polling
for reduced server load. Our results show a strong link between volume of broadcasts
and stream delivery latency. Finally, we discovered a critical security flaw during
our study, and shared it along with a scalable solution with Periscope and Meerkat
management.},
  doi       = {10.1145/2987443.2987453},
  isbn      = {9781450345262},
  keywords  = {cdn, network performance},
  location  = {Santa Monica, California, USA},
  numpages  = {14},
  url       = {https://doi.org/10.1145/2987443.2987453},
}

@InProceedings{McKay2019,
  author    = {McKay, Rob and Pendleton, Brian and Britt, James and Nakhavanit, Ben},
  booktitle = {Proceedings of the 2019 3rd International Conference on Compute and Data Analysis},
  title     = {Machine Learning Algorithms on Botnet Traffic: Ensemble and Simple Algorithms},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {31–35},
  publisher = {Association for Computing Machinery},
  series    = {ICCDA 2019},
  abstract  = {The authors introduce the Bronte machine learning evaluation study for consistent
detection of malware, specifically honed for botnets. Machine learning algorithms
are already being used to detect malware in dynamic environments. This evaluation
utilizes a static measurement approach that could be implemented on edge network devices.
It was generated from conversation-based network traffic. This study fully enumerated
the network traffic features to allow various machine learning algorithms to build
various training sets to deploy against dual test sets. Utilizing the Waikato Environment
for Knowledge Analysis (WEKA) datamining and analysis tool, various algorithmic experiments
were deployed against the modern and large CICIDS2017 dataset. This evaluation study
aimed to push non-IP address features through a series of machine learning classifiers.
The study was conducted differently and more methodically than other related studies
by using three highly randomized training sets and two test data sets. The test sets
were different in that one was a real world based 98.9 benign traffic and one was
50/50 benign to bot traffic. The instance based nearest neighbor and decision tree
classifiers ranked highest only using the training sets; but the J48, an expanded
ID3 decision tree classifier, clearly produced the highest predictions against both
test sets.},
  doi       = {10.1145/3314545.3314569},
  isbn      = {9781450366342},
  keywords  = {intrusion detection, machine learning, Botnet},
  location  = {Kahului, HI, USA},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3314545.3314569},
}

@InProceedings{Krotofil2015,
  author    = {Krotofil, Marina and Larsen, Jason and Gollmann, Dieter},
  booktitle = {Proceedings of the 10th ACM Symposium on Information, Computer and Communications Security},
  title     = {The Process Matters: Ensuring Data Veracity in Cyber-Physical Systems},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {133–144},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '15},
  abstract  = {Cyber-physical systems are characterized by an IT infrastructure controlling effects
in the physical world. Attacks are intentional actions trying to cause undesired physical
effects. When process data originating in the physical world is manipulated before
being handed to the IT infrastructure, the data security property called "veracity"
or trustworthiness will be violated. There is no canonical IT security solution guaranteeing
that the inputs from a sensor faithfully represent reality. However, the laws of physics
may help the defender to detect impossible or implausible sensor readings.This paper
proposes a process-aware approach to detect when a sensor signal is being maliciously
manipulated. We present a set of lightweight real-time algorithms for spoofing sensor
signals directly at the microcontroller of the field device. The detection of spoofed
measurements takes the form of plausibility and consistency checks with the help of
the correlation entropy in a cluster of related sensors. We use the Tennessee Eastman
challenge process to demonstrate the performance of our approach and to highlight
aspects relevant to the detection effectiveness.},
  doi       = {10.1145/2714576.2714599},
  isbn      = {9781450332453},
  keywords  = {veracity, signal spoofing, plausibility checks, cluster entropy, cyber-physical systems},
  location  = {Singapore, Republic of Singapore},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2714576.2714599},
}

@InProceedings{Houser2019,
  author    = {Houser, Rebekah and Li, Zhou and Cotton, Chase and Wang, Haining},
  booktitle = {Proceedings of the 15th International Conference on Emerging Networking Experiments And Technologies},
  title     = {An Investigation on Information Leakage of DNS over TLS},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {123–137},
  publisher = {Association for Computing Machinery},
  series    = {CoNEXT '19},
  abstract  = {DNS over TLS (DoT) protects the confidentiality and integrity of DNS communication
by encrypting DNS messages transmitted between users and resolvers. In recent years,
DoT has been deployed by popular recursive resolvers like Cloudflare and Google. While
DoT is supposed to prevent on-path adversaries from learning and tampering with victims'
DNS requests and responses, it is unclear how much information can be deduced through
traffic analysis on DoT messages. To answer this question, in this work, we develop
a DoT fingerprinting method to analyze DoT traffic and determine if a user has visited
websites of interest to adversaries. Given that a visit to a website typically introduces
a sequence of DNS packets, we can infer the visited websites by modeling the temporal
patterns of packet sizes. Our method can identify DoT traffic for websites with a
false negative rate of less than 17% and a false positive rate of less than 0.5% when
DNS messages are not padded. Moreover, we show that information leakage is still possible
even when DoT messages are padded. These findings highlight the challenges of protecting
DNS privacy, and indicate the necessity of a thorough analysis of the threats underlying
DNS communications for effective defenses.},
  doi       = {10.1145/3359989.3365429},
  isbn      = {9781450369985},
  keywords  = {DNS privacy, traffic analysis, website fingerprinting},
  location  = {Orlando, Florida},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3359989.3365429},
}

@InProceedings{Parkinson2017,
  author    = {Parkinson, Simon and Qin, Yongrui and Khan, Saad and Vallati, Mauro},
  booktitle = {Proceedings of the Second International Conference on Internet of Things, Data and Cloud Computing},
  title     = {Security Auditing in the Fog},
  year      = {2017},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ICC '17},
  abstract  = {Technology specific expert knowledge is often required to analyse security configurations
and determine potential vulnerabilities, but it becomes difficult when it is a new
technology such as Fog computing. Furthermore, additional knowledge is also required
regarding how the security configuration has been constructed in respect to an organisation's
security policies. Traditionally, organisations will often manage their access control
permissions relative to their employees needs, posing challenges to administrators.
This problem is even exacerbated in Fog computing systems where security configurations
are implemented on a large amount of devices at the edges of Internet, and the administrators
are required to retain adequate knowledge on how to perform complex administrative
tasks. In this paper, a novel approach of translating object-based security configurations
in to a graph model is presented. A technique is then developed to autonomously identify
vulnerabilities and perform security auditing of large systems without the need for
expert knowledge. Throughout the paper, access control configuration data is used
as a case study, and empirical analysis is performed on synthetically generated access
control permissions.},
  articleno = {191},
  doi       = {10.1145/3018896.3056808},
  isbn      = {9781450347747},
  keywords  = {graph-based anomaly detection, security auditing, synthetic data sets, fog computing},
  location  = {Cambridge, United Kingdom},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3018896.3056808},
}

@InProceedings{Ghaeini2019,
  author    = {Ghaeini, Hamid Reza and Tippenhauer, Nils Ole and Zhou, Jianying},
  booktitle = {Proceedings of the 14th International Conference on Availability, Reliability and Security},
  title     = {Zero Residual Attacks on Industrial Control Systems and Stateful Countermeasures},
  year      = {2019},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ARES '19},
  abstract  = {In this paper, we discuss the practical implementation of stealthy attacks on industrial
control systems. We start by reviewing the attacks proposed in prior works. Then,
we offer Zero-Residual Attacks (ZeRA), which allow the attacker to launch stealthy
attacks leveraging estimation of the stateful anomaly detector and matching of residuals
as a fraction of actual estimation residual. To perform the zero residual attack,
the attacker will require the use of two state estimators each for the physical system
state and the detector system state, adding complexity that was so far not discussed.
We implement ZeRA and demonstrate its efficacy. Then, we propose to use a Stateful
Detector (SD) to precisely detect such stealthy attacks. We design and implement the
SD detector. The obtained results from the performance evaluation demonstrate that
we can detect stealthy attacks such as the ZeRA, with precision above 99%, sensitivity
above 99%, and Matthews correlation coefficient above 0.98.},
  articleno = {80},
  doi       = {10.1145/3339252.3340331},
  isbn      = {9781450371643},
  keywords  = {Stealthy Attack, Industrial Control System, Stateful Anomaly Detection},
  location  = {Canterbury, CA, United Kingdom},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3339252.3340331},
}

@InProceedings{Lu2018,
  author    = {Lu, Guoyu and Song, Jingkuan},
  booktitle = {Proceedings of the 2018 ACM on International Conference on Multimedia Retrieval},
  title     = {3D Image-Based Indoor Localization Joint With WiFi Positioning},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {465–472},
  publisher = {Association for Computing Machinery},
  series    = {ICMR '18},
  abstract  = {We realize a system that utilizes WiFi to facilitate the image-based localization
system, which avoids the confusion caused by the similar decoration inside the buildings.
While WiFi-based localization thread obtains the rough location information, the image-based
localization thread retrieves the best matching images and clusters the camera poses
associated with the images into different location candidates. The image cluster closest
to the WiFi localization outcome is selected for the exact camera pose estimation.
The usage of WiFi significantly reduces the search scope, avoiding the extensive search
of millions of descriptors in a 3D model. In the image-based localization stage, we
also propose a novel 2D-to-2D-to-3D localization framework which follows a coarse-to-fine
strategy to quickly locate the query image in several location candidates and performs
the local feature matching and camera pose estimation after choosing the correct image
location by WiFi positioning. The entire system demonstrates significant benefits
in combining both images and WiFi signals in localization tasks and great potential
to be deployed in real applications.},
  doi       = {10.1145/3206025.3206070},
  isbn      = {9781450350464},
  keywords  = {3d registration, camera pose estimation, clustering, image-based localization, wifi-based localization},
  location  = {Yokohama, Japan},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3206025.3206070},
}

@InProceedings{Mohamed2014,
  author    = {Mohamed, Manar and Sachdeva, Niharika and Georgescu, Michael and Gao, Song and Saxena, Nitesh and Zhang, Chengcui and Kumaraguru, Ponnurangam and van Oorschot, Paul C. and Chen, Wei-Bang},
  booktitle = {Proceedings of the 9th ACM Symposium on Information, Computer and Communications Security},
  title     = {A Three-Way Investigation of a Game-CAPTCHA: Automated Attacks, Relay Attacks and Usability},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {195–206},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '14},
  abstract  = {Existing captcha solutions on the Internet are a major source of user frustration.
Game captchas are an interesting and, to date, little-studied approach claiming to
make captcha solving a fun activity for the users. One broad form of such captchas
-- called Dynamic Cognitive Game (DCG) captchas -- challenge the user to perform a
game-like cognitive task interacting with a series of dynamic images. We pursue a
comprehensive analysis of a representative category of DCG captchas. We formalize,
design and implement such captchas, and dissect them across: (1) fully automated attacks,
(2) human-solver relay attacks, and (3) usability. Our results suggest that the studied
DCG captchas exhibit high usability and, unlike other known captchas, offer some resistance
to relay attacks, but they are also vulnerable to our novel dictionary-based automated
attack.},
  doi       = {10.1145/2590296.2590298},
  isbn      = {9781450328005},
  keywords  = {web security, usability, CAPTCHA, relay attack},
  location  = {Kyoto, Japan},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2590296.2590298},
}

@InProceedings{Pavur2021,
  author    = {Pavur, James and Martinovic, Ivan},
  booktitle = {Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security},
  title     = {On Detecting Deception in Space Situational Awareness},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {280–291},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '21},
  abstract  = {Space Situational Awareness (SSA) data is critical to the safe piloting of satellites
through an ever-growing field of orbital debris. However, measurement complexity means
that most satellite operators cannot independently acquire SSA data and must rely
on a handful of centralized repositories operated by major space powers. As interstate
competition in orbit increases, so does the threat of attacks abusing these information-sharing
relationships. This paper offers one of the first considerations of defense techniques
against SSA deceptions. Building on historical precedent and real-world SSA data,
we simulate an attack whereby an SSA operator seeks to disguise spy satellites as
pieces of debris. We further develop and evaluate a machine-learning based anomaly
detection tool which allows defenders to detect 90-98% of deception attempts with
little to no in-house astrometry hardware.Beyond the direct contribution of this system,
the paper takes a unique interdisciplinary approach, drawing connections between cyber-security,
astrophysics, and international security studies. It presents the general case that
systems security methods can tackle many novel and complex problems in an historically
neglected domain and provides methods and techniques for doing so.},
  doi       = {10.1145/3433210.3453081},
  isbn      = {9781450382878},
  keywords  = {SSA, space cybersecurity, satellite, space situational awareness},
  location  = {Virtual Event, Hong Kong},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3433210.3453081},
}

@InProceedings{Hansen2016,
  author    = {Hansen, Raymond A. and Peterson, Benjamin and Becker, Timothy},
  booktitle = {Proceedings of the 5th Annual Conference on Research in Information Technology},
  title     = {Investigating the Security of Nexus 1000V Virtual Switches in VMware ESXi Hypervisors},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {47–52},
  publisher = {Association for Computing Machinery},
  series    = {RIIT '16},
  abstract  = {In this paper, the security posture of two versions of the Cisco Nexus 1000V virtual
switch is tested against a set of exploits known to be valid on physical switching
infrastructure. Specifically, the Nexus 1000V as implemented with VMware's ESXi hypervisor
is examined. The attempted exploits are CAM table overflows, VLAN hopping, Spanning
Tree manipulation, ARP poisoning, and Private VLAN attacks. With the exception of
Spanning Tree manipulation, the Nexus 1000V is vulnerable to all of the attacks in
at least one of the tested release combinations. This leads to a call for additional
security considerations when deploying the Nexus 1000V/ESXi combination in data centers
and cloud provider networks as intended by their design.},
  doi       = {10.1145/2978178.2978188},
  isbn      = {9781450344531},
  keywords  = {virtualization, network security, network function virtualization, layer 2 security},
  location  = {Boston, Massachusetts, USA},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2978178.2978188},
}

@InProceedings{Gan2019,
  author    = {Gan, Tian and Ma, Zhixin and Lu, Yuxiao and Song, Xuemeng and Nie, Liqiang},
  booktitle = {Proceedings of the ACM Multimedia Asia},
  title     = {Learn to Gesture: Let Your Body Speak},
  year      = {2019},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {MMAsia '19},
  abstract  = {Presentation is one of the most important and vivid methods to deliver information
to audience. Apart from the content of presentation, how the speaker behaves during
presentation makes a big difference. In other words, gestures, as part of the visual
perception and synchronized with verbal information, express some subtle information
that the voice or words alone cannot deliver. One of the most effective ways to improve
presentation is to practice through feedback/suggestions by an expert. However, hiring
human experts is expensive thus impractical most of the time. Towards this end, we
propose a speech to gesture network (POSE) to generate exemplary body language given
a vocal behavior speech as input. Specifically, we build an "expert" Speech-Gesture
database based on the featured TED talk videos, and design a two-layer attentive recurrent
encoder-decoder network to learn the translation from speech to gesture, as well as
the hierarchical structure within gestures. Lastly, given a speech audio sequence,
the appropriate gesture will be generated and visualized for a more effective communication.
Both objective and subjective validation show the effectiveness of our proposed method.},
  articleno = {33},
  doi       = {10.1145/3338533.3366602},
  isbn      = {9781450368414},
  location  = {Beijing, China},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3338533.3366602},
}

@InProceedings{Wang2015,
  author    = {Wang, Jun and Qian, Zhiyun and Li, Zhichun and Wu, Zhenyu and Rhee, Junghwan and Ning, Xia and Liu, Peng and Jiang, Guofei},
  booktitle = {Proceedings of the 10th ACM Symposium on Information, Computer and Communications Security},
  title     = {Discover and Tame Long-Running Idling Processes in Enterprise Systems},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {543–554},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '15},
  abstract  = {Reducing attack surface is an effective preventive measure to strengthen security
in large systems. However, it is challenging to apply this idea in an enterprise environment
where systems are complex and evolving over time. In this paper, we empirically analyze
and measure a real enterprise to identify unused services that expose attack surface.
Interestingly, such unused services are known to exist and summarized by security
best practices, yet such solutions require significant manual effort.We propose an
automated approach to accurately detect the idling (most likely unused) services that
are in either blocked or bookkeeping states. The idea is to identify repeating events
with perfect time alignment, which is the indication of being idling. We implement
this idea by developing a novel statistical algorithm based on autocorrelation with
time information incorporated. From our measurement results, we find that 88.5% of
the detected idling services can be constrained with a simple syscall-based policy,
which confines the process behaviors within its bookkeeping states. In addition, working
with two IT departments (one of which is a cross validation), we receive positive
feedbacks which show that about 30.6% of such services can be safely disabled or uninstalled
directly. In the future, the IT department plan to incorporate the results to build
a "smaller" OS installation image. Finally, we believe our measurement results raise
the awareness of the potential security risks of idling services.},
  doi       = {10.1145/2714576.2714613},
  isbn      = {9781450332453},
  keywords  = {attack surface reduction, autocorrelation, enterprise systems, idling service detection},
  location  = {Singapore, Republic of Singapore},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2714576.2714613},
}

@InProceedings{Tan2011,
  author    = {Tan, Hailun and Hu, Wen and Jha, Sanjay},
  booktitle = {Proceedings of the 6th ACM Workshop on Performance Monitoring and Measurement of Heterogeneous Wireless and Wired Networks},
  title     = {A TPM-Enabled Remote Attestation Protocol (TRAP) in Wireless Sensor Networks},
  year      = {2011},
  address   = {New York, NY, USA},
  pages     = {9–16},
  publisher = {Association for Computing Machinery},
  series    = {PM2HW2N '11},
  abstract  = {Given the limited resources and computational power of current embedded sensor devices,
memory protection is difficult to achieve and generally unavailable. Hence, the software
run-time buffer overflow that is used by the worm attacks in the Internet could be
easily exploited to inject malicious codes into Wireless Sensor Networks (WSNs). Previous
software-based remote code verification approaches such as SWATT and SCUBA have been
shown difficult to deploy in recent work. In this paper, we propose and implement
a remote attestation protocol for detecting unauthorized tampering in the application
codes running on sensor nodes with the assistance of Trusted Platform Modules (TPMs),
the tiny, cost-effective and tamper-proof cryptographic microcontrollers. In our design,
each sensor node is equipped with a TPM and the firmware running on the node could
be verified by the other sensor nodes in a WSN, including the sink. Specifically,
we present a hardware-based remote attestation protocol, discuss the potential attacks
an adversary could launch against the protocol, and provide comprehensive system performance
results of the protocol in a multi-hop sensor network testbed.},
  doi       = {10.1145/2069087.2069090},
  isbn      = {9781450309028},
  keywords  = {wireless sensor networks, trusted platform module, remote attestation},
  location  = {Miami, Florida, USA},
  numpages  = {8},
  url       = {https://doi.org/10.1145/2069087.2069090},
}

@InBook{Chen2021a,
  author    = {Chen, Yuxin and Yang, Zhuolin and Abbou, Ruben and Lopes, Pedro and Zhao, Ben Y. and Zheng, Haitao},
  publisher = {Association for Computing Machinery},
  title     = {User Authentication via Electrical Muscle Stimulation},
  year      = {2021},
  address   = {New York, NY, USA},
  isbn      = {9781450380966},
  abstract  = {We propose a novel modality for active biometric authentication: electrical muscle
stimulation (EMS). To explore this, we engineered an interactive system, which we
call ElectricAuth, that stimulates the user’s forearm muscles with a sequence of electrical
impulses (i.e., EMS challenge) and measures the user’s involuntary finger movements
(i.e., response to the challenge). ElectricAuth leverages EMS’s intersubject variability,
where the same electrical stimulation results in different movements in different
users because everybody’s physiology is unique (e.g., differences in bone and muscular
structure, skin resistance and composition, etc.). As such, ElectricAuth allows users
to login without memorizing passwords or PINs. ElectricAuth’s challenge-response structure
makes it secure against data breaches and replay attacks, a major vulnerability facing
today’s biometrics such as facial recognition and fingerprints. Furthermore, ElectricAuth
never reuses the same challenge twice in authentications – in just one second of stimulation
it encodes one of 68M possible challenges. In our user studies, we found that ElectricAuth
resists: (1) impersonation attacks (false acceptance rate: 0.17% at 5% false rejection
rate); (2) replay attacks (false acceptance rate: 0.00% at 5% false rejection rate);
and, (3) synthesis attacks (false acceptance rates: 0.2-2.5%). Our longitudinal study
also shows that ElectricAuth produces consistent results over time and across different
humidity and muscle conditions.},
  articleno = {6},
  booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3411764.3445441},
}

@InProceedings{Hofmann2013,
  author    = {Hofmann, Owen S. and Kim, Sangman and Dunn, Alan M. and Lee, Michael Z. and Witchel, Emmett},
  booktitle = {Proceedings of the Eighteenth International Conference on Architectural Support for Programming Languages and Operating Systems},
  title     = {InkTag: Secure Applications on an Untrusted Operating System},
  year      = {2013},
  address   = {New York, NY, USA},
  pages     = {265–278},
  publisher = {Association for Computing Machinery},
  series    = {ASPLOS '13},
  abstract  = {InkTag is a virtualization-based architecture that gives strong safety guarantees
to high-assurance processes even in the presence of a malicious operating system.
InkTag advances the state of the art in untrusted operating systems in both the design
of its hypervisor and in the ability to run useful applications without trusting the
operating system. We introduce paraverification, a technique that simplifies the InkTag
hypervisor by forcing the untrusted operating system to participate in its own verification.
Attribute-based access control allows trusted applications to create decentralized
access control policies. InkTag is also the first system of its kind to ensure consistency
between secure data and metadata, ensuring recoverability in the face of system crashes.},
  doi       = {10.1145/2451116.2451146},
  isbn      = {9781450318709},
  keywords  = {paraverification, virtualization-based security, application protection},
  location  = {Houston, Texas, USA},
  numpages  = {14},
  url       = {https://doi.org/10.1145/2451116.2451146},
}

@Article{Hofmann2013a,
  author     = {Hofmann, Owen S. and Kim, Sangman and Dunn, Alan M. and Lee, Michael Z. and Witchel, Emmett},
  journal    = {SIGPLAN Not.},
  title      = {InkTag: Secure Applications on an Untrusted Operating System},
  year       = {2013},
  issn       = {0362-1340},
  month      = mar,
  number     = {4},
  pages      = {265–278},
  volume     = {48},
  abstract   = {InkTag is a virtualization-based architecture that gives strong safety guarantees
to high-assurance processes even in the presence of a malicious operating system.
InkTag advances the state of the art in untrusted operating systems in both the design
of its hypervisor and in the ability to run useful applications without trusting the
operating system. We introduce paraverification, a technique that simplifies the InkTag
hypervisor by forcing the untrusted operating system to participate in its own verification.
Attribute-based access control allows trusted applications to create decentralized
access control policies. InkTag is also the first system of its kind to ensure consistency
between secure data and metadata, ensuring recoverability in the face of system crashes.},
  address    = {New York, NY, USA},
  doi        = {10.1145/2499368.2451146},
  issue_date = {April 2013},
  keywords   = {application protection, virtualization-based security, paraverification},
  numpages   = {14},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2499368.2451146},
}

@Article{Hofmann2013b,
  author     = {Hofmann, Owen S. and Kim, Sangman and Dunn, Alan M. and Lee, Michael Z. and Witchel, Emmett},
  journal    = {SIGARCH Comput. Archit. News},
  title      = {InkTag: Secure Applications on an Untrusted Operating System},
  year       = {2013},
  issn       = {0163-5964},
  month      = mar,
  number     = {1},
  pages      = {265–278},
  volume     = {41},
  abstract   = {InkTag is a virtualization-based architecture that gives strong safety guarantees
to high-assurance processes even in the presence of a malicious operating system.
InkTag advances the state of the art in untrusted operating systems in both the design
of its hypervisor and in the ability to run useful applications without trusting the
operating system. We introduce paraverification, a technique that simplifies the InkTag
hypervisor by forcing the untrusted operating system to participate in its own verification.
Attribute-based access control allows trusted applications to create decentralized
access control policies. InkTag is also the first system of its kind to ensure consistency
between secure data and metadata, ensuring recoverability in the face of system crashes.},
  address    = {New York, NY, USA},
  doi        = {10.1145/2490301.2451146},
  issue_date = {March 2013},
  keywords   = {virtualization-based security, application protection, paraverification},
  numpages   = {14},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2490301.2451146},
}

@InProceedings{Scofield2017,
  author    = {Scofield, Daniel and Miles, Craig and Kuhn, Stephen},
  booktitle = {Proceedings of the 7th Software Security, Protection, and Reverse Engineering / Software Security and Protection Workshop},
  title     = {Fast Model Learning for the Detection of Malicious Digital Documents},
  year      = {2017},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {SSPREW-7},
  abstract  = {Modern cyber attacks are often conducted by distributing digital documents that contain
malware. The approach detailed herein, which consists of a classifier that uses features
derived from dynamic analysis of a document viewer as it renders the document in question,
is capable of classifying the disposition of digital documents with greater than 98%
accuracy even when its model is trained on just small amounts of data. To keep the
classification model itself small and thereby to provide scalability, we employ an
entity resolution strategy that merges syntactically disparate features that are thought
to be semantically equivalent but vary due to programmatic randomness. Entity resolution
enables construction of a comprehensive model of benign functionality using relatively
few training documents, and the model does not improve significantly with additional
training data.},
  articleno = {3},
  doi       = {10.1145/3151137.3151142},
  isbn      = {9781450353878},
  keywords  = {malware detection, anomaly detection, dynamic analysis},
  location  = {Orlando, FL, USA},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3151137.3151142},
}

@InProceedings{Zhao2015,
  author    = {Zhao, Xiaohan and Liu, Qingyun and Zheng, Haitao and Zhao, Ben Y.},
  booktitle = {Proceedings of the 2015 ACM on Conference on Online Social Networks},
  title     = {Towards Graph Watermarks},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {101–112},
  publisher = {Association for Computing Machinery},
  series    = {COSN '15},
  abstract  = {From network topologies to online social networks, many of today's most sensitive
datasets are captured in large graphs. A significant challenge facing the data owners
is how to share sensitive graphs with collaborators or authorized users, e.g. ISP's
network topology graphs with a third party networking equipment vendor. Current tools
can provide limited node or edge privacy, but significantly modify the graph reducing
its utility.In this work, we propose a new alternative in the form of graph watermarks.
Graph watermarks are small graphs tailor-made for a given graph dataset, a secure
graph key, and a secure user key. To share a sensitive graph G with a collaborator
C, the owner generates a watermark graph W using G, the graph key, and C's key as
input, and embeds W into G to form G'. If G' is leaked by C, its owner can reliably
determine if the watermark W generated for C does in fact reside inside G', thereby
proving C is responsible for the leak. Graph watermarks serve both as a deterrent
against data leakage and a method of recourse after a leak. We provide robust schemes
for embedding and extracting watermarks, and use analysis and experiments on large
real graphs to show that they are unique and difficult to forge. We study the robustness
of graph watermarks against both single and powerful colluding attacker models, then
propose and evaluate mechanisms to dramatically improve resilience.},
  doi       = {10.1145/2817946.2817956},
  isbn      = {9781450339513},
  keywords  = {graph, watermark},
  location  = {Palo Alto, California, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2817946.2817956},
}

@InProceedings{Benyo2018,
  author    = {Benyo, Brett and Clark, Shane and Paulos, Aaron and Pal, Partha},
  booktitle = {Proceedings of the 13th International Conference on Availability, Reliability and Security},
  title     = {HYDRA: Hypothesis Driven Repair Automation},
  year      = {2018},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ARES 2018},
  abstract  = {HYDRA is an automated mechanism to repair code in response to successful attacks.
Given a set of malicious inputs that include the attack and a set of benign inputs
that do not, along with an ability to test the victim application with these labelled
inputs, HYDRA quickly provides rank ordered patches to close the exploited vulnerability.
HYDRA also produces human-readable summaries of its findings and repair actions to
aid the manual vulnerability mitigation process. We tested HYDRA using 8 zero-days,
HYDRA produced patches that stopped the attacks in all 8 cases and preserved application
functionality in 7 of the 8 cases.},
  articleno = {8},
  doi       = {10.1145/3230833.3230861},
  isbn      = {9781450364485},
  keywords  = {resiliency, Automated software repair, zero-day vulnerability},
  location  = {Hamburg, Germany},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3230833.3230861},
}

@InProceedings{Yan2020,
  author    = {Yan, Wenqing and Hylamia, Sam and Voigt, Thiemo and Rohner, Christian},
  booktitle = {Proceedings of the 6th ACM Workshop on Wearable Systems and Applications},
  title     = {PHY-IDS: A Physical-Layer Spoofing Attack Detection System for Wearable Devices},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {1–6},
  publisher = {Association for Computing Machinery},
  series    = {WearSys '20},
  abstract  = {In modern connected healthcare applications, wearable devices supporting real-time
monitoring and diagnosis have become mainstream. However, wearable systems are exposed
to massive cyberattacks that threaten not only data security but also human safety
and life. One of the fundamental security threats is device impersonation. We therefore
propose PHY-IDS; a lightweight real-time detection system that captures spoofing attacks
leveraging on body motions. Our system utilizes time series of physical layer features
and builds on the fact that it is non-trivial to inject malicious frames that are
indistinguishable with legitimate ones. With the help of statistical learning, our
system characterizes the signal behavior and flags deviations as anomalies. We experimentally
evaluate PHY-IDS's performance using bodyworn devices in real attack scenarios. For
four types of attackers with increasing knowledge of the deployed detection system,
the results show that PHY-IDS detects naive attackers with high accuracy above 99.8%
and maintains good accuracy for stronger attackers at a range from 81.0% to 98.9%.},
  doi       = {10.1145/3396870.3400010},
  isbn      = {9781450380133},
  keywords  = {wearables, time series analysis, spoofing attacks, physical-layer security, machine learning},
  location  = {Toronto, Ontario, Canada},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3396870.3400010},
}

@InProceedings{Madani2020,
  author    = {Madani, Pooria and Vlajic, Natalija and Sadeghpour, Shadi},
  booktitle = {Proceedings of the 2020 Joint Workshop on CPS&amp;IoT Security and Privacy},
  title     = {MAC-Layer Spoofing Detection and Prevention in IoT Systems: Randomized Moving Target Approach},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {71–80},
  publisher = {Association for Computing Machinery},
  series    = {CPSIOTSEC'20},
  abstract  = {MAC-layer spoofing, also known as identity spoofing, is recognized as a serious problem
in many practical wireless systems. IoT systems are particularly vulnerable to this
type of attack, as IoT devices (due to their various limitations) are often incapable
of deploying advanced MAC-layer spoofing prevention and detection techniques - such
as cryptographic authentication. Signal-level device fingerprinting is an approach
to identity spoofing detection that is highly suitable for sensor-based IoT networks,
but can be also utilized in many other types of wireless system. Unfortunately, the
previous research works on signal-level device fingerprinting have been based on rather
simplistic assumptions about both - the adversary's behavior as well as the operation
of the defense system. The goal of our work was to examine the effectiveness of a
novel system that combines signal-level device fingerprinting with the principles
of Randomized Moving Target Defense (RMTD) when dealing with a very advanced adversary.
The obtained results show that our RMTD-enhanced signal-level device fingerprinting
technique exhibits far superior defense performance over the non-RMTD techniques previously
discussed in the literature, and as such could be of great value for practical wireless
systems subjected to identity spoofing attacks.},
  doi       = {10.1145/3411498.3419968},
  isbn      = {9781450380874},
  keywords  = {moving target defense, adversarial learning, spoofing, optimal evasion},
  location  = {Virtual Event, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3411498.3419968},
}

@InProceedings{Nandi2013,
  author    = {Nandi, Animesh and Aghasaryan, Armen and Chhabra, Ishan},
  booktitle = {Proceedings of the 12th ACM Workshop on Workshop on Privacy in the Electronic Society},
  title     = {On the Use of Decentralization to Enable Privacy in Web-Scale Recommendation Services},
  year      = {2013},
  address   = {New York, NY, USA},
  pages     = {25–36},
  publisher = {Association for Computing Machinery},
  series    = {WPES '13},
  abstract  = {We present the design, implementation, and evaluation of a decentralized framework
for enabling privacy in Web-scale recommendation services. Our framework, which comprises
of a decentralized middleware that is hosted and run by federated entities, is designed
to support collaborative-filtering and content-based recommendations.We design a novel
distributed protocol that clusters users into interest groups comprised of like-minded
members and ensures a desired minimum size (k-anonymity parameter), while keeping
user profiles on client-side only. In order to aggregate users' consumption for the
purpose of generating recommendations, we design a novel decentralized aggregation
mechanism that protects against auxiliary information attacks that have crippled conventional
k-anonymity based systems.Our prototype system ensures that the desired k-anonymity
level is met, and can prevent auxiliary information attacks using a middleware of
modest size, and is empirically shown to be resistant to moderate degree of collusion.
While preserving privacy, our system enables effective clustering of like-minded users,
and offers good quality of recommendations. Also, the prototype's decentralized design
and lightweight protocols enable almost linear-scaling with increased size of the
middleware.},
  doi       = {10.1145/2517840.2517860},
  isbn      = {9781450324854},
  keywords  = {privacy-preserving collaborative-filtering, k-anonymity, tor, auxiliary information attacks},
  location  = {Berlin, Germany},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2517840.2517860},
}

@InProceedings{Herzberg2014,
  author    = {Herzberg, Amir and Shulman, Haya and Crispo, Bruno},
  booktitle = {Proceedings of the 30th Annual Computer Security Applications Conference},
  title     = {Less is More: Cipher-Suite Negotiation for DNSSEC},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {346–355},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '14},
  abstract  = {We propose a transport layer cipher-suite negotiation mechanism for DNSSEC standard,
allowing name-servers to send responses containing only the keys and signatures that
correspond to the cipher-suite option negotiated with the resolver, rather than sending
all the signatures and keys (as is done currently).As we show, a lack of cipher-suite
negotiation, is one of the factors impeding deployment of DNSSEC, and also results
in adoption of weak ciphers. Indeed, the vast majority of domains rely on RSA 1024-bit
cryptography, which is already considered insecure. Furthermore, domains, that want
better security, have to support a number of cryptographic ciphers. As a result, the
DNSSEC responses are large and often fragmented, harming the DNS functionality, and
causing inefficiency and vulnerabilities.A cipher-suite negotiation mechanism reduces
responses' sizes, and hence solves the interoperability problems with DNSSEC-signed
responses, and prevents reflection and cache poisoning attacks.},
  doi       = {10.1145/2664243.2664283},
  isbn      = {9781450330053},
  keywords  = {DNSSEC, cipher suite negotiation, DNS interoperability, DNS security},
  location  = {New Orleans, Louisiana, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2664243.2664283},
}

@InProceedings{Wang2015a,
  author    = {Wang, Liang and Tasoulis, Sotiris and Roos, Teemu and Kangasharju, Jussi},
  booktitle = {Proceedings of the 24th International Conference on World Wide Web},
  title     = {Kvasir: Seamless Integration of Latent Semantic Analysis-Based Content Provision into Web Browsing},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {251–254},
  publisher = {Association for Computing Machinery},
  series    = {WWW '15 Companion},
  abstract  = {The Internet is overloading its users with excessive information flows, so that effective
content-based filtering becomes crucial in improving user experience and work efficiency.
We build Kvasir, a semantic recommendation system, atop latent semantic analysis and
other state-of-art technologies to seamlessly integrate an automated and proactive
content provision service into web browsing. We utilize the power of Apache Spark
to scale up Kvasir to a practical Internet service. Herein we present the architecture
of Kvasir, along with our solutions to the technical challenges in the actual system
implementation.},
  doi       = {10.1145/2740908.2742825},
  isbn      = {9781450334730},
  keywords  = {big data, web browsing, random projection, information retrieval, content-based filter, latent semantic analysis},
  location  = {Florence, Italy},
  numpages  = {4},
  url       = {https://doi.org/10.1145/2740908.2742825},
}

@Article{Zheng2016,
  author     = {Zheng, Nan and Paloski, Aaron and Wang, Haining},
  journal    = {ACM Trans. Inf. Syst. Secur.},
  title      = {An Efficient User Verification System Using Angle-Based Mouse Movement Biometrics},
  year       = {2016},
  issn       = {1094-9224},
  month      = apr,
  number     = {3},
  volume     = {18},
  abstract   = {Biometric authentication verifies a user based on its inherent, unique characteristics—who
you are. In addition to physiological biometrics, behavioral biometrics has proven
very useful in authenticating a user. Mouse dynamics, with their unique patterns of
mouse movements, is one such behavioral biometric. In this article, we present a user
verification system using mouse dynamics, which is transparent to users and can be
naturally applied for continuous reauthentication. The key feature of our system lies
in using much more fine-grained (point-by-point) angle-based metrics of mouse movements
for user verification. These new metrics are relatively unique from person to person
and independent of a computing platform. Moreover, we utilize support vector machines
(SVMs) for quick and accurate classification. Our technique is robust across different
operating platforms, and no specialized hardware is required. The efficacy of our
approach is validated through a series of experiments, which are based on three sets
of user mouse movement data collected in controllable environments and in the field.
Our experimental results show that the proposed system can verify a user in an accurate
and timely manner, with minor induced system overhead.},
  address    = {New York, NY, USA},
  articleno  = {11},
  doi        = {10.1145/2893185},
  issue_date = {April 2016},
  keywords   = {mouse dynamics, angle-based metrics, User verification},
  numpages   = {27},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2893185},
}

@InProceedings{Haider2017,
  author    = {Haider, Syed Kamran and Omar, Hamza and Lebedev, Ilia and Devadas, Srinivas and van Dijk, Marten},
  booktitle = {Proceedings of the 22nd ACM on Symposium on Access Control Models and Technologies},
  title     = {Leveraging Hardware Isolation for Process Level Access Control &amp; Authentication},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {133–141},
  publisher = {Association for Computing Machinery},
  series    = {SACMAT '17 Abstracts},
  abstract  = {Critical resource sharing among multiple entities in a processing system is inevitable,
which in turn calls for the presence of appropriate authentication and access control
mechanisms. Generally speaking, these mechanisms are implemented via trusted software
"policy checkers" that enforce certain high level application-specific "rules" to
enforce a policy. Whether implemented as operating system modules or embedded inside
the application ad hoc, these policy checkers expose additional attack surface in
addition to the application logic. In order to protect application software from an
adversary, modern secure processing platforms, such as Intel's Software Guard Extensions
(SGX), employ principled hardware isolation to offer secure software containers or
enclaves to execute trusted sensitive code with some integrity and privacy guarantees
against a privileged software adversary. We extend this model further and propose
using these hardware isolation mechanisms to shield the authentication and access
control logic essential to policy checker software. While relying on the fundamental
features of modern secure processors, our framework introduces productive software
design guidelines which enable a guarded environment to execute sensitive policy checking
code - hence enforcing application control flow integrity - and afford flexibility
to the application designer to construct appropriate high-level policies to customize
policy checker software.},
  doi       = {10.1145/3078861.3078882},
  isbn      = {9781450347020},
  keywords  = {secure processors, program authentication, hardware isolation},
  location  = {Indianapolis, Indiana, USA},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3078861.3078882},
}

@InProceedings{Shirvanian2017,
  author    = {Shirvanian, Maliheh and Saxena, Nitesh},
  booktitle = {Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {CCCP: Closed Caption Crypto Phones to Resist MITM Attacks, Human Errors and Click-Through},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {1329–1342},
  publisher = {Association for Computing Machinery},
  series    = {CCS '17},
  abstract  = {Crypto Phones aim to establish end-to-end secure voice (and text) communications based
on human-centric (usually) short checksum validation. They require end users to perform:
(1) checksum comparison to detect traditional data-based man-in-the-middle (data MITM)
attacks, and, optionally, (2) speaker verification to detect sophisticated voice-based
man-in-the-middle (voice MITM) attacks. However, research shows that both tasks are
prone to human errors making Crypto Phones highly vulnerable to MITM attacks, especially
to data MITM given the prominence of these attacks. Further, human errors under benign
settings undermine usability since legitimate calls would often need to be rejected.We
introduce Closed Captioning Crypto Phones (CCCP), that remove the human user from
the loop of checksum comparison by utilizing speech transcription. CCCP simply requires
the user to announce the checksum to the other party--the system automatically transcribes
the spoken checksum and performs the comparison. Automating checksum comparisons offers
many key advantages over traditional designs: (1) the chances of data MITM due to
human errors and "click-through" could be highly reduced (even eliminated); (2) longer
checksums can be utilized, which increases the protocol security against data MITM;
(3) users' cognitive burden is reduced due to the need to perform only a single task,
thereby lowering the potential of human errors.As a main component of CCCP, we first
design and implement an automated checksum comparison tool based on standard Speech
to Text engines. To evaluate the security and usability benefits of CCCP, we then
design and conduct an online user study that mimics a realistic VoIP scenario, and
collect and transcribe a comprehensive data set spoken by a wide variety of speakers
in real-life conditions. Our study results demonstrate that, by using our automated
checksum comparison, CCCP can completely resist data MITM, while significantly reducing
human errors in the benign case compared to the traditional approach. They also show
that CCCP may help reduce the likelihood of voice MITM. Finally, we discuss how CCCP
can be improved by designing specialized transcribers and carefully selected checksum
dictionaries, and how it can be integrated with existing Crypto Phones to bolster
their security and usability.},
  doi       = {10.1145/3133956.3134013},
  isbn      = {9781450349468},
  keywords  = {mobile app security, end-to-end encryption, sas validation, voip security, key exchange validation},
  location  = {Dallas, Texas, USA},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3133956.3134013},
}

@Article{Hu2020,
  author     = {Hu, Zhisheng and Zhu, Minghui and Liu, Peng},
  journal    = {ACM Trans. Priv. Secur.},
  title      = {Adaptive Cyber Defense Against Multi-Stage Attacks Using Learning-Based POMDP},
  year       = {2020},
  issn       = {2471-2566},
  month      = nov,
  number     = {1},
  volume     = {24},
  abstract   = {Growing multi-stage attacks in computer networks impose significant security risks
and necessitate the development of effective defense schemes that are able to autonomously
respond to intrusions during vulnerability windows. However, the defender faces several
real-world challenges, e.g., unknown likelihoods and unknown impacts of successful
exploits. In this article, we leverage reinforcement learning to develop an innovative
adaptive cyber defense to maximize the cost-effectiveness subject to the aforementioned
challenges. In particular, we use Bayesian attack graphs to model the interactions
between the attacker and networks. Then we formulate the defense problem of interest
as a partially observable Markov decision process problem where the defender maintains
belief states to estimate system states, leverages Thompson sampling to estimate transition
probabilities, and utilizes reinforcement learning to choose optimal defense actions
using measured utility values. The algorithm performance is verified via numerical
simulations based on real-world attacks.},
  address    = {New York, NY, USA},
  articleno  = {6},
  doi        = {10.1145/3418897},
  issue_date = {January 2021},
  keywords   = {adaptive cyber defense, Thompson sampling, Reinforcement learning},
  numpages   = {25},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3418897},
}

@InProceedings{Tomic2018,
  author    = {Tomi\'{c}, Ivana and Chen, Po-Yu and Breza, Michael J. and McCann, Julie A.},
  booktitle = {Proceedings of the 15th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services},
  title     = {Antilizer: Run Time Self-Healing Security for Wireless Sensor Networks},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {107–116},
  publisher = {Association for Computing Machinery},
  series    = {MobiQuitous '18},
  abstract  = {Wireless Sensor Network (WSN) applications range from domestic Internet of Things
systems like temperature monitoring of homes to the monitoring and control of large-scale
critical infrastructures. The greatest risk with the use of WSNs in critical infrastructure
is their vulnerability to malicious network level attacks. Their radio communication
network can be disrupted, causing them to lose or delay data which will compromise
system functionality. This paper presents Antilizer, a lightweight, fully-distributed
solution to enable WSNs to detect and recover from common network level attack scenarios.
In Antilizer each sensor node builds a self-referenced trust model of its neighbourhood
using network overhearing. The node uses the trust model to autonomously adapt its
communication decisions. In the case of a network attack, a node can make neighbour
collaboration routing decisions to avoid affected regions of the network. Mobile agents
further bound the damage caused by attacks. These agents enable a simple notification
scheme which propagates collaborative decisions from the nodes to the base station.
A filtering mechanism at the base station further validates the authenticity of the
information shared by mobile agents. We evaluate Antilizer in simulation against several
routing attacks. Our results show that Antilizer reduces data loss down to 1% (4%
on average), with operational overheads of less than 1% and provides fast network-wide
convergence.},
  doi       = {10.1145/3286978.3287029},
  isbn      = {9781450360937},
  keywords  = {Trust, Security, Wireless Sensor Networks, Self-Healing},
  location  = {New York, NY, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3286978.3287029},
}

@InProceedings{Pellegrino2017,
  author    = {Pellegrino, Giancarlo and Johns, Martin and Koch, Simon and Backes, Michael and Rossow, Christian},
  booktitle = {Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {Deemon: Detecting CSRF with Dynamic Analysis and Property Graphs},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {1757–1771},
  publisher = {Association for Computing Machinery},
  series    = {CCS '17},
  abstract  = {Cross-Site Request Forgery (CSRF) vulnerabilities are a severe class of web vulnerabilities
that have received only marginal attention from the research and security testing
communities. While much effort has been spent on countermeasures and detection of
XSS and SQLi, to date, the detection of CSRF vulnerabilities is still performed predominantly
manually.In this paper, we present Deemon, to the best of our knowledge the first
automated security testing framework to discover CSRF vulnerabilities. Our approach
is based on a new modeling paradigm which captures multiple aspects of web applications,
including execution traces, data flows, and architecture tiers in a unified, comprehensive
property graph. We present the paradigm and show how a concrete model can be built
automatically using dynamic traces.Then, using graph traversals, we mine for potentially
vulnerable operations. Using the information captured in the model, our approach then
automatically creates and conducts security tests, to practically validate the found
CSRF issues. We evaluate the effectiveness of Deemon with 10 popular open source web
applications. Our experiments uncovered 14 previously unknown CSRF vulnerabilities
that can be exploited, for instance, to take over user accounts or entire websites.},
  doi       = {10.1145/3133956.3133959},
  isbn      = {9781450349468},
  keywords  = {property graphs, vulnerability analysis, web security, cross-site request forgery, csrf, dynamic analysis},
  location  = {Dallas, Texas, USA},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3133956.3133959},
}

@InProceedings{Kim2020,
  author    = {Kim, Minji and Kim, Junhoe and Park, Gwanmo and Seo, Jinwook},
  booktitle = {Proceedings of the 25th International Conference on Intelligent User Interfaces},
  title     = {PolySquare: A Search Engine for 3D Models with Tag Propagation},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {324–334},
  publisher = {Association for Computing Machinery},
  series    = {IUI '20},
  abstract  = {Searching for desired 3D models is not easy because many of them are not well labeled;
annotations often contain inconsistent information (e.g., uploaders' personal way
of naming) and lack important details (e.g., detailed ornaments and pattern) of each
model. We introduce PolySquare, a search engine for 3D models based on tag propagation---the
process of assigning existing tags to other similar but unlabeled models considering
important local properties. For instance, a tag `wheel' of a wheelchair can be spread
out to other objects with wheels. Furthermore, PolySquare allows people to interactively
refine the search results by iteratively including desired shapes and excluding unwanted
ones. We evaluate the performance of tag propagation by measuring the precision-recall
of propagation results with various similarity thresholds and demonstrate the effectiveness
of the use of local features. We also showcase how PolySquare handles the unrefined
tags through a case study using real 3D model data from Google Poly.},
  doi       = {10.1145/3377325.3377484},
  isbn      = {9781450371186},
  keywords  = {neural networks, 3D model search, 3D text annotation, 3D tagging, 3D data retrieval},
  location  = {Cagliari, Italy},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3377325.3377484},
}

@Article{Scofield2020,
  author     = {Scofield, Daniel and Miles, Craig and Kuhn, Stephen},
  journal    = {Digital Threats: Research and Practice},
  title      = {Automated Model Learning for Accurate Detection of Malicious Digital Documents},
  year       = {2020},
  issn       = {2692-1626},
  month      = aug,
  number     = {3},
  volume     = {1},
  abstract   = {Modern cyber attacks are often conducted by distributing digital documents that contain
malware. The approach detailed herein, which consists of a classifier that uses features
derived from dynamic analysis of a document viewer as it renders the document in question,
is capable of classifying the disposition of digital documents with greater than 98%
accuracy even when its model is trained on just small amounts of data. To keep the
classification model itself small and thereby to provide scalability, we employ an
entity resolution strategy that merges syntactically disparate features that are thought
to be semantically equivalent but vary due to programmatic randomness. Entity resolution
enables construction of a comprehensive model of benign functionality using relatively
few training documents, and the model does not improve significantly with additional
training data. In particular, we describe and quantitatively evaluate a fully automated,
document format--agnostic approach for learning a classification model that provides
efficacious malicious document detection.},
  address    = {New York, NY, USA},
  articleno  = {15},
  doi        = {10.1145/3379505},
  issue_date = {September 2020},
  keywords   = {anomaly detection, dynamic analysis, Malware detection},
  numpages   = {21},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3379505},
}

@InProceedings{Tuveri2018,
  author    = {Tuveri, Nicola and Hassan, Sohaib ul and Garcia, Cesar Pereida and Brumley, Billy Bob},
  booktitle = {Proceedings of the 34th Annual Computer Security Applications Conference},
  title     = {Side-Channel Analysis of SM2: A Late-Stage Featurization Case Study},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {147–160},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '18},
  abstract  = {SM2 is a public key cryptography suite originating from Chinese standards, including
digital signatures and public key encryption. Ahead of schedule, code for this functionality
was recently mainlined in OpenSSL, marked for the upcoming 1.1.1 release. We perform
a security review of this implementation, uncovering various deficiencies ranging
from traditional software quality issues to side-channel risks. To assess the latter,
we carry out a side-channel security evaluation and discover that the implementation
hits every pitfall seen for OpenSSL's ECDSA code in the past decade. We carry out
remote timings, cache timings, and EM analysis, with accompanying empirical data to
demonstrate secret information leakage during execution of both digital signature
generation and public key decryption. Finally, we propose, implement, and empirically
evaluate countermeasures.},
  doi       = {10.1145/3274694.3274725},
  isbn      = {9781450365697},
  keywords  = {SM2, public key cryptography, OpenSSL, software engineering, side-channel analysis, applied cryptography, TVLA, timing attacks, power analysis, cache-timing attacks},
  location  = {San Juan, PR, USA},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3274694.3274725},
}

@InProceedings{Serwadda2013,
  author    = {Serwadda, Abdul and Phoha, Vir V.},
  booktitle = {Proceedings of the 2013 ACM SIGSAC Conference on Computer &amp; Communications Security},
  title     = {When Kids' Toys Breach Mobile Phone Security},
  year      = {2013},
  address   = {New York, NY, USA},
  pages     = {599–610},
  publisher = {Association for Computing Machinery},
  series    = {CCS '13},
  abstract  = {Touch-based verification --- the use of touch gestures (e.g., swiping, zooming, etc.)
to authenticate users of touch screen devices --- has recently been widely evaluated
for its potential to serve as a second layer of defense to the PIN lock mechanism.
In all performance evaluations of touch-based authentication systems however, researchers
have assumed naive (zero-effort) forgeries in which the attacker makes no effort to
mimic a given gesture pattern.In this paper we demonstrate that a simple "Lego" robot
driven by input gleaned from general population swiping statistics can generate forgeries
that achieve alarmingly high penetration rates against touch-based authentication
systems. Using the best classification algorithms in touch-based authentication, we
rigorously explore the effect of the attack, finding that it increases the Equal Error
Rates of the classifiers by between 339% and 1004% depending on parameters such as
the failure-to-enroll threshold and the type of touch stroke generated by the robot.
The paper calls into question the zero-effort impostor testing approach used to benchmark
the performance of touch-based authentication systems.},
  doi       = {10.1145/2508859.2516659},
  isbn      = {9781450324779},
  keywords  = {attack, robot, authentication, touch gestures, biometrics},
  location  = {Berlin, Germany},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2508859.2516659},
}

@Article{Jajodia2018,
  author     = {Jajodia, Sushil and Park, Noseong and Serra, Edoardo and Subrahmanian, V. S.},
  journal    = {ACM Trans. Internet Technol.},
  title      = {SHARE: A Stackelberg Honey-Based Adversarial Reasoning Engine},
  year       = {2018},
  issn       = {1533-5399},
  month      = mar,
  number     = {3},
  volume     = {18},
  abstract   = {A “noisy-rich” (NR) cyber-attacker (Lippmann et al. 2012) is one who tries all available
vulnerabilities until he or she successfully compromises the targeted network. We
develop an adversarial foundation, based on Stackelberg games, for how NR-attackers
will explore an enterprise network and how they will attack it, based on the concept
of a system vulnerability dependency graph. We develop a mechanism by which the network
can be modified by the defender to induce deception by placing honey nodes and apparent
vulnerabilities into the network to minimize the expected impact of the NR-attacker’s
attacks (according to multiple measures of impact). We also consider the case where
the adversary learns from blocked attacks using reinforcement learning. We run detailed
experiments with real network data (but with simulated attack data) and show that
Stackelberg Honey-based Adversarial Reasoning Engine performs very well, even when
the adversary deviates from the initial assumptions made about his or her behavior.
We also develop a method for the attacker to use reinforcement learning when his or
her activities are stopped by the defender. We propose two stopping policies for the
defender: Stop Upon Detection allows the attacker to learn about the defender’s strategy
and (according to our experiments) leads to significant damage in the long run, whereas
Stop After Delay allows the defender to introduce greater uncertainty into the attacker,
leading to better defendability in the long run.},
  address    = {New York, NY, USA},
  articleno  = {30},
  doi        = {10.1145/3137571},
  issue_date = {May 2017},
  keywords   = {Enterprise systems, computer security, adversarial models},
  numpages   = {41},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3137571},
}

@Article{Gu2021,
  author     = {Gu, Renjie and Niu, Chaoyue and Wu, Fan and Chen, Guihai and Hu, Chun and Lyu, Chengfei and Wu, Zhihua},
  journal    = {ACM Comput. Surv.},
  title      = {From Server-Based to Client-Based Machine Learning: A Comprehensive Survey},
  year       = {2021},
  issn       = {0360-0300},
  month      = jan,
  number     = {1},
  volume     = {54},
  abstract   = {In recent years, mobile devices have gained increasing development with stronger computation
capability and larger storage space. Some of the computation-intensive machine learning
tasks can now be run on mobile devices. To exploit the resources available on mobile
devices and preserve personal privacy, the concept of client-based machine learning
has been proposed. It leverages the users’ local hardware and local data to solve
machine learning sub-problems on mobile devices and only uploads computation results
rather than the original data for the optimization of the global model. Such an architecture
can not only relieve computation and storage burdens on servers but also protect the
users’ sensitive information. Another benefit is the bandwidth reduction because various
kinds of local data can be involved in the training process without being uploaded.
In this article, we provide a literature review on the progressive development of
machine learning from server based to client based. We revisit a number of widely
used server-based and client-based machine learning methods and applications. We also
extensively discuss the challenges and future directions in this area. We believe
that this survey will give a clear overview of client-based machine learning and provide
guidelines on applying client-based machine learning to practice.},
  address    = {New York, NY, USA},
  articleno  = {6},
  doi        = {10.1145/3424660},
  issue_date = {April 2021},
  keywords   = {machine learning, federated learning, distributed system, Mobile intelligence, decentralized training},
  numpages   = {36},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3424660},
}

@InProceedings{Herzberg2014a,
  author    = {Herzberg, Amir and Shulman, Haya},
  booktitle = {Proceedings of the 30th Annual Computer Security Applications Conference},
  title     = {DNS Authentication as a Service: Preventing Amplification Attacks},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {356–365},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '14},
  abstract  = {We present the first defence against DNS-amplification DoS attacks, which is compatible
with the common DNS servers configurations and with the (important standard) DNSSEC.
We show that the proposed DNS-authentication system is efficient, and effectively
prevents DNS-based amplification DoS attacks abusing DNS name servers. We present
a game-theoretic model and analysis, predicting a wide-spread adoption of our design,
sufficient to reduce the threat of DNS amplification DoS attacks. To further reduce
costs and provide additional defences for DNS servers, we show how to deploy our design
as a cloud based service.},
  doi       = {10.1145/2664243.2664281},
  isbn      = {9781450330053},
  keywords  = {DNS authentication, DNS reflection, denial of service attacks, source authentication, DNS amplification},
  location  = {New Orleans, Louisiana, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2664243.2664281},
}

@InProceedings{Tambe2019,
  author    = {Tambe, Amit and Aung, Yan Lin and Sridharan, Ragav and Ochoa, Mart\'{\i}n and Tippenhauer, Nils Ole and Shabtai, Asaf and Elovici, Yuval},
  booktitle = {Proceedings of the Ninth ACM Conference on Data and Application Security and Privacy},
  title     = {Detection of Threats to IoT Devices Using Scalable VPN-Forwarded Honeypots},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {85–96},
  publisher = {Association for Computing Machinery},
  series    = {CODASPY '19},
  abstract  = {Attacks on Internet of Things (IoT) devices, exploiting inherent vulnerabilities,
have intensified over the last few years. Recent large-scale attacks, such as Persirai,
Hakai, etc. corroborate concerns about the security of IoT devices. In this work,
we propose an approach that allows easy integration of commercial off-the-shelf IoT
devices into a general honeypot architecture. Our approach projects a small number
of heterogeneous IoT devices (that are physically at one location) as many (geographically
distributed) devices on the Internet, using connections to commercial and private
VPN services. The goal is for those devices to be discovered and exploited by attacks
on the Internet, thereby revealing unknown vulnerabilities. For detection and examination
of potentially malicious traffic, we devise two analysis strategies: (1) given an
outbound connection from honeypot, backtrack into network traffic to detect the corresponding
attack command that caused the malicious connection and use it to download malware,
(2) perform live detection of unseen URLs from HTTP requests using adaptive clustering.
We show that our implementation and analysis strategies are able to detect recent
large-scale attacks targeting IoT devices (IoT Reaper, Hakai, etc.) with overall low
cost and maintenance effort.},
  doi       = {10.1145/3292006.3300024},
  isbn      = {9781450360999},
  keywords  = {adaptive clustering, high-interaction iot honeypot, attack attribution, intrusion detection, network traffic analysis},
  location  = {Richardson, Texas, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3292006.3300024},
}

@InProceedings{Sun2015,
  author    = {Sun, Mingshen and Li, Mengmeng and Lui, John C. S.},
  booktitle = {Proceedings of the 8th ACM Conference on Security &amp; Privacy in Wireless and Mobile Networks},
  title     = {DroidEagle: Seamless Detection of Visually Similar Android Apps},
  year      = {2015},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {WiSec '15},
  abstract  = {Repackaged malware and phishing malware consist 86% [35] of all Android malware, and
they significantly affect the Android ecosystem. Previous work use disassembled Dalvik
bytecode and hashing approaches to detect repackaged malware, but these approaches
are vulnerable to obfuscation attacks and they demand large computational resources
on mobile devices. In this work, we propose a novel methodology which uses the layout
resources within an app to detect apps which are "visually similar", a common characteristic
in repackaged apps and phishing malware. To detect visually similar apps, we design
and implement DroidEagle which consists of two sub-systems: RepoEagle and HostEagle.
RepoEagle is to perform large scale detection on apps repositories (e.g., apps markets),
and HostEagle is a lightweight mobile app which can help users to quickly detect visually
similar Android app upon download. We demonstrate the high accuracy and efficiency
of DroidEagle: Within 3 hours RepoEagle can detect 1298 visually similar apps from
99 626 apps in a repository. In less than one second, HostEagle can help an Android
user to determine whether a downloaded mobile app is a repackaged apps or a phishing
malware. This is the first work which provides both speed and scalability in discovering
repackaged apps and phishing malware in Android system.},
  articleno = {9},
  doi       = {10.1145/2766498.2766508},
  isbn      = {9781450336239},
  location  = {New York, New York},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2766498.2766508},
}

@InProceedings{Kuehrer2015,
  author    = {K\"{u}hrer, Marc and Hupperich, Thomas and Bushart, Jonas and Rossow, Christian and Holz, Thorsten},
  booktitle = {Proceedings of the 2015 Internet Measurement Conference},
  title     = {Going Wild: Large-Scale Classification of Open DNS Resolvers},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {355–368},
  publisher = {Association for Computing Machinery},
  series    = {IMC '15},
  abstract  = {Since several years, millions of recursive DNS resolvers are-deliberately or not-open
to the public. This, however, is counter-intuitive, since the operation of such openly
accessible DNS resolvers is necessary in rare cases only. Furthermore, open resolvers
enable both amplification DDoS and cache snooping attacks, and can be abused by attackers
in multiple other ways. We thus find open recursive DNS resolvers to remain one critical
phenomenon on the Internet.In this paper, we illuminate this phenomenon by analyzing
it from two different angles. On the one hand, we study the landscape of DNS resolvers
based on empirical data we collected for over a year. We analyze the changes over
time and classify the resolvers according to device type and software version. On
the other hand, we take the viewpoint of a client and measure the response authenticity
of these resolvers. Besides legitimate redirections (e.g., to captive portals or router
login pages), we find millions of resolvers to deliberately manipulate DNS resolutions
(i.e., return bogus IP address information). To understand this threat in more detail,
we systematically analyze non-legitimate DNS responses and reveal open DNS resolvers
that manipulate DNS resolutions to censor communication channels, inject advertisements,
serve malicious files, perform phishing, or redirect to other kinds of suspicious
or malicious activities.},
  doi       = {10.1145/2815675.2815683},
  isbn      = {9781450338486},
  keywords  = {dns resolution paths, domain name system, content delivery network, agglomerative hierarchical clustering},
  location  = {Tokyo, Japan},
  numpages  = {14},
  url       = {https://doi.org/10.1145/2815675.2815683},
}

@InProceedings{Haghighat2018,
  author    = {Haghighat, Mohammad Hashem and Li, Jun},
  booktitle = {Proceedings of the 8th International Conference on Communication and Network Security},
  title     = {Edmund: Entropy Based Attack Detection and Mitigation Engine Using Netflow Data},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {1–6},
  publisher = {Association for Computing Machinery},
  series    = {ICCNS 2018},
  abstract  = {Dozens of signature and anomaly based solutions have been proposed to detect malicious
activities in computer networks. However, the number of successful attacks are increasing
every day. In this paper, we developed a novel entropy based technique, called Edmund,
to detect and mitigate Network attacks. While analyzing full payload network traffic
was not recommended due to users' privacy, Edmund used netflow data to detect abnormal
behavior.The experimental results showed that Edmund was able to highly accurate detect
(around 95%) different application, transport, and network layers attacks. It could
identify more than 100K malicious flows raised by 1168 different attackers in our
campus. Identifying the attackers, is a great feature, which enables the network administrators
to mitigate DDoS effects during the attack time.},
  doi       = {10.1145/3290480.3290484},
  isbn      = {9781450365673},
  keywords  = {Network Attacks, Malicious Flows, Entropy, Attack Detection and Mitigation},
  location  = {Qingdao, China},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3290480.3290484},
}

@Article{Lukasiewycz2016,
  author     = {Lukasiewycz, Martin and Mundhenk, Philipp and Steinhorst, Sebastian},
  journal    = {ACM Trans. Des. Autom. Electron. Syst.},
  title      = {Security-Aware Obfuscated Priority Assignment for Automotive CAN Platforms},
  year       = {2016},
  issn       = {1084-4309},
  month      = jan,
  number     = {2},
  volume     = {21},
  abstract   = {Security in automotive in-vehicle networks is an increasing problem with the growing
connectedness of road vehicles. This article proposes a security-aware priority assignment
for automotive controller area network (CAN) platforms with the aim of mitigating
scaling effects of attacks on vehicle fleets. CAN is the dominating field bus in the
automotive domain due to its simplicity, low cost, and robustness. While messages
might be encrypted to enhance the security of CAN systems, their priorities are usually
identical for automotive platforms, comprising generally a large number of vehicle
models. As a result, the identifier uniquely defines which message is sent, allowing
attacks to scale across a fleet of vehicles with the same platform. As a remedy, we
propose a methodology that is capable of determining obfuscated message identifiers
for each individual vehicle. Since identifiers directly represent message priorities,
the approach has to take the resulting response time variations into account while
satisfying application deadlines for each vehicle schedule separately. Our approach
relies on Quadratically Constrained Quadratic Program (QCQP) solving in two stages,
specifying first a set of feasible fixed priorities and subsequently bounded priorities
for each message. With the obtained bounds, obfuscated identifiers are determined,
using a very fast randomized sampling. The experimental results, consisting of a large
set of synthetic test cases and a realistic case study, give evidence of the efficiency
of the proposed approach in terms of scalability. The results also show that the diversity
of obtained identifiers is effectively optimized with our approach, resulting in a
very good obfuscation of CAN messages in in-vehicle communication.},
  address    = {New York, NY, USA},
  articleno  = {32},
  doi        = {10.1145/2831232},
  issue_date = {January 2016},
  keywords   = {priority assignment, automotive, security, CAN},
  numpages   = {27},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2831232},
}

@InProceedings{Shakya2015,
  author    = {Shakya, Shobhit and Zhang, Jian},
  booktitle = {Proceedings of the 2015 ACM International Workshop on International Workshop on Security and Privacy Analytics},
  title     = {Towards Better Semi-Supervised Classification of Malicious Software},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {27–33},
  publisher = {Association for Computing Machinery},
  series    = {IWSPA '15},
  abstract  = {Due to the large number of malicious software (malware) and the large variety among
them, automated detection and analysis using machine learning techniques have become
more and moreimportant for network and computer security.An often encountered scenario
in these security applications is that training examples are scarce but unlabeled
data are abundant. Semi-supervised learning where both labeled and unlabeled data
are used to learn a good model quickly is a natural choice under such condition.We
investigate semi-supervised classification for malware categorization.We observed
that malware data have specific characteristics and that they are noisy. Off-the-shelf
semi-supervised learning may not work well in this case. We proposed a semi supervised
approach that addresses the problems with malware data and can provide better classification.
We conducted a set of experiments to test and compare our method to others. The experimental
results show that semi-supervised classification is a promising direction for malware
classification. Our method achieved more than 90% accuracy when there were only a
few number of training examples. The results also indicates that modifications are
needed to make semi-supervised learning work with malware data. Otherwise, semi-supervised
classification may perform worse than classifiers trained on only the labeled data.},
  doi       = {10.1145/2713579.2713587},
  isbn      = {9781450333412},
  keywords  = {malware classification, graph spectral, machine learning, graph-based semi-supervised learning},
  location  = {San Antonio, Texas, USA},
  numpages  = {7},
  url       = {https://doi.org/10.1145/2713579.2713587},
}

@InProceedings{Foruhandeh2019,
  author    = {Foruhandeh, Mahsa and Man, Yanmao and Gerdes, Ryan and Li, Ming and Chantem, Thidapat},
  booktitle = {Proceedings of the 35th Annual Computer Security Applications Conference},
  title     = {SIMPLE: Single-Frame Based Physical Layer Identification for Intrusion Detection and Prevention on in-Vehicle Networks},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {229–244},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '19},
  abstract  = {The Controller Area Network (CAN) is a bus standard commonly used in the automotive
industry for connecting Electronic Control Units (ECUs) within a vehicle. The broadcast
nature of this protocol, along with the lack of authentication or strong integrity
guarantees for frames, allows for arbitrary data injection/modification and impersonation
of the ECUs. While mitigation strategies have been proposed to counter these attacks,
high implementation costs or violation of backward compatibility hinder their deployment.
In this work, we first examine the shortcomings of state-of-the-art CAN intrusion
detection and identification systems that rely on multiple frames to detect misbehavior
and attribute it to a particular ECU, and show that they are vulnerable to a Hill-Climbing-style
attack. Then we propose SIMPLE, a real-time intrusion detection and identification
system that exploits physical layer features of ECUs, which would not only allow an
attack to be detected using a single frame but also be effectively nullified. SIMPLE
has low computational and data acquisition costs, and its efficacy is demonstrated
by both in-lab experiments with automotive-grade CAN transceivers as well as in-vehicle
experiments, where average equal error rates of close to 0% and 0.8985% are achieved,
respectively.},
  doi       = {10.1145/3359789.3359834},
  isbn      = {9781450376280},
  keywords  = {electronic control units, physical layer identification, controller area networks, hill-climbing attacks},
  location  = {San Juan, Puerto Rico, USA},
  numpages  = {16},
  url       = {https://doi.org/10.1145/3359789.3359834},
}

@InProceedings{Whelan2020,
  author    = {Whelan, Jason and Sangarapillai, Thanigajan and Minawi, Omar and Almehmadi, Abdulaziz and El-Khatib, Khalil},
  booktitle = {Proceedings of the 16th ACM Symposium on QoS and Security for Wireless and Mobile Networks},
  title     = {Novelty-Based Intrusion Detection of Sensor Attacks on Unmanned Aerial Vehicles},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {23–28},
  publisher = {Association for Computing Machinery},
  series    = {Q2SWinet '20},
  abstract  = {Unmanned Aerial Vehicles (UAVs) have proven to be a useful technology in numerous
industries including industrial control systems surveillance, law enforcement, and
military operations. Due to their heavy reliance on wireless protocols and hostile
operating environments, UAVs face a large threat landscape. As attacks against UAVs
increase, an intelligent intrusion detection system (IDS) is needed to aid the UAV
in identifying attacks. The UAV domain presents unique challenges for intelligent
IDS development, such as the variety of sensors, communication protocols, UAV platforms,
control configurations, and dataset availability. In this paper, we propose a novelty-based
approach to intrusion detection in UAVs by using one-class classifiers. One-class
classifiers require only non-anomalous data to exist in the training set. This allows
for the use of flight logs as training data, which are created by most UAVs during
flight by default. Principal Component Analysis is applied to sensor logs for dimensionality
reduction, and one-class classifier models are generated per sensor. A number of one-class
classifiers are selected: One-Class Support Vector Machine, Autoencoder Neural Network,
and Local Outlier Factor. The pre-processing, feature selection, training, and tuning
of the selected algorithms is discussed. GPS spoofing is used throughout the paper
as a common example of an external sensor-based attack. This approach shows to be
effective across multiple UAV platforms with platform-specific F1 scores up to 99.56%
and 99.73% for benign and malicious sensor readings respectively.},
  doi       = {10.1145/3416013.3426446},
  isbn      = {9781450381208},
  keywords  = {cyber-physical systems, novelty detection, intrusion detection, robotic vehicles, machine learning, unmanned aerial vehicles},
  location  = {Alicante, Spain},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3416013.3426446},
}

@InProceedings{Abt2014,
  author    = {Abt, Sebastian and Baier, Harald},
  booktitle = {Proceedings of the 2014 Workshop on Artificial Intelligent and Security Workshop},
  title     = {A Plea for Utilising Synthetic Data When Performing Machine Learning Based Cyber-Security Experiments},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {37–45},
  publisher = {Association for Computing Machinery},
  series    = {AISec '14},
  abstract  = {Cyber-security research is a challenging venture where researchers especially face
the problem of not having broad access to labelled real-world data sets. This unavailability
of data challenges performing scientific sound experiments. Especially, for machine
learning based systems this unavailability effectively hinders us to assess performance,
attributes and limitations of such systems. One approach to address this lack of publicly
available data is to perform experiments using synthetic data. However, we experience
that synthetic data is seldom used in our community. This position paper gives a plea
for utilising synthetic data when performing machine learning based cyber-security
experiments. For this, we collect major challenges our community faces today and discuss
how synthetic data can help solving them. Furthermore, we discuss open questions in
the area of data synthesis and propose directions for future work.},
  doi       = {10.1145/2666652.2666663},
  isbn      = {9781450331531},
  keywords  = {data synthesis, machine learning, cyber-security research, ground-truth},
  location  = {Scottsdale, Arizona, USA},
  numpages  = {9},
  url       = {https://doi.org/10.1145/2666652.2666663},
}

@Article{Laszka2018,
  author     = {Laszka, Aron and Johnson, Benjamin and Grossklags, Jens},
  journal    = {ACM Trans. Internet Technol.},
  title      = {On the Assessment of Systematic Risk in Networked Systems},
  year       = {2018},
  issn       = {1533-5399},
  month      = aug,
  number     = {4},
  volume     = {18},
  abstract   = {In a networked system, the risk of security compromises depends not only on each node’s
security but also on the topological structure formed by the connected individuals,
businesses, and computer systems. Research in network security has been exploring
this phenomenon for a long time, with a variety of modeling frameworks predicting
how many nodes we should expect to lose, on average, for a given network topology,
after certain types of incidents. Meanwhile, the pricing of insurance contracts for
risks related to information technology (better known as cyber-insurance) requires
determining additional information, for example, the maximum number of nodes we should
expect to lose within a 99.5% confidence interval. Previous modeling research in network
security has not addressed these types of questions, while research on cyber-insurance
pricing for networked systems has not taken into account the network’s topology. Our
goal is to bridge that gap, by providing a mathematical basis for the assessment of
systematic risk in networked systems.We define a loss-number distribution to be a
probability distribution on the total number of compromised nodes within a network
following the occurrence of a given incident, and we provide a number of modeling
results that aim to be useful for cyber-insurers in this context. We prove NP-hardness
for the general case of computing the loss-number distribution for an arbitrary network
topology but obtain simplified computable formulas for the special cases of star topologies,
ER-random topologies, and uniform topologies. We also provide a simulation algorithm
that approximates the loss-number distribution for an arbitrary network topology and
that appears to converge efficiently for many common classes of topologies.Scale-free
network topologies have a degree distribution that follows a power law and are commonly
found in real-world networks. We provide an example of a scale-free network in which
a cyber-insurance pricing mechanism that relies naively on incidence reporting data
will fail to accurately predict the true risk level of the entire system. We offer
an alternative mechanism that yields an accurate forecast by taking into account the
network topology, thus highlighting the lack/importance of topological data in security
incident reporting. Our results constitute important steps toward the understanding
of systematic risk and help to contribute to the emergence of a viable cyber-insurance
market.},
  address    = {New York, NY, USA},
  articleno  = {48},
  doi        = {10.1145/3166069},
  issue_date = {November 2018},
  keywords   = {risk mitigation, scale-free networks, Networks, cyber-insurance, topology, security, economics of security},
  numpages   = {28},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3166069},
}

@InProceedings{Kalysch2018,
  author    = {Kalysch, Anatoli and Milisterfer, Oskar and Protsenko, Mykolai and M\"{u}ller, Tilo},
  booktitle = {Proceedings of the 13th International Conference on Availability, Reliability and Security},
  title     = {Tackling Androids Native Library Malware with Robust, Efficient and Accurate Similarity Measures},
  year      = {2018},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ARES 2018},
  abstract  = {Code similarity measures create a comparison metric showing to what degree two code
samples have the same functionality, e.g., to statically detect the use of known libraries
in binary code. They are both an indispensable part of automated malware analysis,
as well as a helper for the detection of plagiarism (IP protection) and the illegal
use of open-source libraries in commercial apps. The centroid similarity metric extracts
control-flow features from binary code and encodes them as geometric structures before
comparing them. In our paper, we propose novel improvements to the centroid approach
and apply it to the ARM architecture for the first time. We implement our approach
as a plug-in for the IDA Pro disassembler and evaluate it regarding efficiency, accuracy
and robustness on Android. Based on a dataset of 508,745 APKs, collected from 18 third-party
app markets, we achieve a detection rate of 89% for the use of native code libraries,
with an FPR of 10.8%. To test the robustness of our approach against the compiler
version, optimization level, and other code transformations, we obfuscate and recompile
known open-source libraries to evaluate which code transformations are resisted. Based
on our results, we discuss how code re-use can be hidden by obfuscation and conclude
with possible improvements.},
  articleno = {58},
  doi       = {10.1145/3230833.3232828},
  isbn      = {9781450364485},
  keywords  = {Android Static Analysis, Reverse Engineering, Code Similarity},
  location  = {Hamburg, Germany},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3230833.3232828},
}

@InProceedings{Shaghaghi2017,
  author    = {Shaghaghi, Arash and Kaafar, Mohamed Ali and Jha, Sanjay},
  booktitle = {Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security},
  title     = {WedgeTail: An Intrusion Prevention System for the Data Plane of Software Defined Networks},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {849–861},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '17},
  abstract  = {Networks are vulnerable to disruptions caused by malicious forwarding devices. The
situation is likely to worsen in Software Defined Networks (SDNs) with the incompatibility
of existing solutions, use of programmable soft switches and the potential of bringing
down an entire network through compromised forwarding devices. In this paper, we present
WedgeTail, an Intrusion Prevention System (IPS) designed to secure the SDN data plane.
WedgeTail regards forwarding devices as points within a geometric space and stores
the path packets take when traversing the network as trajectories. To be efficient,
it prioritizes forwarding devices before inspection using an unsupervised trajectory-based
sampling mechanism. For each of the forwarding device, WedgeTail computes the expected
and actual trajectories of packets and 'hunts' for any forwarding device not processing
packets as expected. Compared to related work, WedgeTail is also capable of distinguishing
between malicious actions such as packet drop and generation. Moreover, WedgeTail
employs a radically different methodology that enables detecting threats autonomously.
In fact, it has no reliance on pre-defined rules by an administrator and may be easily
imported to protect SDN networks with different setups, forwarding devices, and controllers.
We have evaluated WedgeTail in simulated environments, and it has been capable of
detecting and responding to all implanted malicious forwarding devices within a reasonable
time-frame. We report on the design, implementation, and evaluation of WedgeTail in
this manuscript.},
  doi       = {10.1145/3052973.3053039},
  isbn      = {9781450349444},
  keywords  = {SDN security, data plane security, intrusion prevention system, software defined networks},
  location  = {Abu Dhabi, United Arab Emirates},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3052973.3053039},
}

@InProceedings{Orenbach2020,
  author    = {Orenbach, Meni and Baumann, Andrew and Silberstein, Mark},
  booktitle = {Proceedings of the Fifteenth European Conference on Computer Systems},
  title     = {Autarky: Closing Controlled Channels with Self-Paging Enclaves},
  year      = {2020},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {EuroSys '20},
  abstract  = {As the first widely-deployed secure enclave hardware, Intel SGX shows promise as a
practical basis for confidential cloud computing. However, side channels remain SGX's
greatest security weakness. Inparticular, the "controlled-channel attack" on enclave
page faults exploits a longstanding architectural side channel and still lacks effective
mitigation.We propose Autarky: a set of minor, backward-compatible modifications to
the SGX ISA that hide an enclave's page access trace from the host, and give the enclave
full control over its page faults. A trusted library OS implements an enclave self-paging
policy.We prototype Autarky on current SGX hardware and the Graphene library OS, implementing
three paging schemes: a fast software oblivious RAM system made practical by leveraging
the proposed ISA, a novel page cluster abstraction for application-aware secure self-paging,
and a rate-limiting paging mechanism for unmodified binaries. Overall, Autarky provides
a comprehensive defense for controlled-channel attacks which supports efficient secure
demand paging, and adds no overheads in page-fault free execution.},
  articleno = {7},
  doi       = {10.1145/3342195.3387541},
  isbn      = {9781450368827},
  location  = {Heraklion, Greece},
  numpages  = {16},
  url       = {https://doi.org/10.1145/3342195.3387541},
}

@InProceedings{Chowdhary2017,
  author    = {Chowdhary, Ankur and Pisharody, Sandeep and Alshamrani, Adel and Huang, Dijiang},
  booktitle = {Proceedings of the ACM International Workshop on Security in Software Defined Networks &amp; Network Function Virtualization},
  title     = {Dynamic Game Based Security Framework in SDN-Enabled Cloud Networking Environments},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {53–58},
  publisher = {Association for Computing Machinery},
  series    = {SDN-NFVSec '17},
  abstract  = {SDN provides a way to manage complex networks by introducing programmability and abstraction
of the control plane. All networks suffer from attacks to critical infrastructure
and services such as DDoS attacks. We make use of the programmability provided by
the SDN environment to provide a game theoretic attack analysis and countermeasure
selection model in this research work. The model is based on reward and punishment
in a dynamic game with multiple players. The network bandwidth of attackers is downgraded
for a certain period of time, and restored to normal when the player resumes cooperation.
The presented solution is based on Nash Folk Theorem, which is used to implement a
punishment mechanism for attackers who are part of DDoS traffic, and reward for players
who cooperate, in effect enforcing desired outcome for the network administrator.},
  doi       = {10.1145/3040992.3040998},
  isbn      = {9781450349086},
  keywords  = {cloud systems, moving target defense (MTD), game theory, distributed denial of service (DDoS), software defined networking (SDN)},
  location  = {Scottsdale, Arizona, USA},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3040992.3040998},
}

@Article{Sepulveda2021,
  author     = {Sep\'{u}lveda, Johanna and Gross, Mathieu and Zankl, Andreas and Sigl, Georg},
  journal    = {ACM Trans. Embed. Comput. Syst.},
  title      = {Beyond Cache Attacks: Exploiting the Bus-Based Communication Structure for Powerful On-Chip Microarchitectural Attacks},
  year       = {2021},
  issn       = {1539-9087},
  month      = mar,
  number     = {2},
  volume     = {20},
  abstract   = {System-on-Chips (SoCs) are a key enabling technology for the Internet-of-Things (IoT),
a hyper-connected world where on- and inter-chip communication is ubiquitous. SoCs
usually integrate cryptographic hardware cores for confidentiality and authentication
services. However, these components are prone to implementation attacks. During the
operation of a cryptographic core, the secret key may passively be inferred through
cache observations. Access-driven attacks exploiting these observations are therefore
a vital threat to SoCs operating in IoT environments. Previous works have shown the
feasibility of these attacks in the SoC context. Yet, the SoC communication structure
can be used to further improve access-based cache attacks. The communication attacks
are not as well-understood as other micro-architectural attacks. It is important to
raise the awareness of SoC designers of such a threat. To this end, we present four
contributions. First, we demonstrate an improved Prime+Probe attack on four different
AES-128 implementations (original transformation tables, T0-Only, T2KB, and S-Box).
As a novelty, this attack exploits the collisions of the bus-based SoC communication
to further increase its efficiency. Second, we explore the impact of preloading on
the efficiency of our communication-optimized attack. Third, we integrate three countermeasures
(shuffling, mini-tables, and Time-Division Multiple Access (TDMA) bus arbitration)
and evaluate their impact on the attack. Although shuffling and mini-tables countermeasures
were proposed in previous work, their application as countermeasures against the bus-based
attack was not studied before. In addition, TDMA as a countermeasure for bus-based
attacks is an original contribution of this work. Fourth, we further discuss the implications
of our work in the SoC design and its perspective with the new cryptographic primitives
proposed in the ongoing National Institute of Standard and Technology Lightweight
Cryptography competition. The results show that our improved communication-optimized
attack is efficient, speeding up full key recovery by up to 400 times when compared
to the traditional Prime+Probe technique. Moreover, the protection techniques are
feasible and effectively mitigate the proposed improved attack.},
  address    = {New York, NY, USA},
  articleno  = {17},
  doi        = {10.1145/3433653},
  issue_date = {March 2021},
  keywords   = {microarchitecture, bus, side-channel, cache attacks, communication, MPSoC},
  numpages   = {23},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3433653},
}

@InProceedings{Anand2021,
  author    = {Anand, S. Abhishek and Liu, Jian and Wang, Chen and Shirvanian, Maliheh and Saxena, Nitesh and Chen, Yingying},
  booktitle = {Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security},
  title     = {EchoVib: Exploring Voice Authentication via Unique Non-Linear Vibrations of Short Replayed Speech},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {67–81},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '21},
  abstract  = {Recent advances in speaker verification and speech processing technology have seen
voice authentication being adopted on a wide scale in commercial applications like
online banking and customer care support and on devices such as smartphones and IoT
voice assistant systems. However, it has been shown that the current voice authentication
systems can be ineffective against voice synthesis attacks that mimic a user's voice
to high precision. In this work, we suggest a paradigm shift from the traditional
voice authentication systems operating in the audio domain but susceptible to speech
synthesis attacks (in the same audio domain). We leverage a motion sensor's capability
to pick up phonatory vibrations, that can help to uniquely identify a user via voice
signatures in the vibration domain. The user's speech is played/echoed back by a device's
speaker for a short duration (hence our method is termed EchoVib) and the resulting
non-linear phonatory vibrations are picked up by the motion sensor for speaker recognition.
The uniqueness of the device's speaker and its accelerometer results in a device-specific
fingerprint in response to the echoed speech. The use of the vibration domain and
its non-linear relationship with audio allows EchoVib to resist the state-of-the-art
voice synthesis attacks, shown to be successful in the audio domain.We develop an
instance of EchoVib using the onboard loudspeaker and the accelerometer embedded in
smartphones, as the authenticator, based on machine learning techniques. Our evaluation
shows that even with the low-quality loudspeaker and the low-sampling rate of accelerometer
recordings, EchoVib can identify users with an accuracy of over 90%. We also analyze
our system against state-of-art-voice synthesis attacks and show that it can distinguish
between the morphed and the original speaker's voice samples, correctly rejecting
the morphed samples with a success rate of 85% for voice conversion and voice modeling
attacks. We believe that using the vibration domain to detect synthesized speech attacks
is effective due to the hardness of preserving the unique phonatory vibration signatures
and is difficult to mimic due to the non-linear mapping of the unique speaker and
accelerometer response in the vibration domain to the voice in the audio domain.},
  doi       = {10.1145/3433210.3437518},
  isbn      = {9781450382878},
  keywords  = {voice echo fingerprint, vibration domain, voice imitation resistance},
  location  = {Virtual Event, Hong Kong},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3433210.3437518},
}

@InProceedings{Durak2016,
  author    = {Durak, F. Bet\"{u}l and DuBuisson, Thomas M. and Cash, David},
  booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {What Else is Revealed by Order-Revealing Encryption?},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {1155–1166},
  publisher = {Association for Computing Machinery},
  series    = {CCS '16},
  abstract  = {The security of order-revealing encryption (ORE) has been unclear since its invention.
Dataset characteristics for which ORE is especially insecure have been identified,
such as small message spaces and low-entropy distributions. On the other hand, properties
like one-wayness on uniformly-distributed datasets have been proved for ORE constructions.This
work shows that more plaintext information can be extracted from ORE ciphertexts than
was previously thought. We identify two issues: First, we show that when multiple
columns of correlated data are encrypted with ORE, attacks can use the encrypted columns
together to reveal more information than prior attacks could extract from the columns
individually. Second, we apply known attacks, and develop new attacks, to show that
the leakage of concrete ORE schemes on non-uniform data leads to more accurate plaintext
recovery than is suggested by the security theorems which only dealt with uniform
inputs.},
  doi       = {10.1145/2976749.2978379},
  isbn      = {9781450341394},
  keywords  = {inference attacks, order-revealing encryption, database encryption},
  location  = {Vienna, Austria},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2976749.2978379},
}

@Article{Tripathi2021,
  author     = {Tripathi, Nikhil and Hubballi, Neminath},
  journal    = {ACM Comput. Surv.},
  title      = {Application Layer Denial-of-Service Attacks and Defense Mechanisms: A Survey},
  year       = {2021},
  issn       = {0360-0300},
  month      = may,
  number     = {4},
  volume     = {54},
  abstract   = {Application layer Denial-of-Service (DoS) attacks are generated by exploiting vulnerabilities
of the protocol implementation or its design. Unlike volumetric DoS attacks, these
are stealthy in nature and target a specific application running on the victim. There
are several attacks discovered against popular application layer protocols in recent
years. In this article, we provide a structured and comprehensive survey of the existing
application layer DoS attacks and defense mechanisms. We classify existing attacks
and defense mechanisms into different categories, describe their working, and compare
them based on relevant parameters. We conclude the article with directions for future
research.},
  address    = {New York, NY, USA},
  articleno  = {86},
  doi        = {10.1145/3448291},
  issue_date = {July 2021},
  keywords   = {distributed DoS attacks, defense mechanisms, Protocol-specific and generic DoS attacks},
  numpages   = {33},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3448291},
}

@InProceedings{Shepherd2017,
  author    = {Shepherd, Carlton and Akram, Raja Naeem and Markantonakis, Konstantinos},
  booktitle = {Proceedings of the Symposium on Applied Computing},
  title     = {Towards Trusted Execution of Multi-Modal Continuous Authentication Schemes},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {1444–1451},
  publisher = {Association for Computing Machinery},
  series    = {SAC '17},
  abstract  = {The emergence of powerful, sensor-rich devices has led to the development of continuous
authentication (CA) schemes using off-the-shelf hardware, where user behaviour is
compared to past experience to produce an authentication decision with the aim of
addressing challenges with traditional authentication schemes. Current CA proposals,
however, have largely neglected adversaries present in a real-world deployment, namely
the ubiquity of mal ware and software attacks. This has particular importance when
a device cannot be trusted by a third-party, such as a corporation, that controls
access to assets based on that decision. A software compromise, either on the scheme
implementation or platform, may enable an adversary to modify authentication scores
to alter the status of the device in reality, give insights into user behaviour, or
gain unauthorised access to restricted assets. Hence, for the first time, we examine
two standardised constructs that offer isolated and trusted execution - Secure Elements
(SEs) and Trusted Execution Environments (TEEs) - even when an adversary has root-level
privileges, and propose measures for providing trusted CA while retaining deployability.
Based on these, we implement the first system for evaluating TEE-based CA on a consumer
mobile device using Intel SGX, thus providing confidentiality, integrity and trust
while removing the main platform from the TCB. We present an empirical evaluation
of TEE-and non-TEE performance using methods proposed in related CA schemes. Our results
indicate that trusted CA can be provided with no significant performance penalty,
and may even offer performance benefits.},
  doi       = {10.1145/3019612.3019652},
  isbn      = {9781450344869},
  keywords  = {continuous authentication, trusted execution environments, mobile security, trusted computing},
  location  = {Marrakech, Morocco},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3019612.3019652},
}

@InProceedings{Keren2021,
  author    = {Keren, Osnat and Polian, Ilia},
  booktitle = {Proceedings of the 18th ACM International Conference on Computing Frontiers},
  title     = {On Resilience of Security-Oriented Error Detecting Architectures against Power Attacks: A Theoretical Analysis},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {229–237},
  publisher = {Association for Computing Machinery},
  series    = {CF '21},
  abstract  = {It has been previously shown that hardware implementation of fault attack countermeasures
based on error-detecting codes (EDCs) can make the circuit more vulnerable to power
analysis attacks. We revisit this finding and show that the hypothesis space can grow
significantly when a state-of-the-art security-oriented robust EDC is properly crafted.
We use the Roth-Karp decomposition as an analytical tool to prove that by a simple
re-ordering of the EDC's bits, the number of extra bits needed to formulate the hypotheses
becomes so large that power analysis (that tries to exploit additional information
from the redundant bits) is rendered infeasible.},
  doi       = {10.1145/3457388.3458867},
  isbn      = {9781450384049},
  keywords  = {side-channel analysis, error-detecting codes, fault attacks, information leakage, physical attacks},
  location  = {Virtual Event, Italy},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3457388.3458867},
}

@InProceedings{Yuchen2019,
  author    = {Yuchen, Song and Dejin, Tang and Xiaoming, Zhou and Yuanchen, Song},
  booktitle = {Proceedings of the 2019 2nd International Conference on Algorithms, Computing and Artificial Intelligence},
  title     = {Research on Remote Sensing Image Data Attack Method Based on Machine Deep Learning Network},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {439–443},
  publisher = {Association for Computing Machinery},
  series    = {ACAI 2019},
  abstract  = {At present, with the breakthrough and application of in-depth learning technology
in the field of artificial intelligence, the content of information acquired through
interpretation of remote sensing images is more and more abundant, and how to guard
information security has become a new technology hotspot. [1] In order to camouflage
and conceal our important objects, it is necessary to attack the acquired remote sensing
images to remove and confuse the target information and mislead the "enemy" to make
wrong image analysis, which is a means to protect information security.[2] In this
paper, the mainstream algorithm principle is introduced based on machine deep learning
network technology. Aiming at remote sensing image data poisoning attack and sample
attack in the process of deep learning network training, the purpose of tampering
with original image data and hiding characteristic targets is realized.},
  doi       = {10.1145/3377713.3377787},
  isbn      = {9781450372619},
  keywords  = {Deep Learning, Data Attack, Remote Sensing Image},
  location  = {Sanya, China},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3377713.3377787},
}

@InProceedings{Ren2014,
  author    = {Ren, Chuangang and Chen, Kai and Liu, Peng},
  booktitle = {Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering},
  title     = {Droidmarking: Resilient Software Watermarking for Impeding Android Application Repackaging},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {635–646},
  publisher = {Association for Computing Machinery},
  series    = {ASE '14},
  abstract  = {Software plagiarism in Android markets (app repackaging) is raising serious concerns
about the health of the Android ecosystem. Existing app repackaging detection techniques
fall short in detection efficiency and in resilience to circumventing attacks; this
allows repackaged apps to be widely propagated and causes extensive damages before
being detected. To overcome these difficulties and instantly thwart app repackaging
threats, we devise a new dynamic software watermarking technique - Droidmarking -
for Android apps that combines the efforts of all stakeholders and achieves the following
three goals: (1) copyright ownership assertion for developers, (2) real-time app repackaging
detection on user devices, and (3) resilience to evading attacks. Distinct from existing
watermarking techniques, the watermarks in Droidmarking are non-stealthy, which means
that watermark locations are not intentionally concealed, yet still are impervious
to evading attacks. This property effectively enables normal users to recover and
verify watermark copyright information without requiring a confidential watermark
recognizer. Droidmarking is based on a primitive called self-decrypting code (SDC).
Our evaluations show that Droidmarking is a feasible and robust technique to effectively
impede app repackaging with relatively small performance overhead.},
  doi       = {10.1145/2642937.2642977},
  isbn      = {9781450330138},
  keywords  = {app repackaging, software watermarking, android},
  location  = {Vasteras, Sweden},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2642937.2642977},
}

@InProceedings{Goga2013,
  author    = {Goga, Oana and Lei, Howard and Parthasarathi, Sree Hari Krishnan and Friedland, Gerald and Sommer, Robin and Teixeira, Renata},
  booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
  title     = {Exploiting Innocuous Activity for Correlating Users across Sites},
  year      = {2013},
  address   = {New York, NY, USA},
  pages     = {447–458},
  publisher = {Association for Computing Machinery},
  series    = {WWW '13},
  abstract  = {We study how potential attackers can identify accounts on different social network
sites that all belong to the same user, exploiting only innocuous activity that inherently
comes with posted content. We examine three specific features on Yelp, Flickr, and
Twitter: the geo-location attached to a user's posts, the timestamp of posts, and
the user's writing style as captured by language models. We show that among these
three features the location of posts is the most powerful feature to identify accounts
that belong to the same user in different sites. When we combine all three features,
the accuracy of identifying Twitter accounts that belong to a set of Flickr users
is comparable to that of existing attacks that exploit usernames. Our attack can identify
37% more accounts than using usernames when we instead correlate Yelp and Twitter.
Our results have significant privacy implications as they present a novel class of
attacks that exploit users' tendency to assume that, if they maintain different personas
with different names, the accounts cannot be linked together; whereas we show that
the posts themselves can provide enough information to correlate the accounts.},
  doi       = {10.1145/2488388.2488428},
  isbn      = {9781450320351},
  keywords  = {online social networks, account correlation, privacy, language, location, geotags, user profiles},
  location  = {Rio de Janeiro, Brazil},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2488388.2488428},
}

@InProceedings{Maouche2017,
  author    = {Maouche, Mohamed and Mokhtar, Sonia Ben and Bouchenak, Sara},
  booktitle = {Proceedings of the 14th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services},
  title     = {AP-Attack: A Novel User Re-Identification Attack On Mobility Datasets},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {48–57},
  publisher = {Association for Computing Machinery},
  series    = {MobiQuitous 2017},
  abstract  = {Since the advent of hand held devices (e.g., smartphones, tablets, smart watches)
with Ubiquitous computing and the wide popularity of location-based mobile applications,
the amount of captured user location data is dramatically increasing. However, the
gathering and exploitation of this data by mobile application providers raises many
privacy threats as sensitive information can be inferred from it (e.g., home and work
locations, religious beliefs, sexual orientations and social relationships). To address
this issue a number of data obfuscation techniques (also called Location Privacy Protection
Mechanisms or LPPMs) have been proposed in the literature. One of the existing methods
to assess the effectiveness of LPPMs is to test them against user re-identification
attacks. The aim of these attacks is to break user anonymity by re-associating data
obfuscated using a given LPPM with user profiles built from user past mobility. In
this paper, we present AP-Attack a novel re-identification attack that relies on a
heatmap representation of user mobility data. Our experiments run against three representative
LPPMs of the literature using four real mobility datasets show that AP-Attack succeeds
in re-identifying up to 79% users in non-obfuscated data, +27% more users than POI-Attack
and PIT-Attack two well known state-of-the-art attacks. We also present a simple technique
to improve user protection against our attack, which relies on a user-centric application
of multiple-LPPMs.},
  doi       = {10.1145/3144457.3144494},
  isbn      = {9781450353687},
  keywords  = {Security, Mobility Trace, Re-identification attacks, Location Privacy, Protection Mechanism},
  location  = {Melbourne, VIC, Australia},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3144457.3144494},
}

@InProceedings{Shezan2020,
  author    = {Shezan, Faysal Hossain and Hu, Hang and Wang, Jiamin and Wang, Gang and Tian, Yuan},
  booktitle = {Proceedings of The Web Conference 2020},
  title     = {Read Between the Lines: An Empirical Measurement of Sensitive Applications of Voice Personal Assistant Systems},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {1006–1017},
  publisher = {Association for Computing Machinery},
  series    = {WWW '20},
  abstract  = {Voice Personal Assistant (VPA) systems such as Amazon Alexa and Google Home have been
used by tens of millions of households. Recent work demonstrated proof-of-concept
attacks against their voice interface to invoke unintended applications or operations.
However, there is still a lack of empirical understanding of what type of third-party
applications that VPA systems support, and what consequences these attacks may cause.
In this paper, we perform an empirical analysis of the third-party applications of
Amazon Alexa and Google Home to systematically assess the attack surfaces. A key methodology
is to characterize a given application by classifying the sensitive voice commands
it accepts. We develop a natural language processing tool that classifies a given
voice command from two dimensions: (1) whether the voice command is designed to insert
action or retrieve information; (2) whether the command is sensitive or nonsensitive.
The tool combines a deep neural network and a keyword-based model, and uses Active
Learning to reduce the manual labeling effort. The sensitivity classification is based
on a user study (N=404) where we measure the perceived sensitivity of voice commands.
A ground-truth evaluation shows that our tool achieves over 95% of accuracy for both
types of classifications. We apply this tool to analyze 77,957 Amazon Alexa applications
and 4,813 Google Home applications (198,199 voice commands from Amazon Alexa, 13,644
voice commands from Google Home) over two years (2018-2019). In total, we identify
19,263 sensitive “action injection” commands and 5,352 sensitive “information retrieval”
commands. These commands are from 4,596 applications (5.55% out of all applications),
most of which belong to the “smart home” category. While the percentage of sensitive
applications is small, we show the percentage is increasing over time from 2018 to
2019.},
  doi       = {10.1145/3366423.3380179},
  isbn      = {9781450370233},
  keywords  = {Skill, Alexa, Voice-applications, Sensitive-keyword, Malicious-command, Active-learning., Sensitive-commands, Google-Home},
  location  = {Taipei, Taiwan},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3366423.3380179},
}

@InProceedings{Chauhan2017,
  author    = {Chauhan, Jagmohan and Hu, Yining and Seneviratne, Suranga and Misra, Archan and Seneviratne, Aruna and Lee, Youngki},
  booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
  title     = {BreathPrint: Breathing Acoustics-Based User Authentication},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {278–291},
  publisher = {Association for Computing Machinery},
  series    = {MobiSys '17},
  abstract  = {We propose BreathPrint, a new behavioural biometric signature based on audio features
derived from an individual's commonplace breathing gestures. Specifically, BreathPrint
uses the audio signatures associated with the three individual gestures: sniff, normal,
and deep breathing, which are sufficiently different across individuals. Using these
three breathing gestures, we develop the processing pipeline that identifies users
via the microphone sensor on smartphones and wearable devices. In BreathPrint, a user
performs breathing gestures while holding the device very close to their nose. Using
off-the-shelf hardware, we experimentally evaluate the BreathPrint prototype with
10 users, observed over seven days. We show that users can be authenticated reliably
with an accuracy of over 94% for all the three breathing gestures in intra-sessions
and deep breathing gesture provides the best overall balance between true positives
(successful authentication) and false positives (resiliency to directed impersonation
and replay attacks). Moreover, we show that this breathing sound based biometric is
also robust to some typical changes in both physiological and environmental context,
and that it can be applied on multiple smartphone platforms. Early results suggest
that breathing based biometrics show promise as either to be used as a secondary authentication
modality in a multimodal biometric authentication system or as a user disambiguation
technique for some daily lifestyle scenarios.},
  doi       = {10.1145/3081333.3081355},
  isbn      = {9781450349284},
  keywords  = {security, breathing gestures, usability, authentication},
  location  = {Niagara Falls, New York, USA},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3081333.3081355},
}

@InProceedings{Yan2013,
  author    = {Yan, Qiang and Han, Jin and Li, Yingjiu and Zhou, Jianying and Deng, Robert H.},
  booktitle = {Proceedings of the 8th ACM SIGSAC Symposium on Information, Computer and Communications Security},
  title     = {Designing Leakage-Resilient Password Entry on Touchscreen Mobile Devices},
  year      = {2013},
  address   = {New York, NY, USA},
  pages     = {37–48},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '13},
  abstract  = {Touchscreen mobile devices are becoming commodities as the wide adoption of pervasive
computing. These devices allow users to access various services at anytime and anywhere.
In order to prevent unauthorized access to these services, passwords have been pervasively
used in user authentication. However, password-based authentication has intrinsic
weakness in password leakage. This threat could be more serious on mobile devices,
as mobile devices are widely used in public places.Most prior research on improving
leakage resilience of password entry focuses on desktop computers, where specific
restrictions on mobile devices such as small screen size are usually not addressed.
Meanwhile, additional features of mobile devices such as touch screen are not utilized,
as they are not available in the traditional settings with only physical keyboard
and mouse. In this paper, we propose a user authentication scheme named CoverPad for
password entry on touchscreen mobile devices. CoverPad improves leakage resilience
by safely delivering hidden messages, which break the correlation between the underlying
password and the interaction information observable to an adversary. It is also designed
to retain most benefits of legacy passwords, which is critical to a scheme intended
for practical use. The usability of CoverPad is evaluated with an extended user study
which includes additional test conditions related to time pressure, distraction, and
mental workload. These test conditions simulate common situations for a password entry
scheme used on a daily basis, which have not been evaluated in the prior literature.
The results of our user study show the impacts of these test conditions on user performance
as well as the practicability of the proposed scheme.},
  doi       = {10.1145/2484313.2484318},
  isbn      = {9781450317672},
  keywords  = {mobile devices, leakage-resilience, user authentication},
  location  = {Hangzhou, China},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2484313.2484318},
}

@InProceedings{Aranha2020,
  author    = {Aranha, Diego F. and Novaes, Felipe Rodrigues and Takahashi, Akira and Tibouchi, Mehdi and Yarom, Yuval},
  booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {LadderLeak: Breaking ECDSA with Less than One Bit of Nonce Leakage},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {225–242},
  publisher = {Association for Computing Machinery},
  series    = {CCS '20},
  abstract  = {Although it is one of the most popular signature schemes today, ECDSA presents a number
of implementation pitfalls, in particular due to the very sensitive nature of the
random value (known as the nonce) generated as part of the signing algorithm. It is
known that any small amount of nonce exposure or nonce bias can in principle lead
to a full key recovery: the key recovery is then a particular instance of Boneh and
Venkatesan's hidden number problem (HNP). That observation has been practically exploited
in many attacks in the literature, taking advantage of implementation defects or side-channel
vulnerabilities in various concrete ECDSA implementations. However, most of the attacks
so far have relied on at least 2 bits of nonce bias (except for the special case of
curves at the 80-bit security level, for which attacks against 1-bit biases are known,
albeit with a very high number of required signatures). In this paper, we uncover
LadderLeak, a novel class of side-channel vulnerabilities in implementations of the
Montgomery ladder used in ECDSA scalar multiplication. The vulnerability is in particular
present in several recent versions of OpenSSL. However, it leaks less than 1 bit of
information about the nonce, in the sense that it reveals the most significant bit
of the nonce, but with probability &lt;1. Exploiting such a mild leakage would be intractable
using techniques present in the literature so far. However, we present a number of
theoretical improvements of the Fourier analysis approach to solving the HNP (an approach
originally due to Bleichenbacher), and this lets us practically break LadderLeak-vulnerable
ECDSA implementations instantiated over the sect163r1 and NIST P-192 elliptic curves.
In so doing, we achieve several significant computational records in practical attacks
against the HNP.},
  doi       = {10.1145/3372297.3417268},
  isbn      = {9781450370899},
  keywords  = {montgomery ladder, cache attack, hidden number problem, bleichenbacher's attack, generalized birthday problem, ecdsa, side-channel attack, openssl},
  location  = {Virtual Event, USA},
  numpages  = {18},
  url       = {https://doi.org/10.1145/3372297.3417268},
}

@InProceedings{Grace2012,
  author    = {Grace, Michael and Zhou, Yajin and Zhang, Qiang and Zou, Shihong and Jiang, Xuxian},
  booktitle = {Proceedings of the 10th International Conference on Mobile Systems, Applications, and Services},
  title     = {RiskRanker: Scalable and Accurate Zero-Day Android Malware Detection},
  year      = {2012},
  address   = {New York, NY, USA},
  pages     = {281–294},
  publisher = {Association for Computing Machinery},
  series    = {MobiSys '12},
  abstract  = {Smartphone sales have recently experienced explosive growth. Their popularity also
encourages malware authors to penetrate various mobile marketplaces with malicious
applications (or apps). These malicious apps hide in the sheer number of other normal
apps, which makes their detection challenging. Existing mobile anti-virus software
are inadequate in their reactive nature by relying on known malware samples for signature
extraction. In this paper, we propose a proactive scheme to spot zero-day Android
malware. Without relying on malware samples and their signatures, our scheme is motivated
to assess potential security risks posed by these untrusted apps. Specifically, we
have developed an automated system called RiskRanker to scalably analyze whether a
particular app exhibits dangerous behavior (e.g., launching a root exploit or sending
background SMS messages). The output is then used to produce a prioritized list of
reduced apps that merit further investigation. When applied to examine 118,318 total
apps collected from various Android markets over September and October 2011, our system
takes less than four days to process all of them and effectively reports 3281 risky
apps. Among these reported apps, we successfully uncovered 718 malware samples (in
29 families) and 322 of them are zero-day (in 11 families). These results demonstrate
the efficacy and scalability of RiskRanker to police Android markets of all stripes.},
  doi       = {10.1145/2307636.2307663},
  isbn      = {9781450313018},
  keywords  = {android, riskranker, malware},
  location  = {Low Wood Bay, Lake District, UK},
  numpages  = {14},
  url       = {https://doi.org/10.1145/2307636.2307663},
}

@InProceedings{Li2012,
  author    = {Li, Frank and Mittal, Prateek and Caesar, Matthew and Borisov, Nikita},
  booktitle = {Proceedings of the Seventh ACM Workshop on Scalable Trusted Computing},
  title     = {SybilControl: Practical Sybil Defense with Computational Puzzles},
  year      = {2012},
  address   = {New York, NY, USA},
  pages     = {67–78},
  publisher = {Association for Computing Machinery},
  series    = {STC '12},
  abstract  = {Many distributed systems are subject to the Sybil attack, where an adversary subverts
system operation by emulating the behavior of multiple distinct nodes. Most recent
works addressing this problem leverage social networks to establish trust relationships
between users. However, social networks are not appropriate in all systems. They can
be subverted by social engineering techniques, require nodes to maintain and be aware
of social network information, and may require overly optimistic assumptions about
the fast-mixing nature of social links.This paper explores an alternate approach.
We present SybilControl, a novel decentralized scheme for controlling the extent of
Sybil attacks. It is an admission and retainment control scheme for nodes in a distributed
system that requires them to periodically solve computational puzzles. SybilControl
consists of a distributed protocol to allow nodes to collectively verify the computational
work of other nodes, and mechanisms to prevent the malicious influence of misbehaving
nodes that do not perform the computational work. We investigate the practical issues
involved with deploying SybilControl into existing DHTs, particularly with handling
churn. SybilControl is shown to provide strict bounds on the size of Sybil attacks,
given adversaries with finite resources. We also show through simulations that the
performance overhead of enabling SybilControl is manageable using commonplace DHT
churn-handling techniques. This provides strong evidence that SybilControl can be
practically deployed.},
  doi       = {10.1145/2382536.2382548},
  isbn      = {9781450316620},
  keywords  = {distributed systems, computational puzzles, sybil attack},
  location  = {Raleigh, North Carolina, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2382536.2382548},
}

@InProceedings{Liu2015,
  author    = {Liu, Xiangyu and Zhou, Zhe and Diao, Wenrui and Li, Zhou and Zhang, Kehuan},
  booktitle = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security},
  title     = {When Good Becomes Evil: Keystroke Inference with Smartwatch},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {1273–1285},
  publisher = {Association for Computing Machinery},
  series    = {CCS '15},
  abstract  = {One rising trend in today's consumer electronics is the wearable devices, e.g., smartwatches.
With tens of millions of smartwatches shipped, however, the security implications
of such devices are not fully understood. Although previous studies have pointed out
some privacy concerns about the data that can be collected, like personalized health
information, the threat is considered low as the leaked data is not highly sensitive
and there is no real attack implemented. In this paper we investigate a security problem
coming from sensors in smartwatches, especially the accelerometer. The results show
that the actual threat is much beyond people's awareness. Being worn on the wrist,
the accelerometer built within a smartwatch can track user's hand movements, which
makes inferring user inputs on keyboards possible in theory. But several challenges
need to be addressed ahead in the real-world settings: e.g., small and irregular hand
movements occur persistently during typing, which degrades the tracking accuracy and
sometimes even overwhelms useful signals.In this paper, we present a new and practical
side-channel attack to infer user inputs on keyboards by exploiting sensors in smartwatch.
Novel keystroke inference models are developed to mitigate the negative impacts of
tracking noises. We focus on two major categories of keyboards: one is numeric keypad
that is generally used to input digits, and the other is QWERTY keyboard on which
a user can type English text. Two prototypes have been built to infer users' banking
PINs and English text when they type on POS terminal and QWERTY keyboard respectively.
Our results show that for numeric keyboard, the probability of finding banking PINs
in the top 3 candidates can reach 65%, while for QWERTY keyboard, a significant accuracy
improvement is achieved compared to the previous works, especially of the success
rate of finding the correct word in the top 10 candidates.},
  doi       = {10.1145/2810103.2813668},
  isbn      = {9781450338325},
  keywords  = {smartwatch, side-channel attacks, keystroke inference},
  location  = {Denver, Colorado, USA},
  numpages  = {13},
  url       = {https://doi.org/10.1145/2810103.2813668},
}

@InProceedings{Javaheripi2020,
  author    = {Javaheripi, Mojan and Samragh, Mohammad and Fields, Gregory and Javidi, Tara and Koushanfar, Farinaz},
  booktitle = {Proceedings of the 39th International Conference on Computer-Aided Design},
  title     = {CleaNN: Accelerated Trojan Shield for Embedded Neural Networks},
  year      = {2020},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ICCAD '20},
  abstract  = {We propose CleaNN, the first end-to-end framework that enables online mitigation of
Trojans for embedded Deep Neural Network (DNN) applications. A Trojan attack works
by injecting a backdoor in the DNN while training; during inference, the Trojan can
be activated by the specific backdoor trigger. What differentiates CleaNN from the
prior work is its lightweight methodology which recovers the ground-truth class of
Trojan samples without the need for labeled data, model retraining, or prior assumptions
on the trigger or the attack. We leverage dictionary learning and sparse approximation
to characterize the statistical behavior of benign data and identify Trojan triggers.
CleaNN is devised based on algorithm/hardware co-design and is equipped with specialized
hardware to enable efficient real-time execution on resource-constrained embedded
platforms. Proof of concept evaluations on CleaNN for the state-of-the-art Neural
Trojan attacks on visual benchmarks demonstrate its competitive advantage in terms
of attack resiliency and execution overhead.},
  articleno = {11},
  doi       = {10.1145/3400302.3415671},
  isbn      = {9781450380263},
  keywords  = {deep learning, sparse recovery, embedded systems, trojan attack},
  location  = {Virtual Event, USA},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3400302.3415671},
}

@InProceedings{Jian2017,
  author    = {Jian, Zhiqiang and Chen, Long},
  booktitle = {Proceedings of the 2017 International Conference on Cryptography, Security and Privacy},
  title     = {A Defense Method against Docker Escape Attack},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {142–146},
  publisher = {Association for Computing Machinery},
  series    = {ICCSP '17},
  abstract  = {As one of the main technologies to support the virtualization of cloud computing,
Docker has the characteristics of fast and lightweight virtualization on operating
system-level,and is widely used in a variety of cloud platforms. Docker is faced with
the risk of attacks that exploit kernel vulnerability by malicious users, once the
exploit program in the container launches an effective escape attack can gain root
privilege of the host, which will affect the reliability of other containers and the
entire system. This paper discusses the existing security mechanism and security issues
of Docker, summarize the methods and characteristics of Docker escape attack. And
propose a defense method based on status inspection of namespaces, which is proved
to be able to detect anomalous processes and prevent escape behaviors.},
  doi       = {10.1145/3058060.3058085},
  isbn      = {9781450348676},
  keywords  = {Namespaces, Container escape, Docker security},
  location  = {Wuhan, China},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3058060.3058085},
}

@Article{Kantert2016,
  author     = {Kantert, Jan and Tomforde, Sven and Kauder, Melanie and Scharrer, Richard and Edenhofer, Sarah and H\"{a}hner, J\"{o}rg and M\"{u}ller-Schloer, Christian},
  journal    = {ACM Trans. Auton. Adapt. Syst.},
  title      = {Controlling Negative Emergent Behavior by Graph Analysis at Runtime},
  year       = {2016},
  issn       = {1556-4665},
  month      = jun,
  number     = {2},
  volume     = {11},
  abstract   = {Self-organized systems typically consist of distributed autonomous entities. An increasing
part of such systems is characterized by openness and heterogeneity of participants.
For instance, open desktop computing grids provide a framework for unrestrictedly
joining in. However, openness and heterogeneity present severe challenges to the overall
system’s stability and efficiency since uncooperative and even malicious participants
are free to join. A promising solution for this problem is to introduce technical
trust as a basis; however, in turn, the utilization of trust opens space for negative
emergent behavior. This article introduces a system-wide observation and control loop
that influences the self-organized behavior to provide a performant and robust platform
for benevolent participants. Thereby, the observation part is responsible for gathering
information and deriving a system description. We introduce a graph-based approach
to identify groups of suspicious or malicious agents and demonstrate that this clustering
process is highly successful for the considered stereotype agent behaviors. In addition,
the controller part guides the system behavior by issuing norms that make use of incentives
and sanctions. We further present a concept for closing the control loop and show
experimental results that highlight the potential benefit of establishing such a control
loop.},
  address    = {New York, NY, USA},
  articleno  = {7},
  doi        = {10.1145/2890507},
  issue_date = {July 2016},
  keywords   = {negative emergent behavior, Norms, organic computing, guided self-organization},
  numpages   = {34},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2890507},
}

@InProceedings{Duchene2014,
  author    = {Duchene, Fabien and Rawat, Sanjay and Richier, Jean-Luc and Groz, Roland},
  booktitle = {Proceedings of the 4th ACM Conference on Data and Application Security and Privacy},
  title     = {KameleonFuzz: Evolutionary Fuzzing for Black-Box XSS Detection},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {37–48},
  publisher = {Association for Computing Machinery},
  series    = {CODASPY '14},
  abstract  = {Fuzz testing consists in automatically generating and sending malicious inputs to
an application in order to hopefully trigger a vulnerability. Fuzzing entails such
questions as: Where to fuzz? Which parameter to fuzz? Where to observe its effects?In
this paper, we specifically address the questions: How to fuzz a parameter? How to
observe its effects? To address these questions, we propose KameleonFuzz, a black-box
Cross Site Scripting (XSS) fuzzer for web applications. KameleonFuzz can not only
generate malicious inputs to exploit XSS, but also detect how close it is revealing
a vulnerability. The malicious inputs generation and evolution is achieved with a
genetic algorithm, guided by an attack grammar. A double taint inference, up to the
browser parse tree, permits to detect precisely whether an exploitation attempt succeeded.Our
evaluation demonstrates no false positives and high XSS revealing capabilities: KameleonFuzz
detects several vulnerabilities missed by other black-box scanners.},
  doi       = {10.1145/2557547.2557550},
  isbn      = {9781450322782},
  keywords  = {evolutionary algorithm, model inference, black-box security testing, fuzzing, taint inference, cross-site scripting},
  location  = {San Antonio, Texas, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2557547.2557550},
}

@InProceedings{Elsabagh2017,
  author    = {Elsabagh, Mohamed and Fleck, Dan and Stavrou, Angelos},
  booktitle = {Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security},
  title     = {Strict Virtual Call Integrity Checking for C++ Binaries},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {140–154},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '17},
  abstract  = {Modern operating systems are equipped with defenses that render legacy code injection
attacks inoperable. However, attackers can bypass these defenses by crafting attacks
that reuse existing code in a program's memory. One of the most common classes of
attacks manipulates memory data used indirectly to execute code, such as function
pointers. This is especially prevalent in C++ programs, since tables of function pointers
(vtables) are used by all major compilers to support polymorphism. In this paper,
we propose VCI, a binary rewriting system that secures C++ binaries against vtable
attacks. VCI works directly on stripped binary files. It identifies and reconstructs
various C++ semantics from the binary, and constructs a strict CFI policy by resolving
and pairing virtual function calls (vcalls) with precise sets of target classes. The
policy is enforced by instrumenting checks into the binary at vcall sites. Experimental
results on SPEC CPU2006 and Firefox show that VCI is significantly more precise than
state-of-the-art binary solutions. Testing against the ground truth from the source-based
defense GCC VTV, VCI achieved greater than 60% precision in most cases, accounting
for at least 48% to 99% additional reduction in the attack surface compared to the
state-of-the-art binary defenses. VCI incurs a 7.79% average runtime overhead which
is comparable to the state-of-the-art. In addition, we discuss how VCI defends against
real-world attacks, and how it impacts advanced vtable reuse attacks such as COOP.},
  doi       = {10.1145/3052973.3052976},
  isbn      = {9781450349444},
  keywords  = {static binary analysis, C++, type-call pairing, virtual table attacks, control flow integrity},
  location  = {Abu Dhabi, United Arab Emirates},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3052973.3052976},
}

@InProceedings{Zuo2021,
  author    = {Zuo, Fei and Zeng, Qiang},
  booktitle = {Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security},
  title     = {Exploiting the Sensitivity of L2 Adversarial Examples to Erase-and-Restore},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {40–51},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '21},
  abstract  = {By adding carefully crafted perturbations to input images, adversarial examples (AEs)
can be generated to mislead neural-network-based image classifiers. L2 adversarial
perturbations by Carlini and Wagner (CW) are among the most effective but difficult-to-detect
attacks. While many countermeasures against AEs have been proposed, detection of adaptive
CW-L2 AEs is still an open question. We find that, by randomly erasing some pixels
in an L2 AE and then restoring it with an inpainting technique, the AE, before and
after the steps, tends to have different classification results, while a benign sample
does not show this symptom. We thus propose a novel AE detection technique, Erase-and-Restore
(E&amp;R), that exploits the intriguing sensitivity of L2 attacks. Experiments conducted
on two popular image datasets, CIFAR-10 and ImageNet, show that the proposed technique
is able to detect over 98% of L2 AEs and has a very low false positive rate on benign
images. The detection technique exhibits high transferability: a detection system
trained using CW-L2 AEs can accurately detect AEs generated using another L2 attack
method. More importantly, our approach demonstrates strong resilience to adaptive
L2 attacks, filling a critical gap in AE detection. Finally, we interpret the detection
technique through both visualization and quantification.},
  doi       = {10.1145/3433210.3437529},
  isbn      = {9781450382878},
  keywords  = {adversarial example, image classification, adversarial detection},
  location  = {Virtual Event, Hong Kong},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3433210.3437529},
}

@InProceedings{Coffman2018,
  author    = {Coffman, Joel and Chakravarty, Aurin and Russo, Joshua A. and Gearhart, Andrew S.},
  booktitle = {Proceedings of the 5th ACM Workshop on Moving Target Defense},
  title     = {Quantifying the Effectiveness of Software Diversity Using Near-Duplicate Detection Algorithms},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {1–10},
  publisher = {Association for Computing Machinery},
  series    = {MTD '18},
  abstract  = {Software diversity is touted as a way to substantially increase the cost of cyber
attacks by limiting an attacker's ability to reuse exploits across diversified variants
of an application. Despite the number of diversity techniques that have been described
in the research literature, little is known about their effectiveness. In this paper,
we consider near-duplicate detection algorithms as a way to measure the static aspects
of software diversity---viz., their ability to recognize variants of an application.
Due to the widely varying results reported by previous studies, we describe a novel
technique for measuring the similarity of applications that share libraries. We use
this technique to systematically compare various near-duplication detection algorithms
and demonstrate their wide range in effectiveness, including for real-world tasks
such as malware triage. In addition, we use these algorithms as a way to assess the
relative strength of various diversity strategies, from recompilation with different
compilers and optimization levels to techniques specifically designed to thwart exploit
reuse. Our results indicate that even small changes to a binary disproportionately
affect the similarity reported by near-duplicate detection algorithms. In addition,
we observe a wide range in the effectiveness of various diversity strategies.},
  doi       = {10.1145/3268966.3268974},
  isbn      = {9781450360036},
  keywords  = {evaluation, binary analysis, software diversity, diversifying compilers},
  location  = {Toronto, Canada},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3268966.3268974},
}

@InProceedings{Xi2015,
  author    = {Xi, Wei and Ma, Rong and Cai, Yuanhang and Zhao, Kun},
  booktitle = {Proceedings of the 1st Workshop on Context Sensing and Activity Recognition},
  title     = {Prevent CSI Spoofing in Uplink MU-MIMO Transmission},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {13–18},
  publisher = {Association for Computing Machinery},
  series    = {CSAR '15},
  abstract  = {A Multi-User MIMO (MU-MIMO) Access Point (AP) can obtain a capacity gain by simultaneously
transmitting for multiple clients. In order to select concurrent uplink (UL) users
with strong channel orthogonality and thus high total capacity, channel state information
(CSI) feedback from users is required. However, the inaccurate CSI feedback can seriously
influence the efficiency of data transmission. Moreover, due to spontaneous uplink
traffic, uplink user s- election cannot rely on the access point central assignment
and needs a distributed realization instead, which makes the problem even more challenging.
In this paper, we propose a CSI validation algorithm, called CVU, to detect the CSI
spoofing of uplink users. CVU requires CSI at transmitting AP to set antenna gains
and phases to enable simultaneous verification code distribution through beamforming.
Only accurate CSI feedback can user accurately obtains its verification code. AP selects
the users with accurate verification codes to obtain their data using a nonlinear
equalizer. Our simulation results show that CVU significantly outperforms state-of-the-art
user selection methods under CSI spoofing attack.},
  doi       = {10.1145/2820716.2820726},
  isbn      = {9781450338424},
  keywords  = {CSI, user selection, multi-user MIMO},
  location  = {Seoul, South Korea},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2820716.2820726},
}

@InProceedings{Zhu2016,
  author    = {Zhu, Yuhao and Reddi, Vijay Janapa},
  booktitle = {Proceedings of the 37th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  title     = {GreenWeb: Language Extensions for Energy-Efficient Mobile Web Computing},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {145–160},
  publisher = {Association for Computing Machinery},
  series    = {PLDI '16},
  abstract  = {Web computing is gradually shifting toward mobile devices, in which the energy budget
is severely constrained. As a result, Web developers must be conscious of energy efficiency.
However, current Web languages provide developers little control over energy consumption.
In this paper, we take a first step toward language-level research to enable energy-efficient
Web computing. Our key motivation is that mobile systems can wisely budget energy
usage if informed with user quality-of-service (QoS) constraints. To do this, programmers
need new abstractions. We propose two language abstractions, QoS type and QoS target,
to capture two fundamental aspects of user QoS experience. We then present GreenWeb,
a set of language extensions that empower developers to easily express the QoS abstractions
as program annotations. As a proof of concept, we develop a GreenWeb runtime, which
intelligently determines how to deliver specified user QoS expectation while minimizing
energy consumption. Overall, GreenWeb shows significant energy savings (29.2% ∼ 66.0%)
over Android’s default Interactive governor with few QoS violations. Our work demonstrates
a promising first step toward language innovations for energy-efficient Web computing.},
  doi       = {10.1145/2908080.2908082},
  isbn      = {9781450342612},
  keywords  = {Web, Energy-efficiency, Mobile computing},
  location  = {Santa Barbara, CA, USA},
  numpages  = {16},
  url       = {https://doi.org/10.1145/2908080.2908082},
}

@Article{Zhu2016a,
  author     = {Zhu, Yuhao and Reddi, Vijay Janapa},
  journal    = {SIGPLAN Not.},
  title      = {GreenWeb: Language Extensions for Energy-Efficient Mobile Web Computing},
  year       = {2016},
  issn       = {0362-1340},
  month      = jun,
  number     = {6},
  pages      = {145–160},
  volume     = {51},
  abstract   = {Web computing is gradually shifting toward mobile devices, in which the energy budget
is severely constrained. As a result, Web developers must be conscious of energy efficiency.
However, current Web languages provide developers little control over energy consumption.
In this paper, we take a first step toward language-level research to enable energy-efficient
Web computing. Our key motivation is that mobile systems can wisely budget energy
usage if informed with user quality-of-service (QoS) constraints. To do this, programmers
need new abstractions. We propose two language abstractions, QoS type and QoS target,
to capture two fundamental aspects of user QoS experience. We then present GreenWeb,
a set of language extensions that empower developers to easily express the QoS abstractions
as program annotations. As a proof of concept, we develop a GreenWeb runtime, which
intelligently determines how to deliver specified user QoS expectation while minimizing
energy consumption. Overall, GreenWeb shows significant energy savings (29.2% ∼ 66.0%)
over Android’s default Interactive governor with few QoS violations. Our work demonstrates
a promising first step toward language innovations for energy-efficient Web computing.},
  address    = {New York, NY, USA},
  doi        = {10.1145/2980983.2908082},
  issue_date = {June 2016},
  keywords   = {Energy-efficiency, Web, Mobile computing},
  numpages   = {16},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2980983.2908082},
}

@Article{Angiulli2018,
  author     = {Angiulli, Fabrizio and Argento, Luciano and Furfaro, Angelo},
  journal    = {ACM Trans. Internet Technol.},
  title      = {Exploiting Content Spatial Distribution to Improve Detection of Intrusions},
  year       = {2018},
  issn       = {1533-5399},
  month      = jan,
  number     = {2},
  volume     = {18},
  abstract   = {We present PCkAD, a novel semisupervised anomaly-based IDS (Intrusion Detection System)
technique, detecting application-level content-based attacks. Its peculiarity is to
learn legitimate payloads by splitting packets into chunks and determining the within-packet
distribution of n-grams. This strategy is resistant to evasion techniques as blending.
We prove that finding the right legitimate content is NP-hard in the presence of chunks.
Moreover, it improves the false-positive rate for a given detection rate with respect
to the case where the spatial information is not considered. Comparison with well-known
IDSs using n-grams highlights that PCkAD achieves state-of-the-art performances.},
  address    = {New York, NY, USA},
  articleno  = {25},
  doi        = {10.1145/3143422},
  issue_date = {March 2018},
  keywords   = {semisupervised learning, Intrusion detection systems, anomaly detection, n-grams},
  numpages   = {21},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3143422},
}

@InProceedings{Zhang2018,
  author    = {Zhang, Jialong and Gu, Zhongshu and Jang, Jiyong and Wu, Hui and Stoecklin, Marc Ph. and Huang, Heqing and Molloy, Ian},
  booktitle = {Proceedings of the 2018 on Asia Conference on Computer and Communications Security},
  title     = {Protecting Intellectual Property of Deep Neural Networks with Watermarking},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {159–172},
  publisher = {Association for Computing Machinery},
  series    = {ASIACCS '18},
  abstract  = {Deep learning technologies, which are the key components of state-of-the-art Artificial
Intelligence (AI) services, have shown great success in providing human-level capabilities
for a variety of tasks, such as visual analysis, speech recognition, and natural language
processing and etc. Building a production-level deep learning model is a non-trivial
task, which requires a large amount of training data, powerful computing resources,
and human expertises. Therefore, illegitimate reproducing, distribution, and the derivation
of proprietary deep learning models can lead to copyright infringement and economic
harm to model creators. Therefore, it is essential to devise a technique to protect
the intellectual property of deep learning models and enable external verification
of the model ownership.In this paper, we generalize the "digital watermarking'' concept
from multimedia ownership verification to deep neural network (DNNs) models. We investigate
three DNN-applicable watermark generation algorithms, propose a watermark implanting
approach to infuse watermark into deep learning models, and design a remote verification
mechanism to determine the model ownership. By extending the intrinsic generalization
and memorization capabilities of deep neural networks, we enable the models to learn
specially crafted watermarks at training and activate with pre-specified predictions
when observing the watermark patterns at inference. We evaluate our approach with
two image recognition benchmark datasets. Our framework accurately (100%) and quickly
verifies the ownership of all the remotely deployed deep learning models without affecting
the model accuracy for normal input data. In addition, the embedded watermarks in
DNN models are robust and resilient to different counter-watermark mechanisms, such
as fine-tuning, parameter pruning, and model inversion attacks.},
  doi       = {10.1145/3196494.3196550},
  isbn      = {9781450355766},
  keywords  = {watermarking, deep neural network, ownership verification},
  location  = {Incheon, Republic of Korea},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3196494.3196550},
}

@InProceedings{Yu2016,
  author    = {Yu, Tuo and Jin, Haiming and Nahrstedt, Klara},
  booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
  title     = {WritingHacker: Audio Based Eavesdropping of Handwriting via Mobile Devices},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {463–473},
  publisher = {Association for Computing Machinery},
  series    = {UbiComp '16},
  abstract  = {When filling out privacy-related forms in public places such as hospitals or clinics,
people usually are not aware that the sound of their handwriting leaks personal information.
In this paper, we explore the possibility of eavesdropping on handwriting via nearby
mobile devices based on audio signal processing and machine learning. By presenting
a proof-of-concept system, WritingHacker, we show the usage of mobile devices to collect
the sound of victims' handwriting, and to extract handwriting-specific features for
machine learning based analysis. WritingHacker focuses on the situation where the
victim's handwriting follows certain print style. An attacker can keep a mobile device,
such as a common smart-phone, touching the desk used by the victim to record the audio
signals of handwriting. Then the system can provide a word-level estimate for the
content of the handwriting. To reduce the impacts of various writing habits and writing
locations, the system utilizes the methods of letter clustering and dictionary filtering.
Our prototype system's experimental results show that the accuracy of word recognition
reaches around 50% - 60% under certain conditions, which reveals the danger of privacy
leakage through the sound of handwriting.},
  doi       = {10.1145/2971648.2971681},
  isbn      = {9781450344616},
  keywords  = {handwriting, audio signals, eavesdropping},
  location  = {Heidelberg, Germany},
  numpages  = {11},
  url       = {https://doi.org/10.1145/2971648.2971681},
}

@InProceedings{Stevens2016,
  author    = {Stevens, Ryan and Crussell, Jonathan and Chen, Hao},
  booktitle = {Proceedings of the Sixth ACM Conference on Data and Application Security and Privacy},
  title     = {On the Origin of Mobile Apps: Network Provenance for Android Applications},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {160–171},
  publisher = {Association for Computing Machinery},
  series    = {CODASPY '16},
  abstract  = {Many mobile services consist of two components: a server providing an API, and an
application running on smartphones and communicating with the API. An unresolved problem
in this design is that it is difficult for the server to authenticate which app is
accessing the API. This causes many security problems. For example, the provider of
a private network API has to embed secrets in its official app to ensure that only
this app can access the API; however, attackers can uncover the secret by reverse-engineering.
As another example, malicious apps may send automatic requests to ad servers to commit
ad fraud.In this work, we propose a system that allows network API to authenticate
the mobile app that sends each request so that the API can make an informed access
control decision. Our system, the Mobile Trusted-Origin Policy, consists of two parts:
1) an app provenance mechanism that annotates outgoing HTTP(S) requests with information
about which app generated the network traffic, and 2) a code isolation mechanism that
separates code within an app that should have different app provenance signatures
into mobile origin. As motivation for our work, we present two previously-unknown
families of apps that perform click fraud, and examine how the lack of mobile origin
information enables the attacks. Based on our observations, we propose Trusted Cross-Origin
Requests to handle point (1), which automatically includes mobile origin information
in outgoing HTTP requests. Servers may then decide, based on the mobile origin data,
whether to process the request or not. We implement a prototype of our system for
Android and evaluate its performance, security, and deployability. We find that our
system can achieve our security and utility goals with negligible overhead.},
  doi       = {10.1145/2857705.2857712},
  isbn      = {9781450339353},
  keywords  = {app authentication, mobile security, advertising security, mobile advertising},
  location  = {New Orleans, Louisiana, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2857705.2857712},
}

@Article{Tabrizi2019,
  author     = {Tabrizi, Farid Molazem and Pattabiraman, Karthik},
  journal    = {ACM Trans. Embed. Comput. Syst.},
  title      = {Design-Level and Code-Level Security Analysis of IoT Devices},
  year       = {2019},
  issn       = {1539-9087},
  month      = may,
  number     = {3},
  volume     = {18},
  abstract   = {The Internet of Things (IoT) is playing an important role in different aspects of
our lives. Smart grids, smart cars, and medical devices all incorporate IoT devices
as key components. The ubiquity and criticality of these devices make them an attractive
target for attackers. Therefore, we need techniques to analyze their security so that
we can address their potential vulnerabilities. IoT devices, unlike remote servers,
are user-facing and, therefore, an attacker may interact with them more extensively,
e.g., via physical access. Existing techniques for analyzing security of IoT devices
either rely on a pre-defined set of attacks and, therefore, have limited effect or
do not consider the specific capabilities the attackers have against IoT devices.Security
analysis techniques may operate at the design-level, leveraging abstraction to avoid
state-space explosion, or at the code-level for ensuring accuracy. In this article,
we introduce two techniques, one at the design-level, and the other at the code-level,
to analyze security of IoT devices, and compare their effectiveness. The former technique
uses model checking, while the latter uses symbolic execution, to find attacks based
on the attacker’s capabilities. We evaluate our techniques on an open source smart
meter. We find that our code-level analysis technique is able to find three times
more attacks and complete the analysis in half the time, compared to the design-level
analysis technique, with no false positives.},
  address    = {New York, NY, USA},
  articleno  = {20},
  doi        = {10.1145/3310353},
  issue_date = {June 2019},
  keywords   = {IoT, model checking, security analysis},
  numpages   = {25},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3310353},
}

@InProceedings{Pek2014,
  author    = {P\'{e}k, G\'{a}bor and Lanzi, Andrea and Srivastava, Abhinav and Balzarotti, Davide and Francillon, Aur\'{e}lien and Neumann, Christoph},
  booktitle = {Proceedings of the 9th ACM Symposium on Information, Computer and Communications Security},
  title     = {On the Feasibility of Software Attacks on Commodity Virtual Machine Monitors via Direct Device Assignment},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {305–316},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '14},
  abstract  = {The security of virtual machine monitors (VMMs) is a challenging and active field
of research. In particular, due to the increasing significance of hardware virtualization
in cloud solutions, it is important to clearly understand existing and arising VMM-related
threats. Unfortunately, there is still a lot of confusion around this topic as many
attacks presented in the past have never been implemented in practice or tested in
a realistic scenario.In this paper, we shed light on VM related threats and defences
by implementing, testing, and categorizing a wide range of known and unknown attacks
based on directly assigned devices. We executed these attacks on an exhaustive set
of VMM configurations to determine their potential impact. Our experiments suggest
that most of the previously known attacks are ineffective in current VMM setups.We
also developed an automatic tool, called PTFuzz, to discover hardware-level problems
that affects current VMMs. By using PTFuzz, we found several cases of unexpected hardware
behaviour, and a major vulnerability on Intel platforms that potentially impacts a
large set of machines used in the wild. These vulnerabilities affect unprivileged
virtual machines that use a directly assigned device (e.g., network card) and have
all the existing hardware protection mechanisms enabled. Such vulnerabilities either
allow an attacker to generate a host-side interrupt or hardware faults, violating
expected isolation properties. These can cause host software (e.g., VMM) halt as well
as they might open the door for practical VMM exploitations.We believe that our study
can help cloud providers and researchers to better understand the limitations of their
current architectures to provide secure hardware virtualization and prepare for future
attacks.},
  doi       = {10.1145/2590296.2590299},
  isbn      = {9781450328005},
  keywords  = {virtual machine monitor, I/O virtualization, interrupt attack, MMIO, passthrough, DMA attack, PIO},
  location  = {Kyoto, Japan},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2590296.2590299},
}

@InProceedings{Anton2019,
  author    = {Anton, Simon D. Duque and Fraunholz, Daniel and Schotten, Hans Dieter},
  booktitle = {Proceedings of the 14th International Conference on Availability, Reliability and Security},
  title     = {Using Temporal and Topological Features for Intrusion Detection in Operational Networks},
  year      = {2019},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ARES '19},
  abstract  = {Until two decades ago, industrial networks were deemed secure due to physical separation
from public networks. An abundance of successful attacks proved that assumption wrong.
Intrusion detection solutions for industrial application need to meet certain requirements
that differ from home- and office-environments, such as working without feedback to
the process and compatibility with legacy systems. Industrial systems are commonly
used for several decades, updates are often difficult and expensive. Furthermore,
most industrial protocols do not have inherent authentication or encryption mechanisms,
allowing for easy lateral movement of an intruder once the perimeter is breached.
In this work, an algorithm for motif discovery in time series, Matrix Profiles, is
used to detect outliers in the timing behaviour of an industrial process. This process
was monitored in an experimental environment, containing ground truth labels after
attacks were performed. Furthermore, the graph representations of a different industrial
data set that has been emulated are used to detect malicious activities. These activities
can be derived from anomalous communication patterns, represented as edges in the
graph. Finally, an integration concept for both methods is proposed.},
  articleno = {99},
  doi       = {10.1145/3339252.3341476},
  isbn      = {9781450371643},
  keywords  = {Time Series, Machine Learning, IT-Security, Graph, Industrial Process},
  location  = {Canterbury, CA, United Kingdom},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3339252.3341476},
}

@InProceedings{Li2020,
  author    = {Li, Ang and Duan, Yixiao and Yang, Huanrui and Chen, Yiran and Yang, Jianlei},
  booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
  title     = {TIPRDC: Task-Independent Privacy-Respecting Data Crowdsourcing Framework for Deep Learning with Anonymized Intermediate Representations},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {824–832},
  publisher = {Association for Computing Machinery},
  series    = {KDD '20},
  abstract  = {The success of deep learning partially benefits from the availability of various large-scale
datasets. These datasets are often crowdsourced from individual users and contain
private information like gender, age, etc. The emerging privacy concerns from users
on data sharing hinder the generation or use of crowdsourcing datasets and lead to
hunger of training data for new deep learning applications. One naive solution is
to pre-process the raw data to extract features at the user-side, and then only the
extracted features will be sent to the data collector. Unfortunately, attackers can
still exploit these extracted features to train an adversary classifier to infer private
attributes. Some prior arts leveraged game theory to protect private attributes. However,
these defenses are designed for known primary learning tasks, the extracted features
work poorly for unknown learning tasks. To tackle the case where the learning task
may be unknown or changing, we present TIPRDC, a task-independent privacy-respecting
data crowdsourcing framework with anonymized intermediate representation. The goal
of this framework is to learn a feature extractor that can hide the privacy information
from the intermediate representations; while maximally retaining the original information
embedded in the raw data for the data collector to accomplish unknown learning tasks.
We design a hybrid training method to learn the anonymized intermediate representation:
(1) an adversarial training process for hiding private information from features;
(2) maximally retain original information using a neural-network-based mutual information
estimator. We extensively evaluate TIPRDC and compare it with existing methods using
two image datasets and one text dataset. Our results show that TIPRDC substantially
outperforms other existing methods. Our work is the first task-independent privacy-respecting
data crowdsourcing framework.},
  doi       = {10.1145/3394486.3403125},
  isbn      = {9781450379984},
  keywords  = {anonymized intermediate representations, deep learning, privacy-respecting data crowdsourcing},
  location  = {Virtual Event, CA, USA},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3394486.3403125},
}

@InProceedings{Hendler2020,
  author    = {Hendler, Danny and Kels, Shay and Rubin, Amir},
  booktitle = {Proceedings of the 15th ACM Asia Conference on Computer and Communications Security},
  title     = {AMSI-Based Detection of Malicious PowerShell Code Using Contextual Embeddings},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {679–693},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '20},
  abstract  = {PowerShell is a command-line shell, supporting a scripting language. It is widely
used in organizations for configuration management and task automation but is also
increasingly used for launching cyber attacks against organizations, mainly because
it is pre-installed on Windows machines and exposes strong functionality that may
be leveraged by attackers. This makes the problem of detecting malicious PowerShell
code both urgent and challenging. Microsoft's Antimalware Scan Interface (AMSI), built
into Windows 10, allows defending systems to scan all the code passed to scripting
engines such as PowerShell prior to its execution. In this work, we conduct the first
study of malicious PowerShell code detection using the information made available
by AMSI. We present several novel deep-learning based detectors of malicious PowerShell
code that employ pretrained contextual embeddings of words from the PowerShell "language".
A contextual word embedding is able to project semantically-similar words to proximate
vectors in the embedding space. A known problem in the cybersecurity domain is that
labeled data is relatively scarce, in comparison with unlabeled data, making it difficult
to devise effective supervised detection of malicious activity of many types. This
is also the case with PowerShell code. Our work shows that this problem can be mitigated
by learning a pretrained contextual embedding based on unlabeled data. We trained
and evaluated our models using real-world data, collected using AMSI. The contextual
embedding was learnt using a large corpus of unlabeled PowerShell scripts and modules
collected from public repositories. Our performance analysis establishes that the
use of unlabeled data for the embedding significantly improved the performance of
our detectors. Our best-performing model uses an architecture that enables the processing
of textual signals from both the character and token levels and obtains a true-positive
rate of nearly 90% while maintaining a low false-positive rate of less than 0.1%.},
  doi       = {10.1145/3320269.3384742},
  isbn      = {9781450367509},
  keywords  = {powershell, contextual embedding, cybersecurity, neural networks},
  location  = {Taipei, Taiwan},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3320269.3384742},
}

@InProceedings{Irazoqui2018,
  author    = {Irazoqui, Gorka and Eisenbarth, Thomas and Sunar, Berk},
  booktitle = {Proceedings of the Eighth ACM Conference on Data and Application Security and Privacy},
  title     = {MASCAT: Preventing Microarchitectural Attacks Before Distribution},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {377–388},
  publisher = {Association for Computing Machinery},
  series    = {CODASPY '18},
  abstract  = {Microarchitectural attacks have gained popularity lately for the threat they pose
and for their stealthiness. They are stealthy as they only exploit common harmless
resources accessible at lowest privilege level, e.g. timed memory and cache accesses.
Microarchitectural attacks have proven successful on shared cloud instances across
VMs, on smartphones with sandboxing, and on numerous embedded platforms. Further they
have shown to have catastrophic consequences such as critical data recovery or memory
isolation bypassing. Due to the rise of malicious code, app store operators such as
Microsoft, Apple and Google are already vetting apps before releasing them. Microarchitectural
attacks however still bypass such detection mechanisms as they mainly utilize standard
resources and look harmless. Given the rise of malicious code in app stores and in
online repositories it becomes essential to scan applications for such stealthy attacks
to prevent their distribution.We present a static code analysis tool, MASCAT, capable
of scanning for ever-evolving microarchitectural attacks. MASCAT can be used by app
store service providers to perform large scale fully automated analysis of applications.
The initial MASCAT suite is built to include cache/DRAM access attacks and rowhammer.
MASCAT detects several patterns that are common and necessary to execute microarchitectural
attacks. MASCAT currently has a detection rate of 96% and an average false positive
rate tested in 1200 applications of 0.75%. Further, our tool can easily be extended
to cover newer attack vectors as they emerge},
  doi       = {10.1145/3176258.3176316},
  isbn      = {9781450356329},
  keywords  = {static code analysis., cache attacks, microarchitectural attacks},
  location  = {Tempe, AZ, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3176258.3176316},
}

@InProceedings{Chen2017,
  author    = {Chen, Sheng-Yu and Jeng, Tzung-Han and Huang, Chuan-Chiang and Chen, Chien-Chih and Chou, Kuo-Sen},
  booktitle = {Proceedings of the 2017 the 7th International Conference on Communication and Network Security},
  title     = {Doctrina: Annotated Bipartite Graph Mining for Malware-Control Domain Detection},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {67–75},
  publisher = {Association for Computing Machinery},
  series    = {ICCNS 2017},
  abstract  = {Malware-Control Domain is a common and efficacious cybercriminal utensil to remotely
control malware-infected machines and steal sensitive information, and cause losses
billions dollars every year. Since attackers use creative and obfuscation techniques
to evade blacklists and fool users, we propose Doctrina, a novel defense system that
allows for efficiently discovering the occurrence of new malware-control domain names
in very large ISP networks. Doctrina extracted 20 features from DNS traffic which
based on annotated bipartite graph mining with a scalable architecture design to find
out new Malware-Control Domain. We implemented a proof-of-concept version of Doctrina
and deployed it in two large enterprises for a long period. The experiment results
show that Doctrina can achieve AUC as good as 98% and find new malware-control domains
which cannot be identified by other reputation system. In addition, we show that Doctrina
outperforms Segugio, a previously proposed domain name reputation system.},
  doi       = {10.1145/3163058.3163061},
  isbn      = {9781450353496},
  keywords  = {Maware-control domain, Mapreduce, DNS},
  location  = {Tokyo, Japan},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3163058.3163061},
}

@InProceedings{Cook2021,
  author    = {Cook, Meghan and Baez, Jeffrey},
  booktitle = {DG.O2021: The 22nd Annual International Conference on Digital Government Research},
  title     = {Informing a Statewide Investment: The NYS Voter Registration Data Pattern Detection Prototype Project},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {60–66},
  publisher = {Association for Computing Machinery},
  series    = {DG.O'21},
  abstract  = {This management case study presents the results of a prototype project conducted with
the New York State Board of Elections (NYSBOE) to investigate and make recommendations
on pattern detection analytical models for the purposes of informing their future
investment of a statewide detection and visualization system for voter registration
data. NYSBOE, a bipartisan organization with a mission to protect the integrity of
elections, recognized that a critical element of protecting elections includes a systematic
and intelligence driven approach to monitoring voter registration data as part of
an overall cybersecurity program. Using over thirteen years of data from the NYS voter
registration database (NYSVoter), the prototypes yielded valuable insights on the
analytical models and visualizations most appropriate for the purpose of pattern detection
in voter registration data so that state election leaders can better inform their
investment. This management paper presents a short background on voter registration
data, elections, and the importance of pattern detection as a part of a cyber security
program, prototype project background, insights generating in identifying most appropriate
analytical models and visualizations for voter registration data, and a short conclusion.},
  doi       = {10.1145/3463677.3463693},
  isbn      = {9781450384926},
  keywords  = {Statistical Modeling, Information Systems, Database Management, Pattern Detection},
  location  = {Omaha, NE, USA},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3463677.3463693},
}

@InProceedings{Nikiforakis2014,
  author    = {Nikiforakis, Nick and Maggi, Federico and Stringhini, Gianluca and Rafique, M. Zubair and Joosen, Wouter and Kruegel, Christopher and Piessens, Frank and Vigna, Giovanni and Zanero, Stefano},
  booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
  title     = {Stranger Danger: Exploring the Ecosystem of Ad-Based URL Shortening Services},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {51–62},
  publisher = {Association for Computing Machinery},
  series    = {WWW '14},
  abstract  = {URL shortening services facilitate the need of exchanging long URLs using limited
space, by creating compact URL aliases that redirect users to the original URLs when
followed. Some of these services show advertisements (ads) to link-clicking users
and pay a commission of their advertising earnings to link-shortening users.In this
paper, we investigate the ecosystem of these increasingly popular ad-based URL shortening
services. Even though traditional URL shortening services have been thoroughly investigated
in previous research, we argue that, due to the monetary incentives and the presence
of third-party advertising networks, ad-based URL shortening services and their users
are exposed to more hazards than traditional shortening services. By analyzing the
services themselves, the advertisers involved, and their users, we uncover a series
of issues that are actively exploited by malicious advertisers and endanger the users.
Moreover, next to documenting the ongoing abuse, we suggest a series of defense mechanisms
that services and users can adopt to protect themselves.},
  doi       = {10.1145/2566486.2567983},
  isbn      = {9781450327442},
  keywords  = {malware, short URLs, advertising, iframe, HTML5},
  location  = {Seoul, Korea},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2566486.2567983},
}

@InProceedings{Lu2019,
  author    = {Lu, Chaoyi and Liu, Baojun and Li, Zhou and Hao, Shuang and Duan, Haixin and Zhang, Mingming and Leng, Chunying and Liu, Ying and Zhang, Zaifeng and Wu, Jianping},
  booktitle = {Proceedings of the Internet Measurement Conference},
  title     = {An End-to-End, Large-Scale Measurement of DNS-over-Encryption: How Far Have We Come?},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {22–35},
  publisher = {Association for Computing Machinery},
  series    = {IMC '19},
  abstract  = {DNS packets are designed to travel in unencrypted form through the Internet based
on its initial standard. Recent discoveries show that real-world adversaries are actively
exploiting this design vulnerability to compromise Internet users' security and privacy.
To mitigate such threats, several protocols have been proposed to encrypt DNS queries
between DNS clients and servers, which we jointly term as DNS-over-Encryption. While
some proposals have been standardized and are gaining strong support from the industry,
little has been done to understand their status from the view of global users.This
paper performs by far the first end-to-end and large-scale analysis on DNS-over-Encryption.
By collecting data from Internet scanning, user-end measurement and passive monitoring
logs, we have gained several unique insights. In general, the service quality of DNS-over-Encryption
is satisfying, in terms of accessibility and latency. For DNS clients, DNS-over-Encryption
queries are less likely to be disrupted by in-path interception compared to traditional
DNS, and the extra overhead is tolerable. However, we also discover several issues
regarding how the services are operated. As an example, we find 25% DNS-over-TLS service
providers use invalid SSL certificates. Compared to traditional DNS, DNS-over-Encryption
is used by far fewer users but we have witnessed a growing trend. As such, we believe
the community should push broader adoption of DNS-over-Encryption and we also suggest
the service providers carefully review their implementations.},
  doi       = {10.1145/3355369.3355580},
  isbn      = {9781450369480},
  keywords  = {DNS Privacy, DNS Measurement, DNS-over-TLS, DNS-over-HTTPS, Domane Name System},
  location  = {Amsterdam, Netherlands},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3355369.3355580},
}

@InProceedings{Feyisetan2020,
  author    = {Feyisetan, Oluwaseyi and Balle, Borja and Drake, Thomas and Diethe, Tom},
  booktitle = {Proceedings of the 13th International Conference on Web Search and Data Mining},
  title     = {Privacy- and Utility-Preserving Textual Analysis via Calibrated Multivariate Perturbations},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {178–186},
  publisher = {Association for Computing Machinery},
  series    = {WSDM '20},
  abstract  = {Accurately learning from user data while providing quantifiable privacy guarantees
provides an opportunity to build better ML models while maintaining user trust. This
paper presents a formal approach to carrying out privacy preserving text perturbation
using the notion of d_χ-privacy designed to achieve geo-indistinguishability in location
data. Our approach applies carefully calibrated noise to vector representation of
words in a high dimension space as defined by word embedding models. We present a
privacy proof that satisfies d_χ-privacy where the privacy parameter $varepsilon$
provides guarantees with respect to a distance metric defined by the word embedding
space. We demonstrate how $varepsilon$ can be selected by analyzing plausible deniability
statistics backed up by large scale analysis on GloVe and fastText embeddings. We
conduct privacy audit experiments against $2$ baseline models and utility experiments
on 3 datasets to demonstrate the tradeoff between privacy and utility for varying
values of varepsilon on different task types. Our results demonstrate practical utility
(&lt; 2% utility loss for training binary classifiers) while providing better privacy
guarantees than baseline models.},
  doi       = {10.1145/3336191.3371856},
  isbn      = {9781450368223},
  keywords  = {plausible deniability, privacy, differential privacy},
  location  = {Houston, TX, USA},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3336191.3371856},
}

@InProceedings{Shringarputale2020,
  author    = {Shringarputale, Sushrut and McDaniel, Patrick and Butler, Kevin and La Porta, Thomas},
  booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Cloud Computing Security Workshop},
  title     = {Co-Residency Attacks on Containers Are Real},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {53–66},
  publisher = {Association for Computing Machinery},
  series    = {CCSW'20},
  abstract  = {Public clouds are inherently multi-tenant: applications deployed by different parties
(including malicious ones) may reside on the same physical machines and share various
hardware resources. With the introduction of newer hypervisors, containerization frameworks
like Docker, and managed/orchestrated clusters using systems like Kubernetes, cloud
providers downplay the feasibility of co-tenant attacks by marketing a belief that
applications do not operate on shared hardware. In this paper, we challenge the conventional
wisdom that attackers cannot confirm co-residency with a victim application from inside
state-of-the-art containers running on virtual machines. We analyze the degree of
vulnerability present in containers running on various systems including within a
broad range of commercially utilized orchestrators. Our results show that on commercial
cloud environments including AWS and Azure, we can obtain over 90% success rates for
co-residency detection using real-life workloads. Our investigation confirms that
co-residency attacks are a significant concern on containers running on modern orchestration
systems.},
  doi       = {10.1145/3411495.3421357},
  isbn      = {9781450380843},
  keywords  = {side-channel attacks, co-residency detection, cloud computing, virtualization, security and privacy, virtual machines, containers},
  location  = {Virtual Event, USA},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3411495.3421357},
}

@InProceedings{Xu2019,
  author    = {Xu, Qiumin and Naghibijouybari, Hoda and Wang, Shibo and Abu-Ghazaleh, Nael and Annavaram, Murali},
  booktitle = {Proceedings of the ACM International Conference on Supercomputing},
  title     = {GPUGuard: Mitigating Contention Based Side and Covert Channel Attacks on GPUs},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {497–509},
  publisher = {Association for Computing Machinery},
  series    = {ICS '19},
  abstract  = {Graphics processing units (GPUs) are moving towards supporting concurrent kernel execution
where multiple kernels may be co-executed on the same GPU and even on the same streaming
multiprocessor (SM) core. While concurrent kernel execution improves hardware resource
utilization, it opens up vulnerabilities to covert-channel and side-channel attacks.
These attacks exploit information leakage across kernels that results from contention
on shared resources; they have been shown to be a dangerous threat on CPUs, and are
starting to be demonstrated on GPUs. The unique micro-architectural features of GPUs,
such as specialized cache structures and massive parallel thread support, create opportunities
for GPU-specific channels to be formed. In this paper, we propose GPUGuard, a decision
tree based detection and a hierarchical defense framework that can reliably close
the covert channels. Our results show that GPUGuard can detect contention with 100%
sensitivity and a small (8.5%) false positive rate. The timing channels are mitigated
through Tangram, a GPU-specific contention channel elimination scheme, with only 8%
to 23% overhead when there is an attack and zero performance overhead when no attacks
are detected. Compared to temporal partitioning, GPUGuard is 69%-96% faster in various
architectures even when active, showing that it is possible to gain substantial performance
from executing concurrent kernels on a single SM while securing GPUs against these
attacks.},
  doi       = {10.1145/3330345.3330389},
  isbn      = {9781450360791},
  location  = {Phoenix, Arizona},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3330345.3330389},
}

@InProceedings{Gates2012,
  author    = {Gates, Christopher and Li, Ninghui and Chen, Jing and Proctor, Robert},
  booktitle = {Proceedings of the 28th Annual Computer Security Applications Conference},
  title     = {CodeShield: Towards Personalized Application Whitelisting},
  year      = {2012},
  address   = {New York, NY, USA},
  pages     = {279–288},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '12},
  abstract  = {Malware has been a major security problem both in organizations and homes for more
than a decade. One common feature of most malware attacks is that at a certain point
early in the attack, an executable is dropped on the system which, when executed,
enables the attacker to achieve their goals and maintain control of the compromised
machine. In this paper we propose the concept of Personalized Application Whitelisting
(PAW) to block all unsolicited foreign code from executing on a system. We introduce
CodeShield, an approach to implement PAW on Windows hosts. CodeShield uses a simple
and novel security model, and a new user interaction approach for obtaining security-critical
decisions from users. We have implemented CodeShield, demonstrated its security effectiveness,
and conducted a user study, having 38 participants run CodeShield on their laptops
for 6 weeks. Results from the data demonstrate the usability and promises of our design.},
  doi       = {10.1145/2420950.2420992},
  isbn      = {9781450313124},
  location  = {Orlando, Florida, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2420950.2420992},
}

@InProceedings{Baarzi2020,
  author    = {Baarzi, Ataollah Fatahi and Kesidis, George and Fleck, Dan and Stavrou, Angelos},
  booktitle = {Proceedings of the 13th European Workshop on Systems Security},
  title     = {Microservices Made Attack-Resilient Using Unsupervised Service Fissioning},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {31–36},
  publisher = {Association for Computing Machinery},
  series    = {EuroSec '20},
  abstract  = {Application-layer DoS attacks are increasing as the number of cloud-deployed microservice
applications is increasing. The attacker tries to exhaust computing resources and
brings the nominal applications down by exploiting application-layer vulnerabilities.
As traditional solutions for volumetric DoS attacks will not be able to handle these
attacks, new approaches are required to detect and respond to application-layer attacks.
In this work, we propose an unsupervised, non-intrusive and application-agnostic detection
approach and fissioning based response mechanism. We built our prototype on Kubernetes,
the state of the art container orchestrator for microservices, and show its effectiveness
through experimental evaluation. Our preliminary results show that using our detection
and defense mechanism, we are able to a) efficiently identify the attacks and b) reduce
the effect of the attack on legitimate users by 3\texttimes{} compared to a case where there
is no detection/defense in place.},
  doi       = {10.1145/3380786.3391395},
  isbn      = {9781450375238},
  keywords  = {cloud computing, microservices, systems security, DDoS attack},
  location  = {Heraklion, Greece},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3380786.3391395},
}

@InProceedings{Rodhe2012,
  author    = {Rodhe, Ioana and Rohner, Christian and Ngai, Edith C.-H.},
  booktitle = {Proceedings of the 8h ACM Symposium on QoS and Security for Wireless and Mobile Networks},
  title     = {On Location Privacy and Quality of Information in Participatory Sensing},
  year      = {2012},
  address   = {New York, NY, USA},
  pages     = {55–62},
  publisher = {Association for Computing Machinery},
  series    = {Q2SWinet '12},
  abstract  = {Participatory sensing applications typically bind sensor data to locations. Location
privacy preserving mechanisms protecting the location of users introduce therefore
an uncertainty in the collected data distributions. We consider two strategies to
reconstruct a data distribution after k-anonymity has been applied to the users' location
information. We investigate how different parameters for the location privacy preserving
mechanism influence both the quality of information and the location privacy of the
users. Our results show that the cloak area resulted from applying k-anonymity has
a higher impact on both the quality of information and the location privacy than the
number of users, k, that are cloaked together.},
  doi       = {10.1145/2387218.2387229},
  isbn      = {9781450316194},
  keywords  = {location privacy, quality of information, participatory sensing, data collection},
  location  = {Paphos, Cyprus},
  numpages  = {8},
  url       = {https://doi.org/10.1145/2387218.2387229},
}

@InProceedings{Naumenko2019,
  author    = {Naumenko, Gleb and Maxwell, Gregory and Wuille, Pieter and Fedorova, Alexandra and Beschastnikh, Ivan},
  booktitle = {Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {Erlay: Efficient Transaction Relay for Bitcoin},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {817–831},
  publisher = {Association for Computing Machinery},
  series    = {CCS '19},
  abstract  = {Bitcoin is a top-ranked cryptocurrency that has experienced huge growth and survived
numerous attacks. The protocols making up Bitcoin must therefore accommodate the growth
of the network and ensure security.Security of the Bitcoin network depends on connectivity
between the nodes. Higher connectivity yields better security. In this paper we make
two observations: (1) current connectivity in the Bitcoin network is too low for optimal
security; (2) at the same time, increasing connectivity will substantially increase
the bandwidth used by the transaction dissemination protocol, making it prohibitively
expensive to operate a Bitcoin node. Half of the total bandwidth needed to operate
a Bitcoin node is currently used to just announce transactions. Unlike block relay,
transaction dissemination has received little attention in prior work.We propose a
new transaction dissemination protocol, Erlay, that not only reduces the bandwidth
consumption by 40% assuming current connectivity, but also keeps the bandwidth use
almost constant as the connectivity increases. In contrast, the existing protocol
increases the bandwidth consumption linearly with the number of connections. By allowing
more connections at a small cost, Erlay improves the security of the Bitcoin network.
And, as we demonstrate, Erlay also hardens the network against attacks that attempt
to learn the origin node of a transaction. Erlay is currently being investigated by
the Bitcoin community for future use with the Bitcoin protocol.},
  doi       = {10.1145/3319535.3354237},
  isbn      = {9781450367479},
  keywords  = {peer-to-peer, bandwidth, distributed systems, gossip},
  location  = {London, United Kingdom},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3319535.3354237},
}

@InProceedings{Dou2020,
  author    = {Dou, Yingtong and Ma, Guixiang and Yu, Philip S. and Xie, Sihong},
  booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
  title     = {Robust Spammer Detection by Nash Reinforcement Learning},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {924–933},
  publisher = {Association for Computing Machinery},
  series    = {KDD '20},
  abstract  = {Online reviews provide product evaluations for customers to make decisions. Unfortunately,
the evaluations can be manipulated using fake reviews ("spams") by professional spammers,
who have learned increasingly insidious and powerful spamming strategies by adapting
to the deployed detectors. Spamming strategies are hard to capture, as they can be
varying quickly along time, different across spammers and target products, and more
critically, remained unknown in most cases. Furthermore, most existing detectors focus
on detection accuracy, which is not well-aligned with the goal of maintaining the
trustworthiness of product evaluations. To address the challenges, we formulate a
minimax game where the spammers and spam detectors compete with each other on their
practical goals that are not solely based on detection accuracy. Nash equilibria of
the game lead to stable detectors that are agnostic to any mixed detection strategies.
However, the game has no closed-form solution and is not differentiable to admit the
typical gradient-based algorithms. We turn the game into two dependent Markov Decision
Processes (MDPs) to allow efficient stochastic optimization based on multi-armed bandit
and policy gradient. We experiment on three large review datasets using various state-of-the-art
spamming and detection strategies and show that the optimization algorithm can reliably
find an equilibrial detector that can robustly and effectively prevent spammers with
any mixed spamming strategies from attaining their practical goal. Our code is available
at https://github.com/YingtongDou/Nash-Detect.},
  doi       = {10.1145/3394486.3403135},
  isbn      = {9781450379984},
  keywords  = {spam detection, reinforcement learning, adversarial learning},
  location  = {Virtual Event, CA, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3394486.3403135},
}

@InProceedings{Dadras2015,
  author    = {Dadras, Soodeh and Gerdes, Ryan M. and Sharma, Rajnikant},
  booktitle = {Proceedings of the 10th ACM Symposium on Information, Computer and Communications Security},
  title     = {Vehicular Platooning in an Adversarial Environment},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {167–178},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '15},
  abstract  = {In this paper, we show that a single, maliciously controlled vehicle can destabilize
a vehicular platoon, to catastrophic effect, through local modifications to the prevailing
control law. Specifically, by combining changes to the gains of the associated law
with the appropriate vehicle movements, the attacker can cause the platoon to oscillate
at a resonant frequency, causing accidents that could result in serious injury or
death. We determine the range of gains, and their corresponding frequencies, that
allow an attacker to violate the string stability and stability criteria at different
positions in the platoon. Furthermore, we prove that the attack can be successful
at any position in the platoon and at frequencies that can be realized by the other
vehicles in the platoon. Our work implies that neither the string stability nor stability
conditions, when used singly, ensure proper platoon operation, and that neither can
be used to ensure the other. Finally, we show that an attacker is theoretically capable
of gaining control over the individual position and velocity (states) of other vehicles
in the platoon; two attacks are demonstrated for this vulnerability.},
  doi       = {10.1145/2714576.2714619},
  isbn      = {9781450332453},
  keywords  = {adaptive cruise control, attack, autonomous and automated vehicles, cooperative adaptive cruise control, vehicle platoon},
  location  = {Singapore, Republic of Singapore},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2714576.2714619},
}

@InProceedings{Gisdakis2012,
  author    = {Gisdakis, Stylianos and Papadimitratos, Panos},
  booktitle = {Proceedings of the First ACM International Workshop on Mission-Oriented Wireless Sensor Networking},
  title     = {On the Optimal Allocation of Adversarial Resources},
  year      = {2012},
  address   = {New York, NY, USA},
  pages     = {33–38},
  publisher = {Association for Computing Machinery},
  series    = {MiSeNet '12},
  abstract  = {Security is important for mission-critical wireless sensor networks (WSNs). This is
especially so because powerful adversaries could compromise and control a significant
fraction of the network nodes. A plethora of schemes has been developed to secure
wireless sensor networks and resilience to sophisticated attacks has been analyzed.
However, the question of how the adversary could deploy her resources to maximally
affect the attacked system has remained largely unaddressed. This is the problem this
paper is concerned with: Given a number of compromised entities (nodes) and cryptographic
keys, how can the adversary devise a close-to-optimal attack tactic? To the best of
our knowledge, this is the first investigation of its kind: while the basic adversarial
behavior is well-known, the problem of how the adversary can optimally deploy her
resources to maximize the attack impact has not been considered for WSNs. We consider
an abstract model of the mission-critical WSN and the adversary, and we find that
the determination of an optimal attack is computationally hard, thus, we devise an
efficient heuristic approach. An intelligent adversarial resource allocation indeed
yields disproportional gains for the attacker. Our analysis is the first necessary
step to comprehend how to best address vulnerabilities.},
  doi       = {10.1145/2348656.2348666},
  isbn      = {9781450315296},
  keywords  = {resource allocation, security analysis, adversary modeling},
  location  = {Istanbul, Turkey},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2348656.2348666},
}

@InProceedings{Beigi2019,
  author    = {Beigi, Ghazaleh and Guo, Ruocheng and Nou, Alexander and Zhang, Yanchao and Liu, Huan},
  booktitle = {Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining},
  title     = {Protecting User Privacy: An Approach for Untraceable Web Browsing History and Unambiguous User Profiles},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {213–221},
  publisher = {Association for Computing Machinery},
  series    = {WSDM '19},
  abstract  = {The overturning of the Internet Privacy Rules by the Federal Communications Commissions
(FCC) in late March 2017 allows Internet Service Providers (ISPs) to collect, share
and sell their customers' Web browsing data without their consent. With third-party
trackers embedded on Web pages, this new rule has put user privacy under more risk.
The need arises for users on their own to protect their Web browsing history from
any potential adversaries. Although some available solutions such as Tor, VPN, and
HTTPS can help users conceal their online activities, their use can also significantly
hamper personalized online services, i.e., degraded utility. In this paper, we design
an effective Web browsing history anonymization scheme, PBooster, aiming to protect
users' privacy while retaining the utility of their Web browsing history. The proposed
model pollutes users' Web browsing history by automatically inferring how many and
what links should be added to the history while addressing the utility-privacy trade-off
challenge. We conduct experiments to validate the quality of the manipulated Web browsing
history and examine the robustness of the proposed approach for user privacy protection.},
  doi       = {10.1145/3289600.3291026},
  isbn      = {9781450359405},
  keywords  = {privacy, web browsing history anonymization, trade-off, utility},
  location  = {Melbourne VIC, Australia},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3289600.3291026},
}

@InProceedings{Fraunholz2018a,
  author    = {Fraunholz, Daniel and Krohmer, Daniel and Duque Anton, Simon and Schotten, Hans Dieter},
  booktitle = {Proceedings of the 5th ACM Workshop on Moving Target Defense},
  title     = {Catch Me If You Can: Dynamic Concealment of Network Entities},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {31–39},
  publisher = {Association for Computing Machinery},
  series    = {MTD '18},
  abstract  = {In this paper, a framework for Moving Target Defense is introduced. This framework
bases on three pillars: network address mutation, communication stack randomization
and the dynamic deployment of decoys. The network address mutation is based on the
concept of domain generation algorithms, where different features are included to
fulfill the system requirements. Those requirements are time dependency, unpredictability
and determinism. Communication stack randomization is applied additionally to increase
the complexity of reconnaissance activity. By employing communication stack randomization,
previously fingerprinted systems do not only differ in the network address but also
in their communication pattern behavior. And finally, decoys are integrated into the
proposed framework to detect attackers that have breached the perimeter. Furthermore,
attacker's resources can be bound by interacting with the decoy systems. Additionally,
the framework can be extended with more advanced Moving Target Defense methods such
as obscuring port numbers of services.},
  doi       = {10.1145/3268966.3268970},
  isbn      = {9781450360036},
  keywords  = {deception, information security, moving target defense, network mutation},
  location  = {Toronto, Canada},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3268966.3268970},
}

@InProceedings{Letavay2019,
  author    = {Letavay, Viliam and Pluskal, Jan and Ry\v{s}av\'{y}, Ond\v{r}ej},
  booktitle = {Proceedings of the 6th Conference on the Engineering of Computer Based Systems},
  title     = {Network Forensic Analysis for Lawful Enforcement on Steroids, Distributed and Scalable},
  year      = {2019},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ECBS '19},
  abstract  = {Forensic analysis of intercepted network traffic focuses on finding and extracting
communication evidence, such as instant messaging, email, VoIP calls, localization
information, documents, images. Due to the amount of data captured, this process is
time-consuming and complicated. Most commonly used forensic network analysis tools
have limited capabilities for large data processing. In this paper, we are introducing
a new tool that achieves better data processing performance using available computing
resources through distributed processing. Thanks to the technology used, this tool
can be used on commodity hardware in a local area network, in a dedicated computing
cluster or cloud environment.},
  articleno = {20},
  doi       = {10.1145/3352700.3352720},
  isbn      = {9781450376365},
  keywords  = {Network Forensics, Distributed Computing, Network Traffic Processing},
  location  = {Bucharest, Romania},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3352700.3352720},
}

@InProceedings{Zhao2020,
  author    = {Zhao, Benjamin Zi Hao and Kaafar, Mohamed Ali and Kourtellis, Nicolas},
  booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Cloud Computing Security Workshop},
  title     = {Not One but Many Tradeoffs: Privacy Vs. Utility in Differentially Private Machine Learning},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {15–26},
  publisher = {Association for Computing Machinery},
  series    = {CCSW'20},
  abstract  = {Data holders are increasingly seeking to protect their user's privacy, whilst still
maximizing their ability to produce machine learning (ML) models with high quality
predictions. In this work, we empirically evaluate various implementations of differential
privacy (DP), and measure their ability to fend off real-world privacy attacks, in
addition to measuring their core goal of providing accurate classifications. We establish
an evaluation framework to ensure each of these implementations are fairly evaluated.
Our selection of DP implementations add DP noise at different positions within the
framework, either at the point of data collection/release, during updates while training
of the model, or after training by perturbing learned model parameters. We evaluate
each implementation across a range of privacy budgets and datasets, each implementation
providing the same mathematical privacy guarantees. By measuring the models' resistance
to real world attacks of membership and attribute inference, and their classification
accuracy. we determine which implementations provide the most desirable tradeoff between
privacy and utility. We found that the number of classes of a given dataset is unlikely
to influence where the privacy and utility tradeoff occurs, a counter-intuitive inference
in contrast to the known relationship of increased privacy vulnerability in datasets
with more classes. Additionally, in the scenario that high privacy constraints are
required, perturbing input training data before applying ML modeling does not trade
off as much utility, as compared to noise added later in the ML process.},
  doi       = {10.1145/3411495.3421352},
  isbn      = {9781450380843},
  keywords  = {tradeoff, membership inference attack, privacy, differential privacy attack, machine learning, utility, attribute inference attack, privacy attack},
  location  = {Virtual Event, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3411495.3421352},
}

@InProceedings{Block2015,
  author    = {Block, Kenneth and Noubir, Guevara},
  booktitle = {Proceedings of the 2015 ACM Workshop on Cloud Computing Security Workshop},
  title     = {Return of the Covert Channel, Data Center Style},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {17–28},
  publisher = {Association for Computing Machinery},
  series    = {CCSW '15},
  abstract  = {This work characterizes an interference-based covert timing channel in a highly virtualized,
active data center. The adversary leaks sensitive data from a compromised machine
without any direct TCP/IP communication pathway between it and the channel's external
sink. The attack exploits a publicly facing innocuous and uncompromised commercial
server in a shared resources attack. This victimized server unwittingly partakes in
a stealthy operation by providing the exfiltration medium. The channel exhibits a
one bit per second data rate that can increase proportionally with the decrease in
the victim's content transmission time. The channel operates 24x7 in a major university's
Computer Science department's data center that experiences highly dynamic loads. Bit
Error Rate and capacity are evaluated with the application of spreading gain, a technique
used in wireless spread spectrum designs. Additionally, time synchronization drift
characterization and channel tolerance to clock skew are demonstrated. A technique
for identifying symbol discrimination thresholds requiring no a priori knowledge of
truth is demonstrated.},
  doi       = {10.1145/2808425.2808433},
  isbn      = {9781450338257},
  keywords  = {network security, cloud security, data center networks, virtualization and security, distributed systems security},
  location  = {Denver, Colorado, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2808425.2808433},
}

@InProceedings{Checkoway2016,
  author    = {Checkoway, Stephen and Maskiewicz, Jacob and Garman, Christina and Fried, Joshua and Cohney, Shaanan and Green, Matthew and Heninger, Nadia and Weinmann, Ralf-Philipp and Rescorla, Eric and Shacham, Hovav},
  booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {A Systematic Analysis of the Juniper Dual EC Incident},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {468–479},
  publisher = {Association for Computing Machinery},
  series    = {CCS '16},
  abstract  = {In December 2015, Juniper Networks announced multiple security vulnerabilities stemming
from unauthorized code in ScreenOS, the operating system for their NetScreen VPN routers.
The more sophisticated of these vulnerabilities was a passive VPN decryption capability,
enabled by a change to one of the elliptic curve points used by the Dual EC pseudorandom
number generator. In this paper, we describe the results of a full independent analysis
of the ScreenOS randomness and VPN key establishment protocol subsystems, which we
carried out in response to this incident. While Dual EC is known to be insecure against
an attacker who can choose the elliptic curve parameters, Juniper had claimed in 2013
that ScreenOS included countermeasures against this type of attack. We find that,
contrary to Juniper's public statements, the ScreenOS VPN implementation has been
vulnerable since 2008 to passive exploitation by an attacker who selects the Dual
EC curve point. This vulnerability arises due to apparent flaws in Juniper's countermeasures
as well as a cluster of changes that were all introduced concurrently with the inclusion
of Dual EC in a single 2008 release. We demonstrate the vulnerability on a real NetScreen
device by modifying the firmware to install our own parameters, and we show that it
is possible to passively decrypt an individual VPN session in isolation without observing
any other network traffic. We investigate the possibility of passively fingerprinting
ScreenOS implementations in the wild. This incident is an important example of how
guidelines for random number generation, engineering, and validation can fail in practice.},
  doi       = {10.1145/2976749.2978395},
  isbn      = {9781450341394},
  keywords  = {VPN, dual EC DRBG, pseudorandom number generator, juniper},
  location  = {Vienna, Austria},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2976749.2978395},
}

@Article{RodriguezGomez2013,
  author     = {Rodr\'{\i}guez-G\'{o}mez, Rafael A. and Maci\'{a}-Fern\'{a}ndez, Gabriel and Garc\'{\i}a-Teodoro, Pedro},
  journal    = {ACM Comput. Surv.},
  title      = {Survey and Taxonomy of Botnet Research through Life-Cycle},
  year       = {2013},
  issn       = {0360-0300},
  month      = aug,
  number     = {4},
  volume     = {45},
  abstract   = {Of all current threats to cybersecurity, botnets are at the top of the list. In consequence,
interest in this problem is increasing rapidly among the research community and the
number of publications on the question has grown exponentially in recent years. This
article proposes a taxonomy of botnet research and presents a survey of the field
to provide a comprehensive overview of all these contributions. Furthermore, we hope
to provide researchers with a clear perspective of the gaps that remain to be filled
in our defenses against botnets. The taxonomy is based upon the botnet's life-cycle,
defined as the sequence of stages a botnet needs to pass through in order to reach
its goal.This approach allows us to consider the problem of botnets from a global
perspective, which constitutes a key difference from other taxonomies that have been
proposed. Under this novel taxonomy, we conclude that all attempts to defeat botnets
should be focused on one or more stages of this life-cycle. In fact, the sustained
hindering of any of the stages makes it possible to thwart a botnet's progress and
thus render it useless. We test the potential capabilities of our taxonomy by means
of a survey of current botnet research, and find it genuinely useful in understanding
the focus of the different contributions in this field.},
  address    = {New York, NY, USA},
  articleno  = {45},
  doi        = {10.1145/2501654.2501659},
  issue_date = {August 2013},
  keywords   = {taxonomy, botnet, defense, survey, Attack, detection},
  numpages   = {33},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2501654.2501659},
}

@InProceedings{Zhan2020,
  author    = {Zhan, Xian and Fan, Lingling and Liu, Tianming and Chen, Sen and Li, Li and Wang, Haoyu and Xu, Yifei and Luo, Xiapu and Liu, Yang},
  booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
  title     = {Automated Third-Party Library Detection for Android Applications: Are We There Yet?},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {919–930},
  publisher = {Association for Computing Machinery},
  series    = {ASE '20},
  abstract  = {Third-party libraries (TPLs) have become a significant part of the Android ecosystem.
Developers can employ various TPLs with different functionalities to facilitate their
app development. Unfortunately, the popularity of TPLs also brings new challenges
and even threats. TPLs may carry malicious or vulnerable code, which can infect popular
apps to pose threats to mobile users. Besides, the code of third-party libraries could
constitute noises in some downstream tasks (e.g., malware and repackaged app detection).
Thus, researchers have developed various tools to identify TPLs. However, no existing
work has studied these TPL detection tools in detail; different tools focus on different
applications with performance differences, but little is known about them.To better
understand existing TPL detection tools and dissect TPL detection techniques, we conduct
a comprehensive empirical study to fill the gap by evaluating and comparing all publicly
available TPL detection tools based on four criteria: effectiveness, efficiency, code
obfuscation-resilience capability, and ease of use. We reveal their advantages and
disadvantages based on a systematic and thorough empirical study. Furthermore, we
also conduct a user study to evaluate the usability of each tool. The results show
that LibScout outperforms others regarding effectiveness, LibRadar takes less time
than others and is also regarded as the most easy-to-use one, and LibPecker performs
the best in defending against code obfuscation techniques. We further summarize the
lessons learned from different perspectives, including users, tool implementation,
and researchers. Besides, we enhance these open-sourced tools by fixing their limitations
to improve their detection ability. We also build an extensible framework that integrates
all existing available TPL detection tools, providing online service for the research
community. We make publicly available the evaluation dataset and enhanced tools. We
believe our work provides a clear picture of existing TPL detection techniques and
also give a road-map for future directions.},
  doi       = {10.1145/3324884.3416582},
  isbn      = {9781450367684},
  keywords  = {library detection, empirical study, Android, third-party library},
  location  = {Virtual Event, Australia},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3324884.3416582},
}

@Article{Mundhenk2017,
  author     = {Mundhenk, Philipp and Paverd, Andrew and Mrowca, Artur and Steinhorst, Sebastian and Lukasiewycz, Martin and Fahmy, Suhaib A. and Chakraborty, Samarjit},
  journal    = {ACM Trans. Des. Autom. Electron. Syst.},
  title      = {Security in Automotive Networks: Lightweight Authentication and Authorization},
  year       = {2017},
  issn       = {1084-4309},
  month      = mar,
  number     = {2},
  volume     = {22},
  abstract   = {With the increasing amount of interconnections between vehicles, the attack surface
of internal vehicle networks is rising steeply. Although these networks are shielded
against external attacks, they often do not have any internal security to protect
against malicious components or adversaries who can breach the network perimeter.
To secure the in-vehicle network, all communicating components must be authenticated,
and only authorized components should be allowed to send and receive messages. This
is achieved through the use of an authentication framework. Cryptography is widely
used to authenticate communicating parties and provide secure communication channels
(e.g., Internet communication). However, the real-time performance requirements of
in-vehicle networks restrict the types of cryptographic algorithms and protocols that
may be used. In particular, asymmetric cryptography is computationally infeasible
during vehicle operation.In this work, we address the challenges of designing authentication
protocols for automotive systems. We present Lightweight Authentication for Secure
Automotive Networks (LASAN), a full lifecycle authentication approach. We describe
the core LASAN protocols and show how they protect the internal vehicle network while
complying with the real-time constraints and low computational resources of this domain.
By leveraging the fixed structure of automotive networks, we minimize bandwidth and
computation requirements. Unlike previous work, we also explain how this framework
can be integrated into all aspects of the automotive product lifecycle, including
manufacturing, vehicle maintenance, and software updates. We evaluate LASAN in two
different ways: First, we analyze the security properties of the protocols using established
protocol verification techniques based on formal methods. Second, we evaluate the
timing requirements of LASAN and compare these to other frameworks using a new highly
modular discrete event simulator for in-vehicle networks, which we have developed
for this evaluation.},
  address    = {New York, NY, USA},
  articleno  = {25},
  doi        = {10.1145/2960407},
  issue_date = {March 2017},
  keywords   = {security, lightweight, authorization, authentication, Automotive},
  numpages   = {27},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2960407},
}

@InProceedings{Wei2018,
  author    = {Wei, Jiayi and Chen, Jia and Feng, Yu and Ferles, Kostas and Dillig, Isil},
  booktitle = {Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  title     = {Singularity: Pattern Fuzzing for Worst Case Complexity},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {213–223},
  publisher = {Association for Computing Machinery},
  series    = {ESEC/FSE 2018},
  abstract  = {We describe a new blackbox complexity testing technique for determining the worst-case
asymptotic complexity of a given application. The key idea is to look for an input
pattern —rather than a concrete input— that maximizes the asymptotic resource usage
of the target program. Because input patterns can be described concisely as programs
in a restricted language, our method transforms the complexity testing problem to
optimal program synthesis. In particular, we express these input patterns using a
new model of computation called Recurrent Computation Graph (RCG) and solve the optimal
synthesis problem by developing a genetic programming algorithm that operates on RCGs.
We have implemented the proposed ideas in a tool called Singularityand evaluate it
on a diverse set of benchmarks. Our evaluation shows that Singularitycan effectively
discover the worst-case complexity of various algorithms and that it is more scalable
compared to existing state-of-the-art techniques. Furthermore, our experiments also
corroborate that Singularitycan discover previously unknown performance bugs and availability
vulnerabilities in real-world applications such as Google Guava and JGraphT.},
  doi       = {10.1145/3236024.3236039},
  isbn      = {9781450355735},
  keywords  = {genetic programming, availability vulnerability, optimal program synthesis, performance bug, fuzzing, Complexity testing},
  location  = {Lake Buena Vista, FL, USA},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3236024.3236039},
}

@InProceedings{Lu2011,
  author    = {Lu, Kangjie and Zou, Dabi and Wen, Weiping and Gao, Debin},
  booktitle = {Proceedings of the 27th Annual Computer Security Applications Conference},
  title     = {DeRop: Removing Return-Oriented Programming from Malware},
  year      = {2011},
  address   = {New York, NY, USA},
  pages     = {363–372},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '11},
  abstract  = {Over the last few years, malware analysis has been one of the hottest areas in security
research. Many techniques and tools have been developed to assist in automatic analysis
of malware. This ranges from basic tools like disassemblers and decompilers, to static
and dynamic tools that analyze malware behaviors, to automatic malware clustering
and classification techniques, to virtualization technologies to assist malware analysis,
to signature- and anomaly-based malware detection, and many others. However, most
of these techniques and tools would not work on new attacking techniques, e.g., attacks
that use return-oriented programming (ROP).In this paper, we look into the possibility
of enabling existing defense technologies designed for normal malware to cope with
malware using return-oriented programming. We discuss difficulties in removing ROP
from malware, and design and implement an automatic converter, called deRop, that
converts an ROP exploit into shellcode that is semantically equivalent with the original
ROP exploit but does not use ROP, which could then be analyzed by existing malware
defense technologies. We apply deRop on four real ROP malwares and demonstrate success
in using deRop for the automatic conversion. We further discuss applicability and
limitations of deRop.},
  doi       = {10.1145/2076732.2076784},
  isbn      = {9781450306720},
  keywords  = {malware analysis, return-oriented programming},
  location  = {Orlando, Florida, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2076732.2076784},
}

@InProceedings{Wang2019,
  author    = {Wang, Binghui and Gong, Neil Zhenqiang},
  booktitle = {Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {Attacking Graph-Based Classification via Manipulating the Graph Structure},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {2023–2040},
  publisher = {Association for Computing Machinery},
  series    = {CCS '19},
  abstract  = {Graph-based classification methods are widely used for security analytics. Roughly
speaking, graph-based classification methods include collective classification and
graph neural network. Attacking a graph-based classification method enables an attacker
to evade detection in security analytics. However, existing adversarial machine learning
studies mainly focused on machine learning for non-graph data. Only a few recent studies
touched adversarial graph-based classification methods. However, they focused on graph
neural network, leaving collective classification largely unexplored. We aim to bridge
this gap in this work. We consider an attacker's goal is to evade detection via manipulating
the graph structure. We formulate our attack as a graph-based optimization problem,
solving which produces the edges that an attacker needs to manipulate to achieve its
attack goal. However, it is computationally challenging to solve the optimization
problem exactly. To address the challenge, we propose several approximation techniques
to solve the optimization problem. We evaluate our attacks and compare them with a
recent attack designed for graph neural networks using four graph datasets. Our results
show that our attacks can effectively evade graph-based classification methods. Moreover,
our attacks outperform the existing attack for evading collective classification methods
and some graph neural network methods.},
  doi       = {10.1145/3319535.3354206},
  isbn      = {9781450367479},
  keywords  = {adversarial graph neural network, adversarial graph-based classification, adversarial machine learning},
  location  = {London, United Kingdom},
  numpages  = {18},
  url       = {https://doi.org/10.1145/3319535.3354206},
}

@InProceedings{Chen2014,
  author    = {Chen, Jie and Venkataramani, Guru},
  booktitle = {Proceedings of the Third Workshop on Hardware and Architectural Support for Security and Privacy},
  title     = {An Algorithm for Detecting Contention-Based Covert Timing Channels on Shared Hardware},
  year      = {2014},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {HASP '14},
  abstract  = {As we increasingly rely on computers to process and manage our personal data, safeguarding
sensitive information from malicious hackers is a fast growing concern. Among many
forms of information leakage, covert timing channels operate by establishing an illegitimate
communication channel between two processes and transmitting information via timing
modulation, violating the underlying system's security policy. Recent studies have
shown the vulnerability of popular computing environments, such as cloud, to these
covert timing channels. In this work, we propose an algorithm to detect the possible
presence of covert timing channels on shared hardware that use contention-based patterns
for communication. Preliminary experiments demonstrate that our algorithm is able
to successfully detect different types of covert timing channels at varying bandwidths,
message patterns, and has zero false alarms.},
  articleno = {1},
  doi       = {10.1145/2611765.2611766},
  isbn      = {9781450327770},
  location  = {Minneapolis, Minnesota, USA},
  numpages  = {8},
  url       = {https://doi.org/10.1145/2611765.2611766},
}

@InProceedings{Garcia2011,
  author    = {Garcia, Rui and Rodrigues, Rodrigo and Pregui\c{c}a, Nuno},
  booktitle = {Proceedings of the Sixth Conference on Computer Systems},
  title     = {Efficient Middleware for Byzantine Fault Tolerant Database Replication},
  year      = {2011},
  address   = {New York, NY, USA},
  pages     = {107–122},
  publisher = {Association for Computing Machinery},
  series    = {EuroSys '11},
  abstract  = {Byzantine fault tolerance (BFT) enhances the reliability and availability of replicated
systems subject to software bugs, malicious attacks, or other unexpected events. This
paper presents Byzantium, a BFT database replication middleware that provides snapshot
isolation semantics. It is the first BFT database system that allows for concurrent
transaction execution without relying on a centralized component, which is essential
for having both performance and robustness. Byzantium builds on an existing BFT library
but extends it with a set of techniques for increasing concurrency in the execution
of operations, for optimistically executing operations in a single replica, and for
striping and load-balancing read operations across replicas. Experimental results
show that our replication protocols introduce only a modest performance overhead for
read-write dominated workloads and perform better than a non-replicated database system
for read-only workloads.},
  doi       = {10.1145/1966445.1966456},
  isbn      = {9781450306348},
  keywords  = {middleware, databases, byzantine fault-tolerance},
  location  = {Salzburg, Austria},
  numpages  = {16},
  url       = {https://doi.org/10.1145/1966445.1966456},
}

@Article{Zoppi2021,
  author     = {Zoppi, Tommaso and Ceccarelli, Andrea and Capecchi, Tommaso and Bondavalli, Andrea},
  journal    = {ACM/IMS Trans. Data Sci.},
  title      = {Unsupervised Anomaly Detectors to Detect Intrusions in the Current Threat Landscape},
  year       = {2021},
  issn       = {2691-1922},
  month      = apr,
  number     = {2},
  volume     = {2},
  abstract   = {Anomaly detection aims at identifying unexpected fluctuations in the expected behavior
of a given system. It is acknowledged as a reliable answer to the identification of
zero-day attacks to such extent, several ML algorithms that suit for binary classification
have been proposed throughout years. However, the experimental comparison of a wide
pool of unsupervised algorithms for anomaly-based intrusion detection against a comprehensive
set of attacks datasets was not investigated yet. To fill such gap, we exercise 17
unsupervised anomaly detection algorithms on 11 attack datasets. Results allow elaborating
on a wide range of arguments, from the behavior of the individual algorithm to the
suitability of the datasets to anomaly detection. We conclude that algorithms as Isolation
Forests, One-Class Support Vector Machines, and Self-Organizing Maps are more effective
than their counterparts for intrusion detection, while clustering algorithms represent
a good alternative due to their low computational complexity. Further, we detail how
attacks with unstable, distributed, or non-repeatable behavior such as Fuzzing, Worms,
and Botnets are more difficult to detect. Ultimately, we digress on capabilities of
algorithms in detecting anomalies generated by a wide pool of unknown attacks, showing
that achieved metric scores do not vary with respect to identifying single attacks.},
  address    = {New York, NY, USA},
  articleno  = {7},
  doi        = {10.1145/3441140},
  issue_date = {April 2021},
  keywords   = {unsupervised algorithms, attacks datasets, Anomaly detection, intrusion detection, comparison, machine learning},
  numpages   = {26},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3441140},
}

@InProceedings{Hilbig2021,
  author    = {Hilbig, Aaron and Lehmann, Daniel and Pradel, Michael},
  booktitle = {Proceedings of the Web Conference 2021},
  title     = {An Empirical Study of Real-World WebAssembly Binaries: Security, Languages, Use Cases},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {2696–2708},
  publisher = {Association for Computing Machinery},
  series    = {WWW '21},
  abstract  = {WebAssembly has emerged as a low-level language for the web and beyond. Despite its
popularity in different domains, little is known about WebAssembly binaries that occur
in the wild. This paper presents a comprehensive empirical study of 8,461 unique WebAssembly
binaries gathered from a wide range of sources, including source code repositories,
package managers, and live websites. We study the security properties, source languages,
and use cases of the binaries and how they influence the security of the WebAssembly
ecosystem. Our findings update some previously held assumptions about real-world WebAssembly
and highlight problems that call for future research. For example, we show that vulnerabilities
that propagate from insecure source languages potentially affect a wide range of binaries
(e.g., two thirds of the binaries are compiled from memory unsafe languages, such
as C and C++) and that 21% of all binaries import potentially dangerous APIs from
their host environment. We also show that cryptomining, which once accounted for the
majority of all WebAssembly code, has been marginalized (less than 1% of all binaries
found on the web) and gives way to a diverse set of use cases. Finally, 29% of all
binaries on the web are minified, calling for techniques to decompile and reverse
engineer WebAssembly. Overall, our results show that WebAssembly has left its infancy
and is growing up into a language that powers a diverse ecosystem, with new challenges
and opportunities for security researchers and practitioners. Besides these insights,
we also share the dataset underlying our study, which is 58 times larger than the
largest previously reported benchmark.},
  doi       = {10.1145/3442381.3450138},
  isbn      = {9781450383127},
  location  = {Ljubljana, Slovenia},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3442381.3450138},
}

@InProceedings{Zand2014,
  author    = {Zand, Ali and Vigna, Giovanni and Yan, Xifeng and Kruegel, Christopher},
  booktitle = {Proceedings of the 29th Annual ACM Symposium on Applied Computing},
  title     = {Extracting Probable Command and Control Signatures for Detecting Botnets},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {1657–1662},
  publisher = {Association for Computing Machinery},
  series    = {SAC '14},
  abstract  = {Botnets, which are networks of compromised machines under the control of a single
malicious entity, are a serious threat to online security. The fact that botnets,
by definition, receive their commands from a single entity can be leveraged to fight
them. To this end, one requires techniques that can detect command and control (C&amp;C)
traffic, as well as the servers that host C&amp;C services. Given the knowledge of a C&amp;C
server's IP address, one can use this information to detect all hosts that attempt
to contact such a server, and subsequently disinfect, disable, or block the infected
machines. This information can also be used by law enforcement to take down the C&amp;C
server.In this paper, we present a new botnet C&amp;C signature extraction approach that
can be used to find C&amp;C communication in traffic generated by executing malware samples
in a dynamic analysis system. This approach works in two steps. First, we extract
all frequent strings seen in the network traffic. Second, we use a function that assigns
a score to each string. This score represents the likelihood that the string is indicative
of C&amp;C traffic. This function allows us to rank strings and focus our attention on
those that likely represent good C&amp;C signatures. We apply our technique to almost
2.6 million network connections produced by running more than 1.4 million malware
samples. Using our technique, we were able to automatically extract a set of signatures
that are able to identify C&amp;C traffic. Furthermore, we compared our signatures with
those used by existing tools, such as Snort and BotHunter.},
  doi       = {10.1145/2554850.2554896},
  isbn      = {9781450324694},
  location  = {Gyeongju, Republic of Korea},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2554850.2554896},
}

@InProceedings{Allen2011,
  author    = {Allen, Josef and Ty, Sereyvathana and Liu, Xiuwen and Lozano, Ivan},
  booktitle = {Proceedings of the Seventh Annual Workshop on Cyber Security and Information Intelligence Research},
  title     = {Preventing Cascading Event: A Distributed Cyber-Physical Approach},
  year      = {2011},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {CSIIRW '11},
  articleno = {54},
  doi       = {10.1145/2179298.2179358},
  isbn      = {9781450309455},
  location  = {Oak Ridge, Tennessee, USA},
  numpages  = {1},
  url       = {https://doi.org/10.1145/2179298.2179358},
}

@InProceedings{He2017,
  author    = {He, Liang and Li, Zhixiang and Shen, Chao},
  booktitle = {Proceedings of the ACM Turing 50th Celebration Conference - China},
  title     = {Performance Evaluation of Anomaly-Detection Algorithm for Keystroke-Typing Based Insider Detection},
  year      = {2017},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ACM TUR-C '17},
  abstract  = {Keystroke dynamics is the process to identify or authenticate individuals based on
the typing rhythm behaviors. There are many classifications proposed to check the
user's legitimacy, and therefore we should make it clear how they perform in order
to confirm promising research direction. Nevertheless, these researches provide experiments
in different situations such as datasets, conditions and methodologies as well. This
paper aims to benchmark the algorithms in the same dataset and feature in order to
measure the performance on an equal level. Using dataset containing 51 subjects' typing
rhythm, we implemented and evaluated 13 classifiers measured by F1-measure. We also
develop a way to process the typing data, and test it on these algorithms. Considering
the case that the model should reject outlander, we test the algorithms on open set.
The top-performing classifier achieves F1-measure rates 0.92 when using 50 subjects'
typing normalized data to train and the remaining one to test. The results, along
with the normalization methodology, constitute a benchmark for comparing classifiers
and measuring performance of keystroke dynamics for insider detection.},
  articleno = {32},
  doi       = {10.1145/3063955.3063987},
  isbn      = {9781450348737},
  keywords  = {F1-measure, normalization, insider identification, keystroke dynamics},
  location  = {Shanghai, China},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3063955.3063987},
}

@InProceedings{Peng2014,
  author    = {Peng, Chunyi and Li, Chi-Yu and Wang, Hongyi and Tu, Guan-Hua and Lu, Songwu},
  booktitle = {Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {Real Threats to Your Data Bills: Security Loopholes and Defenses in Mobile Data Charging},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {727–738},
  publisher = {Association for Computing Machinery},
  series    = {CCS '14},
  abstract  = {Secure mobile data charging (MDC) is critical to cellular network operations. It must
charge the right user for the right volume that (s)he authorizes to consume (i.e.,
requirements of authentication, authorization, and accounting (AAA)). In this work,
we conduct security analysis of the MDC system in cellular networks. We find that
all three can be breached in both design and practice, and identify three concrete
vulnerabilities: authentication bypass, authorization fraud and accounting volume
inaccuracy. The root causes lie in technology fundamentals of cellular networks and
the Internet IP design, as well as imprudent implementations. We devise three showcase
attacks to demonstrate that, even simple attacks can easily penetrate the operational
3G/4G cellular networks. We further propose and evaluate defense solutions.},
  doi       = {10.1145/2660267.2660346},
  isbn      = {9781450329576},
  keywords  = {authentication, aaa, defense, mobile data services, accounting, authorization, cellular networks, attack},
  location  = {Scottsdale, Arizona, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2660267.2660346},
}

@InProceedings{Speicher2019,
  author    = {Speicher, Patrick and Steinmetz, Marcel and Hoffmann, J\"{o}rg and Backes, Michael and K\"{u}nnemann, Robert},
  booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
  title     = {Towards Automated Network Mitigation Analysis},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {1971–1978},
  publisher = {Association for Computing Machinery},
  series    = {SAC '19},
  abstract  = {Penetration testing is a well-established practical concept for the identification
of potentially exploitable security weaknesses and an important component of a security
audit. Providing a holistic security assessment for networks consisting of several
hundreds hosts is hardly feasible though without some sort of mechanization. Mitigation,
prioritizing counter-measures subject to a given budget, currently lacks a solid theoretical
understanding and is hence more art than science. In this work, we propose the first
approach for conducting comprehensive what-if analyses in order to reason about mitigation
in a conceptually well-founded manner. To evaluate and compare mitigation strategies,
we use simulated penetration testing, i.e., automated attack-finding, based on a network
model to which a subset of a given set of mitigation actions, e.g., changes to the
network topology, system updates, configuration changes etc. is applied. Using Stackelberg
planning, we determine optimal combinations that minimize the maximal attacker success
(similar to a Stackelberg game), and thus provide a well-founded basis for a holistic
mitigation strategy. We show that these Stackelberg planning models can largely be
derived from network scan, public vulnerability databases and manual inspection with
various degrees of automation and detail, and we simulate mitigation analysis on networks
of different size and vulnerability.},
  doi       = {10.1145/3297280.3297473},
  isbn      = {9781450359337},
  keywords  = {planning, network security, simulated penetration testing},
  location  = {Limassol, Cyprus},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3297280.3297473},
}

@InProceedings{Raimbault2013,
  author    = {Raimbault, F\'{e}lix and Piti\'{e}, Fran\c{c}ois and Kokaram, Anil},
  booktitle = {Proceedings of the 10th European Conference on Visual Media Production},
  title     = {User-Assisted Sparse Stereo-Video Segmentation},
  year      = {2013},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {CVMP '13},
  abstract  = {Motion-based video segmentation has been studied for many years and remains challenging.
Ill-posed problems must be solved when seeking for a fully automated solution, so
it is increasingly popular to maintain users in the processing loop by letting them
set parameters or draw mattes to guide the segmentation process. When processing multiple-view
videos, however, the amount of user interaction should not be proportional to the
number of views. In this paper we present a novel sparse segmentation algorithm for
two-view stereoscopic videos that maintains temporal coherence and view consistency
throughout. We track feature points on both views with a generic tracker and analyse
the pairwise affinity of both temporally overlapping and disjoint tracks, whereas
existing similar techniques only exploit the information available when tracks overlap.
The use of stereo-disparity also allows our technique to process jointly feature tracks
on both views, exhibiting a good view consistency in the segmentation output. To make
up for the lack of high level understanding inherent to segmentation techniques, we
allow the user to refine the output with a split-and-merge approach so as to obtain
a desired view-consistent segmentation output over many frames in a few clicks. We
present several real video examples to illustrate the versatility of our technique.},
  articleno = {3},
  doi       = {10.1145/2534008.2534027},
  isbn      = {9781450325899},
  keywords  = {user interaction, motion segmentation, sparse, stereoscopic video},
  location  = {London, United Kingdom},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2534008.2534027},
}

@InProceedings{Bortoli2016,
  author    = {Bortoli, Stefano and Bouquet, Paolo and Pompermaier, Flavio and Molinari, Andrea},
  booktitle = {Proceedings of the International Workshop on Semantic Big Data},
  title     = {Semantic Big Data for Tax Assessment},
  year      = {2016},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {SBD '16},
  abstract  = {Semantic Big Data is about the creation of new applications exploiting the richness
and flexibility of declarative semantics combined with scalable and highly distributed
data management systems. In this work, we present an application scenario in which
a domain ontology, Open Refine and the Okkam Entity Name System enable a frictionless
and scalable data integration process leading to a knowledge base for tax assessment.
Further, we introduce the concept of Entiton as a flexible and efficient data model
suitable for large scale data inference and analytic tasks. We successfully tested
our data processing pipeline on a real world dataset, supporting ACI Informatica in
the investigation for Vehicle Excise Duty (VED) evasion in Aosta Valley region (Italy).
Besides useful business intelligence indicators, we implemented a distributed temporal
inference engine to unveil VED evasion and circulation ban violations. The results
of the integration are presented to the tax agents in a powerful Siren Solution KiBi
dashboard, enabling seamless data exploration and business intelligence.},
  articleno = {5},
  doi       = {10.1145/2928294.2928297},
  isbn      = {9781450342995},
  keywords  = {semantic big data, entity name system, inference, tax assessment},
  location  = {San Francisco, California},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2928294.2928297},
}

@Article{Bonchi2011,
  author     = {Bonchi, Francesco and Lakshmanan, Laks V.S. and Wang, Hui (Wendy)},
  journal    = {SIGKDD Explor. Newsl.},
  title      = {Trajectory Anonymity in Publishing Personal Mobility Data},
  year       = {2011},
  issn       = {1931-0145},
  month      = aug,
  number     = {1},
  pages      = {30–42},
  volume     = {13},
  abstract   = {Recent years have witnessed pervasive use of location-aware devices such as GSM mobile
phones, GPS-enabled PDAs, location sensors, and active RFID tags. The use of these
devices generates a huge collection of spatio-temporal data, variously called moving
object data, trajectory data, or moblity data. These data can be used for various
data analysis purposes such as city traffic control, mobility management, urban planning,
and location-based service advertisements. Clearly, the spatio-temporal data so collected
may help an attacker to discover personal and sensitive information like user habits,
social customs, religious and sexual preferences of individuals. Consequently, it
raises serious concerns about privacy. Simply replacing users' real identifiers (name,
SSN, etc.) with pseudonyms is insufficient to guarantee anonymity. The problem is
that due to the existence of quasi-identifiers, i.e., spatio-temporal data points
that can be linked to external information to re-identify individuals, the attacker
may be able to trace the anonymous spatio-temporal data back to individuals.In this
survey, we discuss recent advancement on anonymity preserving data publishing of moving
object databases in an off-line fashion. We first introduce several anonymity models,
then we describe in detail some of the proposed techniques to enforce trajectory anonymity,
discussing their merits and limitations. We conclude by identifying challenging open
problems that need attention.},
  address    = {New York, NY, USA},
  doi        = {10.1145/2031331.2031336},
  issue_date = {June 2011},
  numpages   = {13},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2031331.2031336},
}

@InProceedings{Harbort2011,
  author    = {Harbort, Zach and Louthan, G. and Hale, J.},
  booktitle = {Proceedings of the Seventh Annual Workshop on Cyber Security and Information Intelligence Research},
  title     = {Techniques for Attack Graph Visualization and Interaction},
  year      = {2011},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {CSIIRW '11},
  abstract  = {Attack graphs provide a comprehensive overview of attack vectors. Unfortunately, their
complexity dramatically increases as the number of hosts in a network grows. For realistic
networks, the human eye cannot discern the state of a network without tracing individual
attack paths. In order to combat this complexity, we discuss and implement mitigation
techniques and the use of collaborative multi-touch environments for an intuitive,
natural approach to visual analytics.},
  articleno = {74},
  doi       = {10.1145/2179298.2179383},
  isbn      = {9781450309455},
  location  = {Oak Ridge, Tennessee, USA},
  numpages  = {1},
  url       = {https://doi.org/10.1145/2179298.2179383},
}

@InProceedings{Alshraa2019,
  author    = {Alshra'a, Abdullah Soliman and Seitz, Jochen},
  booktitle = {Proceedings of the 3rd International Conference on Future Networks and Distributed Systems},
  title     = {External Device to Protect the Software-Defined Network Performance in Case of a Malicious Attack},
  year      = {2019},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ICFNDS '19},
  abstract  = {Many security analyses argue that the Software-Defined Network (SDNs) framework has
many vulnerabilities because SDN provides malicious users an easy opportunity to overload
network resources. Typically, the malicious user directs the attack towards the network
layer, especially the controller plane which acts as the core of the network. However,
the attack is redirected to the application layer when the attacker is defeated in
the network layer. This paper proposes to extend the SDN controller with an external
device to improve the SDN architecture and to protect the service level of the SDN
components against malicious attacks. Simulation results show that the proposal successfully
protects Web servers against Slow HTTP DDoS attacks.},
  articleno = {25},
  doi       = {10.1145/3341325.3342016},
  isbn      = {9781450371636},
  keywords  = {Distributed Denial of Service (DDoS) Attack, SDN Security, Software Defined Network (SDN)},
  location  = {Paris, France},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3341325.3342016},
}

@InProceedings{Findling2019,
  author    = {Findling, Rainhard Dieter and Quddus, Tahmid and Sigg, Stephan},
  booktitle = {Proceedings of the 17th International Conference on Advances in Mobile Computing &amp; Multimedia},
  title     = {Hide My Gaze with EOG! Towards Closed-Eye Gaze Gesture Passwords That Resist Observation-Attacks with Electrooculography in Smart Glasses},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {107–116},
  publisher = {Association for Computing Machinery},
  series    = {MoMM2019},
  abstract  = {Smart glasses allow for gaze gesture passwords as a hands-free form of mobile authentication.
However, pupil movements for password input are easily observed by attackers, who
thereby can derive the password. In this paper we investigate closed-eye gaze gesture
passwords with EOG sensors in smart glasses. We propose an approach to detect and
recognize closed-eye gaze gestures, together with a 7 and 9 character gaze gesture
alphabet. Our evaluation indicates good gaze gesture detection rates. However, recognition
is challenging specifically for vertical eye movements with 71.2%-86.5% accuracy and
better results for opened than closed eyes. We further find that closed-eye gaze gesture
passwords are difficult to attack from observations with 0% success rate in our evaluation,
while attacks on open eye passwords succeed with 61%. This indicates that closed-eye
gaze gesture passwords protect the authentication secret significantly better than
their open eye counterparts.},
  doi       = {10.1145/3365921.3365922},
  isbn      = {9781450371780},
  keywords  = {password, EOG sensors, mobile, Authentication, closed-eye, gaze gestures, smart glasses, hands-free},
  location  = {Munich, Germany},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3365921.3365922},
}

@InProceedings{Shan2017,
  author    = {Shan, Huasong and Wang, Qingyang and Pu, Calton},
  booktitle = {Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {Tail Attacks on Web Applications},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {1725–1739},
  publisher = {Association for Computing Machinery},
  series    = {CCS '17},
  abstract  = {As the extension of Distributed Denial-of-Service (DDoS) attacks to application layer
in recent years, researchers pay much interest in these new variants due to a low-volume
and intermittent pattern with a higher level of stealthiness, invaliding the state-of-the-art
DDoS detection/defense mechanisms. We describe a new type of low-volume application
layer DDoS attack--Tail Attacks on Web Applications. Such attack exploits a newly
identified system vulnerability of n-tier web applications (millibottlenecks with
sub-second duration and resource contention with strong dependencies among distributed
nodes) with the goal of causing the long-tail latency problem of the target web application
(e.g., 95th percentile response time &gt; 1 second) and damaging the long-term business
of the service provider, while all the system resources are far from saturation, making
it difficult to trace the cause of performance degradation.We present a modified queueing
network model to analyze the impact of our attacks in n-tier architecture systems,
and numerically solve the optimal attack parameters. We adopt a feedback control-theoretic
(e.g., Kalman filter) framework that allows attackers to fit the dynamics of background
requests or system state by dynamically adjusting attack parameters. To evaluate the
practicality of such attacks, we conduct extensive validation through not only analytical,
numerical, and simulation results but also real cloud production setting experiments
via a representative benchmark website equipped with state-of-the-art DDoS defense
tools. We further proposed a solution to detect and defense the proposed attacks,
involving three stages: fine-grained monitoring, identifying bursts, and blocking
bots.},
  doi       = {10.1145/3133956.3133968},
  isbn      = {9781450349468},
  keywords  = {long-tail latency, n-tier systems, web attack, ddos attack, milli-bottleneck, pulsating attack},
  location  = {Dallas, Texas, USA},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3133956.3133968},
}

@InProceedings{Emura2017,
  author    = {Emura, Keita and Hayashi, Takuya and Ishida, Ai},
  booktitle = {Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security},
  title     = {Group Signatures with Time-Bound Keys Revisited: A New Model and an Efficient Construction},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {777–788},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '17},
  abstract  = {Chu et al. (ASIACCS 2012) proposed group signature with time-bound keys (GS-TBK) where
each signing key is associated to an expiry time τ. In addition to prove the membership
of the group, a signer needs to prove that the expiry time has not passed, i.e., t&lt;τ
where t is the current time. A signer whose expiry time has passed is automatically
revoked, and this revocation is called natural revocation. Simultaneously, signers
can be revoked before their expiry times have passed due to the compromise of the
credential. This revocation is called premature revocation. A nice property of the
Chu et al. proposal is that the size of revocation lists can be reduced compared to
those of Verifier-Local Revocation (VLR) group signature schemes, by assuming that
natural revocation accounts for most of signer revocations in practice, and prematurely
revoked signers are only a small fraction. In this paper, we point out that the definition
of traceability of Chu et al. did not capture unforgeability of expiry time of signing
keys which guarantees that no adversary who has a signing key associated to an expiry
time τ can compute a valid signature after τ has passed. We introduce a security model
that captures unforgeability, and propose a GS-TBK scheme secure in the new model.
Our scheme also provides the constant signing costs whereas those of the previous
schemes depend on the bit-length of the time representation. Finally, we give implementation
results, and show that our scheme is feasible in practical settings.},
  doi       = {10.1145/3052973.3052979},
  isbn      = {9781450349444},
  keywords  = {group signatures, time-bound keys, revocation},
  location  = {Abu Dhabi, United Arab Emirates},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3052973.3052979},
}

@InProceedings{Wu2020,
  author    = {Wu, Tingmin and Zhang, Rongjunchen and Ma, Wanlun and Wen, Sheng and Xia, Xin and Paris, Cecile and Nepal, Surya and Xiang, Yang},
  booktitle = {Proceedings of the 15th ACM Asia Conference on Computer and Communications Security},
  title     = {What Risk? I Don't Understand. An Empirical Study on Users' Understanding of the Terms Used in Security Texts},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {248–262},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '20},
  abstract  = {Users receive a multitude of security information in written articles, e.g., newspapers,
security blogs, and training materials. However, prior research suggests that these
delivery methods, including security awareness campaigns, mostly fail to increase
people's knowledge about cyber threats. It seems that users find such information
challenging to absorb and understand. Yet, to raise users' security awareness and
understanding, it is essential to ensure the users comprehend the provided information
so that they can apply the advice it contains in practice. We conducted a subjective
study to measure the level of users' understanding of security texts. We find that
61% of the terms security experts used in their writings are hard for the public to
understand, even for people with some IT backgrounds. We also observe that 88% of
security texts have at least one such term. Moreover, we notice that existing dictionaries,
including the online ones (e.g., Google Dictionary), cover no more than 35% of the
terms found in security texts. To improve users' ability to understand security texts,
we developed a framework to build a user-oriented security-centric dictionary from
multiple sources. To evaluate the effectiveness of the dictionary, we developed a
tool as a service to detect technical terms and explain their meanings to the user
in pop-ups. The results of a subjective study to measure the tool's performance showed
that it could increase users' ability to understand security articles by 30%.},
  doi       = {10.1145/3320269.3384761},
  isbn      = {9781450367509},
  keywords  = {user study, user security awareness, security term explanation},
  location  = {Taipei, Taiwan},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3320269.3384761},
}

@InProceedings{Fraser2017,
  author    = {Fraser, Olivia Lucca and Zincir-Heywood, Nur and Heywood, Malcolm and Jacobs, John T.},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
  title     = {Return-Oriented Programme Evolution with ROPER: A Proof of Concept},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {1447–1454},
  publisher = {Association for Computing Machinery},
  series    = {GECCO '17},
  abstract  = {Return-orientated programming (ROP) identifies code snippets ending in a return instruction
(gadgets) and chains them together to construct exploits. Gadgets are already present
in executable memory, thus avoiding the need to explicitly inject new code. As such
ROP represents one of the most difficult exploit mechanisms to mitigate. ROP design
is essentially driven by the skill of human hacker, limiting the ability of exploit
mitigation to reacting to attacks. In this work we describe an evolutionary approach
to ROP design, thus potentially pointing to the automatic detection of vulnerabilities
before application code is released.},
  doi       = {10.1145/3067695.3082508},
  isbn      = {9781450349390},
  keywords  = {exploit development, genetic programming, ROP attacks, ARM architecture},
  location  = {Berlin, Germany},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3067695.3082508},
}

@InProceedings{He2019,
  author    = {He, Huan and Henderson, Jette and Ho, Joyce C},
  booktitle = {The World Wide Web Conference},
  title     = {Distributed Tensor Decomposition for Large Scale Health Analytics},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {659–669},
  publisher = {Association for Computing Machinery},
  series    = {WWW '19},
  abstract  = {In the past few decades, there has been rapid growth in quantity and variety of healthcare
data. These large sets of data are usually high dimensional (e.g. patients, their
diagnoses, and medications to treat their diagnoses) and cannot be adequately represented
as matrices. Thus, many existing algorithms can not analyze them. To accommodate these
high dimensional data, tensor factorization, which can be viewed as a higher-order
extension of methods like PCA, has attracted much attention and emerged as a promising
solution. However, tensor factorization is a computationally expensive task, and existing
methods developed to factor large tensors are not flexible enough for real-world situations.
To address this scaling problem more efficiently, we introduce SGranite, a distributed,
scalable, and sparse tensor factorization method fit through stochastic gradient descent.
SGranite offers three contributions: (1) Scalability: it employs a block partitioning
and parallel processing design and thus scales to large tensors, (2) Accuracy: we
show that our method can achieve results faster without sacrificing the quality of
the tensor decomposition, and (3) FlexibleConstraints: we show our approach can encompass
various kinds of constraints including l2 norm, l1 norm, and logistic regularization.
We demonstrate SGranite's capabilities in two real-world use cases. In the first,
we use Google searches for flu-like symptoms to characterize and predict influenza
patterns. In the second, we use SGranite to extract clinically interesting sets (i.e.,
phenotypes) of patients from electronic health records. Through these case studies,
we show SGranite has the potential to be used to rapidly characterize, predict, and
manage a large multimodal datasets, thereby promising a novel, data-driven solution
that can benefit very large segments of the population.},
  doi       = {10.1145/3308558.3313548},
  isbn      = {9781450366748},
  keywords  = {Distributed Algorithm, Tensor Decomposition, Web Mining, Health Analytics, User-Generated Content, Apache Spark},
  location  = {San Francisco, CA, USA},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3308558.3313548},
}

@InProceedings{Liu2016,
  author    = {Liu, Daiping and Hao, Shuai and Wang, Haining},
  booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {All Your DNS Records Point to Us: Understanding the Security Threats of Dangling DNS Records},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {1414–1425},
  publisher = {Association for Computing Machinery},
  series    = {CCS '16},
  abstract  = {In a dangling DNS record (Dare), the resources pointed to by the DNS record are invalid,
but the record itself has not yet been purged from DNS. In this paper, we shed light
on a largely overlooked threat in DNS posed by dangling DNS records. Our work reveals
that Dare can be easily manipulated by adversaries for domain hijacking. In particular,
we identify three attack vectors that an adversary can harness to exploit Dares. In
a large-scale measurement study, we uncover 467 exploitable Dares in 277 Alexa top
10,000 domains and 52 edu zones, showing that Dare is a real, prevalent threat. By
exploiting these Dares, an adversary can take full control of the (sub)domains and
can even have them signed with a Certificate Authority (CA). It is evident that the
underlying cause of exploitable Dares is the lack of authenticity checking for the
resources to which that DNS record points. We then propose three defense mechanisms
to effectively mitigate Dares with little human effort.},
  doi       = {10.1145/2976749.2978387},
  isbn      = {9781450341394},
  keywords  = {dangling records, DNS, domain hijacking},
  location  = {Vienna, Austria},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2976749.2978387},
}

@InProceedings{Wang2018,
  author    = {Wang, Ningfei and Ji, Shouling and Wang, Ting},
  booktitle = {Proceedings of the 11th ACM Workshop on Artificial Intelligence and Security},
  title     = {Integration of Static and Dynamic Code Stylometry Analysis for Programmer De-Anonymization},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {74–84},
  publisher = {Association for Computing Machinery},
  series    = {AISec '18},
  abstract  = {De-anonymizing the authors of anonymous code (i.e., code stylometry) entails significant
privacy and security implications. Most existing code stylometry methods solely rely
on static (e.g., lexical, layout, and syntactic) features extracted from source code,
while neglecting its key difference from regular text -- it is executable! In this
paper, we present Sundae, a novel code de-anonymization framework that integrates
both static and dynamic stylometry analysis. Compared with the existing solutions,
Sundae departs in significant ways: (i) it requires much less number of static, hand-crafted
features; (ii) it requires much less labeled data for training; and (iii) it can be
readily extended to new programmers once their stylometry information becomes available
Through extensive evaluation on benchmark datasets, we demonstrate that Sundae delivers
strong empirical performance. For example, under the setting of 229 programmers and
9 problems, it outperforms the state-of-art method by a margin of 45.65% on Python
code de-anonymization. The empirical results highlight the integration of static and
dynamic analysis as a promising direction for code stylometry research.},
  doi       = {10.1145/3270101.3270110},
  isbn      = {9781450360043},
  keywords  = {code stylometry, dynamic analysis, de-anonymization},
  location  = {Toronto, Canada},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3270101.3270110},
}

@InProceedings{Duan2019,
  author    = {Duan, Jun and Hamlen, Kevin W. and Ferrell, Benjamin},
  booktitle = {Proceedings of the 28th International Symposium on High-Performance Parallel and Distributed Computing},
  title     = {Better Late Than Never: An n-Variant Framework of Verification for Java Source Code on CPU x GPU Hybrid Platform},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {207–218},
  publisher = {Association for Computing Machinery},
  series    = {HPDC '19},
  abstract  = {A method of detecting malicious intrusions and runtime faults in software is proposed,
which replicates untrusted computations onto two diverse but often co-located instruction
architectures: CPU and GPU. Divergence between the replicated computations signals
an intrusion or fault, such as a zero-day exploit. A prototype implementation for
Java demonstrates that the approach is realizable in practice, and can successfully
detect exploitation of Java VM and runtime system vulnerabilities even when the vulnerabilities
are not known in advance to defenders. To achieve acceptable performance, it is shown
that GPU parallelism can be leveraged to rapidly validate CPU computations that would
otherwise exhibit unacceptable performance if executed on GPU alone. The resulting
system detects anomalies in CPU computations on a short delay, during which the GPU
replica quickly validates many CPU computation fragments in parallel in order to catch
up with the CPU computation. Significant differences between the CPU and GPU computational
models lead to high natural diversity between the replicas, affording detection of
large exploit classes without laborious manual diversification of the code.},
  doi       = {10.1145/3307681.3326604},
  isbn      = {9781450366700},
  keywords  = {n-variant, intrusion detection, software reliability, java, software exploit detection, software engineering},
  location  = {Phoenix, AZ, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3307681.3326604},
}

@InProceedings{Sirinam2019,
  author    = {Sirinam, Payap and Mathews, Nate and Rahman, Mohammad Saidur and Wright, Matthew},
  booktitle = {Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {Triplet Fingerprinting: More Practical and Portable Website Fingerprinting with N-Shot Learning},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {1131–1148},
  publisher = {Association for Computing Machinery},
  series    = {CCS '19},
  abstract  = {Website Fingerprinting (WF) attacks pose a serious threat to users' online privacy,
including for users of the Tor anonymity system. By exploiting recent advances in
deep learning, WF attacks like Deep Fingerprinting (DF) have reached up to 98% accuracy.
The DF attack, however, requires large amounts of training data that needs to be updated
regularly, making it less practical for the weaker attacker model typically assumed
in WF. Moreover, research on WF attacks has been criticized for not demonstrating
attack effectiveness under more realistic and more challenging scenarios. Most research
on WF attacks assumes that the testing and training data have similar distributions
and are collected from the same type of network at about the same time. In this paper,
we examine how an attacker could leverage N-shot learning---a machine learning technique
requiring just a few training samples to identify a given class---to reduce the effort
of gathering and training with a large WF dataset as well as mitigate the adverse
effects of dealing with different network conditions. In particular, we propose a
new WF attack called Triplet Fingerprinting (TF) that uses triplet networks for N-shot
learning. We evaluate this attack in challenging settings such as where the training
and testing data are collected multiple years apart on different networks, and we
find that the TF attack remains effective in such settings with 85% accuracy or better.
We also show that the TF attack is also effective in the open world and outperforms
traditional transfer learning. On top of that, the attack requires only five examples
to recognize a website, making it dangerous in a wide variety of scenarios where gathering
and training on a complete dataset would be impractical.},
  doi       = {10.1145/3319535.3354217},
  isbn      = {9781450367479},
  keywords  = {privacy, n-shot learning, triplet networks, deep learning, tor, website fingerprinting},
  location  = {London, United Kingdom},
  numpages  = {18},
  url       = {https://doi.org/10.1145/3319535.3354217},
}

@InProceedings{MartinezPlumed2020,
  author    = {Mart\'{\i}nez-Plumed, Fernando and Tolan, Song\"{u}l and Pesole, Annarosa and Hern\'{a}ndez-Orallo, Jos\'{e} and Fern\'{a}ndez-Mac\'{\i}as, Enrique and G\'{o}mez, Emilia},
  booktitle = {Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
  title     = {Does AI Qualify for the Job? A Bidirectional Model Mapping Labour and AI Intensities},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {94–100},
  publisher = {Association for Computing Machinery},
  series    = {AIES '20},
  abstract  = {In this paper we present a setting for examining the relation be-tween the distribution
of research intensity in AI research and the relevance for a range of work tasks (and
occupations) in current and simulated scenarios. We perform a mapping between labourand
AI using a set of cognitive abilities as an intermediate layer. This setting favours
a two-way interpretation to analyse (1) what impact current or simulated AI research
activity has or would have on labour-related tasks and occupations, and (2) what areas
of AI research activity would be responsible for a desired or undesired effect on
specific labour tasks and occupations. Concretely, in our analysis we map 59 generic
labour-related tasks from several worker surveys and databases to 14 cognitive abilities
from the cognitive science literature, and these to a comprehensive list of 328 AI
benchmarks used to evaluate progress in AI techniques. We provide this model and its
implementation as a tool for simulations. We also show the effectiveness of our setting
with some illustrative examples.},
  doi       = {10.1145/3375627.3375831},
  isbn      = {9781450371100},
  keywords  = {simulation, ai impact, ai benchmarks, labour market, tasks, ai intensity},
  location  = {New York, NY, USA},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3375627.3375831},
}

@InProceedings{Park2015,
  author    = {Park, Junkil and Ivanov, Radoslav and Weimer, James and Pajic, Miroslav and Lee, Insup},
  booktitle = {Proceedings of the ACM/IEEE Sixth International Conference on Cyber-Physical Systems},
  title     = {Sensor Attack Detection in the Presence of Transient Faults},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {1–10},
  publisher = {Association for Computing Machinery},
  series    = {ICCPS '15},
  abstract  = {This paper addresses the problem of detection and identification of sensor attacks
in the presence of transient faults. We consider a system with multiple sensors measuring
the same physical variable, where some sensors might be under attack and provide malicious
values. We consider a setup, in which each sensor provides the controller with an
interval of possible values for the true value. While approaches exist for detecting
malicious sensor attacks, they are conservative in that they treat attacks and faults
in the same way, thus neglecting the fact that sensors may provide faulty measurements
at times due to temporary disturbances (e.g., a tunnel for GPS). To address this problem,
we propose a transient fault model for each sensor and an algorithm designed to detect
and identify attacks in the presence of transient faults. The fault model consists
of three aspects: the size of the sensor's interval (1) and an upper bound on the
number of errors (2) allowed in a given window size (3). Given such a model for each
sensor, the algorithm uses pairwise inconsistencies between sensors to detect and
identify attacks. In addition to the algorithm, we provide a framework for selecting
a fault model for each sensor based on training data. Finally, we validate the algorithm's
performance on real measurement data obtained from an unmanned ground vehicle.},
  doi       = {10.1145/2735960.2735984},
  isbn      = {9781450334556},
  location  = {Seattle, Washington},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2735960.2735984},
}

@InProceedings{Moon2015,
  author    = {Moon, Soo-Jin and Sekar, Vyas and Reiter, Michael K.},
  booktitle = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security},
  title     = {Nomad: Mitigating Arbitrary Cloud Side Channels via Provider-Assisted Migration},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {1595–1606},
  publisher = {Association for Computing Machinery},
  series    = {CCS '15},
  abstract  = {Recent studies have shown a range of co-residency side channels that can be used to
extract private information from cloud clients. Unfortunately, addressing these side
channels often requires detailed attack-specific fixes that require significant modifications
to hardware, client virtual machines (VM), or hypervisors. Furthermore, these solutions
cannot be generalized to future side channels. Barring extreme solutions such as single
tenancy which sacrifices the multiplexing benefits of cloud computing, such side channels
will continue to affect critical services. In this work, we present Nomad, a system
that offers vector-agnostic defense against known and future side channels. Nomad
envisions a provider-assisted VM migration service, applying the moving target defense
philosophy to bound the information leakage due to side channels. In designing Nomad,
we make four key contributions: (1) a formal model to capture information leakage
via side channels in shared cloud deployments; (2) identifying provider-assisted VM
migration as a robust defense for arbitrary side channels; (3) a scalable online VM
migration heuristic that can handle large datacenter workloads; and (4) a practical
implementation in OpenStack. We show that Nomad is scalable to large cloud deployments,
achieves near-optimal information leakage subject to constraints on migration overhead,
and imposes minimal performance degradation for typical cloud applications such as
web services and Hadoop MapReduce.},
  doi       = {10.1145/2810103.2813706},
  isbn      = {9781450338325},
  keywords  = {cross-VM side-channel attacks, cloud computing, VM migration},
  location  = {Denver, Colorado, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2810103.2813706},
}

@InProceedings{ElRabih2019,
  author    = {ElRabih, Diana},
  booktitle = {Proceedings of the 2019 2nd International Conference on Data Storage and Data Engineering},
  title     = {Cooperative and Distributed Intrusion Detection Using BigData},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {54–58},
  publisher = {Association for Computing Machinery},
  series    = {DSDE 2019},
  abstract  = {Internet infrastructure is vulnerable to various attacks, then security and privacy
are the key issues for Internet applications. Internet requires various security solutions
where the communication is secured with confidentiality, integrity, and authentication
services. Therefore, the challenge of implementing secure and protected communication
in the Internet network must be addressed. The Internet network is secured with encryption
and authentication, but it cannot be protected and secured against cyber-attacks.
Hence, an Intrusion Detection System IDS is needed. Analyzing Internet network flows,
logs, and system events has been used for intrusion detection. Big Data analytics
can correlate multiple information sources into a coherent view, identify anomalies
and suspicious activities, and finally achieve effective and efficient intrusion detection.
One solution is to have an IDS that supervises the situation for all the computers
in the Internet and makes decision regarding possible attacks. This method is not
effective due to large scale of Internet and high speed of Internet. This problem
is resolved in this paper by proposing an approach of a distributed intrusion detection
system that is based on cooperative agents (sensors) using Big Data. Then agents (sensors)
in our approach work together in a distributed and cooperative manner and these agents
(sensors) perform data collection and data analysis using Big Data technology to detect
intrusion in the Internet.},
  doi       = {10.1145/3354153.3354157},
  isbn      = {9781450372169},
  keywords  = {Internet, BigData, Intrusion Detection},
  location  = {Jeju, Republic of Korea},
  numpages  = {5},
  url       = {https://doi.org/10.1145/3354153.3354157},
}

@InProceedings{Giannopoulos2019,
  author    = {Giannopoulos, Linos and Degkleri, Eirini and Tsanakas, Panayiotis and Mitropoulos, Dimitris},
  booktitle = {Proceedings of the 12th European Workshop on Systems Security},
  title     = {Pythia: Identifying Dangerous Data-Flows in Django-Based Applications},
  year      = {2019},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {EuroSec '19},
  abstract  = {Web frameworks that allow developers to create applications based on design patterns
such as the Model View Controller (MVC), provide by default a number of security checks.
Nevertheless, by using specific constructs, developers may disable these checks thus
re-introducing classic application vulnerabilities such as Cross-site Scripting (XSS)
and Cross-Site Request Forgery (CSRF). Framework-specific elements including (1) the
complex nature of these applications, (2) the different features that they involve
(e.g. templates), and (3) the inheritance mechanisms that governs them, make the identification
of such issues very difficult.To tackle this problem, we have developed Pythia, a
scheme that analyzes applications based on the Django framework. To identify potentially
dangerous data flows that can lead to XSS and CSRF defects, Pythia takes into account
all the aforementioned elements and employs ideas coming from standard data-flow analysis
and taint tracking schemes. To the best of our knowledge, Pythia is the first mechanism
to consider framework-specific elements in its analysis. We have evaluated our scheme
with positive results. Specifically, we used Pythia to examine five open-source applications
that are currently in production and have thousands of users including an e-voting
service, and a web-based translation management system. In four cases we have identified
dangerous paths that in turn led to vulnerabilities. Notably, in many cases the paths
involved the particular features of Django-based applications e.g. templates.},
  articleno = {5},
  doi       = {10.1145/3301417.3312497},
  isbn      = {9781450362740},
  keywords  = {Templates, Application Security, Cross-site Scripting, Cross-Site Request Forgery, Data-flow Analysis, Unsanitized Output, Django},
  location  = {Dresden, Germany},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3301417.3312497},
}

@InProceedings{Song2016,
  author    = {Song, Linhai and Huang, Heqing and Zhou, Wu and Wu, Wenfei and Zhang, Yiying},
  booktitle = {Proceedings of the 7th ACM SIGOPS Asia-Pacific Workshop on Systems},
  title     = {Learning from Big Malwares},
  year      = {2016},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {APSys '16},
  abstract  = {This paper calls for the attention to investigate real-world malwares in large scales
by examining the largest real malware repository, VirusTotal. As a first step, we
analyzed two fundamental characteristics of Windows executable malwares from VirusTotal.
We designed offline and online tools for this analysis. Our results show that malwares
appear in bursts and that distributions of malwares are highly skewed.},
  articleno = {12},
  doi       = {10.1145/2967360.2967367},
  isbn      = {9781450342650},
  location  = {Hong Kong, Hong Kong},
  numpages  = {8},
  url       = {https://doi.org/10.1145/2967360.2967367},
}

@InProceedings{Herzberg2013,
  author    = {Herzberg, Amir and Shulman, Haya and Ullrich, Johanna and Weippl, Edgar},
  booktitle = {Proceedings of the 2013 ACM Workshop on Cloud Computing Security Workshop},
  title     = {Cloudoscopy: Services Discovery and Topology Mapping},
  year      = {2013},
  address   = {New York, NY, USA},
  pages     = {113–122},
  publisher = {Association for Computing Machinery},
  series    = {CCSW '13},
  abstract  = {We define and study cloudoscopy, i.e., exposing sensitive information about the location
of (victim) cloud services and/or about the internal organisation of the cloud network,
in spite of location-hiding efforts by cloud providers. A typical cloudoscopy attack
is composed of a number of steps: first expose the internal IP address of a victim
instance, then measure its hop-count distance from adversarial cloud instances, and
finally test to find a specific instance which is close enough to the victim (e.g.,
co-resident) to allow (denial of service or side-channel) attacks. We refer to the
three steps/modules involved in such cloudoscopy attack by the terms IP address deanonymisation,
hop-count measuring, and co-residence testing.We present specific methods for these
three cloudoscopy modules, and report on results of our experimental validation on
popular cloud platform providers. Our techniques can be used for attacking (victim)
servers, as well as for benign goals, e.g., optimisation of instances placement and
communication, or comparing clouds and validating cloud-provider placement guarantees.},
  doi       = {10.1145/2517488.2517491},
  isbn      = {9781450324908},
  keywords  = {cloud tomography, socket overloading, cloud mapping, low rate attacks, cloud security},
  location  = {Berlin, Germany},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2517488.2517491},
}

@Article{Masud2011,
  author     = {Masud, Mohammad M. and Al-Khateeb, Tahseen M. and Hamlen, Kevin W. and Gao, Jing and Khan, Latifur and Han, Jiawei and Thuraisingham, Bhavani},
  journal    = {ACM Trans. Manage. Inf. Syst.},
  title      = {Cloud-Based Malware Detection for Evolving Data Streams},
  year       = {2011},
  issn       = {2158-656X},
  month      = oct,
  number     = {3},
  volume     = {2},
  abstract   = {Data stream classification for intrusion detection poses at least three major challenges.
First, these data streams are typically infinite-length, making traditional multipass
learning algorithms inapplicable. Second, they exhibit significant concept-drift as
attackers react and adapt to defenses. Third, for data streams that do not have any
fixed feature set, such as text streams, an additional feature extraction and selection
task must be performed. If the number of candidate features is too large, then traditional
feature extraction techniques fail.In order to address the first two challenges, this
article proposes a multipartition, multichunk ensemble classifier in which a collection
of v classifiers is trained from r consecutive data chunks using v-fold partitioning
of the data, yielding an ensemble of such classifiers. This multipartition, multichunk
ensemble technique significantly reduces classification error compared to existing
single-partition, single-chunk ensemble approaches, wherein a single data chunk is
used to train each classifier. To address the third challenge, a feature extraction
and selection technique is proposed for data streams that do not have any fixed feature
set. The technique's scalability is demonstrated through an implementation for the
Hadoop MapReduce cloud computing architecture. Both theoretical and empirical evidence
demonstrate its effectiveness over other state-of-the-art stream classification techniques
on synthetic data, real botnet traffic, and malicious executables.},
  address    = {New York, NY, USA},
  articleno  = {16},
  doi        = {10.1145/2019618.2019622},
  issue_date = {October 2011},
  keywords   = {malicious executable, Data mining, malware detection, data streams, n-gram analysis},
  numpages   = {27},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2019618.2019622},
}

@InProceedings{Kang2012,
  author    = {Kang, Boojoong and Kim, Taekeun and Kwon, Heejun and Choi, Yangseo and Im, Eul Gyu},
  booktitle = {Proceedings of the 2012 ACM Research in Applied Computation Symposium},
  title     = {Malware Classification Method via Binary Content Comparison},
  year      = {2012},
  address   = {New York, NY, USA},
  pages     = {316–321},
  publisher = {Association for Computing Machinery},
  series    = {RACS '12},
  abstract  = {With the wide spread uses of the Internet, the number of Internet attacks keeps increasing,
and malware is the main cause of most Internet attacks. Malware is used by attackers
to infect normal users' computers and to acquire private information as well as to
attack other machines. The number of new malware and variants of malware is increasing
every year because the automated tools allow attackers to generate the new malware
or their variants easily. Therefore, performance improvement of the malware analysis
is critical to prevent malware from spreading rapidly and to mitigate damages to users.
In this paper, we proposed a new malware classification method by analyzing similarities
of malware. Our method analyzes a small part of malware to reduce analysis overheads,
and experimental results showed that our approach can effectively classify malware
families.},
  doi       = {10.1145/2401603.2401672},
  isbn      = {9781450314923},
  keywords  = {malware classification, malware detection, static analysis, binary analysis, malware similarity},
  location  = {San Antonio, Texas},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2401603.2401672},
}

@InProceedings{Suneja2019,
  author    = {Suneja, Sahil and Kanso, Ali and Isci, Canturk},
  booktitle = {Proceedings of the 5th International Workshop on Container Technologies and Container Clouds},
  title     = {Can Container Fusion Be Securely Achieved?},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {31–36},
  publisher = {Association for Computing Machinery},
  series    = {WOC '19},
  abstract  = {Linux containers are key enablers for building microservices. The application's microservices
fall broadly under two categories, the core-microservices implementing the business
logic and the utility-microservices implementing middleware functionalities. Such
functionalities include vulnerability scanning, monitoring, telemetry, etc. Segregating
the utility-microservices in separate containers from the core-microservice containers
may prevent them from achieving their functionality. This is due to the strong isolation
between containers. By diffusing the boundaries between containers we can fuse them
together and enable close collaboration. However, this raises several security concerns,
especially that the utility-microservices may include vulnerabilities that threaten
the entire application. In this paper, we analyze the different techniques to enhance
the security of container fusion and present an automated solution based on Kubernetes
to configure utility-microservices containers to fuse with core-microservices containers.},
  doi       = {10.1145/3366615.3368356},
  isbn      = {9781450370332},
  keywords  = {Linux containers, Kubernetes, security, orchestration, microservices},
  location  = {Davis, CA, USA},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3366615.3368356},
}
{10.1145/2660267.2660278,
author = {Ji, Shouling and Li, Weiqing and Srivatsa, Mudhakar and Beyah, Raheem},
title = {Structural Data De-Anonymization: Quantification, Practice, and Implications},
year = {2014},
isbn = {9781450329576},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2660267.2660278},
doi = {10.1145/2660267.2660278},
abstract = {In this paper, we study the quantification, practice, and implications of structural
data (e.g., social data, mobility traces) De-Anonymization (DA). First, we address
several open problems in structural data DA by quantifying perfect and (1-ε)-perfect
structural data DA}, where ε is the error tolerated by a DA scheme. To the best of
our knowledge, this is the first work on quantifying structural data DA under a general
data model, which closes the gap between structural data DA practice and theory. Second,
we conduct the first large-scale study on the de-anonymizability of 26 real world
structural datasets, including Social Networks (SNs), Collaborations Networks, Communication
Networks, Autonomous Systems, and Peer-to-Peer networks. We also quantitatively show
the conditions for perfect and (1-ε)-perfect DA of the 26 datasets. Third, following
our quantification, we design a practical and novel single-phase cold start Optimization
based DA} (ODA) algorithm. Experimental analysis of ODA shows that about 77.7% - 83.3%
of the users in Gowalla (.2M users and 1M edges) and 86.9% - 95.5% of the users in
Google+ (4.7M users and 90.8M edges) are de-anonymizable in different scenarios, which
implies optimization based DA is implementable and powerful in practice. Finally,
we discuss the implications of our DA quantification and ODA and provide some general
suggestions for future secure data publishing.},
booktitle = {Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1040–1053},
numpages = {14},
keywords = {mobility traces, structural data, social networks, evaluation, de-anonymization, quantification},
location = {Scottsdale, Arizona, USA},
series = {CCS '14}
}

@Article{McGettrick2013,
  author     = {McGettrick, Andrew and Timanovsky, Yan},
  journal    = {ACM Inroads},
  title      = {Digest of ACM Educational Activities},
  year       = {2013},
  issn       = {2153-2184},
  month      = jun,
  number     = {2},
  pages      = {20–25},
  volume     = {4},
  abstract   = {Welcome to the latest installment of "EduBits," your quarterly pipeline to new and
exciting happenings in the world of ACM education. In this edition, the ACM Education
Board kicks off a National Science Foundation (NSF)-funded effort to advance cybersecurity
education. Also, Cameron Wilson, Director of ACM's Public Policy Office, offers his
perspectives from Capitol Hill, and Cherri M. Pancake, Chair of the ACM Special Interest
Group on High Performance Computing (SIGHPC), shares key programs for HPC students,
academics, and practitioners. When it comes to computing education, there are as many
interests as there are challenges---and the Education Council strives to represent
them all. Although the Council typically meets only once a year, members of the Board
are involved in ongoing initiatives throughout the year, undertaking many projects
between Council meetings.},
  address    = {New York, NY, USA},
  doi        = {10.1145/2465085.2465090},
  issue_date = {June 2013},
  numpages   = {6},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2465085.2465090},
}

@InProceedings{Zhu2020,
  author    = {Zhu, Shitong and Li, Shasha and Wang, Zhongjie and Chen, Xun and Qian, Zhiyun and Krishnamurthy, Srikanth V. and Chan, Kevin S. and Swami, Ananthram},
  booktitle = {Proceedings of the 16th International Conference on Emerging Networking EXperiments and Technologies},
  title     = {You Do (Not) Belong Here: Detecting DPI Evasion Attacks with Context Learning},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {183–197},
  publisher = {Association for Computing Machinery},
  series    = {CoNEXT '20},
  abstract  = {As Deep Packet Inspection (DPI) middleboxes become increasingly popular, a spectrum
of adversarial attacks have emerged with the goal of evading such middleboxes. Many
of these attacks exploit discrepancies between the middlebox network protocol implementations,
and the more rigorous/complete versions implemented at end hosts. These evasion attacks
largely involve subtle manipulations of packets to cause different behaviours at DPI
and end hosts, to cloak malicious network traffic that is otherwise detectable. With
recent automated discovery, it has become prohibitively challenging to manually curate
rules for detecting these manipulations. In this work, we propose CLAP, the first
fully-automated, unsupervised ML solution to accurately detect and localize DPI evasion
attacks. By learning what we call the packet context, which essentially captures inter-relationships
across both (1) different packets in a connection; and (2) different header fields
within each packet, from benign traffic traces only, CLAP can detect and pinpoint
packets that violate the benign packet contexts (which are the ones that are specially
crafted for evasion purposes). Our evaluations with 73 state-of-the-art DPI evasion
attacks show that CLAP achieves an Area Under the Receiver Operating Characteristic
Curve (AUCROC) of <u>0.963</u>, an Equal Error Rate (EER) of only <u>0.061</u> in
detection, and an accuracy of <u>94.6%</u> in localization. These results suggest
that CLAP can be a promising tool for thwarting DPI evasion attacks.},
  doi       = {10.1145/3386367.3431311},
  isbn      = {9781450379489},
  location  = {Barcelona, Spain},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3386367.3431311},
}

@InProceedings{Li2019,
  author    = {Li, Zhenyuan and Chen, Qi Alfred and Xiong, Chunlin and Chen, Yan and Zhu, Tiantian and Yang, Hai},
  booktitle = {Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {Effective and Light-Weight Deobfuscation and Semantic-Aware Attack Detection for PowerShell Scripts},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {1831–1847},
  publisher = {Association for Computing Machinery},
  series    = {CCS '19},
  abstract  = {In recent years, PowerShell is increasingly reported to appear in a variety of cyber
attacks ranging from advanced persistent threat, ransomware, phishing emails, cryptojacking,
financial threats, to fileless attacks. However, since the PowerShell language is
dynamic by design and can construct script pieces at different levels, state-of-the-art
static analysis based PowerShell attack detection approaches are inherently vulnerable
to obfuscations. To overcome this challenge, in this paper we design the first effective
and light-weight deobfuscation approach for PowerShell scripts. To address the challenge
in precisely identifying the recoverable script pieces, we design a novel subtree-based
deobfuscation method that performs obfuscation detection and emulation-based recovery
at the level of subtrees in the abstract syntax tree of PowerShell scripts. Building
upon the new deobfuscation method, we are able to further design the first semantic-aware
PowerShell attack detection system. To enable semantic-based detection, we leverage
the classic objective-oriented association mining algorithm and newly identify 31
semantic signatures for PowerShell attacks. We perform an evaluation on a collection
of 2342 benign samples and 4141 malicious samples, and find that our deobfuscation
method takes less than 0.5 seconds on average and meanwhile increases the similarity
between the obfuscated and original scripts from only 0.5% to around 80%, which is
thus both effective and light-weight. In addition, with our deobfuscation applied,
the attack detection rates for Windows Defender and VirusTotal increase substantially
from 0.3% and 2.65% to 75.0% and 90.0%, respectively. Furthermore, when our deobfuscation
is applied, our semantic-aware attack detection system outperforms both Windows Defender
and VirusTotal with a 92.3% true positive rate and a 0% false positive rate on average.},
  doi       = {10.1145/3319535.3363187},
  isbn      = {9781450367479},
  keywords  = {semantic-aware, deobfuscation, powershell, abstract syntax tree},
  location  = {London, United Kingdom},
  numpages  = {17},
  url       = {https://doi.org/10.1145/3319535.3363187},
}

@InProceedings{Diesch2020,
  author    = {Diesch, Rainer and Krcmar, Helmut},
  booktitle = {Proceedings of the 15th International Conference on Availability, Reliability and Security},
  title     = {SoK: Linking Information Security Metrics to Management Success Factors},
  year      = {2020},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ARES '20},
  abstract  = {Information security metrics are used to measure the effectiveness of information
security countermeasures. A large number of metrics and their technical nature creates
difficulties when generating reports for the information security management level
of an organization. Managers struggle with the usefulness and clarity of the metrics
because they are not linked to the security management goals. Also, responsible managers
with no technical information security background struggle to understand the metrics.
Therefore, this study uses a state-of-the-art literature analysis together with the
Goal-Question-Metric approach to investigate linking technical security metrics to
management success factors. This study enables the management to design appropriate
security reports for their organization and to direct the metrics toward making goal-oriented
decisions. Furthermore, the study invites future research by revealing areas in which
security metrics do not exist and create new solutions and studies to suggest a standardized
information security dashboard.},
  articleno = {98},
  doi       = {10.1145/3407023.3407059},
  isbn      = {9781450388337},
  keywords  = {systematic literature review, goal-question-metric approach, information security metrics, security management success factors},
  location  = {Virtual Event, Ireland},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3407023.3407059},
}

@InProceedings{Wressnegger2017,
  author    = {Wressnegger, Christian and Freeman, Kevin and Yamaguchi, Fabian and Rieck, Konrad},
  booktitle = {Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security},
  title     = {Automatically Inferring Malware Signatures for Anti-Virus Assisted Attacks},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {587–598},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '17},
  abstract  = {Although anti-virus software has significantly evolved over the last decade, classic
signature matching based on byte patterns is still a prevalent concept for identifying
security threats. Anti-virus signatures are a simple and fast detection mechanism
that can complement more sophisticated analysis strategies. However, if signatures
are not designed with care, they can turn from a defensive mechanism into an instrument
of attack. In this paper, we present a novel method for automatically deriving signatures
from anti-virus software and discuss how the extracted signatures can be used to attack
sensible data with the aid of the virus scanner itself. To this end, we study the
practicability of our approach using four commercial products and exemplary demonstrate
anti-virus assisted attacks in three different scenarios.},
  doi       = {10.1145/3052973.3053002},
  isbn      = {9781450349444},
  keywords  = {anti-virus, malware, signatures, attacks},
  location  = {Abu Dhabi, United Arab Emirates},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3052973.3053002},
}

@InProceedings{Li2015,
  author    = {Li, Richard and Abendroth, Dallin and Lin, Xing and Guo, Yuankai and Baek, Hyun-Wook and Eide, Eric and Ricci, Robert and Van der Merwe, Jacobus},
  booktitle = {Proceedings of the Sixth ACM Symposium on Cloud Computing},
  title     = {P<span class="smallcaps SmallerCapital">otassium</span>: Penetration Testing as a Service},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {30–42},
  publisher = {Association for Computing Machinery},
  series    = {SoCC '15},
  abstract  = {Penetration testing---the process of probing a deployed system for security vulnerabilities---involves
a fundamental tension. If one tests a production system, there is a real danger of
collateral damage; this is particularly true for systems hosted in the cloud due to
the presence of other tenants. If one tests against a separate system brought up to
model the live one, the dynamic state of the production system is not captured, and
the value of the test is reduced. This paper presents Potassium, which provides penetration
testing as a service (PTaaS) and resolves this tension for system owners, penetration
testers, and cloud providers. Potassium uses techniques originally developed for live
migration of virtual machines to clone them instead, capturing their full disk, memory,
and network state. Potassium isolates the cloned system from the rest of the cloud,
providing confidence that side effects of the penetration test will not harm other
tenants. The penetration tester effectively owns the cloned system, allowing testing
to be more thorough, efficient, and automatable. Experiments with our Potassium prototype
show that PTaaS can detect real-world vulnerabilities while having minimal impact
on cloud-based production systems.},
  doi       = {10.1145/2806777.2806935},
  isbn      = {9781450336512},
  keywords  = {cloud computing, OpenStack, pentesting, PTaaS},
  location  = {Kohala Coast, Hawaii},
  numpages  = {13},
  url       = {https://doi.org/10.1145/2806777.2806935},
}

@Article{Sharif2019,
  author     = {Sharif, Mahmood and Bhagavatula, Sruti and Bauer, Lujo and Reiter, Michael K.},
  journal    = {ACM Trans. Priv. Secur.},
  title      = {A General Framework for Adversarial Examples with Objectives},
  year       = {2019},
  issn       = {2471-2566},
  month      = jun,
  number     = {3},
  volume     = {22},
  abstract   = {Images perturbed subtly to be misclassified by neural networks, called adversarial
examples, have emerged as a technically deep challenge and an important concern for
several application domains. Most research on adversarial examples takes as its only
constraint that the perturbed images are similar to the originals. However, real-world
application of these ideas often requires the examples to satisfy additional objectives,
which are typically enforced through custom modifications of the perturbation process.
In this article, we propose adversarial generative nets (AGNs), a general methodology
to train a generator neural network to emit adversarial examples satisfying desired
objectives. We demonstrate the ability of AGNs to accommodate a wide range of objectives,
including imprecise ones difficult to model, in two application domains. In particular,
we demonstrate physical adversarial examples—eyeglass frames designed to fool face
recognition—with better robustness, inconspicuousness, and scalability than previous
approaches, as well as a new attack to fool a handwritten-digit classifier.},
  address    = {New York, NY, USA},
  articleno  = {16},
  doi        = {10.1145/3317611},
  issue_date = {July 2019},
  keywords   = {adversarial examples, Machine learning, neural networks, face recognition},
  numpages   = {30},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3317611},
}

@Article{Song2018,
  author     = {Song, Chen and Li, Zhengxiong and Xu, Wenyao and Zhou, Chi and Jin, Zhanpeng and Ren, Kui},
  journal    = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
  title      = {My Smartphone Recognizes Genuine QR Codes! Practical Unclonable QR Code via 3D Printing},
  year       = {2018},
  month      = jul,
  number     = {2},
  volume     = {2},
  abstract   = {Additive manufacturing, or 3D printing, has been widely applied in product manufacturing.
However, the emerging unauthorized access of 3D printing data, as well as the growth
in the pervasiveness and capability of 3D printing devices have raised serious concerns
about 3D printing product anti-counterfeit. Electronic product tags are the current
standard for authentication purposes; however, often this technology is neither secure
nor cost-effective, and fails to take advantage of other unique 3D printing features.
Considering the great usability of the QR code, we are motivated to enhance the QR
code for the practical and cost-effective 3D printing product identification. Particularly,
we bring up the all-in-one design, all-in-one manufacturing concept incorporating
the QR code in the complete 3D printing paradigm. In detail, we explore the possibility
of leveraging the random and uncontrollable process variations in the 3D printing
system to generate a unique fingerprint for the integrated QR code. To this end, we
present an end-to-end 3D-printed QR code verification framework, which does not change
the original QR protocol and functionality. The entire solution can be implemented
with commodity 3D printers and smartphones. Specifically, we first investigate the
inevitable and random process variations in the 3D printing mechanism and analyze
the causality between the variations and detectable geometric deformation. We further
develop a fingerprint extraction algorithm taking into account both the QR code property
and the 3D printer characteristics. The system evaluation indicates that our solution
is secure and robust in multiple scenarios.},
  address    = {New York, NY, USA},
  articleno  = {83},
  doi        = {10.1145/3214286},
  issue_date = {June 2018},
  keywords   = {Embedded Systems, Authentication, Hardware Security, 3D Printing},
  numpages   = {20},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3214286},
}

@InProceedings{Ghaffarinia2019,
  author    = {Ghaffarinia, Masoud and Hamlen, Kevin W.},
  booktitle = {Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {Binary Control-Flow Trimming},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {1009–1022},
  publisher = {Association for Computing Machinery},
  series    = {CCS '19},
  abstract  = {A new method of automatically reducing the attack surfaces of binary software is introduced,
affording code consumers the power to remove features that are unwanted or unused
in a particular deployment context. The approach targets stripped binary native code
with no source-derived metadata or symbols, can remove semantic features irrespective
of whether they were intended and/or known to code developers, and anticipates consumers
who can demonstrate desired features (e.g., via unit testing), but who may not know
the existence of specific unwanted features, and who lack any formal specifications
of the code's semantics.Through a combination of runtime tracing, machine learning,
in-lined reference monitoring, and contextual control-flow integrity enforcement,
it is demonstrated that automated code feature removal is nevertheless feasible under
these constraints, even for complex programs such as compilers and servers. The approach
additionally accommodates consumers whose demonstration of desired features is incomplete;
a tunable entropy-based metric detects coverage lapses and conservatively preserves
unexercised but probably desired flows. A prototype implementation for Intel x86-64
exhibits low runtime overhead for trimmed binaries (about 1.87%), and case studies
show that consumer-side control-flow trimming can successfully eliminate zero-day
vulnerabilities.},
  doi       = {10.1145/3319535.3345665},
  isbn      = {9781450367479},
  keywords  = {control-flow integrity, software debloating},
  location  = {London, United Kingdom},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3319535.3345665},
}

@Article{Argyros2017,
  author     = {Argyros, George and Petsios, Theofilos and Sivakorn, Suphannee and Keromytis, Angelos D. and Polakis, Jason},
  journal    = {ACM Trans. Priv. Secur.},
  title      = {Evaluating the Privacy Guarantees of Location Proximity Services},
  year       = {2017},
  issn       = {2471-2566},
  month      = feb,
  number     = {4},
  volume     = {19},
  abstract   = {Location-based services have become an integral part of everyday life. To address
the privacy issues that emerge from the use and sharing of location information, social
networks and smartphone applications have adopted location proximity schemes as a
means of balancing user privacy with utility. Unfortunately, despite the extensive
academic literature on this topic, the schemes that large service providers have adopted
are not always designed or implemented correctly, rendering users vulnerable to location-disclosure
attacks. Such attacks have recently received major publicity as, in some cases, they
even exposed citizens of oppressive regimes to life-threatening risks. In this article,
we systematically assess the defenses that popular location-based services and mobile
applications deploy to guard against adversaries seeking to identify a user’s location.
We provide the theoretical foundations for formalizing the privacy guarantees of currently
adopted proximity models, design practical attacks for each case, and prove tight
bounds on the number of queries required for carrying out successful attacks in practice.To
evaluate the completeness of our approach, we conduct extensive experiments against
popular services including Facebook, Foursquare, and Grindr. Our results demonstrate
that, even though the aforementioned services implement various privacy-preserving
techniques to protect their users, they are still vulnerable to attacks. In particular,
we are able to pinpoint Facebook users within 5m of their exact location. For Foursquare
and Grindr, users are pinpointed within 15m of their location in 90% of the cases,
even with the strictest privacy settings enabled. Our attacks are highly efficient
and complete within a few seconds. The severity of our findings was acknowledged by
Facebook and Foursquare, both of which have followed our recommendations and adopted
our design of a safe proximity scheme in their production systems. As the number of
mobile applications offering location functionality will continue to increase, service
providers and software developers must be able to assess the privacy guarantees that
their services offer. To that end, we discuss viable defenses that can be currently
adopted by all major services, and provide an open-source testing framework to be
used by researchers and service providers who wish to evaluate the privacy-preserving
properties of applications offering proximity functionality.},
  address    = {New York, NY, USA},
  articleno  = {12},
  doi        = {10.1145/3007209},
  issue_date = {February 2017},
  keywords   = {location privacy, user discovery attacks, location proximity, spatial cloaking, Location-based services},
  numpages   = {31},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3007209},
}

@InProceedings{Bagaria2019,
  author    = {Bagaria, Vivek and Kannan, Sreeram and Tse, David and Fanti, Giulia and Viswanath, Pramod},
  booktitle = {Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {Prism: Deconstructing the Blockchain to Approach Physical Limits},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {585–602},
  publisher = {Association for Computing Machinery},
  series    = {CCS '19},
  abstract  = {The concept of a blockchain was invented by Satoshi Nakamoto to maintain a distributed
ledger. In addition to its security, important performance measures of a blockchain
protocol are its transaction throughput and confirmation latency. In a decentralized
setting, these measures are limited by two underlying physical network attributes:
communication capacity and speed-of-light propagation delay. In this work we introduce
Prism, a new proof-of-work blockchain protocol, which can achieve 1) security against
up to 50% adversarial hashing power; 2) optimal throughput up to the capacity C of
the network; 3) confirmation latency for honest transactions proportional to the propagation
delay D, with confirmation error probability exponentially small in the bandwidth-delay
product CD; 4) eventual total ordering of all transactions. Our approach to the design
of this protocol is based on deconstructing Nakamoto's blockchain into its basic functionalities
and systematically scaling up these functionalities to approach their physical limits.},
  doi       = {10.1145/3319535.3363213},
  isbn      = {9781450367479},
  keywords  = {proof-of-work, blockchains, scalability, latency, throughput},
  location  = {London, United Kingdom},
  numpages  = {18},
  url       = {https://doi.org/10.1145/3319535.3363213},
}

@InProceedings{Li2020a,
  author    = {Li, Yu and Li, Min and Luo, Bo and Tian, Ye and Xu, Qiang},
  booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {DeepDyve: Dynamic Verification for Deep Neural Networks},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {101–112},
  publisher = {Association for Computing Machinery},
  series    = {CCS '20},
  abstract  = {Deep neural networks (DNNs) have become one of the enabling technologies in many safety-critical
applications, e.g., autonomous driving and medical image analysis. DNN systems, however,
suffer from various kinds of threats, such as adversarial example attacks and fault
injection attacks. While there are many defense methods proposed against maliciously
crafted inputs, solutions against faults presented in the DNN system itself (e.g.,
parameters and calculations) are far less explored. In this paper, we develop a novel
lightweight fault-tolerant solution for DNN-based systems, namely DeepDyve, which
employs pre-trained neural networks that are far simpler and smaller than the original
DNN for dynamic verification. The key to enabling such lightweight checking is that
the smaller neural network only needs to produce approximate results for the initial
task without sacrificing fault coverage much. We develop efficient and effective architecture
and task exploration techniques to achieve optimized risk/overhead trade-off in DeepDyve.
Experimental results show that DeepDyve can reduce 90% of the risks at around 10%
overhead.},
  doi       = {10.1145/3372297.3423338},
  isbn      = {9781450370899},
  keywords  = {deep learning, fault injection attack, dynamic verification},
  location  = {Virtual Event, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3372297.3423338},
}

@InProceedings{Rawat2016,
  author    = {Rawat, A. and Singh, A. K. and Jithin, J. and Jeyanthi, N. and Thandeeswaran, R.},
  booktitle = {Proceedings of the International Conference on Advances in Information Communication Technology &amp; Computing},
  title     = {RSJ Approach for User Authentication},
  year      = {2016},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {AICTC '16},
  abstract  = {Some of the common works like, upload and retrieval of data, buying and selling things,
earning and donating or transaction of money etc., are the most common works performed
in daily life through internet. For every user who is accessing the internet regularly,
their highest priority is to make sure that there data is secured. Users are willing
to pay huge amount of money to the service provider for maintaining the security.
But the intention of malicious users is to access and misuse others data. For that
they are using zombie bots. Always Bots are not the only malicious, legitimate authorized
user can also impersonate to access the data illegally. This makes the job tougher
to discriminate between the bots and boots. For providing security form that threats,
here we are proposing a novel RSJ Approach by User Authentication. RSJ approach is
a secure way for providing the security to the user form both bots and malicious users.},
  articleno = {101},
  doi       = {10.1145/2979779.2979880},
  isbn      = {9781450342131},
  keywords  = {Authentication, Dempster--Shafer, CAPTCHA, Bots, keystroke},
  location  = {Bikaner, India},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2979779.2979880},
}

@InProceedings{Panigrahy2011,
  author    = {Panigrahy, Saroj Kumar and Jena, Sanjay Kumar and Turuk, Ashok Kumar},
  booktitle = {Proceedings of the 2011 International Conference on Communication, Computing &amp; Security},
  title     = {Security in Bluetooth, RFID and Wireless Sensor Networks},
  year      = {2011},
  address   = {New York, NY, USA},
  pages     = {628–633},
  publisher = {Association for Computing Machinery},
  series    = {ICCCS '11},
  abstract  = {Recently, new families of wireless ad hoc networks have emerged for specialized applications---
personal area networks. Wireless personal area networks (WPAN) is rapidly gaining
popularity. A wide variety of traditional computing devices and embedded Internet
appliances are networked around us. However, due to the broadcast nature of these
networks and the heterogeneity of devices on these networks, new security problems
will arise, because the different types of devices have different capabilities and
security requirements. In this paper, an overview of security issues like attacks
and its countermeasures for wireless personal area networks such as Bluetooth, RFID
and wireless sensor networks has been provided.},
  doi       = {10.1145/1947940.1948071},
  isbn      = {9781450304641},
  keywords  = {RFID, WPAN, WSN, Bluetooth},
  location  = {Rourkela, Odisha, India},
  numpages  = {6},
  url       = {https://doi.org/10.1145/1947940.1948071},
}

@Article{Pedro2013,
  author     = {Pedro, Ricardo Wandr\'{e} Dias and Nunes, F\'{a}tima L. S. and Machado-Lima, Ariane},
  journal    = {ACM Comput. Surv.},
  title      = {Using Grammars for Pattern Recognition in Images: A Systematic Review},
  year       = {2013},
  issn       = {0360-0300},
  month      = nov,
  number     = {2},
  volume     = {46},
  abstract   = {Grammars are widely used to describe string languages such as programming and natural
languages and, more recently, biosequences. Moreover, since the 1980s grammars have
been used in computer vision and related areas. Some factors accountable for this
increasing use regard its relatively simple understanding and its ability to represent
some semantic pattern models found in images, both spatially and temporally. The objective
of this article is to present an overview regarding the use of syntactic pattern recognition
methods in image representations in several applications. To achieve this purpose,
we used a systematic review process to investigate the main digital libraries in the
area and to document the phases of the study in order to allow the auditing and further
investigation. The results indicated that in some of the studies retrieved, manually
created grammars were used to comply with a particular purpose. Other studies performed
a learning process of the grammatical rules. In addition, this article also points
out still unexplored research opportunities in the literature.},
  address    = {New York, NY, USA},
  articleno  = {26},
  doi        = {10.1145/2543581.2543593},
  issue_date = {November 2013},
  keywords   = {image representation, syntactic methods, formal languages, pattern recognition, computer vision, Image grammars},
  numpages   = {34},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2543581.2543593},
}

@InProceedings{Marotta2013,
  author    = {Marotta, Antonio and Carrozza, Gabriella and Avallone, Stefano and Manetti, Vittorio},
  booktitle = {Proceedings of the 3rd International Conference on Application and Theory of Automation in Command and Control Systems},
  title     = {An OpenFlow-Based Architecture for IaaS Security},
  year      = {2013},
  address   = {New York, NY, USA},
  pages     = {118–121},
  publisher = {Association for Computing Machinery},
  series    = {ATACCS '13},
  abstract  = {Cloud Computing technology and its service model, Infrastructure as a Service, are
emerging as the leading approaches to encourage the scalable and efficient utilization
of resources and the convenient consumption of elastic services. Despite all the advantages
that derive from the application of Cloud Computing IaaS model, when dealing with
mission and safety critical infrastructures "built in the cloud", it is needed to
be also aware of the security gaps and concerns. In this work we present our proposed
architecture to tackle cloud security issues and we describe the first results of
our experimental campaign.},
  doi       = {10.1145/2494493.2494510},
  isbn      = {9781450322492},
  location  = {Naples, Italy},
  numpages  = {4},
  url       = {https://doi.org/10.1145/2494493.2494510},
}

@InProceedings{Pour2019,
  author    = {Pour, Morteza Safaei and Mangino, Antonio and Friday, Kurt and Rathbun, Matthias and Bou-Harb, Elias and Iqbal, Farkhund and Shaban, Khaled and Erradi, Abdelkarim},
  booktitle = {Proceedings of the 14th International Conference on Availability, Reliability and Security},
  title     = {Data-Driven Curation, Learning and Analysis for Inferring Evolving IoT Botnets in the Wild},
  year      = {2019},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ARES '19},
  abstract  = {The insecurity of the Internet-of-Things (IoT) paradigm continues to wreak havoc in
consumer and critical infrastructure realms. Several challenges impede addressing
IoT security at large, including, the lack of IoT-centric data that can be collected,
analyzed and correlated, due to the highly heterogeneous nature of such devices and
their widespread deployments in Internet-wide environments. To this end, this paper
explores macroscopic, passive empirical data to shed light on this evolving threat
phenomena. This not only aims at classifying and inferring Internet-scale compromised
IoT devices by solely observing such one-way network traffic, but also endeavors to
uncover, track and report on orchestrated "in the wild" IoT botnets. Initially, to
prepare the effective utilization of such data, a novel probabilistic model is designed
and developed to cleanse such traffic from noise samples (i.e., misconfiguration traffic).
Subsequently, several shallow and deep learning models are evaluated to ultimately
design and develop a multi-window convolution neural network trained on active and
passive measurements to accurately identify compromised IoT devices. Consequently,
to infer orchestrated and unsolicited activities that have been generated by well-coordinated
IoT botnets, hierarchical agglomerative clustering is deployed by scrutinizing a set
of innovative and efficient network feature sets. By analyzing 3.6 TB of recent darknet
traffic, the proposed approach uncovers a momentous 440,000 compromised IoT devices
and generates evidence-based artifacts related to 350 IoT botnets. While some of these
detected botnets refer to previously documented campaigns such as the Hide and Seek,
Hajime and Fbot, other events illustrate evolving threats such as those with cryptojacking
capabilities and those that are targeting industrial control system communication
and control services.},
  articleno = {6},
  doi       = {10.1145/3339252.3339272},
  isbn      = {9781450371643},
  keywords  = {IoT botnets, network telescopes, network security, Internet measurements, Internet-of-Things, deep learning},
  location  = {Canterbury, CA, United Kingdom},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3339252.3339272},
}

@InProceedings{Amir2020,
  author    = {Amir, Sarah and Forte, Domenic},
  booktitle = {Proceedings of the 39th International Conference on Computer-Aided Design},
  title     = {Adaptable and Divergent Synthetic Benchmark Generation for Hardware Security},
  year      = {2020},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ICCAD '20},
  abstract  = {Benchmarking can drive the development of technologies by facilitating standardization
of features for comparison of different methods. While hardware security has seen
an exponential growth in innovation throughout the last decade, the lack of sufficient
benchmarks for data-driven analysis is prominent. Researchers must currently rely
on decades-old VLSI benchmarks, which in most cases were not designed with security
evaluation in mind. Considering the present day computational power, these benchmarks
lack in both quality and quantity for usage in hardware security topics such as obfuscation
and hardware Trojans. Many advanced techniques, like statistical analysis and machine
learning, require a large number of samples in order to sufficiently examine the feature
space. In an attempt to resolve this issue, we have developed the first synthetic
benchmark generation process flow. This paper describes our novel technique that utilizes
linear optimization to generate an endless number of synthetic combinational benchmarks
that are adaptable to user input constraints and divergent in quantifiable structural
features from input reference benchmarks. Thus, our framework offers customization
for generating richer and more challenging benchmarks for data-driven hardware security.
Through experimentation, we verify that our benchmarks offers more structural variation
than the current benchmark suites.},
  articleno = {49},
  doi       = {10.1145/3400302.3415648},
  isbn      = {9781450380263},
  keywords  = {linear programming, hardware security, synthetic benchmark},
  location  = {Virtual Event, USA},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3400302.3415648},
}

@InProceedings{Yu2013,
  author    = {Yu, Lu and Brooks, Richard R.},
  booktitle = {Proceedings of the Eighth Annual Cyber Security and Information Intelligence Research Workshop},
  title     = {Applying POMDP to Moving Target Optimization},
  year      = {2013},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {CSIIRW '13},
  abstract  = {Diversity maintains security by making the computing environment less standard and
less predictable. Recent studies show that many randomization techniques, e.g. address
space layout randomization (ASLR) significantly enhance system security simply through
reducing the number of return to libc exploits [14]. However, "diversity" may incur
significant overhead on the computing platforms. We study the problem of implementing
diversity to trade off security performance with diversity implementation costs. We
address this problem by formulating it as a partially observable Markov decision process
(POMDP). An optimal solution considering a fixed amount of history can be obtained
by transforming the POMDP optimization problem into a nonlinear programming (NLP)
problem. Simulation results for a set of benchmark problems illustrate the effectiveness
of the proposed method.},
  articleno = {49},
  doi       = {10.1145/2459976.2460032},
  isbn      = {9781450316873},
  keywords  = {POMDP, diversity implementation, NLP},
  location  = {Oak Ridge, Tennessee, USA},
  numpages  = {4},
  url       = {https://doi.org/10.1145/2459976.2460032},
}

@InProceedings{Cardenas2019,
  author    = {Cardenas, D. Jonathan Sebastian and Hahn, Adam},
  booktitle = {Proceedings of the Northwest Cybersecurity Symposium},
  title     = {IoT Threats to the Smart Grid: A Framework for Analyzing Emerging Risks},
  year      = {2019},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {NCS '19},
  abstract  = {Internet of Things (IoT) technologies have experienced an unprecedented growth over
the last decade due to their wide applicability and low overall costs. These same
factors have also allowed IoT deployments to transition into industrial environments
which are expected to meet high reliability requirements. These technological-base
shifts have raised operational (safety) concerns among researchers, which have been
further fueled by high-profile cyber incidents that have exposed vulnerabilities in
field devices. Although, multiple IoT cyber security issues are being actively researched,
a compelling issue is to identify threats associated with cross-domain devices. A
cross-domain vulnerability is any such vulnerability that can cause other non-IT system
to experience unintended consequences.Recent research has shown that physical systems,
like the electrical grid might be exposed to abnormal conditions if a large set of
load-controllable IoT devices are compromised [5]. Although risk reduction methodologies
for bulk power components have been proposed these are focused towards SCADA-based
systems which are owned, maintained, and operated by the utility under controlled
environments. Whereas, IoT devices are owned by customers, spread across a wide service
area, without supervised security policies.In this work, a detailed analysis of such
threats is performed on large-scale IoT deployments that could allow attackers to
control a large amount of aggregated power. Based on our research, future-growth of
large-load controllers and smart inverters could pose threats to grid operations due
to their rapid load changing capabilities, these changes could exceed steady-state
or transient design limits leading to unintended consequences. Therefore utilities
need to methodologically analyzing these risks. This paper proposes such a methodology,
which includes risk modeling and mitigation strategies.},
  articleno = {1},
  doi       = {10.1145/3332448.3332452},
  isbn      = {9781450366144},
  keywords  = {Cybersecurity, Internet of Things, Distributed Energy Resources},
  location  = {Richland, WA, USA},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3332448.3332452},
}

@InProceedings{Pouliot2016,
  author    = {Pouliot, David and Wright, Charles V.},
  booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {The Shadow Nemesis: Inference Attacks on Efficiently Deployable, Efficiently Searchable Encryption},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {1341–1352},
  publisher = {Association for Computing Machinery},
  series    = {CCS '16},
  abstract  = {Encrypting Internet communications has been the subject of renewed focus in recent
years. In order to add end-to-end encryption to legacy applications without losing
the convenience of full-text search, ShadowCrypt and Mimesis Aegis use a new cryptographic
technique called "efficiently deployable efficiently searchable encryption" (EDESE)
that allows a standard full-text search system to perform searches on encrypted data.
Compared to other recent techniques for searching on encrypted data, EDESE schemes
leak a great deal of statistical information about the encrypted messages and the
keywords they contain. Until now, the practical impact of this leakage has been difficult
to quantify.In this paper, we show that the adversary's task of matching plaintext
keywords to the opaque cryptographic identifiers used in EDESE can be reduced to the
well-known combinatorial optimization problem of weighted graph matching (WGM). Using
real email and chat data, we show how off-the-shelf WGM solvers can be used to accurately
and efficiently recover hundreds of the most common plaintext keywords from a set
of EDESE-encrypted messages. We show how to recover the tags from Bloom filters so
that the WGM solver can be used with the set of encrypted messages that utilizes a
Bloom filter to encode its search tags. We also show that the attack can be mitigated
by carefully configuring Bloom filter parameters.},
  doi       = {10.1145/2976749.2978401},
  isbn      = {9781450341394},
  keywords  = {security, efficiently deployable efficiently searchable encryption, encrypted email},
  location  = {Vienna, Austria},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2976749.2978401},
}

@InProceedings{Raftopoulos2011,
  author    = {Raftopoulos, Elias and Dimitropoulos, Xenofontas},
  booktitle = {Proceedings of the 2011 ACM SIGCOMM Conference on Internet Measurement Conference},
  title     = {Detecting, Validating and Characterizing Computer Infections in the Wild},
  year      = {2011},
  address   = {New York, NY, USA},
  pages     = {29–44},
  publisher = {Association for Computing Machinery},
  series    = {IMC '11},
  abstract  = {Although network intrusion detection systems (IDSs) have been studied for several
years, their operators are still overwhelmed by a large number of false-positive alerts.
In this work we study the following problem: from a large archive of intrusion alerts
collected in a production network, we want to detect with a small number of false
positives hosts within the network that have been infected by malware. Solving this
problem is essential not only for reducing the false-positive rate of IDSs, but also
for labeling traces collected in the wild with information about validated security
incidents. We use a 9-month long dataset of IDS alerts and we first build a novel
heuristic to detect infected hosts from the on average 3 million alerts we observe
per day. Our heuristic uses a statistical measure to find hosts that exhibit a repeated
multi-stage malicious footprint involving specific classes of alerts. A significant
part of our work is devoted to the validation of our heuristic. We conduct a complex
experiment to assess the security of suspected infected systems in a production environment
using data from several independent sources, including intrusion alerts, blacklists,
host scanning logs, vulnerability reports, and search engine queries. We find that
the false positive rate of our heuristic is 15% and analyze in-depth the root causes
of the false positives. Having validated our heuristic, we apply it to our entire
trace, and characterize various important properties of 9 thousand infected hosts
in total. For example, we find that among the infected hosts, a small number of heavy
hitters originate most outbound attacks and that future infections are more likely
to occur close to already infected hosts.},
  doi       = {10.1145/2068816.2068820},
  isbn      = {9781450310130},
  keywords  = {alert correlation, snort, network security, malware, j-measure, intrusion detection},
  location  = {Berlin, Germany},
  numpages  = {16},
  url       = {https://doi.org/10.1145/2068816.2068820},
}

@InProceedings{Perez2020,
  author    = {Perez, Daniel and Xu, Jiahua and Livshits, Benjamin},
  booktitle = {Proceedings of the ACM Internet Measurement Conference},
  title     = {Revisiting Transactional Statistics of High-Scalability Blockchains},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {535–550},
  publisher = {Association for Computing Machinery},
  series    = {IMC '20},
  abstract  = {Scalability has been a bottleneck for major blockchains such as Bitcoin and Ethereum.
Despite the significantly improved scalability claimed by several high-profile blockchain
projects, there has been little effort to understand how their transactional throughput
is being used. In this paper, we examine recent network traffic of three major high-scalability
blockchains---EOSIO, Tezos and XRP Ledger (XRPL)---over a period of seven months.
Our analysis reveals that only a small fraction of the transactions are used for value
transfer purposes. In particular, 96% of the transactions on EOSIO were triggered
by the airdrop of a currently valueless token; on Tezos, 76% of throughput was used
for maintaining consensus; and over 94% of transactions on XRPL carried no economic
value. We also identify a persisting airdrop on EOSIO as a DoS attack and detect a
two-month-long spam attack on XRPL. The paper explores the different designs of the
three blockchains and sheds light on how they could shape user behavior.},
  doi       = {10.1145/3419394.3423628},
  isbn      = {9781450381383},
  keywords  = {Blockchain, Transactional throughput, Internet measurements, Data extraction},
  location  = {Virtual Event, USA},
  numpages  = {16},
  url       = {https://doi.org/10.1145/3419394.3423628},
}

@Article{Mladenovic2021,
  author     = {Mladenovi\'{c}, Miljana and O\v{s}mjanski, Vera and Stankovi\'{c}, Sta\v{s}a Vuji\v{c}i\'{c}},
  journal    = {ACM Comput. Surv.},
  title      = {Cyber-Aggression, Cyberbullying, and Cyber-Grooming: A Survey and Research Challenges},
  year       = {2021},
  issn       = {0360-0300},
  month      = jan,
  number     = {1},
  volume     = {54},
  abstract   = {Cyber-aggression, cyberbullying, and cyber-grooming are distinctive and similar phenomena
that represent the objectionable content appearing on online social media. Timely
detection of the objectionable content is very important for its prevention and reduction.
This article explores and spotlights diversity of definitions of cyber-aggression,
cyberbulling, and cyber-grooming; analyzes current categorization systems and taxonomies;
identifies the targets, target categories, and subcategories of the subjects of the
objectionable content research; analyzes the ambiguity of the linguistic terms in
the domain; reviews present databases gathered for researching the field; explores
types of features used for modeling systems for automatic detection; and examines
methods for automatic detection and/or prediction of the objectionable content. The
results point to directions of system development for tracing transformations of objectionable
content over time on different online social platforms.},
  address    = {New York, NY, USA},
  articleno  = {1},
  doi        = {10.1145/3424246},
  issue_date = {April 2021},
  keywords   = {automatic hate speech detection, cyber-predators, Cyber-aggression, cyberbulluing, cyber-grooming},
  numpages   = {42},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3424246},
}

@InProceedings{Delimitrou2017,
  author    = {Delimitrou, Christina and Kozyrakis, Christos},
  booktitle = {Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems},
  title     = {Bolt: I Know What You Did Last Summer... In The Cloud},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {599–613},
  publisher = {Association for Computing Machinery},
  series    = {ASPLOS '17},
  abstract  = {Cloud providers routinely schedule multiple applications per physical host to increase
efficiency. The resulting interference on shared resources often leads to performance
degradation and, more importantly, security vulnerabilities. Interference can leak
important information ranging from a service's placement to confidential data, like
private keys. We present Bolt, a practical system that accurately detects the type
and characteristics of applications sharing a cloud platform based on the interference
an adversary sees on shared resources. Bolt leverages online data mining techniques
that only require 2-5 seconds for detection. In a multi-user study on EC2, Bolt correctly
identifies the characteristics of 385 out of 436 diverse workloads. Extracting this
information enables a wide spectrum of previously-impractical cloud attacks, including
denial of service attacks (DoS) that increase tail latency by 140x, as well as resource
freeing (RFA) and co-residency attacks. Finally, we show that while advanced isolation
mechanisms, such as cache partitioning lower detection accuracy, they are insufficient
to eliminate these vulnerabilities altogether. To do so, one must either disallow
core sharing, or only allow it between threads of the same application, leading to
significant inefficiencies and performance penalties.},
  doi       = {10.1145/3037697.3037703},
  isbn      = {9781450344654},
  keywords  = {denial of service attack, isolation, datacenter, security, interference, data mining, latency, cloud computing},
  location  = {Xi'an, China},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3037697.3037703},
}

@Article{Delimitrou2017a,
  author     = {Delimitrou, Christina and Kozyrakis, Christos},
  journal    = {SIGPLAN Not.},
  title      = {Bolt: I Know What You Did Last Summer... In The Cloud},
  year       = {2017},
  issn       = {0362-1340},
  month      = apr,
  number     = {4},
  pages      = {599–613},
  volume     = {52},
  abstract   = {Cloud providers routinely schedule multiple applications per physical host to increase
efficiency. The resulting interference on shared resources often leads to performance
degradation and, more importantly, security vulnerabilities. Interference can leak
important information ranging from a service's placement to confidential data, like
private keys. We present Bolt, a practical system that accurately detects the type
and characteristics of applications sharing a cloud platform based on the interference
an adversary sees on shared resources. Bolt leverages online data mining techniques
that only require 2-5 seconds for detection. In a multi-user study on EC2, Bolt correctly
identifies the characteristics of 385 out of 436 diverse workloads. Extracting this
information enables a wide spectrum of previously-impractical cloud attacks, including
denial of service attacks (DoS) that increase tail latency by 140x, as well as resource
freeing (RFA) and co-residency attacks. Finally, we show that while advanced isolation
mechanisms, such as cache partitioning lower detection accuracy, they are insufficient
to eliminate these vulnerabilities altogether. To do so, one must either disallow
core sharing, or only allow it between threads of the same application, leading to
significant inefficiencies and performance penalties.},
  address    = {New York, NY, USA},
  doi        = {10.1145/3093336.3037703},
  issue_date = {April 2017},
  keywords   = {denial of service attack, data mining, latency, interference, cloud computing, datacenter, security, isolation},
  numpages   = {15},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3093336.3037703},
}

@Article{Delimitrou2017b,
  author     = {Delimitrou, Christina and Kozyrakis, Christos},
  journal    = {SIGARCH Comput. Archit. News},
  title      = {Bolt: I Know What You Did Last Summer... In The Cloud},
  year       = {2017},
  issn       = {0163-5964},
  month      = apr,
  number     = {1},
  pages      = {599–613},
  volume     = {45},
  abstract   = {Cloud providers routinely schedule multiple applications per physical host to increase
efficiency. The resulting interference on shared resources often leads to performance
degradation and, more importantly, security vulnerabilities. Interference can leak
important information ranging from a service's placement to confidential data, like
private keys. We present Bolt, a practical system that accurately detects the type
and characteristics of applications sharing a cloud platform based on the interference
an adversary sees on shared resources. Bolt leverages online data mining techniques
that only require 2-5 seconds for detection. In a multi-user study on EC2, Bolt correctly
identifies the characteristics of 385 out of 436 diverse workloads. Extracting this
information enables a wide spectrum of previously-impractical cloud attacks, including
denial of service attacks (DoS) that increase tail latency by 140x, as well as resource
freeing (RFA) and co-residency attacks. Finally, we show that while advanced isolation
mechanisms, such as cache partitioning lower detection accuracy, they are insufficient
to eliminate these vulnerabilities altogether. To do so, one must either disallow
core sharing, or only allow it between threads of the same application, leading to
significant inefficiencies and performance penalties.},
  address    = {New York, NY, USA},
  doi        = {10.1145/3093337.3037703},
  issue_date = {March 2017},
  keywords   = {denial of service attack, security, datacenter, isolation, data mining, interference, cloud computing, latency},
  numpages   = {15},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3093337.3037703},
}

@InProceedings{Amit2020,
  author    = {Amit, Nadav and Tai, Amy and Wei, Michael},
  booktitle = {Proceedings of the Fifteenth European Conference on Computer Systems},
  title     = {Don't Shoot down TLB Shootdowns!},
  year      = {2020},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {EuroSys '20},
  abstract  = {Translation Lookaside Buffers (TLBs) are critical for building performant virtual
memory systems. Because most processors do not provide coherence for TLB mappings,
TLB shootdowns provide a software mechanism that invokes inter-processor interrupts
(IPLs) to synchronize TLBs. TLB shootdowns are expensive, so recent work has aimed
to avoid the frequency of shootdowns through techniques such as batching. We show
that aggressive batching can cause correctness issues and addressing them can obviate
the benefits of batching. Instead, our work takes a different approach which focuses
on both improving the performance of TLB shootdowns and carefully selecting where
to avoid shootdowns. We introduce four general techniques to improve shootdown performance:
(1) concurrently flush initiator and remote TLBs, (2) early acknowledgement from remote
cores, (3) cacheline consolidation of kernel data structures to reduce cacheline contention,
and (4) in-context flushing of userspace entries to address the overheads introduced
by Spectre and Meltdown mitigations. We also identify that TLB flushing can be avoiding
when handling copy-on-write (CoW) faults and some TLB shootdowns can be batched in
certain system calls. Overall, we show that our approach results in significant speedups
without sacrificing safety and correctness in both microbenchmarks and real-world
applications.},
  articleno = {35},
  doi       = {10.1145/3342195.3387518},
  isbn      = {9781450368827},
  location  = {Heraklion, Greece},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3342195.3387518},
}

@InProceedings{Konoth2018,
  author    = {Konoth, Radhesh Krishnan and Vineti, Emanuele and Moonsamy, Veelasha and Lindorfer, Martina and Kruegel, Christopher and Bos, Herbert and Vigna, Giovanni},
  booktitle = {Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {MineSweeper: An In-Depth Look into Drive-by Cryptocurrency Mining and Its Defense},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {1714–1730},
  publisher = {Association for Computing Machinery},
  series    = {CCS '18},
  abstract  = {A wave of alternative coins that can be effectively mined without specialized hardware,
and a surge in cryptocurrencies' market value has led to the development of cryptocurrency
mining ( cryptomining ) services, such as Coinhive, which can be easily integrated
into websites to monetize the computational power of their visitors. While legitimate
website operators are exploring these services as an alternative to advertisements,
they have also drawn the attention of cybercriminals: drive-by mining (also known
as cryptojacking ) is a new web-based attack, in which an infected website secretly
executes JavaScript code and/or a WebAssembly module in the user's browser to mine
cryptocurrencies without her consent. In this paper, we perform a comprehensive analysis
on Alexa's Top 1 Million websites to shed light on the prevalence and profitability
of this attack. We study the websites affected by drive-by mining to understand the
techniques being used to evade detection, and the latest web technologies being exploited
to efficiently mine cryptocurrency. As a result of our study, which covers 28 Coinhive-like
services that are widely being used by drive-by mining websites, we identified 20
active cryptomining campaigns. Motivated by our findings, we investigate possible
countermeasures against this type of attack. We discuss how current blacklisting approaches
and heuristics based on CPU usage are insufficient, and present MineSweeper, a novel
detection technique that is based on the intrinsic characteristics of cryptomining
code, and, thus, is resilient to obfuscation. Our approach could be integrated into
browsers to warn users about silent cryptomining when visiting websites that do not
ask for their consent.},
  doi       = {10.1145/3243734.3243858},
  isbn      = {9781450356930},
  keywords  = {drive-by attacks, malware, mining, cryptocurrency, cryptojacking},
  location  = {Toronto, Canada},
  numpages  = {17},
  url       = {https://doi.org/10.1145/3243734.3243858},
}

@InProceedings{Liu2016a,
  author    = {Liu, Yushan and Ji, Shouling and Mittal, Prateek},
  booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {SmartWalk: Enhancing Social Network Security via Adaptive Random Walks},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {492–503},
  publisher = {Association for Computing Machinery},
  series    = {CCS '16},
  abstract  = {Random walks form a critical foundation in many social network based security systems
and applications. Currently, the design of such social security mechanisms is limited
to the classical paradigm of using fixed-length random walks for all nodes on a social
graph. However, the fixed-length walk paradigm induces a poor trade-off between security
and other desirable properties. In this paper, we propose SmartWalk, a security enhancing
system which incorporates adaptive random walks in social network security applications.
We utilize a set of supervised machine learning techniques to predict the necessary
random walk length based on the structural characteristics of a social graph. Using
experiments on multiple real world topologies, we show that the desired walk length
starting from a specific node can be well predicted given the local features of the
node, and limited knowledge for a small set of training nodes. We describe node-adaptive
and path-adaptive random walk usage models, where the walk length adaptively changes
based on the starting node and the intermediate nodes on the path, respectively. We
experimentally demonstrate the applicability of adaptive random walks on a number
of social network based security and privacy systems, including Sybil defenses, anonymous
communication and link privacy preserving systems, and show up to two orders of magnitude
improvement in performance.},
  doi       = {10.1145/2976749.2978319},
  isbn      = {9781450341394},
  keywords  = {network security and privacy, adaptive random walks, social networks},
  location  = {Vienna, Austria},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2976749.2978319},
}

@InProceedings{Cheng2016,
  author    = {Cheng, Raymond and Scott, William and Ellenbogen, Paul and Howell, Jon and Roesner, Franziska and Krishnamurthy, Arvind and Anderson, Thomas},
  booktitle = {Proceedings of the Seventh ACM Symposium on Cloud Computing},
  title     = {Radiatus: A Shared-Nothing Server-Side Web Architecture},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {237–250},
  publisher = {Association for Computing Machinery},
  series    = {SoCC '16},
  abstract  = {Web applications are a frequent target of successful attacks. In most web frameworks,
the damage is amplified by the fact that application code is responsible for security
enforcement. In this paper, we design and evaluate Radiatus, a shared-nothing web
framework where application-specific computation and storage on the server is contained
within a sandbox with the privileges of the end-user. By strongly isolating users,
user data and service availability can be protected from application vulnerabilities.To
make Radiatus practical at the scale of modern web applications, we introduce a distributed
capabilities system to allow fine-grained secure resource sharing across the many
distributed services that compose an application. We analyze the strengths and weaknesses
of a shared-nothing web architecture, which protects applications from a large class
of vulnerabilities, but adds an overhead of 60.7% per server and requires an additional
31MB of memory per active user. We demonstrate that the system can scale to 20K operations
per second on a 500-node AWS cluster.},
  doi       = {10.1145/2987550.2987571},
  isbn      = {9781450345255},
  keywords  = {security, isolation, web application},
  location  = {Santa Clara, CA, USA},
  numpages  = {14},
  url       = {https://doi.org/10.1145/2987550.2987571},
}

@InProceedings{Fass2019,
  author    = {Fass, Aurore and Backes, Michael and Stock, Ben},
  booktitle = {Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {HideNoSeek: Camouflaging Malicious JavaScript in Benign ASTs},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {1899–1913},
  publisher = {Association for Computing Machinery},
  series    = {CCS '19},
  abstract  = {In the malware field, learning-based systems have become popular to detect new malicious
variants. Nevertheless, attackers with specific and internal knowledge of a target
system may be able to produce input samples which are misclassified. In practice,
the assumption of strong attackers is not realistic as it implies access to insider
information. We instead propose HideNoSeek, a novel and generic camouflage attack,
which evades the entire class of detectors based on syntactic features, without needing
any information about the system it is trying to evade. Our attack consists of changing
the constructs of malicious JavaScript samples to reproduce a benign syntax. For this
purpose, we automatically rewrite the Abstract Syntax Trees (ASTs) of malicious JavaScript
inputs into existing benign ones. In particular, HideNoSeek uses malicious seeds and
searches for isomorphic subgraphs between the seeds and traditional benign scripts.
Specifically, it replaces benign sub-ASTs by their malicious equivalents (same syntactic
structure) and adjusts the benign data dependencies--without changing the AST--so
that the malicious semantics is kept. In practice, we leveraged 23 malicious seeds
to generate 91,020 malicious scripts, which perfectly reproduce ASTs of Alexa top
10,000 web pages. Also, we can produce on average 14 different malicious samples with
the same AST as each Alexa top 10. Overall, a standard trained classifier has 99.98%
false negatives with HideNoSeek inputs, while a classifier trained on such samples
has over 88.74% false positives, rendering the targeted static detectors unreliable.},
  doi       = {10.1145/3319535.3345656},
  isbn      = {9781450367479},
  keywords  = {AST, web security, adversarial attacks, malicious JavaScript},
  location  = {London, United Kingdom},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3319535.3345656},
}

@Article{Rao2016,
  author     = {Rao, Huaming and Huang, Shih-Wen and Fu, Wai-Tat},
  journal    = {ACM Trans. Intell. Syst. Technol.},
  title      = {Leveraging Human Computations to Improve Schematization of Spatial Relations from Imagery},
  year       = {2016},
  issn       = {2157-6904},
  month      = mar,
  number     = {4},
  volume     = {7},
  abstract   = {The process of generating schematic maps of salient objects from a set of pictures
of an indoor environment is challenging. It has been an active area of research as
it is crucial to a wide range of context- and location-aware services, as well as
for general scene understanding. Although many automated systems have been developed
to solve the problem, most of them either require predefining labels or expensive
equipment, such as RGBD sensors or lasers, to scan the environment. In this article,
we introduce a prototype system to show how human computations can be utilized to
generate schematic maps from a set of pictures, without making strong assumptions
or demanding extra devices. The system requires humans (crowd workers from Amazon
Mechanical Turks) to do simple spatial mapping tasks in various conditions, and their
data are aggregated by filtering and clustering techniques that allow salient cues
to be identified in the pictures and their spatial relations to be inferred and projected
on a two-dimensional map. In particular, we tested and demonstrated the effectiveness
of two methods that improved the quality of the generated schematic map: (1) We encouraged
humans to adopt an allocentric representations of salient objects by guiding them
to perform mental rotations of these objects and (2) we sensitized human perception
by guided arrows superimposed on the imagery to improve the accuracy of depth and
width estimation. We demonstrated the feasibility of our system by evaluating the
results of schematic maps generated from indoor pictures taken from an office building.
By calculating Riemannian shape distances between the generated maps to the ground
truth, we found that the generated schematic maps captured the spatial relations well.
Our results showed that the combination of human computations and machine clustering
could lead to more-accurate schematized maps from imagery. We also discuss how our
approach may have important insights on methods that leverage human computations in
other areas.},
  address    = {New York, NY, USA},
  articleno  = {54},
  doi        = {10.1145/2873065},
  issue_date = {July 2016},
  keywords   = {spatial cognition, Human computations, picture schematization, crowdsourcing},
  numpages   = {21},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2873065},
}

@InProceedings{Xing2019,
  author    = {Xing, Jiarong and Wu, Wenqing and Chen, Ang},
  booktitle = {Proceedings of the 18th ACM Workshop on Hot Topics in Networks},
  title     = {Architecting Programmable Data Plane Defenses into the Network with FastFlex},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {161–169},
  publisher = {Association for Computing Machinery},
  series    = {HotNets '19},
  abstract  = {This paper is motivated by the ever increasing scale and diversity of attacks that
are best handled by the network infrastructure. FastFlex builds upon recent progress,
which has developed a variety of network defenses in programmable data planes, and
takes this trend one step further: it aims to develop architectural support for these
defenses as a first-class citizen. We envision that the network architecture would
support these defenses as naturally as it does routing---as the network routes traffic
end-to-end, it also turns the defenses on and off as needed for attack mitigation.
We propose a key abstraction: the multimode data plane. Normally, it operates under
optimal configurations computed by centralized control, but upon attacks, it performs
distributed mode changes entirely in data plane for mitigation. Mixed-vector attacks
would trigger co-existing modes at different regions of the network, and attacks that
rapidly change would be met with equally fast mode adaptations. We sketch this vision,
discuss the opportunities and challenges it involves, and present a use case on link-flooding
defense.},
  doi       = {10.1145/3365609.3365860},
  isbn      = {9781450370202},
  location  = {Princeton, NJ, USA},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3365609.3365860},
}

@Article{Rahman2021,
  author     = {Rahman, M. Tanjidur and Dipu, Nusrat Farzana and Mehta, Dhwani and Tajik, Shahin and Tehranipoor, Mark and Asadizanjani, Navid},
  journal    = {J. Emerg. Technol. Comput. Syst.},
  title      = {CONCEALING-Gate: Optical Contactless Probing Resilient Design},
  year       = {2021},
  issn       = {1550-4832},
  month      = jun,
  number     = {3},
  volume     = {17},
  abstract   = {Optical probing, though developed as silicon debugging tools from the chip backside,
has shown its capability of extracting secret data, such as cryptographic keys and
user identifications, from modern system-on-chip devices. Existing optical probing
countermeasures are based on detecting any device modification attempt or abrupt change
in operating conditions during asset extraction. These countermeasures usually require
additional fabrication steps and cause area and power overheads. In this article,
we propose a novel low-overhead design methodology to prevent optical probing. It
leverages additional operational logic gates, termed as “CONCEALING-Gates,” inserted
as neighbor gates of the logic gates connected to the nets carrying asset signals.
The switching activity of the asset carrying logic is camouflaged with the switching
activity of the concealing-gate. The input signal and placement in the layout of the
concealing-gates must be selected in such a way that they remain equally effective
in preventing different variants of optical probing, i.e., electro-optical frequency
mapping and Electro-optical probing. The methodology is suitable for the existing
ASIC/FPGA design flow and fabrication process, since designing new standard logic
cells is not required. We have performed a comprehensive security evaluation of the
concealing-gates using a security metric developed based on the parameters that are
crucial for optical probing. The attack resiliency of the logic cells, protected by
concealing-gates, is evaluated using an empirical study-based simulation methodology
and experimental validation. Our analysis has shown that in the presence of concealing-gates,
logic cells achieve high resiliency against optical contactless probing techniques.},
  address    = {New York, NY, USA},
  articleno  = {39},
  doi        = {10.1145/3446998},
  issue_date = {June 2021},
  keywords   = {hardware security, optical probing, logic locking, Backside protection},
  numpages   = {25},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3446998},
}

@InProceedings{PereidaGarcia2016,
  author    = {Pereida Garc\'{\i}a, Cesar and Brumley, Billy Bob and Yarom, Yuval},
  booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {"Make Sure DSA Signing Exponentiations Really Are Constant-Time"},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {1639–1650},
  publisher = {Association for Computing Machinery},
  series    = {CCS '16},
  abstract  = {TLS and SSH are two of the most commonly used protocols for securing Internet traffic.
Many of the implementations of these protocols rely on the cryptographic primitives
provided in the OpenSSL library. In this work we disclose a vulnerability in OpenSSL,
affecting all versions and forks (e.g. LibreSSL and BoringSSL) since roughly October
2005, which renders the implementation of the DSA signature scheme vulnerable to cache-based
side-channel attacks. Exploiting the software defect, we demonstrate the first published
cache-based key-recovery attack on these protocols: 260 SSH-2 handshakes to extract
a 1024/160-bit DSA host key from an OpenSSH server, and 580 TLS 1.2 handshakes to
extract a 2048/256-bit DSA key from an stunnel server.},
  doi       = {10.1145/2976749.2978420},
  isbn      = {9781450341394},
  keywords  = {side-channel analysis, cache-timing attacks, applied cryptography, timing attacks, digital signatures, DSA, CVE-2016-2178, OpenSSL},
  location  = {Vienna, Austria},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2976749.2978420},
}

@Article{Charles2021,
  author     = {Charles, Subodha and Mishra, Prabhat},
  journal    = {ACM Comput. Surv.},
  title      = {A Survey of Network-on-Chip Security Attacks and Countermeasures},
  year       = {2021},
  issn       = {0360-0300},
  month      = may,
  number     = {5},
  volume     = {54},
  abstract   = {With the advances of chip manufacturing technologies, computer architects have been
able to integrate an increasing number of processors and other heterogeneous components
on the same chip. Network-on-Chip (NoC) is widely employed by multicore System-on-Chip
(SoC) architectures to cater to their communication requirements. NoC has received
significant attention from both attackers and defenders. The increased usage of NoC
and its distributed nature across the chip has made it a focal point of potential
security attacks. Due to its prime location in the SoC coupled with connectivity with
various components, NoC can be effectively utilized to implement security countermeasures
to protect the SoC from potential attacks. There is a wide variety of existing literature
on NoC security attacks and countermeasures. In this article, we provide a comprehensive
survey of security vulnerabilities in NoC-based SoC architectures and discuss relevant
countermeasures.},
  address    = {New York, NY, USA},
  articleno  = {101},
  doi        = {10.1145/3450964},
  issue_date = {June 2021},
  keywords   = {machine learning, Hardware security},
  numpages   = {36},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3450964},
}

@InProceedings{Arapinis2012,
  author    = {Arapinis, Myrto and Mancini, Loretta and Ritter, Eike and Ryan, Mark and Golde, Nico and Redon, Kevin and Borgaonkar, Ravishankar},
  booktitle = {Proceedings of the 2012 ACM Conference on Computer and Communications Security},
  title     = {New Privacy Issues in Mobile Telephony: Fix and Verification},
  year      = {2012},
  address   = {New York, NY, USA},
  pages     = {205–216},
  publisher = {Association for Computing Machinery},
  series    = {CCS '12},
  abstract  = {Mobile telephony equipment is daily carried by billions of subscribers everywhere
they go. Avoiding linkability of subscribers by third parties, and protecting the
privacy of those subscribers is one of the goals of mobile telecommunication protocols.
We use formal methods to model and analyse the security properties of 3G protocols.
We expose two novel threats to the user privacy in 3G telephony systems, which make
it possible to trace and identify mobile telephony subscribers, and we demonstrate
the feasibility of a low cost implementation of these attacks. We propose fixes to
these privacy issues, which also take into account and solve other privacy attacks
known from the literature. We successfully prove that our privacy-friendly fixes satisfy
the desired unlinkability and anonymity properties using the automatic verification
tool ProVerif.},
  doi       = {10.1145/2382196.2382221},
  isbn      = {9781450316514},
  keywords  = {anonymity, unlinkability, proverif, mobile telephony},
  location  = {Raleigh, North Carolina, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2382196.2382221},
}

@InProceedings{Duermuth2016,
  author    = {D\"{u}rmuth, Markus and Oswald, David and Pastewka, Niklas},
  booktitle = {Proceedings of the 6th International Workshop on Trustworthy Embedded Devices},
  title     = {Side-Channel Attacks on Fingerprint Matching Algorithms},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {3–13},
  publisher = {Association for Computing Machinery},
  series    = {TrustED '16},
  abstract  = {Biometric authentication schemes are frequently used to establish the identity of
a user. Often, a trusted hardware device is used to decide if a provided biometric
feature is sufficiently close to the features stored by the legitimate user during
enrollment. In this paper, we address the question whether the stored features can
be extracted with side-channel attacks. We consider several models for types of leakage
that are relevant specifically for fingerprint verification, and show results for
attacks against the Bozorth3 and a custom matching algorithm. This work shows an interesting
path for future research on the susceptibility of biometric algorithms towards side-channel
attacks.},
  doi       = {10.1145/2995289.2995294},
  isbn      = {9781450345675},
  keywords  = {fingerprint matching, bozorth3, biometry, simple power analysis, side-channel analysis},
  location  = {Vienna, Austria},
  numpages  = {11},
  url       = {https://doi.org/10.1145/2995289.2995294},
}

@InProceedings{Wolinsky2013,
  author    = {Wolinsky, David Isaac and Syta, Ewa and Ford, Bryan},
  booktitle = {Proceedings of the 2013 ACM SIGSAC Conference on Computer &amp; Communications Security},
  title     = {Hang with Your Buddies to Resist Intersection Attacks},
  year      = {2013},
  address   = {New York, NY, USA},
  pages     = {1153–1166},
  publisher = {Association for Computing Machinery},
  series    = {CCS '13},
  abstract  = {Some anonymity schemes might in principle protect users from pervasive network surveillance--but
only if all messages are independent and unlinkable. Users in practice often need
pseudonymity--sending messages intentionally linkable to each other but not to the
sender--but pseudonymity in dynamic networks exposes users to intersection attacks.
We present Buddies, the first systematic design for intersection attack resistance
in practical anonymity systems. Buddies groups users dynamically into buddy sets,
controlling message transmission to make buddies within a set behaviorally indistinguishable
under traffic analysis. To manage the inevitable tradeoffs between anonymity guarantees
and communication responsiveness, Buddies enables users to select independent attack
mitigation policies for each pseudonym. Using trace-based simulations and a working
prototype, we find that Buddies can guarantee non-trivial anonymity set sizes in realistic
chat/microblogging scenarios, for both short-lived and long-lived pseudonyms.},
  doi       = {10.1145/2508859.2516740},
  isbn      = {9781450324779},
  keywords  = {anonymity, disclosure, intersection, pseudonymity},
  location  = {Berlin, Germany},
  numpages  = {14},
  url       = {https://doi.org/10.1145/2508859.2516740},
}

@InProceedings{Safarzadeh2020,
  author    = {Safarzadeh, Mahdieh and Abadi, Mahdi and Nowroozi, Alireza},
  booktitle = {Proceedings of the 35th Annual ACM Symposium on Applied Computing},
  title     = {HAL-RD: Cross-Correlating Heterogeneous Alerts and Logs Using Resource Dependencies},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {1726–1735},
  publisher = {Association for Computing Machinery},
  series    = {SAC '20},
  abstract  = {Many organizations today use a variety of security and monitoring tools at various
levels of defense. These tools often generate heterogeneous alerts and logs when an
attack occurs. Because of the large volume and dispersion of these alerts and logs,
the manual cross-correlation of them is a time-consuming and labor-intensive task.
The main challenge is that heterogeneous alerts and logs generated as a result of
an attack stage do not necessarily have common features, or there are no explicit
relationships between them that can be used for cross-correlation. In this paper,
we overcome this deficiency by presenting HAL-RD, a novel technique that uses resource
dependencies to cross-correlate heterogeneous alerts and logs. In this technique,
we track logs for backward and forward dependencies between resources. This information
is then used to construct an attack state graph, which is a directed graph whose nodes
represent attack states and whose directed edges represent the chronological ordering
between them. Each attack state integrates information found in multiple heterogeneous
alerts, logs, and OS-level operations, which relate to one stage in a multi-stage
attack. In certain circumstances, the attack state graph is incrementally updated.
By doing this, when an attacker continues his/her multi-stage attack after a delay,
all of his/her activities are identified. The evaluation results demonstrate the effectiveness
of HAL-RD for cross-correlating heterogeneous alerts and logs.},
  doi       = {10.1145/3341105.3373911},
  isbn      = {9781450368667},
  keywords  = {attack state graph, heterogeneous alerts and logs, alert correlation, alert enrichment, cross-correlation},
  location  = {Brno, Czech Republic},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3341105.3373911},
}

@InProceedings{Spreitzenbarth2013,
  author    = {Spreitzenbarth, Michael and Freiling, Felix and Echtler, Florian and Schreck, Thomas and Hoffmann, Johannes},
  booktitle = {Proceedings of the 28th Annual ACM Symposium on Applied Computing},
  title     = {Mobile-Sandbox: Having a Deeper Look into Android Applications},
  year      = {2013},
  address   = {New York, NY, USA},
  pages     = {1808–1815},
  publisher = {Association for Computing Machinery},
  series    = {SAC '13},
  abstract  = {Smartphones in general and Android in particular are increasingly shifting into the
focus of cybercriminals. For understanding the threat to security and privacy it is
important for security researchers to analyze malicious software written for these
systems. The exploding number of Android malware calls for automation in the analysis.
In this paper, we present Mobile-Sandbox, a system designed to automatically analyze
Android applications in two novel ways: (1) it combines static and dynamic analysis,
i.e., results of static analysis are used to guide dynamic analysis and extend coverage
of executed code, and (2) it uses specific techniques to log calls to native (i.e.,
"non-Java") APIs. We evaluated the system on more than 36,000 applications from Asian
third-party mobile markets and found that 24% of all applications actually use native
calls in their code.},
  doi       = {10.1145/2480362.2480701},
  isbn      = {9781450316569},
  keywords  = {malware, application analysis, Android},
  location  = {Coimbra, Portugal},
  numpages  = {8},
  url       = {https://doi.org/10.1145/2480362.2480701},
}

@InProceedings{Kashyap2012,
  author    = {Kashyap, Hirak Jyoti and Bhattacharyya, D. K.},
  booktitle = {Proceedings of the Second International Conference on Computational Science, Engineering and Information Technology},
  title     = {A DDoS Attack Detection Mechanism Based on Protocol Specific Traffic Features},
  year      = {2012},
  address   = {New York, NY, USA},
  pages     = {194–200},
  publisher = {Association for Computing Machinery},
  series    = {CCSEIT '12},
  abstract  = {This paper focuses on finding the most relevant and smallest possible subset of features
for DDoS attack detection. A generic architecture of victim end DDoS defense mechanisms
is presented and a near real time anomaly detection mechanism with high detection
accuracy is introduced. The method is evaluated based on two real time and one benchmark
dataset.},
  doi       = {10.1145/2393216.2393249},
  isbn      = {9781450313100},
  keywords  = {linear correlation, dimensionality reduction, intrusion data, LCFS},
  location  = {Coimbatore UNK, India},
  numpages  = {7},
  url       = {https://doi.org/10.1145/2393216.2393249},
}

@Article{Sethi2018,
  author     = {Sethi, Tegjyot Singh and Kantardzic, Mehmed},
  journal    = {Ubiquity},
  title      = {When Good Machine Learning Leads to Bad Security: Big Data (Ubiquity Symposium)},
  year       = {2018},
  month      = may,
  number     = {May},
  volume     = {2018},
  abstract   = {While machine learning has proven to be promising in several application domains,
our understanding of its behavior and limitations is still in its nascent stages.
One such domain is that of cybersecurity, where machine learning models are replacing
traditional rule based systems, owing to their ability to generalize and deal with
large scale attacks which are not seen before. However, the naive transfer of machine
learning principles to the domain of security needs to be taken with caution. Machine
learning was not designed with security in mind and as such is prone to adversarial
manipulation and reverse engineering. While most data based learning models rely on
a static assumption of the world, the security landscape is one that is especially
dynamic, with an ongoing never ending arms race between the system designer and the
attackers. Any solution designed for such a domain needs to take into account an active
adversary and needs to evolve over time, in the face of emerging threats. We term
this as the "Dynamic Adversarial Mining" problem, and this paper provides motivation
and foundation for this new interdisciplinary area of research, at the crossroads
of machine learning, cybersecurity, and streaming data mining.},
  address    = {New York, NY, USA},
  articleno  = {1},
  doi        = {10.1145/3158346},
  issue_date = {May 2018},
  numpages   = {14},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3158346},
}

@InProceedings{Guan2016,
  author    = {Guan, Chong and Sun, Kun and Wang, Zhan and Zhu, WenTao},
  booktitle = {Proceedings of the 11th ACM on Asia Conference on Computer and Communications Security},
  title     = {Privacy Breach by Exploiting PostMessage in HTML5: Identification, Evaluation, and Countermeasure},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {629–640},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '16},
  abstract  = {The postMessage mechanism in HTML5 enables different webpage origins to exchange information
and communicate. It becomes increasingly popular among the websites that need to import
contents from third-party services, such as advertisements and preferable recommendations.
Ideally, a receiver function should be locally implemented in the hosting page that
needs to receive third-party messages. However, in the real world, the receiver function
is usually provided by a third-party service provider, and the function code is imported
via the HTML "script" tag so that the imported code is deemed as from the same origin
with the hosting page. In the case that a site uses multiple third-party services,
all the receiver functions imported by the hosting page can receive messages from
any third-party provider. Based on this observation, we identify a new information
leakage threat named DangerNeighbor attacks that allow a malicious service eavesdrop
messages from other services to the hosting page.We study 5000 popular websites and
find that the DangerNeighbor attack is a real threat to the sites adopting the postMessage
mechanism. To defeat this attack, we propose an easily deployable approach to protect
messages from being eavesdropped by a malicious provider. In this approach, the site
owner simply imports a piece of JavaScript code and specifies a mapping table, where
messages from different origins are associated with corresponding receiver functions,
respectively. The approach, which is transparent to the providers, ensures that a
receiver function only receives messages from a specific origin.},
  doi       = {10.1145/2897845.2897901},
  isbn      = {9781450342339},
  keywords  = {HTML5, privacy, postmessage},
  location  = {Xi'an, China},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2897845.2897901},
}

@InProceedings{Blochberger2019,
  author    = {Blochberger, Maximilian and Rieck, Jakob and Burkert, Christian and Mueller, Tobias and Federrath, Hannes},
  booktitle = {Proceedings of the 18th ACM Workshop on Privacy in the Electronic Society},
  title     = {State of the Sandbox: Investigating MacOS Application Security},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {150–161},
  publisher = {Association for Computing Machinery},
  series    = {WPES'19},
  abstract  = {Sandboxing is a way to deliberately restrict applications accessing resources that
they do not need to function properly. Sandboxing is intended to limit the effect
of potential exploits and to mitigate overreach to personal data. Since June 1, 2012,
sandboxing is a mandatory requirement for apps distributed through the Mac App Store
(MAS). In addition, Apple has made it easier for developers to specify sandbox entitlements
- capabilities that allow the app to access certain resources. However, sandboxing
is still optional for macOS apps distributed outside Apple's official app store. This
paper provides two contributions. First, the sandbox mechanism of macOS is analyzed
and a critical sandbox-bypass is identified. Second, the general adoption of the sandbox
mechanism, as well as app-specific sandbox configurations are evaluated. For that
purpose all 8366 free apps of the MAS, making 25 % of all apps available on the MAS,
as well as 4672 apps retrieved from MacUpdate (MU), a third-party app store, were
analyzed dynamically. The dataset is over eight times larger than the second biggest
study of macOS apps. It is shown that more than 94 % of apps on the MAS are sandboxed.
However, more than 89 % of apps distributed through MU do not make use of sandboxing,
putting users' data at risk.},
  doi       = {10.1145/3338498.3358654},
  isbn      = {9781450368308},
  keywords  = {macos, sandboxing, capabilities, entitlements},
  location  = {London, United Kingdom},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3338498.3358654},
}

@Article{Gilad2013a,
  author     = {Gilad, Yossi and Herzberg, Amir},
  journal    = {ACM Trans. Inf. Syst. Secur.},
  title      = {Fragmentation Considered Vulnerable},
  year       = {2013},
  issn       = {1094-9224},
  month      = apr,
  number     = {4},
  volume     = {15},
  abstract   = {We show that fragmented IPv4 and IPv6 traffic is vulnerable to effective interception
and denial-of-service (DoS) attacks by an off-path attacker. Specifically, we demonstrate
a weak attacker intercepting more than 80% of the data between peers and causing over
94% loss rate.We show that our attacks are practical through experimental validation
on popular industrial and open-source products, with realistic network setups that
involve NAT or tunneling and include concurrent legitimate traffic as well as packet
losses. The interception attack requires a zombie agent behind the same NAT or tunnel-gateway
as the victim destination; the DoS attack only requires a puppet agent, that is, a
sandboxed applet or script running in web-browser context.The complexity of our attacks
depends on the predictability of the IP Identification (ID) field which is typically
implemented as one or multiple counters, as allowed and recommended by the IP specifications.
The attacks are much simpler and more efficient for implementations, such as Windows,
which use one ID counter for all destinations. Therefore, much of our focus is on
presenting effective attacks for implementations, such as Linux, which use per-destination
ID counters.We present practical defenses for the attacks presented in this article,
the defenses can be deployed on network firewalls without changes to hosts or operating
system kernel.},
  address    = {New York, NY, USA},
  articleno  = {16},
  doi        = {10.1145/2445566.2445568},
  issue_date = {April 2013},
  keywords   = {IP fragmentation, denial of service},
  numpages   = {31},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2445566.2445568},
}

@InProceedings{Kalliola2018,
  author    = {Kalliola, Aapo and Lal, Shankar and Ahola, Kimmo and Oliver, Ian and Miche, Yoan and Aura, Tuomas},
  booktitle = {Proceedings of the 13th International Conference on Availability, Reliability and Security},
  title     = {Security Wrapper Orchestration in Cloud},
  year      = {2018},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ARES 2018},
  abstract  = {We present an architecture and implementation of the security wrapper concept for
the protection of virtualized network functions in a cloud environment. The security
wrapper is the enclosing of a set of virtualized resources within a data plane transparent
protective envelope in the network forwarding graph. The extent and capabilities of
this envelope are dynamic. We present a prototype implementation of the security wrapper
and analyze its behaviour in different operation scenarios. Measurements of the wrapper
orchestration delays, resource overhead and data plane traffic impact indicate that
the proposed mechanism can be deployed in virtualized networks with little overhead
while remaining relatively transparent to the traffic traversing the security wrapper
boundary.},
  articleno = {29},
  doi       = {10.1145/3230833.3232853},
  isbn      = {9781450364485},
  location  = {Hamburg, Germany},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3230833.3232853},
}

@InProceedings{Bajtos2018,
  author    = {Bajto\v{s}, Tom\'{a}\v{s} and Sokol, Pavol and M\'{e}ze\v{s}ov\'{a}, Ter\'{e}zia},
  booktitle = {Proceedings of the Central European Cybersecurity Conference 2018},
  title     = {Virtual Honeypots and Detection of Telnet Botnets},
  year      = {2018},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {CECC 2018},
  abstract  = {Despite recommendations to not use telnet, there is an increasing number of telnet-based
botnets and a need to analyse these attacks. We deployed a network of high interaction
honeypots that simulate telnet devices. From the collected data, we created a dataset
that we analysed from different perspectives. In this paper, we focus on the infection
phase of botnets. Based on the found signatures collected by our samples, we can divide
the botnets into 9 families. We show dependencies between commands, and between commands
and directories used to propagate botnets.},
  articleno = {2},
  doi       = {10.1145/3277570.3277572},
  isbn      = {9781450365154},
  keywords  = {telnet, botnet, analysis, honeypots},
  location  = {Ljubljana, Slovenia},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3277570.3277572},
}

@InProceedings{Dresen2020,
  author    = {Dresen, Christian and Ising, Fabian and Poddebniak, Damian and Kappert, Tobias and Holz, Thorsten and Schinzel, Sebastian},
  booktitle = {Proceedings of the 15th ACM Asia Conference on Computer and Communications Security},
  title     = {CORSICA: Cross-Origin Web Service Identification},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {409–419},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '20},
  abstract  = {Vulnerabilities in private networks are difficult to detect for attackers outside
of the network. While there are known methods for port scanning internal hosts that
work by luring unwitting internal users to an external web page that hosts malicious
JavaScript code, no such method for detailed and precise service identification is
known. The reason is that the Same Origin Policy (SOP) prevents access to HTTP responses
of other origins by default.We perform a structured analysis of loopholes in the SOP
that can be used to identify web applications across network boundaries. For this,
we analyze HTML5, CSS, and JavaScript features of standard-compliant web browsers
that may leak sensitive information about cross-origin content. The results reveal
several novel techniques, including leaking JavaScript function names or styles of
cross-origin requests that are available in all common browsers.We implement and test
these techniques in a tool called CORSICA. It can successfully identify 31 of 42 (74%)
of web services running on different IoT devices as well as the version numbers of
the four most widely used content management systems WordPress, Drupal, Joomla, and
TYPO3. CORSICA can also determine the patch level on average down to three versions
(WordPress), six versions (Drupal), two versions (Joomla), and four versions (TYPO3)
with only ten requests on average. Furthermore, CORSICA is able to identify 48 WordPress
plugins containing 65 vulnerabilities.Finally, we analyze mitigation strategies and
show that the proposed but not yet implemented strategies Cross-Origin Resource Policy
(CORP) and Sec-Metadata would prevent our identification techniques.},
  doi       = {10.1145/3320269.3372196},
  isbn      = {9781450367509},
  keywords  = {web security, JavaScript, SOP, fingerprinting, perimeter security, service identification},
  location  = {Taipei, Taiwan},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3320269.3372196},
}

@InProceedings{Spreitzer2016,
  author    = {Spreitzer, Raphael and Griesmayr, Simone and Korak, Thomas and Mangard, Stefan},
  booktitle = {Proceedings of the 9th ACM Conference on Security &amp; Privacy in Wireless and Mobile Networks},
  title     = {Exploiting Data-Usage Statistics for Website Fingerprinting Attacks on Android},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {49–60},
  publisher = {Association for Computing Machinery},
  series    = {WiSec '16},
  abstract  = {The browsing behavior of a user allows to infer personal details, such as health status,
political interests, sexual orientation, etc. In order to protect this sensitive information
and to cope with possible privacy threats, defense mechanisms like SSH tunnels and
anonymity networks (e.g., Tor) have been established. A known shortcoming of these
defenses is that website fingerprinting attacks allow to infer a user's browsing behavior
based on traffic analysis techniques. However, website fingerprinting typically assumes
access to the client's network or to a router near the client, which restricts the
applicability of these attacks.In this work, we show that this rather strong assumption
is not required for website fingerprinting attacks. Our client-side attack overcomes
several limitations and assumptions of network-based fingerprinting attacks, e.g.,
network conditions and traffic noise, disabled browser caches, expensive training
phases, etc. Thereby, we eliminate assumptions used for academic purposes and present
a practical attack that can be implemented easily and deployed on a large scale. Eventually,
we show that an unprivileged application can infer the browsing behavior by exploiting
the unprotected access to the Android data-usage statistics. More specifically, we
are able to infer 97% of 2,500 page visits out of a set of 500 monitored pages correctly.
Even if the traffic is routed through Tor by using the Orbot proxy in combination
with the Orweb browser, we can infer 95% of 500 page visits out of a set of 100 monitored
pages correctly. Thus, the READ_HISTORY_BOOKMARKS permission, which is supposed to
protect the browsing behavior, does not provide protection.},
  doi       = {10.1145/2939918.2939922},
  isbn      = {9781450342704},
  keywords  = {side-channel attack, mobile security, mobile malware, website fingerprinting, data-usage statistics},
  location  = {Darmstadt, Germany},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2939918.2939922},
}

@InProceedings{Gelernter2015,
  author    = {Gelernter, Nethanel and Grinstein, Yoel and Herzberg, Amir},
  booktitle = {Proceedings of the 31st Annual Computer Security Applications Conference},
  title     = {Cross-Site Framing Attacks},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {161–170},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC 2015},
  abstract  = {We identify the threat of cross-site framing attacks, which involves planting false
evidence that incriminates computer users, without requiring access to their computer.
We further show that a variety of framing-evidence can be planted using only modest
framing-attacker capabilities. The attacker can plant evidence in both the logs of
popular reputable sites and in the computer of the victim, without requiring client-side
malware and without leaving traces.To infect the records of several of the most popular
sites, we identified operations that are often considered benign and hence not protected
from cross-site request forgery (CSRF) attacks. We demonstrate the attacks on the
largest search engines: Google, Bing, and Yahoo!, on Youtube and Facebook, and on
the e-commerce sites: Amazon, eBay, and Craigslist.To plant pieces of framing evidence
on the computer, we abused the vulnerabilities of browsers and weaknesses in the examination
procedure done by forensic software. Specifically, we show that it is possible to
manipulate the common NTFS file system and to plant files on the hard disk of the
victim, without leaving any traces indicating that these files were created via the
browser.We validated the effectiveness of the framing evidence with the assistance
of law authorities, in addition to using prominent forensic software. This work also
discusses tactics for defense against cross-site framing and its applicability to
web-services, browsers, and forensic software.},
  doi       = {10.1145/2818000.2818029},
  isbn      = {9781450336826},
  keywords  = {Web attacks, Security, Framing, Forensic},
  location  = {Los Angeles, CA, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2818000.2818029},
}

@InProceedings{Park2016,
  author    = {Park, Shinjo and Shaik, Altaf and Borgaonkar, Ravishankar and Seifert, Jean-Pierre},
  booktitle = {Proceedings of the 6th Workshop on Security and Privacy in Smartphones and Mobile Devices},
  title     = {White Rabbit in Mobile: Effect of Unsecured Clock Source in Smartphones},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {13–21},
  publisher = {Association for Computing Machinery},
  series    = {SPSM '16},
  abstract  = {With its high penetration rate and relatively good clock accuracy, smartphones are
replacing watches in several market segments. Modern smartphones have more than one
clock source to complement each other: NITZ (Network Identity and Time Zone), NTP
(Network Time Protocol), and GNSS (Global Navigation Satellite System) including GPS.
NITZ information is delivered by the cellular core network, indicating the network
name and clock information. NTP provides a facility to synchronize the clock with
a time server. Among these clock sources, only NITZ and NTP are updated without user
interaction, as location services require manual activation. In this paper, we analyze
security aspects of these clock sources and their impact on security features of modern
smartphones. In particular, we investigate NITZ and NTP procedures over cellular networks
(2G, 3G and 4G) and Wi-Fi communication respectively. Furthermore, we analyze several
European, Asian, and American cellular networks from NITZ perspective. We identify
three classes of vulnerabilities: specification issues in a cellular protocol, configurational
issues in cellular network deployments, and implementation issues in different mobile
OS's. We demonstrate how an attacker with low cost setup can spoof NITZ and NTP messages
to cause Denial of Service attacks. Finally, we propose methods for securely synchronizing
the clock on smartphones.},
  doi       = {10.1145/2994459.2994465},
  isbn      = {9781450345644},
  keywords  = {NTP, cellular network, baseband, nitz, clock, timekeeping},
  location  = {Vienna, Austria},
  numpages  = {9},
  url       = {https://doi.org/10.1145/2994459.2994465},
}

@InProceedings{Wirtz2019,
  author    = {Wirtz, Roman and Heisel, Maritta},
  booktitle = {Proceedings of the 24th European Conference on Pattern Languages of Programs},
  title     = {Managing Security Risks: Template-Based Specification of Controls},
  year      = {2019},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {EuroPLop '19},
  abstract  = {Threats that harm the security of software become more and more frequent. Such incidents
can lead to substantial damage, not only financially, but also in terms of reputation
loss. The combination of that consequence and the likelihood of an incident is called
risk. Risk management processes describe coordinated activities to identify, evaluate
and treat those risks. To reduce costs, it is necessary to concentrate on the most
severe risks and to address those risks as early as possible by following the principle
of security-by-design. In this paper, we introduce a template that enables security
analysts to specify controls to treat risks in a systematic manner. Instances of the
template make knowledge about controls reusable in future development projects. We
designed our template for an application during requirements engineering. Our aim
is to bridge the gap between functional requirements engineering and security. To
do so, we consider controls as early aspects and relate them to relevant functional
requirements and threats which can be treated by the control. Our template makes explicit
how those aspects can be integrated into a requirements model by using a problem-based
approach. To simplify the evaluation of controls, we adapt the concept of the Common
Vulnerability Scoring System. The defined attributes will later allow a semi-automatic
suggestion and evaluation of suitable controls.},
  articleno = {10},
  doi       = {10.1145/3361149.3361159},
  isbn      = {9781450362061},
  keywords  = {risk management, controls, security, pattern, requirements engineering},
  location  = {Irsee, Germany},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3361149.3361159},
}

@InProceedings{Springall2016,
  author    = {Springall, Drew and Durumeric, Zakir and Halderman, J. Alex},
  booktitle = {Proceedings of the 2016 Internet Measurement Conference},
  title     = {Measuring the Security Harm of TLS Crypto Shortcuts},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {33–47},
  publisher = {Association for Computing Machinery},
  series    = {IMC '16},
  abstract  = {TLS has the potential to provide strong protection against network-based attackers
and mass surveillance, but many implementations take security shortcuts in order to
reduce the costs of cryptographic computations and network round trips. We report
the results of a nine-week study that measures the use and security impact of these
shortcuts for HTTPS sites among Alexa Top Million domains. We find widespread deployment
of DHE and ECDHE private value reuse, TLS session resumption, and TLS session tickets.
These practices greatly reduce the protection afforded by forward secrecy: connections
to 38% of Top Million HTTPS sites are vulnerable to decryption if the server is compromised
up to 24 hours later, and 10% up to 30 days later, regardless of the selected cipher
suite. We also investigate the practice of TLS secrets and session state being shared
across domains, finding that in some cases, the theft of a single secret value can
compromise connections to tens of thousands of sites. These results suggest that site
operators need to better understand the tradeoffs between optimizing TLS performance
and providing strong security, particularly when faced with nation-state attackers
with a history of aggressive, large-scale surveillance.},
  doi       = {10.1145/2987443.2987480},
  isbn      = {9781450345262},
  keywords  = {government surveillance, session resumption, transport layer security, nsa, gchq, tls, nation state attacker, edward snowden, ssl, secure socket layer},
  location  = {Santa Monica, California, USA},
  numpages  = {15},
  url       = {https://doi.org/10.1145/2987443.2987480},
}

@InProceedings{Fatemieh2011,
  author    = {Fatemieh, Omid and LeMay, Michael and Gunter, Carl A.},
  booktitle = {Proceedings of the 27th Annual Computer Security Applications Conference},
  title     = {Reliable Telemetry in White Spaces Using Remote Attestation},
  year      = {2011},
  address   = {New York, NY, USA},
  pages     = {323–332},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '11},
  abstract  = {We consider reliable telemetry in white spaces in the form of protecting the integrity
of distributed spectrum measurements against coordinated misreporting attacks. Our
focus is on the case where a subset of the sensors can be remotely attested. We propose
a practical framework for using statistical sequential estimation coupled with machine
learning classifiers to deter attacks and achieve quantifiably precise outcome. We
provide an application-oriented case study in the context of spectrum measurements
in the white spaces. The study includes a cost analysis for remote attestation, as
well as an evaluation using real transmitter and terrain data from the FCC and NASA
for Southwest Pennsylvania. The results show that with as low as 15% penetration of
attestation-capable nodes, more than 94% of the attempts from omniscient attackers
can be thwarted.},
  doi       = {10.1145/2076732.2076779},
  isbn      = {9781450306720},
  location  = {Orlando, Florida, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2076732.2076779},
}

@InProceedings{Agosta2014,
  author    = {Agosta, Giovanni and Barenghi, Alessandro and Pelosi, Gerardo and Scandale, Michele},
  booktitle = {Proceedings of the 7th International Conference on Security of Information and Networks},
  title     = {Differential Fault Analysis for Block Ciphers: An Automated Conservative Analysis},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {137–144},
  publisher = {Association for Computing Machinery},
  series    = {SIN '14},
  abstract  = {Differential Fault Analysis (DFA) exploits the differences between a correct and a
faulty output of a cipher implementation to derive the secret parameters. All the
current DFA techniques are tailored to the cipher being attacked and do not provide
a general framework. We propose an automated general framework to assess the vulnerability
of block ciphers against DFAs, providing a conservative analysis on the attacker capabilities
and a practical lower bound on the attacker effort required to extract the secret-key.
The proposed technique is based on dataflow analysis of software cipher implementations
and has been implemented as a pass of the llvm compiler infrastructure. This work
shows how the automated tool we developed is able to detect which and how many faults
an attacker can exploit to recover the values of portions of the secret-key material
employed by a standard block cipher, validating the effectiveness of our approach.
The precise analysis provided by our tool allows to apply the computationally demanding
fault attack countermeasures only to the vulnerable portions of the cipher.},
  doi       = {10.1145/2659651.2659709},
  isbn      = {9781450330336},
  keywords  = {Side-channel Attacks, Cryptographic Engineering, Differential Fault Analysis, Cryptography},
  location  = {Glasgow, Scotland, UK},
  numpages  = {8},
  url       = {https://doi.org/10.1145/2659651.2659709},
}

@InProceedings{Xue2017,
  author    = {Xue, Tangli and Luo, Hongcheng and Cheng, Danpeng and Yuan, Zikang and Yang, Xin},
  booktitle = {Proceedings of the 25th ACM International Conference on Multimedia},
  title     = {Real-Time Monocular Dense Mapping for Augmented Reality},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {510–518},
  publisher = {Association for Computing Machinery},
  series    = {MM '17},
  abstract  = {Monocular simultaneous localization and mapping (SLAM) is a key enabling technique
for many augmented reality (AR) applications. However, conventional methods for monocular
SLAM can obtain only sparse or semi-dense maps in highly-textured image areas. Poorly-textured
regions which widely exist in indoor and man-made urban environments can be hardly
reconstructed, impeding interactions between virtual objects and real scenes in AR
apps. In this paper,we present a novel method for real-time monocular dense mapping
based on the piecewise planarity assumption for poorly textured regions. Specifically,
a semi-dense map for highly-textured regions is first calculated by pixel matching
and triangulation [6, 7]. Large textureless regions extracted by Maximally Stable
Color Regions (MSCR) [11], which is a homogeneous-color region detector, are approximated
using piecewise planar models which are estimated by the corresponding semi-dense
3D points and the proposed multi-plane segmentation algorithm. Plane models associated
with the same 3D area across multiple overlapping views are linked and fused to ensure
a consistent and accurate 3D reconstruction. Experimental results on two public datasets
[15, 23] demonstrate that our method is 2.3X~2.9X faster than the state-of-the-art
method DPPTAM [2], and meanwhile achieves better reconstruction accuracy and completeness.
We also apply our method to a real AR application and live experiments with a hand-held
camera demonstrate the effectiveness and efficiency of our method in practical scenario.},
  doi       = {10.1145/3123266.3123348},
  isbn      = {9781450349062},
  keywords  = {monocular dense mapping, multiplane segmentation, plane model, augmented reality},
  location  = {Mountain View, California, USA},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3123266.3123348},
}

@InProceedings{Willems2012,
  author    = {Willems, Carsten and Hund, Ralf and Fobian, Andreas and Felsch, Dennis and Holz, Thorsten and Vasudevan, Amit},
  booktitle = {Proceedings of the 28th Annual Computer Security Applications Conference},
  title     = {Down to the Bare Metal: Using Processor Features for Binary Analysis},
  year      = {2012},
  address   = {New York, NY, USA},
  pages     = {189–198},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '12},
  abstract  = {A detailed understanding of the behavior of exploits and malicious software is necessary
to obtain a comprehensive overview of vulnerabilities in operating systems or client
applications, and to develop protection techniques and tools. To this end, a lot of
research has been done in the last few years on binary analysis techniques to efficiently
and precisely analyze code. Most of the common analysis frameworks are based on software
emulators since such tools offer a fine-grained control over the execution of a given
program. Naturally, this leads to an arms race where the attackers are constantly
searching for new methods to detect such analysis frameworks in order to successfully
evade analysis.In this paper, we focus on two aspects. As a first contribution, we
introduce several novel mechanisms by which an attacker can delude an emulator. In
contrast to existing detection approaches that perform a dedicated test on the environment
and combine the test with an explicit conditional branch, our detection mechanisms
introduce code sequences that have an implicitly different behavior on a native machine
when compared to an emulator. Such differences in behavior are caused by the side-effects
of the particular operations and imperfections in the emulation process that cannot
be mitigated easily. Motivated by these findings, we introduce a novel approach to
generate execution traces. We propose to utilize the processor itself to generate
such traces. Mores precisely, we propose to use a hardware feature called branch tracing
available on commodity x86 processors in which the log of all branches taken during
code execution is generated directly by the processor. Effectively, the logging is
thus performed at the lowest level possible. We evaluate the practical viability of
this approach.},
  doi       = {10.1145/2420950.2420980},
  isbn      = {9781450313124},
  location  = {Orlando, Florida, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2420950.2420980},
}

@InProceedings{Nicolle2012,
  author    = {Nicolle, J\'{e}r\'{e}mie and Rapp, Vincent and Bailly, K\'{e}vin and Prevost, Lionel and Chetouani, Mohamed},
  booktitle = {Proceedings of the 14th ACM International Conference on Multimodal Interaction},
  title     = {Robust Continuous Prediction of Human Emotions Using Multiscale Dynamic Cues},
  year      = {2012},
  address   = {New York, NY, USA},
  pages     = {501–508},
  publisher = {Association for Computing Machinery},
  series    = {ICMI '12},
  abstract  = {Designing systems able to interact with humans in a natural manner is a complex and
far from solved problem. A key aspect of natural interaction is the ability to understand
and appropriately respond to human emotions. This paper details our response to the
Audio/Visual Emotion Challenge (AVEC'12) whose goal is to continuously predict four
affective signals describing human emotions (namely valence, arousal, expectancy and
power). The proposed method uses log-magnitude Fourier spectra to extract multiscale
dynamic descriptions of signals characterizing global and local face appearance as
well as head movements and voice. We perform a kernel regression with very few representative
samples selected via a supervised weighted-distance-based clustering, that leads to
a high generalization power. For selecting features, we introduce a new correlation-based
measure that takes into account a possible delay between the labels and the data and
significantly increases robustness. We also propose a particularly fast regressor-level
fusion framework to merge systems based on different modalities. Experiments have
proven the efficiency of each key point of the proposed method and we obtain very
promising results.},
  doi       = {10.1145/2388676.2388783},
  isbn      = {9781450314671},
  keywords  = {affective computing, facial expressions, feature selection, multimodal fusion, dynamic features},
  location  = {Santa Monica, California, USA},
  numpages  = {8},
  url       = {https://doi.org/10.1145/2388676.2388783},
}

@Article{Ji2016,
  author     = {Ji, Shouling and Li, Weiqing and Srivatsa, Mudhakar and He, Jing Selena and Beyah, Raheem},
  journal    = {ACM Trans. Inf. Syst. Secur.},
  title      = {General Graph Data De-Anonymization: From Mobility Traces to Social Networks},
  year       = {2016},
  issn       = {1094-9224},
  month      = apr,
  number     = {4},
  volume     = {18},
  abstract   = {When people utilize social applications and services, their privacy suffers a potential
serious threat. In this article, we present a novel, robust, and effective de-anonymization
attack to mobility trace data and social data. First, we design a Unified Similarity
(US) measurement, which takes account of local and global structural characteristics
of data, information obtained from auxiliary data, and knowledge inherited from ongoing
de-anonymization results. By analyzing the measurement on real datasets, we find that
some data can potentially be de-anonymized accurately and the other can be de-anonymized
in a coarse granularity. Utilizing this property, we present a US-based De-Anonymization
(DA) framework, which iteratively de-anonymizes data with accuracy guarantee. Then,
to de-anonymize large-scale data without knowledge of the overlap size between the
anonymized data and the auxiliary data, we generalize DA to an Adaptive De-Anonymization
(ADA) framework. By smartly working on two core matching subgraphs, ADA achieves high
de-anonymization accuracy and reduces computational overhead. Finally, we examine
the presented de-anonymization attack on three well-known mobility traces: St Andrews,
Infocom06, and Smallblue, and three social datasets: ArnetMiner, Google+, and Facebook.
The experimental results demonstrate that the presented de-anonymization framework
is very effective and robust to noise.The source code and employed datasets are now
publicly available at SecGraph [2015].},
  address    = {New York, NY, USA},
  articleno  = {12},
  doi        = {10.1145/2894760},
  issue_date = {May 2016},
  keywords   = {Graph de-anonymization, mobility traces, social networks},
  numpages   = {29},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2894760},
}

@InProceedings{ElZoghby2020,
  author    = {El-Zoghby, Ayman M. and Azer, Marianne A.},
  booktitle = {Proceedings of the 2020 9th International Conference on Software and Information Engineering (ICSIE)},
  title     = {Survey of Code Reuse Attacks and Comparison of Mitigation Techniques},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {88–96},
  publisher = {Association for Computing Machinery},
  series    = {ICSIE 2020},
  abstract  = {Code-Reuse Attacks (CRAs) are solid mechanisms to bypass advanced software and hardware
defenses. Due to vulnerabilities found in software which allows attackers to corrupt
the memory space of the vulnerable software to modify maliciously the contents of
the memory; hence controlling the software to be able to run arbitrary code. The CRAs
defenses either prevents the attacker from reading program code, controlling program
memory space directly or indirectly through the usage of pointers. This paper provides
a thorough evaluation of the current mitigation techniques against CRAs with regards
to impact on performance, coverage, and efficiency of those techniques.},
  doi       = {10.1145/3436829.3436865},
  isbn      = {9781450377218},
  keywords  = {security, CRA, exploit mitigation, efficiency, ROP},
  location  = {Cairo, Egypt},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3436829.3436865},
}

@InProceedings{Kuvaiskii2017,
  author    = {Kuvaiskii, Dmitrii and Oleksenko, Oleksii and Arnautov, Sergei and Trach, Bohdan and Bhatotia, Pramod and Felber, Pascal and Fetzer, Christof},
  booktitle = {Proceedings of the Twelfth European Conference on Computer Systems},
  title     = {SGXBOUNDS: Memory Safety for Shielded Execution},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {205–221},
  publisher = {Association for Computing Machinery},
  series    = {EuroSys '17},
  abstract  = {Shielded execution based on Intel SGX provides strong security guarantees for legacy
applications running on untrusted platforms. However, memory safety attacks such as
Heartbleed can render the confidentiality and integrity properties of shielded execution
completely ineffective. To prevent these attacks, the state-of-the-art memory-safety
approaches can be used in the context of shielded execution.In this work, we first
showcase that two prominent software- and hardware-based defenses, AddressSanitizer
and Intel MPX respectively, are impractical for shielded execution due to high performance
and memory overheads. This motivated our design of SGXBounds---an efficient memory-safety
approach for shielded execution exploiting the architectural features of Intel SGX.
Our design is based on a simple combination of tagged pointers and compact memory
layout.We implemented SGXBounds based on the LLVM compiler framework targeting unmodified
multithreaded applications. Our evaluation using Phoenix, PARSEC, and RIPE benchmark
suites shows that SGXBounds has performance and memory overheads of 17% and 0.1% respectively,
while providing security guarantees similar to AddressSanitizer and Intel MPX. We
have obtained similar results with SPEC CPU2006 and four real-world case studies:
SQLite, Memcached, Apache, and Nginx.},
  doi       = {10.1145/3064176.3064192},
  isbn      = {9781450349383},
  location  = {Belgrade, Serbia},
  numpages  = {17},
  url       = {https://doi.org/10.1145/3064176.3064192},
}

@InProceedings{Boshmaf2011,
  author    = {Boshmaf, Yazan and Muslukhov, Ildar and Beznosov, Konstantin and Ripeanu, Matei},
  booktitle = {Proceedings of the 27th Annual Computer Security Applications Conference},
  title     = {The Socialbot Network: When Bots Socialize for Fame and Money},
  year      = {2011},
  address   = {New York, NY, USA},
  pages     = {93–102},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '11},
  abstract  = {Online Social Networks (OSNs) have become an integral part of today's Web. Politicians,
celebrities, revolutionists, and others use OSNs as a podium to deliver their message
to millions of active web users. Unfortunately, in the wrong hands, OSNs can be used
to run astroturf campaigns to spread misinformation and propaganda. Such campaigns
usually start off by infiltrating a targeted OSN on a large scale. In this paper,
we evaluate how vulnerable OSNs are to a large-scale infiltration by socialbots: computer
programs that control OSN accounts and mimic real users. We adopt a traditional web-based
botnet design and built a Socialbot Network (SbN): a group of adaptive socialbots
that are orchestrated in a command-and-control fashion. We operated such an SbN on
Facebook---a 750 million user OSN---for about 8 weeks. We collected data related to
users' behavior in response to a large-scale infiltration where socialbots were used
to connect to a large number of Facebook users. Our results show that (1) OSNs, such
as Facebook, can be infiltrated with a success rate of up to 80%, (2) depending on
users' privacy settings, a successful infiltration can result in privacy breaches
where even more users' data are exposed when compared to a purely public access, and
(3) in practice, OSN security defenses, such as the Facebook Immune System, are not
effective enough in detecting or stopping a large-scale infiltration as it occurs.},
  doi       = {10.1145/2076732.2076746},
  isbn      = {9781450306720},
  location  = {Orlando, Florida, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2076732.2076746},
}

@InBook{Abdelrahman2017,
  author    = {Abdelrahman, Yomna and Khamis, Mohamed and Schneegass, Stefan and Alt, Florian},
  pages     = {3751–3763},
  publisher = {Association for Computing Machinery},
  title     = {Stay Cool! Understanding Thermal Attacks on Mobile-Based User Authentication},
  year      = {2017},
  address   = {New York, NY, USA},
  isbn      = {9781450346559},
  abstract  = {PINs and patterns remain among the most widely used knowledge-based authentication
schemes. As thermal cameras become ubiquitous and affordable, we foresee a new form
of threat to user privacy on mobile devices. Thermal cameras allow performing thermal
attacks, where heat traces, resulting from authentication, can be used to reconstruct
passwords. In this work we investigate in details the viability of exploiting thermal
imaging to infer PINs and patterns on mobile devices. We present a study (N=18) where
we evaluated how properties of PINs and patterns influence their thermal attacks resistance.
We found that thermal attacks are indeed viable on mobile devices; overlapping patterns
significantly decrease successful thermal attack rate from 100% to 16.67%, while PINs
remain vulnerable (&gt;72% success rate) even with duplicate digits. We conclude by recommendations
for users and designers of authentication schemes on how to resist thermal attacks.},
  booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3025453.3025461},
}

@InProceedings{Effendy2012,
  author    = {Effendy, Suhendry and Yap, Roland H.C. and Halim, Felix},
  booktitle = {Proceedings of the Second ACM Conference on Data and Application Security and Privacy},
  title     = {Revisiting Link Privacy in Social Networks},
  year      = {2012},
  address   = {New York, NY, USA},
  pages     = {61–70},
  publisher = {Association for Computing Machinery},
  series    = {CODASPY '12},
  abstract  = {In this paper, we revisit the problem of the link privacy attack in online social
networks. In the link privacy attack, it turns out that by bribing or compromising
a small number of nodes (users) in the social network graph, it is possible to obtain
complete link information for a much larger fraction of other non-bribed nodes in
the graph. This can constitute a significant privacy breach in online social networks
where the link information of nodes is kept private or accessible only to closely
related nodes.We show that the link privacy attack can be made even more effective
with degree inference. Since online social networks typically have high degree, the
link privacy attack becomes quite feasible even with an in-lookahead neighborhood
of one (only friends can see a user's links/profile). To reduce the effect of the
link privacy attack, we present several practical mitigation strategies -- non-uniform
user privacy settings, approximation of the node degree information and a non-constant
cost model for the attack. All the strategies are able to mitigate the privacy link
attack by either reducing the effectiveness of the attack or by making it more expensive
to mount. Interestingly, some of the more efficient strategies now become worse than
the RANDOM strategy and the effect of a larger neighborhood which would otherwise
make the attack even more efficient can be mitigated.},
  doi       = {10.1145/2133601.2133609},
  isbn      = {9781450310918},
  keywords  = {crawlers, social networks, privacy},
  location  = {San Antonio, Texas, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2133601.2133609},
}

@Article{Serwadda2016,
  author     = {Serwadda, Abdul and Phoha, Vir V. and Wang, Zibo and Kumar, Rajesh and Shukla, Diksha},
  journal    = {ACM Trans. Inf. Syst. Secur.},
  title      = {Toward Robotic Robbery on the Touch Screen},
  year       = {2016},
  issn       = {1094-9224},
  month      = may,
  number     = {4},
  volume     = {18},
  abstract   = {Despite the tremendous amount of research fronting the use of touch gestures as a
mechanism of continuous authentication on smart phones, very little research has been
conducted to evaluate how these systems could behave if attacked by sophisticated
adversaries. In this article, we present two Lego-driven robotic attacks on touch-based
authentication: a population statistics--driven attack and a user-tailored attack.
The population statistics--driven attack is based on patterns gleaned from a large
population of users, whereas the user-tailored attack is launched based on samples
stolen from the victim. Both attacks are launched by a Lego robot that is trained
on how to swipe on the touch screen. Using seven verification algorithms and a large
dataset of users, we show that the attacks cause the system’s mean false acceptance
rate (FAR) to increase by up to fivefold relative to the mean FAR seen under the standard
zero-effort impostor attack. The article demonstrates the threat that robots pose
to touch-based authentication and provides compelling evidence as to why the zero-effort
attack should cease to be used as the benchmark for touch-based authentication systems.},
  address    = {New York, NY, USA},
  articleno  = {14},
  doi        = {10.1145/2898353},
  issue_date = {May 2016},
  keywords   = {smartphone security, robotic attacks, behavioral biometrics, Touch gestures},
  numpages   = {25},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2898353},
}

@Article{Bansal2020,
  author     = {Bansal, Maggi and Chana, Inderveer and Clarke, Siobh\'{a}n},
  journal    = {ACM Comput. Surv.},
  title      = {A Survey on IoT Big Data: Current Status, 13 V’s Challenges, and Future Directions},
  year       = {2020},
  issn       = {0360-0300},
  month      = dec,
  number     = {6},
  volume     = {53},
  abstract   = {Driven by the core technologies, i.e., sensor-based autonomous data acquisition and
the cloud-based big data analysis, IoT automates the actuation of data-driven intelligent
actions on the connected objects. This automation enables numerous useful real-life
use-cases, such as smart transport, smart living, smart cities, and so on. However,
recent industry surveys reflect that data-related challenges are responsible for slower
growth of IoT in recent years. For this reason, this article presents a systematic
and comprehensive survey on IoT Big Data (IoTBD) with the aim to identify the uncharted
challenges for IoTBD. This article analyzes the state-of-the-art academic works in
IoT and big data management across various domains and proposes a taxonomy for IoTBD
management. Then, the survey explores the IoT portfolio of major cloud vendors and
provides a classification of vendor services for the integration of IoT and IoTBD
on their cloud platforms. After that, the survey identifies the IoTBD challenges in
terms of 13 V’s challenges and envisions IoTBD as “Big Data 2.0.” Then the survey
provides comprehensive analysis of recent works that address IoTBD challenges by highlighting
their strengths and weaknesses to assess the recent trends and future research directions.
Finally, the survey concludes with discussion on open research issues for IoTBD.},
  address    = {New York, NY, USA},
  articleno  = {131},
  doi        = {10.1145/3419634},
  issue_date = {February 2021},
  keywords   = {cloud computing in IoT, V’s challenges for IoT big data, big data 2.0, IoT big data, IoT big data survey, cloud IoT services},
  numpages   = {59},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3419634},
}

@Article{Shi2021,
  author     = {Shi, Cong and Liu, Jian and Liu, Hongbo and Chen, Yingying},
  journal    = {ACM Trans. Internet Things},
  title      = {WiFi-Enabled User Authentication through Deep Learning in Daily Activities},
  year       = {2021},
  issn       = {2691-1914},
  month      = may,
  number     = {2},
  volume     = {2},
  abstract   = {User authentication is a critical process in both corporate and home environments
due to the ever-growing security and privacy concerns. With the advancement of smart
cities and home environments, the concept of user authentication is evolved with a
broader implication by not only preventing unauthorized users from accessing confidential
information but also providing the opportunities for customized services corresponding
to a specific user. Traditional approaches of user authentication either require specialized
device installation or inconvenient wearable sensor attachment. This article supports
the extended concept of user authentication with a device-free approach by leveraging
the prevalent WiFi signals made available by IoT devices, such as smart refrigerator,
smart TV, and smart thermostat, and so on. The proposed system utilizes the WiFi signals
to capture unique human physiological and behavioral characteristics inherited from
their daily activities, including both walking and stationary ones. Particularly,
we extract representative features from channel state information (CSI) measurements
of WiFi signals, and develop a deep-learning-based user authentication scheme to accurately
identify each individual user. To mitigate the signal distortion caused by surrounding
people’s movements, our deep learning model exploits a CNN-based architecture that
constructively combines features from multiple receiving antennas and derives more
reliable feature abstractions. Furthermore, a transfer-learning-based mechanism is
developed to reduce the training cost for new users and environments. Extensive experiments
in various indoor environments are conducted to demonstrate the effectiveness of the
proposed authentication system. In particular, our system can achieve over 94% authentication
accuracy with 11 subjects through different activities.},
  address    = {New York, NY, USA},
  articleno  = {13},
  doi        = {10.1145/3448738},
  issue_date = {May 2021},
  keywords   = {WiFi signals, User authentication, IoT},
  numpages   = {25},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3448738},
}

@InProceedings{Dotan2020,
  author    = {Dotan, Maya and Pignolet, Yvonne-Anne and Schmid, Stefan and Tochner, Saar and Zohar, Aviv},
  booktitle = {Proceedings of the 15th International Conference on Availability, Reliability and Security},
  title     = {SOK: Cryptocurrency Networking Context, State-of-the-Art, Challenges},
  year      = {2020},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ARES '20},
  abstract  = {Cryptocurrencies such as Bitcoin are realized using distributed systems and hence
critically rely on the performance and security of the interconnecting network. The
requirements on these networks and their usage, however can differ significantly from
traditional communication networks, with implications on all layers of the protocol
stack. This paper is motivated by these differences, and in particular by the observation
that many fundamental design aspects of these networks are not well-understood today.
In order to support the networking community to contribute to this emerging application
domain, we present a structured overview of the field, from topology and neighbor
discovery to block and transaction propagation. In particular, we provide the context,
highlighting differences and commonalities with traditional networks, review the state-of-the-art,
and identify open research challenges. Our paper can hence also be seen as a call-to-arms
to improve the foundation on top of which cryptocurrencies are built.},
  articleno = {5},
  doi       = {10.1145/3407023.3407043},
  isbn      = {9781450388337},
  location  = {Virtual Event, Ireland},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3407023.3407043},
}

@Article{Bianchini2017,
  author     = {Bianchini, Devis and Antonellis, Valeria De and Melchiori, Michele},
  journal    = {ACM Trans. Web},
  title      = {WISeR: A Multi-Dimensional Framework for Searching and Ranking Web APIs},
  year       = {2017},
  issn       = {1559-1131},
  month      = jul,
  number     = {3},
  volume     = {11},
  abstract   = {Mashups are agile applications that aggregate RESTful services, developed by third
parties, whose functions are exposed as Web Application Program Interfaces (APIs)
within public repositories. From mashups developers’ viewpoint, Web API search may
benefit from selection criteria that combine several dimensions used to describe the
APIs, such as categories, tags, and technical features (e.g., protocols and data formats).
Nevertheless, other dimensions might be fruitfully exploited to support Web API search.
Among them, past API usage experiences by other developers may be used to suggest
the right APIs for a target application. Past experiences might emerge from the co-occurrence
of Web APIs in the same mashups. Ratings assigned by developers after using the Web
APIs to create their own mashups or after using mashups developed by others can be
considered as well. This article aims to advance the current state of the art for
Web API search and ranking from mashups developers’ point of view, by addressing two
key issues: multi-dimensional modeling and multi-dimensional framework for selection.
The model for Web API characterization embraces multiple descriptive dimensions, by
considering several public repositories, that focus on different and only partially
overlapping dimensions. The proposed Web API selection framework, called WISeR (Web
apI Search and Ranking), is based on functions devoted to developers to exploit the
multi-dimensional descriptions, in order to enhance the identification of candidate
Web APIs to be proposed, according to the given requirements. Furthermore, WISeR adapts
to changes that occur during the Web API selection and mashup development, by revising
the dimensional attributes in order to conform to developers’ preferences and constraints.
We also present an experimental evaluation of the framework.},
  address    = {New York, NY, USA},
  articleno  = {19},
  doi        = {10.1145/3061710},
  issue_date = {July 2017},
  keywords   = {Multi-dimensional Web API model, RESTful services, Web API search and ranking, mashups},
  numpages   = {32},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3061710},
}

@InProceedings{Tai2020,
  author    = {Tai, Jianwei and Jia, Xiaoqi and Huang, Qingjia and Zhang, Weijuan and Du, Haichao and Zhang, Shengzhi},
  booktitle = {Annual Computer Security Applications Conference},
  title     = {SEEF-ALDR: A Speaker Embedding Enhancement Framework via Adversarial Learning Based Disentangled Representation},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {939–950},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '20},
  abstract  = {Speaker verification, as a biometric authentication mechanism, has been widely used
due to the pervasiveness of voice control on smart devices. However, the task of “in-the-wild”
speaker verification is still challenging, considering the speech samples may contain
lots of identity-unrelated information, e.g., background noise, reverberation, emotion,
etc. Previous works focus on optimizing the model to improve verification accuracy,
without taking into account the elimination of the impact from the identity-unrelated
information. To solve the above problem, we propose SEEF-ALDR, a novel Speaker Embedding
Enhancement Framework via Adversarial Learning based Disentangled Representation,
to reinforce the performance of existing models on speaker verification. The key idea
is to retrieve as much speaker identity information as possible from the original
speech, thus minimizing the impact of identity-unrelated information on the speaker
verification task by using adversarial learning. Experimental results demonstrate
that the proposed framework can significantly improve the performance of speaker verification
by 20.3% and 23.8% on average over 13 tested baselines on dataset Voxceleb1 and 8
tested baselines on dataset Voxceleb2 respectively, without adjusting the structure
or hyper-parameters of them. Furthermore, the ablation study was conducted to evaluate
the contribution of each module in SEEF-ALDR. Finally, porting an existing model into
the proposed framework is straightforward and cost-efficient, with very little effort
from the model owners due to the modular design of the framework.},
  doi       = {10.1145/3427228.3427274},
  isbn      = {9781450388580},
  keywords  = {Adversarial Learning, Disentangled Representation, Biometrics, Speaker Embedding},
  location  = {Austin, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3427228.3427274},
}

@InProceedings{Tex2018,
  author    = {Tex, Christine and Sch\"{a}ler, Martin and B\"{o}hm, Klemens},
  booktitle = {Proceedings of the 30th International Conference on Scientific and Statistical Database Management},
  title     = {Towards Meaningful Distance-Preserving Encryption},
  year      = {2018},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {SSDBM '18},
  abstract  = {Mining complex data is an essential and at the same time challenging task. Therefore,
organizations pass on their encrypted data to service providers carrying out such
analyses. Thus, encryption must preserve the mining results. Many mining algorithms
are distance-based. Thus, we investigate how to preserve the results for such algorithms
upon encryption. To this end, we propose the notion of distance-preserving encryption
(DPE). This notion has just the right strictness - we show that we cannot relax it,
using formal arguments as well as experiments. Designing a DPE scheme is challenging,
as it depends both on the data set and the specific distance measure in use. We propose
a procedure to engineer DPE-schemes, dubbed DisPE. In a case study, we instantiate
DisPE for SQL query logs, a type of data containing valuable information about user
interests. In this study, we design DPE schemes for all SQL query distance measures
from the scientific literature. We formally show that one can use a combination of
existing secure property-preserving encryption schemes to this end. Finally, we discuss
on the generalizability of our findings using two other data sets as examples.},
  articleno = {2},
  doi       = {10.1145/3221269.3223029},
  isbn      = {9781450365055},
  location  = {Bozen-Bolzano, Italy},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3221269.3223029},
}

@InBook{Sfikas2020,
  author    = {Sfikas, Konstantinos and Liapis, Antonios},
  publisher = {Association for Computing Machinery},
  title     = {Collaborative Agent Gameplay in the Pandemic Board Game},
  year      = {2020},
  address   = {New York, NY, USA},
  isbn      = {9781450388078},
  abstract  = {While artificial intelligence has been applied to control players’ decisions in board
games for over half a century, little attention is given to games with no player competition.
Pandemic is an exemplar collaborative board game where all players coordinate to overcome
challenges posed by events occurring during the game’s progression. This paper proposes
an artificial agent which controls all players’ actions and balances chances of winning
versus risk of losing in this highly stochastic environment. The agent applies a Rolling
Horizon Evolutionary Algorithm on an abstraction of the game-state that lowers the
branching factor and simulates the game’s stochasticity. Results show that the proposed
algorithm can find winning strategies more consistently in different games of varying
difficulty. The impact of a number of state evaluation metrics is explored, balancing
between optimistic strategies that favor winning and pessimistic strategies that guard
against losing.},
  articleno = {1},
  booktitle = {International Conference on the Foundations of Digital Games},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3402942.3402943},
}

@Article{Kumar2021,
  author     = {Kumar, Rajesh and Isik, Can and Phoha, Vir V.},
  journal    = {Digital Threats: Research and Practice},
  title      = {Treadmill Assisted Gait Spoofing (TAGS): An Emerging Threat to Wearable Sensor-Based Gait Authentication},
  year       = {2021},
  issn       = {2692-1626},
  month      = jun,
  number     = {3},
  volume     = {2},
  abstract   = {In this work, we examine the impact of Treadmill Assisted Gait Spoofing on Wearable
Sensor-based Gait Authentication (WSGait). We consider more realistic implementation
and deployment scenarios than the previous study, which focused only on the accelerometer
sensor and a fixed set of features. Specifically, we consider the situations in which
the implementation of WSGait could be using one or more sensors embedded into modern
smartphones. In addition, it could be using different sets of features or different
classification algorithms, or both. Despite the use of a variety of sensors, feature
sets (ranked by mutual information), and six different classification algorithms,
Treadmill Assisted Gait Spoofing was able to increase the average false accept rate
from 4% to 26%. Such a considerable increase in the average false accept rate, especially
under the stringent implementation and deployment scenarios considered in this study,
calls for a further investigation into the design of evaluations of WSGait before
its deployment for public use.},
  address    = {New York, NY, USA},
  articleno  = {23},
  doi        = {10.1145/3442151},
  issue_date = {July 2021},
  keywords   = {User authentication, gait spoofing, behavioral biometrics, gait authentication, wearable sensors},
  numpages   = {17},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3442151},
}

@InProceedings{Chen2017a,
  author    = {Chen, Lin and Yang, Hua and Wu, Shuang and Gao, Zhiyong},
  booktitle = {Proceedings of the 25th ACM International Conference on Multimedia},
  title     = {Data Generation for Improving Person Re-Identification},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {609–617},
  publisher = {Association for Computing Machinery},
  series    = {MM '17},
  abstract  = {In this paper, we explore ways to address the challenges such as data bias caused
by the lack of data on person re-identification problem. We propose a data generation
framework from both intra- and inter-view aspects for data augmentation to advance
the performance of the existing person re-identification algorithms. Specifically,
for intra-view data generation, the proposed method generates useful predicted sequences
within a camera view for certain person data expansion. The generated sequences well
preserve the movement information of the camera and objects, which expands the original
data with longer sequence length to tackle the problem caused by insufficient data
from the root. For more challenging datasets which suffer from background clutters,
we propose an inter-view image generation with automatic end-to-end background substitution
to eliminate the influence by the background and increase the diversity of the training
data as well, which makes the recognition system learn to focus on the regions of
objects and image features related to identity. We then propose a flexible data augmentation
method based on our data generation approaches to improve the performance of the person
re-identification and analyze the advantages and applicability of these approaches
respectively. Evaluated on the challenging re-id datasets, our method outperforms
existing state-of-the-art approaches without any network structure modification on
the baseline neural network. Cross-datasets evaluation results show that our method
has favorable generalization ability and is potentially helpful for solving similar
recognition tasks due to the common issue of insufficient data.},
  doi       = {10.1145/3123266.3123302},
  isbn      = {9781450349062},
  keywords  = {person re-identification, background substitution, generation, data augmentation},
  location  = {Mountain View, California, USA},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3123266.3123302},
}

@InProceedings{Du2020,
  author    = {Du, Xiaoyu and Hargreaves, Chris and Sheppard, John and Anda, Felix and Sayakkara, Asanka and Le-Khac, Nhien-An and Scanlon, Mark},
  booktitle = {Proceedings of the 15th International Conference on Availability, Reliability and Security},
  title     = {SoK: Exploring the State of the Art and the Future Potential of Artificial Intelligence in Digital Forensic Investigation},
  year      = {2020},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ARES '20},
  abstract  = {Multi-year digital forensic backlogs have become commonplace in law enforcement agencies
throughout the globe. Digital forensic investigators are overloaded with the volume
of cases requiring their expertise compounded by the volume of data to be processed.
Artificial intelligence is often seen as the solution to many big data problems. This
paper summarises existing artificial intelligence based tools and approaches in digital
forensics. Automated evidence processing leveraging artificial intelligence based
techniques shows great promise in expediting the digital forensic analysis process
while increasing case processing capacities. For each application of artificial intelligence
highlighted, a number of current challenges and future potential impact is discussed.},
  articleno = {46},
  doi       = {10.1145/3407023.3407068},
  isbn      = {9781450388337},
  keywords  = {machine learning, digital forensics, deep learning},
  location  = {Virtual Event, Ireland},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3407023.3407068},
}

@InProceedings{Shin2018,
  author    = {Shin, Youngjoo and Kim, Hyung Chan and Kwon, Dokeun and Jeong, Ji Hoon and Hur, Junbeom},
  booktitle = {Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {Unveiling Hardware-Based Data Prefetcher, a Hidden Source of Information Leakage},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {131–145},
  publisher = {Association for Computing Machinery},
  series    = {CCS '18},
  abstract  = {Data prefetching is a hardware-based optimization mechanism used in most of the modern
microprocessors. It fetches data to the cache before it is needed. In this paper,
we present a novel microarchitectural attack that exploits the prefetching mechanism.
Our attack targets Instruction pointer (IP)-based stride prefetching in Intel processors.
Stride prefetcher detects memory access patterns with a regular stride, which are
likely to be found in lookup table-based cryptographic implementations. By monitoring
the prefetching activities near the lookup table, attackers can extract sensitive
information such as secret keys from victim applications. This kind of leakage from
prefetching has never been considered in the design of constant time algorithm to
prevent side-channel attacks. We show the potential of the proposed attack by applying
it against the Elliptic Curve Diffie-Hellman (ECDH) algorithm built upon the latest
version of OpenSSL library. To the best of our knowledge, this is the first microarchitectural
side-channel attack exploiting the hardware prefetching of modern microprocessors.},
  doi       = {10.1145/3243734.3243736},
  isbn      = {9781450356930},
  keywords  = {microarchitectural side-channel attacks, hardware prefetching, OpenSSL, ECDH algorithm},
  location  = {Toronto, Canada},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3243734.3243736},
}

@Article{Alharbi2021,
  author     = {Alharbi, Ahmed and Dong, Hai and Yi, Xun and Tari, Zahir and Khalil, Ibrahim},
  journal    = {ACM Comput. Surv.},
  title      = {Social Media Identity Deception Detection: A Survey},
  year       = {2021},
  issn       = {0360-0300},
  month      = apr,
  number     = {3},
  volume     = {54},
  abstract   = {Social media have been growing rapidly and become essential elements of many people’s
lives. Meanwhile, social media have also come to be a popular source for identity
deception. Many social media identity deception cases have arisen over the past few
years. Recent studies have been conducted to prevent and detect identity deception.
This survey analyzes various identity deception attacks, which can be categorized
into fake profile, identity theft, and identity cloning. This survey provides a detailed
review of social media identity deception detection techniques. It also identifies
primary research challenges and issues in the existing detection techniques. This
article is expected to benefit both researchers and social media providers.},
  address    = {New York, NY, USA},
  articleno  = {69},
  doi        = {10.1145/3446372},
  issue_date = {June 2021},
  keywords   = {sockpuppet, social botnet, Sybil, Identity deception, fake profile, detection techniques, identity cloning, identity theft},
  numpages   = {35},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3446372},
}

@InProceedings{Li2012a,
  author    = {Li, Zhou and Zhang, Kehuan and Xie, Yinglian and Yu, Fang and Wang, XiaoFeng},
  booktitle = {Proceedings of the 2012 ACM Conference on Computer and Communications Security},
  title     = {Knowing Your Enemy: Understanding and Detecting Malicious Web Advertising},
  year      = {2012},
  address   = {New York, NY, USA},
  pages     = {674–686},
  publisher = {Association for Computing Machinery},
  series    = {CCS '12},
  abstract  = {With the Internet becoming the dominant channel for marketing and promotion, online
advertisements are also increasingly used for illegal purposes such as propagating
malware, scamming, click frauds, etc. To understand the gravity of these malicious
advertising activities, which we call malvertising, we perform a large-scale study
through analyzing ad-related Web traces crawled over a three-month period. Our study
reveals the rampancy of malvertising: hundreds of top ranking Web sites fell victims
and leading ad networks such as DoubleClick were infiltrated.To mitigate this threat,
we identify prominent features from malicious advertising nodes and their related
content delivery paths, and leverage them to build a new detection system called MadTracer.
MadTracer automatically generates detection rules and utilizes them to inspect advertisement
delivery processes and detect malvertising activities. Our evaluation shows that MadTracer
was capable of capturing a large number of malvertising cases, 15 times as many as
Google Safe Browsing and Microsoft Forefront did together, at a low false detection
rate. It also detected new attacks, including a type of click-fraud attack that has
never been reported before.},
  doi       = {10.1145/2382196.2382267},
  isbn      = {9781450316514},
  keywords  = {statistical learning, malvertising, online advertising},
  location  = {Raleigh, North Carolina, USA},
  numpages  = {13},
  url       = {https://doi.org/10.1145/2382196.2382267},
}

@InProceedings{McCulley2018,
  author    = {McCulley, Shane and Roussev, Vassil},
  booktitle = {Proceedings of the 34th Annual Computer Security Applications Conference},
  title     = {Latent Typing Biometrics in Online Collaboration Services},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {66–76},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '18},
  abstract  = {The use of typing biometrics---the characteristic typing patterns of individual keyboard
users---has been studied extensively in the context of enhancing multi-factor authentication
services. The key starting point for such work has been the collection of high-fidelity
local timing data, and the key (implicit) security assumption has been that such biometrics
could not be obtained by other means.We show that the latter assumption to be false,
and that it is entirely feasible to obtain useful typing biometric signatures from
third-party timing logs. Specifically, we show that the logs produced by realtime
collaboration services during their normal operation are of sufficient fidelity to
successfully impersonate a user using remote data only. Since the logs are routinely
shared as a byproduct of the services' operation, this creates an entirely new avenue
of attack that few users would be aware of.As a proof of concept, we construct successful
biometric attacks using only the log-based structure (complete editing history) of
a shared Google Docs, or Zoho Writer, document which is readily available to all contributing
parties. Using the largest available public data set of typing biometrics, we are
able to create successful forgeries 100% of the time against a commercial biometric
service.Our results suggest that typing biometrics are not robust against practical
forgeries, and should not be given the same weight as other authentication factors.
Another important implication is that the routine collection of detailed timing logs
by various online services also inherently (and implicitly) contains biometrics. This
not only raises obvious privacy concerns, but may also undermine the effectiveness
of network anonymization solutions, such as ToR, when used with existing services.},
  doi       = {10.1145/3274694.3274754},
  isbn      = {9781450365697},
  keywords  = {keystroke dynamics, cloud security, cloud forensics, typing biometrics, authorship attribution, privacy, online collaboration, multifactor authentication},
  location  = {San Juan, PR, USA},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3274694.3274754},
}

@Article{Lin2013,
  author     = {Lin, Jimmy and Ryaboy, Dmitriy},
  journal    = {SIGKDD Explor. Newsl.},
  title      = {Scaling Big Data Mining Infrastructure: The Twitter Experience},
  year       = {2013},
  issn       = {1931-0145},
  month      = apr,
  number     = {2},
  pages      = {6–19},
  volume     = {14},
  abstract   = {The analytics platform at Twitter has experienced tremendous growth over the past
few years in terms of size, complexity, number of users, and variety of use cases.
In this paper, we discuss the evolution of our infrastructure and the development
of capabilities for data mining on "big data". One important lesson is that successful
big data mining in practice is about much more than what most academics would consider
data mining: life "in the trenches" is occupied by much preparatory work that precedes
the application of data mining algorithms and followed by substantial effort to turn
preliminary models into robust solutions. In this context, we discuss two topics:
First, schemas play an important role in helping data scientists understand petabyte-scale
data stores, but they're insufficient to provide an overall "big picture" of the data
available to generate insights. Second, we observe that a major challenge in building
data analytics platforms stems from the heterogeneity of the various components that
must be integrated together into production workflows---we refer to this as "plumbing".
This paper has two goals: For practitioners, we hope to share our experiences to flatten
bumps in the road for those who come after us. For academic researchers, we hope to
provide a broader context for data mining in production environments, pointing out
opportunities for future work.},
  address    = {New York, NY, USA},
  doi        = {10.1145/2481244.2481247},
  issue_date = {December 2012},
  numpages   = {14},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2481244.2481247},
}

@Article{Kourtellis2015,
  author     = {Kourtellis, Nicolas and Blackburn, Jeremy and Borcea, Cristian and Iamnitchi, Adriana},
  journal    = {ACM Trans. Internet Technol.},
  title      = {Special Issue on Foundations of Social Computing: Enabling Social Applications via Decentralized Social Data Management},
  year       = {2015},
  issn       = {1533-5399},
  month      = mar,
  number     = {1},
  volume     = {15},
  abstract   = {An unprecedented information wealth produced by online social networks, further augmented
by location/collocation data, is currently fragmented across different proprietary
services. Combined, it can accurately represent the social world and enable novel
socially aware applications. We present Prometheus, a socially aware peer-to-peer
service that collects social information from multiple sources into a multigraph managed
in a decentralized fashion on user-contributed nodes, and exposes it through an interface
implementing nontrivial social inferences while complying with user-defined access
policies. Simulations and experiments on PlanetLab with emulated application workloads
show the system exhibits good end-to-end response time, low communication overhead,
and resilience to malicious attacks.},
  address    = {New York, NY, USA},
  articleno  = {1},
  doi        = {10.1145/2700057},
  issue_date = {February 2015},
  keywords   = {socially aware data management, Distributed systems, social inferences, social sensors, P2P networks, decentralized social graph},
  numpages   = {26},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2700057},
}

@Article{Yiu2011,
  author     = {Yiu, Man Lung and Jensen, Christian S. and M\o{}ller, Jesper and Lu, Hua},
  journal    = {ACM Trans. Database Syst.},
  title      = {Design and Analysis of a Ranking Approach to Private Location-Based Services},
  year       = {2011},
  issn       = {0362-5915},
  month      = jun,
  number     = {2},
  volume     = {36},
  abstract   = {Users of mobile services wish to retrieve nearby points of interest without disclosing
their locations to the services. This article addresses the challenge of optimizing
the query performance while satisfying given location privacy and query accuracy requirements.
The article's proposal, SpaceTwist, aims to offer location privacy for k nearest neighbor
(kNN) queries at low communication cost without requiring a trusted anonymizer. The
solution can be used with a conventional DBMS as well as with a server optimized for
location-based services. In particular, we believe that this is the first solution
that expresses the server-side functionality in a single SQL statement. In its basic
form, SpaceTwist utilizes well-known incremental NN query processing on the server.
When augmented with a server-side granular search technique, SpaceTwist is capable
of exploiting relaxed query accuracy guarantees for obtaining better performance.
We extend SpaceTwist with so-called ring ranking, which improves the communication
cost, delayed termination, which improves the privacy afforded the user, and the ability
to function in spatial networks in addition to Euclidean space. We report on analytical
and empirical studies that offer insight into the properties of SpaceTwist and suggest
that our proposal is indeed capable of offering privacy with very good performance
in realistic settings.},
  address    = {New York, NY, USA},
  articleno  = {10},
  doi        = {10.1145/1966385.1966388},
  issue_date = {May 2011},
  keywords   = {mobile service, Location privacy},
  numpages   = {42},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/1966385.1966388},
}

@InProceedings{Bhatia2016,
  author    = {Bhatia, Jaspreet and Breaux, Travis D. and Friedberg, Liora and Hibshi, Hanan and Smullen, Daniel},
  booktitle = {Proceedings of the 2016 ACM on Workshop on Information Sharing and Collaborative Security},
  title     = {Privacy Risk in Cybersecurity Data Sharing},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {57–64},
  publisher = {Association for Computing Machinery},
  series    = {WISCS '16},
  abstract  = {As information systems become increasingly interdependent, there is an increased need
to share cybersecurity data across government agencies and companies, and within and
across industrial sectors. This sharing includes threat, vulnerability and incident
reporting data, among other data. For cyberattacks that include sociotechnical vectors,
such as phishing or watering hole attacks, this increased sharing could expose customer
and employee personal data to increased privacy risk. In the US, privacy risk arises
when the government voluntarily receives data from companies without meaningful consent
from individuals, or without a lawful procedure that protects an individual's right
to due process. In this paper, we describe a study to examine the trade-off between
the need for potentially sensitive data, which we call incident data usage, and the
perceived privacy risk of sharing that data with the government. The study is comprised
of two parts: a data usage estimate built from a survey of 76 security professionals
with mean eight years' experience; and a privacy risk estimate that measures privacy
risk using an ordinal likelihood scale and nominal data types in factorial vignettes.
The privacy risk estimate also factors in data purposes with different levels of societal
benefit, including terrorism, imminent threat of death, economic harm, and loss of
intellectual property. The results show which data types are high-usage, low-risk
versus those that are low-usage, high-risk. We discuss the implications of these results
and recommend future work to improve privacy when data must be shared despite the
increased risk to privacy.},
  doi       = {10.1145/2994539.2994541},
  isbn      = {9781450345651},
  keywords  = {cybersecurity data sharing, personal privacy, data usage, risk perception},
  location  = {Vienna, Austria},
  numpages  = {8},
  url       = {https://doi.org/10.1145/2994539.2994541},
}

@InProceedings{HabibiLashkari2020,
  author    = {Habibi Lashkari, Arash and Kaur, Gurdip and Rahali, Abir},
  booktitle = {2020 the 10th International Conference on Communication and Network Security},
  title     = {DIDarknet: A Contemporary Approach to Detect and Characterize the Darknet Traffic Using Deep Image Learning},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {1–13},
  publisher = {Association for Computing Machinery},
  series    = {ICCNS 2020},
  abstract  = {Darknet traffic classification is significantly important to categorize real-time
applications. Although there are notable efforts to classify darknet traffic which
rely heavily on existing datasets and machine learning classifiers, there are extremely
few efforts to detect and characterize darknet traffic using deep learning. This work
proposes a novel approach, named DeepImage, which uses feature selection to pick the
most important features to create a gray image and feed it to a two-dimensional convolutional
neural network to detect and characterize darknet traffic. Two encrypted traffic datasets
are merged to create a darknet dataset to evaluate the proposed approach which successfully
characterizes darknet traffic with 86% accuracy.},
  doi       = {10.1145/3442520.3442521},
  isbn      = {9781450389037},
  keywords  = {encrypted traffic, characterization, deep learning, tor, detection, darknet, VPN, darknet traffic},
  location  = {Tokyo, Japan},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3442520.3442521},
}

@InProceedings{Savva2011,
  author    = {Savva, Manolis and Kong, Nicholas and Chhajta, Arti and Fei-Fei, Li and Agrawala, Maneesh and Heer, Jeffrey},
  booktitle = {Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology},
  title     = {ReVision: Automated Classification, Analysis and Redesign of Chart Images},
  year      = {2011},
  address   = {New York, NY, USA},
  pages     = {393–402},
  publisher = {Association for Computing Machinery},
  series    = {UIST '11},
  abstract  = {Poorly designed charts are prevalent in reports, magazines, books and on the Web.
Most of these charts are only available as bitmap images; without access to the underlying
data it is prohibitively difficult for viewers to create more effective visual representations.
In response we present ReVision, a system that automatically redesigns visualizations
to improve graphical perception. Given a bitmap image of a chart as input, ReVision
applies computer vision and machine learning techniques to identify the chart type
(e.g., pie chart, bar chart, scatterplot, etc.). It then extracts the graphical marks
and infers the underlying data. Using a corpus of images drawn from the web, ReVision
achieves image classification accuracy of 96% across ten chart categories. It also
accurately extracts marks from 79% of bar charts and 62% of pie charts, and from these
charts it successfully extracts data from 71% of bar charts and 64% of pie charts.
ReVision then applies perceptually-based design principles to populate an interactive
gallery of redesigned charts. With this interface, users can view alternative chart
designs and retarget content to different visual styles.},
  doi       = {10.1145/2047196.2047247},
  isbn      = {9781450307161},
  keywords  = {chart understanding, computer vision, information extraction, redesign, visualization},
  location  = {Santa Barbara, California, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2047196.2047247},
}

@InProceedings{Fahrnberger2017,
  author    = {Fahrnberger, G\"{u}nter},
  booktitle = {Proceedings of the 18th International Conference on Distributed Computing and Networking},
  title     = {Contemporary IT Security for Military Online Collaboration Platforms},
  year      = {2017},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ICDCN '17},
  abstract  = {Persistent armed conflicts with volatile intensities around Europe and resultant incidents
directly on the old continent prompt the European governments and their general staffs
to hold militiamen as reserve forces ready for emergency cases. These semi-professional
soldiers need to regularly exercise their military skills. It is common practice that
the leaderships of militia organizations connect via the Internet to military online
collaboration platforms to prepare their field exercises there. Despite the involvement
of the Internet in the transmission of sensitive military data, the IT security objectives
authenticity, integrity, nonrepudiation, privacy, and resilience must be achieved
at all costs. In the absence of an apposite IT security concept for such platforms
in the literature, this publication amalgamates topical techniques to propose an access
model that fulfills all five IT security targets. Beside the development stages threat
model, security policy, and security mechanism, the disquisition proves the feasibility
of the approach by manifesting airtight performance and security analyses.},
  articleno = {33},
  doi       = {10.1145/3007748.3007754},
  isbn      = {9781450348393},
  keywords  = {Security, Military, ECG, Biometry, Secrecy, Integrity, Availability, Cooperation, Privacy, Confidentiality, Electrocardiography, Nonrepudiation, Collaboration, Electrocardiogram, Authentication, Resilience, Protection, Authenticity},
  location  = {Hyderabad, India},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3007748.3007754},
}

@InProceedings{Enev2012,
  author    = {Enev, Miro and Jung, Jaeyeon and Bo, Liefeng and Ren, Xiaofeng and Kohno, Tadayoshi},
  booktitle = {Proceedings of the 28th Annual Computer Security Applications Conference},
  title     = {SensorSift: Balancing Sensor Data Privacy and Utility in Automated Face Understanding},
  year      = {2012},
  address   = {New York, NY, USA},
  pages     = {149–158},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '12},
  abstract  = {We introduce SensorSift, a new theoretical scheme for balancing utility and privacy
in smart sensor applications. At the heart of our contribution is an algorithm which
transforms raw sensor data into a 'sifted' representation which minimizes exposure
of user defined private attributes while maximally exposing application-requested
public attributes. We envision multiple applications using the same platform, and
requesting access to public attributes explicitly not known at the time of the platform
creation. Support for future-defined public attributes, while still preserving the
defined privacy of the private attributes, is a central challenge that we tackle.To
evaluate our approach, we apply SensorSift to the PubFig dataset of celebrity face
images, and study how well we can simultaneously hide and reveal various policy combinations
of face attributes using machine classifiers.We find that as long as the public and
private attributes are not significantly correlated, it is possible to generate a
sifting transformation which reduces private attribute inferences to random guessing
while maximally retaining classifier accuracy of public attributes relative to raw
data (average PubLoss = .053 and PrivLoss = .075, see Figure 4). In addition, our
sifting transformations led to consistent classification performance when evaluated
using a set of five modern machine learning methods (linear SVM, kNearest Neighbors,
Random Forests, kernel SVM, and Neural Nets).},
  doi       = {10.1145/2420950.2420975},
  isbn      = {9781450313124},
  location  = {Orlando, Florida, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2420950.2420975},
}

@InProceedings{Sochor2020,
  author    = {Sochor, Hannes and Ferrarotti, Flavio and Ramler, Rudolf},
  booktitle = {Proceedings of the 15th International Conference on Availability, Reliability and Security},
  title     = {Automated Security Test Generation for MQTT Using Attack Patterns},
  year      = {2020},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ARES '20},
  abstract  = {The dramatic increase of attacks and malicious activities has made security a major
concern in the development of interconnected cyber-physical systems and raised the
need to address this concern also in testing. The goal of security testing is to discover
vulnerabilities in the system under test so that they can be fixed before an attacker
finds and abuses them. However, testing for security issues faces the challenge of
systematically exploring a potentially non-tractable number of interaction scenarios
that have to include also invalid inputs and possible harmful interaction attempts.
In this paper, we describe an approach for automated generation of test cases for
security testing, which are based on attack patterns. These patterns are blueprints
that can be used for exploiting common vulnerabilities. The approach combines random
test case generation with attack patterns implemented for the Message Queuing Telemetry
Transport (MQTT) protocol. We have applied the proposed testing approach to five popular
and widely available MQTT brokers, generating 1,804 interaction sequences in form
of executable test cases which resulted in numerous test failures, unhandled exceptions
and crashes. A detailed manual analysis of these cases have revealed 28 security-relevant
issues and critical shortcomings in the tested MQTT broker implementations.},
  articleno = {97},
  doi       = {10.1145/3407023.3407078},
  isbn      = {9781450388337},
  keywords  = {fuzz testing, attack patterns, MQTT, test case generation, test automation, security testing},
  location  = {Virtual Event, Ireland},
  numpages  = {9},
  url       = {https://doi.org/10.1145/3407023.3407078},
}

@Article{Jacobson2012,
  author     = {Jacobson, Van and Smetters, Diana K. and Thornton, James D. and Plass, Michael and Briggs, Nick and Braynard, Rebecca},
  journal    = {Commun. ACM},
  title      = {Networking Named Content},
  year       = {2012},
  issn       = {0001-0782},
  month      = jan,
  number     = {1},
  pages      = {117–124},
  volume     = {55},
  abstract   = {Current network use is dominated by content distribution and retrieval yet current
networking protocols are designed for conversations between hosts. Accessing content
and services requires mapping from the what that users care about to the network's
where. We present Content-Centric Networking (CCN) which uses content chunks as a
primitive---decoupling location from identity, security and access, and retrieving
chunks of content by name. Using new approaches to routing named content, derived
from IP, CCN simultaneously achieves scalability, security, and performance. We describe
our implementation of the architecture's basic features and demonstrate its performance
and resilience with secure file downloads and VoIP calls.},
  address    = {New York, NY, USA},
  doi        = {10.1145/2063176.2063204},
  issue_date = {January 2012},
  numpages   = {8},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2063176.2063204},
}

@Article{Liu2018,
  author     = {Liu, Rui and Cornelius, Cory and Rawassizadeh, Reza and Peterson, Ronald and Kotz, David},
  journal    = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
  title      = {Vocal Resonance: Using Internal Body Voice for Wearable Authentication},
  year       = {2018},
  month      = mar,
  number     = {1},
  volume     = {2},
  abstract   = {We observe the advent of body-area networks of pervasive wearable devices, whether
for health monitoring, personal assistance, entertainment, or home automation. For
many devices, it is critical to identify the wearer, allowing sensor data to be properly
labeled or personalized behavior to be properly achieved. In this paper we propose
the use of vocal resonance, that is, the sound of the person's voice as it travels
through the person's body -- a method we anticipate would be suitable for devices
worn on the head, neck, or chest. In this regard, we go well beyond the simple challenge
of speaker recognition: we want to know who is wearing the device. We explore two
machine-learning approaches that analyze voice samples from a small throat-mounted
microphone and allow the device to determine whether (a) the speaker is indeed the
expected person, and (b) the microphone-enabled device is physically on the speaker's
body. We collected data from 29 subjects, demonstrate the feasibility of a prototype,
and show that our DNN method achieved balanced accuracy 0.914 for identification and
0.961 for verification by using an LSTM-based deep-learning model, while our efficient
GMM method achieved balanced accuracy 0.875 for identification and 0.942 for verification.},
  address    = {New York, NY, USA},
  articleno  = {19},
  doi        = {10.1145/3191751},
  issue_date = {March 2018},
  keywords   = {wearable device, mobile system security, vocal resonance, authentication, Biometric},
  numpages   = {23},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3191751},
}

@InProceedings{Kim2017,
  author    = {Kim, Doowon and Kwon, Bum Jun and Dumitra\c{s}, Tudor},
  booktitle = {Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {Certified Malware: Measuring Breaches of Trust in the Windows Code-Signing PKI},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {1435–1448},
  publisher = {Association for Computing Machinery},
  series    = {CCS '17},
  abstract  = {Digitally signed malware can bypass system protection mechanisms that install or launch
only programs with valid signatures. It can also evade anti-virus programs, which
often forego scanning signed binaries. Known from advanced threats such as Stuxnet
and Flame, this type of abuse has not been measured systematically in the broader
malware landscape. In particular, the methods, effectiveness window, and security
implications of code-signing PKI abuse are not well understood. We propose a threat
model that highlights three types of weaknesses in the code-signing PKI. We overcome
challenges specific to code-signing measurements by introducing techniques for prioritizing
the collection of code signing certificates that are likely abusive. We also introduce
an algorithm for distinguishing among different types of threats. These techniques
allow us to study threats that breach the trust encoded in the Windows code signing
PKI. The threats include stealing the private keys associated with benign certificates
and using them to sign malware or by impersonating legitimate companies that do not
develop software and, hence, do not own code-signing certificates. Finally, we discuss
the actionable implications of our findings and propose concrete steps for improving
the security of the code-signing ecosystem.},
  doi       = {10.1145/3133956.3133958},
  isbn      = {9781450349468},
  keywords  = {malware, windows authenticode, pki, code signing, compromised certificates},
  location  = {Dallas, Texas, USA},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3133956.3133958},
}

@Article{Luo2018,
  author     = {Luo, Zhiqing and Wang, Wei and Xiao, Jiang and Huang, Qianyi and jiang, Tao and Zhang, Qian},
  journal    = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
  title      = {Authenticating On-Body Backscatter by Exploiting Propagation Signatures},
  year       = {2018},
  month      = sep,
  number     = {3},
  volume     = {2},
  abstract   = {The vision of battery-free communication has made backscatter a compelling technology
for on-body wearable and implantable devices. Recent advances have facilitated the
communication between backscatter tags and on-body smart devices. These studies have
focused on the communication dimension, while the security dimension remains vulnerable.
It has been demonstrated that wireless connectivity can be exploited to send unauthorized
commands or fake messages that result in device malfunctioning. The key challenge
in defending these attacks stems from the minimalist design in backscatter. Thus,
in this paper, we explore the feasibility of authenticating an on-body backscatter
tag without modifying its signal or protocol. We present SecureScatter, a physical-layer
solution that delegates the security of backscatter to an on-body smart device. To
this end, we profile the on-body propagation paths of backscatter links, and construct
highly sensitive propagation signatures to identify on-body backscatter links. We
implement our design in a software radio and evaluate it with different backscatter
tags that work at 2.4 GHz and 900 MHz. Results show that our system can identify on-body
devices at 93.23% average true positive rate and 3.18% average false positive rate.},
  address    = {New York, NY, USA},
  articleno  = {123},
  doi        = {10.1145/3266002},
  issue_date = {September 2018},
  keywords   = {Wearable computing, Backscatter, On-body authentication},
  numpages   = {22},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3266002},
}

@InProceedings{Tuerpe2012,
  author    = {T\"{u}rpe, Sven},
  booktitle = {Proceedings of the 2012 New Security Paradigms Workshop},
  title     = {Point-and-Shoot Security Design: Can We Build Better Tools for Developers?},
  year      = {2012},
  address   = {New York, NY, USA},
  pages     = {27–42},
  publisher = {Association for Computing Machinery},
  series    = {NSPW '12},
  abstract  = {Security property degrees systematize the angles from which one can discuss the security
of a system. Microscopic properties characterize how specific actions affect parts
of a system. Mesoscopic properties describe how the pursuit of an attack objective
may affect the system and the attacker. Macroscopic properties represent the interaction
of a threat environment with a system. Properties of different degrees are interdependent,
but not in a simple and universal manner.Security design aims to control security
properties, shaping them in a favorable way. Its objective is macroscopic control
through design decisions on all three degrees. Design tools today occupy mostly the
lower half of the property degree scale. A few macroscopic design aids exist but provide
little guidance to engineers.Security designers are thus in a similar situation as
photographers, having to make fundamental design decisions without methodologies other
than their private, homegrown approaches. This is essential for art but a deficiency
in engineering. Standardized mechanization in point-and-shoot cameras helps inexpert
photographers to a limited extent but can get in the way of the experienced and ambitious.
Point-and-shoot security design, shorthand for current practice as well as a widely
held expectation, may do the same to security engineers.},
  doi       = {10.1145/2413296.2413300},
  isbn      = {9781450317948},
  keywords  = {security properties, macroscopic security, systematization, security engineering, security tools, threat, property degree, abstraction, security model, epistemology, adversary, philosophy},
  location  = {Bertinoro, Italy},
  numpages  = {16},
  url       = {https://doi.org/10.1145/2413296.2413300},
}

@InProceedings{Pal2017,
  author    = {Pal, Partha and Soule, Nathaniel and Lageman, Nate and Clark, Shane S. and Carvalho, Marco and Granados, Adrian and Alves, Anthony},
  booktitle = {Proceedings of the 12th International Conference on Availability, Reliability and Security},
  title     = {Adaptive Resource Management Enabling Deception (ARMED)},
  year      = {2017},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ARES '17},
  abstract  = {Distributed Denial of Service (DDoS) attacks routinely disrupt access to critical
services. Mitigation of these attacks often relies on planned over-provisioning or
elastic provisioning of resources, and third-party monitoring, analysis, and scrubbing
of network traffic. While volumetric attacks which saturate a victim's network are
most common, non-volumetric, low and slow, DDoS attacks can achieve their goals without
requiring high traffic volume by targeting vulnerable network protocols or protocol
implementations. Non-volumetric attacks, unlike their noisy counterparts, require
more sophisticated detection mechanisms, and typically have only post-facto and targeted
protocol/application mitigations. In this paper, we introduce our work under the Adaptive
Resource Management Enabling Deception (ARMED) effort, which is developing a network-level
approach to automatically mitigate sophisticated DDoS attacks through deception-focused
adaptive maneuvering. We describe the concept, implementation, and initial evaluation
of the ARMED Network Actors (ANAs) that facilitate transparent interception, sensing,
analysis, and mounting of adaptive responses that can disrupt the adversary's decision
process.},
  articleno = {52},
  doi       = {10.1145/3098954.3103151},
  isbn      = {9781450352574},
  keywords  = {Cybersecurity, Denial of Service, Deception},
  location  = {Reggio Calabria, Italy},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3098954.3103151},
}

@InProceedings{Lu2020,
  author    = {Lu, Chris Xiaoxuan and Li, Yang and Xiangli, Yuanbo and Li, Zhengxiong},
  booktitle = {Proceedings of The Web Conference 2020},
  title     = {Nowhere to Hide: Cross-Modal Identity Leakage between Biometrics and Devices},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {212–223},
  publisher = {Association for Computing Machinery},
  series    = {WWW '20},
  abstract  = {Along with the benefits of Internet of Things (IoT) come potential privacy risks,
since billions of the connected devices are granted permission to track information
about their users and communicate it to other parties over the Internet. Of particular
interest to the adversary is the user identity which constantly plays an important
role in launching attacks. While the exposure of a certain type of physical biometrics
or device identity is extensively studied, the compound effect of leakage from both
sides remains unknown in multi-modal sensing environments. In this work, we explore
the feasibility of the compound identity leakage across cyber-physical spaces and
unveil that co-located smart device IDs (e.g., smartphone MAC addresses) and physical
biometrics (e.g., facial/vocal samples) are side channels to each other. It is demonstrated
that our method is robust to various observation noise in the wild and an attacker
can comprehensively profile victims in multi-dimension with nearly zero analysis effort.
Two real-world experiments on different biometrics and device IDs show that the presented
approach can compromise more than 70% of device IDs and harvests multiple biometric
clusters with purity at the same time.},
  doi       = {10.1145/3366423.3380108},
  isbn      = {9781450370233},
  keywords  = {Cross-modality Association, Internet of Things, Identity Leakage},
  location  = {Taipei, Taiwan},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3366423.3380108},
}

@InProceedings{Erbacher2011,
  author    = {Erbacher, Robert and Biswas, Anupama and Cameron, Trent},
  booktitle = {Proceedings of the Seventh Annual Workshop on Cyber Security and Information Intelligence Research},
  title     = {A Novel Data Reduction Technique},
  year      = {2011},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {CSIIRW '11},
  articleno = {35},
  doi       = {10.1145/2179298.2179336},
  isbn      = {9781450309455},
  location  = {Oak Ridge, Tennessee, USA},
  numpages  = {1},
  url       = {https://doi.org/10.1145/2179298.2179336},
}

@Article{Paschalides2020,
  author     = {Paschalides, Demetris and Stephanidis, Dimosthenis and Andreou, Andreas and Orphanou, Kalia and Pallis, George and Dikaiakos, Marios D. and Markatos, Evangelos},
  journal    = {ACM Trans. Internet Technol.},
  title      = {MANDOLA: A Big-Data Processing and Visualization Platform for Monitoring and Detecting Online Hate Speech},
  year       = {2020},
  issn       = {1533-5399},
  month      = mar,
  number     = {2},
  volume     = {20},
  abstract   = {In recent years, the increasing propagation of hate speech in online social networks
and the need for effective counter-measures have drawn significant investment from
social network companies and researchers. This has resulted in the development of
many web platforms and mobile applications for reporting and monitoring online hate
speech incidents. In this article, we present MANDOLA, a big-data processing system
that monitors, detects, visualizes, and reports the spread and penetration of online
hate-related speech using big-data approaches. MANDOLA consists of six individual
components that intercommunicate to consume, process, store, and visualize statistical
information regarding hate speech spread online. We also present a novel ensemble-based
classification algorithm for hate speech detection that can significantly improve
the performance of MANDOLA’s ability to detect hate speech. To present the functionality
and usability of our system, we present a use case scenario of real-life event annotation
and data correlation. As shown from the performance of the individual modules, as
well as the usability and functionality of the whole system, MANDOLA is a powerful
system for reporting and monitoring online hate speech.},
  address    = {New York, NY, USA},
  articleno  = {11},
  doi        = {10.1145/3371276},
  issue_date = {May 2020},
  keywords   = {system approach, Hate speech, big-data processing platform, deep learning, online social networks},
  numpages   = {21},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3371276},
}

@InProceedings{Kjaergaard2012,
  author    = {Kj\ae{}rgaard, Mikkel Baun and Wirz, Martin and Roggen, Daniel and Tr\"{o}ster, Gerhard},
  booktitle = {Proceedings of the 2012 ACM Conference on Ubiquitous Computing},
  title     = {Detecting Pedestrian Flocks by Fusion of Multi-Modal Sensors in Mobile Phones},
  year      = {2012},
  address   = {New York, NY, USA},
  pages     = {240–249},
  publisher = {Association for Computing Machinery},
  series    = {UbiComp '12},
  abstract  = {Previous work on the recognition of human movement patterns has mainly focused on
movements of individuals. This paper addresses the joint identification of the indoor
movement of multiple persons forming a cohesive whole - specifically a flock - with
clustering approaches operating on features derived from multiple sensor modalities
of modern smartphones. Automatic detection of flocks has several important applications,
including evacuation management and socially aware computing. The novelty of this
paper is, firstly, to use data fusion techniques to combine several sensor modalities
(WiFi, accelerometer and compass) to improve recognition accuracy over previous unimodal
approaches. Secondly, improve the recognition of flocks using hierarchical clustering.
We use a dataset comprising 16 subjects forming one to four flocks walking in a building
on single and multiple floors. With the best settings, we achieve a F-score accuracy
of up to 87 percent an improvement of up to twelve percent points over existing approaches.},
  doi       = {10.1145/2370216.2370256},
  isbn      = {9781450312240},
  keywords  = {crowd behavior sensing, pattern recognition, signal strength-based methods, mobile sensing},
  location  = {Pittsburgh, Pennsylvania},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2370216.2370256},
}

@InProceedings{Polakis2015,
  author    = {Polakis, Iasonas and Argyros, George and Petsios, Theofilos and Sivakorn, Suphannee and Keromytis, Angelos D.},
  booktitle = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security},
  title     = {Where's Wally? Precise User Discovery Attacks in Location Proximity Services},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {817–828},
  publisher = {Association for Computing Machinery},
  series    = {CCS '15},
  abstract  = {Location proximity schemes have been adopted by social networks and other smartphone
apps as a means of balancing user privacy with utility. However, misconceptions about
the privacy offered by proximity services have rendered users vulnerable to trilateration
attacks that can expose their location. Such attacks have received major publicity.
and, as a result, popular service providers have deployed countermeasures for preventing
user discovery attacks.In this paper, we systematically assess the effectiveness of
the defenses that proximity services have deployed against adversaries attempting
to identify a user's location. We provide the theoretical foundation for formalizing
the problem under different proximity models, design practical attacks for each case,
and prove tight bounds on the number of queries required for carrying out the attacks.
To evaluate the completeness of our approach, we conduct extensive experiments against
popular services. While we identify a diverse set of defense techniques that prevent
trilateration attacks, we demonstrate their inefficiency against more elaborate attacks.
In fact, we pinpoint Facebook users within 5 meters of their exact location, and 90%
of Foursquare users within 15 meters. Our attacks are extremely efficient and complete
within 3-7 seconds. The severity of our attacks was acknowledged by Facebook and Foursquare,
both of which have followed our recommendations and adopted spatial cloaking to protect
their users. Furthermore, our findings have wide implications as numerous popular
apps with a massive user base remain vulnerable to this significant threat.},
  doi       = {10.1145/2810103.2813605},
  isbn      = {9781450338325},
  keywords  = {location privacy, location proximity, location-based services, user discovery attacks, spatial cloaking},
  location  = {Denver, Colorado, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2810103.2813605},
}

@Article{Xu2021,
  author     = {Xu, Weitao and Zhang, Junqing and Huang, Shunqi and Luo, Chengwen and Li, Wei},
  journal    = {ACM Comput. Surv.},
  title      = {Key Generation for Internet of Things: A Contemporary Survey},
  year       = {2021},
  issn       = {0360-0300},
  month      = jan,
  number     = {1},
  volume     = {54},
  abstract   = {Key generation is a promising technique to bootstrap secure communications for the
Internet of Things devices that have no prior knowledge between each other. In the
past few years, a variety of key generation protocols and systems have been proposed.
In this survey, we review and categorise recent key generation systems based on a
novel taxonomy. Then, we provide both quantitative and qualitative comparisons of
existing approaches. We also discuss the security vulnerabilities of key generation
schemes and possible countermeasures. Finally, we discuss the current challenges and
point out several potential research directions.},
  address    = {New York, NY, USA},
  articleno  = {14},
  doi        = {10.1145/3429740},
  issue_date = {April 2021},
  keywords   = {device pairing, authentication, IoT, key generation},
  numpages   = {37},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3429740},
}

@Article{Shu2017,
  author     = {Shu, Xiaokui and Yao, Danfeng (Daphne) and Ramakrishnan, Naren and Jaeger, Trent},
  journal    = {ACM Trans. Priv. Secur.},
  title      = {Long-Span Program Behavior Modeling and Attack Detection},
  year       = {2017},
  issn       = {2471-2566},
  month      = sep,
  number     = {4},
  volume     = {20},
  abstract   = {Intertwined developments between program attacks and defenses witness the evolution
of program anomaly detection methods. Emerging categories of program attacks, e.g.,
non-control data attacks and data-oriented programming, are able to comply with normal
trace patterns at local views. This article points out the deficiency of existing
program anomaly detection models against new attacks and presents long-span behavior
anomaly detection (LAD), a model based on mildly context-sensitive grammar verification.
The key feature of LAD is its reasoning of correlations among arbitrary events that
occurred in long program traces. It extends existing correlation analysis between
events at a stack snapshot, e.g., paired call and ret, to correlation analysis among
events that historically occurred during the execution. The proposed method leverages
specialized machine learning techniques to probe normal program behavior boundaries
in vast high-dimensional detection space. Its two-stage modeling/detection design
analyzes event correlation at both binary and quantitative levels. Our prototype successfully
detects all reproduced real-world attacks against sshd, libpcre, and sendmail. The
detection procedure incurs 0.1 ms to 1.3 ms overhead to profile and analyze a single
behavior instance that consists of tens of thousands of function call or system call
events.},
  address    = {New York, NY, USA},
  articleno  = {12},
  doi        = {10.1145/3105761},
  issue_date = {October 2017},
  keywords   = {program analysis, Intrusion detection, anomaly detection, co-occurrence analysis, context-sensitive grammar, event frequency correlation, machine learning},
  numpages   = {28},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3105761},
}

@Article{Diaz2014,
  author     = {Diaz, Fernando},
  journal    = {SIGIR Forum},
  title      = {Experimentation Standards for Crisis Informatics},
  year       = {2014},
  issn       = {0163-5840},
  month      = dec,
  number     = {2},
  pages      = {22–30},
  volume     = {48},
  address    = {New York, NY, USA},
  doi        = {10.1145/2701583.2701586},
  issue_date = {December 2014},
  numpages   = {9},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2701583.2701586},
}

@InProceedings{Adam2018,
  author    = {Adam, I. and Ping, J.},
  booktitle = {Proceedings of the 13th International Conference on Availability, Reliability and Security},
  title     = {Framework for Security Event Management in 5G},
  year      = {2018},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ARES 2018},
  abstract  = {5G will support a wide range of industry verticals and security is fundamental to
successfully deliver 5G networks for different kind of use cases. Heterogeneous devices
and applications will lead to different security requirements to be covered by diverse
security functions. Security management in 5G networks should meet the needs of heterogeneous
business models in the 5G ecosystem and address the motivations from the different
stakeholders. We present a framework for automated security event management to offer
security monitoring and correlation capabilities to mobile network operators, infrastructure
service providers, and tenants like verticals while considering the performance requirements
from future applications as well as security and regulatory compliance with Service
Levels.},
  articleno = {51},
  doi       = {10.1145/3230833.3233254},
  isbn      = {9781450364485},
  keywords  = {Security function, 5G telco cloud, slicing, service level agreement, security management},
  location  = {Hamburg, Germany},
  numpages  = {7},
  url       = {https://doi.org/10.1145/3230833.3233254},
}

@InProceedings{Chen2012,
  author    = {Chen, Yuxin and Luo, Bo},
  booktitle = {Proceedings of the Second ACM Conference on Data and Application Security and Privacy},
  title     = {S2A: Secure Smart Household Appliances},
  year      = {2012},
  address   = {New York, NY, USA},
  pages     = {217–228},
  publisher = {Association for Computing Machinery},
  series    = {CODASPY '12},
  abstract  = {Security protection is an integral component for smart homes; however, smart appliances
security has received little attention in the research community. Household appliances
become very vulnerable if we introduce smart functions without proper security protection.
In particular, smart access functions enable users to operate devices remotely. Meanwhile,
smart devices are are also designed to support residential demand response, i.e. postpone
non-urgent tasks to non-peak hours. However, remote adversaries could utilize such
functions to manipulate smart appliances' operations without physically touching them.
Such interferences, if not properly handled, could damage the smart devices, disturb
owners' life or even harm the households' physical security.In this paper, we present
S2A, a security protection solution to be embedded in smart appliances. First, a SUP
model is developed to quantify penalties from device security, usability and electricity
price. We employ multi-criteria reinforcement learning to integrate the three factors
to determine an optimal operation strategy. Next, to leverage the risk of forged control
commands or pricing data, we present a realtime assessment mechanism based on Bayesian
inference. Risk indices are further integrated into the SUP model to serve as weighting
factors of corresponding decision criteria. Evaluation shows that S2A ensures appliances
security while providing good usability and economical efficiency.},
  doi       = {10.1145/2133601.2133628},
  isbn      = {9781450310918},
  keywords  = {machine learning for security, smart household devices, intrusion detection, smart grids},
  location  = {San Antonio, Texas, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2133601.2133628},
}

@Article{Chiang2014,
  author     = {Chiang, Yao-Yi and Leyk, Stefan and Knoblock, Craig A.},
  journal    = {ACM Comput. Surv.},
  title      = {A Survey of Digital Map Processing Techniques},
  year       = {2014},
  issn       = {0360-0300},
  month      = may,
  number     = {1},
  volume     = {47},
  abstract   = {Maps depict natural and human-induced changes on earth at a fine resolution for large
areas and over long periods of time. In addition, maps—especially historical maps—are
often the only information source about the earth as surveyed using geodetic techniques.
In order to preserve these unique documents, increasing numbers of digital map archives
have been established, driven by advances in software and hardware technologies. Since
the early 1980s, researchers from a variety of disciplines, including computer science
and geography, have been working on computational methods for the extraction and recognition
of geographic features from archived images of maps (digital map processing). The
typical result from map processing is geographic information that can be used in spatial
and spatiotemporal analyses in a Geographic Information System environment, which
benefits numerous research fields in the spatial, social, environmental, and health
sciences. However, map processing literature is spread across a broad range of disciplines
in which maps are included as a special type of image. This article presents an overview
of existing map processing techniques, with the goal of bringing together the past
and current research efforts in this interdisciplinary field, to characterize the
advances that have been made, and to identify future research directions and opportunities.},
  address    = {New York, NY, USA},
  articleno  = {1},
  doi        = {10.1145/2557423},
  issue_date = {July 2014},
  keywords   = {pattern recognition, geographic information systems, graphics recognition, Map processing, image processing, color segmentation},
  numpages   = {44},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2557423},
}

@Article{Islam2018,
  author     = {Islam, Mohammad A. and Yang, Luting and Ranganath, Kiran and Ren, Shaolei},
  journal    = {Proc. ACM Meas. Anal. Comput. Syst.},
  title      = {Why Some Like It Loud: Timing Power Attacks in Multi-Tenant Data Centers Using an Acoustic Side Channel},
  year       = {2018},
  month      = apr,
  number     = {1},
  volume     = {2},
  abstract   = {The common practice of power infrastructure oversubscription in data centers exposes
dangerous vulnerabilities to well-timed power attacks (i.e., maliciously timed power
loads to overload the infrastructure capacity), possibly creating outages and resulting
in multimillion-dollar losses. In this paper, we focus on the emerging threat of power
attacks in a multi-tenant data center, where a malicious tenant (i.e., attacker) aims
at compromising the data center availability through power attacks. We discover a
novel acoustic side channel resulting from servers' cooling fan noise, which can help
the attacker time power attacks at the moments when benign tenants' power usage is
high. Concretely, we exploit the acoustic side channel by: (1) employing a high-pass
filter to filter out the air conditioner's noise; (2) applying non-negative matrix
factorization with sparsity constraint to demix the received aggregate noise and detect
periods of high power usage by benign tenants; and (3) designing a state machine to
guide power attacks. We run experiments in a practical data center environment as
well as simulation studies, and demonstrate that the acoustic side channel can assist
the attacker with detecting more than 50% of all attack opportunities, representing
state-of-the-art timing accuracy.},
  address    = {New York, NY, USA},
  articleno  = {6},
  doi        = {10.1145/3179409},
  issue_date = {March 2018},
  keywords   = {acoustic side channel, power attack, data center},
  numpages   = {33},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3179409},
}

@Article{Li2018,
  author     = {Li, Bo and Vorobeychik, Yevgeniy},
  journal    = {ACM Trans. Knowl. Discov. Data},
  title      = {Evasion-Robust Classification on Binary Domains},
  year       = {2018},
  issn       = {1556-4681},
  month      = jun,
  number     = {4},
  volume     = {12},
  abstract   = {The success of classification learning has led to numerous attempts to apply it in
adversarial settings such as spam and malware detection. The core challenge in this
class of applications is that adversaries are not static, but make a deliberate effort
to evade the classifiers. We investigate both the problem of modeling the objectives
of such adversaries, as well as the algorithmic problem of accounting for rational,
objective-driven adversaries. We first present a general approach based on mixed-integer
linear programming (MILP) with constraint generation. This approach is the first to
compute an optimal solution to adversarial loss minimization for two general classes
of adversarial evasion models in the context of binary feature spaces. To further
improve scalability and significantly generalize the scope of the MILP-based method,
we propose a principled iterative retraining framework, which can be used with arbitrary
classifiers and essentially arbitrary attack models. We show that the retraining approach,
when it converges, minimizes an upper bound on adversarial loss. Extensive experiments
demonstrate that the mixed-integer programming approach significantly outperforms
several state-of-the-art adversarial learning alternatives. Moreover, the retraining
framework performs nearly as well, but scales significantly better. Finally, we show
that our approach is robust to misspecifications of the adversarial model.},
  address    = {New York, NY, USA},
  articleno  = {50},
  doi        = {10.1145/3186282},
  issue_date = {July 2018},
  keywords   = {Adversarial classification, mixed-integer linear programming, robust learning, adversarial examples, classifier evasion},
  numpages   = {32},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3186282},
}

@InProceedings{Vishnu2014,
  author    = {Vishnu, B. A. and Jevitha, K. P.},
  booktitle = {Proceedings of the 2014 International Conference on Interdisciplinary Advances in Applied Computing},
  title     = {Prediction of Cross-Site Scripting Attack Using Machine Learning Algorithms},
  year      = {2014},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ICONIAAC '14},
  abstract  = {Dynamic web pages are widely used by web applications to provide better user experience
and to attract more web users. The web applications use the client side and server
side scripts to provide dynamic behavior to the web pages. Cross-Site Scripting (XSS)
attack uses malicious scripts and links injected into the trusted web pages to steal
sensitive data from the victims. In this paper, we present the experimental results
obtained using three machine learning algorithms (Na\"{\i}ve Bayes, Support Vector Machine
and J48 Decision Tree) for the prediction of Cross-site scripting attack. This is
done using the features based on normal and malicious URLs and JavaScript. J48 gave
better results than Na\"{\i}ve Bayes and Support Vector Machine based on the features extracted
from URL and Java Script code. All the algorithms gave comparatively better results
with discretized attributes but noticeable difference in performance was seen only
in the case of SVM.},
  articleno = {55},
  doi       = {10.1145/2660859.2660969},
  isbn      = {9781450329088},
  keywords  = {Machine learning, Web application security, Cross Site Scripting (XSS)},
  location  = {Amritapuri, India},
  numpages  = {5},
  url       = {https://doi.org/10.1145/2660859.2660969},
}

@Article{Ovelgoenne2017,
  author     = {Ovelg\"{o}nne, Michael and Dumitra\c{s}, Tudor and Prakash, B. Aditya and Subrahmanian, V. S. and Wang, Benjamin},
  journal    = {ACM Trans. Intell. Syst. Technol.},
  title      = {Understanding the Relationship between Human Behavior and Susceptibility to Cyber Attacks: A Data-Driven Approach},
  year       = {2017},
  issn       = {2157-6904},
  month      = mar,
  number     = {4},
  volume     = {8},
  abstract   = {Despite growing speculation about the role of human behavior in cyber-security of
machines, concrete data-driven analysis and evidence have been lacking. Using Symantec’s
WINE platform, we conduct a detailed study of 1.6 million machines over an 8-month
period in order to learn the relationship between user behavior and cyber attacks
against their personal computers. We classify users into 4 categories (gamers, professionals,
software developers, and others, plus a fifth category comprising everyone) and identify
a total of 7 features that act as proxies for human behavior. For each of the 35 possible
combinations (5 categories times 7 features), we studied the relationship between
each of these seven features and one dependent variable, namely the number of attempted
malware attacks detected by Symantec on the machine. Our results show that there is
a strong relationship between several features and the number of attempted malware
attacks. Had these hosts not been protected by Symantec’s anti-virus product or a
similar product, they would likely have been infected. Surprisingly, our results show
that software developers are more at risk of engaging in risky cyber-behavior than
other categories.},
  address    = {New York, NY, USA},
  articleno  = {51},
  doi        = {10.1145/2890509},
  issue_date = {July 2017},
  keywords   = {Malware, computer virus, user behavior},
  numpages   = {25},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2890509},
}

@InProceedings{Choi2016,
  author    = {Choi, Kibum and Son, Yunmok and Noh, Juhwan and Shin, Hocheol and Choi, Jaeyeong and Kim, Yongdae},
  booktitle = {Proceedings of the 9th ACM Conference on Security &amp; Privacy in Wireless and Mobile Networks},
  title     = {Dissecting Customized Protocols: Automatic Analysis for Customized Protocols Based on IEEE 802.15.4},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {183–193},
  publisher = {Association for Computing Machinery},
  series    = {WiSec '16},
  abstract  = {IEEE 802.15.4 is widely used as lower layers for not only wellknown wireless communication
standards such as ZigBee, 6LoWPAN, and WirelessHART, but also customized protocols
developed by manufacturers, particularly for various Internet of Things (IoT) devices.
Customized protocols are not usually publicly disclosed nor standardized. Moreover,
unlike textual protocols (e.g., HTTP, SMTP, POP3.), customized protocols for IoT devices
provide no clues such as strings or keywords that are useful for analysis. Instead,
they use bits or bytes to represent header and body information in order to save power
and bandwidth. On the other hand, they often do not employ encryption, fragmentation,
or authentication to save cost and effort in implementations. In other words, their
security relies only on the confidentiality of the protocol itself.In this paper,
we introduce a novel methodology to analyze and reconstruct unknown wireless customized
protocols over IEEE 802.15.4. Based on this methodology, we develop an automatic analysis
and spoofing tool called WPAN automatic spoofer (WASp) that can be used to understand
and reconstruct customized protocols to byte-level accuracy, and to generate packets
that can be used for verification of analysis results or spoofing attacks. The methodology
consists of four phases: packet collection, packet grouping, protocol analysis, and
packet generation. Except for the packet collection step, all steps are fully automated.Although
the use of customized protocols is also unknown before the collecting phase, we choose
two real-world target systems for evaluation: the smart plug system and platform screen
door (PSD) to evaluate our methodology and WASp. In the evaluation, 7,299 and 217
packets are used as datasets for both target systems, respectively. As a result, on
average, WASp is found to reduce entropy of legitimate message space by 93.77% and
88.11% for customized protocols used in smart plug and PSD systems, respectively.
In addition, on average, 48.19% of automatically generated packets are successfully
spoofed for the first target systems.},
  doi       = {10.1145/2939918.2939921},
  isbn      = {9781450342704},
  keywords  = {wireless spoofing attacks, automatic protocol reversing, customized pan protocol},
  location  = {Darmstadt, Germany},
  numpages  = {11},
  url       = {https://doi.org/10.1145/2939918.2939921},
}

@Article{Cao2012,
  author     = {Cao, Zhen and Deng, Hui and Guan, Zhi and Chen, Zhong},
  journal    = {ACM Trans. Sen. Netw.},
  title      = {Information-Theoretic Modeling of False Data Filtering Schemes in Wireless Sensor Networks},
  year       = {2012},
  issn       = {1550-4859},
  month      = mar,
  number     = {2},
  volume     = {8},
  abstract   = {False data filtering schemes are designed to filter out false data injected by malicious
sensors; they keep the network immune to bogus event reports. Theoretic understanding
of false data filtering schemes and guidelines to further improve their designs are
still lacking. This article first presents an information-theoretic model of false
data filtering schemes. From the information-theoretic view, we define the scheme's
filtering capacity CFi as the uncertainty-reduction ratio of the target input variable,
given the output. This metric not only performs better than existing metrics but also
implies that only by optimizing the false negative rate and false positive rate simultaneously,
can we promote a scheme's overall performance. Based on the investigation from the
modeling efforts, we propose HiFi, a hybrid authentication-based false data filtering
scheme. HiFi leverages the benefits of both symmetric and asymmetric cryptography
and achieves a high filtering capacity, as well as low computation and communication
overhead. Performance analysis demonstrates that our proposed metric is rational and
useful, and that HiFi is effective and energy efficient.},
  address    = {New York, NY, USA},
  articleno  = {14},
  doi        = {10.1145/2140522.2140527},
  issue_date = {March 2012},
  keywords   = {information theory, False data filtering, sensor networks},
  numpages   = {19},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2140522.2140527},
}

@InProceedings{Bates2012,
  author    = {Bates, Adam and Mood, Benjamin and Pletcher, Joe and Pruse, Hannah and Valafar, Masoud and Butler, Kevin},
  booktitle = {Proceedings of the 2012 ACM Workshop on Cloud Computing Security Workshop},
  title     = {Detecting Co-Residency with Active Traffic Analysis Techniques},
  year      = {2012},
  address   = {New York, NY, USA},
  pages     = {1–12},
  publisher = {Association for Computing Machinery},
  series    = {CCSW '12},
  abstract  = {Virtualization is the cornerstone of the developing third party compute industry,
allowing cloud providers to instantiate multiple virtual machines (VMs) on a single
set of physical resources. Customers utilize cloud resources alongside unknown and
untrusted parties, creating the co-resident threat -- unless perfect isolation is
provided by the virtual hypervisor, there exists the possibility for unauthorized
access to sensitive customer information through the exploitation of covert side channels.This
paper presents co-resident watermarking, a traffic analysis attack that allows a malicious
co-resident VM to inject a watermark signature into the network flow of a target instance.
This watermark can be used to exfiltrate and broadcast co-residency data from the
physical machine, compromising isolation without reliance on internal side channels.
As a result, our approach is difficult to defend without costly underutilization of
the physical machine. We evaluate co-resident watermarking under a large variety of
conditions, system loads and hardware configurations, from a local lab environment
to production cloud environments (Futuregrid and the University of Oregon's ACISS).
We demonstrate the ability to initiate a covert channel of 4 bits per second, and
we can confirm co-residency with a target VM instance in less than 10 seconds. We
also show that passive load measurement of the target and subsequent behavior profiling
is possible with this attack. Our investigation demonstrates the need for the careful
design of hardware to be used in the cloud.},
  doi       = {10.1145/2381913.2381915},
  isbn      = {9781450316651},
  keywords  = {traffic analysis, covert channel, cloud security},
  location  = {Raleigh, North Carolina, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2381913.2381915},
}

@Article{Bai2015,
  author     = {Bai, Aijun and Wu, Feng and Chen, Xiaoping},
  journal    = {ACM Trans. Intell. Syst. Technol.},
  title      = {Online Planning for Large Markov Decision Processes with Hierarchical Decomposition},
  year       = {2015},
  issn       = {2157-6904},
  month      = jul,
  number     = {4},
  volume     = {6},
  abstract   = {Markov decision processes (MDPs) provide a rich framework for planning under uncertainty.
However, exactly solving a large MDP is usually intractable due to the “curse of dimensionality”—
the state space grows exponentially with the number of state variables. Online algorithms
tackle this problem by avoiding computing a policy for the entire state space. On
the other hand, since online algorithm has to find a near-optimal action online in
almost real time, the computation time is often very limited. In the context of reinforcement
learning, MAXQ is a value function decomposition method that exploits the underlying
structure of the original MDP and decomposes it into a combination of smaller subproblems
arranged over a task hierarchy. In this article, we present MAXQ-OP—a novel online
planning algorithm for large MDPs that utilizes MAXQ hierarchical decomposition in
online settings. Compared to traditional online planning algorithms, MAXQ-OP is able
to reach much more deeper states in the search tree with relatively less computation
time by exploiting MAXQ hierarchical decomposition online. We empirically evaluate
our algorithm in the standard Taxi domain—a common benchmark for MDPs—to show the
effectiveness of our approach. We have also conducted a long-term case study in a
highly complex simulated soccer domain and developed a team named WrightEagle that
has won five world champions and five runners-up in the recent 10 years of RoboCup
Soccer Simulation 2D annual competitions. The results in the RoboCup domain confirm
the scalability of MAXQ-OP to very large domains.},
  address    = {New York, NY, USA},
  articleno  = {45},
  doi        = {10.1145/2717316},
  issue_date = {August 2015},
  keywords   = {MDP, RoboCup, online planning, MAXQ-OP},
  numpages   = {28},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2717316},
}

@InProceedings{Werthmann2013,
  author    = {Werthmann, Tim and Hund, Ralf and Davi, Lucas and Sadeghi, Ahmad-Reza and Holz, Thorsten},
  booktitle = {Proceedings of the 8th ACM SIGSAC Symposium on Information, Computer and Communications Security},
  title     = {PSiOS: Bring Your Own Privacy &amp; Security to IOS Devices},
  year      = {2013},
  address   = {New York, NY, USA},
  pages     = {13–24},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '13},
  abstract  = {Apple iOS is one of the most popular mobile operating systems. As its core security
technology, iOS provides application sandboxing but assigns a generic sandboxing profile
to every third-party application. However, recent attacks and incidents with benign
applications demonstrate that this design decision is vulnerable to crucial privacy
and security breaches, allowing applications (either benign or malicious) to access
contacts, photos, and device IDs. Moreover, the dynamic character of iOS apps written
in Objective-C renders the currently proposed static analysis tools less useful.In
this paper, we aim to address the open problem of preventing (not only detecting)
privacy leaks and simultaneously strengthening security against runtime attacks on
iOS. Compared to similar research work on the open Android, realizing such a system
for the closed-source iOS is highly involved.We present the design and implementation
of PSiOS, a tool that features a novel policy enforcement framework for iOS. It provides
fine-grained, application-specific, and user/administrator defined sandboxing for
each third-party application without requiring access to the application source code.
Our reference implementation deploys control-flow integrity based on the recently
proposed MoCFI (Mobile CFI) framework that only protects applications against runtime
attacks. We evaluated several popular iOS applications (e.g., Facebook, WhatsApp)
to demonstrate the efficiency and effectiveness of PSiOS.},
  doi       = {10.1145/2484313.2484316},
  isbn      = {9781450317672},
  keywords  = {application sandboxing, ios, software security},
  location  = {Hangzhou, China},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2484313.2484316},
}

@InProceedings{Yu2015,
  author    = {Yu, Miao and Gligor, Virgil D. and Zhou, Zongwei},
  booktitle = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security},
  title     = {Trusted Display on Untrusted Commodity Platforms},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {989–1003},
  publisher = {Association for Computing Machinery},
  series    = {CCS '15},
  abstract  = {A trusted display service assures the confidentiality and authenticity of content
output by a security-sensitive application and thus prevents a compromised commodity
operating system or application from surreptitiously reading or modifying the displayed
output. Past approaches have failed to provide trusted display on commodity platforms
that use modern graphics processing units (GPUs). For example, full GPU virtualization
encourages the sharing of GPU address space with multiple virtual machines {em without}
providing adequate hardware protection mechanisms; e.g., address-space separation
and instruction execution control. This paper proposes a new trusted display service
that has a minimal trusted code base and maintains full compatibility with commodity
computing platforms. The service relies on a GPU separation kernel that (1) defines
different types of GPU objects, (2) mediates access to security-sensitive objects,
and (3) emulates object whenever required by commodity-platform compatibility. The
separation kernel employs a new address-space separation mechanism that avoids the
challenging problem of GPU instruction verification without adequate hardware support.
The implementation of the trusted-display service has a code base that is two orders
of magnitude smaller than other similar services, such as those based on full GPU
virtualization. Performance measurements show that the trusted-display overhead added
over and above that of the underlying trusted system is fairly modest.},
  doi       = {10.1145/2810103.2813719},
  isbn      = {9781450338325},
  keywords  = {GPU separation kernel, trusted display},
  location  = {Denver, Colorado, USA},
  numpages  = {15},
  url       = {https://doi.org/10.1145/2810103.2813719},
}

@InProceedings{Li2012b,
  author    = {Li, Ninghui and Qardaji, Wahbeh and Su, Dong},
  booktitle = {Proceedings of the 7th ACM Symposium on Information, Computer and Communications Security},
  title     = {On Sampling, Anonymization, and Differential Privacy or, <i>k</i>-Anonymization Meets Differential Privacy},
  year      = {2012},
  address   = {New York, NY, USA},
  pages     = {32–33},
  publisher = {Association for Computing Machinery},
  series    = {ASIACCS '12},
  abstract  = {This paper aims at answering the following two questions in privacy-preserving data
analysis and publishing. The first is: What formal privacy guarantee (if any) does
k-anonymization methods provide? k-Anonymization methods have been studied extensively
in the database community, but have been known to lack strong privacy guarantees.
The second question is: How can we benefit from the adversary's uncertainty about
the data? More specifically, can we come up a meaningful relaxation of differential
privacy [2, 3] by exploiting the adversary's uncertainty about the dataset? We now
discuss these two motivations in more detail.},
  doi       = {10.1145/2414456.2414474},
  isbn      = {9781450316484},
  location  = {Seoul, Korea},
  numpages  = {2},
  url       = {https://doi.org/10.1145/2414456.2414474},
}

@InProceedings{Piskozub2019,
  author    = {Piskozub, Michal and Spolaor, Riccardo and Conti, Mauro and Martinovic, Ivan},
  booktitle = {Proceedings of the 6th ACM Workshop on Moving Target Defense},
  title     = {On the Resilience of Network-Based Moving Target Defense Techniques Against Host Profiling Attacks},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {1–12},
  publisher = {Association for Computing Machinery},
  series    = {MTD'19},
  abstract  = {Researchers propose Moving Target Defense (MTD) strategies for networking infrastructures
as a countermeasure to impede attackers from identifying and exploiting vulnerable
network hosts. In this paper, we investigate the weaknesses of Network-based Moving
Target Defense (NMTD) against passive host profiling attacks. In particular, we consider
periodical and reactive approaches to change hosts' identifiers. To evaluate the capabilities
of a host profiling attack, we design Hostbuster, a tool that reidentifies hosts based
on network flow data. We experimentally evaluate its effectiveness using real-world
network traffic from the University of Oxford. We show the robustness of learned host
profiles, which are valid for more than two months. On average, our experiments result
in 80% classification performance given by the F1 score. As a result of these analyses,
we provide guidelines to strengthen NMTD against these types of attacks.},
  doi       = {10.1145/3338468.3356825},
  isbn      = {9781450368285},
  keywords  = {moving target defense, one-vs-rest random forest, host profiling, network flow data processing},
  location  = {London, United Kingdom},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3338468.3356825},
}

@InProceedings{Sung2020,
  author    = {Sung, Keen and Huang, JianYi and Corner, Mark D. and Levine, Brian N.},
  booktitle = {Proceedings of the 26th Annual International Conference on Mobile Computing and Networking},
  title     = {Re-Identification of Mobile Devices Using Real-Time Bidding Advertising Networks},
  year      = {2020},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {MobiCom '20},
  abstract  = {Advertisers gather data about users and their mobile devices through ads placed within
Android and iOS apps. Most of the time, location, device, and app information are
linked to the same device using a unique advertising ID (Ad ID). If the Ad ID is not
available, advertisers can still use geo-coordinates or IP address to infer links
in data gathered from different ad placements.Even though the Ad ID can be disabled
by users on both OSes, we demonstrate that advertisers can leave their own unique
strings (marks) in the app storage, and use these strings to link information collected
from ads. Users cannot clear these marks without losing all data within the app. Because
advertising platforms allow connection filtering and geofencing, users who either
connect using a non-cellular IP address or allow location access to the app are substantially
easier to be rediscovered by the advertiser.We carried out many large-scale experiments
on iOS and Android devices involving hundreds of thousands of impressions. We found
that on average 49% of impressions from an iOS device, and 59% of Android impressions
could be re-identified for less than $5/day per device using this strategy. We subsequently
verified this method on 1,727 devices and recovered 660 of them within 48 hours for
$86.73. Finally, we explore the behavior of privacy-seeking VPN users. We found that
for the majority, their clearnet IP address and location could be unmasked easily
using ads.},
  articleno = {48},
  doi       = {10.1145/3372224.3419205},
  isbn      = {9781450370851},
  keywords  = {VPN, cellular, privacy, mobile advertising, security},
  location  = {London, United Kingdom},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3372224.3419205},
}

@InProceedings{Lee2021,
  author    = {Lee, Joonhee and Lee, Hyunwoo and Jeong, Jongheon and Kim, Doowon and Kwon, Ted Taekyoung},
  booktitle = {Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security},
  title     = {Analyzing Spatial Differences in the TLS Security of Delegated Web Services},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {475–487},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '21},
  abstract  = {To provide secure content delivery, Transport Layer Security (TLS) has become a de
facto standard over a couple of decades. However, TLS has a long history of security
weaknesses and drawbacks. Thus, the security of TLS has been enhanced by addressing
security problems through continuous version upgrades. Meanwhile, to provide fast
content delivery globally, websites (or origin web servers) need to deploy and administer
many machines in globally distributed environments. They often delegate the management
of machines to web hosting services or content delivery networks (CDNs), where the
security configurations of distributed servers may vary spatially depending on the
managing entities or locations. Based on these spatial differences in TLS security,
we find that the security level of TLS connections (and their web services) can be
lowered. After collecting the information of (web) domains that exhibit different
TLS versions and cryptographic options depending on clients' locations, we show that
it is possible to redirect TLS handshake messages to weak TLS servers, which both
the origin server and the client may not be aware of. We investigate 7M domains with
these spatial differences of security levels in the wild and conduct the analyses
to better understand the root causes of this phenomenon. We also measure redirection
delays at various locations in the world to see whether there are noticeable delays
in redirections.},
  doi       = {10.1145/3433210.3453107},
  isbn      = {9781450382878},
  keywords  = {downgrade attack, domain name delegation, TLS deployment},
  location  = {Virtual Event, Hong Kong},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3433210.3453107},
}

@Article{Dotan2021,
  author     = {Dotan, Maya and Pignolet, Yvonne-Anne and Schmid, Stefan and Tochner, Saar and Zohar, Aviv},
  journal    = {ACM Comput. Surv.},
  title      = {Survey on Blockchain Networking: Context, State-of-the-Art, Challenges},
  year       = {2021},
  issn       = {0360-0300},
  month      = may,
  number     = {5},
  volume     = {54},
  abstract   = {Blockchains, in general, and cryptocurrencies such as Bitcoin, in particular, are
realized using distributed systems and hence critically rely on the performance and
security of the interconnecting network. The requirements on these networks and their
usage, however, can differ significantly from traditional communication networks,
with implications on all layers of the protocol stack. This article is motivated by
these differences and, in particular, by the observation that many fundamental design
aspects of these networks are not well-understood today. To support the networking
community to contribute to this emerging application domain, we present a structured
overview of the field, from topology and neighbor discovery, over block and transaction
propagation, to sharding and off-chain networks, also reviewing existing empirical
results from different measurement studies. In particular, for each of these domains,
we provide the context, highlighting differences and commonalities with traditional
networks, review the state-of-the-art, and identify open research challenges. Our
article can hence also be seen as a call-to-arms to improve the foundation on top
of which blockchains are built.},
  address    = {New York, NY, USA},
  articleno  = {107},
  doi        = {10.1145/3453161},
  issue_date = {June 2021},
  keywords   = {payment networks, distributed computing, Blockchains},
  numpages   = {34},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3453161},
}

@Article{Li2021,
  author     = {Li, Chaohao and Ji, Xiaoyu and Wang, Bin and Wang, Kai and Xu, Wenyuan},
  journal    = {ACM Trans. Sen. Netw.},
  title      = {SenCS: Enabling Real-Time Indoor Proximity Verification via Contextual Similarity},
  year       = {2021},
  issn       = {1550-4859},
  month      = may,
  number     = {2},
  volume     = {17},
  abstract   = {Indoor proximity verification has become an increasingly useful primitive for the
scenarios where access is granted to the previously unknown users when they enter
a given area (e.g., a hotel room). Existing solutions either rely on homogeneous sensing
modalities shared by two parties or require additional human interactions. In this
article, we propose a context-based indoor proximity verification scheme, called SenCS,
to enable real-time autonomous access for mobile devices, utilizing the available
heterogeneous sensors at the user side and at the room side. The intuition is that
only when the user is within a room can sensors from both sides observe the same events
in the room. Yet such a solution is challenging, because the events may not provide
enough entropy within the required time and the heterogeneity in sensing modalities
may not always agree on the sensed events. To overcome the challenges, we exploit
the time intervals between successively human actions to create heterogeneous contextual
fingerprints (HCF) at a millisecond level. By comparing the contextual similarity
between the HCF s from both the room and user sides, SenCS accomplishes the indoor
proximity verification. Through proof-of-concept implementation and evaluations on
30 participants, SenCS achieves an accuracy of 99.77% and an equal error rate (EER)
of 0.23% across various hardware configurations.},
  address    = {New York, NY, USA},
  articleno  = {19},
  doi        = {10.1145/3449071},
  issue_date = {June 2021},
  keywords   = {real-time, Indoor proximity verification, contextual similarity, heterogeneous sensor},
  numpages   = {22},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3449071},
}

@InProceedings{Avoine2017,
  author    = {Avoine, Gildas and Bultel, Xavier and Gambs, S\'{e}bastien and G\'{e}rault, David and Lafourcade, Pascal and Onete, Cristina and Robert, Jean-Marc},
  booktitle = {Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security},
  title     = {A Terrorist-Fraud Resistant and Extractor-Free Anonymous Distance-Bounding Protocol},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {800–814},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '17},
  abstract  = {Distance-bounding protocols have been introduced to thwart relay attacks against contactless
authentication protocols. In this context, verifiers have to authenticate the credentials
of untrusted provers. Unfortunately, these protocols are themselves subject to complex
threats such as terrorist-fraud attacks, in which a malicious prover helps an accomplice
to authenticate. Provably guaranteeing the resistance of distance-bounding protocols
to these attacks is complex. The classical solutions assume that rational provers
want to protect their long-term authentication credentials, even with respect to their
accomplices. Thus, terrorist-fraud resistant protocols generally rely on artificial
extraction mechanisms, ensuring that an accomplice can retrieve the credential of
his partnering prover, if he is able to authenticate. We propose a novel approach
to obtain provable terrorist-fraud resistant protocols that does not rely on an accomplice
being able to extract any long-term key. Instead, we simply assume that he can replay
the information received from the prover. Thus, rational provers should refuse to
cooperate with third parties if they can impersonate them freely afterwards. We introduce
a generic construction for provably secure distance-bounding protocols, and give three
instances of this construction: (1) an efficient symmetric-key protocol, (2) a public-key
protocol protecting the identities of provers against external eavesdroppers, and
finally (3) a fully anonymous protocol protecting the identities of provers even against
malicious verifiers that try to profile them.},
  doi       = {10.1145/3052973.3053000},
  isbn      = {9781450349444},
  keywords  = {efficient protocol, proven secure protocol, anonymous protocol, distance bounding},
  location  = {Abu Dhabi, United Arab Emirates},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3052973.3053000},
}

@InProceedings{Ghiette2018,
  author    = {Ghi\"{e}tte, Vincent and Doerr, Christian},
  booktitle = {Proceedings of the 2018 Workshop on Traffic Measurements for Cybersecurity},
  title     = {How Media Reports Trigger Copycats: An Analysis of the Brewing of the Largest Packet Storm to Date},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {8–13},
  publisher = {Association for Computing Machinery},
  series    = {WTMC '18},
  abstract  = {In late February 2018, news spread through the mainstream media about a massive distributed
denial-of-service attack on the popular software collaboration website github.com.
Estimated at a rate of 1.3 Terrabit per second, this massive packet flood was the
largest DDoS attack by volume to date, surpassing previous records set by the first
IoT-based DDoS attacks in 2017.In this paper, we analyze the behavior of the actors
scanning and probing the Internet for presence of exploitable memcached servers that
were the root cause of this attack, both before and after the media coverage. We find
that the attacks of late February were preceeded by a large scale reconnaissance action
a month before, and that the attacks were the result of an extended evolution of methods
to find a suitable attack strategy. Furthermore, we see that the coverage about the
massive DDoS attack actually triggered another wave of DDoS attacks, resulting in
the large influx of new, previously unseen users who seem to be leveraging ready-made
tools.},
  doi       = {10.1145/3229598.3229606},
  isbn      = {9781450359108},
  keywords  = {threat intelligence, memcached, denial-of-service attacks},
  location  = {Budapest, Hungary},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3229598.3229606},
}

@InProceedings{Kim2017a,
  author    = {Kim, Taegyu and Kim, Chung Hwan and Choi, Hongjun and Kwon, Yonghwi and Saltaformaggio, Brendan and Zhang, Xiangyu and Xu, Dongyan},
  booktitle = {Proceedings of the 33rd Annual Computer Security Applications Conference},
  title     = {RevARM: A Platform-Agnostic ARM Binary Rewriter for Security Applications},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {412–424},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC 2017},
  abstract  = {ARM is the leading processor architecture in the emerging mobile and embedded market.
Unfortunately, there has been a myriad of security issues on both mobile and embedded
systems. While many countermeasures of such security issues have been proposed in
recent years, a majority of applications still cannot be patched or protected due
to run-time and space overhead constraints and the unavailability of source code.
More importantly, the rapidly evolving mobile and embedded market makes any platform-specific
solution ineffective. In this paper, we propose RevARM, a binary rewriting technique
capable of instrumenting ARM-based binaries without limitation on the target platform.
Unlike many previous binary instrumentation tools that are designed to instrument
binaries based on x86, RevARM must resolve a number of new, ARM-specific binary rewriting
challenges. Moreover, RevARM is able to handle stripped binaries, requires no symbolic/semantic
information, and supports Mach-O binaries, overcoming the limitations of existing
approaches. Finally, we demonstrate the capabilities of RevARM in solving real-world
security challenges. Our evaluation results across a variety of platforms, including
popular mobile and embedded systems, show that RevARM is highly effective in instrumenting
ARM binaries with an average of 3.2% run-time and 1.3% space overhead.},
  doi       = {10.1145/3134600.3134627},
  isbn      = {9781450353458},
  location  = {Orlando, FL, USA},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3134600.3134627},
}

@InProceedings{Szurdi2017,
  author    = {Szurdi, Janos and Christin, Nicolas},
  booktitle = {Proceedings of the 2017 Internet Measurement Conference},
  title     = {Email Typosquatting},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {419–431},
  publisher = {Association for Computing Machinery},
  series    = {IMC '17},
  abstract  = {While website domain typosquatting is highly annoying for legitimate domain operators,
research has found that it relatively rarely presents a great risk to individual users.
However, any application (e.g., email, ftp,...) relying on the domain name system
for name resolution is equally vulnerable to domain typosquatting, and consequences
may be more dire than with website typosquatting.This paper presents the first in-depth
measurement study of email typosquatting. Working in concert with our IRB, we registered
76 typosquatting domain names to study a wide variety of user mistakes, while minimizing
the amount of personal information exposed to us. In the span of over seven months,
we received millions of emails at our registered domains. While most of these emails
are spam, we infer, from our measurements, that every year, three of our domains should
receive approximately 3,585 "legitimate" emails meant for somebody else. Worse, we
find, by examining a small sample of all emails, that these emails may contain sensitive
information (e.g., visa documents or medical records).We then project from our measurements
that 1,211 typosquatting domains registered by unknown entities receive in the vicinity
of 800,000 emails a year. Furthermore, we find that millions of registered typosquatting
domains have MX records pointing to only a handful of mail servers. However, a second
experiment in which we send "honey emails" to typosquatting domains only shows very
limited evidence of attempts at credential theft (despite some emails being read),
meaning that the threat, for now, appears to remain theoretical.},
  doi       = {10.1145/3131365.3131399},
  isbn      = {9781450351188},
  keywords  = {typosquatting, abuse, measurement, ethics, domain name},
  location  = {London, United Kingdom},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3131365.3131399},
}

@InProceedings{Liu2017,
  author    = {Liu, Daiping and Li, Zhou and Du, Kun and Wang, Haining and Liu, Baojun and Duan, Haixin},
  booktitle = {Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {Don't Let One Rotten Apple Spoil the Whole Barrel: Towards Automated Detection of Shadowed Domains},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {537–552},
  publisher = {Association for Computing Machinery},
  series    = {CCS '17},
  abstract  = {Domain names have been exploited for illicit online activities for decades. In the
past, miscreants mostly registered new domains for their attacks. However, the domains
registered for malicious purposes can be deterred by existing reputation and blacklisting
systems. In response to the arms race, miscreants have recently adopted a new strategy,
called domain shadowing, to build their attack infrastructures. Specifically, instead
of registering new domains, miscreants are beginning to compromise legitimate ones
and spawn malicious subdomains under them. This has rendered almost all existing countermeasures
ineffective and fragile because subdomains inherit the trust of their apex domains,
and attackers can virtually spawn an infinite number of shadowed domains.In this paper,
we conduct the first study to understand and detect this emerging threat. Bootstrapped
with a set of manually confirmed shadowed domains, we identify a set of novel features
that uniquely characterize domain shadowing by analyzing the deviation from their
apex domains and the correlation among different apex domains. Building upon these
features, we train a classifier and apply it to detect shadowed domains on the daily
feeds of VirusTotal, a large open security scanning service. Our study highlights
domain shadowing as an increasingly rampant threat. Moreover, while previously confirmed
domain shadowing campaigns are exclusively involved in exploit kits, we reveal that
they are also widely exploited for phishing attacks. Finally, we observe that instead
of algorithmically generating subdomain names, several domain shadowing cases exploit
the wildcard DNS records.},
  doi       = {10.1145/3133956.3134049},
  isbn      = {9781450349468},
  keywords  = {domain hijacking, domain shadowing, dns},
  location  = {Dallas, Texas, USA},
  numpages  = {16},
  url       = {https://doi.org/10.1145/3133956.3134049},
}

@InProceedings{Zhang2015,
  author    = {Zhang, Tianwei and Lee, Ruby B.},
  booktitle = {Proceedings of the 42nd Annual International Symposium on Computer Architecture},
  title     = {CloudMonatt: An Architecture for Security Health Monitoring and Attestation of Virtual Machines in Cloud Computing},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {362–374},
  publisher = {Association for Computing Machinery},
  series    = {ISCA '15},
  abstract  = {Cloud customers need guarantees regarding the security of their virtual machines (VMs),
operating within an Infrastructure as a Service (IaaS) cloud system. This is complicated
by the customer not knowing where his VM is executing, and on the semantic gap between
what the customer wants to know versus what can be measured in the cloud. We present
an architecture for monitoring a VM's security health, with the ability to attest
this to the customer in an unforgeable manner. We show a concrete implementation of
property-based attestation and a full prototype based on the OpenStack open source
cloud software.},
  doi       = {10.1145/2749469.2750422},
  isbn      = {9781450334020},
  location  = {Portland, Oregon},
  numpages  = {13},
  url       = {https://doi.org/10.1145/2749469.2750422},
}

@Article{Zhang2015a,
  author     = {Zhang, Tianwei and Lee, Ruby B.},
  journal    = {SIGARCH Comput. Archit. News},
  title      = {CloudMonatt: An Architecture for Security Health Monitoring and Attestation of Virtual Machines in Cloud Computing},
  year       = {2015},
  issn       = {0163-5964},
  month      = jun,
  number     = {3S},
  pages      = {362–374},
  volume     = {43},
  abstract   = {Cloud customers need guarantees regarding the security of their virtual machines (VMs),
operating within an Infrastructure as a Service (IaaS) cloud system. This is complicated
by the customer not knowing where his VM is executing, and on the semantic gap between
what the customer wants to know versus what can be measured in the cloud. We present
an architecture for monitoring a VM's security health, with the ability to attest
this to the customer in an unforgeable manner. We show a concrete implementation of
property-based attestation and a full prototype based on the OpenStack open source
cloud software.},
  address    = {New York, NY, USA},
  doi        = {10.1145/2872887.2750422},
  issue_date = {June 2015},
  numpages   = {13},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2872887.2750422},
}

@InProceedings{Pashchenko2020,
  author    = {Pashchenko, Ivan and Vu, Duc-Ly and Massacci, Fabio},
  booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {A Qualitative Study of Dependency Management and Its Security Implications},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {1513–1531},
  publisher = {Association for Computing Machinery},
  series    = {CCS '20},
  abstract  = {Several large scale studies on the Maven, NPM, and Android ecosystems point out that
many developers do not often update their vulnerable software libraries thus exposing
the user of their code to security risks. The purpose of this study is to qualitatively
investigate the choices and the interplay of functional and security concerns on the
developers' overall decision-making strategies for selecting, managing, and updating
software dependencies.We run 25 semi-structured interviews with developers of both
large and small-medium enterprises located in nine countries. All interviews were
transcribed, coded, and analyzed according to applied thematic analysis. They highlight
the trade-offs that developers are facing and that security researchers must understand
to provide effective support to mitigate vulnerabilities (for example bundling security
fixes with functional changes might hinder adoption due to lack of resources to fix
functional breaking changes).We further distill our observations to actionable implications
on what algorithms and automated tools should achieve to effectively support (semi-)automatic
dependency management.},
  doi       = {10.1145/3372297.3417232},
  isbn      = {9781450370899},
  keywords  = {security, vulnerable dependencies, dependency management, qualitative study, interviews},
  location  = {Virtual Event, USA},
  numpages  = {19},
  url       = {https://doi.org/10.1145/3372297.3417232},
}

@InProceedings{Hypolite2020,
  author    = {Hypolite, Joel and Sonchack, John and Hershkop, Shlomo and Dautenhahn, Nathan and DeHon, Andr\'{e} and Smith, Jonathan M.},
  booktitle = {Proceedings of the 16th International Conference on Emerging Networking EXperiments and Technologies},
  title     = {DeepMatch: Practical Deep Packet Inspection in the Data Plane Using Network Processors},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {336–350},
  publisher = {Association for Computing Machinery},
  series    = {CoNEXT '20},
  abstract  = {Restricting data plane processing to packet headers precludes analysis of payloads
to improve routing and security decisions. DeepMatch delivers line-rate regular expression
matching on payloads using Network Processors (NPs). It further supports packet reordering
to match patterns in flows that cross packet boundaries. Our evaluation shows that
an implementation of DeepMatch, on a 40 Gbps Netronome NFP-6000 SmartNIC, achieves
up to line rate for streams of unrelated packets and up to 20 Gbps when searches span
multiple packets within a flow. In contrast with prior work, this throughput is data-independent
and adds no burstiness. DeepMatch opens new opportunities for programmable data planes.},
  doi       = {10.1145/3386367.3431290},
  isbn      = {9781450379489},
  keywords  = {P4, programmable data planes, SmartNIC, network processors},
  location  = {Barcelona, Spain},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3386367.3431290},
}

@Article{Zou2018,
  author     = {Zou, Yongpan and Zhao, Meng and Zhou, Zimu and Lin, Jiawei and Li, Mo and Wu, Kaishun},
  journal    = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
  title      = {BiLock: User Authentication via Dental Occlusion Biometrics},
  year       = {2018},
  month      = sep,
  number     = {3},
  volume     = {2},
  abstract   = {User authentication on smart devices is indispensable to keep data privacy and security.
It is especially significant for emerging wearable devices such as smartwatches considering
data sensitivity in them. However, conventional authentication methods are not applicable
for wearables due to constraints of size and hardware, which makes present wearable
devices lack convenient, secure and low-cost authentication schemes. To tackle this
problem, we reveal a novel biometric authentication mechanism which makes use of sounds
of human dental occlusion (i.e., tooth click). We demonstrate its feasibility by comprehensive
measurement study, and design a prototype-BiLock with two Android platforms. Extensive
real-world experiments have been conducted to evaluate the accuracy, robustness and
security of BiLock in different environments. The results show that BiLock can achieve
less than 5% average false reject rate and 0.95% average false accept rate even in
a noisy environment. Comparative experiments also demonstrate that BiLock possesses
advantages in robustness to noise and security against replay and observation attacks
over existing voiceprinting schemes.},
  address    = {New York, NY, USA},
  articleno  = {152},
  doi        = {10.1145/3264962},
  issue_date = {September 2018},
  keywords   = {Mobile devices, Dental occlusion, Biometric authentication},
  numpages   = {20},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3264962},
}

@InProceedings{Xia2019,
  author    = {Xia, Zenghua and Liu, Chang and Gong, Neil Zhenqiang and Li, Qi and Cui, Yong and Song, Dawn},
  booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
  title     = {Characterizing and Detecting Malicious Accounts in Privacy-Centric Mobile Social Networks: A Case Study},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {2012–2022},
  publisher = {Association for Computing Machinery},
  series    = {KDD '19},
  abstract  = {Malicious accounts are one of the biggest threats to the security and privacy of online
social networks (OSNs). In this work, we study a new type of OSN, called privacy-centric
mobile social network (PC-MSN), such as KakaoTalk and LINE, which has attracted billions
of users recently. The design of PC-MSN is inspired to protect their users' privacy
from strangers: (1) a stranger is not easy to send a friend request to a user who
does not want to make friends with strangers; and (2) strangers cannot view a user's
post. Such a design mitigates the security issue of malicious accounts. At the same
time, it also brings the battleground between attackers and defenders to an earlier
stage, i.e., making friendship, than the one studied in previous works. Also, previous
defense proposals mostly rely on certain assumptions on the attacker, which may not
be robust in the new PC-MSNs. As a result, previous malicious accounts detection approaches
are less effective on a PC-MSN.To mitigate this issue, we study the patterns in friend
requests to distinguish malicious accounts, and perform a systematic study over 1
million labeled data from WLink, a real PC-MSN with billions of users, to confirm
our hypothesis. Based on the results, we propose dozens of new features and leverage
machine learning to detect malicious accounts. We evaluate our method and compare
it with existing methods, and the results show that our method achieves a precision
of 99.5% and a recall of 98.4%, which significantly outperform previous state-of-the-art
methods. Importantly, we qualitatively analyze the robustness of the designed features,
and our evaluation shows that using only robust features can achieve the same level
of performance as using all features. WLink has deployed our detection method. Our
method can detect 0.59 million malicious accounts daily, which is 6 times higher than
the previous deployment on WLink, with a precision of over 90%.},
  doi       = {10.1145/3292500.3330702},
  isbn      = {9781450362016},
  keywords  = {malicious accounts detection, neural networks, online social networks, friend request},
  location  = {Anchorage, AK, USA},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3292500.3330702},
}

@InProceedings{Borgaonkar2011,
  author    = {Borgaonkar, Ravishankar and Redon, Kevin and Seifert, Jean-Pierre},
  booktitle = {Proceedings of the 4th International Conference on Security of Information and Networks},
  title     = {Security Analysis of a Femtocell Device},
  year      = {2011},
  address   = {New York, NY, USA},
  pages     = {95–102},
  publisher = {Association for Computing Machinery},
  series    = {SIN '11},
  abstract  = {Mobile network operators are adapting femtocells in order to simplify their network
architecture for increased coverage, performance, and greater revenue opportunities.
While emerging as a new low-cost technology which assures best connectivity, it has
also introduced a range of new potential security risks for the mobile network operators.
In this paper, we analyze these security issues and demonstrate the weaknesses of
femtocell security. We demonstrate several security flaws that allowing attackers
to gain root access and to install malicious applications on the femtocell. Furthermore,
we experimentally evaluate and show a wide range of possible threats to femtocell;
including compromise of femtocell credentials; physical, configuration, and protocol
attacks; user data and identity privacy attacks. The vulnerabilities we found suggest
that commercial-available femtocells fail to fulfill 3GPP security requirements and
could expose operator network elements to the attacker. Our findings and successful
attacks exhibit the need for further research to bridge the gap between theoretical
and practical security of femtocell devices.},
  doi       = {10.1145/2070425.2070442},
  isbn      = {9781450310208},
  keywords  = {hnb, 3g, home base station, 3gpp, femtocell},
  location  = {Sydney, Australia},
  numpages  = {8},
  url       = {https://doi.org/10.1145/2070425.2070442},
}

@InProceedings{Gulmezoglu2017,
  author    = {Gulmezoglu, Berk and Eisenbarth, Thomas and Sunar, Berk},
  booktitle = {Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security},
  title     = {Cache-Based Application Detection in the Cloud Using Machine Learning},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {288–300},
  publisher = {Association for Computing Machinery},
  series    = {ASIA CCS '17},
  abstract  = {Cross-VM attacks have emerged as a major threat on commercial clouds. These attacks
commonly exploit hardware level leakages on shared physical servers. A co-located
machine can readily feel the presence of a co-located instance with a heavy computational
load through performance degradation due to contention on shared resources. Shared
cache architectures such as the last level cache (LLC) have become a popular leakage
source to mount cross-VM attack. By exploiting LLC leakages, researchers have already
shown that it is possible to recover fine grain information such as cryptographic
keys from popular software libraries. This makes it essential to verify implementations
that handle sensitive data across the many versions and numerous target platforms,
a task too complicated, error prone and costly to be handled by human beings. Here
we propose a machine learning based technique to classify applications according to
their cache access profiles. We show that with minimal and simple manual processing
steps feature vectors can be used to train models using support vector machines to
classify the applications with a high degree of success. The profiling and training
steps are completely automated and do not require any inspection or study of the code
to be classified. In native execution, we achieve a successful classification rate
as high as 98% (L1 cache) and 78% (LLC) over 40 benchmark applications in the Phoronix
suite with mild training. In the cross-VM setting on the noisy Amazon EC2 the success
rate drops to 60% for a suite of 25 applications. With this initial study we demonstrate
that it is possible to train meaningful models to successfully predict applications
running in co-located instances.},
  doi       = {10.1145/3052973.3053036},
  isbn      = {9781450349444},
  keywords  = {prime&amp;probe, machine learning, SVM, cross-vm attacks},
  location  = {Abu Dhabi, United Arab Emirates},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3052973.3053036},
}

@InProceedings{Rula2020,
  author    = {Rula, John P. and Richter, Philipp and Smaragdakis, Georgios and Berger, Arthur},
  booktitle = {Proceedings of the ACM Internet Measurement Conference},
  title     = {Who's Left behind? Measuring Adoption of Application Updates at Scale},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {710–723},
  publisher = {Association for Computing Machinery},
  series    = {IMC '20},
  abstract  = {This work presents a large-scale, longitudinal measurement study on the adoption of
application updates, enabling continuous reporting of potentially vulnerable software
populations worldwide. Studying the factors impacting software currentness, we investigate
and discuss the impact of the platform and its updating strategies on software currentness,
device lock-in effects, as well as user behavior. Utilizing HTTP User-Agent strings
from end-hosts, we introduce techniques to extract application and operating system
information from myriad structures, infer version release dates of applications, and
measure population adoption, at a global scale. To deal with loosely structured User-Agent
data, we develop a semi-supervised method that can reliably extract application and
version information for some 87% of requests served by a major CDN every day. Using
this methodology, we track release and adoption dynamics of some 35,000 applications.
Analyzing over three years of CDN logs, we show that vendors' update strategies and
platforms have a significant effect on the adoption of application updates. Our results
show that, on some platforms, up to 25% of requests originate from hosts running application
versions that are out-of-date by more than 100 days, and 16% more than 300 days. We
find pronounced differences across geographical regions, and overall, less developed
regions are more likely to have out-of-date software versions. Though, for every country,
we find that at least 10% of requests reaching the CDN run software that is out-of-date
by more than three months.},
  doi       = {10.1145/3419394.3423656},
  isbn      = {9781450381383},
  location  = {Virtual Event, USA},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3419394.3423656},
}

@InProceedings{McCreadie2018,
  author    = {McCreadie, Richard and Macdonald, Craig and Ounis, Iadh},
  booktitle = {The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval},
  title     = {Automatic Ground Truth Expansion for Timeline Evaluation},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {685–694},
  publisher = {Association for Computing Machinery},
  series    = {SIGIR '18},
  abstract  = {The development of automatic systems that can produce timeline summaries by filtering
high-volume streams of text documents, retaining only those that are relevant to a
particular information need (e.g. topic or event), remains a very challenging task.
To advance the field of automatic timeline generation, robust and reproducible evaluation
methodologies are needed. To this end, several evaluation metrics and labeling methodologies
have recently been developed - focusing on information nugget or cluster-based ground
truth representations, respectively. These methodologies rely on human assessors manually
mapping timeline items (e.g. tweets) to an explicit representation of what information
a 'good' summary should contain. However, while these evaluation methodologies produce
reusable ground truth labels, prior works have reported cases where such labels fail
to accurately estimate the performance of new timeline generation systems due to label
incompleteness. In this paper, we first quantify the extent to which timeline summary
ground truth labels fail to generalize to new summarization systems, then we propose
and evaluate new automatic solutions to this issue. In particular, using a depooling
methodology over 21 systems and across three high-volume datasets, we quantify the
degree of system ranking error caused by excluding those systems when labeling. We
show that when considering lower-effectiveness systems, the test collections are robust
(the likelihood of systems being miss-ranked is low). However, we show that the risk
of systems being miss-ranked increases as the effectiveness of systems held-out from
the pool increases. To reduce the risk of miss-ranking systems, we also propose two
different automatic ground truth label expansion techniques. Our results show that
our proposed expansion techniques can be effective for increasing the robustness of
the TREC-TS test collections, markedly reducing the number of miss-rankings by up
to 50% on average among the scenarios tested.},
  doi       = {10.1145/3209978.3210034},
  isbn      = {9781450356572},
  keywords  = {labelling, pooling, temporal summarization, timeline generation, trec, ground truth},
  location  = {Ann Arbor, MI, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3209978.3210034},
}

@Article{Adrian2018,
  author     = {Adrian, David and Bhargavan, Karthikeyan and Durumeric, Zakir and Gaudry, Pierrick and Green, Matthew and Halderman, J. Alex and Heninger, Nadia and Springall, Drew and Thom\'{e}, Emmanuel and Valenta, Luke and VanderSloot, Benjamin and Wustrow, Eric and Zanella-B\'{e}guelin, Santiago and Zimmermann, Paul},
  journal    = {Commun. ACM},
  title      = {Imperfect Forward Secrecy: How Diffie-Hellman Fails in Practice},
  year       = {2018},
  issn       = {0001-0782},
  month      = dec,
  number     = {1},
  pages      = {106–114},
  volume     = {62},
  abstract   = {We investigate the security of Diffie-Hellman key exchange as used in popular Internet
protocols and find it to be less secure than widely believed. First, we present Logjam,
a novel flaw in TLS that lets a man-in-the-middle downgrade connections to "export-grade"
Diffie-Hellman. To carry out this attack, we implement the number field sieve discrete
logarithm algorithm. After a week-long precomputation for a specified 512-bit group,
we can compute arbitrary discrete logarithms in that group in about a minute. We find
that 82% of vulnerable servers use a single 512-bit group, and that 8.4% of Alexa
Top Million HTTPS sites are vulnerable to the attack. In response, major browsers
have changed to reject short groups.We go on to consider Diffie-Hellman with 768-
and 1024-bit groups. We estimate that even in the 1024-bit case, the computations
are plausible given nation-state resources. A small number of fixed or standardized
groups are used by millions of servers; performing precomputation for a single 1024-bit
group would allow passive eavesdropping on 18% of popular HTTPS sites, and a second
group would allow decryption of traffic to 66% of IPsec VPNs and 26% of SSH servers.
A close reading of published NSA leaks shows that the agency's attacks on VPNs are
consistent with having achieved such a break. We conclude that moving to stronger
key exchange methods should be a priority for the Internet community.},
  address    = {New York, NY, USA},
  doi        = {10.1145/3292035},
  issue_date = {January 2019},
  numpages   = {9},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3292035},
}

@Article{Chen2013,
  author     = {Chen, Jiawen and Bautembach, Dennis and Izadi, Shahram},
  journal    = {ACM Trans. Graph.},
  title      = {Scalable Real-Time Volumetric Surface Reconstruction},
  year       = {2013},
  issn       = {0730-0301},
  month      = jul,
  number     = {4},
  volume     = {32},
  abstract   = {We address the fundamental challenge of scalability for real-time volumetric surface
reconstruction methods. We design a memory efficient, hierarchical data structure
for commodity graphics hardware, which supports live reconstruction of large-scale
scenes with fine geometric details. Our sparse data structure fuses overlapping depth
maps from a moving depth camera into a single volumetric representation, from which
detailed surface models are extracted. Our hierarchy losslessly streams data bidirectionally
between GPU and host, allowing for unbounded reconstructions. Our pipeline, comprised
of depth map post-processing, camera pose estimation, volumetric fusion, surface extraction,
and streaming, runs entirely in real-time. We experimentally demonstrate that a shallow
hierarchy with relatively large branching factors yields the best memory/speed tradeoff,
consuming an order of magnitude less memory than a regular grid. We compare an implementation
of our data structure to existing methods and demonstrate higher-quality reconstructions
on a variety of large-scale scenes, all captured in real-time.},
  address    = {New York, NY, USA},
  articleno  = {113},
  doi        = {10.1145/2461912.2461940},
  issue_date = {July 2013},
  keywords   = {scalability, kinect, streaming, real-time, hierarchical grid, GPU, volumetric surface reconstruction},
  numpages   = {16},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2461912.2461940},
}

@InProceedings{Ernst2014,
  author    = {Ernst, Michael D. and Just, Ren\'{e} and Millstein, Suzanne and Dietl, Werner and Pernsteiner, Stuart and Roesner, Franziska and Koscher, Karl and Barros, Paulo Barros and Bhoraskar, Ravi and Han, Seungyeop and Vines, Paul and Wu, Edward X.},
  booktitle = {Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {Collaborative Verification of Information Flow for a High-Assurance App Store},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {1092–1104},
  publisher = {Association for Computing Machinery},
  series    = {CCS '14},
  abstract  = {Current app stores distribute some malware to unsuspecting users, even though the
app approval process may be costly and time-consuming. High-integrity app stores must
provide stronger guarantees that their apps are not malicious. We propose a verification
model for use in such app stores to guarantee that the apps are free of malicious
information flows. In our model, the software vendor and the app store auditor collaborate
-- each does tasks that are easy for her/him, reducing overall verification cost.
The software vendor provides a behavioral specification of information flow (at a
finer granularity than used by current app stores) and source code annotated with
information-flow type qualifiers. A flow-sensitive, context-sensitive information-flow
type system checks the information flow type qualifiers in the source code and proves
that only information flows in the specification can occur at run time. The app store
auditor uses the vendor-provided source code to manually verify declassifications.We
have implemented the information-flow type system for Android apps written in Java,
and we evaluated both its effectiveness at detecting information-flow violations and
its usability in practice. In an adversarial Red Team evaluation, we analyzed 72 apps
(576,000 LOC) for malware. The 57 Trojans among these had been written specifically
to defeat a malware analysis such as ours. Nonetheless, our information-flow type
system was effective: it detected 96% of malware whose malicious behavior was related
to information flow and 82% of all malware. In addition to the adversarial evaluation,
we evaluated the practicality of using the collaborative model. The programmer annotation
burden is low: 6 annotations per 100 LOC. Every sound analysis requires a human to
review potential false alarms, and in our experiments, this took 30 minutes per 1,000
LOC for an auditor unfamiliar with the app.},
  doi       = {10.1145/2660267.2660343},
  isbn      = {9781450329576},
  keywords  = {static analysis, information flow, android security, collaborative verification},
  location  = {Scottsdale, Arizona, USA},
  numpages  = {13},
  url       = {https://doi.org/10.1145/2660267.2660343},
}

@InProceedings{Bock2020,
  author    = {Bock, Kevin and Hughey, George and Merino, Louis-Henri and Arya, Tania and Liscinsky, Daniel and Pogosian, Regina and Levin, Dave},
  booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
  title     = {Come as You Are: Helping Unmodified Clients Bypass Censorship with Server-Side Evasion},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {586–598},
  publisher = {Association for Computing Machinery},
  series    = {SIGCOMM '20},
  abstract  = {Decades of work on censorship evasion have resulted in myriad ways to empower clients
with the ability to access censored content, but to our knowledge all of them have
required some degree of client-side participation. Having to download and run anti-censorship
software can put users at risk, and does not help the many users who do not even realize
they are being censored in the first place.In this paper, we present the first purely
server-side censorship evasion strategies---11 in total. We extend a recent tool,
Geneva, to automate the discovery and implementation of server-side strategies, and
we apply it to four countries (China, India, Iran, and Kazakhstan) and five protocols
(DNS-over-TCP, FTP, HTTP, HTTPS, and SMTP). We also perform follow-on experiments
to understand why the strategies Geneva finds work, and to glean new insights into
how censors operate. Among these, we find that China runs a completely separate network
stack (each with its own unique bugs) for each application-layer protocol that it
censors.The server-side techniques we find are easier and safer to deploy than client-side
strategies. Our code and data are publicly available.},
  doi       = {10.1145/3387514.3405889},
  isbn      = {9781450379557},
  keywords  = {Server-side, Censorship, Geneva},
  location  = {Virtual Event, USA},
  numpages  = {13},
  url       = {https://doi.org/10.1145/3387514.3405889},
}

@InProceedings{Petsios2017,
  author    = {Petsios, Theofilos and Zhao, Jason and Keromytis, Angelos D. and Jana, Suman},
  booktitle = {Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {SlowFuzz: Automated Domain-Independent Detection of Algorithmic Complexity Vulnerabilities},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {2155–2168},
  publisher = {Association for Computing Machinery},
  series    = {CCS '17},
  abstract  = {Algorithmic complexity vulnerabilities occur when the worst-case time/space complexity
of an application is significantly higher than the respective average case for particular
user-controlled inputs. When such conditions are met, an attacker can launch Denial-of-Service
attacks against a vulnerable application by providing inputs that trigger the worst-case
behavior. Such attacks have been known to have serious effects on production systems,
take down entire websites, or lead to bypasses of Web Application Firewalls.Unfortunately,
existing detection mechanisms for algorithmic complexity vulnerabilities are domain-specific
and often require significant manual effort. In this paper, we design, implement,
and evaluate SlowFuzz, a domain-independent framework for automatically finding algorithmic
complexity vulnerabilities. SlowFuzz automatically finds inputs that trigger worst-case
algorithmic behavior in the tested binary. SlowFuzz uses resource-usage-guided evolutionary
search techniques to automatically find inputs that maximize computational resource
utilization for a given application.We demonstrate that SlowFuzz successfully generates
inputs that match the theoretical worst-case performance for several well-known algorithms.
SlowFuzz was also able to generate a large number of inputs that trigger different
algorithmic complexity vulnerabilities in real-world applications, including various
zip parsers used in antivirus software, regular expression libraries used in Web Application
Firewalls, as well as hash table implementations used in Web applications. In particular,
SlowFuzz generated inputs that achieve 300-times slowdown in the decompression routine
of the bzip utility, discovered regular expressions that exhibit matching times exponential
in the input size, and also managed to automatically produce inputs that trigger a
high number of collisions in PHP's default hashtable implementation.},
  doi       = {10.1145/3133956.3134073},
  isbn      = {9781450349468},
  keywords  = {algorithmic complexity attacks, fuzzing, dos attacks, resource exhaustion attacks},
  location  = {Dallas, Texas, USA},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3133956.3134073},
}

@InProceedings{Punal2012,
  author    = {Pu\~{n}al, Oscar and Aguiar, Ana and Gross, James},
  booktitle = {Proceedings of the Ninth ACM International Workshop on Vehicular Inter-Networking, Systems, and Applications},
  title     = {In VANETs We Trust? Characterizing RF Jamming in Vehicular Networks},
  year      = {2012},
  address   = {New York, NY, USA},
  pages     = {83–92},
  publisher = {Association for Computing Machinery},
  series    = {VANET '12},
  abstract  = {In this paper we study the impact of RF jamming on 802.11p car-to-car communications.
We build a jammer on a software defined radio and implement constant, reactive and
pilot jamming patterns, whose effectiveness is first measured in an anechoic chamber.
We perform extensive experiments in two relevant outdoor scenarios, namely a straight
road in an open space as well as a dense building scenario with a crossroad and characterize
the performance of 802.11p communications under the impact of constant and reactive
RF jamming. The constant jammer is able to dramatically disrupt communication regardless
of the scenario. The reactive jammer exhibits a low impact in scenarios with reduced
line-of-sight as its jamming success greatly depends on the relative position of the
nodes. It is, however, very effective in open-space scenarios. In general, we observe
that RF jamming can cause large communication-blind areas. Under these conditions,
critical safety applications would simply fail in their purpose of timely warning
dissemination.},
  doi       = {10.1145/2307888.2307903},
  isbn      = {9781450313179},
  keywords  = {security, vehicular networks, rf jamming},
  location  = {Low Wood Bay, Lake District, UK},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2307888.2307903},
}

@InProceedings{Kaechele2015,
  author    = {K\"{a}chele, Markus and Thiam, Patrick and Palm, G\"{u}nther and Schwenker, Friedhelm and Schels, Martin},
  booktitle = {Proceedings of the 5th International Workshop on Audio/Visual Emotion Challenge},
  title     = {Ensemble Methods for Continuous Affect Recognition: Multi-Modality, Temporality, and Challenges},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {9–16},
  publisher = {Association for Computing Machinery},
  series    = {AVEC '15},
  abstract  = {In this paper we present a multi-modal system based on audio, video and bio-physiological
features for continuous recognition of human affect in unconstrained scenarios. We
leverage the robustness of ensemble classifiers as base learners and refine the predictions
using stochastic gradient descent based optimization on the desired loss function.
Furthermore we provide a discussion about pre- and post-processing steps that help
to improve the robustness of the regression and subsequently the prediction quality.},
  doi       = {10.1145/2808196.2811637},
  isbn      = {9781450337434},
  keywords  = {affect recognition, AVEC 2015, multi-modal fusion},
  location  = {Brisbane, Australia},
  numpages  = {8},
  url       = {https://doi.org/10.1145/2808196.2811637},
}

@InProceedings{Le2020,
  author    = {Le, Quoc Cuong and Hidane, Moncef},
  booktitle = {Proceedings of the 35th Annual ACM Symposium on Applied Computing},
  title     = {Appearance Features for Online Multiple Camera Multiple Target Tracking},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {2089–2096},
  publisher = {Association for Computing Machinery},
  series    = {SAC '20},
  abstract  = {Multiple object tracking methods in the state-of-the-art are challenged by appearance
variation, environment changes and long-term occlusions. Exploiting multiple calibrated
and frame synchronized cameras holds the promise of alleviating these problems, in
particular, the one pertaining to occlusion. The practical realization of this idea
faces the problem that the appearance of the same target can change through different
cameras. Thus, particular care should be taken in order to enhance the computation
of appearance distances between targets in multiple cameras. In this paper, we tackle
the problem of multiple object multiple camera tracking by adopting a Markov Decision
Process framework. We concentrate on the effect of the affinity function by discussing
different possible implementations and validating their performance, in terms of the
MOT metric and the ID measure, on the PETS 2009 and EPFL datasets. Our experimental
result shows a significant improvement of multiple cameras approaches with a sufficiently
large overlapping zone compared to single camera ones.},
  doi       = {10.1145/3341105.3373960},
  isbn      = {9781450368667},
  keywords  = {multiple object tracking (MOT), multiple target multiple camera tracking (MTMCT), appearance feature extraction, data association, tracking-by-detection},
  location  = {Brno, Czech Republic},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3341105.3373960},
}

@InProceedings{Wang2019a,
  author    = {Wang, Yaojing and Yao, Yuan and Tong, Hanghang and Xu, Feng and Lu, Jian},
  booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
  title     = {Discerning Edge Influence for Network Embedding},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {429–438},
  publisher = {Association for Computing Machinery},
  series    = {CIKM '19},
  abstract  = {Network embedding, which learns the low-dimensional representations of nodes, has
gained significant research attention. Despite its superior empirical success, often
measured by the prediction performance of downstream tasks (e.g., multi-label classification),
it is unclear em why a given embedding algorithm outputs the specific node representations,
and em how the resulting node representations relate to the structure of the input
network. In this paper, we propose to discern the edge influence as the first step
towards understanding skip-gram basd network embedding methods. For this purpose,
we propose an auditing framework Near, whose key part includes two algorithms (Near-add
 and Near-del ) to effectively and efficiently quantify the influence of each edge.
Based on the algorithms, we further identify high-influential edges by exploiting
the linkage between edge influence and the network structure. Experimental results
demonstrate that the proposed algorithms (Near-add  and Near-del ) are significantly
faster (up to $2,000times$) than straightforward methods with little quality loss.
Moreover, the proposed framework can efficiently identify the most influential edges
for network embedding in the context of downstream prediction task and adversarial
attacking.},
  doi       = {10.1145/3357384.3358044},
  isbn      = {9781450369763},
  keywords  = {network embedding, edge influence, network topological properties},
  location  = {Beijing, China},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3357384.3358044},
}

@InBook{Lyu2017,
  author    = {Lyu, Lingjuan and He, Xuanli and Law, Yee Wei and Palaniswami, Marimuthu},
  pages     = {1219–1228},
  publisher = {Association for Computing Machinery},
  title     = {Privacy-Preserving Collaborative Deep Learning with Application to Human Activity Recognition},
  year      = {2017},
  address   = {New York, NY, USA},
  isbn      = {9781450349185},
  abstract  = {The proliferation of wearable devices has contributed to the emergence of mobile crowdsensing,
which leverages the power of the crowd to collect and report data to a third party
for large-scale sensing and collaborative learning. However, since the third party
may not be honest, privacy poses a major concern. In this paper, we address this concern
with a two-stage privacy-preserving scheme called RG-RP: the first stage is designed
to mitigate maximum a posteriori (MAP) estimation attacks by perturbing each participant's
data through a nonlinear function called repeated Gompertz (RG); while the second
stage aims to maintain accuracy and reduce transmission energy by projecting high-dimensional
data to a lower dimension, using a row-orthogonal random projection (RP) matrix. The
proposed RG-RP scheme delivers better recovery resistance to MAP estimation attacks
than most state-of-the-art techniques on both synthetic and real-world datasets. For
collaborative learning, we proposed a novel LSTM-CNN model combining the merits of
Long Short-Term Memory (LSTM) and Convolutional Neural Networks (CNN). Our experiments
on two representative movement datasets captured by wearable sensors demonstrate that
the proposed LSTM-CNN model outperforms standalone LSTM, CNN and Deep Belief Network.
Together, RG+RP and LSTM-CNN provide a privacy-preserving collaborative learning framework
that is both accurate and privacy-preserving.},
  booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3132847.3132990},
}

@InProceedings{Oh2020,
  author    = {Oh, Hyunyoung and Ahmad, Adil and Park, Seonghyun and Lee, Byoungyoung and Paek, Yunheung},
  booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {TRUSTORE: Side-Channel Resistant Storage for SGX Using Intel Hybrid CPU-FPGA},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {1903–1918},
  publisher = {Association for Computing Machinery},
  series    = {CCS '20},
  abstract  = {Intel SGX is a security solution promising strong and practical security guarantees
for trusted computing. However, recent reports demonstrated that such security guarantees
of SGX are broken due to access pattern based side-channel attacks, including page
fault, cache, branch prediction, and speculative execution. In order to stop these
side-channel attackers, Oblivious RAM (ORAM) has gained strong attention from the
security community as it provides cryptographically proven protection against access
pattern based side-channels. While several proposed systems have successfully applied
ORAM to thwart side-channels, those are severely limited in performance and its scalability
due to notorious performance issues of ORAM. This paper presents TrustOre, addressing
these issues that arise when using ORAM with Intel SGX. TrustOre leverages an external
device, FPGA, to implement a trusted storage service within a completed isolated environment
secure from side-channel attacks. TrustOre tackles several challenges in achieving
such a goal: extending trust from SGX to FPGA without imposing architectural changes,
providing a verifiably-secure connection between SGX applications and FPGA, and seamlessly
supporting various access operations from SGX applications to FPGA.We implemented
TrustOre on the commodity Intel Hybrid CPU-FPGA architecture. Then we evaluated with
three state-of-the-art ORAM-based SGX applications, ZeroTrace, Obliviate, and Obfuscuro,
as well as an end-to-end key-value store application. According to our evaluation,
TrustOre-based applications outperforms ORAM-based original applications ranging from
10x to 43x, while also showing far better scalability than ORAM-based ones. We emphasize
that since TrustOre can be deployed as a simple plug-in to SGX machine's PCIe slot,
it is readily used to thwart side-channel attacks in SGX, arguably one of the most
cryptic and critical security holes today.},
  doi       = {10.1145/3372297.3417265},
  isbn      = {9781450370899},
  keywords  = {Intel SGX, access pattern based side-channel, secure storage, hybrid CPU-FPGA},
  location  = {Virtual Event, USA},
  numpages  = {16},
  url       = {https://doi.org/10.1145/3372297.3417265},
}

@InProceedings{Alt2014,
  author    = {Alt, Lance and Beverly, Robert and Dainotti, Alberto},
  booktitle = {Proceedings of the 30th Annual Computer Security Applications Conference},
  title     = {Uncovering Network Tarpits with Degreaser},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {156–165},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '14},
  abstract  = {Network tarpits, whereby a single host or appliance can masquerade as many fake hosts
on a network and slow network scanners, are a form of defensive cyber-deception. In
this work, we develop degreaser, an efficient fingerprinting tool to remotely detect
tarpits. In addition to validating our tool in a controlled environment, we use degreaser
to perform an Internet-wide scan. We discover tarpits of non-trivial size in the wild
(prefixes as large as/16), and characterize their distribution and behavior. We then
show how tarpits pollute existing network measurement surveys that are tarpit-na\"{\i}ve,
e.g. Internet census data, and how degreaser can improve the accuracy of such surveys.
Lastly, our findings suggest several ways in which to advance the realism of current
network tarpits, thereby raising the bar on tarpits as an operational security mechanism.},
  doi       = {10.1145/2664243.2664285},
  isbn      = {9781450330053},
  keywords  = {sticky honeypot, deception, tarpits, internet census},
  location  = {New Orleans, Louisiana, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2664243.2664285},
}

@InProceedings{Nikiforakis2012,
  author    = {Nikiforakis, Nick and Invernizzi, Luca and Kapravelos, Alexandros and Van Acker, Steven and Joosen, Wouter and Kruegel, Christopher and Piessens, Frank and Vigna, Giovanni},
  booktitle = {Proceedings of the 2012 ACM Conference on Computer and Communications Security},
  title     = {You Are What You Include: Large-Scale Evaluation of Remote Javascript Inclusions},
  year      = {2012},
  address   = {New York, NY, USA},
  pages     = {736–747},
  publisher = {Association for Computing Machinery},
  series    = {CCS '12},
  abstract  = {JavaScript is used by web developers to enhance the interactivity of their sites,
offload work to the users' browsers and improve their sites' responsiveness and user-friendliness,
making web pages feel and behave like traditional desktop applications. An important
feature of JavaScript, is the ability to combine multiple libraries from local and
remote sources into the same page, under the same namespace. While this enables the
creation of more advanced web applications, it also allows for a malicious JavaScript
provider to steal data from other scripts and from the page itself. Today, when developers
include remote JavaScript libraries, they trust that the remote providers will not
abuse the power bestowed upon them.In this paper, we report on a large-scale crawl
of more than three million pages of the top 10,000 Alexa sites, and identify the trust
relationships of these sites with their library providers. We show the evolution of
JavaScript inclusions over time and develop a set of metrics in order to assess the
maintenance-quality of each JavaScript provider, showing that in some cases, top Internet
sites trust remote providers that could be successfully compromised by determined
attackers and subsequently serve malicious JavaScript. In this process, we identify
four, previously unknown, types of vulnerabilities that attackers could use to attack
popular web sites. Lastly, we review some proposed ways of protecting a web application
from malicious remote scripts and show that some of them may not be as effective as
previously thought.},
  doi       = {10.1145/2382196.2382274},
  isbn      = {9781450316514},
  keywords  = {javascript, trust, remote inclusions},
  location  = {Raleigh, North Carolina, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2382196.2382274},
}

@InProceedings{Xue2020,
  author    = {Xue, Tao and Wen, Yu and Luo, Bo and Zhang, Boyang and Zheng, Yang and Hu, Yanfei and Li, Yingjiu and Li, Gang and Meng, Dan},
  booktitle = {Annual Computer Security Applications Conference},
  title     = {GuardSpark++: Fine-Grained Purpose-Aware Access Control for Secure Data Sharing and Analysis in Spark},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {582–596},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '20},
  abstract  = {With the development of computing and communication technologies, extremely large
amount of data has been collected, stored, utilized, and shared, while new security
and privacy challenges arise. Existing platforms do not provide flexible and practical
access control mechanisms for big data analytics applications. In this paper, we present
GuardSpark++, a fine-grained access control mechanism for secure data sharing and
analysis in Spark. In particular, we first propose a purpose-aware access control
(PAAC) model, which introduces new concepts of data processing/operation purposes
to conventional purpose-based access control. An automatic purpose analysis algorithm
is developed to identify purposes from data analytics operations and queries, so that
access control could be enforced accordingly. Moreover, we develop an access control
mechanism in Spark Catalyst, which provides unified PAAC enforcement for heterogeneous
data sources and upper-layer applications. We evaluate GuardSpark++ with five data
sources and four structured data analytics engines in Spark. The experimental results
show that GuardSpark++ provides effective access control functionalities with a very
small performance overhead (average 3.97%).},
  doi       = {10.1145/3427228.3427640},
  isbn      = {9781450388580},
  keywords  = {Spark, access control, purpose, data sharing, data protection, big data},
  location  = {Austin, USA},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3427228.3427640},
}

@InProceedings{Andriesse2015,
  author    = {Andriesse, Dennis and Rossow, Christian and Bos, Herbert},
  booktitle = {Proceedings of the 2015 Internet Measurement Conference},
  title     = {Reliable Recon in Adversarial Peer-to-Peer Botnets},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {129–140},
  publisher = {Association for Computing Machinery},
  series    = {IMC '15},
  abstract  = {The decentralized nature of Peer-to-Peer (P2P) botnets precludes traditional takedown
strategies, which target dedicated command infrastructure. P2P botnets replace this
infrastructure with command channels distributed across the full infected population.
Thus, mitigation strongly relies on accurate reconnaissance techniques which map the
botnet population. While prior work has studied passive disturbances to reconnaissance
accuracy ---such as IP churn and NAT gateways---, the same is not true of active anti-reconnaissance
attacks. This work shows that active attacks against crawlers and sensors occur frequently
in major P2P botnets. Moreover, we show that current crawlers and sensors in the Sality
and Zeus botnets produce easily detectable anomalies, making them prone to such attacks.
Based on our findings, we categorize and evaluate vectors for stealthier and more
reliable P2P botnet reconnaissance.},
  doi       = {10.1145/2815675.2815682},
  isbn      = {9781450338486},
  keywords  = {reconnaissance, crawling, peer-to-peer botnet},
  location  = {Tokyo, Japan},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2815675.2815682},
}

@InProceedings{Heinl2021,
  author    = {Heinl, Michael P. and G\"{o}lz, Simon and B\"{o}sch, Christoph},
  booktitle = {DG.O2021: The 22nd Annual International Conference on Digital Government Research},
  title     = {A Comparative Security Analysis of the German Federal Postal Voting Process},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {198–207},
  publisher = {Association for Computing Machinery},
  series    = {DG.O'21},
  abstract  = {The percentage of votes cast by postal voting increases with every election for the
German federal parliament (Bundestag). However, especially compared to Internet voting,
concerns regarding security, transparency, and trustworthiness of postal voting are
rarely discussed. This paper outlines the established process of postal voting in
Germany and evaluates it with regard to various security-relevant characteristics.
For this evaluation, a methodology originally developed for Internet voting is used
in order to ensure comparability. The aim is to identify weaknesses as well as potential
for optimization, to compare German postal voting with selected Internet voting schemes,
and to derive implications for policy and further research.},
  doi       = {10.1145/3463677.3463679},
  isbn      = {9781450384926},
  keywords  = {Internet Voting, Security, Remote Voting, Postal Voting},
  location  = {Omaha, NE, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3463677.3463679},
}

@InProceedings{Merrill2017,
  author    = {Merrill, Nick and Curran, Max T. and Chuang, John},
  booktitle = {Proceedings of the 2017 New Security Paradigms Workshop},
  title     = {Is the Future of Authenticity All In Our Heads? Moving Passthoughts From the Lab to the World},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {70–79},
  publisher = {Association for Computing Machinery},
  series    = {NSPW 2017},
  abstract  = {Passthoughts, in which a user thinks a secret thought to log in to services or devices,
provides two factors of authentication (knowledge and inherence) in a single step.
Since its proposal in 2005, passthoughts enjoyed a number of successful empirical
studies. In this paper, we renew the promise of passthoughts authentication, outlining
the main challenges that passthoughts must overcome in order to move from the lab
to the real world. We propose two studies, which seek different angles at the fundamental
questions we pose. Further, we propose it as a fruitful case study for thinking about
what authentication can, and should, be expected to do, as it pushes up against questions
of what sorts of "selves" authentication systems must be tasked with recognizing.
Through this discussion, we raise novel possibilities for authentication broadly,
such as "organic passwords" that change naturally over time, or systems that reject
users who are not acting quite "like themselves."},
  doi       = {10.1145/3171533.3171537},
  isbn      = {9781450363846},
  keywords  = {passthoughts, authentication, usable security},
  location  = {Santa Cruz, CA, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3171533.3171537},
}

@Article{Chatzakou2019,
  author     = {Chatzakou, Despoina and Leontiadis, Ilias and Blackburn, Jeremy and Cristofaro, Emiliano De and Stringhini, Gianluca and Vakali, Athena and Kourtellis, Nicolas},
  journal    = {ACM Trans. Web},
  title      = {Detecting Cyberbullying and Cyberaggression in Social Media},
  year       = {2019},
  issn       = {1559-1131},
  month      = oct,
  number     = {3},
  volume     = {13},
  abstract   = {Cyberbullying and cyberaggression are increasingly worrisome phenomena affecting people
across all demographics. More than half of young social media users worldwide have
been exposed to such prolonged and/or coordinated digital harassment. Victims can
experience a wide range of emotions, with negative consequences such as embarrassment,
depression, isolation from other community members, which embed the risk to lead to
even more critical consequences, such as suicide attempts.In this work, we take the
first concrete steps to understand the characteristics of abusive behavior in Twitter,
one of today’s largest social media platforms. We analyze 1.2 million users and 2.1
million tweets, comparing users participating in discussions around seemingly normal
topics like the NBA, to those more likely to be hate-related, such as the Gamergate
controversy, or the gender pay inequality at the BBC station. We also explore specific
manifestations of abusive behavior, i.e., cyberbullying and cyberaggression, in one
of the hate-related communities (Gamergate). We present a robust methodology to distinguish
bullies and aggressors from normal Twitter users by considering text, user, and network-based
attributes. Using various state-of-the-art machine-learning algorithms, we classify
these accounts with over 90% accuracy and AUC. Finally, we discuss the current status
of Twitter user accounts marked as abusive by our methodology and study the performance
of potential mechanisms that can be used by Twitter to suspend users in the future.},
  address    = {New York, NY, USA},
  articleno  = {17},
  doi        = {10.1145/3343484},
  issue_date = {November 2019},
  keywords   = {twitter, aggression, bullying, Online social networks (OSNs)},
  numpages   = {51},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3343484},
}

@InProceedings{Victor2021,
  author    = {Victor, Friedhelm and Weintraud, Andrea Marie},
  booktitle = {Proceedings of the Web Conference 2021},
  title     = {Detecting and Quantifying Wash Trading on Decentralized Cryptocurrency Exchanges},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {23–32},
  publisher = {Association for Computing Machinery},
  series    = {WWW '21},
  abstract  = {Cryptoassets such as cryptocurrencies and tokens are increasingly traded on decentralized
exchanges. The advantage for users is that the funds are not in custody of a centralized
external entity. However, these exchanges are prone to manipulative behavior. In this
paper, we illustrate how wash trading activity can be identified on two of the first
popular limit order book-based decentralized exchanges on the Ethereum blockchain,
IDEX and EtherDelta. We identify a lower bound of accounts and trading structures
that meet the legal definitions of wash trading, discovering that they are responsible
for a wash trading volume in equivalent of 159 million U.S. Dollars. While self-trades
and two-account structures are predominant, complex forms also occur. We quantify
these activities, finding that on both exchanges, more than 30% of all traded tokens
have been subject to wash trading activity. On EtherDelta, 10% of the tokens have
almost exclusively been wash traded. All data is made available for future research.
Our findings underpin the need for countermeasures that are applicable in decentralized
systems.},
  doi       = {10.1145/3442381.3449824},
  isbn      = {9781450383127},
  keywords  = {crime, measurement, blockchain, self-trades, wash trading},
  location  = {Ljubljana, Slovenia},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3442381.3449824},
}

@InBook{Zixin2020,
  author    = {Zixin, Qin and Han, Wang and Shengjin, Wang},
  pages     = {110–115},
  publisher = {Association for Computing Machinery},
  title     = {SPF-Net: Semantic Parsed Feature for Pedestrian Attribute Recognition},
  year      = {2020},
  address   = {New York, NY, USA},
  isbn      = {9781450389075},
  booktitle = {2020 The 4th International Conference on Video and Image Processing},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3447450.3447468},
}

@Article{Elmandouh2018,
  author     = {Elmandouh, Eman M. and Wassal, Amr G.},
  journal    = {ACM Trans. Des. Autom. Electron. Syst.},
  title      = {Guiding Formal Verification Orchestration Using Machine Learning Methods},
  year       = {2018},
  issn       = {1084-4309},
  month      = aug,
  number     = {5},
  volume     = {23},
  abstract   = {Typical modern HW designs include many blocks associated with thousands of design
properties. Having today's commercial formal verifiers utilize a complementary set
of state-of-art formal algorithms is a key in enabling the formal verification tools
to successfully cope with verification problems of different sizes, types, and complexities.
Formal engines orchestration is the methodology used to pick the most appropriate
formal engine for a specific verification problem. It assures proper scheduling of
the formal engines to minimize the time consumed to solve individual design verification
problems, hence highly impacts the time required to verify the overall design properties.
This work proposes the utilization of supervised machine learning classification techniques
to guide the orchestration step by predicting the formal engines that should be assigned
to a design property. Up to 16,500 formal verification runs on RTL designs and their
properties are used to train the classifier to create a prediction model. The classifier
assigns any new verification problem to an appropriate list of formal engines associated
with a probability distribution over the set of engines classes. Our results indicate
how the proposed model is able to improve the formal suite total run-time by up to
59% of its maximum allowable time improvement using multi-classification-based orchestration
and to nominate with 88% accuracy the appropriate formal engines for new-to-verify
HW designs.},
  address    = {New York, NY, USA},
  articleno  = {62},
  doi        = {10.1145/3224206},
  issue_date = {October 2018},
  keywords   = {classification ML, Formal verification, algorithm selection},
  numpages   = {33},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3224206},
}

@Article{Ebke2014,
  author     = {Ebke, Hans-Christian and Campen, Marcel and Bommes, David and Kobbelt, Leif},
  journal    = {ACM Trans. Graph.},
  title      = {Level-of-Detail Quad Meshing},
  year       = {2014},
  issn       = {0730-0301},
  month      = nov,
  number     = {6},
  volume     = {33},
  abstract   = {The most effective and popular tools for obtaining feature aligned quad meshes from
triangular input meshes are based on cross field guided parametrization. These methods
are incarnations of a conceptual three-step pipeline: (1) cross field computation,
(2) field-guided surface parametrization, (3) quad mesh extraction. While in most
meshing scenarios the user prescribes a desired target quad size or edge length, this
information is typically taken into account from step 2 onwards only, but not in the
cross field computation step. This turns into a problem in the presence of small scale
geometric or topological features or noise in the input mesh: closely placed singularities
are induced in the cross field, which are not properly reproducible by vertices in
a quad mesh with the prescribed edge length, causing severe distortions or even failure
of the meshing algorithm. We reformulate the construction of cross fields as well
as field-guided parametrizations in a scale-aware manner which effectively suppresses
densely spaced features and noise of geometric as well as topological kind. Dominant
large-scale features are adequately preserved in the output by relying on the unaltered
input mesh as the computational domain.},
  address    = {New York, NY, USA},
  articleno  = {184},
  doi        = {10.1145/2661229.2661240},
  issue_date = {November 2014},
  keywords   = {quad meshing, guiding fields},
  numpages   = {11},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2661229.2661240},
}

@Article{Rojas2021,
  author     = {Rojas, Camilo and Poulsen, Niels and Van Tuyl, Mileva and Vargas, Daniel and Cohen, Zipporah and Paradiso, Joe and Maes, Pattie and Esvelt, Kevin and Adib, Fadel},
  journal    = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
  title      = {A Scalable Solution for Signaling Face Touches to Reduce the Spread of Surface-Based Pathogens},
  year       = {2021},
  month      = mar,
  number     = {1},
  volume     = {5},
  abstract   = {Hand-to-Face transmission has been estimated to be a minority, yet non-negligible,
vector of COVID-19 transmission and a major vector for multiple other pathogens. At
the same time, as it cannot be effectively addressed with mainstream protection measures,
such as wearing masks or tracing contacts, it remains largely untackled. To help address
this issue, we have developed Saving Face - an app that alerts users when they are
about to touch their faces, by analyzing the distortion patterns in the ultrasound
signal emitted by their earphones. The system only relies on pre-existing hardware
(a smartphone with generic earphones), which allows it to be rapidly scalable to billions
of smartphone users worldwide. This paper describes the design, implementation and
evaluation of the system, as well as the results of a user study testing the solution's
accuracy, robustness, and user experience during various day-to-day activities (93.7%
Sensitivity and 91.5% Precision, N=10). While this paper focuses on the system's application
to detecting hand-to-face gestures, the technique can also be applicable to other
types of gestures and gesture-based applications.},
  address    = {New York, NY, USA},
  articleno  = {31},
  doi        = {10.1145/3448121},
  issue_date = {March 2021},
  keywords   = {behavior change, machine learning, mobile devices, signal processing, wearables},
  numpages   = {22},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3448121},
}

@Article{Zhang2016,
  author     = {Zhang, Yihua and Blanton, Marina},
  journal    = {ACM Trans. Storage},
  title      = {Efficient Dynamic Provable Possession of Remote Data via Update Trees},
  year       = {2016},
  issn       = {1553-3077},
  month      = feb,
  number     = {2},
  volume     = {12},
  abstract   = {The emergence and wide availability of remote storage service providers prompted work
in the security community that allows clients to verify integrity and availability
of the data that they outsourced to a not fully trusted remote storage server at a
relatively low cost. Most recent solutions to this problem allow clients to read and
update (i.e., insert, modify, or delete) stored data blocks while trying to lower
the overhead associated with verifying the integrity of the stored data. In this work,
we develop a novel scheme, performance of which favorably compares with the existing
solutions. Our solution additionally enjoys a number of new features, such as a natural
support for operations on ranges of blocks, revision control, and support for multiple
user access to shared content. The performance guarantees that we achieve stem from
a novel data structure called a balanced update tree and removing the need for interaction
during update operations in addition to communicating the updates themselves.},
  address    = {New York, NY, USA},
  articleno  = {9},
  doi        = {10.1145/2747877},
  issue_date = {February 2016},
  keywords   = {outsourced storage, Provable data possession, integrity verification, balanced tree},
  numpages   = {45},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2747877},
}

@InProceedings{Adrian2015,
  author    = {Adrian, David and Bhargavan, Karthikeyan and Durumeric, Zakir and Gaudry, Pierrick and Green, Matthew and Halderman, J. Alex and Heninger, Nadia and Springall, Drew and Thom\'{e}, Emmanuel and Valenta, Luke and VanderSloot, Benjamin and Wustrow, Eric and Zanella-B\'{e}guelin, Santiago and Zimmermann, Paul},
  booktitle = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security},
  title     = {Imperfect Forward Secrecy: How Diffie-Hellman Fails in Practice},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {5–17},
  publisher = {Association for Computing Machinery},
  series    = {CCS '15},
  abstract  = {We investigate the security of Diffie-Hellman key exchange as used in popular Internet
protocols and find it to be less secure than widely believed. First, we present Logjam,
a novel flaw in TLS that lets a man-in-the-middle downgrade connections to "export-grade"
Diffie-Hellman. To carry out this attack, we implement the number field sieve discrete
log algorithm. After a week-long precomputation for a specified 512-bit group, we
can compute arbitrary discrete logs in that group in about a minute. We find that
82% of vulnerable servers use a single 512-bit group, allowing us to compromise connections
to 7% of Alexa Top Million HTTPS sites. In response, major browsers are being changed
to reject short groups. We go on to consider Diffie-Hellman with 768- and 1024-bit
groups. We estimate that even in the 1024-bit case, the computations are plausible
given nation-state resources. A small number of fixed or standardized groups are used
by millions of servers; performing precomputation for a single 1024-bit group would
allow passive eavesdropping on 18% of popular HTTPS sites, and a second group would
allow decryption of traffic to 66% of IPsec VPNs and 26% of SSH servers. A close reading
of published NSA leaks shows that the agency's attacks on VPNs are consistent with
having achieved such a break. We conclude that moving to stronger key exchange methods
should be a priority for the Internet community.},
  doi       = {10.1145/2810103.2813707},
  isbn      = {9781450338325},
  keywords  = {logjam, internet measurement, number field sieve, Diffie-Hellman, vulnerabilities},
  location  = {Denver, Colorado, USA},
  numpages  = {13},
  url       = {https://doi.org/10.1145/2810103.2813707},
}

@InProceedings{Oktay2015,
  author    = {Oktay, Kerim Yasin and Mehrotra, Sharad and Khadilkar, Vaibhav and Kantarcioglu, Murat},
  booktitle = {Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data},
  title     = {SEMROD: Secure and Efficient MapReduce Over HybriD Clouds},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {153–166},
  publisher = {Association for Computing Machinery},
  series    = {SIGMOD '15},
  abstract  = {This paper describes SEMROD, a sensitive data aware MapReduce (MR) framework for hybrid
clouds. SEMROD steers data and computation through public and private machines in
such a way that no knowledge about sensitive data is leaked to public machines. For
this purpose, SEMROD keeps trace of intermediate keys (generated during MR execution)
that become sensitive, based on which it makes dynamic task scheduling decisions.
SEMROD guarantees that adversaries viz. public machines) cannot gain any ``additional''
information about sensitive data from either the data stored on public machines or
the communication between public and private machines during job execution. SEMROD
extends naturally from a single MR job to multi-phase MR jobs that result, for instance,
from compiling Hive queries into MR jobs. Using SEMROD, computation that may involve
sensitive data can exploit public machines, thereby bringing significant performance
benefits. Such computation would otherwise be restricted to only private clouds. Our
experiments clearly demonstrate performance advantages to using SEMROD as compared
with other secure alternatives, even when the percentage of sensitive data is as high
as 50%.},
  doi       = {10.1145/2723372.2723741},
  isbn      = {9781450327589},
  keywords  = {data processing, secure, hybrid cloud, mapreduce},
  location  = {Melbourne, Victoria, Australia},
  numpages  = {14},
  url       = {https://doi.org/10.1145/2723372.2723741},
}

@Article{Xi2016,
  author     = {Xi, Kai and Hu, Jiankun and Kumar, B. V. K. Vijaya},
  journal    = {ACM Trans. Embed. Comput. Syst.},
  title      = {FE-SViT: A SViT-Based Fuzzy Extractor Framework},
  year       = {2016},
  issn       = {1539-9087},
  month      = aug,
  number     = {4},
  volume     = {15},
  abstract   = {As a promising bio-cryptographic technique, the fuzzy extractor seamlessly binds biometrics
and cryptography for template protection and key generation. However, most existing
methods hardly solve the following issues simultaneously: (1) Fingerprint registration,
(2) Verification accuracy, (3) Security strength, and (4) Computational efficiency.
In this article, we introduce a bio-crypto-oriented fingerprint verification scheme
- Selective Vertex-indexed Triangulation (SViT) which maps minutia global topology
to local triangulation with minimum information loss. Then, a SViT-based fuzzy extractor
framework (FE-SViT) is proposed and high verification accuracy is achieved. The FE-SViT
is highly parallelizable and efficient which makes it suitable for embedded devices.},
  address    = {New York, NY, USA},
  articleno  = {78},
  doi        = {10.1145/2930669},
  issue_date = {August 2016},
  keywords   = {key generation, Fuzzy extractor, biometric template protection, fingerprint security},
  numpages   = {24},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2930669},
}

@InProceedings{Akestoridis2020,
  author    = {Akestoridis, Dimitrios-Georgios and Harishankar, Madhumitha and Weber, Michael and Tague, Patrick},
  booktitle = {Proceedings of the 13th ACM Conference on Security and Privacy in Wireless and Mobile Networks},
  title     = {Zigator: Analyzing the Security of Zigbee-Enabled Smart Homes},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {77–88},
  publisher = {Association for Computing Machinery},
  series    = {WiSec '20},
  abstract  = {As the popularity of Internet-connected devices for residential use increases, it
is important to ensure that they meet appropriate security goals, given that they
interact with the physical world through sensors and actuators. Zigbee is a wireless
communication protocol that is commonly used in smart home environments, which builds
on top of the IEEE 802.15.4 standard. In this work we present a security analysis
tool, called Zigator, that enables in-depth study of Zigbee networks. In particular,
we study the security consequences of the design choice to disable MAC-layer security
in centralized Zigbee networks. We show that valuable information can be gained from
passive inspection of Zigbee traffic, including the identification of certain encrypted
NWK commands, which we then use to develop selective jamming and spoofing attacks.
An attacker may launch these attacks in order to force the end user to factory reset
targeted devices and eventually expose the network key. We validated our attacks by
setting up a testbed, using open-source tools, that incorporates commercial Zigbee
devices. Finally, we publicly release the software tools that we developed and the
Zigbee packets that we captured, to contribute back to the research community.},
  doi       = {10.1145/3395351.3399363},
  isbn      = {9781450380065},
  keywords  = {smart home, IEEE 802.15.4, Zigbee, security analysis, jamming},
  location  = {Linz, Austria},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3395351.3399363},
}

@InProceedings{Davis2019,
  author    = {Davis, James C. and Michael IV, Louis G. and Coghlan, Christy A. and Servant, Francisco and Lee, Dongyoon},
  booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  title     = {Why Aren’t Regular Expressions a Lingua Franca? An Empirical Study on the Re-Use and Portability of Regular Expressions},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {443–454},
  publisher = {Association for Computing Machinery},
  series    = {ESEC/FSE 2019},
  abstract  = {This paper explores the extent to which regular expressions (regexes) are portable
across programming languages. Many languages offer similar regex syntaxes, and it
would be natural to assume that regexes can be ported across language boundaries.
But can regexes be copy/pasted across language boundaries while retaining their semantic
and performance characteristics?  In our survey of 158 professional software developers,
most indicated that they re-use regexes across language boundaries and about half
reported that they believe regexes are a universal language.We experimentally evaluated
the riskiness of this practice using a novel regex corpus — 537,806 regexes from 193,524
projects written in JavaScript, Java, PHP, Python, Ruby, Go, Perl, and Rust. Using
our polyglot regex corpus, we explored the hitherto-unstudied regex portability problems:
logic errors due to semantic differences, and security vulnerabilities due to performance
differences.  We report that developers’ belief in a regex lingua franca is understandable
but unfounded. Though most regexes compile across language boundaries, 15% exhibit
semantic differences across languages and 10% exhibit performance differences across
languages. We explained these differences using regex documentation, and further illuminate
our findings by investigating regex engine implementations. Along the way we found
bugs in the regex engines of JavaScript-V8, Python, Ruby, and Rust, and potential
semantic and performance regex bugs in thousands of modules.},
  doi       = {10.1145/3338906.3338909},
  isbn      = {9781450355728},
  keywords  = {portability, developer perceptions, ReDoS, empirical software engineering, re-use, mining software repositories, Regular expressions},
  location  = {Tallinn, Estonia},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3338906.3338909},
}

@InProceedings{Bernstein2019,
  author    = {Bernstein, Daniel J. and H\"{u}lsing, Andreas and K\"{o}lbl, Stefan and Niederhagen, Ruben and Rijneveld, Joost and Schwabe, Peter},
  booktitle = {Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {The SPHINCS<sup>+</sup> Signature Framework},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {2129–2146},
  publisher = {Association for Computing Machinery},
  series    = {CCS '19},
  abstract  = {We introduce SPHINCS+, a stateless hash-based signature framework. SPHINCS+ has significant
advantages over the state of the art in terms of speed, signature size, and security,
and is among the nine remaining signature schemes in the second round of the NIST
PQC standardization project. One of our main contributions in this context is a new
few-time signature scheme that we call FORS. Our second main contribution is the introduction
of tweakable hash functions and a demonstration how they allow for a unified security
analysis of hash-based signature schemes. We give a security reduction for SPHINCS+
using this abstraction and derive secure parameters in accordance with the resulting
bound. Finally, we present speed results for our optimized implementation of SPHINCS+
and compare to SPHINCS-256, Gravity-SPHINCS, and Picnic.},
  doi       = {10.1145/3319535.3363229},
  isbn      = {9781450367479},
  keywords  = {exact security, sphincs, post-quantum cryptography, hash-based signatures, stateless, tweakable hash functions, NIST PGC},
  location  = {London, United Kingdom},
  numpages  = {18},
  url       = {https://doi.org/10.1145/3319535.3363229},
}

@InProceedings{Slater2019,
  author    = {Slater, David and Novotney, Scott and Moore, Jessica and Morgan, Sean and Tenaglia, Scott},
  booktitle = {Proceedings of the 35th Annual Computer Security Applications Conference},
  title     = {Robust Keystroke Transcription from the Acoustic Side-Channel},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {776–787},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '19},
  abstract  = {The acoustic emanations from keyboards provide a side-channel attack from which an
attacker can recover sensitive user information, such as passwords and personally
identifiable information. Previous work has shown the feasibility of these attacks
given isolated key strokes, but has not demonstrated robust keystroke detection and
segmentation in the presence of realistic noise and fast typing speeds. Common problems
include noises like doors closing or speech as well as overlapping keystroke waveforms.
Prior work has assumed that isolating the waveform of individual key strokes can be
achieved with near 100% accuracy, but we show that these techniques generate a large
number of misses and false positives, drastically impacting the downstream keystroke
classification task.To solve this problem, we present a deep learning system, leveraging
related state-of-the-art techniques from speech transcription, that performs end-to-end,
audio-to-keystroke transcription with superior performance. The recurrent architecture
enables it to robustly handle overlapping waveforms and adapt to local noise profiles.
Furthermore, the joint approach to keystroke detection and classification enables
us to both train without ground truth keystroke timings and outperform standard classification
approaches even when they have ground truth timings. Due to the paucity of existing
datasets, we collected a novel acoustic and keylogger dataset comprising 17 users
and 86k keystrokes across various real-world typing tasks. On this dataset, we reduce
the end-to-end character error rate on English text from 36.0% to 7.41% for known
typists and 41.3% to 15.41% for unknown typists. The keystroke acoustic side-channel
attack remains dangerously feasible.},
  doi       = {10.1145/3359789.3359816},
  isbn      = {9781450376280},
  keywords  = {acoustics, neural networks, user privacy, keystroke transcription, side-channel attacks, deep learning},
  location  = {San Juan, Puerto Rico, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3359789.3359816},
}

@Article{Jiang2020,
  author     = {Jiang, Hongda and Wang, Bin and Wang, Xi and Christie, Marc and Chen, Baoquan},
  journal    = {ACM Trans. Graph.},
  title      = {Example-Driven Virtual Cinematography by Learning Camera Behaviors},
  year       = {2020},
  issn       = {0730-0301},
  month      = jul,
  number     = {4},
  volume     = {39},
  abstract   = {Designing a camera motion controller that has the capacity to move a virtual camera
automatically in relation with contents of a 3D animation, in a cinematographic and
principled way, is a complex and challenging task. Many cinematographic rules exist,
yet practice shows there are significant stylistic variations in how these can be
applied.In this paper, we propose an example-driven camera controller which can extract
camera behaviors from an example film clip and re-apply the extracted behaviors to
a 3D animation, through learning from a collection of camera motions. Our first technical
contribution is the design of a low-dimensional cinematic feature space that captures
the essence of a film's cinematic characteristics (camera angle and distance, screen
composition and character configurations) and which is coupled with a neural network
to automatically extract these cinematic characteristics from real film clips. Our
second technical contribution is the design of a cascaded deep-learning architecture
trained to (i) recognize a variety of camera motion behaviors from the extracted cinematic
features, and (ii) predict the future motion of a virtual camera given a character
3D animation. We propose to rely on a Mixture of Experts (MoE) gating+prediction mechanism
to ensure that distinct camera behaviors can be learned while ensuring generalization.We
demonstrate the features of our approach through experiments that highlight (i) the
quality of our cinematic feature extractor (ii) the capacity to learn a range of behaviors
through the gating mechanism, and (iii) the ability to generate a variety of camera
motions by applying different behaviors extracted from film clips. Such an example-driven
approach offers a high level of controllability which opens new possibilities toward
a deeper understanding of cinematographic style and enhanced possibilities in exploiting
real film data in virtual environments.},
  address    = {New York, NY, USA},
  articleno  = {45},
  doi        = {10.1145/3386569.3392427},
  issue_date = {July 2020},
  keywords   = {machine learning, virtual cinematography, camera behaviors},
  numpages   = {14},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3386569.3392427},
}

@InProceedings{Hahn2016,
  author    = {Hahn, Florian and Kerschbaum, Florian},
  booktitle = {Proceedings of the 2016 ACM on Cloud Computing Security Workshop},
  title     = {Poly-Logarithmic Range Queries on Encrypted Data with Small Leakage},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {23–34},
  publisher = {Association for Computing Machinery},
  series    = {CCSW '16},
  abstract  = {Privacy-preserving range queries allow encrypting data while still enabling queries
on ciphertexts if their corresponding plaintexts fall within a requested range. This
provides a data owner the possibility to outsource data collections to a cloud service
provider without sacrificing privacy nor losing functionality of filtering this data.
However, existing methods for range queries either leak additional information (like
the ordering of the complete data set) or slow down the search process tremendously
by requiring to query each ciphertext in the data collection. We present a novel scheme
that only leaks the access pattern while supporting amortized poly-logarithmic search
time. Our construction is based on the novel idea of enabling the cloud service provider
to compare requested range queries. By doing so, the cloud service provider can use
the access pattern to speed-up search time for range queries in the future. On the
one hand, values that have fallen within a queried range, are stored in an interactively
built index for future requests. On the other hand, values that have not been queried
do not leak any information to the cloud service provider and stay perfectly secure.
In order to show its practicability we have implemented our scheme and give a detailed
runtime evaluation.},
  doi       = {10.1145/2996429.2996437},
  isbn      = {9781450345729},
  keywords  = {secure computation, encrypted database, searchable encryption},
  location  = {Vienna, Austria},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2996429.2996437},
}

@InProceedings{Biryukov2014,
  author    = {Biryukov, Alex and Khovratovich, Dmitry and Pustogarov, Ivan},
  booktitle = {Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {Deanonymisation of Clients in Bitcoin P2P Network},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {15–29},
  publisher = {Association for Computing Machinery},
  series    = {CCS '14},
  abstract  = {Bitcoin is a digital currency which relies on a distributed set of miners to mint
coins and on a peer-to-peer network to broadcast transactions. The identities of Bitcoin
users are hidden behind pseudonyms (public keys) which are recommended to be changed
frequently in order to increase transaction unlinkability.We present an efficient
method to deanonymize Bitcoin users, which allows to link user pseudonyms to the IP
addresses where the transactions are generated. Our techniques work for the most common
and the most challenging scenario when users are behind NATs or firewalls of their
ISPs. They allow to link transactions of a user behind a NAT and to distinguish connections
and transactions of different users behind the same NAT. We also show that a natural
countermeasure of using Tor or other anonymity services can be cut-off by abusing
anti-DoS countermeasures of the Bitcoin network. Our attacks require only a few machines
and have been experimentally verified. The estimated success rate is between 11% and
60% depending on how stealthy an attacker wants to be. We propose several countermeasures
to mitigate these new attacks.},
  doi       = {10.1145/2660267.2660379},
  isbn      = {9781450329576},
  keywords  = {tor, p2p, bitcoin, anonymity},
  location  = {Scottsdale, Arizona, USA},
  numpages  = {15},
  url       = {https://doi.org/10.1145/2660267.2660379},
}

@Article{Ceylan2014,
  author     = {Ceylan, Duygu and Mitra, Niloy J. and Zheng, Youyi and Pauly, Mark},
  journal    = {ACM Trans. Graph.},
  title      = {Coupled Structure-from-Motion and 3D Symmetry Detection for Urban Facades},
  year       = {2014},
  issn       = {0730-0301},
  month      = feb,
  number     = {1},
  volume     = {33},
  abstract   = {Repeated structures are ubiquitous in urban facades. Such repetitions lead to ambiguity
in establishing correspondences across sets of unordered images. A decoupled structure-from-motion
reconstruction followed by symmetry detection often produces errors: outputs are either
noisy and incomplete, or even worse, appear to be valid but actually have a wrong
number of repeated elements. We present an optimization framework for extracting repeated
elements in images of urban facades, while simultaneously calibrating the input images
and recovering the 3D scene geometry using a graph-based global analysis. We evaluate
the robustness of the proposed scheme on a range of challenging examples containing
widespread repetitions and nondistinctive features. These image sets are common but
cannot be handled well with state-of-the-art methods. We show that the recovered symmetry
information along with the 3D geometry enables a range of novel image editing operations
that maintain consistency across the images.},
  address    = {New York, NY, USA},
  articleno  = {2},
  doi        = {10.1145/2517348},
  issue_date = {January 2014},
  keywords   = {coupled editing, Structure-from-motion, image collections, 3D reconstruction, symmetry detection},
  numpages   = {15},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2517348},
}

@Article{Harman2012,
  author     = {Harman, Mark and Mansouri, S. Afshin and Zhang, Yuanyuan},
  journal    = {ACM Comput. Surv.},
  title      = {Search-Based Software Engineering: Trends, Techniques and Applications},
  year       = {2012},
  issn       = {0360-0300},
  month      = dec,
  number     = {1},
  volume     = {45},
  abstract   = {In the past five years there has been a dramatic increase in work on Search-Based
Software Engineering (SBSE), an approach to Software Engineering (SE) in which Search-Based
Optimization (SBO) algorithms are used to address problems in SE. SBSE has been applied
to problems throughout the SE lifecycle, from requirements and project planning to
maintenance and reengineering. The approach is attractive because it offers a suite
of adaptive automated and semiautomated solutions in situations typified by large
complex problem spaces with multiple competing and conflicting objectives.This article1
provides a review and classification of literature on SBSE. The work identifies research
trends and relationships between the techniques applied and the applications to which
they have been applied and highlights gaps in the literature and avenues for further
research.},
  address    = {New York, NY, USA},
  articleno  = {11},
  doi        = {10.1145/2379776.2379787},
  issue_date = {November 2012},
  keywords   = {Software engineering, search-based techniques, survey},
  numpages   = {61},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2379776.2379787},
}

@Article{Matsumoto2017,
  author     = {Matsumoto, Stephanos and Reischuk, Raphael M. and Szalachowski, Pawel and Kim, Tiffany Hyun-Jin and Perrig, Adrian},
  journal    = {ACM Trans. Priv. Secur.},
  title      = {Authentication Challenges in a Global Environment},
  year       = {2017},
  issn       = {2471-2566},
  month      = jan,
  number     = {1},
  volume     = {20},
  abstract   = {In this article, we address the problem of scaling authentication for naming, routing,
and end-entity (EE) certification to a global environment in which authentication
policies and users’ sets of trust roots vary widely. The current mechanisms for authenticating
names (DNSSEC), routes (BGPSEC), and EE certificates (TLS) do not support a coexistence
of authentication policies, affect the entire Internet when compromised, cannot update
trust root information efficiently, and do not provide users with the ability to make
flexible trust decisions. We propose the Scalable Authentication Infrastructure for
Next-generation Trust (SAINT), which partitions the Internet into groups with common,
local trust roots and isolates the effects of a compromised trust root. SAINT requires
groups with direct routing connections to cross-sign each other for authentication
purposes, allowing diverse authentication policies while keeping all entities’ authentication
information globally discoverable. SAINT makes trust root management a central part
of the network architecture, enabling trust root updates within seconds and allowing
users to make flexible trust decisions. SAINT operates without a significant performance
penalty and can be deployed alongside existing infrastructures.},
  address    = {New York, NY, USA},
  articleno  = {1},
  doi        = {10.1145/3007208},
  issue_date = {February 2017},
  keywords   = {Public-key infrastructures, authentication, future internet architectures},
  numpages   = {34},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3007208},
}

@Article{Kamp2011,
  author     = {Kamp, Poul-Henning},
  journal    = {Commun. ACM},
  title      = {B.Y.O.C (1,342 Times and Counting)},
  year       = {2011},
  issn       = {0001-0782},
  month      = mar,
  number     = {3},
  pages      = {56–58},
  volume     = {54},
  abstract   = {Why can't we all use standard libraries for commonly needed algorithms?},
  address    = {New York, NY, USA},
  doi        = {10.1145/1897852.1897870},
  issue_date = {March 2011},
  numpages   = {3},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/1897852.1897870},
}

@Comment{jabref-meta: databaseType:bibtex;}
