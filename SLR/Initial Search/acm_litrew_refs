@article{10.1145/3439950,
author = {Pang, Guansong and Shen, Chunhua and Cao, Longbing and Hengel, Anton Van Den},
title = {Deep Learning for Anomaly Detection: A Review},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3439950},
doi = {10.1145/3439950},
abstract = {Anomaly detection, a.k.a. outlier detection or novelty detection, has been a lasting yet active research area in various research communities for several decades. There are still some unique problem complexities and challenges that require advanced approaches. In recent years, deep learning enabled anomaly detection, i.e., deep anomaly detection, has emerged as a critical direction. This article surveys the research of deep anomaly detection with a comprehensive taxonomy, covering advancements in 3 high-level categories and 11 fine-grained categories of the methods. We review their key intuitions, objective functions, underlying assumptions, advantages, and disadvantages and discuss how they address the aforementioned challenges. We further discuss a set of possible future opportunities and new perspectives on addressing the challenges.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {38},
numpages = {38},
keywords = {Anomaly detection, novelty detection, one-class classification, outlier detection, deep learning}
}

@article{10.1145/3344382,
author = {Bridges, Robert A. and Glass-Vanderlan, Tarrah R. and Iannacone, Michael D. and Vincent, Maria S. and Chen, Qian (Guenevere)},
title = {A Survey of Intrusion Detection Systems Leveraging Host Data},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3344382},
doi = {10.1145/3344382},
abstract = {This survey focuses on intrusion detection systems (IDS) that leverage host-based data sources for detecting attacks on enterprise network. The host-based IDS (HIDS) literature is organized by the input data source, presenting targeted sub-surveys of HIDS research leveraging system logs, audit data, Windows Registry, file systems, and program analysis. While system calls are generally included in audit data, several publicly available system call datasets have spawned a flurry of IDS research on this topic, which merits a separate section. To accommodate current researchers, a section giving descriptions of publicly available datasets is included, outlining their characteristics and shortcomings when used for IDS evaluation. Related surveys are organized and described. All sections are accompanied by tables concisely organizing the literature and datasets discussed. Finally, challenges, trends, and broader observations are throughout the survey and in the conclusion along with future directions of IDS research. Overall, this survey was designed to allow easy access to the diverse types of data available on a host for sensing intrusion, the progressions of research using each, and the accessible datasets for prototyping in the area.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {128},
numpages = {35},
keywords = {host, anomaly detection, Intrusion detection}
}

@article{10.1145/3178582,
author = {Resende, Paulo Angelo Alves and Drummond, Andr\'{e} Costa},
title = {A Survey of Random Forest Based Methods for Intrusion Detection Systems},
year = {2018},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3178582},
doi = {10.1145/3178582},
abstract = {Over the past decades, researchers have been proposing different Intrusion Detection approaches to deal with the increasing number and complexity of threats for computer systems. In this context, Random Forest models have been providing a notable performance on their applications in the realm of the behaviour-based Intrusion Detection Systems. Specificities of the Random Forest model are used to provide classification, feature selection, and proximity metrics. This work provides a comprehensive review of the general basic concepts related to Intrusion Detection Systems, including taxonomies, attacks, data collection, modelling, evaluation metrics, and commonly used methods. It also provides a survey of Random Forest based methods applied in this context, considering the particularities involved in these models. Finally, some open questions and challenges are posed combined with possible directions to deal with them, which may guide future works on the area.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {48},
numpages = {36},
keywords = {Machine Learning, anomaly detection, Intrusion Detection Systems, Random Forest methods, behavioural methods}
}

@article{10.1145/3214304,
author = {Liu, Ming and Xue, Zhi and Xu, Xianghua and Zhong, Changmin and Chen, Jinjun},
title = {Host-Based Intrusion Detection System with System Calls: Review and Future Trends},
year = {2018},
issue_date = {January 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3214304},
doi = {10.1145/3214304},
abstract = {In a contemporary data center, Linux applications often generate a large quantity of real-time system call traces, which are not suitable for traditional host-based intrusion detection systems deployed on every single host. Training data mining models with system calls on a single host that has static computing and storage capacity is time-consuming, and intermediate datasets are not capable of being efficiently handled. It is cumbersome for the maintenance and updating of host-based intrusion detection systems (HIDS) installed on every physical or virtual host, and comprehensive system call analysis can hardly be performed to detect complex and distributed attacks among multiple hosts. Considering these limitations of current system-call-based HIDS, in this article, we provide a review of the development of system-call-based HIDS and future research trends. Algorithms and techniques relevant to system-call-based HIDS are investigated, including feature extraction methods and various data mining algorithms. The HIDS dataset issues are discussed, including currently available datasets with system calls and approaches for researchers to generate new datasets. The application of system-call-based HIDS on current embedded systems is studied, and related works are investigated. Finally, future research trends are forecast regarding three aspects, namely, the reduction of the false-positive rate, the improvement of detection efficiency, and the enhancement of collaborative security.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {98},
numpages = {36},
keywords = {cloud computing, big data, system call, intrusion detection, Cybersecurity}
}

@article{10.1145/3453155,
author = {Luo, Yuan and Xiao, Ya and Cheng, Long and Peng, Guojun and Yao, Danfeng (Daphne)},
title = {Deep Learning-Based Anomaly Detection in Cyber-Physical Systems: Progress and Opportunities},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3453155},
doi = {10.1145/3453155},
abstract = {Anomaly detection is crucial to ensure the security of cyber-physical systems (CPS). However, due to the increasing complexity of CPSs and more sophisticated attacks, conventional anomaly detection methods, which face the growing volume of data and need domain-specific knowledge, cannot be directly applied to address these challenges. To this end, deep learning-based anomaly detection (DLAD) methods have been proposed. In this article, we review state-of-the-art DLAD methods in CPSs. We propose a taxonomy in terms of the type of anomalies, strategies, implementation, and evaluation metrics to understand the essential properties of current methods. Further, we utilize this taxonomy to identify and highlight new characteristics and designs in each CPS domain. Also, we discuss the limitations and open problems of these methods. Moreover, to give users insights into choosing proper DLAD methods in practice, we experimentally explore the characteristics of typical neural models, the workflow of DLAD methods, and the running performance of DL models. Finally, we discuss the deficiencies of DL approaches, our findings, and possible directions to improve DLAD methods and motivate future research.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {106},
numpages = {36},
keywords = {anomaly detection, Deep learning, cyber-physical systems}
}

@article{10.1145/3232848,
author = {Kiennert, Christophe and Ismail, Ziad and Debar, Herve and Leneutre, Jean},
title = {A Survey on Game-Theoretic Approaches for Intrusion Detection and Response Optimization},
year = {2018},
issue_date = {January 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3232848},
doi = {10.1145/3232848},
abstract = {Intrusion Detection Systems (IDS) are key components for securing critical infrastructures, capable of detecting malicious activities on networks or hosts. However, the efficiency of an IDS depends primarily on both its configuration and its precision. The large amount of network traffic that needs to be analyzed, in addition to the increase in attacks’ sophistication, renders the optimization of intrusion detection an important requirement for infrastructure security, and a very active research subject. In the state of the art, a number of approaches have been proposed to improve the efficiency of intrusion detection and response systems. In this article, we review the works relying on decision-making techniques focused on game theory and Markov decision processes to analyze the interactions between the attacker and the defender, and classify them according to the type of the optimization problem they address. While these works provide valuable insights for decision-making, we discuss the limitations of these solutions as a whole, in particular regarding the hypotheses in the models and the validation methods. We also propose future research directions to improve the integration of game-theoretic approaches into IDS optimization techniques.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {90},
numpages = {31},
keywords = {IDS, game theory, MDP, Intrusion detection and response, optimization}
}

@article{10.1145/3312739,
author = {Taha, Ayman and Hadi, Ali S.},
title = {Anomaly Detection Methods for Categorical Data: A Review},
year = {2019},
issue_date = {May 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3312739},
doi = {10.1145/3312739},
abstract = {Anomaly detection has numerous applications in diverse fields. For example, it has been widely used for discovering network intrusions and malicious events. It has also been used in numerous other applications such as identifying medical malpractice or credit fraud. Detection of anomalies in quantitative data has received a considerable attention in the literature and has a venerable history. By contrast, and despite the widespread availability use of categorical data in practice, anomaly detection in categorical data has received relatively little attention as compared to quantitative data. This is because detection of anomalies in categorical data is a challenging problem. Some anomaly detection techniques depend on identifying a representative pattern then measuring distances between objects and this pattern. Objects that are far from this pattern are declared as anomalies. However, identifying patterns and measuring distances are not easy in categorical data compared with quantitative data. Fortunately, several papers focussing on the detection of anomalies in categorical data have been published in the recent literature. In this article, we provide a comprehensive review of the research on the anomaly detection problem in categorical data. Previous review articles focus on either the statistics literature or the machine learning and computer science literature. This review article combines both literatures. We review 36 methods for the detection of anomalies in categorical data in both literatures and classify them into 12 different categories based on the conceptual definition of anomalies they use. For each approach, we survey anomaly detection methods, and then show the similarities and differences among them. We emphasize two important issues, the number of parameters each method requires and its time complexity. The first issue is critical, because the performance of these methods are sensitive to the choice of these parameters. The time complexity is also very important in real applications especially in big data applications. We report the time complexity if it is reported by the authors of the methods. If it is not, then we derive it ourselves and report it in this article. In addition, we discuss the common problems and the future directions of the anomaly detection in categorical data.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {38},
numpages = {35},
keywords = {novelty detection, nominal data, data mining, outliers detection, semi-supervised learning, holo entropy, mixed data, Shannon entropy, unsupervised learning, supervised learning, intrusion detection systems, Computational complexity}
}

@article{10.1145/3184898,
author = {Ramaki, Ali Ahmadian and Rasoolzadegan, Abbas and Bafghi, Abbas Ghaemi},
title = {A Systematic Mapping Study on Intrusion Alert Analysis in Intrusion Detection Systems},
year = {2018},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3184898},
doi = {10.1145/3184898},
abstract = {Intrusion alert analysis is an attractive and active topic in the area of intrusion detection systems. In recent decades, many research communities have been working in this field. The main objective of this article is to achieve a taxonomy of research fields in intrusion alert analysis by using a systematic mapping study of 468 high-quality papers. The results show that there are 10 different research topics in the field, which can be classified into three broad groups: pre-processing, processing, and post-processing. The processing group contains most of the research works, and the post-processing group is newer than others.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {55},
numpages = {41},
keywords = {Network security, systematic mapping study (SMS), systematic review, alert correlation, intrusion alert analysis}
}

@article{10.1145/2716260,
author = {Vasilomanolakis, Emmanouil and Karuppayah, Shankar and M\"{u}hlh\"{a}user, Max and Fischer, Mathias},
title = {Taxonomy and Survey of Collaborative Intrusion Detection},
year = {2015},
issue_date = {July 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2716260},
doi = {10.1145/2716260},
abstract = {The dependency of our society on networked computers has become frightening: In the economy, all-digital networks have turned from facilitators to drivers; as cyber-physical systems are coming of age, computer networks are now becoming the central nervous systems of our physical world—even of highly critical infrastructures such as the power grid. At the same time, the 24/7 availability and correct functioning of networked computers has become much more threatened: The number of sophisticated and highly tailored attacks on IT systems has significantly increased. Intrusion Detection Systems (IDSs) are a key component of the corresponding defense measures; they have been extensively studied and utilized in the past. Since conventional IDSs are not scalable to big company networks and beyond, nor to massively parallel attacks, Collaborative IDSs (CIDSs) have emerged. They consist of several monitoring components that collect and exchange data. Depending on the specific CIDS architecture, central or distributed analysis components mine the gathered data to identify attacks. Resulting alerts are correlated among multiple monitors in order to create a holistic view of the network monitored. This article first determines relevant requirements for CIDSs; it then differentiates distinct building blocks as a basis for introducing a CIDS design space and for discussing it with respect to requirements. Based on this design space, attacks that evade CIDSs and attacks on the availability of the CIDSs themselves are discussed. The entire framework of requirements, building blocks, and attacks as introduced is then used for a comprehensive analysis of the state of the art in collaborative intrusion detection, including a detailed survey and comparison of specific CIDS approaches.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {55},
numpages = {33},
keywords = {Collaborative intrusion detection, network security, attacks, classification}
}

@article{10.1145/2791120,
author = {Ibidunmoye, Olumuyiwa and Hern\'{a}ndez-Rodriguez, Francisco and Elmroth, Erik},
title = {Performance Anomaly Detection and Bottleneck Identification},
year = {2015},
issue_date = {September 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2791120},
doi = {10.1145/2791120},
abstract = {In order to meet stringent performance requirements, system administrators must effectively detect undesirable performance behaviours, identify potential root causes, and take adequate corrective measures. The problem of uncovering and understanding performance anomalies and their causes (bottlenecks) in different system and application domains is well studied. In order to assess progress, research trends, and identify open challenges, we have reviewed major contributions in the area and present our findings in this survey. Our approach provides an overview of anomaly detection and bottleneck identification research as it relates to the performance of computing systems. By identifying fundamental elements of the problem, we are able to categorize existing solutions based on multiple factors such as the detection goals, nature of applications and systems, system observability, and detection methods.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {4},
numpages = {35},
keywords = {performance problem identification, Systems performance, performance anomaly detection, bottleneck detection}
}

@article{10.1145/2542049,
author = {Mitchell, Robert and Chen, Ing-Ray},
title = {A Survey of Intrusion Detection Techniques for Cyber-Physical Systems},
year = {2014},
issue_date = {April 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2542049},
doi = {10.1145/2542049},
abstract = {Pervasive healthcare systems, smart grids, and unmanned aircraft systems are examples of Cyber-Physical Systems (CPSs) that have become highly integrated in the modern world. As this integration deepens, the importance of securing these systems increases. In order to identify gaps and propose research directions in CPS intrusion detection research, we survey the literature of this area. Our approach is to classify modern CPS Intrusion Detection System (IDS) techniques based on two design dimensions: detection technique and audit material. We summarize advantages and drawbacks of each dimension’s options. We also summarize the most and least studied CPS IDS techniques in the literature and provide insight on the effectiveness of IDS techniques as they apply to CPSs. Finally, we identify gaps in CPS IDS research and suggest future research areas.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {55},
numpages = {29},
keywords = {Cyber-physical systems, security, intrusion detection, classification}
}

@article{10.1145/2827699,
author = {Kulkarni, Amey and Pino, Youngok and French, Matthew and Mohsenin, Tinoosh},
title = {Real-Time Anomaly Detection Framework for Many-Core Router through Machine-Learning Techniques},
year = {2016},
issue_date = {December 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {1550-4832},
url = {https://doi.org/10.1145/2827699},
doi = {10.1145/2827699},
abstract = {In this article, we propose a real-time anomaly detection framework for an NoC-based many-core architecture. We assume that processing cores and memories are safe and anomaly is included through a communication medium (i.e., router). The article targets three different attacks, namely, traffic diversion, route looping, and core address spoofing attacks. The attacks are detected by using machine-learning techniques. Comprehensive analysis on machine-learning algorithms suggests that Support Vector Machine (SVM) and K-Nearest Neighbor (K-NN) have better attack detection efficiency. It has been observed that both algorithms have accuracy in the range of 94% to 97%. Additional hardware complexity analysis advocates SVM to be implemented on hardware. To test the framework, we implement a condition-based attack insertion module; attacks are performed intra- and intercluster. The proposed real-time anomaly detection framework is fully placed and routed on Xilinx Virtex-7 FPGA. Postplace and -route implementation results show that SVM has 12% to 2% area overhead and 3% to 1% power overhead for the quad-core and 16-core implementation, respectively. It is also observed that it takes 25% to 18% of the total execution time to detect an anomaly in transferred packets for quad-core and 16-core, respectively. The proposed framework achieves 65% reduction in area overhead and is 3 times faster compared to previous published work.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = jun,
articleno = {10},
numpages = {22},
keywords = {many-core, anomaly detection, Hardware security, machine learning, NoC}
}

@article{10.1145/3417989,
author = {Santhosh, K. K. and Dogra, D. P. and Roy, P. P.},
title = {Anomaly Detection in Road Traffic Using Visual Surveillance: A Survey},
year = {2020},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3417989},
doi = {10.1145/3417989},
abstract = {Computer vision has evolved in the last decade as a key technology for numerous applications replacing human supervision. Timely detection of traffic violations and abnormal behavior of pedestrians at public places through computer vision and visual surveillance can be highly effective for maintaining traffic order in cities. However, despite a handful of computer vision–based techniques proposed in recent times to understand the traffic violations or other types of on-road anomalies, no methodological survey is available that provides a detailed insight into the classification techniques, learning methods, datasets, and application contexts. Thus, this study aims to investigate the recent visual surveillance–related research on anomaly detection in public places, particularly on road. The study analyzes various vision-guided anomaly detection techniques using a generic framework such that the key technical components can be easily understood. Our survey includes definitions of related terminologies and concepts, judicious classifications of the vision-guided anomaly detection approaches, detailed analysis of anomaly detection methods including deep learning–based methods, descriptions of the relevant datasets with environmental conditions, and types of anomalies. The study also reveals vital gaps in the available datasets and anomaly detection capability in various contexts, and thus gives future directions to the computer vision–guided anomaly detection research. As anomaly detection is an important step in automatic road traffic surveillance, this survey can be a useful resource for interested researchers working on solving various issues of Intelligent Transportation Systems (ITS).},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {119},
numpages = {26},
keywords = {Learning methods, road traffic analysis, classification}
}

@article{10.1145/3453158,
author = {Rosenberg, Ishai and Shabtai, Asaf and Elovici, Yuval and Rokach, Lior},
title = {Adversarial Machine Learning Attacks and Defense Methods in the Cyber Security Domain},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3453158},
doi = {10.1145/3453158},
abstract = {In recent years, machine learning algorithms, and more specifically deep learning algorithms, have been widely used in many fields, including cyber security. However, machine learning systems are vulnerable to adversarial attacks, and this limits the application of machine learning, especially in non-stationary, adversarial environments, such as the cyber security domain, where actual adversaries (e.g., malware developers) exist. This article comprehensively summarizes the latest research on adversarial attacks against security solutions based on machine learning techniques and illuminates the risks they pose. First, the adversarial attack methods are characterized based on their stage of occurrence, and the attacker’ s goals and capabilities. Then, we categorize the applications of adversarial attack and defense methods in the cyber security domain. Finally, we highlight some characteristics identified in recent research and discuss the impact of recent advancements in other adversarial learning domains on future research directions in the cyber security domain. To the best of our knowledge, this work is the first to discuss the unique challenges of implementing end-to-end adversarial attacks in the cyber security domain, map them in a unified taxonomy, and use the taxonomy to highlight future research directions.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {108},
numpages = {36},
keywords = {evasion attacks, poisoning attacks, Adversarial learning, adversarial examples, adversarial machine learning, deep learning, cyber security}
}

@article{10.1145/3448291,
author = {Tripathi, Nikhil and Hubballi, Neminath},
title = {Application Layer Denial-of-Service Attacks and Defense Mechanisms: A Survey},
year = {2021},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3448291},
doi = {10.1145/3448291},
abstract = {Application layer Denial-of-Service (DoS) attacks are generated by exploiting vulnerabilities of the protocol implementation or its design. Unlike volumetric DoS attacks, these are stealthy in nature and target a specific application running on the victim. There are several attacks discovered against popular application layer protocols in recent years. In this article, we provide a structured and comprehensive survey of the existing application layer DoS attacks and defense mechanisms. We classify existing attacks and defense mechanisms into different categories, describe their working, and compare them based on relevant parameters. We conclude the article with directions for future research.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {86},
numpages = {33},
keywords = {defense mechanisms, Protocol-specific and generic DoS attacks, distributed DoS attacks}
}

@article{10.1145/3301614,
author = {Swami, Rochak and Dave, Mayank and Ranga, Virender},
title = {Software-Defined Networking-Based DDoS Defense Mechanisms},
year = {2019},
issue_date = {May 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3301614},
doi = {10.1145/3301614},
abstract = {Distributed Denial of Service attack (DDoS) is recognized to be one of the most catastrophic attacks against various digital communication entities. Software-defined networking (SDN) is an emerging technology for computer networks that uses open protocols for controlling switches and routers placed at the network edges by using specialized open programmable interfaces. In this article, a detailed study on DDoS threats prevalent in SDN is presented. First, SDN features are examined from the perspective of security, and then a discussion on SDN security features is done. Further, two viewpoints on protecting networks against DDoS attacks are presented. In the first view, SDN utilizes its abilities to secure conventional networks. In the second view, SDN may become a victim of the threat itself because of the centralized control mechanism. The main focus of this research work is on discovering critical security implications in SDN while reviewing the current ongoing research studies. By emphasizing the available state-of-the-art techniques, an extensive review of the advancement of SDN security is provided to the research and IT communities.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {28},
numpages = {36},
keywords = {Software-defined networking, distributed denial of service, data plane, control plane}
}

@article{10.1145/3203245,
author = {Giraldo, Jairo and Urbina, David and Cardenas, Alvaro and Valente, Junia and Faisal, Mustafa and Ruths, Justin and Tippenhauer, Nils Ole and Sandberg, Henrik and Candell, Richard},
title = {A Survey of Physics-Based Attack Detection in Cyber-Physical Systems},
year = {2018},
issue_date = {September 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3203245},
doi = {10.1145/3203245},
abstract = {Monitoring the “physics” of cyber-physical systems to detect attacks is a growing area of research. In its basic form, a security monitor creates time-series models of sensor readings for an industrial control system and identifies anomalies in these measurements to identify potentially false control commands or false sensor readings. In this article, we review previous work on physics-based anomaly detection based on a unified taxonomy that allows us to identify limitations and unexplored challenges and to propose new solutions.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {76},
numpages = {36},
keywords = {Cyber-physical systems, industrial control systems, metrics}
}

@article{10.1145/3379499,
author = {Suaboot, Jakapan and Fahad, Adil and Tari, Zahir and Grundy, John and Mahmood, Abdun Naser and Almalawi, Abdulmohsen and Zomaya, Albert Y. and Drira, Khalil},
title = {A Taxonomy of Supervised Learning for IDSs in SCADA Environments},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3379499},
doi = {10.1145/3379499},
abstract = {Supervisory Control and Data Acquisition (SCADA) systems play an important role in monitoring industrial processes such as electric power distribution, transport systems, water distribution, and wastewater collection systems. Such systems require a particular attention with regards to security aspects, as they deal with critical infrastructures that are crucial to organizations and countries. Protecting SCADA systems from intrusion is a very challenging task because they do not only inherit traditional IT security threats but they also include additional vulnerabilities related to field components (e.g., cyber-physical attacks). Many of the existing intrusion detection techniques rely on supervised learning that consists of algorithms that are first trained with reference inputs to learn specific information, and then tested on unseen inputs for classification purposes. This article surveys supervised learning from a specific security angle, namely SCADA-based intrusion detection. Based on a systematic review process, existing literature is categorized and evaluated according to SCADA-specific requirements. Additionally, this survey reports on well-known SCADA datasets and testbeds used with machine learning methods. Finally, we present key challenges and our recommendations for using specific supervised methods for SCADA systems.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {40},
numpages = {37},
keywords = {machine learning, SCADA security, network intrusion, supervised learning}
}

@article{10.1145/3431233,
author = {Aliwa, Emad and Rana, Omer and Perera, Charith and Burnap, Peter},
title = {Cyberattacks and Countermeasures for In-Vehicle Networks},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3431233},
doi = {10.1145/3431233},
abstract = {As connectivity between and within vehicles increases, so does concern about safety and security. Various automotive serial protocols are used inside vehicles such as Controller Area Network (CAN), Local Interconnect Network (LIN), and FlexRay. CAN Bus is the most used in-vehicle network protocol to support exchange of vehicle parameters between Electronic Control Units (ECUs). This protocol lacks security mechanisms by design and is therefore vulnerable to various attacks. Furthermore, connectivity of vehicles has made the CAN Bus vulnerable not only from within the vehicle but also from outside. With the rise of connected cars, more entry points and interfaces have been introduced on board vehicles, thereby also leading to a wider potential attack surface. Existing security mechanisms focus on the use of encryption, authentication, and vehicle Intrusion Detection Systems (IDS), which operate under various constraints such as low bandwidth, small frame size (e.g., in the CAN protocol), limited availability of computational resources, and real-time sensitivity. We survey and classify current cryptographic and IDS approaches and compare these approaches based on criteria such as real-time constraints, types of hardware used, changes in CAN Bus behaviour, types of attack mitigation, and software/ hardware used to validate these approaches. We conclude with mitigation strategies limitations and research challenges for the future.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {21},
numpages = {37},
keywords = {intrusion detection systems, cybersecurity, CAN bus}
}

@article{10.1145/3329786,
author = {Or-Meir, Ori and Nissim, Nir and Elovici, Yuval and Rokach, Lior},
title = {Dynamic Malware Analysis in the Modern Era—A State of the Art Survey},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3329786},
doi = {10.1145/3329786},
abstract = {Although malicious software (malware) has been around since the early days of computers, the sophistication and innovation of malware has increased over the years. In particular, the latest crop of ransomware has drawn attention to the dangers of malicious software, which can cause harm to private users as well as corporations, public services (hospitals and transportation systems), governments, and security institutions. To protect these institutions and the public from malware attacks, malicious activity must be detected as early as possible, preferably before it conducts its harmful acts. However, it is not always easy to know what to look for—especially when dealing with new and unknown malware that has never been seen. Analyzing a suspicious file by static or dynamic analysis methods can provide relevant and valuable information regarding a file's impact on the hosting system and help determine whether the file is malicious or not, based on the method's predefined rules. While various techniques (e.g., code obfuscation, dynamic code loading, encryption, and packing) can be used by malware writers to evade static analysis (including signature-based anti-virus tools), dynamic analysis is robust to these techniques and can provide greater understanding regarding the analyzed file and consequently can lead to better detection capabilities. Although dynamic analysis is more robust than static analysis, existing dynamic analysis tools and techniques are imperfect, and there is no single tool that can cover all aspects of malware behavior. The most recent comprehensive survey performed in this area was published in 2012. Since that time, the computing environment has changed dramatically with new types of malware (ransomware, cryptominers), new analysis methods (volatile memory forensics, side-channel analysis), new computing environments (cloud computing, IoT devices), new machine-learning algorithms, and more. The goal of this survey is to provide a comprehensive and up-to-date overview of existing methods used to dynamically analyze malware, which includes a description of each method, its strengths and weaknesses, and its resilience against malware evasion techniques. In addition, we include an overview of prominent studies presenting the usage of machine-learning methods to enhance dynamic malware analysis capabilities aimed at detection, classification, and categorization.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {88},
numpages = {48},
keywords = {Dynamic analysis, malware, evasion, detection, behavioral analysis}
}

@article{10.1145/2785733,
author = {Meng, Guozhu and Liu, Yang and Zhang, Jie and Pokluda, Alexander and Boutaba, Raouf},
title = {Collaborative Security: A Survey and Taxonomy},
year = {2015},
issue_date = {September 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2785733},
doi = {10.1145/2785733},
abstract = {Security is oftentimes centrally managed. An alternative trend of using collaboration in order to improve security has gained momentum over the past few years. Collaborative security is an abstract concept that applies to a wide variety of systems and has been used to solve security issues inherent in distributed environments. Thus far, collaboration has been used in many domains such as intrusion detection, spam filtering, botnet resistance, and vulnerability detection. In this survey, we focus on different mechanisms of collaboration and defense in collaborative security. We systematically investigate numerous use cases of collaborative security by covering six types of security systems. Aspects of these systems are thoroughly studied, including their technologies, standards, frameworks, strengths and weaknesses. We then present a comprehensive study with respect to their analysis target, timeliness of analysis, architecture, network infrastructure, initiative, shared information and interoperability. We highlight five important topics in collaborative security, and identify challenges and possible directions for future research. Our work contributes the following to the existing research on collaborative security with the goal of helping to make collaborative security systems more resilient and efficient. This study (1) clarifies the scope of collaborative security, (2) identifies the essential components of collaborative security, (3) analyzes the multiple mechanisms of collaborative security, and (4) identifies challenges in the design of collaborative security.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {1},
numpages = {42},
keywords = {trust, malware, intrusion detection, information sharing, Collaborative security, taxonomy, spam, privacy}
}

@article{10.1145/3432893,
author = {Qasem, Abdullah and Shirani, Paria and Debbabi, Mourad and Wang, Lingyu and Lebel, Bernard and Agba, Basile L.},
title = {Automatic Vulnerability Detection in Embedded Devices and Firmware: Survey and Layered Taxonomies},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3432893},
doi = {10.1145/3432893},
abstract = {In the era of the internet of things (IoT), software-enabled inter-connected devices are of paramount importance. The embedded systems are very frequently used in both security and privacy-sensitive applications. However, the underlying software (a.k.a. firmware) very often suffers from a wide range of security vulnerabilities, mainly due to their outdated systems or reusing existing vulnerable libraries; which is evident by the surprising rise in the number of attacks against embedded systems. Therefore, to protect those embedded systems, detecting the presence of vulnerabilities in the large pool of embedded devices and their firmware plays a vital role. To this end, there exist several approaches to identify and trigger potential vulnerabilities within deployed embedded systems firmware. In this survey, we provide a comprehensive review of the state-of-the-art proposals, which detect vulnerabilities in embedded systems and firmware images by employing various analysis techniques, including static analysis, dynamic analysis, symbolic execution, and hybrid approaches. Furthermore, we perform both quantitative and qualitative comparisons among the surveyed approaches. Moreover, we devise taxonomies based on the applications of those approaches, the features used in the literature, and the type of the analysis. Finally, we identify the unresolved challenges and discuss possible future directions in this field of research.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {25},
numpages = {42},
keywords = {Binary code analysis, internet of things (IoT), embedded device security, vulnerability detection, firmware analysis}
}

@article{10.1145/2693841,
author = {Roy, Arpan and Sarkar, Santonu and Ganesan, Rajeshwari and Goel, Geetika},
title = {Secure the Cloud: From the Perspective of a Service-Oriented Organization},
year = {2015},
issue_date = {April 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2693841},
doi = {10.1145/2693841},
abstract = {In response to the revival of virtualized technology by Rosenblum and Garfinkel [2005], NIST defined cloud computing, a new paradigm in service computing infrastructures. In cloud environments, the basic security mechanism is ingrained in virtualization—that is, the execution of instructions at different privilege levels. Despite its obvious benefits, the caveat is that a crashed virtual machine (VM) is much harder to recover than a crashed workstation. When crashed, a VM is nothing but a giant corrupt binary file and quite unrecoverable by standard disk-based forensics. Therefore, VM crashes should be avoided at all costs. Security is one of the major contributors to such VM crashes. This includes compromising the hypervisor, cloud storage, images of VMs used infrequently, and remote cloud client used by the customer as well as threat from malicious insiders. Although using secure infrastructures such as private clouds alleviate several of these security problems, most cloud users end up using cheaper options such as third-party infrastructures (i.e., private clouds), thus a thorough discussion of all known security issues is pertinent. Hence, in this article, we discuss ongoing research in cloud security in order of the attack scenarios exploited most often in the cloud environment. We explore attack scenarios that call for securing the hypervisor, exploiting co-residency of VMs, VM image management, mitigating insider threats, securing storage in clouds, abusing lightweight software-as-a-service clients, and protecting data propagation in clouds. Wearing a practitioner's glasses, we explore the relevance of each attack scenario to a service company like Infosys. At the same time, we draw parallels between cloud security research and implementation of security solutions in the form of enterprise security suites for the cloud. We discuss the state of practice in the form of enterprise security suites that include cryptographic solutions, access control policies in the cloud, new techniques for attack detection, and security quality assurance in clouds.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {41},
numpages = {30},
keywords = {open problems, enterprise security suites, attack scenarios, service-oriented organization, Cloud security}
}

@article{10.1145/3092566,
author = {Ghaffarian, Seyed Mohammad and Shahriari, Hamid Reza},
title = {Software Vulnerability Analysis and Discovery Using Machine-Learning and Data-Mining Techniques: A Survey},
year = {2017},
issue_date = {November 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3092566},
doi = {10.1145/3092566},
abstract = {Software security vulnerabilities are one of the critical issues in the realm of computer security. Due to their potential high severity impacts, many different approaches have been proposed in the past decades to mitigate the damages of software vulnerabilities. Machine-learning and data-mining techniques are also among the many approaches to address this issue. In this article, we provide an extensive review of the many different works in the field of software vulnerability analysis and discovery that utilize machine-learning and data-mining techniques. We review different categories of works in this domain, discuss both advantages and shortcomings, and point out challenges and some uncharted territories in the field.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {56},
numpages = {36},
keywords = {survey, machine-learning, software security, review, Software vulnerability analysis, data-mining, software vulnerability discovery}
}

@article{10.1145/3439729,
author = {Deldjoo, Yashar and Noia, Tommaso Di and Merra, Felice Antonio},
title = {A Survey on Adversarial Recommender Systems: From Attack/Defense Strategies to Generative Adversarial Networks},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3439729},
doi = {10.1145/3439729},
abstract = {Latent-factor models (LFM) based on collaborative filtering (CF), such as matrix factorization (MF) and deep CF methods, are widely used in modern recommender systems (RS) due to their excellent performance and recommendation accuracy. However, success has been accompanied with a major new arising challenge: Many applications of machine learning (ML) are adversarial in nature [146]. In recent years, it has been shown that these methods are vulnerable to adversarial examples, i.e., subtle but non-random perturbations designed to force recommendation models to produce erroneous outputs.The goal of this survey is two-fold: (i) to present recent advances on adversarial machine learning (AML) for the security of RS (i.e., attacking and defense recommendation models) and (ii) to show another successful application of AML in generative adversarial networks (GANs) for generative applications, thanks to their ability for learning (high-dimensional) data distributions. In this survey, we provide an exhaustive literature review of 76 articles published in major RS and ML journals and conferences. This review serves as a reference for the RS community working on the security of RS or on generative models using GANs to improve their quality.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {35},
numpages = {38},
keywords = {security, adversarial perturbation, privacy, robustness, Recommender systems, adversarial machine learning, generative adversarial network, min-max game}
}

@article{10.1145/3381028,
author = {Boukerche, Azzedine and Zheng, Lining and Alfandi, Omar},
title = {Outlier Detection: Methods, Models, and Classification},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3381028},
doi = {10.1145/3381028},
abstract = {Over the past decade, we have witnessed an enormous amount of research effort dedicated to the design of efficient outlier detection techniques while taking into consideration efficiency, accuracy, high-dimensional data, and distributed environments, among other factors. In this article, we present and examine these characteristics, current solutions, as well as open challenges and future research directions in identifying new outlier detection strategies. We propose a taxonomy of the recently designed outlier detection strategies while underlying their fundamental characteristics and properties. We also introduce several newly trending outlier detection methods designed for high-dimensional data, data streams, big data, and minimally labeled data. Last, we review their advantages and limitations and then discuss future and new challenging issues.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {55},
numpages = {37},
keywords = {anomaly detection, semi-supervised learning, unsupervised learning, Outlier detection}
}

@article{10.1145/3301285,
author = {Bhat, Parnika and Dutta, Kamlesh},
title = {A Survey on Various Threats and Current State of Security in Android Platform},
year = {2019},
issue_date = {February 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3301285},
doi = {10.1145/3301285},
abstract = {The advent of the Android system has brought smartphone technology to the doorsteps of the masses. The latest technologies have made it affordable for every section of the society. However, the emergence of the Android platform has also escalated the growth of cybercrime through the mobile platform. Its open source operating system has made it a center of attraction for the attackers. This article provides a comprehensive study of the state of the Android Security domain. This article classifies the attacks on the Android system in four categories (i) hardware-based attacks, (ii) kernel-based attacks, (iii) hardware abstraction layer-based attacks, and (iv) application-based attacks. The study deals with various threats and security measures relating to these categories and presents an in-depth analysis of the underlying problems in the Android security domain. The article also stresses the role of Android application developers in realizing a more secure Android environment. This article attempts to provide a comparative analysis of various malware detection techniques concerning their methods and limitations. The study can help researchers gain knowledge of the Android security domain from various aspects and build a more comprehensive, robust, and efficient solution to the threats that Android is facing.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {21},
numpages = {35},
keywords = {malware detection, Android, malware, intra library collusion, privilege escalation}
}

@article{10.1145/3309550,
author = {Sundararajan, Aditya and Sarwat, Arif I. and Pons, Alexander},
title = {A Survey on Modality Characteristics, Performance Evaluation Metrics, and Security for Traditional and Wearable Biometric Systems},
year = {2019},
issue_date = {May 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3309550},
doi = {10.1145/3309550},
abstract = {Biometric research is directed increasingly toward Wearable Biometric Systems (WBS) for user authentication and identification. However, prior to engaging in WBS research, how their operational dynamics and design considerations differ from those of Traditional Biometric Systems (TBS) must be understood. While the current literature is cognizant of those differences, there is no effective work that summarizes the factors where TBS and WBS differ, namely, their modality characteristics, performance, security, and privacy. To bridge the gap, this article accordingly reviews and compares the key characteristics of modalities, contrasts the metrics used to evaluate system performance, and highlights the divergence in critical vulnerabilities, attacks, and defenses for TBS and WBS. It further discusses how these factors affect the design considerations for WBS, the open challenges, and future directions of research in these areas. In doing so, the article provides a big-picture overview of the important avenues of challenges and potential solutions that researchers entering the field should be aware of. Hence, this survey aims to be a starting point for researchers in comprehending the fundamental differences between TBS and WBS before understanding the core challenges associated with WBS and its design.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {39},
numpages = {36},
keywords = {WBAN, threats, vulnerabilities, wearables, attacks, Biometrics, metrics}
}

@article{10.1145/2963145,
author = {Xu, Meng and Song, Chengyu and Ji, Yang and Shih, Ming-Wei and Lu, Kangjie and Zheng, Cong and Duan, Ruian and Jang, Yeongjin and Lee, Byoungyoung and Qian, Chenxiong and Lee, Sangho and Kim, Taesoo},
title = {Toward Engineering a Secure Android Ecosystem: A Survey of Existing Techniques},
year = {2016},
issue_date = {November 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2963145},
doi = {10.1145/2963145},
abstract = {The openness and extensibility of Android have made it a popular platform for mobile devices and a strong candidate to drive the Internet-of-Things. Unfortunately, these properties also leave Android vulnerable, attracting attacks for profit or fun. To mitigate these threats, numerous issue-specific solutions have been proposed. With the increasing number and complexity of security problems and solutions, we believe this is the right moment to step back and systematically re-evaluate the Android security architecture and security practices in the ecosystem. We organize the most recent security research on the Android platform into two categories: the software stack and the ecosystem. For each category, we provide a comprehensive narrative of the problem space, highlight the limitations of the proposed solutions, and identify open problems for future research. Based on our collection of knowledge, we envision a blueprint for engineering a secure, next-generation Android ecosystem.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {38},
numpages = {47},
keywords = {survey, Android, mobile malware, ecosystem}
}

@article{10.1145/3442181,
author = {Sabir, Bushra and Ullah, Faheem and Babar, M. Ali and Gaire, Raj},
title = {Machine Learning for Detecting Data Exfiltration: A Review},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3442181},
doi = {10.1145/3442181},
abstract = {Context: Research at the intersection of cybersecurity, Machine Learning (ML), and Software Engineering (SE) has recently taken significant steps in proposing countermeasures for detecting sophisticated data exfiltration attacks. It is important to systematically review and synthesize the ML-based data exfiltration countermeasures for building a body of knowledge on this important topic. Objective: This article aims at systematically reviewing ML-based data exfiltration countermeasures to identify and classify ML approaches, feature engineering techniques, evaluation datasets, and performance metrics used for these countermeasures. This review also aims at identifying gaps in research on ML-based data exfiltration countermeasures. Method: We used Systematic Literature Review (SLR) method to select and review 92 papers. Results: The review has enabled us to: (a) classify the ML approaches used in the countermeasures into data-driven, and behavior-driven approaches; (b) categorize features into six types: behavioral, content-based, statistical, syntactical, spatial, and temporal; (c) classify the evaluation datasets into simulated, synthesized, and real datasets; and (d) identify 11 performance measures used by these studies. Conclusion: We conclude that: (i) The integration of data-driven and behavior-driven approaches should be explored; (ii) There is a need of developing high quality and large size evaluation datasets; (iii) Incremental ML model training should be incorporated in countermeasures; (iv) Resilience to adversarial learning should be considered and explored during the development of countermeasures to avoid poisoning attacks; and (v) The use of automated feature engineering should be encouraged for efficiently detecting data exfiltration attacks.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {50},
numpages = {47},
keywords = {advanced persistent threat, Data exfiltration, machine learning, data breach, data leakage}
}

@article{10.1145/3425780,
author = {Mirsky, Yisroel and Lee, Wenke},
title = {The Creation and Detection of Deepfakes: A Survey},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3425780},
doi = {10.1145/3425780},
abstract = {Generative deep learning algorithms have progressed to a point where it is difficult to tell the difference between what is real and what is fake. In 2018, it was discovered how easy it is to use this technology for unethical and malicious applications, such as the spread of misinformation, impersonation of political leaders, and the defamation of innocent individuals. Since then, these “deepfakes” have advanced significantly.In this article, we explore the creation and detection of deepfakes and provide an in-depth view as to how these architectures work. The purpose of this survey is to provide the reader with a deeper understanding of (1) how deepfakes are created and detected, (2) the current trends and advancements in this domain, (3) the shortcomings of the current defense solutions, and (4) the areas that require further research and attention.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {7},
numpages = {41},
keywords = {reenactment, replacement, Deepfake, social engineering, deep fake, face swap, generative AI, impersonation}
}

@article{10.1145/3417978,
author = {Qiu, Junyang and Zhang, Jun and Luo, Wei and Pan, Lei and Nepal, Surya and Xiang, Yang},
title = {A Survey of Android Malware Detection with Deep Neural Models},
year = {2020},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3417978},
doi = {10.1145/3417978},
abstract = {Deep Learning (DL) is a disruptive technology that has changed the landscape of cyber security research. Deep learning models have many advantages over traditional Machine Learning (ML) models, particularly when there is a large amount of data available. Android malware detection or classification qualifies as a big data problem because of the fast booming number of Android malware, the obfuscation of Android malware, and the potential protection of huge values of data assets stored on the Android devices. It seems a natural choice to apply DL on Android malware detection. However, there exist challenges for researchers and practitioners, such as choice of DL architecture, feature extraction and processing, performance evaluation, and even gathering adequate data of high quality. In this survey, we aim to address the challenges by systematically reviewing the latest progress in DL-based Android malware detection and classification. We organize the literature according to the DL architecture, including FCN, CNN, RNN, DBN, AE, and hybrid models. The goal is to reveal the research frontier, with the focus on representing code semantics for Android malware detection. We also discuss the challenges in this emerging field and provide our view of future research opportunities and directions.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {126},
numpages = {36},
keywords = {Android malware, malware detection, deep learning, neural network, feature representation, machine learning}
}

@article{10.1145/3446372,
author = {Alharbi, Ahmed and Dong, Hai and Yi, Xun and Tari, Zahir and Khalil, Ibrahim},
title = {Social Media Identity Deception Detection: A Survey},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3446372},
doi = {10.1145/3446372},
abstract = {Social media have been growing rapidly and become essential elements of many people’s lives. Meanwhile, social media have also come to be a popular source for identity deception. Many social media identity deception cases have arisen over the past few years. Recent studies have been conducted to prevent and detect identity deception. This survey analyzes various identity deception attacks, which can be categorized into fake profile, identity theft, and identity cloning. This survey provides a detailed review of social media identity deception detection techniques. It also identifies primary research challenges and issues in the existing detection techniques. This article is expected to benefit both researchers and social media providers.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {69},
numpages = {35},
keywords = {sockpuppet, identity theft, social botnet, Sybil, fake profile, detection techniques, identity cloning, Identity deception}
}

@article{10.1145/3003816,
author = {Gardiner, Joseph and Nagaraja, Shishir},
title = {On the Security of Machine Learning in Malware C&amp;C Detection: A Survey},
year = {2016},
issue_date = {December 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3003816},
doi = {10.1145/3003816},
abstract = {One of the main challenges in security today is defending against malware attacks. As trends and anecdotal evidence show, preventing these attacks, regardless of their indiscriminate or targeted nature, has proven difficult: intrusions happen and devices get compromised, even at security-conscious organizations. As a consequence, an alternative line of work has focused on detecting and disrupting the individual steps that follow an initial compromise and are essential for the successful progression of the attack. In particular, several approaches and techniques have been proposed to identify the command and control (C8C) channel that a compromised system establishes to communicate with its controller.A major oversight of many of these detection techniques is the design’s resilience to evasion attempts by the well-motivated attacker. C8C detection techniques make widespread use of a machine learning (ML) component. Therefore, to analyze the evasion resilience of these detection techniques, we first systematize works in the field of C8C detection and then, using existing models from the literature, go on to systematize attacks against the ML components used in these approaches.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {59},
numpages = {39},
keywords = {machine learning, botnets, network intrusion, data mining, Command and control channels}
}

@article{10.1145/3191329,
author = {Zhauniarovich, Yury and Khalil, Issa and Yu, Ting and Dacier, Marc},
title = {A Survey on Malicious Domains Detection through DNS Data Analysis},
year = {2018},
issue_date = {September 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3191329},
doi = {10.1145/3191329},
abstract = {Malicious domains are one of the major resources required for adversaries to run attacks over the Internet. Due to the important role of the Domain Name System (DNS), extensive research has been conducted to identify malicious domains based on their unique behavior reflected in different phases of the life cycle of DNS queries and responses. Existing approaches differ significantly in terms of intuitions, data analysis methods as well as evaluation methodologies. This warrants a thorough systematization of the approaches and a careful review of the advantages and limitations of every group.In this article, we perform such an analysis. To achieve this goal, we present the necessary background knowledge on DNS and malicious activities leveraging DNS. We describe a general framework of malicious domain detection techniques using DNS data. Applying this framework, we categorize existing approaches using several orthogonal viewpoints, namely (1) sources of DNS data and their enrichment, (2) data analysis methods, and (3) evaluation strategies and metrics. In each aspect, we discuss the important challenges that the research community should address in order to fully realize the power of DNS data analysis to fight against attacks leveraging malicious domains.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {67},
numpages = {36},
keywords = {Malicious domains detection, domain name system}
}

@article{10.1145/2635673,
author = {Laszka, Aron and Felegyhazi, Mark and Buttyan, Levente},
title = {A Survey of Interdependent Information Security Games},
year = {2014},
issue_date = {January 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2635673},
doi = {10.1145/2635673},
abstract = {Risks faced by information system operators and users are not only determined by their own security posture, but are also heavily affected by the security-related decisions of others. This interdependence between information system operators and users is a fundamental property that shapes the efficiency of security defense solutions. Game theory is the most appropriate method to model the strategic interactions between these participants. In this survey, we summarize game-theoretic interdependence models, characterize the emerging security inefficiencies, and present mechanisms to improve the security decisions of the participants. We focus our attention on games with interdependent defenders and do not discuss two-player attacker-defender games. Our goal is to distill the main insights from the state of the art and to identify the areas that need more attention from the research community.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {23},
numpages = {38},
keywords = {externality, security economics, security games, Interdependent security}
}

@article{10.1145/2856126,
author = {Sgandurra, Daniele and Lupu, Emil},
title = {Evolution of Attacks, Threat Models, and Solutions for Virtualized Systems},
year = {2016},
issue_date = {February 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2856126},
doi = {10.1145/2856126},
abstract = {Virtualization technology enables Cloud providers to efficiently use their computing services and resources. Even if the benefits in terms of performance, maintenance, and cost are evident, however, virtualization has also been exploited by attackers to devise new ways to compromise a system. To address these problems, research security solutions have evolved considerably over the years to cope with new attacks and threat models. In this work, we review the protection strategies proposed in the literature and show how some of the solutions have been invalidated by new attacks, or threat models, that were previously not considered. The goal is to show the evolution of the threats, and of the related security and trust assumptions, in virtualized systems that have given rise to complex threat models and the corresponding sophistication of protection strategies to deal with such attacks. We also categorize threat models, security and trust assumptions, and attacks against a virtualized system at the different layers—in particular, hardware, virtualization, OS, and application.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {46},
numpages = {38},
keywords = {Virtualization, threat models, Cloud computing, integrity attacks}
}

@article{10.1145/3429982,
author = {Alasad, Qutaiba and Lin, Jie and Yuan, Jiann-Shuin and Fan, Deliang and Awad, Amro},
title = {Resilient and Secure Hardware Devices Using ASL},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {2},
issn = {1550-4832},
url = {https://doi.org/10.1145/3429982},
doi = {10.1145/3429982},
abstract = {Due to the globalization of Integrated Circuit (IC) design in the semiconductor industry and the outsourcing of chip manufacturing, Third-Party Intellectual Properties (3PIPs) become vulnerable to IP piracy, reverse engineering, counterfeit IC, and hardware trojans. To thwart such attacks, ICs can be protected using logic encryption techniques. However, strong resilient techniques incur significant overheads. Side-channel attacks (SCAs) further complicate matters by introducing potential attacks post fabrication. One of the most severe SCAs is power analysis (PA) attacks, in which an attacker can observe the power variations of the device and analyze them to extract the secret key. PA attacks can be mitigated via adding large extra hardware; however, the overheads of such solutions can render them impractical, especially when there are power and area constraints.All Spin Logic Device (ASLD) is one of the most promising spintronic devices due to its unique properties: small area, no spin-charge signal conversion, zero leakage current, non-volatile memory, high density, low operating voltage, and its compatibility with conventional CMOS technology. In this article, we extend the work in Reference [1] on the usage of ASLD to produce secure and resilient circuits that withstand IC attacks (during the fabrication) and PA attacks (after fabrication), including reverse engineering attacks. First, we show that ASLD has another unique feature: identical power dissipation through the switching operations, where such properties can be effectively used to prevent PA and IC attacks. We then evaluate the proposed ASLD-based on performance overheads and security guarantees.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = jan,
articleno = {11},
numpages = {26},
keywords = {ASLD, Hardware security, emerging devices, reverse engineering attacks and defenses, logic encryption, side-channel analysis attacks and countermeasures}
}

@article{10.1145/2835375,
author = {Heartfield, Ryan and Loukas, George},
title = {A Taxonomy of Attacks and a Survey of Defence Mechanisms for Semantic Social Engineering Attacks},
year = {2015},
issue_date = {February 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2835375},
doi = {10.1145/2835375},
abstract = {Social engineering is used as an umbrella term for a broad spectrum of computer exploitations that employ a variety of attack vectors and strategies to psychologically manipulate a user. Semantic attacks are the specific type of social engineering attacks that bypass technical defences by actively manipulating object characteristics, such as platform or system applications, to deceive rather than directly attack the user. Commonly observed examples include obfuscated URLs, phishing emails, drive-by downloads, spoofed websites and scareware to name a few. This article presents a taxonomy of semantic attacks, as well as a survey of applicable defences. By contrasting the threat landscape and the associated mitigation techniques in a single comparative matrix, we identify the areas where further research can be particularly beneficial.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {37},
numpages = {39},
keywords = {semantic attacks, social engineering attacks, survey, Computer crime}
}

@article{10.1145/3305268,
author = {Islam, Chadni and Babar, Muhammad Ali and Nepal, Surya},
title = {A Multi-Vocal Review of Security Orchestration},
year = {2019},
issue_date = {May 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3305268},
doi = {10.1145/3305268},
abstract = {Organizations use diverse types of security solutions to prevent cyber-attacks. Multiple vendors provide security solutions developed using heterogeneous technologies and paradigms. Hence, it is a challenging rather impossible to easily make security solutions to work an integrated fashion. Security orchestration aims at smoothly integrating multivendor security tools that can effectively and efficiently interoperate to support security staff of a Security Operation Centre (SOC). Given the increasing role and importance of security orchestration, there has been an increasing amount of literature on different aspects of security orchestration solutions. However, there has been no effort to systematically review and analyze the reported solutions. We report a Multivocal Literature Review that has systematically selected and reviewed both academic and grey (blogs, web pages, white papers) literature on different aspects of security orchestration published from January 2007 until July 2017. The review has enabled us to provide a working definition of security orchestration and classify the main functionalities of security orchestration into three main areas—unification, orchestration, and automation. We have also identified the core components of a security orchestration platform and categorized the drivers of security orchestration based on technical and socio-technical aspects. We also provide a taxonomy of security orchestration based on the execution environment, automation strategy, deployment type, mode of task and resource type. This review has helped us to reveal several areas of further research and development in security orchestration.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {37},
numpages = {45},
keywords = {Security orchestration, intelligent security assistant, security automation, multivocal literature review}
}

@article{10.1145/3122816,
author = {Batalla, Jordi Mongay and Vasilakos, Athanasios and Gajewski, Mariusz},
title = {Secure Smart Homes: Opportunities and Challenges},
year = {2017},
issue_date = {November 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3122816},
doi = {10.1145/3122816},
abstract = {The Smart Home concept integrates smart applications in the daily human life. In recent years, Smart Homes have increased security and management challenges due to the low capacity of small sensors, multiple connectivity to the Internet for efficient applications (use of big data and cloud computing), and heterogeneity of home systems, which require inexpert users to configure devices and micro-systems. This article presents current security and management approaches in Smart Homes and shows the good practices imposed on the market for developing secure systems in houses. At last, we propose future solutions for efficiently and securely managing the Smart Homes.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {75},
numpages = {32},
keywords = {Smart Home, constrained devices, security, wireless sensor networks}
}

@article{10.1145/2767005,
author = {Ardagna, Claudio A. and Asal, Rasool and Damiani, Ernesto and Vu, Quang Hieu},
title = {From Security to Assurance in the Cloud: A Survey},
year = {2015},
issue_date = {September 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2767005},
doi = {10.1145/2767005},
abstract = {The cloud computing paradigm has become a mainstream solution for the deployment of business processes and applications. In the public cloud vision, infrastructure, platform, and software services are provisioned to tenants (i.e., customers and service providers) on a pay-as-you-go basis. Cloud tenants can use cloud resources at lower prices, and higher performance and flexibility, than traditional on-premises resources, without having to care about infrastructure management. Still, cloud tenants remain concerned with the cloud’s level of service and the nonfunctional properties their applications can count on. In the last few years, the research community has been focusing on the nonfunctional aspects of the cloud paradigm, among which cloud security stands out. Several approaches to security have been described and summarized in general surveys on cloud security techniques. The survey in this article focuses on the interface between cloud security and cloud security assurance. First, we provide an overview of the state of the art on cloud security. Then, we introduce the notion of cloud security assurance and analyze its growing impact on cloud security approaches. Finally, we present some recommendations for the development of next-generation cloud security and assurance solutions.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {2},
numpages = {50},
keywords = {survey, Assurance, security, transparency, cloud computing}
}

@article{10.1145/3376123,
author = {Sequeiros, Jo\~{a}o B. F. and Chimuco, Francisco T. and Samaila, Musa G. and Freire, M\'{a}rio M. and In\'{a}cio, Pedro R. M.},
title = {Attack and System Modeling Applied to IoT, Cloud, and Mobile Ecosystems: Embedding Security by Design},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3376123},
doi = {10.1145/3376123},
abstract = {Over the years, pervasive computing and communication technologies have enabled the emergence of new computing paradigms that have gained importance across a wide spectrum of domains. The three most notable that have witnessed significant advancements and have a solid track record of exponential growth in diverse applications are the Internet of Things (IoT), Cloud, and Mobile Computing. The ubiquity of these paradigms, their expandability, and applicability in different problem spaces have made them invaluable in modern computing solutions. Security becomes a real concern, especially when it comes to the development of applications in these environments, as numerous security issues may arise from potential design flaws. Secure application development across these three technologies can only be achieved when applications and systems are designed and developed with security in mind. This will improve the quality of the solutions and ensure that vulnerabilities are identified. It will also help in defining countermeasures against cyberattacks or mitigate the effects of potential threats to the systems. This article surveys existing approaches, tools, and techniques for attack and system modeling applicable to IoT, Cloud computing, and Mobile Computing. It also evaluates the strengths and limitations of the reviewed approaches and tools, from which it highlights the main existing challenges and open issues in the area.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {25},
numpages = {32},
keywords = {survey, Cloud computing, attack modeling, security, system modeling, IoT, Mobile computing}
}

@article{10.1145/3450964,
author = {Charles, Subodha and Mishra, Prabhat},
title = {A Survey of Network-on-Chip Security Attacks and Countermeasures},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3450964},
doi = {10.1145/3450964},
abstract = {With the advances of chip manufacturing technologies, computer architects have been able to integrate an increasing number of processors and other heterogeneous components on the same chip. Network-on-Chip (NoC) is widely employed by multicore System-on-Chip (SoC) architectures to cater to their communication requirements. NoC has received significant attention from both attackers and defenders. The increased usage of NoC and its distributed nature across the chip has made it a focal point of potential security attacks. Due to its prime location in the SoC coupled with connectivity with various components, NoC can be effectively utilized to implement security countermeasures to protect the SoC from potential attacks. There is a wide variety of existing literature on NoC security attacks and countermeasures. In this article, we provide a comprehensive survey of security vulnerabilities in NoC-based SoC architectures and discuss relevant countermeasures.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {101},
numpages = {36},
keywords = {Hardware security, machine learning}
}

@article{10.1145/3337772,
author = {Pawlick, Jeffrey and Colbert, Edward and Zhu, Quanyan},
title = {A Game-Theoretic Taxonomy and Survey of Defensive Deception for Cybersecurity and Privacy},
year = {2019},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3337772},
doi = {10.1145/3337772},
abstract = {Cyberattacks on both databases and critical infrastructure have threatened public and private sectors. Ubiquitous tracking and wearable computing have infringed upon privacy. Advocates and engineers have recently proposed using defensive deception as a means to leverage the information asymmetry typically enjoyed by attackers as a tool for defenders. The term deception, however, has been employed broadly and with a variety of meanings. In this article, we survey 24 articles from 2008 to 2018 that use game theory to model defensive deception for cybersecurity and privacy. Then, we propose a taxonomy that defines six types of deception: perturbation, moving target defense, obfuscation, mixing, honey-x, and attacker engagement. These types are delineated by their information structures, agents, actions, and duration: precisely concepts captured by game theory. Our aims are to rigorously define types of defensive deception, to capture a snapshot of the state of the literature, to provide a menu of models that can be used for applied research, and to identify promising areas for future work. Our taxonomy provides a systematic foundation for understanding different types of defensive deception commonly encountered in cybersecurity and privacy.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {82},
numpages = {28},
keywords = {taxonomy, honeypot, perturbation, moving target defense, obfuscation, attacker engagement, mix network, Cybersecurity, game theory, survey, deception, privacy}
}

@article{10.1145/2480741.2480757,
author = {P\'{e}k, G\'{a}bor and Butty\'{a}n, Levente and Bencs\'{a}th, Boldizs\'{a}r},
title = {A Survey of Security Issues in Hardware Virtualization},
year = {2013},
issue_date = {June 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2480741.2480757},
doi = {10.1145/2480741.2480757},
abstract = {Virtualization is a powerful technology for increasing the efficiency of computing services; however, besides its advantages, it also raises a number of security issues. In this article, we provide a thorough survey of those security issues in hardware virtualization. We focus on potential vulnerabilities and existing attacks on various virtualization platforms, but we also briefly sketch some possible countermeasures. To the best of our knowledge, this is the first survey of security issues in hardware virtualization with this level of details. Moreover, the adversary model and the structuring of the attack vectors are original contributions, never published before.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {40},
numpages = {34},
keywords = {operating systems, security, Hardware virtualization, malware}
}

@article{10.1145/3417987,
author = {Waheed, Nazar and He, Xiangjian and Ikram, Muhammad and Usman, Muhammad and Hashmi, Saad Sajid and Usman, Muhammad},
title = {Security and Privacy in IoT Using Machine Learning and Blockchain: Threats and Countermeasures},
year = {2020},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3417987},
doi = {10.1145/3417987},
abstract = {Security and privacy of users have become significant concerns due to the involvement of the Internet of Things (IoT) devices in numerous applications. Cyber threats are growing at an explosive pace making the existing security and privacy measures inadequate. Hence, everyone on the Internet is a product for hackers. Consequently, Machine Learning (ML) algorithms are used to produce accurate outputs from large complex databases, where the generated outputs can be used to predict and detect vulnerabilities in IoT-based systems. Furthermore, Blockchain (BC) techniques are becoming popular in modern IoT applications to solve security and privacy issues. Several studies have been conducted on either ML algorithms or BC techniques. However, these studies target either security or privacy issues using ML algorithms or BC techniques, thus posing a need for a combined survey on efforts made in recent years addressing both security and privacy issues using ML algorithms and BC techniques. In this article, we provide a summary of research efforts made in the past few years, from 2008 to 2019, addressing security and privacy issues using ML algorithms and BC techniques in the IoT domain. First, we discuss and categorize various security and privacy threats reported in the past 12 years in the IoT domain. We then classify the literature on security and privacy efforts based on ML algorithms and BC techniques in the IoT domain. Finally, we identify and illuminate several challenges and future research directions using ML algorithms and BC techniques to address security and privacy issues in the IoT domain.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {122},
numpages = {37},
keywords = {Blockchain, cybersecurity, Internet of Things, machine learning}
}

@article{10.1145/3359626,
author = {De Guzman, Jaybie A. and Thilakarathna, Kanchana and Seneviratne, Aruna},
title = {Security and Privacy Approaches in Mixed Reality: A Literature Survey},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3359626},
doi = {10.1145/3359626},
abstract = {Mixed reality (MR) technology development is now gaining momentum due to advances in computer vision, sensor fusion, and realistic display technologies. With most of the research and development focused on delivering the promise of MR, the privacy and security implications of this technology are yet to be thoroughly investigated. This survey article aims to put in to light these risks and to look into the latest security and privacy work on MR. Specifically, we list and review the different protection approaches that have been proposed to ensure user and data security and privacy in MR. We extend the scope to include work on related technologies such as augmented reality, virtual reality, and human-computer interaction as crucial components, if not the origins, of MR, as well as numerous related work from the larger area of mobile devices, wearables, and Internet-of-Things. We highlight the lack of investigation, implementation, and evaluation of data protection approaches in MR. Further challenges and directions on MR security and privacy are also discussed.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {110},
numpages = {37},
keywords = {augmented reality, privacy, security, Mixed reality}
}

@article{10.1145/3057268,
author = {Do, Cuong T. and Tran, Nguyen H. and Hong, Choongseon and Kamhoua, Charles A. and Kwiat, Kevin A. and Blasch, Erik and Ren, Shaolei and Pissinou, Niki and Iyengar, Sundaraja Sitharama},
title = {Game Theory for Cyber Security and Privacy},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3057268},
doi = {10.1145/3057268},
abstract = {In this survey, we review the existing game-theoretic approaches for cyber security and privacy issues, categorizing their application into two classes, security and privacy. To show how game theory is utilized in cyberspace security and privacy, we select research regarding three main applications: cyber-physical security, communication security, and privacy. We present game models, features, and solutions of the selected works and describe their advantages and limitations from design to implementation of the defense mechanisms. We also identify some emerging trends and topics for future research. This survey not only demonstrates how to employ game-theoretic approaches to security and privacy but also encourages researchers to employ game theory to establish a comprehensive understanding of emerging security and privacy problems in cyberspace and potential solutions.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {30},
numpages = {37},
keywords = {Game theory, cyber security, privacy}
}

@article{10.1145/3264628,
author = {Avoine, Gildas and Bing\"{o}l, Muhammed Ali and Boureanu, Ioana and \v{c}apkun, Srdjan and Hancke, Gerhard and Karda\c{s}, S\"{u}leyman and Kim, Chong Hee and Lauradoux, C\'{e}dric and Martin, Benjamin and Munilla, Jorge and Peinado, Alberto and Rasmussen, Kasper Bonne and Singel\'{e}e, Dave and Tchamkerten, Aslan and Trujillo-Rasua, Rolando and Vaudenay, Serge},
title = {Security of Distance-Bounding: A Survey},
year = {2018},
issue_date = {January 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3264628},
doi = {10.1145/3264628},
abstract = {Distance-bounding protocols allow a verifier to both authenticate a prover and evaluate whether the latter is located in his vicinity. These protocols are of particular interest in contactless systems, e.g., electronic payment or access control systems, which are vulnerable to distance-based frauds. This survey analyzes and compares in a unified manner many existing distance-bounding protocols with respect to several key security and complexity features.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {94},
numpages = {33},
keywords = {Information security, contactless, proximity check, distance-bounding, relay attacks, mafia fraud, terrorist fraud, cryptography, distance fraud}
}

@article{10.1145/2545883,
author = {Winkler, Thomas and Rinner, Bernhard},
title = {Security and Privacy Protection in Visual Sensor Networks: A Survey},
year = {2014},
issue_date = {July 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2545883},
doi = {10.1145/2545883},
abstract = {Visual sensor networks (VSNs) are receiving a lot of attention in research, and at the same time, commercial applications are starting to emerge. VSN devices come with image sensors, adequate processing power, and memory. They use wireless communication interfaces to collaborate and jointly solve tasks such as tracking persons within the network. VSNs are expected to replace not only many traditional, closed-circuit surveillance systems but also to enable emerging applications in scenarios such as elderly care, home monitoring, or entertainment. In all of these applications, VSNs monitor a potentially large group of people and record sensitive image data that might contain identities of persons, their behavior, interaction patterns, or personal preferences. These intimate details can be easily abused, for example, to derive personal profiles.The highly sensitive nature of images makes security and privacy in VSNs even more important than in most other sensor and data networks. However, the direct use of security techniques developed for related domains might be misleading due to the different requirements and design challenges. This is especially true for aspects such as data confidentiality and privacy protection against insiders, generating awareness among monitored people, and giving trustworthy feedback about recorded personal data—all of these aspects go beyond what is typically required in other applications.In this survey, we present an overview of the characteristics of VSN applications, the involved security threats and attack scenarios, and the major security challenges. A central contribution of this survey is our classification of VSN security aspects into data-centric, node-centric, network-centric, and user-centric security. We identify and discuss the individual security requirements and present a profound overview of related work for each class. We then discuss privacy protection techniques and identify recent trends in VSN security and privacy. A discussion of open research issues concludes this survey.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {2},
numpages = {42},
keywords = {Visual sensor networks, image sensor security, privacy protection}
}

@article{10.1145/2733306,
author = {Sufatrio and Tan, Darell J. J. and Chua, Tong-Wei and Thing, Vrizlynn L. L.},
title = {Securing Android: A Survey, Taxonomy, and Challenges},
year = {2015},
issue_date = {July 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2733306},
doi = {10.1145/2733306},
abstract = {Recent years have seen a global adoption of smart mobile devices, particularly those based on Android. However, Android’s widespread adoption is marred with increasingly rampant malware threats. This article gives a survey and taxonomy of existing works that secure Android devices. Based on Android app deployment stages, the taxonomy enables us to analyze schemes that share similar objective and approach and to inspect their key differences. Additionally, this article highlights the limitations of existing works and current challenges. It thus distills the state of the art in Android security research and identifies potential research directions for safeguarding billions (and keep counting) of Android-run devices.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {58},
numpages = {45},
keywords = {Android security, mobile security, Android, malware mitigation}
}

@article{10.1145/3439951,
author = {Dhar, Tapobrata and Roy, Surajit Kumar and Giri, Chandan},
title = {Hardware Trojan Horse Detection through Improved Switching of Dormant Nets},
year = {2021},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {3},
issn = {1550-4832},
url = {https://doi.org/10.1145/3439951},
doi = {10.1145/3439951},
abstract = {Covert Hardware Trojan Horses (HTH) introduced by malicious attackers during the fabless manufacturing process of integrated circuits (IC) have the potential to cause malignant functions within the circuit. This article employs a Design-for-Security technique to detect any HTHs present in the circuit by inserting tri-state buffers (TSB) in the ICs that inject the internal nets with weighted logic values during the test phase. This increases the transitions in the logic values of the nets within the IC, thereby stimulating any inserted HTH circuits. The TSBs are efficiently inserted in the IC considering various circuit parameters and testability measures to bolster the transitions in logic values of the nets throughout the IC while minimising the area overhead. Simulation results show a significant increase in transitions in logic values within HTH triggers using this method, thus aiding in their detection through side-channel analysis or direct activation of the payload.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = may,
articleno = {33},
numpages = {22},
keywords = {clustering, design for security, Hardware trojan horses, transition probability}
}

@article{10.1145/3284748,
author = {Boukerche, Azzedine and Zhang, Qi},
title = {Countermeasures against Worm Spreading: A New Challenge for Vehicular Networks},
year = {2019},
issue_date = {May 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3284748},
doi = {10.1145/3284748},
abstract = {Vehicular ad hoc networks (VANETs) are essential components of the intelligent transport systems. They are attracting an increasing amount of interest in research and industrial sectors. Vehicular nodes are capable of transporting, sensing, processing information, and wireless communication, which makes them more vulnerable to worm infections than conventional hosts. This survey provides an overview on worm spreading over VANETs. We first briefly introduce the computer worms. Then the V2X communication and applications are discussed from malware and worms propagation perspective to show the indispensability of studying the characteristics of worm propagating on VANETs. The recent literature on worm spreading and containment on VANETs are categorized based on their research methods. The improvements and limitations of the existing studies are discussed. Next, the main factors influencing worm spreading in vehicular networks are discussed followed by a summary of countermeasure strategies designed to deal with these worms.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {34},
numpages = {25},
keywords = {VANETs, LTE-vehicle, malware, worms, information diffusion, worm containment}
}

@article{10.1145/2825026,
author = {Avoine, Gildas and Beaujeant, Antonin and Hernandez-Castro, Julio and Demay, Louis and Teuwen, Philippe},
title = {A Survey of Security and Privacy Issues in EPassport Protocols},
year = {2016},
issue_date = {February 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2825026},
doi = {10.1145/2825026},
abstract = {This article examines in great detail the most relevant security and privacy issues affecting the protocols used by contactless chips integrated in ePassports, and presents all relevant literature together with some new attacks and insights that could help in improving future standards and the next generations of ePassports.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {47},
numpages = {37},
keywords = {Information security, identification of persons, cryptography, forensics, privacy, smartcards}
}

@article{10.1145/3448977,
author = {Laranjeiro, Nuno and Agnelo, Jo\~{a}o and Bernardino, Jorge},
title = {A Systematic Review on Software Robustness Assessment},
year = {2021},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3448977},
doi = {10.1145/3448977},
abstract = {Robustness is the degree to which a certain system or component can operate correctly in the presence of invalid inputs or stressful environmental conditions. With the increasing complexity and widespread use of computer systems, obtaining assurances regarding their robustness has become of vital importance. This survey discusses the state of the art on software robustness assessment, with emphasis on key aspects like types of systems being evaluated, assessment techniques used, the target of the techniques, the types of faults used, and how system behavior is classified. The survey concludes with the identification of gaps and open challenges related with robustness assessment.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {89},
numpages = {65},
keywords = {robustness testing, Software robustness, robustness evaluation}
}

@article{10.1145/3073559,
author = {Ye, Yanfang and Li, Tao and Adjeroh, Donald and Iyengar, S. Sitharama},
title = {A Survey on Malware Detection Using Data Mining Techniques},
year = {2017},
issue_date = {October 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3073559},
doi = {10.1145/3073559},
abstract = {In the Internet age, malware (such as viruses, trojans, ransomware, and bots) has posed serious and evolving security threats to Internet users. To protect legitimate users from these threats, anti-malware software products from different companies, including Comodo, Kaspersky, Kingsoft, and Symantec, provide the major defense against malware. Unfortunately, driven by the economic benefits, the number of new malware samples has explosively increased: anti-malware vendors are now confronted with millions of potential malware samples per year. In order to keep on combating the increase in malware samples, there is an urgent need to develop intelligent methods for effective and efficient malware detection from the real and large daily sample collection. In this article, we first provide a brief overview on malware as well as the anti-malware industry, and present the industrial needs on malware detection. We then survey intelligent malware detection methods. In these methods, the process of detection is usually divided into two stages: feature extraction and classification/clustering. The performance of such intelligent malware detection approaches critically depend on the extracted features and the methods for classification/clustering. We provide a comprehensive investigation on both the feature extraction and the classification/clustering techniques. We also discuss the additional issues and the challenges of malware detection using data mining techniques and finally forecast the trends of malware development.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {41},
numpages = {40},
keywords = {data mining, malware detection, Survey}
}

@article{10.1145/3234148,
author = {Tziakouris, Giannis and Bahsoon, Rami and Babar, Muhammad Ali},
title = {A Survey on Self-Adaptive Security for Large-Scale Open Environments},
year = {2018},
issue_date = {January 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3234148},
doi = {10.1145/3234148},
abstract = {Contemporary software systems operate in heterogeneous, dynamic, and distributed environments, where security needs change at runtime. The security solutions for such systems need to be adaptive for the continuous satisfaction of the software systems’ security goals. Whilst the existing research on self-adaptive security has made notable advancement towards designing and engineering self-adaptive security solutions, there exists little work on the taxonomic analysis of the architectures of the reported research and its applicability for open and ultra-large environments. We propose an architecture-centric taxonomy for mapping and comparing the current research and identifying the future research directions in this field. The proposed taxonomy has been used to review the representative work on the architectural characteristics that self-adaptive security systems must maintain for their effective application in large-scale open environments. We reflect on the findings from the taxonomic analysis and discuss the design principles, research challenges and limitations reported in the state of the art and practice. We outline the directions for the future research on architectural level support for self-adaptive security systems for large-scale open environments.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {100},
numpages = {42},
keywords = {ultra-large environments, Self-adaptive systems}
}

@article{10.1145/3337956,
author = {Moghaddam, Sara Kardani and Buyya, Rajkumar and Ramamohanarao, Kotagiri},
title = {Performance-Aware Management of Cloud Resources: A Taxonomy and Future Directions},
year = {2019},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3337956},
doi = {10.1145/3337956},
abstract = {The dynamic nature of the cloud environment has made the distributed resource management process a challenge for cloud service providers. The importance of maintaining quality of service in accordance with customer expectations and the highly dynamic nature of cloud-hosted applications add new levels of complexity to the process. Advances in big-data learning approaches have shifted conventional static capacity planning solutions to complex performance-aware resource management methods. It is shown that the process of decision-making for resource adjustment is closely related to the behavior of the system, including the utilization of resources and application components. Therefore, a continuous monitoring of system attributes and performance metrics provides the raw data for the analysis of problems affecting the performance of the application. Data analytic methods, such as statistical and machine-learning approaches, offer the required concepts, models, and tools to dig into the data and find general rules, patterns, and characteristics that define the functionality of the system. Obtained knowledge from the data analysis process helps to determine the changes in the workloads, faulty components, or problems that can cause system performance to degrade. A timely reaction to performance degradation can avoid violations of service level agreements, including performing proper corrective actions such as auto-scaling or other resource adjustment solutions. In this article, we investigate the main requirements and limitations of cloud resource management, including a study of the approaches to workload and anomaly analysis in the context of performance management in the cloud. A taxonomy of the works on this problem is presented that identifies main approaches in existing research from the data analysis side to resource adjustment techniques. Finally, considering the observed gaps in the general direction of the reviewed works, a list of these gaps is proposed for future researchers to pursue.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {84},
numpages = {37},
keywords = {big-data analytics, Anomaly detection, resource management, performance management}
}

@article{10.1145/2742642,
author = {Mukhopadhyay, Anirban and Maulik, Ujjwal and Bandyopadhyay, Sanghamitra},
title = {A Survey of Multiobjective Evolutionary Clustering},
year = {2015},
issue_date = {July 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2742642},
doi = {10.1145/2742642},
abstract = {Data clustering is a popular unsupervised data mining tool that is used for partitioning a given dataset into homogeneous groups based on some similarity/dissimilarity metric. Traditional clustering algorithms often make prior assumptions about the cluster structure and adopt a corresponding suitable objective function that is optimized either through classical techniques or metaheuristic approaches. These algorithms are known to perform poorly when the cluster assumptions do not hold in the data. Multiobjective clustering, in which multiple objective functions are simultaneously optimized, has emerged as an attractive and robust alternative in such situations. In particular, application of multiobjective evolutionary algorithms for clustering has become popular in the past decade because of their population-based nature. Here, we provide a comprehensive and critical survey of the multitude of multiobjective evolutionary clustering techniques existing in the literature. The techniques are classified according to the encoding strategies adopted, objective functions, evolutionary operators, strategy for maintaining nondominated solutions, and the method of selection of the final solution. The pros and cons of the different approaches are mentioned. Finally, we have discussed some real-life applications of multiobjective clustering in the domains of image segmentation, bioinformatics, web mining, and so forth.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {61},
numpages = {46},
keywords = {evolutionary algorithms, Clustering, multiobjective optimization, Pareto optimality}
}

@article{10.1145/2818184,
author = {Illiano, Vittorio P. and Lupu, Emil C.},
title = {Detecting Malicious Data Injections in Wireless Sensor Networks: A Survey},
year = {2015},
issue_date = {November 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2818184},
doi = {10.1145/2818184},
abstract = {Wireless Sensor Networks are widely advocated to monitor environmental parameters, structural integrity of the built environment and use of urban spaces, services and utilities. However, embedded sensors are vulnerable to compromise by external actors through malware but also through their wireless and physical interfaces. Compromised sensors can be made to report false measurements with the aim to produce inappropriate and potentially dangerous responses. Such malicious data injections can be particularly difficult to detect if multiple sensors have been compromised as they could emulate plausible sensor behaviour such as failures or detection of events where none occur. This survey reviews the related work on malicious data injection in wireless sensor networks, derives general principles and a classification of approaches within this domain, compares related studies and identifies areas that require further investigation.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {24},
numpages = {33},
keywords = {correlation, security, Wireless sensor networks}
}

@article{10.1145/3431389,
author = {Sisejkovic, Dominik and Merchant, Farhad and Reimann, Lennart M. and Srivastava, Harshit and Hallawa, Ahmed and Leupers, Rainer},
title = {Challenging the Security of Logic Locking Schemes in the Era of Deep Learning: A Neuroevolutionary Approach},
year = {2021},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {3},
issn = {1550-4832},
url = {https://doi.org/10.1145/3431389},
doi = {10.1145/3431389},
abstract = {Logic locking is a prominent technique to protect the integrity of hardware designs throughout the integrated circuit design and fabrication flow. However, in recent years, the security of locking schemes has been thoroughly challenged by the introduction of various deobfuscation attacks. As in most research branches, deep learning is being introduced in the domain of logic locking as well. Therefore, in this article we present SnapShot, a novel attack on logic locking that is the first of its kind to utilize artificial neural networks to directly predict a key bit value from a locked synthesized gate-level netlist without using a golden reference. Hereby, the attack uses a simpler yet more flexible learning model compared to existing work. Two different approaches are evaluated. The first approach is based on a simple feedforward fully connected neural network. The second approach utilizes genetic algorithms to evolve more complex convolutional neural network architectures specialized for the given task. The attack flow offers a generic and customizable framework for attacking locking schemes using machine learning techniques. We perform an extensive evaluation of SnapShot for two realistic attack scenarios, comprising both reference combinational and sequential benchmark circuits as well as silicon-proven RISC-V core modules. The evaluation results show that SnapShot achieves an average key prediction accuracy of 82.60% for the selected attack scenario, with a significant performance increase of 10.49 percentage points compared to the state of the art. Moreover, SnapShot outperforms the existing technique on all evaluated benchmarks. The results indicate that the security foundation of common logic locking schemes is built on questionable assumptions. Based on the lessons learned, we discuss the vulnerabilities and potentials of logic locking uncovered by SnapShot. The conclusions offer insights into the challenges of designing future logic locking schemes that are resilient to machine learning attacks.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = may,
articleno = {30},
numpages = {26},
keywords = {RISC-V, neuroevolution, logic locking, deep learning, IP protection}
}

@article{10.1145/3340960,
author = {Bae, Juhee and Helldin, Tove and Riveiro, Maria and Nowaczyk, S\l{}awomir and Bouguelia, Mohamed-Rafik and Falkman, G\"{o}ran},
title = {Interactive Clustering: A Comprehensive Review},
year = {2020},
issue_date = {May 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3340960},
doi = {10.1145/3340960},
abstract = {In this survey, 105 papers related to interactive clustering were reviewed according to seven perspectives: (1) on what level is the interaction happening, (2) which interactive operations are involved, (3) how user feedback is incorporated, (4) how interactive clustering is evaluated, (5) which data and (6) which clustering methods have been used, and (7) what outlined challenges there are. This article serves as a comprehensive overview of the field and outlines the state of the art within the area as well as identifies challenges and future research needs.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {1},
numpages = {39},
keywords = {Clustering, feedback, user, interactive, evaluation, interaction}
}

@article{10.1145/3393880,
author = {Guo, Bin and Ding, Yasan and Yao, Lina and Liang, Yunji and Yu, Zhiwen},
title = {The Future of False Information Detection on Social Media: New Perspectives and Trends},
year = {2020},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3393880},
doi = {10.1145/3393880},
abstract = {The massive spread of false information on social media has become a global risk, implicitly influencing public opinion and threatening social/political development. False information detection (FID) has thus become a surging research topic in recent years. As a promising and rapidly developing research field, we find that much effort has been paid to new research problems and approaches of FID. Therefore, it is necessary to give a comprehensive review of the new research trends of FID. We first give a brief review of the literature history of FID, based on which we present several new research challenges and techniques of it, including early detection, detection by multimodal data fusion, and explanatory detection. We further investigate the extraction and usage of various crowd intelligence in FID, which paves a promising way to tackle FID challenges. Finally, we give our views on the open issues and future research directions of FID, such as model adaptivity/generality to new events, embracing of novel machine learning models, aggregation of crowd wisdom, adversarial attack and defense in detection models, and so on.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {68},
numpages = {36},
keywords = {fake news, False information detection, explanatory detection, crowd intelligence, social media}
}

@article{10.1145/3303771,
author = {Homoliak, Ivan and Toffalini, Flavio and Guarnizo, Juan and Elovici, Yuval and Ochoa, Mart\'{\i}n},
title = {Insight Into Insiders and IT: A Survey of Insider Threat Taxonomies, Analysis, Modeling, and Countermeasures},
year = {2019},
issue_date = {May 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3303771},
doi = {10.1145/3303771},
abstract = {Insider threats are one of today’s most challenging cybersecurity issues that are not well addressed by commonly employed security solutions. In this work, we propose structural taxonomy and novel categorization of research that contribute to the organization and disambiguation of insider threat incidents and the defense solutions used against them. The objective of our categorization is to systematize knowledge in insider threat research while using an existing grounded theory method for rigorous literature review. The proposed categorization depicts the workflow among particular categories that include incidents and datasets, analysis of incidents, simulations, and defense solutions. Special attention is paid to the definitions and taxonomies of the insider threat; we present a structural taxonomy of insider threat incidents that is based on existing taxonomies and the 5W1H questions of the information gathering problem. Our survey will enhance researchers’ efforts in the domain of insider threat because it provides (1) a novel structural taxonomy that contributes to orthogonal classification of incidents and defining the scope of defense solutions employed against them, (2) an overview on publicly available datasets that can be used to test new detection solutions against other works, (3) references of existing case studies and frameworks modeling insiders’ behaviors for the purpose of reviewing defense solutions or extending their coverage, and (4) a discussion of existing trends and further research directions that can be used for reasoning in the insider threat domain.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {30},
numpages = {40},
keywords = {malicious insider threat, 5W1H questions, unintentional insider threat, masqueraders, traitors, Insider threat, grounded theory for rigorous literature review}
}

@article{10.1145/3410160,
author = {Matheu, Sara N. and Hern\'{a}ndez-Ramos, Jos\'{e} L. and Skarmeta, Antonio F. and Baldini, Gianmarco},
title = {A Survey of Cybersecurity Certification for the Internet of Things},
year = {2020},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3410160},
doi = {10.1145/3410160},
abstract = {In recent years, cybersecurity certification is gaining momentum as the baseline to build a structured approach to mitigate cybersecurity risks in the Internet of Things (IoT). This initiative is driven by industry, governmental institutions, and research communities, which have the goal to make IoT more secure for the end-users. In this survey, we analyze the current cybersecurity certification schemes, as well as the potential challenges to make them applicable for the IoT ecosystem. We also examine current efforts related to risk assessment and testing processes, which are widely recognized as the processes to build a cybersecurity certification framework. Our work provides a multidisciplinary perspective of a possible IoT cybersecurity certification framework by integrating research and technical tools and processes with policies and governance structures, which are analyzed against a set of identified challenges. This survey is intended to give a comprehensive overview of cybersecurity certification to facilitate the definition of a framework that fits in emerging scenarios, such as the IoT paradigm.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {115},
numpages = {36},
keywords = {labelling, IoT, security, Security certification, security risk assessment, security testing}
}

@article{10.1145/3199674,
author = {Huang, Keman and Siegel, Michael and Madnick, Stuart},
title = {Systematically Understanding the Cyber Attack Business: A Survey},
year = {2018},
issue_date = {September 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3199674},
doi = {10.1145/3199674},
abstract = {Cyber attacks are increasingly menacing businesses. Based on the literature review and publicly available reports, this article conducts an extensive and consistent survey of the services used by the cybercrime business, organized using the value chain perspective, to understand cyber attack in a systematic way. Understanding the specialization, commercialization, and cooperation for cyber attacks helps us to identify 24 key value-added activities and their relations. These can be offered “as a service” for use in a cyber attack. This framework helps to understand the cybercriminal service ecosystem and hacking innovations. Finally, a few examples are provided showing how this framework can help to build a more cyber immune system, like targeting cybercrime control-points and assigning defense responsibilities to encourage collaboration.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {70},
numpages = {36},
keywords = {cyber-crime-as-a-service, value chain model, cyber crime, hacking innovation, sharing responsibility, control point, Cyber attack business}
}

@article{10.1145/3017427,
author = {Tam, Kimberly and Feizollah, Ali and Anuar, Nor Badrul and Salleh, Rosli and Cavallaro, Lorenzo},
title = {The Evolution of Android Malware and Android Analysis Techniques},
year = {2017},
issue_date = {February 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3017427},
doi = {10.1145/3017427},
abstract = {With the integration of mobile devices into daily life, smartphones are privy to increasing amounts of sensitive information. Sophisticated mobile malware, particularly Android malware, acquire or utilize such data without user consent. It is therefore essential to devise effective techniques to analyze and detect these threats. This article presents a comprehensive survey on leading Android malware analysis and detection techniques, and their effectiveness against evolving malware. This article categorizes systems by methodology and date to evaluate progression and weaknesses. This article also discusses evaluations of industry solutions, malware statistics, and malware evasion techniques and concludes by supporting future research paths.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {76},
numpages = {41},
keywords = {malware, classification, dynamic analysis, Android, static analysis, detection}
}

@article{10.1145/2501654.2501657,
author = {Xie, Jierui and Kelley, Stephen and Szymanski, Boleslaw K.},
title = {Overlapping Community Detection in Networks: The State-of-the-Art and Comparative Study},
year = {2013},
issue_date = {August 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2501654.2501657},
doi = {10.1145/2501654.2501657},
abstract = {This article reviews the state-of-the-art in overlapping community detection algorithms, quality measures, and benchmarks. A thorough comparison of different algorithms (a total of fourteen) is provided. In addition to community-level evaluation, we propose a framework for evaluating algorithms' ability to detect overlapping nodes, which helps to assess overdetection and underdetection. After considering community-level detection performance measured by normalized mutual information, the Omega index, and node-level detection performance measured by F-score, we reached the following conclusions. For low overlapping density networks, SLPA, OSLOM, Game, and COPRA offer better performance than the other tested algorithms. For networks with high overlapping density and high overlapping diversity, both SLPA and Game provide relatively stable performance. However, test results also suggest that the detection in such networks is still not yet fully resolved. A common feature observed by various algorithms in real-world networks is the relatively small fraction of overlapping nodes (typically less than 30%), each of which belongs to only 2 or 3 communities.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {43},
numpages = {35},
keywords = {social networks, Overlapping community detection}
}

@article{10.1145/2501654.2501659,
author = {Rodr\'{\i}guez-G\'{o}mez, Rafael A. and Maci\'{a}-Fern\'{a}ndez, Gabriel and Garc\'{\i}a-Teodoro, Pedro},
title = {Survey and Taxonomy of Botnet Research through Life-Cycle},
year = {2013},
issue_date = {August 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2501654.2501659},
doi = {10.1145/2501654.2501659},
abstract = {Of all current threats to cybersecurity, botnets are at the top of the list. In consequence, interest in this problem is increasing rapidly among the research community and the number of publications on the question has grown exponentially in recent years. This article proposes a taxonomy of botnet research and presents a survey of the field to provide a comprehensive overview of all these contributions. Furthermore, we hope to provide researchers with a clear perspective of the gaps that remain to be filled in our defenses against botnets. The taxonomy is based upon the botnet's life-cycle, defined as the sequence of stages a botnet needs to pass through in order to reach its goal.This approach allows us to consider the problem of botnets from a global perspective, which constitutes a key difference from other taxonomies that have been proposed. Under this novel taxonomy, we conclude that all attempts to defeat botnets should be focused on one or more stages of this life-cycle. In fact, the sustained hindering of any of the stages makes it possible to thwart a botnet's progress and thus render it useless. We test the potential capabilities of our taxonomy by means of a survey of current botnet research, and find it genuinely useful in understanding the focus of the different contributions in this field.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {45},
numpages = {33},
keywords = {detection, Attack, defense, taxonomy, survey, botnet}
}

@article{10.1145/2946802,
author = {Alsabah, Mashael and Goldberg, Ian},
title = {Performance and Security Improvements for Tor: A Survey},
year = {2016},
issue_date = {November 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2946802},
doi = {10.1145/2946802},
abstract = {Tor [Dingledine et al. 2004] is the most widely used anonymity network today, serving millions of users on a daily basis using a growing number of volunteer-run routers. Since its deployment in 2003, there have been more than three dozen proposals that aim to improve its performance, security, and unobservability. Given the significance of this research area, our goal is to provide the reader with the state of current research directions and challenges in anonymous communication systems, focusing on the Tor network. We shed light on the design weaknesses and challenges facing the network and point out unresolved issues.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {32},
numpages = {36},
keywords = {performance, Privacy-enhancing technologies, anonymity networks}
}

@article{10.1145/3398394,
author = {Serban, Alex and Poll, Erik and Visser, Joost},
title = {Adversarial Examples on Object Recognition: A&nbsp;Comprehensive Survey},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3398394},
doi = {10.1145/3398394},
abstract = {Deep neural networks are at the forefront of machine learning research. However, despite achieving impressive performance on complex tasks, they can be very sensitive: Small perturbations of inputs can be sufficient to induce incorrect behavior. Such perturbations, called adversarial examples, are intentionally designed to test the network’s sensitivity to distribution drifts. Given their surprisingly small size, a wide body of literature conjectures on their existence and how this phenomenon can be mitigated. In this article, we discuss the impact of adversarial examples on security, safety, and robustness of neural networks. We start by introducing the hypotheses behind their existence, the methods used to construct or protect against them, and the capacity to transfer adversarial examples between different machine learning models. Altogether, the goal is to provide a comprehensive and self-contained survey of this growing field of research.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {66},
numpages = {38},
keywords = {machine learning, Adversarial examples, robustness, security}
}

@article{10.1145/3177848,
author = {Brandt, Tobias and Grawunder, Marco},
title = {GeoStreams: A Survey},
year = {2018},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3177848},
doi = {10.1145/3177848},
abstract = {Positional data from small and mobile Global Positioning Systems has become ubiquitous and allows for many new applications such as road traffic or vessel monitoring as well as location-based services. To make these applications possible, for which information on location is more important than ever, streaming spatial data needs to be managed, mined, and used intelligently. This article provides an overview of previous work in this evolving research field and discusses different applications as well as common problems and solutions. The conclusion indicates promising directions for future research.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {44},
numpages = {37},
keywords = {GeoStreams, data stream engines, data stream management systems}
}

@article{10.1145/2522968.2522978,
author = {Zhang, Xin and Yang, Yee-Hong and Han, Zhiguang and Wang, Hui and Gao, Chao},
title = {Object Class Detection: A Survey},
year = {2013},
issue_date = {October 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2522968.2522978},
doi = {10.1145/2522968.2522978},
abstract = {Object class detection, also known as category-level object detection, has become one of the most focused areas in computer vision in the new century. This article attempts to provide a comprehensive survey of the recent technical achievements in this area of research. More than 270 major publications are included in this survey covering different aspects of the research, which include: (i) problem description: key tasks and challenges; (ii) core techniques: appearance modeling, localization strategies, and supervised classification methods; (iii) evaluation issues: approaches, metrics, standard datasets, and state-of-the-art results; and (iv) new development: particularly new approaches and applications motivated by the recent boom of social images. Finally, in retrospect of what has been achieved so far, the survey also discusses what the future may hold for object class detection research.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {10},
numpages = {53},
keywords = {Object class detection, intra-class appearance variation, evaluation, categorization, appearance model, social images, segmentation}
}

@article{10.1145/3309545,
author = {Habibzadeh, Hadi and Kaptan, Cem and Soyata, Tolga and Kantarci, Burak and Boukerche, Azzedine},
title = {Smart City System Design: A Comprehensive Study of the Application and Data Planes},
year = {2019},
issue_date = {May 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3309545},
doi = {10.1145/3309545},
abstract = {Recent global smart city efforts resemble the establishment of electricity networks when electricity was first invented, which meant the start of a new era to sell electricity as a utility. A century later, in the smart era, the network to deliver services goes far beyond a single entity like electricity. Supplemented by a well-established Internet infrastructure that can run an endless number of applications, abundant processing and storage capabilities of clouds, resilient edge computing, and sophisticated data analysis like machine learning and deep learning, an already-booming Internet of Things movement makes this new era far more exciting.In this article, we present a multi-faceted survey of machine intelligence in modern implementations. We partition smart city infrastructure into application, sensing, communication, security, and data planes and put an emphasis on the data plane as the mainstay of computing and data storage. We investigate (i) a centralized and distributed implementation of data plane’s physical infrastructure and (ii) a complementary application of data analytics, machine learning, deep learning, and data visualization to implement robust machine intelligence in a smart city software core. We finalize our article with pointers to open issues and challenges.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {41},
numpages = {38},
keywords = {diagnostic, mobile computing, edge-computing, Crowdsensing, predictive, big data, and prescriptive analytics, cybersecurity, unsupervised learning, data science, smart sustainable cities, supervised learning, deep learning}
}

@article{10.1145/3331174,
author = {Usman, Muhammad and Jan, Mian Ahmad and He, Xiangjian and Chen, Jinjun},
title = {A Survey on Representation Learning Efforts in Cybersecurity Domain},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3331174},
doi = {10.1145/3331174},
abstract = {In this technology-based era, network-based systems are facing new cyber-attacks on daily bases. Traditional cybersecurity approaches are based on old threat-knowledge databases and need to be updated on a daily basis to stand against new generation of cyber-threats and protect underlying network-based systems. Along with updating threat-knowledge databases, there is a need for proper management and processing of data generated by sensitive real-time applications. In recent years, various computing platforms based on representation learning algorithms have emerged as a useful resource to manage and exploit the generated data to extract meaningful information. If these platforms are properly utilized, then strong cybersecurity systems can be developed to protect the underlying network-based systems and support sensitive real-time applications. In this survey, we highlight various cyber-threats, real-life examples, and initiatives taken by various international organizations. We discuss various computing platforms based on representation learning algorithms to process and analyze the generated data. We highlight various popular datasets introduced by well-known global organizations that can be used to train the representation learning algorithms to predict and detect threats. We also provide an in-depth analysis of research efforts based on representation learning algorithms made in recent years to protect the underlying network-based systems against current cyber-threats. Finally, we highlight various limitations and challenges in these efforts and available datasets that need to be considered when using them to build cybersecurity systems.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {111},
numpages = {28},
keywords = {datasets, computing, representation learning, cybersecurity, Cyber-attacks}
}

@article{10.1145/3372823,
author = {Kaloudi, Nektaria and Li, Jingyue},
title = {The AI-Based Cyber Threat Landscape: A Survey},
year = {2020},
issue_date = {May 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3372823},
doi = {10.1145/3372823},
abstract = {Recent advancements in artificial intelligence (AI) technologies have induced tremendous growth in innovation and automation. Although these AI technologies offer significant benefits, they can be used maliciously. Highly targeted and evasive attacks in benign carrier applications, such as DeepLocker, have demonstrated the intentional use of AI for harmful purposes. Threat actors are constantly changing and improving their attack strategy with particular emphasis on the application of AI-driven techniques in the attack process, called AI-based cyber attack, which can be used in conjunction with conventional attack techniques to cause greater damage. Despite several studies on AI and security, researchers have not summarized AI-based cyber attacks enough to be able to understand the adversary’s actions and to develop proper defenses against such attacks. This study aims to explore existing studies of AI-based cyber attacks and to map them onto a proposed framework, providing insight into new threats. Our framework includes the classification of several aspects of malicious uses of AI during the cyber attack life cycle and provides a basis for their detection to predict future threats. We also explain how to apply this framework to analyze AI-based cyber attacks in a hypothetical scenario of a critical smart grid infrastructure.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {20},
numpages = {34},
keywords = {AI attacks, Cybersecurity, attack analysis, cyber-physical systems, cyber threat prevention, smart grid}
}

@article{10.1145/3107614,
author = {Boukerche, Azzedine and Siddiqui, Abdul Jabbar and Mammeri, Abdelhamid},
title = {Automated Vehicle Detection and Classification: Models, Methods, and Techniques},
year = {2017},
issue_date = {November 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3107614},
doi = {10.1145/3107614},
abstract = {Automated Vehicle Classification (AVC) based on vision sensors has received active attention from researchers, due to heightened security concerns in Intelligent Transportation Systems. In this work, we propose a categorization of AVC studies based on the granularity of classification, namely Vehicle Type Recognition, Vehicle Make Recognition, and Vehicle Make and Model Recognition. For each category of AVC systems, we present a comprehensive review and comparison of features extraction, global representation, and classification techniques. We also present the accuracy and speed-related performance metrics and discuss how they can be used to compare and evaluate different AVC works. The various datasets proposed over the years for AVC are also compared in light of the real-world challenges they represent, and those they do not. The major challenges involved in each category of AVC systems are presented, highlighting open problems in this area of research. Finally, we conclude by providing future directions of research in this area, paving the way toward efficient large-scale AVC systems. This survey shall help researchers interested in the area to analyze works completed so far in each category of AVC, focusing on techniques proposed for each module, and to chalk out strategies to enhance state-of-the-art technology.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {62},
numpages = {39},
keywords = {smart city surveillance, vehicle detection, vehicle recognition, intelligent transportation system, vehicle localization, video surveillance, vehicle verification, Vehicle classification, target tracking, vehicle identification}
}

@article{10.1145/2767132,
author = {Barenghi, Alessandro and Bertoni, Guido M. and Breveglieri, Luca and Pelosi, Gerardo and Sanfilippo, Stefano and Susella, Ruggero},
title = {A Fault-Based Secret Key Retrieval Method for ECDSA: Analysis and Countermeasure},
year = {2016},
issue_date = {December 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {1550-4832},
url = {https://doi.org/10.1145/2767132},
doi = {10.1145/2767132},
abstract = {Elliptic curve cryptosystems proved to be well suited for securing systems with constrained resources like embedded and portable devices. In a fault-based attack, errors are induced during the computation of a cryptographic primitive, and the results are collected to derive information about the secret key safely stored in the device. We introduce a novel attack methodology to recover the secret key employed in implementations of the Elliptic Curve Digital Signature Algorithm. Our attack exploits the information leakage induced when altering the execution of the modular arithmetic operations used in the signature primitive and does not rely on the underlying elliptic curve mathematical structure, thus being applicable to all standardized curves. We provide both a validation of the feasibility of the attack, even employing common off-the-shelf hardware to perform the required computations, and a low-cost countermeasure to counteract it.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = apr,
articleno = {8},
numpages = {26},
keywords = {elliptic curve digital signature algorithm, fault attacks, cryptography, ECDSA, Digital signatures, embedded systems security}
}

@article{10.1145/3446374,
author = {Saxena, Divya and Cao, Jiannong},
title = {Generative Adversarial Networks (GANs): Challenges, Solutions, and Future Directions},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3446374},
doi = {10.1145/3446374},
abstract = {Generative Adversarial Networks (GANs) is a novel class of deep generative models that has recently gained significant attention. GANs learn complex and high-dimensional distributions implicitly over images, audio, and data. However, there exist major challenges in training of GANs, i.e., mode collapse, non-convergence, and instability, due to inappropriate design of network architectre, use of objective function, and selection of optimization algorithm. Recently, to address these challenges, several solutions for better design and optimization of GANs have been investigated based on techniques of re-engineered network architectures, new objective functions, and alternative optimization algorithms. To the best of our knowledge, there is no existing survey that has particularly focused on the broad and systematic developments of these solutions. In this study, we perform a comprehensive survey of the advancements in GANs design and optimization solutions proposed to handle GANs challenges. We first identify key research issues within each design and optimization technique and then propose a new taxonomy to structure solutions by key research issues. In accordance with the taxonomy, we provide a detailed discussion on different GANs variants proposed within each solution and their relationships. Finally, based on the insights gained, we present promising research directions in this rapidly growing field.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {63},
numpages = {42},
keywords = {Image generation, GANs applications, GANs variants, GANs, GANs challenges, computer vision, GANs Survey, deep Generative models, Generative Adversarial Networks, Deep learning, mode collapse}
}

@article{10.1145/3434398,
author = {Boukerche, Azzedine and Hou, Zhijun},
title = {Object Detection Using Deep Learning Methods in Traffic Scenarios},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3434398},
doi = {10.1145/3434398},
abstract = {The recent boom of autonomous driving nowadays has made object detection in traffic scenes a hot topic of research. Designed to classify and locate instances in the image, this is a basic but challenging task in the computer vision field. With its powerful feature extraction abilities, which are vital for object detection, deep learning has expanded its application areas to this field during the past several years and thus achieved breakthroughs. However, even with such powerful approaches, traffic scenarios have their own specific challenges, such as real-time detection, changeable weather, and complex lighting conditions. This survey is dedicated to summarizing research and papers on applying deep learning to the transportation environment in recent years. More than 100 research papers are covered, and different aspects such as key generic object detection frameworks, categorized object detection applications in traffic scenario, evaluation metrics, and classified datasets are included. Some open research fields are also provided. We believe that it is the first survey focusing on deep learning-based object detection in traffic scenario.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {30},
numpages = {35},
keywords = {deep learning, Object detection, vehicle detection, autonomous driving system, convolutional neural networks}
}

@article{10.1145/3161603,
author = {Zubiaga, Arkaitz and Aker, Ahmet and Bontcheva, Kalina and Liakata, Maria and Procter, Rob},
title = {Detection and Resolution of Rumours in Social Media: A Survey},
year = {2018},
issue_date = {June 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3161603},
doi = {10.1145/3161603},
abstract = {Despite the increasing use of social media platforms for information and news gathering, its unmoderated nature often leads to the emergence and spread of rumours, i.e., items of information that are unverified at the time of posting. At the same time, the openness of social media platforms provides opportunities to study how users share and discuss rumours, and to explore how to automatically assess their veracity, using natural language processing and data mining techniques. In this article, we introduce and discuss two types of rumours that circulate on social media: long-standing rumours that circulate for long periods of time, and newly emerging rumours spawned during fast-paced events such as breaking news, where reports are released piecemeal and often with an unverified status in their early stages. We provide an overview of research into social media rumours with the ultimate goal of developing a rumour classification system that consists of four components: rumour detection, rumour tracking, rumour stance classification, and rumour veracity classification. We delve into the approaches presented in the scientific literature for the development of each of these four components. We summarise the efforts and achievements so far toward the development of rumour classification systems and conclude with suggestions for avenues for future research in social media mining for the detection and resolution of rumours.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {32},
numpages = {36},
keywords = {rumour classification, rumour resolution, social media, veracity, Rumour detection, disinformation, misinformation}
}

@article{10.1145/2840724,
author = {Narayan, John and Shukla, Sandeep K. and Clancy, T. Charles},
title = {A Survey of Automatic Protocol Reverse Engineering Tools},
year = {2015},
issue_date = {February 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2840724},
doi = {10.1145/2840724},
abstract = {Computer network protocols define the rules in which two entities communicate over a network of unique hosts. Many protocol specifications are unknown, unavailable, or minimally documented, which prevents thorough analysis of the protocol for security purposes. For example, modern botnets often use undocumented and unique application-layer communication protocols to maintain command and control over numerous distributed hosts. Inferring the specification of closed protocols has numerous advantages, such as intelligent deep packet inspection, enhanced intrusion detection system algorithms for communications, and integration with legacy software packages. The multitude of closed protocols coupled with existing time-intensive reverse engineering methodologies has spawned investigation into automated approaches for reverse engineering of closed protocols. This article summarizes and organizes previously presented automatic protocol reverse engineering tools by approach. Approaches that focus on reverse engineering the finite state machine of a target protocol are separated from those that focus on reverse engineering the protocol format.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {40},
numpages = {26},
keywords = {Protocol reverse engineering, communication security}
}

@article{10.1145/3369026,
author = {K\"{u}\c{c}\"{u}k, Dilek and Can, Fazli},
title = {Stance Detection: A Survey},
year = {2020},
issue_date = {May 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3369026},
doi = {10.1145/3369026},
abstract = {Automatic elicitation of semantic information from natural language texts is an important research problem with many practical application areas. Especially after the recent proliferation of online content through channels such as social media sites, news portals, and forums; solutions to problems such as sentiment analysis, sarcasm/controversy/veracity/rumour/fake news detection, and argument mining gained increasing impact and significance, revealed with large volumes of related scientific publications. In this article, we tackle an important problem from the same family and present a survey of stance detection in social media posts and (online) regular texts. Although stance detection is defined in different ways in different application settings, the most common definition is “automatic classification of the stance of the producer of a piece of text, towards a target, into one of these three classes: {Favor, Against, Neither}.” Our survey includes definitions of related problems and concepts, classifications of the proposed approaches so far, descriptions of the relevant datasets and tools, and related outstanding issues. Stance detection is a recent natural language processing topic with diverse application areas, and our survey article on this newly emerging topic will act as a significant resource for interested researchers and practitioners.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {12},
numpages = {37},
keywords = {Twitter, Stance detection, social media analysis, deep learning}
}

@article{10.1145/3291047,
author = {Pinto, Sandro and Santos, Nuno},
title = {Demystifying Arm TrustZone: A Comprehensive Survey},
year = {2019},
issue_date = {February 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3291047},
doi = {10.1145/3291047},
abstract = {The world is undergoing an unprecedented technological transformation, evolving into a state where ubiquitous Internet-enabled “things” will be able to generate and share large amounts of security- and privacy-sensitive data. To cope with the security threats that are thus foreseeable, system designers can find in Arm TrustZone hardware technology a most valuable resource. TrustZone is a System-on-Chip and CPU system-wide security solution, available on today’s Arm application processors and present in the new generation Arm microcontrollers, which are expected to dominate the market of smart “things.” Although this technology has remained relatively underground since its inception in 2004, over the past years, numerous initiatives have significantly advanced the state of the art involving Arm TrustZone. Motivated by this revival of interest, this paper presents an in-depth study of TrustZone technology. We provide a comprehensive survey of relevant work from academia and industry, presenting existing systems into two main areas, namely, Trusted Execution Environments and hardware-assisted virtualization. Furthermore, we analyze the most relevant weaknesses of existing systems and propose new research directions within the realm of tiniest devices and the Internet of Things, which we believe to have potential to yield high-impact contributions in the future.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {130},
numpages = {36},
keywords = {virtualization, Arm, security, TEE, survey, TrustZone}
}

@article{10.1145/3444688,
author = {Magnani, Matteo and Hanteer, Obaida and Interdonato, Roberto and Rossi, Luca and Tagarelli, Andrea},
title = {Community Detection in Multiplex Networks},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3444688},
doi = {10.1145/3444688},
abstract = {A multiplex network models different modes of interaction among same-type entities. In this article, we provide a taxonomy of community detection algorithms in multiplex networks. We characterize the different algorithms based on various properties and we discuss the type of communities detected by each method. We then provide an extensive experimental evaluation of the reviewed methods to answer three main questions: to what extent the evaluated methods are able to detect ground-truth communities, to what extent different methods produce similar community structures, and to what extent the evaluated methods are scalable. One goal of this survey is to help scholars and practitioners to choose the right methods for the data and the task at hand, while also emphasizing when such choice is problematic.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {48},
numpages = {35},
keywords = {Community detection, multiplex networks, multiplex community detection}
}

@article{10.1145/2938639,
author = {Souza, \'{E}fren L. and Nakamura, Eduardo F. and Pazzi, Richard W.},
title = {Target Tracking for Sensor Networks: A Survey},
year = {2016},
issue_date = {November 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2938639},
doi = {10.1145/2938639},
abstract = {Target-tracking algorithms typically organize the network into a logical structure (e.g., tree, cluster, or faces) to enable data fusion and reduce communication costs. These algorithms often predict the target’s future position. In addition to using position forecasts for decision making, we can also use such information to save energy by activating only the set of sensors nearby the target’s trajectory. In this work, we survey of the state of the art of target-tracking techniques in sensor networks. We identify three different formulations for the target-tracking problem and classify the target-tracking algorithms based on common characteristics. Furthermore, for the sake of a better understanding of the target-tracking process, we organize this process in six components: target detection, node cooperation, position computation, future-position estimation, energy management, and target recovery. Each component has different solutions that affect the target-tracking performance.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {30},
numpages = {31},
keywords = {Kalman filter, particle filter, Target tracking}
}

@article{10.1145/3345317,
author = {Folt\'{y}nek, Tom\'{a}\v{s} and Meuschke, Norman and Gipp, Bela},
title = {Academic Plagiarism Detection: A Systematic Literature Review},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3345317},
doi = {10.1145/3345317},
abstract = {This article summarizes the research on computational methods to detect academic plagiarism by systematically reviewing 239 research papers published between 2013 and 2018. To structure the presentation of the research contributions, we propose novel technically oriented typologies for plagiarism prevention and detection efforts, the forms of academic plagiarism, and computational plagiarism detection methods. We show that academic plagiarism detection is a highly active research field. Over the period we review, the field has seen major advances regarding the automated detection of strongly obfuscated and thus hard-to-identify forms of academic plagiarism. These improvements mainly originate from better semantic text analysis methods, the investigation of non-textual content features, and the application of machine learning. We identify a research gap in the lack of methodologically thorough performance evaluations of plagiarism detection systems. Concluding from our analysis, we see the integration of heterogeneous analysis methods for textual and non-textual content features using machine learning as the most promising area for future research contributions to improve the detection of academic plagiarism further.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {112},
numpages = {42},
keywords = {text-matching software, literature review, machine learning, Plagiarism detection, semantic analysis}
}

@article{10.1145/3311951,
author = {Rateke, Thiago and Justen, Karla A. and Chiarella, Vito F. and Sobieranski, Antonio C. and Comunello, Eros and Wangenheim, Aldo Von},
title = {Passive Vision Region-Based Road Detection: A Literature Review},
year = {2019},
issue_date = {May 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3311951},
doi = {10.1145/3311951},
abstract = {We present a literature review to analyze the state of the art in the area of road detection based upon frontal images. For this purpose, a systematic literature review (SLR) was conducted that focuses on analyzing region-based works, since they can adapt to different surface types and do not depend on road geometry or lane markings. Through the comprehensive study of publications in a 11-year time frame, we analyze the methods that are being used, on which types of surface they are applied, whether they are adaptive in relation to surface changes, and whether they are able to distinguish possible faults or changes in the road, such as potholes, shadows, and puddles.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {31},
numpages = {34},
keywords = {visual navigation, passive vision, road segmentation, Systematic literature review, road detection}
}

@article{10.1145/3146389,
author = {Khalastchi, Eliahu and Kalech, Meir},
title = {On Fault Detection and Diagnosis in Robotic Systems},
year = {2018},
issue_date = {April 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3146389},
doi = {10.1145/3146389},
abstract = {The use of robots in our daily lives is increasing. Different types of robots perform different tasks that are too dangerous or too dull to be done by humans. These sophisticated machines are susceptible to different types of faults. These faults have to be detected and diagnosed in time to allow recovery and continuous operation. The field of Fault Detection and Diagnosis (FDD) has been studied for many years. This research has given birth to many approaches and techniques that are applicable to different types of physical machines. Yet the domain of robotics poses unique requirements that are very challenging for traditional FDD approaches. The study of FDD for robotics is relatively new, and only few surveys were presented. These surveys have focused on traditional FDD approaches and how these approaches may broadly apply to a generic type of robot. Yet robotic systems can be identified by fundamental characteristics, which pose different constraints and requirements from FDD. In this article, we aim to provide the reader with useful insights regarding the use of FDD approaches that best suit the different characteristics of robotic systems. We elaborate on the advantages these approaches have and the challenges they must face. To meet this aim, we use two perspectives: (1) we elaborate on FDD from the perspective of the different characteristics a robotic system may have and give examples of successful FDD approaches, and (2) we elaborate on FDD from the perspective of the different FDD approaches and analyze the advantages and disadvantages of each approach with respect to robotic systems. Finally, we describe research opportunities for robotic systems’ FDD. With these three contributions, readers from the FDD research communities are introduced to FDD for robotic systems, and the robotics research community is introduced to the field of FDD.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {9},
numpages = {24},
keywords = {robots, fault diagnosis, Fault detection}
}

@article{10.1145/3419100,
author = {Turan, Furkan and Verbauwhede, Ingrid},
title = {Trust in FPGA-Accelerated Cloud Computing},
year = {2020},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3419100},
doi = {10.1145/3419100},
abstract = {Platforms combining Central Processing Systems (CPUs) with Field Programmable Gate Arrays (FPGAs) have become popular, as they promise high performance with energy efficiency. This is the result of the combination of FPGA accelerators tuned to the application, with the CPU providing the programming flexibility. Unfortunately, the security of these new platforms has received little attention: The classic software security assumption that hardware is immutable no longer holds. It is expected that attack surfaces will expand and threats will evolve, hence the trust models, and security solutions should be prepared. The attacker model should be enhanced and consider the following three basic entities as the source of threats: applications run by users, accelerators designed by third-party developers, and the cloud service providers enabling the computation on their platforms. In our work, we review current trust models and existing security assumptions and point out their shortcomings. We survey existing research that target secure remote FPGA configuration, the protection of intellectual property, and secure shared use of FPGAs. When combined, these are the foundations to build a solution for secure use of FPGAs in the cloud. In addition to analysing the existing research, we provide discussions on how to improve it and disclose various concerns that have not been addressed yet.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {128},
numpages = {28},
keywords = {CPU, trust, security, FPGA}
}

@article{10.1145/2480741.2480747,
author = {Gomes, Jo\~{a}o V. and In\'{a}cio, Pedro R. M. and Pereira, Manuela and Freire, M\'{a}rio M. and Monteiro, Paulo P.},
title = {Detection and Classification of Peer-to-Peer Traffic: A Survey},
year = {2013},
issue_date = {June 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2480741.2480747},
doi = {10.1145/2480741.2480747},
abstract = {The emergence of new Internet paradigms has changed the common properties of network data, increasing the bandwidth consumption and balancing traffic in both directions. These facts raise important challenges, making it necessary to devise effective solutions for managing network traffic. Since traditional methods are rather ineffective and easily bypassed, particular attention has been paid to the development of new approaches for traffic classification. This article surveys the studies on peer-to-peer traffic detection and classification, making an extended review of the literature. Furthermore, it provides a comprehensive analysis of the concepts and strategies for network monitoring.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {30},
numpages = {40},
keywords = {traffic monitoring, peer-to-peer, deep packet inspection, Application classification, behavioral analysis}
}

@article{10.1145/3186585,
author = {RASTGOO, Mohammad Naim and Nakisa, Bahareh and Rakotonirainy, Andry and Chandran, Vinod and Tjondronegoro, Dian},
title = {A Critical Review of Proactive Detection of Driver Stress Levels Based on Multimodal Measurements},
year = {2018},
issue_date = {January 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3186585},
doi = {10.1145/3186585},
abstract = {Stress is a major concern in daily life, as it imposes significant and growing health and economic costs on society every year. Stress and driving are a dangerous combination and can lead to life-threatening situations, evidenced by the large number of road traffic crashes that occur every year due to driver stress. In addition, the rate of general health issues caused by work-related chronic stress in drivers who work in public and private transport is greater than in many other occupational groups. An in-vehicle warning system for driver stress levels is needed to continuously predict dangerous driving situations and proactively alert drivers to ensure safe and comfortable driving. As a result of the recent developments in ambient intelligence, such as sensing technologies, pervasive devices, context recognition, and communications, driver stress can be automatically detected using multimodal measurements. This critical review investigates the state of the art of techniques and achievements for automatic driver stress level detection based on multimodal sensors and data. In this work, the most widely used data followed by frequent and highly performed selected features to detect driver stress levels are analyzed and presented. This review also discusses key methodological issues and gaps that hinder the implementation of driver stress detection systems and offers insights into future research directions.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {88},
numpages = {35},
keywords = {physical signals, EDA, physiological signals, contextual data, machine learning, real-time stress recognition system, respiration, vehicle dynamic data, Driver stress level detection, multimodality, ECG}
}

@article{10.1145/2791577,
author = {Xu, Tianyin and Zhou, Yuanyuan},
title = {Systems Approaches to Tackling Configuration Errors: A Survey},
year = {2015},
issue_date = {July 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2791577},
doi = {10.1145/2791577},
abstract = {In recent years, configuration errors (i.e., misconfigurations) have become one of the dominant causes of system failures, resulting in many severe service outages and downtime. Unfortunately, it is notoriously difficult for system users (e.g., administrators and operators) to prevent, detect, and troubleshoot configuration errors due to the complexity of the configurations as well as the systems under configuration. As a result, the cost of resolving configuration errors is often tremendous from the aspects of both compensating the service disruptions and diagnosing, recovering from the failures. The prevalence, severity, and cost have made configuration errors one of the most thorny system problems that desire to be addressed.This survey article provides a holistic and structured overview of the systems approaches that tackle configuration errors. To understand the problem fundamentally, we first discuss the characteristics of configuration errors and the challenges of tackling such errors. Then, we discuss the state-of-the-art systems approaches that address different types of configuration errors in different scenarios. Our primary goal is to equip the stakeholder with a better understanding of configuration errors and the potential solutions for resolving configuration errors in the spectrum of system development and management. To inspire follow-up research, we further discuss the open problems with regard to system configuration. To the best of our knowledge, this is the first survey on the topic of tackling configuration errors.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {70},
numpages = {41},
keywords = {deployment, troubleshooting, vulnerability, validation, diagnosis, Configuration, management, configuration error, testing, failure, detection, automation, misconfiguration}
}

@article{10.1145/3436755,
author = {Liu, Bo and Ding, Ming and Shaham, Sina and Rahayu, Wenny and Farokhi, Farhad and Lin, Zihuai},
title = {When Machine Learning Meets Privacy: A Survey and Outlook},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3436755},
doi = {10.1145/3436755},
abstract = {The newly emerged machine learning (e.g., deep learning) methods have become a strong driving force to revolutionize a wide range of industries, such as smart healthcare, financial technology, and surveillance systems. Meanwhile, privacy has emerged as a big concern in this machine learning-based artificial intelligence era. It is important to note that the problem of privacy preservation in the context of machine learning is quite different from that in traditional data privacy protection, as machine learning can act as both friend and foe. Currently, the work on the preservation of privacy and machine learning are still in an infancy stage, as most existing solutions only focus on privacy problems during the machine learning process. Therefore, a comprehensive study on the privacy preservation problems and machine learning is required. This article surveys the state of the art in privacy issues and solutions for machine learning. The survey covers three categories of interactions between privacy and machine learning: (i) private machine learning, (ii) machine learning-aided privacy protection, and (iii) machine learning-based privacy attack and corresponding protection schemes. The current research progress in each category is reviewed and the key challenges are identified. Finally, based on our in-depth analysis of the area of privacy and machine learning, we point out future research directions in this field.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {31},
numpages = {36},
keywords = {privacy, Machine learning, deep learning, differential privacy}
}

@article{10.1145/3394898,
author = {Stanley-Marbell, Phillip and Alaghi, Armin and Carbin, Michael and Darulova, Eva and Dolecek, Lara and Gerstlauer, Andreas and Gillani, Ghayoor and Jevdjic, Djordje and Moreau, Thierry and Cacciotti, Mattia and Daglis, Alexandros and Jerger, Natalie Enright and Falsafi, Babak and Misailovic, Sasa and Sampson, Adrian and Zufferey, Damien},
title = {Exploiting Errors for Efficiency: A Survey from Circuits to Applications},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3394898},
doi = {10.1145/3394898},
abstract = {When a computational task tolerates a relaxation of its specification or when an algorithm tolerates the effects of noise in its execution, hardware, system software, and programming language compilers or their runtime systems can trade deviations from correct behavior for lower resource usage. We present, for the first time, a synthesis of research results on computing systems that only make as many errors as their end-to-end applications can tolerate. The results span the disciplines of computer-aided design of circuits, digital system design, computer architecture, programming languages, operating systems, and information theory. Rather than over-provisioning the resources controlled by each of these layers of abstraction to avoid errors, it can be more efficient to exploit the masking of errors occurring at one layer and thereby prevent those errors from propagating to a higher layer.We demonstrate the potential benefits of end-to-end approaches using two illustrative examples. We introduce a formalization of terminology that allows us to present a coherent view across the techniques traditionally used by different research communities in their individual layer of focus. Using this formalization, we survey tradeoffs for individual layers of computing systems at the circuit, architecture, operating system, and programming language levels as well as fundamental information-theoretic limits to tradeoffs between resource usage and correctness.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {51},
numpages = {39},
keywords = {error efficiency, cross-layer optimization, Approximate computing}
}

@article{10.1145/3395046,
author = {Zhou, Xinyi and Zafarani, Reza},
title = {A Survey of Fake News: Fundamental Theories, Detection Methods, and Opportunities},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3395046},
doi = {10.1145/3395046},
abstract = {The explosive growth in fake news and its erosion to democracy, justice, and public trust has increased the demand for fake news detection and intervention. This survey reviews and evaluates methods that can detect fake news from four perspectives: the false knowledge it carries, its writing style, its propagation patterns, and the credibility of its source. The survey also highlights some potential research tasks based on the review. In particular, we identify and detail related fundamental theories across various disciplines to encourage interdisciplinary research on fake news. It is our hope that this survey can facilitate collaborative efforts among experts in computer and information sciences, social sciences, political science, and journalism to research fake news, where such efforts can lead to fake news detection that is not only efficient but, more importantly, explainable.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {109},
numpages = {40},
keywords = {deception detection, information credibility, misinformation, disinformation, social media, Fake news, news verification, fact-checking, knowledge graph}
}

@article{10.1145/2988546,
author = {Steiner, Rodrigo Vieira and Lupu, Emil},
title = {Attestation in Wireless Sensor Networks: A Survey},
year = {2016},
issue_date = {December 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2988546},
doi = {10.1145/2988546},
abstract = {Attestation is a mechanism used by a trusted entity to validate the software integrity of an untrusted platform. Over the past few years, several attestation techniques have been proposed. While they all use variants of a challenge-response protocol, they make different assumptions about what an attacker can and cannot do. Thus, they propose intrinsically divergent validation approaches. We survey in this article the different approaches to attestation, focusing in particular on those aimed at Wireless Sensor Networks. We discuss the motivations, challenges, assumptions, and attacks of each approach. We then organise them into a taxonomy and discuss the state of the art, carefully analysing the advantages and disadvantages of each proposal. We also point towards the open research problems and give directions on how to address them.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {51},
numpages = {31},
keywords = {Attestation, wireless sensor networks}
}

@article{10.1145/3064834,
author = {Houshmand, Mahboobeh and Sedighi, Mehdi and Zamani, Morteza Saheb and Marjoei, Kourosh},
title = {Quantum Circuit Synthesis Targeting to Improve One-Way Quantum Computation Pattern Cost Metrics},
year = {2017},
issue_date = {August 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
issn = {1550-4832},
url = {https://doi.org/10.1145/3064834},
doi = {10.1145/3064834},
abstract = {One-way quantum computation (1WQC) is a model of universal quantum computations in which a specific highly entangled state called a cluster state allows for quantum computation by single-qubit measurements. The needed computations in this model are organized as measurement patterns. The traditional approach to obtain a measurement pattern is by translating a quantum circuit that solely consists of CZ and J(α) gates into the corresponding measurement patterns and then performing some optimizations by using techniques proposed for the 1WQC model. However, in these cases, the input of the problem is a quantum circuit, not an arbitrary unitary matrix. Therefore, in this article, we focus on the first phase—that is, decomposing a unitary matrix into CZ and J(α) gates. Two well-known quantum circuit synthesis methods, namely cosine-sine decomposition and quantum Shannon decomposition are considered and then adapted for a library of gates containing CZ and J(α), equipped with optimizations. By exploring the solution space of the combinations of these two methods in a bottom-up approach of dynamic programming, a multiobjective quantum circuit synthesis method is proposed that generates a set of quantum circuits. This approach attempts to simultaneously improve the measurement pattern cost metrics after the translation from this set of quantum circuits.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = may,
articleno = {55},
numpages = {27},
keywords = {quantum circuits, Measurement patterns, one-way quantum computation, multiobjective optimization, synthesis}
}

@article{10.1145/3429740,
author = {Xu, Weitao and Zhang, Junqing and Huang, Shunqi and Luo, Chengwen and Li, Wei},
title = {Key Generation for Internet of Things: A Contemporary Survey},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3429740},
doi = {10.1145/3429740},
abstract = {Key generation is a promising technique to bootstrap secure communications for the Internet of Things devices that have no prior knowledge between each other. In the past few years, a variety of key generation protocols and systems have been proposed. In this survey, we review and categorise recent key generation systems based on a novel taxonomy. Then, we provide both quantitative and qualitative comparisons of existing approaches. We also discuss the security vulnerabilities of key generation schemes and possible countermeasures. Finally, we discuss the current challenges and point out several potential research directions.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {14},
numpages = {37},
keywords = {authentication, key generation, IoT, device pairing}
}

@article{10.1145/3182658,
author = {Shirazi, Fatemeh and Simeonovski, Milivoj and Asghar, Muhammad Rizwan and Backes, Michael and Diaz, Claudia},
title = {A Survey on Routing in Anonymous Communication Protocols},
year = {2018},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3182658},
doi = {10.1145/3182658},
abstract = {The Internet has undergone dramatic changes in the past 2 decades and now forms a global communication platform that billions of users rely on for their daily activities. While this transformation has brought tremendous benefits to society, it has also created new threats to online privacy, such as omnipotent governmental surveillance. As a result, public interest in systems for anonymous communication has drastically increased. In this work, we survey previous research on designing, developing, and deploying systems for anonymous communication. Our taxonomy and comparative assessment provide important insights about the differences between the existing classes of anonymous communication protocols.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {51},
numpages = {39},
keywords = {routing protocols, communication networks, Anonymous communication}
}

@article{10.1145/3301282,
author = {Hong, Yongjun and Hwang, Uiwon and Yoo, Jaeyoon and Yoon, Sungroh},
title = {How Generative Adversarial Networks and Their Variants Work: An Overview},
year = {2019},
issue_date = {February 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3301282},
doi = {10.1145/3301282},
abstract = {Generative Adversarial Networks (GANs) have received wide attention in the machine learning field for their potential to learn high-dimensional, complex real data distribution. Specifically, they do not rely on any assumptions about the distribution and can generate real-like samples from latent space in a simple manner. This powerful property allows GANs to be applied to various applications such as image synthesis, image attribute editing, image translation, domain adaptation, and other academic fields. In this article, we discuss the details of GANs for those readers who are familiar with, but do not comprehend GANs deeply or who wish to view GANs from various perspectives. In addition, we explain how GANs operates and the fundamental meaning of various objective functions that have been suggested recently. We then focus on how the GAN can be combined with an autoencoder framework. Finally, we enumerate the GAN variants that are applied to various tasks and other fields for those who are interested in exploiting GANs for their research.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {10},
numpages = {43},
keywords = {integral probability metric, domain adaptation, semi-supervised learning, mode collapse, Generative adversarial networks, variational auto-encoder}
}

@article{10.1145/3349265,
author = {Barua, Hrishav Bakul and Mondal, Kartick Chandra},
title = {A Comprehensive Survey on Cloud Data Mining (CDM) Frameworks and Algorithms},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3349265},
doi = {10.1145/3349265},
abstract = {Data mining is used for finding meaningful information out of a vast expanse of data. With the advent of Big Data concept, data mining has come to much more prominence. Discovering knowledge out of a gigantic volume of data efficiently is a major concern as the resources are limited. Cloud computing plays a major role in such a situation. Cloud data mining fuses the applicability of classical data mining with the promises of cloud computing. This allows it to perform knowledge discovery out of huge volumes of data with efficiency. This article presents the existing frameworks, services, platforms, and algorithms for cloud data mining. The frameworks and platforms are compared among each other based on similarity, data mining task support, parallelism, distribution, streaming data processing support, fault tolerance, security, memory types, storage systems, and others. Similarly, the algorithms are grouped on the basis of parallelism type, scalability, streaming data mining support, and types of data managed. We have also provided taxonomies on the basis of data mining techniques such as clustering, classification, and association rule mining. We also have attempted to discuss and identify the major applications of cloud data mining. The various taxonomies for cloud data mining frameworks, platforms, and algorithms have been identified. This article aims at gaining better insight into the present research realm and directing the future research toward efficient cloud data mining in future cloud systems.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {104},
numpages = {62},
keywords = {velocity, taxonomy, survey, framework, cloud computing, distributed computing, Review, data mining, variety, volume, big data analytics, big data, parallelism, graph mining, clustering, cloud data mining (CDM), classification and association rule mining, data science, machine learning}
}

@article{10.1145/2807593,
author = {Baudry, Benoit and Monperrus, Martin},
title = {The Multiple Facets of Software Diversity: Recent Developments in Year 2000 and Beyond},
year = {2015},
issue_date = {September 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2807593},
doi = {10.1145/2807593},
abstract = {Early experiments with software diversity in the mid 1970s investigated N-version programming and recovery blocks to increase the reliability of embedded systems. Four decades later, the literature about software diversity has expanded in multiple directions: goals (fault tolerance, security, software engineering), means (managed or automated diversity), and analytical studies (quantification of diversity and its impact). Our article contributes to the field of software diversity as the first work that adopts an inclusive vision of the area, with an emphasis on the most recent advances in the field. This survey includes classical work about design and data diversity for fault tolerance, as well as the cybersecurity literature that investigates randomization at different system levels. It broadens this standard scope of diversity to include the study and exploitation of natural diversity and the management of diverse software products. Our survey includes the most recent works, with an emphasis from 2000 to the present. The targeted audience is researchers and practitioners in one of the surveyed fields who miss the big picture of software diversity. Assembling the multiple facets of this fascinating topic sheds a new light on the field.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {16},
numpages = {26},
keywords = {program transformation, Software diversity, design principles}
}

@article{10.1145/2906149,
author = {Khan, Suleman and Gani, Abdullah and Wahab, Ainuddin Wahid Abdul and Bagiwa, Mustapha Aminu and Shiraz, Muhammad and Khan, Samee U. and Buyya, Rajkumar and Zomaya, Albert Y.},
title = {Cloud Log Forensics: Foundations, State of the Art, and Future Directions},
year = {2016},
issue_date = {July 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2906149},
doi = {10.1145/2906149},
abstract = {Cloud log forensics (CLF) mitigates the investigation process by identifying the malicious behavior of attackers through profound cloud log analysis. However, the accessibility attributes of cloud logs obstruct accomplishment of the goal to investigate cloud logs for various susceptibilities. Accessibility involves the issues of cloud log access, selection of proper cloud log file, cloud log data integrity, and trustworthiness of cloud logs. Therefore, forensic investigators of cloud log files are dependent on cloud service providers (CSPs) to get access of different cloud logs. Accessing cloud logs from outside the cloud without depending on the CSP is a challenging research area, whereas the increase in cloud attacks has increased the need for CLF to investigate the malicious activities of attackers. This paper reviews the state of the art of CLF and highlights different challenges and issues involved in investigating cloud log data. The logging mode, the importance of CLF, and cloud log-as-a-service are introduced. Moreover, case studies related to CLF are explained to highlight the practical implementation of cloud log investigation for analyzing malicious behaviors. The CLF security requirements, vulnerability points, and challenges are identified to tolerate different cloud log susceptibilities. We identify and introduce challenges and future directions to highlight open research areas of CLF for motivating investigators, academicians, and researchers to investigate them.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {7},
numpages = {42},
keywords = {integrity, Cloud computing, big data, correlation of cloud logs, cloud log forensics, authenticity, confidentiality}
}

@article{10.1145/2682899,
author = {D'mello, Sidney K. and Kory, Jacqueline},
title = {A Review and Meta-Analysis of Multimodal Affect Detection Systems},
year = {2015},
issue_date = {April 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2682899},
doi = {10.1145/2682899},
abstract = {Affect detection is an important pattern recognition problem that has inspired researchers from several areas. The field is in need of a systematic review due to the recent influx of Multimodal (MM) affect detection systems that differ in several respects and sometimes yield incompatible results. This article provides such a survey via a quantitative review and meta-analysis of 90 peer-reviewed MM systems. The review indicated that the state of the art mainly consists of person-dependent models (62.2% of systems) that fuse audio and visual (55.6%) information to detect acted (52.2%) expressions of basic emotions and simple dimensions of arousal and valence (64.5%) with feature- (38.9%) and decision-level (35.6%) fusion techniques. However, there were also person-independent systems that considered additional modalities to detect nonbasic emotions and complex dimensions using model-level fusion techniques. The meta-analysis revealed that MM systems were consistently (85% of systems) more accurate than their best unimodal counterparts, with an average improvement of 9.83% (median of 6.60%). However, improvements were three times lower when systems were trained on natural (4.59%) versus acted data (12.7%). Importantly, MM accuracy could be accurately predicted (cross-validated R2 of 0.803) from unimodal accuracies and two system-level factors. Theoretical and applied implications and recommendations are discussed.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {43},
numpages = {36},
keywords = {Affective computing, evaluation, survey, methodology, human-centered computing}
}

@article{10.1145/2767007,
author = {Naveed, Muhammad and Ayday, Erman and Clayton, Ellen W. and Fellay, Jacques and Gunter, Carl A. and Hubaux, Jean-Pierre and Malin, Bradley A. and Wang, Xiaofeng},
title = {Privacy in the Genomic Era},
year = {2015},
issue_date = {September 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2767007},
doi = {10.1145/2767007},
abstract = {Genome sequencing technology has advanced at a rapid pace and it is now possible to generate highly-detailed genotypes inexpensively. The collection and analysis of such data has the potential to support various applications, including personalized medical services. While the benefits of the genomics revolution are trumpeted by the biomedical community, the increased availability of such data has major implications for personal privacy; notably because the genome has certain essential features, which include (but are not limited to) (i) an association with traits and certain diseases, (ii) identification capability (e.g., forensics), and (iii) revelation of family relationships. Moreover, direct-to-consumer DNA testing increases the likelihood that genome data will be made available in less regulated environments, such as the Internet and for-profit companies. The problem of genome data privacy thus resides at the crossroads of computer science, medicine, and public policy. While the computer scientists have addressed data privacy for various data types, there has been less attention dedicated to genomic data. Thus, the goal of this paper is to provide a systematization of knowledge for the computer science community. In doing so, we address some of the (sometimes erroneous) beliefs of this field and we report on a survey we conducted about genome data privacy with biomedical specialists. Then, after characterizing the genome privacy problem, we review the state-of-the-art regarding privacy attacks on genomic data and strategies for mitigating such attacks, as well as contextualizing these attacks from the perspective of medicine and public policy. This paper concludes with an enumeration of the challenges for genome data privacy and presents a framework to systematize the analysis of threats and the design of countermeasures as the field moves forward.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {6},
numpages = {44},
keywords = {health care, recreational genomics, Genomics privacy, biomedical research, security}
}

@article{10.1145/3440755,
author = {Chandrasekaran, Dhivya and Mago, Vijay},
title = {Evolution of Semantic Similarity—A Survey},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3440755},
doi = {10.1145/3440755},
abstract = {Estimating the semantic similarity between text data is one of the challenging and open research problems in the field of Natural Language Processing (NLP). The versatility of natural language makes it difficult to define rule-based methods for determining semantic similarity measures. To address this issue, various semantic similarity methods have been proposed over the years. This survey article traces the evolution of such methods beginning from traditional NLP techniques such as kernel-based methods to the most recent research work on transformer-based models, categorizing them based on their underlying principles as knowledge-based, corpus-based, deep neural network–based methods, and hybrid methods. Discussing the strengths and weaknesses of each method, this survey provides a comprehensive view of existing systems in place for new researchers to experiment and develop innovative ideas to address the issue of semantic similarity.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {41},
numpages = {37},
keywords = {knowledge-based methods, linguistics, Semantic similarity, corpus-based methods, supervised and unsupervised methods, word embeddings}
}

@article{10.1145/3310331,
author = {Gr\"{o}ndahl, Tommi and Asokan, N.},
title = {Text Analysis in Adversarial Settings: Does Deception Leave a Stylistic Trace?},
year = {2019},
issue_date = {July 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3310331},
doi = {10.1145/3310331},
abstract = {Textual deception constitutes a major problem for online security. Many studies have argued that deceptiveness leaves traces in writing style, which could be detected using text classification techniques. By conducting an extensive literature review of existing empirical work, we demonstrate that while certain linguistic features have been indicative of deception in certain corpora, they fail to generalize across divergent semantic domains. We suggest that deceptiveness as such leaves no content-invariant stylistic trace, and textual similarity measures provide a superior means of classifying texts as potentially deceptive. Additionally, we discuss forms of deception beyond semantic content, focusing on hiding author identity by writing style obfuscation. Surveying the literature on both author identification and obfuscation techniques, we conclude that current style transformation methods fail to achieve reliable obfuscation while simultaneously ensuring semantic faithfulness to the original text. We propose that future work in style transformation should pay particular attention to disallowing semantically drastic changes.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {45},
numpages = {36},
keywords = {Stylometry, text obfuscation, author identification, deanonymization, deception}
}

@article{10.1145/3388922,
author = {Welsh, Thomas and Benkhelifa, Elhadj},
title = {On Resilience in Cloud Computing: A Survey of Techniques across the Cloud Domain},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3388922},
doi = {10.1145/3388922},
abstract = {Cloud infrastructures are highly favoured as a computing delivery model worldwide, creating a strong societal dependence. It is therefore vital to enhance their resilience, providing persistent service delivery under a variety of conditions. Cloud environments are highly complex and continuously evolving. Additionally, the plethora of use-cases ensures requirements for persistent service delivery vary. As a contribution to knowledge, this work surveys resilience techniques for cloud environments. We apply a novel perspective using a layered model of traditional and emerging cloud paradigms. Works are then classified according to the Resilinets model. For each layer, the most common techniques with limitations are derived including an actor’s strength in influencing resilience in the cloud with each technique. We conclude with some future challenges to the field of resilient cloud computing.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {59},
numpages = {36},
keywords = {cloud, fog, edge, survey, Resilience}
}

@article{10.1145/3324473,
author = {Liao, Xiaofeng and Zhao, Zhiming},
title = {Unsupervised Approaches for Textual Semantic Annotation, A Survey},
year = {2019},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3324473},
doi = {10.1145/3324473},
abstract = {Semantic annotation is a crucial part of achieving the vision of the Semantic Web and has long been a research topic among various communities. The most challenging problem in reaching the Semantic Web’s real potential is the gap between a large amount of unlabeled existing/new data and the limited annotation capability available. To resolve this problem, numerous works have been carried out to increase the degree of automation of semantic annotation from manual to semi-automatic to fully automatic. The richness of these works has been well-investigated by numerous surveys focusing on different aspects of the problem. However, a comprehensive survey targeting unsupervised approaches for semantic annotation is still missing and is urgently needed. To better understand the state-of-the-art of semantic annotation in the textual domain adopting unsupervised approaches, this article investigates existing literature and presents a survey to answer three research questions: (1) To what extent can semantic annotation be performed in a fully automatic manner by using an unsupervised way? (2) What kind of unsupervised approaches for semantic annotation already exist in literature? (3) What characteristics and relationships do these approaches have?In contrast to existing surveys, this article helps the reader get an insight into the state-of-art of semantic annotation using unsupervised approaches. While examining the literature, this article also addresses the inconsistency in the terminology used in the literature to describe the various semantic annotation tools’ degree of automation and provides more consistent terminology. Based on this, a uniform summary of the degree of automation of the many semantic annotation tools that were previously investigated can now be presented.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {66},
numpages = {45},
keywords = {unsupervised, machine learning, entity linking, entity recognition, Semantic annotation, relation extraction, information extraction}
}

@article{10.1145/3446371,
author = {Haq, Irfan Ul and Caballero, Juan},
title = {A Survey of Binary Code Similarity},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3446371},
doi = {10.1145/3446371},
abstract = {Binary code similarityapproaches compare two or more pieces of binary code to identify their similarities and differences. The ability to compare binary code enables many real-world applications on scenarios where source code may not be available such as patch analysis, bug search, and malware detection and analysis. Over the past 22 years numerous binary code similarity approaches have been proposed, but the research area has not yet been systematically analyzed. This article presents the first survey of binary code similarity. It analyzes 70 binary code similarity approaches, which are systematized on four aspects: (1) the applications they enable, (2) their approach characteristics, (3) how the approaches are implemented, and (4) the benchmarks and methodologies used to evaluate them. In addition, the survey discusses the scope and origins of the area, its evolution over the past two decades, and the challenges that lie ahead.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {51},
numpages = {38},
keywords = {code diffing, Binary code similarity, cross-architecture, executable, code search}
}

@article{10.1145/3429252,
author = {Bellavista, Paolo and Foschini, Luca and Mora, Alessio},
title = {Decentralised Learning in Federated Deployment Environments: A System-Level Survey},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3429252},
doi = {10.1145/3429252},
abstract = {Decentralised learning is attracting more and more interest because it embodies the principles of data minimisation and focused data collection, while favouring the transparency of purpose specification (i.e., the objective for which a model is built). Cloud-centric-only processing and deep learning are no longer strict necessities to train high-fidelity models; edge devices can actively participate in the decentralised learning process by exchanging meta-level information in place of raw data, thus paving the way for better privacy guarantees. In addition, these new possibilities can relieve the network backbone from unnecessary data transfer and allow it to meet strict low-latency requirements by leveraging on-device model inference. This survey provides a detailed and up-to-date overview of the most recent contributions available in the state-of-the-art decentralised learning literature. In particular, it originally provides the reader audience with a clear presentation of the peculiarities of federated settings, with a novel taxonomy of decentralised learning approaches, and with a detailed description of the most relevant and specific system-level contributions of the surveyed solutions for privacy, communication efficiency, non-IIDness, device heterogeneity, and poisoning defense.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {15},
numpages = {38},
keywords = {poisoning defense, Decentralised learning, privacy, federated deployment, communication efficiency}
}

@article{10.1145/3447866,
author = {Boukerche, Azzedine and Ma, Xiren},
title = {Vision-Based Autonomous Vehicle Recognition: A New Challenge for Deep Learning-Based Systems},
year = {2021},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3447866},
doi = {10.1145/3447866},
abstract = {Vision-based Automated Vehicle Recognition (VAVR) has attracted considerable attention recently. Particularly given the reliance on emerging deep learning methods, which have powerful feature extraction and pattern learning abilities, vehicle recognition has made significant progress. VAVR is an essential part of Intelligent Transportation Systems. The VAVR system can fast and accurately locate a target vehicle, which significantly helps improve regional security. A comprehensive VAVR system contains three components: Vehicle Detection (VD), Vehicle Make and Model Recognition (VMMR), and Vehicle Re-identification (VRe-ID). These components perform coarse-to-fine recognition tasks in three steps. In this article, we conduct a thorough review and comparison of the state-of-the-art deep learning--based models proposed for VAVR. We present a detailed introduction to different vehicle recognition datasets used for a comprehensive evaluation of the proposed models. We also critically discuss the major challenges and future research trends involved in each task. Finally, we summarize the characteristics of the methods for each task. Our comprehensive model analysis will help researchers that are interested in VD, VMMR, and VRe-ID and provide them with possible directions to solve current challenges and further improve the performance and robustness of models.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {84},
numpages = {37},
keywords = {vehicle detection, fine-grained recognition, convolutional neural network, video surveillance, Deep learning, vehicle re-identification, vehicle make and model recognition, intelligent transportation system}
}

@article{10.1145/3234150,
author = {Pouyanfar, Samira and Sadiq, Saad and Yan, Yilin and Tian, Haiman and Tao, Yudong and Reyes, Maria Presa and Shyu, Mei-Ling and Chen, Shu-Ching and Iyengar, S. S.},
title = {A Survey on Deep Learning: Algorithms, Techniques, and Applications},
year = {2018},
issue_date = {January 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3234150},
doi = {10.1145/3234150},
abstract = {The field of machine learning is witnessing its golden era as deep learning slowly becomes the leader in this domain. Deep learning uses multiple layers to represent the abstractions of data to build computational models. Some key enabler deep learning algorithms such as generative adversarial networks, convolutional neural networks, and model transfers have completely changed our perception of information processing. However, there exists an aperture of understanding behind this tremendously fast-paced domain, because it was never previously represented from a multiscope perspective. The lack of core understanding renders these powerful methods as black-box machines that inhibit development at a fundamental level. Moreover, deep learning has repeatedly been perceived as a silver bullet to all stumbling blocks in machine learning, which is far from the truth. This article presents a comprehensive review of historical and recent state-of-the-art approaches in visual, audio, and text processing; social network analysis; and natural language processing, followed by the in-depth analysis on pivoting and groundbreaking advances in deep learning applications. It was also undertaken to review the issues faced in deep learning such as unsupervised learning, black-box models, and online learning and to illustrate how these challenges can be transformed into prolific future research avenues.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {92},
numpages = {36},
keywords = {Deep learning, neural networks, big data, distributed processing, survey, machine learning}
}

@article{10.1145/3447773,
author = {Luengo, Elena Almaraz and Villalba, Luis Javier Garc\'{\i}a},
title = {Recommendations on Statistical Randomness Test Batteries for Cryptographic Purposes},
year = {2021},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3447773},
doi = {10.1145/3447773},
abstract = {Security in different applications is closely related to the goodness of the sequences generated for such purposes. Not only in Cryptography but also in other areas, it is necessary to obtain long sequences of random numbers or that, at least, behave as such. To decide whether the generator used produces sequences that are random, unpredictable and independent, statistical checks are needed. Different batteries of hypothesis tests have been proposed for this purpose.In this work, a survey of the main test batteries is presented, indicating their pros and cons, giving some guidelines for their use and presenting some practical examples.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {80},
numpages = {34},
keywords = {Diehard, TRNG, SPRNG, quasi-random numbers, pseudo-random number, NIST, PRNG, hypothesis testing, TestU01, Knuth, Dieharder, Cryp-X, true random number}
}

@article{10.1145/3400030,
author = {Khan, Saad and Parkinson, Simon and Grant, Liam and Liu, Na and Mcguire, Stephen},
title = {Biometric Systems Utilising Health Data from Wearable Devices: Applications and Future Challenges in Computer Security},
year = {2020},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3400030},
doi = {10.1145/3400030},
abstract = {Health data are being increasingly sensed from the health-based wearable Internet of Things (IoT) devices, providing much-needed fitness and health tracking. However, data generated also present opportunities within computer security, specifically with biometric systems used for identification and authentication purposes. This article performs a systematic review of health-based IoT data collected from wearable IoT technology. This involved performing research in the underlying data sources, what they are collected for in terms of their health monitoring, and the underlying data characteristics. Furthermore, it explores existing work in computer security using these data sources, identifying key themes of work, key limitations, and challenges. Finally, key opportunities are provided as summaries to the potential of health-based IoT data, highlighting challenges that are yet to be addressed, which motivate areas of future work.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {85},
numpages = {29},
keywords = {biometrics, authentication, wearable technology, Health data}
}

@article{10.1145/3453444,
author = {Ashmore, Rob and Calinescu, Radu and Paterson, Colin},
title = {Assuring the Machine Learning Lifecycle: Desiderata, Methods, and Challenges},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3453444},
doi = {10.1145/3453444},
abstract = {Machine learning has evolved into an enabling technology for a wide range of highly successful applications. The potential for this success to continue and accelerate has placed machine learning (ML) at the top of research, economic, and political agendas. Such unprecedented interest is fuelled by a vision of ML applicability extending to healthcare, transportation, defence, and other domains of great societal importance. Achieving this vision requires the use of ML in safety-critical applications that demand levels of assurance beyond those needed for current ML applications. Our article provides a comprehensive survey of the state of the art in the assurance of ML, i.e., in the generation of evidence that ML is sufficiently safe for its intended use. The survey covers the methods capable of providing such evidence at different stages of the machine learning lifecycle, i.e., of the complex, iterative process that starts with the collection of the data used to train an ML component for a system, and ends with the deployment of that component within the system. The article begins with a systematic presentation of the ML lifecycle and its stages. We then define assurance desiderata for each stage, review existing methods that contribute to achieving these desiderata, and identify open challenges that require further research.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {111},
numpages = {39},
keywords = {assurance evidence, assurance, safety-critical systems, Machine learning lifecycle, machine learning workflow}
}

@article{10.1145/3195832,
author = {Farr\'{U}s, Mireia},
title = {Voice Disguise in Automatic Speaker Recognition},
year = {2018},
issue_date = {September 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3195832},
doi = {10.1145/3195832},
abstract = {Humans are able to identify other people’s voices even in voice disguise conditions. However, we are not immune to all voice changes when trying to identify people from voice. Likewise, automatic speaker recognition systems can also be deceived by voice imitation and other types of disguise. Taking into account the voice disguise classification into the combination of two different categories (deliberate/non-deliberate and electronic/non-electronic), this survey provides a literature review on the influence of voice disguise in the automatic speaker recognition task and the robustness of these systems to such voice changes. Additionally, the survey addresses existing applications dealing with voice disguise and analyzes some issues for future research.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {68},
numpages = {22},
keywords = {robustness, voice imitation, Speaker recognition, voice disguise, voice conversion, channel degradation}
}

@article{10.1145/3337065,
author = {Dai, Hong-Ning and Wong, Raymond Chi-Wing and Wang, Hao and Zheng, Zibin and Vasilakos, Athanasios V.},
title = {Big Data Analytics for Large-Scale Wireless Networks: Challenges and Opportunities},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3337065},
doi = {10.1145/3337065},
abstract = {The wide proliferation of various wireless communication systems and wireless devices has led to the arrival of big data era in large-scale wireless networks. Big data of large-scale wireless networks has the key features of wide variety, high volume, real-time velocity, and huge value leading to the unique research challenges that are different from existing computing systems. In this article, we present a survey of the state-of-art big data analytics (BDA) approaches for large-scale wireless networks. In particular, we categorize the life cycle of BDA into four consecutive stages: Data Acquisition, Data Preprocessing, Data Storage, and Data Analytics. We then present a detailed survey of the technical solutions to the challenges in BDA for large-scale wireless networks according to each stage in the life cycle of BDA. Moreover, we discuss the open research issues and outline the future directions in this promising area.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {99},
numpages = {36},
keywords = {machine learning, wireless networks, Big data}
}

@article{10.1145/3441692,
author = {Huang, Huawei and Kong, Wei and Zhou, Sicong and Zheng, Zibin and Guo, Song},
title = {A Survey of State-of-the-Art on Blockchains: Theories, Modelings, and Tools},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3441692},
doi = {10.1145/3441692},
abstract = {To draw a roadmap of current research activities of the blockchain community, we first conduct a brief overview of state-of-the-art blockchain surveys published in the past 5 years. We found that those surveys are basically studying the blockchain-based applications, such as blockchain-assisted Internet of Things (IoT), business applications, security-enabled solutions, and many other applications in diverse fields. However, we think that a comprehensive survey toward the essentials of blockchains by exploiting the state-of-the-art theoretical modelings, analytic models, and useful experiment tools is still missing. To fill this gap, we perform a thorough survey by identifying and classifying the most recent high-quality research outputs that are closely related to the theoretical findings and essential mechanisms of blockchain systems and networks. Several promising open issues are also summarized for future research directions. We hope this survey can serve as a useful guideline for researchers, engineers, and educators about the cutting-edge development of blockchains in the perspectives of theories, modelings, and tools.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {44},
numpages = {42},
keywords = {Blockchain, analytic models, experiment tools, theoretical modelings}
}

@article{10.1145/3329784,
author = {Ghosh, Swarnendu and Das, Nibaran and Das, Ishita and Maulik, Ujjwal},
title = {Understanding Deep Learning Techniques for Image Segmentation},
year = {2019},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3329784},
doi = {10.1145/3329784},
abstract = {The machine learning community has been overwhelmed by a plethora of deep learning--based approaches. Many challenging computer vision tasks, such as detection, localization, recognition, and segmentation of objects in an unconstrained environment, are being efficiently addressed by various types of deep neural networks, such as convolutional neural networks, recurrent networks, adversarial networks, and autoencoders. Although there have been plenty of analytical studies regarding the object detection or recognition domain, many new deep learning techniques have surfaced with respect to image segmentation techniques. This article approaches these various deep learning techniques of image segmentation from an analytical perspective. The main goal of this work is to provide an intuitive understanding of the major techniques that have made a significant contribution to the image segmentation domain. Starting from some of the traditional image segmentation approaches, the article progresses by describing the effect that deep learning has had on the image segmentation domain. Thereafter, most of the major segmentation algorithms have been logically categorized with paragraphs dedicated to their unique contribution. With an ample amount of intuitive explanations, the reader is expected to have an improved ability to visualize the internal dynamics of these processes.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {73},
numpages = {35},
keywords = {semantic image segmentation, convolutional neural networks, Deep learning}
}

@article{10.1145/3365199,
author = {Randal, Allison},
title = {The Ideal Versus the Real: Revisiting the History of Virtual Machines and Containers},
year = {2020},
issue_date = {May 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3365199},
doi = {10.1145/3365199},
abstract = {The common perception in both academic literature and industry today is that virtual machines offer better security, whereas containers offer better performance. However, a detailed review of the history of these technologies and the current threats they face reveals a different story. This survey covers key developments in the evolution of virtual machines and containers from the 1950s to today, with an emphasis on countering modern misperceptions with accurate historical details and providing a solid foundation for ongoing research into the future of secure isolation for multitenant infrastructures, such as cloud and container deployments.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {5},
numpages = {31},
keywords = {virtual machines, virtualization, Containers}
}

@article{10.1145/3379444,
author = {Alam, Iqbal and Sharif, Kashif and Li, Fan and Latif, Zohaib and Karim, M. M. and Biswas, Sujit and Nour, Boubakr and Wang, Yu},
title = {A Survey of Network Virtualization Techniques for Internet of Things Using SDN and NFV},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3379444},
doi = {10.1145/3379444},
abstract = {Internet of Things (IoT) and Network Softwarization are fast becoming core technologies of information systems and network management for the next-generation Internet. The deployment and applications of IoT range from smart cities to urban computing and from ubiquitous healthcare to tactile Internet. For this reason, the physical infrastructure of heterogeneous network systems has become more complicated and thus requires efficient and dynamic solutions for management, configuration, and flow scheduling. Network softwarization in the form of Software Defined Networks and Network Function Virtualization has been extensively researched for IoT in the recent past. In this article, we present a systematic and comprehensive review of virtualization techniques explicitly designed for IoT networks. We have classified the literature into software-defined networks designed for IoT, function virtualization for IoT networks, and software-defined IoT networks. These categories are further divided into works that present architectural, security, and management solutions. Besides, the article highlights several short-term and long-term research challenges and open issues related to the adoption of software-defined Internet of Things.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {35},
numpages = {40},
keywords = {network function virtualization, network softwarization, software-defined IoT, software-defined network, Internet of Things}
}

@article{10.1145/3398020,
author = {Qian, Bin and Su, Jie and Wen, Zhenyu and Jha, Devki Nandan and Li, Yinhao and Guan, Yu and Puthal, Deepak and James, Philip and Yang, Renyu and Zomaya, Albert Y. and Rana, Omer and Wang, Lizhe and Koutny, Maciej and Ranjan, Rajiv},
title = {Orchestrating the Development Lifecycle of Machine Learning-Based IoT Applications: A Taxonomy and Survey},
year = {2020},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3398020},
doi = {10.1145/3398020},
abstract = {Machine Learning (ML) and Internet of Things (IoT) are complementary advances: ML techniques unlock the potential of IoT with intelligence, and IoT applications increasingly feed data collected by sensors into ML models, thereby employing results to improve their business processes and services. Hence, orchestrating ML pipelines that encompass model training and implication involved in the holistic development lifecycle of an IoT application often leads to complex system integration. This article provides a comprehensive and systematic survey of the development lifecycle of ML-based IoT applications. We outline the core roadmap and taxonomy and subsequently assess and compare existing standard techniques used at individual stages.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {82},
numpages = {47},
keywords = {IoT, orchestration, machine learning, deep learning}
}

@article{10.1145/2333112.2333113,
author = {Budzisz, undefinedukasz and Garcia, Johan and Brunstrom, Anna and Ferr\'{u}s, Ramon},
title = {A Taxonomy and Survey of SCTP Research},
year = {2012},
issue_date = {August 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2333112.2333113},
doi = {10.1145/2333112.2333113},
abstract = {The Stream Control Transmission Protocol (SCTP) is a relatively recent general-purpose transport layer protocol for IP networks that has been introduced as a complement to the well-established TCP and UDP transport protocols. Although initially conceived for the transport of PSTN signaling messages over IP networks, the introduction of key features in SCTP, such as multihoming and multistreaming, has spurred considerable research interest surrounding SCTP and its applicability to different networking scenarios. This article aims to provide a detailed survey of one of these new features—multihoming—which, as it is shown, is the subject of evaluation in more than half of all published SCTP-related articles. To this end, the article first summarizes and organizes SCTP-related research conducted so far by developing a four-dimensional taxonomy reflecting the (1) protocol feature examined, (2) application area, (3) network environment, and (4) study approach. Over 430 SCTP-related publications have been analyzed and classified according to the proposed taxonomy. As a result, a clear perspective on this research area in the decade since the first protocol standardization in 2000 is given, covering both current and future research trends. On continuation, a detailed survey of the SCTP multihoming feature is provided, examining possible applications of multihoming, such as robustness, handover support, and loadsharing.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {18},
numpages = {36},
keywords = {taxonomy, loadsharing, multihoming, SCTP, handoff management, robustness}
}

@article{10.1145/3190618,
author = {Sundararajan, Kalaivani and Woodard, Damon L.},
title = {Deep Learning for Biometrics: A Survey},
year = {2018},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3190618},
doi = {10.1145/3190618},
abstract = {In the recent past, deep learning methods have demonstrated remarkable success for supervised learning tasks in multiple domains including computer vision, natural language processing, and speech processing. In this article, we investigate the impact of deep learning in the field of biometrics, given its success in other domains. Since biometrics deals with identifying people by using their characteristics, it primarily involves supervised learning and can leverage the success of deep learning in other related domains. In this article, we survey 100 different approaches that explore deep learning for recognizing individuals using various biometric modalities. We find that most deep learning research in biometrics has been focused on face and speaker recognition. Based on inferences from these approaches, we discuss how deep learning methods can benefit the field of biometrics and the potential gaps that deep learning approaches need to address for real-world biometric applications.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {65},
numpages = {34},
keywords = {face recognition, Deep learning, convolutional neural networks, deep belief nets, speaker recognition, autoencoders, feature learning}
}

@article{10.1145/3295748,
author = {Hossain, MD. Zakir and Sohel, Ferdous and Shiratuddin, Mohd Fairuz and Laga, Hamid},
title = {A Comprehensive Survey of Deep Learning for Image Captioning},
year = {2019},
issue_date = {February 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3295748},
doi = {10.1145/3295748},
abstract = {Generating a description of an image is called image captioning. Image captioning requires recognizing the important objects, their attributes, and their relationships in an image. It also needs to generate syntactically and semantically correct sentences. Deep-learning-based techniques are capable of handling the complexities and challenges of image captioning. In this survey article, we aim to present a comprehensive review of existing deep-learning-based image captioning techniques. We discuss the foundation of the techniques to analyze their performances, strengths, and limitations. We also discuss the datasets and the evaluation metrics popularly used in deep-learning-based automatic image captioning.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {118},
numpages = {36},
keywords = {Image captioning, computer vision, CNN, deep learning, LSTM, natural language processing}
}

@article{10.1145/3092742,
author = {Zhong, Changtao and Sastry, Nishanth},
title = {Systems Applications of Social Networks},
year = {2017},
issue_date = {November 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3092742},
doi = {10.1145/3092742},
abstract = {The aim of this article is to provide an understanding of social networks as a useful addition to the standard toolbox of techniques used by system designers. To this end, we give examples of how data about social links have been collected and used in different application contexts. We develop a broad taxonomy-based overview of common properties of social networks, review how they might be used in different applications, and point out potential pitfalls where appropriate. We propose a framework, distinguishing between two main types of social network-based user selection—personalised user selection, which identifies target users who may be relevant for a given source node, using the social network around the source as a context, and generic user selection or group delimitation, which filters for a set of users who satisfy a set of application requirements based on their social properties. Using this framework, we survey applications of social networks in three typical kinds of application scenarios: recommender systems, content-sharing systems (e.g., P2P or video streaming), and systems that defend against users who abuse the system (e.g., spam or sybil attacks). In each case, we discuss potential directions for future research that involve using social network properties.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {63},
numpages = {42},
keywords = {social properties, recommendation, file sharing, content delivery, anti-spam, Social networks, sybil}
}

@article{10.1145/3403954,
author = {Sharma, Pratima and Jindal, Rajni and Borah, Malaya Dutta},
title = {Blockchain Technology for Cloud Storage: A Systematic Literature Review},
year = {2020},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3403954},
doi = {10.1145/3403954},
abstract = {The demand for Blockchain innovation and the significance of its application has inspired ever-progressing exploration in various scientific and practical areas. Even though it is still in the initial testing stage, the blockchain is being viewed as a progressive solution to address present-day technology concerns, such as decentralization, identity, trust, character, ownership of data, and information-driven choices. Simultaneously, the world is facing an increase in the diversity and quantity of digital information produced by machines and users. While effectively looking for the ideal approach to storing and processing cloud data, the blockchain innovation provides significant inputs. This article reviews the application of blockchain technology for securing cloud storage.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {89},
numpages = {32},
keywords = {cloud storage, decentralization, cloud computing, cloud security, Blockchain technology}
}

@article{10.1145/3230632,
author = {Gui, Qiong and Ruiz-Blondet, Maria V. and Laszlo, Sarah and Jin, Zhanpeng},
title = {A Survey on Brain Biometrics},
year = {2019},
issue_date = {February 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3230632},
doi = {10.1145/3230632},
abstract = {Brainwaves, which reflect brain electrical activity and have been studied for a long time in the domain of cognitive neuroscience, have recently been proposed as a promising biometric approach due to their unique advantages of confidentiality, resistance to spoofing/circumvention, sensitivity to emotional and mental state, continuous nature, and cancelability. Recent research efforts have explored many possible ways of using brain biometrics and demonstrated that they are a promising candidate for more robust and secure personal identification and authentication. Although existing research on brain biometrics has obtained some intriguing insights, much work is still necessary to achieve a reliable ready-to-deploy brain biometric system. This article aims to provide a detailed survey of the current literature and outline the scientific work conducted on brain biometric systems. It provides an up-to-date review of state-of-the-art acquisition, collection, processing, and analysis of brainwave signals, publicly available databases, feature extraction and selection, and classifiers. Furthermore, it highlights some of the emerging open research problems for brain biometrics, including multimodality, security, permanence, and stability.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {112},
numpages = {38},
keywords = {authentication, brain, identification, brainprints, Biometric}
}

@article{10.1145/1978802.1978805,
author = {Rocha, Anderson and Scheirer, Walter and Boult, Terrance and Goldenstein, Siome},
title = {Vision of the Unseen: Current Trends and Challenges in Digital Image and Video Forensics},
year = {2011},
issue_date = {October 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/1978802.1978805},
doi = {10.1145/1978802.1978805},
abstract = {Digital images are everywhere—from our cell phones to the pages of our online news sites. How we choose to use digital image processing raises a surprising host of legal and ethical questions that we must address. What are the ramifications of hiding data within an innocent image? Is this an intentional security practice when used legitimately, or intentional deception? Is tampering with an image appropriate in cases where the image might affect public behavior? Does an image represent a crime, or is it simply a representation of a scene that has never existed? Before action can even be taken on the basis of a questionable image, we must detect something about the image itself. Investigators from a diverse set of fields require the best possible tools to tackle the challenges presented by the malicious use of today's digital image processing techniques.In this survey, we introduce the emerging field of digital image forensics, including the main topic areas of source camera identification, forgery detection, and steganalysis. In source camera identification, we seek to identify the particular model of a camera, or the exact camera, that produced an image. Forgery detection's goal is to establish the authenticity of an image, or to expose any potential tampering the image might have undergone. With steganalysis, the detection of hidden data within an image is performed, with a possible attempt to recover any detected data. Each of these components of digital image forensics is described in detail, along with a critical analysis of the state of the art, and recommendations for the direction of future research.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {26},
numpages = {42},
keywords = {Image and video forensics, forgery and fraud detection, hidden messages detection, image and video source identification, legal aspects}
}

@article{10.1145/3295749,
author = {Jabal, Amani Abu and Davari, Maryam and Bertino, Elisa and Makaya, Christian and Calo, Seraphin and Verma, Dinesh and Russo, Alessandra and Williams, Christopher},
title = {Methods and Tools for Policy Analysis},
year = {2019},
issue_date = {February 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3295749},
doi = {10.1145/3295749},
abstract = {Policy-based management of computer systems, computer networks and devices is a critical technology especially for present and future systems characterized by large-scale systems with autonomous devices, such as robots and drones. Maintaining reliable policy systems requires efficient and effective analysis approaches to ensure that the policies verify critical properties, such as correctness and consistency. In this paper, we present an extensive overview of methods for policy analysis. Then, we survey policy analysis systems and frameworks that have been proposed and compare them under various dimensions. We conclude the paper by outlining novel research directions in the area of policy analysis.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {121},
numpages = {35},
keywords = {similarity analysis, Policy analysis, network policies, policy design and organization, policy quality requirements, access control policies, change impact analysis}
}

@article{10.1145/3360498,
author = {Humbert, Mathias and Trubert, Benjamin and Huguenin, K\'{e}vin},
title = {A Survey on Interdependent Privacy},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3360498},
doi = {10.1145/3360498},
abstract = {The privacy of individuals does not only depend on their own actions and data but may also be affected by the privacy decisions and by the data shared by other individuals. This interdependence is an essential aspect of privacy and ignoring it can lead to serious privacy violations. In this survey, we summarize and analyze research on interdependent privacy risks and on the associated (cooperative and non-cooperative) solutions. We also demonstrate that interdependent privacy has been studied in isolation in different research communities. By doing so, we systematize knowledge on interdependent privacy research and provide insights on how this research should be conducted and which challenges it should address.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {122},
numpages = {40},
keywords = {game theory, user studies, Interdependent privacy, statistical learning}
}

@article{10.1145/2933232,
author = {Xiao, Jiang and Zhou, Zimu and Yi, Youwen and Ni, Lionel M.},
title = {A Survey on Wireless Indoor Localization from the Device Perspective},
year = {2016},
issue_date = {November 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2933232},
doi = {10.1145/2933232},
abstract = {With the marvelous development of wireless techniques and ubiquitous deployment of wireless systems indoors, myriad indoor location-based services (ILBSs) have permeated into numerous aspects of modern life. The most fundamental functionality is to pinpoint the location of the target via wireless devices. According to how wireless devices interact with the target, wireless indoor localization schemes roughly fall into two categories: device based and device free. In device-based localization, a wireless device (e.g., a smartphone) is attached to the target and computes its location through cooperation with other deployed wireless devices. In device-free localization, the target carries no wireless devices, while the wireless infrastructure deployed in the environment determines the target’s location by analyzing its impact on wireless signals.This article is intended to offer a comprehensive state-of-the-art survey on wireless indoor localization from the device perspective. In this survey, we review the recent advances in both modes by elaborating on the underlying wireless modalities, basic localization principles, and data fusion techniques, with special emphasis on emerging trends in (1) leveraging smartphones to integrate wireless and sensor capabilities and extend to the social context for device-based localization, and (2) extracting specific wireless features to trigger novel human-centric device-free localization. We comprehensively compare each scheme in terms of accuracy, cost, scalability, and energy efficiency. Furthermore, we take a first look at intrinsic technical challenges in both categories and identify several open research issues associated with these new challenges.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {25},
numpages = {31},
keywords = {channel state information, device free, device based, Wireless indoor localization}
}

@article{10.1145/2894761,
author = {Zuo, Xiang and Iamnitchi, Adriana},
title = {A Survey of Socially Aware Peer-to-Peer Systems},
year = {2016},
issue_date = {July 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2894761},
doi = {10.1145/2894761},
abstract = {Peer-to-peer technologies have proven their strength in large-scale resource sharing and data transfer. Such systems, however, still need to address a variety of issues, including efficient routing, security, quality of service, incentives, and reputation. Recent research started leveraging social information to develop new and effective techniques to improve the performance of peer-to-peer systems. However, using social information is a double-edged sword, which can bring benefits as well as new challenges. This survey presents and classifies the types of social information that have been used so far in the design of peer-to-peer systems, how the social fabric has been used to facilitate transactions in the system, and some challenges caused by using social information.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {9},
numpages = {28},
keywords = {socially aware peer-to-peer systems, peer-to-peer systems, Social networks}
}

@article{10.1145/3177847,
author = {Barmpatsalou, Konstantia and Cruz, Tiago and Monteiro, Edmundo and Simoes, Paulo},
title = {Current and Future Trends in Mobile Device Forensics: A Survey},
year = {2018},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3177847},
doi = {10.1145/3177847},
abstract = {Contemporary mobile devices are the result of an evolution process, during which computational and networking capabilities have been continuously pushed to keep pace with the constantly growing workload requirements. This has allowed devices such as smartphones, tablets, and personal digital assistants to perform increasingly complex tasks, up to the point of efficiently replacing traditional options such as desktop computers and notebooks. However, due to their portability and size, these devices are more prone to theft, to become compromised, or to be exploited for attacks and other malicious activity. The need for investigation of the aforementioned incidents resulted in the creation of the Mobile Forensics (MF) discipline. MF, a sub-domain of digital forensics, is specialized in extracting and processing evidence from mobile devices in such a way that attacking entities and actions are identified and traced. Beyond its primary research interest on evidence acquisition from mobile devices, MF has recently expanded its scope to encompass the organized and advanced evidence representation and analysis of future malicious entity behavior. Nonetheless, data acquisition still remains its main focus. While the field is under continuous research activity, new concepts such as the involvement of cloud computing in the MF ecosystem and the evolution of enterprise mobile solutions—particularly mobile device management and bring your own device—bring new opportunities and issues to the discipline. The current article presents the research conducted within the MF ecosystem during the last 7 years, identifies the gaps, and highlights the differences from past research directions, and addresses challenges and open issues in the field.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {46},
numpages = {31},
keywords = {evidence acquisition, forensic ontologies, digital forensics, mobile cloud forensics, digital investigations, evidence parsing, Mobile forensics}
}

@article{10.1145/3106739,
author = {Andreasen, Esben and Gong, Liang and M\o{}ller, Anders and Pradel, Michael and Selakovic, Marija and Sen, Koushik and Staicu, Cristian-Alexandru},
title = {A Survey of Dynamic Analysis and Test Generation for JavaScript},
year = {2017},
issue_date = {November 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3106739},
doi = {10.1145/3106739},
abstract = {JavaScript has become one of the most prevalent programming languages. Unfortunately, some of the unique properties that contribute to this popularity also make JavaScript programs prone to errors and difficult for program analyses to reason about. These properties include the highly dynamic nature of the language, a set of unusual language features, a lack of encapsulation mechanisms, and the “no crash” philosophy. This article surveys dynamic program analysis and test generation techniques for JavaScript targeted at improving the correctness, reliability, performance, security, and privacy of JavaScript-based software.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {66},
numpages = {36},
keywords = {dynamic languages, Program analysis, test generation}
}

@article{10.1145/3362168,
author = {Fan, Xinxin and Liu, Ling and Zhang, Rui and Jing, Quanliang and Bi, Jingping},
title = {Decentralized Trust Management: Risk Analysis and Trust Aggregation},
year = {2020},
issue_date = {May 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3362168},
doi = {10.1145/3362168},
abstract = {Decentralized trust management is used as a referral benchmark for assisting decision making by human or intelligence machines in open collaborative systems. During any given period of time, each participant may only interact with a few other participants. Simply relying on direct trust may frequently resort to random team formation. Thus, trust aggregation becomes critical. It can leverage decentralized trust management to learn about indirect trust of every participant based on past transaction experiences. This article presents alternative designs of decentralized trust management and their efficiency and robustness from three perspectives. First, we study the risk factors and adverse effects of six common threat models. Second, we review the representative trust aggregation models and trust metrics. Third, we present an in-depth analysis and comparison of these reference trust aggregation methods with respect to effectiveness and robustness. We show our comparative study results through formal analysis and experimental evaluation. This comprehensive study advances the understanding of adverse effects of present and future threats and the robustness of different trust metrics. It may also serve as a guideline for research and development of next-generation trust aggregation algorithms and services in the anticipation of risk factors and mischievous threats.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {2},
numpages = {33},
keywords = {trust aggregation, threat risk, adverse effect, Trust management}
}

@article{10.1145/3446373,
author = {Li, Xi and Wang, Zehua and Leung, Victor C. M. and Ji, Hong and Liu, Yiming and Zhang, Heli},
title = {Blockchain-Empowered Data-Driven Networks: A Survey and Outlook},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3446373},
doi = {10.1145/3446373},
abstract = {The paths leading to future networks are pointing towards a data-driven paradigm to better cater to the explosive growth of mobile services as well as the increasing heterogeneity of mobile devices, many of which generate and consume large volumes and variety of data. These paths are also hampered by significant challenges in terms of security, privacy, services provisioning, and network management. Blockchain, which is a technology for building distributed ledgers that provide an immutable log of transactions recorded in a distributed network, has become prominent recently as the underlying technology of cryptocurrencies and is revolutionizing data storage and processing in computer network systems. For future data-driven networks (DDNs), blockchain is considered as a promising solution to enable the secure storage, sharing, and analytics of data, privacy protection for users, robust, trustworthy network control, and decentralized routing and resource managements. However, many important challenges and open issues remain to be addressed before blockchain can be deployed widely to enable future DDNs. In this article, we present a survey on the existing research works on the application of blockchain technologies in computer networks and identify challenges and potential solutions in the applications of blockchains in future DDNs. We identify application scenarios in which future blockchain-empowered DDNs could improve the efficiency and security, and generally the effectiveness of network services.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {58},
numpages = {38},
keywords = {blockchain, blockchain-empowered data-driven networks, Data-driven networks, networking technologies}
}

@article{10.1145/3427476,
author = {Mirza, Behroz and Syed, Tahir Q. and Khan, Behraj and Malik, Yameen},
title = {Potential Deep Learning Solutions to Persistent and Emerging Big Data Challenges—A Practitioners’ Cookbook},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3427476},
doi = {10.1145/3427476},
abstract = {The phenomenon of Big Data continues to present moving targets for the scientific and technological state-of-the-art. This work demonstrates that the solution space of these challenges has expanded with deep learning now moving beyond traditional applications in computer vision and natural language processing to diverse and core machine learning tasks such as learning with streaming and non-iid-data, partial supervision, and large volumes of distributed data while preserving privacy. We present a framework coalescing multiple deep methods and corresponding models as responses to specific Big Data challenges. First, we perform a detailed per-challenge review of existing techniques, with benchmarks and usage advice, and subsequently synthesize them together into one organic construct that we discover principally uses extensions of one underlying model, the autoencoder. This work therefore provides a synthesis where challenges at scale across the Vs of Big Data could be addressed by new algorithms and architectures being proposed in the deep learning community. The value being proposed to the reader from either community in terms of nomenclature, concepts, and techniques of the other would advance the cause of multi-disciplinary, transversal research and accelerate the advance of technology in both domains.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {10},
numpages = {39},
keywords = {representation learning, semi-supervised learning, ladder networks, federated learning, regenerative chaining, adaptive deep belief networks, zero shot learning, extreme learning machine, extreme transfer learning, Distributed deep learning, self-supervision, reinforcement learning}
}

@article{10.1145/2379776.2379788,
author = {Esling, Philippe and Agon, Carlos},
title = {Time-Series Data Mining},
year = {2012},
issue_date = {November 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2379776.2379788},
doi = {10.1145/2379776.2379788},
abstract = {In almost every scientific field, measurements are performed over time. These observations lead to a collection of organized data called time series. The purpose of time-series data mining is to try to extract all meaningful knowledge from the shape of data. Even if humans have a natural capacity to perform these tasks, it remains a complex problem for computers. In this article we intend to provide a survey of the techniques applied for time-series data mining. The first part is devoted to an overview of the tasks that have captured most of the interest of researchers. Considering that in most cases, time-series task relies on the same components for implementation, we divide the literature depending on these common aspects, namely representation techniques, distance measures, and indexing methods. The study of the relevant literature has been categorized for each individual aspects. Four types of robustness could then be formalized and any kind of distance could then be classified. Finally, the study submits various research trends and avenues that can be explored in the near future. We hope that this article can provide a broad and deep understanding of the time-series data mining research field.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {12},
numpages = {34},
keywords = {similarity measures, stream analysis, data indexing, query by content, data mining, sequence matching, temporal analysis, Distance measures, time series}
}

@article{10.1145/3408292,
author = {Wang, Jingwen and Jing, Xuyang and Yan, Zheng and Fu, Yulong and Pedrycz, Witold and Yang, Laurence T.},
title = {A Survey on Trust Evaluation Based on Machine Learning},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3408292},
doi = {10.1145/3408292},
abstract = {Trust evaluation is the process of quantifying trust with attributes that influence trust. It faces a number of severe issues such as lack of essential evaluation data, demand of big data process, request of simple trust relationship expression, and expectation of automation. In order to overcome these problems and intelligently and automatically evaluate trust, machine learning has been applied into trust evaluation. Researchers have proposed many methods to use machine learning for trust evaluation. However, the literature still lacks a comprehensive literature review on this topic. In this article, we perform a thorough survey on trust evaluation based on machine learning. First, we cover essential prerequisites of trust evaluation and machine learning. Then, we justify a number of requirements that a sound trust evaluation method should satisfy, and propose them as evaluation criteria to assess the performance of trust evaluation methods. Furthermore, we systematically organize existing methods according to application scenarios and provide a comprehensive literature review on trust evaluation from the perspective of machine learning’s function in trust evaluation and evaluation granularity. Finally, according to the completed review and evaluation, we explore some open research problems and suggest the directions that are worth our research effort in the future.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {107},
numpages = {36},
keywords = {evaluation requirements, machine learning, Trust evaluation, performance metrics}
}

@article{10.1145/3318460,
author = {Xiong, Hu and Wu, Yan and Lu, Zhenyu},
title = {A Survey of Group Key Agreement Protocols with Constant Rounds},
year = {2019},
issue_date = {July 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3318460},
doi = {10.1145/3318460},
abstract = {Group key agreement (shorten as GKA) protocol enables a group of users to negotiate a one-time session key and protect the thereafter group-oriented communication with this session key across an unreliable network. The number of communication rounds is one of the main concern for practical applications where the cardinality of group participants involved is considerable. It is critical to have fixed constant rounds in GKA protocols to secure these applications. In light of overwhelming variety and multitude of constant-round GKA protocols, this article surveys these protocols from a series of perspectives to supply better comprehension for researchers and scholars. Concretely, this article captures the state of the art of constant-round GKA protocols by analyzing the design rationale, examining the framework and security model, and evaluating all discussed protocols in terms of efficiency and security properties. In addition, this article discusses the extension of constant-round GKA protocols including dynamic membership updating, password-based, affiliation-hiding, and fault-tolerance. In conclusion, this article also points out a number of interesting future directions.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {57},
numpages = {32},
keywords = {secure group communication, group key agreement, survey, Constant-round}
}

@article{10.1145/2522968.2522970,
author = {Yenikaya, Sibel and Yenikaya, G\"{o}khan and D\"{u}ven, Ekrem},
title = {Keeping the Vehicle on the Road: A Survey on on-Road Lane Detection Systems},
year = {2013},
issue_date = {October 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2522968.2522970},
doi = {10.1145/2522968.2522970},
abstract = {The development of wireless sensor networks, such as researchers Advanced Driver Assistance Systems (ADAS) requires the ability to analyze the road scene just like a human does. Road scene analysis is an essential, complex, and challenging task and it consists of: road detection (which includes the localization of the road, the determination of the relative position between vehicle and road, and the analysis of the vehicle's heading direction) and obstacle detection (which is mainly based on localizing possible obstacles on the vehicle's path). The detection of the road borders, the estimation of the road geometry, and the localization of the vehicle are essential tasks in this context since they are required for the lateral and longitudinal control of the vehicle. Within this field, on-board vision has been widely used since it has many advantages (higher resolution, low power consumption, low cost, easy aesthetic integration, and nonintrusive nature) over other active sensors such as RADAR or LIDAR. At first glance the problem of detecting the road geometry from visual information seems simple and early works in this field were quickly rewarded with promising results. However, the large variety of scenarios and the high rates of success demanded by the industry have kept the lane detection research work alive. In this article a comprehensive review of vision-based road detection systems vision is presented.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {2},
numpages = {43},
keywords = {road detecetion, lane detection, Computer vision, road following, intelligent vehicles}
}

@article{10.1145/3041956,
author = {Salayma, Marwa and Al-Dubai, Ahmed and Romdhani, Imed and Nasser, Youssef},
title = {Wireless Body Area Network (WBAN): A Survey on Reliability, Fault Tolerance, and Technologies Coexistence},
year = {2017},
issue_date = {April 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3041956},
doi = {10.1145/3041956},
abstract = {Wireless Body Area Network (WBAN) has been a key element in e-health to monitor bodies. This technology enables new applications under the umbrella of different domains, including the medical field, the entertainment and ambient intelligence areas. This survey paper places substantial emphasis on the concept and key features of the WBAN technology. First, the WBAN concept is introduced and a review of key applications facilitated by this networking technology is provided. The study then explores a wide variety of communication standards and methods deployed in this technology. Due to the sensitivity and criticality of the data carried and handled by WBAN, fault tolerance is a critical issue and widely discussed in this paper. Hence, this survey investigates thoroughly the reliability and fault tolerance paradigms suggested for WBANs. Open research and challenging issues pertaining to fault tolerance, coexistence and interference management and power consumption are also discussed along with some suggested trends in these aspects.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {3},
numpages = {38},
keywords = {QoS, WBAN standards, Wireless body area networks, fading, medical, channel access}
}

@article{10.1145/3236009,
author = {Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Giannotti, Fosca and Pedreschi, Dino},
title = {A Survey of Methods for Explaining Black Box Models},
year = {2018},
issue_date = {January 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3236009},
doi = {10.1145/3236009},
abstract = {In recent years, many accurate decision support systems have been constructed as black boxes, that is as systems that hide their internal logic to the user. This lack of explanation constitutes both a practical and an ethical issue. The literature reports many approaches aimed at overcoming this crucial weakness, sometimes at the cost of sacrificing accuracy for interpretability. The applications in which black box decision systems can be used are various, and each approach is typically developed to provide a solution for a specific problem and, as a consequence, it explicitly or implicitly delineates its own definition of interpretability and explanation. The aim of this article is to provide a classification of the main problems addressed in the literature with respect to the notion of explanation and the type of black box system. Given a problem definition, a black box type, and a desired explanation, this survey should help the researcher to find the proposals more useful for his own work. The proposed classification of approaches to open black box models should also be useful for putting the many research open questions in perspective.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {93},
numpages = {42},
keywords = {interpretability, explanations, transparent models, Open the black box}
}

@article{10.1145/3172866,
author = {Bonfim, Michel S. and Dias, Kelvin L. and Fernandes, Stenio F. L.},
title = {Integrated NFV/SDN Architectures: A Systematic Literature Review},
year = {2019},
issue_date = {February 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3172866},
doi = {10.1145/3172866},
abstract = {Network Functions Virtualization (NFV) and Software-Defined Networking (SDN) are new paradigms in the move towards open software and network hardware. While NFV aims to virtualize network functions and deploy them into general purpose hardware, SDN makes networks programmable by separating the control and data planes. NFV and SDN are complementary technologies capable of providing one network solution. SDN can provide connectivity between Virtual Network Functions (VNFs) in a flexible and automated way, whereas NFV can use SDN as part of a service function chain. There are many studies designing NFV/SDN architectures in different environments. Researchers have been trying to address reliability, performance, and scalability problems using different architectural designs. This Systematic Literature Review (SLR) focuses on integrated NFV/SDN architectures, with the following goals: (i) to investigate and provide an in-depth review of the state of the art of NFV/SDN architectures, (ii) to synthesize their architectural designs, and (iii) to identify areas for further improvements. Broadly, this SLR will encourage researchers to advance the current stage of development (i.e., the state of the practice) of integrated NFV/SDN architectures and shed some light on future research efforts and the challenges faced.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {114},
numpages = {39},
keywords = {autonomic management, service-level agreement, security, quality of service, network virtualization, resource scheduling, scalability, mobile networks, resource management, network function virtualization, resource provisioning, cloud computing, elasticity, Software-defined networking, reliability}
}

@article{10.1145/2896499,
author = {Caballero, Juan and Lin, Zhiqiang},
title = {Type Inference on Executables},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2896499},
doi = {10.1145/2896499},
abstract = {In many applications, source code and debugging symbols of a target program are not available, and the only thing that we can access is the program executable. A fundamental challenge with executables is that, during compilation, critical information such as variables and types is lost. Given that typed variables provide fundamental semantics of a program, for the last 16 years, a large amount of research has been carried out on binary code type inference, a challenging task that aims to infer typed variables from executables (also referred to as binary code). In this article, we systematize the area of binary code type inference according to its most important dimensions: the applications that motivate its importance, the approaches used, the types that those approaches infer, the implementation of those approaches, and how the inference results are evaluated. We also discuss limitations, underdeveloped problems and open challenges, and propose further applications.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {65},
numpages = {35},
keywords = {program executables, binary code analysis, Type inference}
}

@article{10.1145/2480741.2480752,
author = {\v{C}repin\v{s}ek, Matej and Liu, Shih-Hsi and Mernik, Marjan},
title = {Exploration and Exploitation in Evolutionary Algorithms: A Survey},
year = {2013},
issue_date = {June 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2480741.2480752},
doi = {10.1145/2480741.2480752},
abstract = {“Exploration and exploitation are the two cornerstones of problem solving by search.” For more than a decade, Eiben and Schippers' advocacy for balancing between these two antagonistic cornerstones still greatly influences the research directions of evolutionary algorithms (EAs) [1998]. This article revisits nearly 100 existing works and surveys how such works have answered the advocacy. The article introduces a fresh treatment that classifies and discusses existing work within three rational aspects: (1) what and how EA components contribute to exploration and exploitation; (2) when and how exploration and exploitation are controlled; and (3) how balance between exploration and exploitation is achieved. With a more comprehensive and systematic understanding of exploration and exploitation, more research in this direction may be motivated and refined.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {35},
numpages = {33},
keywords = {exploration and exploitation, evolutionary algorithms, Diversity}
}

@article{10.1145/3362031,
author = {Ren, Ju and Zhang, Deyu and He, Shiwen and Zhang, Yaoxue and Li, Tao},
title = {A Survey on End-Edge-Cloud Orchestrated Network Computing Paradigms: Transparent Computing, Mobile Edge Computing, Fog Computing, and Cloudlet},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3362031},
doi = {10.1145/3362031},
abstract = {Sending data to the cloud for analysis was a prominent trend during the past decades, driving cloud computing as a dominant computing paradigm. However, the dramatically increasing number of devices and data traffic in the Internet-of-Things (IoT) era are posing significant burdens on the capacity-limited Internet and uncontrollable service delay. It becomes difficult to meet the delay-sensitive and context-aware service requirements of IoT applications by using cloud computing alone. Facing these challenges, computing paradigms are shifting from the centralized cloud computing to distributed edge computing. Several new computing paradigms, including Transparent Computing, Mobile Edge Computing, Fog Computing, and Cloudlet, have emerged to leverage the distributed resources at network edge to provide timely and context-aware services. By integrating end devices, edge servers, and cloud, they form a hierarchical IoT architecture, i.e., End-Edge-Cloud orchestrated architecture to improve the performance of IoT systems. This article presents a comprehensive survey of these emerging computing paradigms from the perspective of end-edge-cloud orchestration. Specifically, we first introduce and compare the architectures and characteristics of different computing paradigms. Then, a comprehensive survey is presented to discuss state-of-the-art research in terms of computation offloading, caching, security, and privacy. Finally, some potential research directions are envisioned for fostering continuous research efforts.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {125},
numpages = {36},
keywords = {fog computing, transparent computing, cloudlet, mobile edge computing, End-edge-cloud orchestration, network computing}
}

@article{10.1145/3309665,
author = {Fiaz, Mustansar and Mahmood, Arif and Javed, Sajid and Jung, Soon Ki},
title = {Handcrafted and Deep Trackers: Recent Visual Object Tracking Approaches and Trends},
year = {2019},
issue_date = {May 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3309665},
doi = {10.1145/3309665},
abstract = {In recent years, visual object tracking has become a very active research area. An increasing number of tracking algorithms are being proposed each year. It is because tracking has wide applications in various real-world problems such as human-computer interaction, autonomous vehicles, robotics, surveillance, and security just to name a few. In the current study, we review latest trends and advances in the tracking area and evaluate the robustness of different trackers based on the feature extraction methods. The first part of this work includes a comprehensive survey of the recently proposed trackers. We broadly categorize trackers into Correlation Filter based Trackers (CFTs) and Non-CFTs. Each category is further classified into various types based on the architecture and the tracking mechanism. In the second part of this work, we experimentally evaluated 24 recent trackers for robustness and compared handcrafted and deep feature based trackers. We observe that trackers using deep features performed better, though in some cases a fusion of both increased performance significantly. To overcome the drawbacks of the existing benchmarks, a new benchmark Object Tracking and Temple Color (OTTC) has also been proposed and used in the evaluation of different algorithms. We analyze the performance of trackers over 11 different challenges in OTTC and 3 other benchmarks. Our study concludes that Discriminative Correlation Filter (DCF) based trackers perform better than the others. Our study also reveals that inclusion of different types of regularizations over DCF often results in boosted tracking performance. Finally, we sum up our study by pointing out some insights and indicating future trends in the visual object tracking field.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {43},
numpages = {44},
keywords = {Robustness of tracking algorithms, tracking evaluation, object tracking, surveillance}
}

@article{10.1145/2811403,
author = {Edwards, Matthew and Rashid, Awais and Rayson, Paul},
title = {A Systematic Survey of Online Data Mining Technology Intended for Law Enforcement},
year = {2015},
issue_date = {September 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2811403},
doi = {10.1145/2811403},
abstract = {As an increasing amount of crime takes on a digital aspect, law enforcement bodies must tackle an online environment generating huge volumes of data. With manual inspections becoming increasingly infeasible, law enforcement bodies are optimising online investigations through data-mining technologies. Such technologies must be well designed and rigorously grounded, yet no survey of the online data-mining literature exists which examines their techniques, applications and rigour. This article remedies this gap through a systematic mapping study describing online data-mining literature which visibly targets law enforcement applications, using evidence-based practices in survey making to produce a replicable analysis which can be methodologically examined for deficiencies.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {15},
numpages = {54},
keywords = {cybercrime, open-source intelligence, Systematic survey, online data mining, law enforcement, OSINT, literature review}
}

@article{10.1145/3424246,
author = {Mladenovi\'{c}, Miljana and O\v{s}mjanski, Vera and Stankovi\'{c}, Sta\v{s}a Vuji\v{c}i\'{c}},
title = {Cyber-Aggression, Cyberbullying, and Cyber-Grooming: A Survey and Research Challenges},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3424246},
doi = {10.1145/3424246},
abstract = {Cyber-aggression, cyberbullying, and cyber-grooming are distinctive and similar phenomena that represent the objectionable content appearing on online social media. Timely detection of the objectionable content is very important for its prevention and reduction. This article explores and spotlights diversity of definitions of cyber-aggression, cyberbulling, and cyber-grooming; analyzes current categorization systems and taxonomies; identifies the targets, target categories, and subcategories of the subjects of the objectionable content research; analyzes the ambiguity of the linguistic terms in the domain; reviews present databases gathered for researching the field; explores types of features used for modeling systems for automatic detection; and examines methods for automatic detection and/or prediction of the objectionable content. The results point to directions of system development for tracing transformations of objectionable content over time on different online social platforms.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {1},
numpages = {42},
keywords = {automatic hate speech detection, cyber-predators, Cyber-aggression, cyber-grooming, cyberbulluing}
}

@article{10.1145/3410158,
author = {Rathore, Aditya Singh and Li, Zhengxiong and Zhu, Weijin and Jin, Zhanpeng and Xu, Wenyao},
title = {A Survey on Heart Biometrics},
year = {2020},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3410158},
doi = {10.1145/3410158},
abstract = {In recent years, biometrics (e.g., fingerprint or face recognition) has replaced traditional passwords and PINs as a widely used method for user authentication, particularly in personal or mobile devices. Differing from state-of-the-art biometrics, heart biometrics offer the advantages of liveness detection, which provides strong tolerance to spoofing attacks. To date, several authentication methods primarily focusing on electrocardiogram (ECG) have demonstrated remarkable success; however, the degree of exploration with other cardiac signals is still limited. To this end, we discuss the challenges in various cardiac domains and propose future prospectives for developing effective heart biometrics systems in real-world applications.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {114},
numpages = {38},
keywords = {sensors, authentication, Cardiac signals, wearables, feature extraction}
}

@article{10.1145/3447744,
author = {Chen, Kaixuan and Zhang, Dalin and Yao, Lina and Guo, Bin and Yu, Zhiwen and Liu, Yunhao},
title = {Deep Learning for Sensor-Based Human Activity Recognition: Overview, Challenges, and Opportunities},
year = {2021},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3447744},
doi = {10.1145/3447744},
abstract = {The vast proliferation of sensor devices and Internet of Things enables the applications of sensor-based activity recognition. However, there exist substantial challenges that could influence the performance of the recognition system in practical scenarios. Recently, as deep learning has demonstrated its effectiveness in many areas, plenty of deep methods have been investigated to address the challenges in activity recognition. In this study, we present a survey of the state-of-the-art deep learning methods for sensor-based human activity recognition. We first introduce the multi-modality of the sensory data and provide information for public datasets that can be used for evaluation in different challenge tasks. We then propose a new taxonomy to structure the deep methods by challenges. Challenges and challenge-related deep methods are summarized and analyzed to form an overview of the current research progress. At the end of this work, we discuss the open issues and provide some insights for future directions.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {77},
numpages = {40},
keywords = {sensors, deep learning, Activity recognition}
}

@article{10.1145/3009965,
author = {Abura'ed, Nour and Khan, Faisal Shah and Bhaskar, Harish},
title = {Advances in the Quantum Theoretical Approach to Image Processing Applications},
year = {2017},
issue_date = {February 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3009965},
doi = {10.1145/3009965},
abstract = {In this article, a detailed survey of the quantum approach to image processing is presented. Recently, it has been established that existing quantum algorithms are applicable to image processing tasks allowing quantum informational models of classical image processing. However, efforts continue in identifying the diversity of its applicability in various image processing domains. Here, in addition to reviewing some of the critical image processing applications that quantum mechanics have targeted, such as denoising, edge detection, image storage, retrieval, and compression, this study will also highlight the complexities in transitioning from the classical to the quantum domain. This article shall establish theoretical fundamentals, analyze performance and evaluation, draw key statistical evidence to support claims, and provide recommendations based on published literature mostly during the period from 2010 to 2015.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {75},
numpages = {49},
keywords = {image compression, image denoising, Quantum computing, image processing, edge detection, image retrieval, image watermarking, image storage}
}

@article{10.1145/3343440,
author = {Kaur, Harsurinder and Pannu, Husanbir Singh and Malhi, Avleen Kaur},
title = {A Systematic Review on Imbalanced Data Challenges in Machine Learning: Applications and Solutions},
year = {2019},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3343440},
doi = {10.1145/3343440},
abstract = {In machine learning, the data imbalance imposes challenges to perform data analytics in almost all areas of real-world research. The raw primary data often suffers from the skewed perspective of data distribution of one class over the other as in the case of computer vision, information security, marketing, and medical science. The goal of this article is to present a comparative analysis of the approaches from the reference of data pre-processing, algorithmic and hybrid paradigms for contemporary imbalance data analysis techniques, and their comparative study in lieu of different data distribution and their application areas.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {79},
numpages = {36},
keywords = {data analysis, machine learning, Data imbalance, sampling}
}

@article{10.1145/3342101,
author = {Almoqbel, Mashael and Xu, Songhua},
title = {Computational Mining of Social Media to Curb Terrorism},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3342101},
doi = {10.1145/3342101},
abstract = {In the ever-connected social networking era, terrorists exploit social media platforms via sophisticated approaches. To curb these activities, a rich collection of computational methods was developed. This article surveys the use of social media by terrorists, followed by a temporal classification framework that overviews computational countermeasures at four major stages, including inception of an attack, immediately before an attack, onset of an attack, and after an attack. The literature surveyed was organized around the four temporal stages. The resulting survey is summarized in a table with the main technology used in each stage based on the time of the attack.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {87},
numpages = {25},
keywords = {counterterrorism, computational analytics, Terrorism, social media mining}
}

@article{10.1145/3336117,
author = {Arias-Cabarcos, Patricia and Krupitzer, Christian and Becker, Christian},
title = {A Survey on Adaptive Authentication},
year = {2019},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3336117},
doi = {10.1145/3336117},
abstract = {Adaptive Authentication allows a system to dynamically select the best mechanism(s) for authenticating a user depending on contextual factors, such as location, proximity to devices, and other attributes. Though this technology has the potential to change the current password-dominated authentication landscape, research to date has not led to practical solutions that transcend to our daily lives. Motivated to find out how to improve adaptive authentication design, we provide a structured survey of the existing literature to date and analyze it to identify and discuss current research challenges and future directions.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {80},
numpages = {30},
keywords = {usable security, systematic literature review, Adaptive authentication}
}

@article{10.1145/2886012,
author = {Schrittwieser, Sebastian and Katzenbeisser, Stefan and Kinder, Johannes and Merzdovnik, Georg and Weippl, Edgar},
title = {Protecting Software through Obfuscation: Can It Keep Pace with Progress in Code Analysis?},
year = {2016},
issue_date = {July 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2886012},
doi = {10.1145/2886012},
abstract = {Software obfuscation has always been a controversially discussed research area. While theoretical results indicate that provably secure obfuscation in general is impossible, its widespread application in malware and commercial software shows that it is nevertheless popular in practice. Still, it remains largely unexplored to what extent today’s software obfuscations keep up with state-of-the-art code analysis and where we stand in the arms race between software developers and code analysts. The main goal of this survey is to analyze the effectiveness of different classes of software obfuscation against the continuously improving deobfuscation techniques and off-the-shelf code analysis tools.The answer very much depends on the goals of the analyst and the available resources. On the one hand, many forms of lightweight static analysis have difficulties with even basic obfuscation schemes, which explains the unbroken popularity of obfuscation among malware writers. On the other hand, more expensive analysis techniques, in particular when used interactively by a human analyst, can easily defeat many obfuscations. As a result, software obfuscation for the purpose of intellectual property protection remains highly challenging.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {4},
numpages = {37},
keywords = {Software obfuscation, program analysis, software protection, malware, reverse engineering}
}

@article{10.1145/2522968.2522976,
author = {Radetzki, Martin and Feng, Chaochao and Zhao, Xueqian and Jantsch, Axel},
title = {Methods for Fault Tolerance in Networks-on-Chip},
year = {2013},
issue_date = {October 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2522968.2522976},
doi = {10.1145/2522968.2522976},
abstract = {Networks-on-Chip constitute the interconnection architecture of future, massively parallel multiprocessors that assemble hundreds to thousands of processing cores on a single chip. Their integration is enabled by ongoing miniaturization of chip manufacturing technologies following Moore's Law. It comes with the downside of the circuit elements' increased susceptibility to failure. Research on fault-tolerant Networks-on-Chip tries to mitigate partial failure and its effect on network performance and reliability by exploiting various forms of redundancy at the suitable network layers. The article at hand reviews the failure mechanisms, fault models, diagnosis techniques, and fault-tolerance methods in on-chip networks, and surveys and summarizes the research of the last ten years. It is structured along three communication layers: the data link, the network, and the transport layers. The most important results are summarized and open research problems and challenges are highlighted to guide future research on this topic.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {8},
numpages = {38},
keywords = {fault models, fault tolerance, failure mechanisms, diagnosis, dependability, reconfiguration, Network-on-Chip}
}

@article{10.1145/2617756,
author = {Marasco, Emanuela and Ross, Arun},
title = {A Survey on Antispoofing Schemes for Fingerprint Recognition Systems},
year = {2014},
issue_date = {January 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2617756},
doi = {10.1145/2617756},
abstract = {Several issues related to the vulnerability of fingerprint recognition systems to attacks have been highlighted in the biometrics literature. One such vulnerability involves the use of artificial fingers, where materials such as Play-Doh, silicone, and gelatin are inscribed with fingerprint ridges. Researchers have demonstrated that some commercial fingerprint recognition systems can be deceived when these artificial fingers are placed on the sensor; that is, the system successfully processes the ensuing fingerprint images, thereby allowing an adversary to spoof the fingerprints of another individual. However, at the same time, several countermeasures that discriminate between live fingerprints and spoof artifacts have been proposed. While some of these antispoofing schemes are hardware based, several software-based approaches have been proposed as well. In this article, we review the literature and present the state of the art in fingerprint antispoofing.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {28},
numpages = {36},
keywords = {Biometrics, fingerprints, liveness detection, person verification, antispoofing}
}

@article{10.1145/2817552,
author = {Saini, Mukesh and Alelaiwi, Abdulhameed and Saddik, Abdulmotaleb El},
title = {How Close Are We to Realizing a Pragmatic VANET Solution? A Meta-Survey},
year = {2015},
issue_date = {November 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2817552},
doi = {10.1145/2817552},
abstract = {Vehicular Ad-hoc Networks (VANETs) are seen as the key enabling technology of Intelligent Transportation Systems (ITS). In addition to safety, VANETs also provide a cost-effective platform for numerous comfort and entertainment applications. A pragmatic solution of VANETs requires synergistic efforts in multidisciplinary areas of communication standards, routings, security and trust. Furthermore, a realistic VANET simulator is required for performance evaluation. There have been many research efforts in these areas, and consequently, a number of surveys have been published on various aspects. In this article, we first explain the key characteristics of VANETs, then provide a meta-survey of research works. We take a tutorial approach to introducing VANETs and gradually discuss intricate details. Extensive listings of existing surveys and research projects have been provided to assess development efforts. The article is useful for researchers to look at the big picture and channel their efforts in an effective way.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {29},
numpages = {40},
keywords = {Internet of Vehicles, security, trust, applications, simulation, routing, tutorial, VANET, standards, safety, Vehicular Ad-hoc Network, survey}
}

@article{10.1145/3442444,
author = {A., Asha K. and Hsu, Li En and Patyal, Abhishek and Chen, Hung-Ming},
title = {Improving the Quality of FPGA RO-PUF by Principal Component Analysis (PCA)},
year = {2021},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {3},
issn = {1550-4832},
url = {https://doi.org/10.1145/3442444},
doi = {10.1145/3442444},
abstract = {Ring Oscillator Physical Unclonable Functions (RO-PUFs) exploit the inherent manufacturing process variations, such as systematic and stochastic variations, to generate secret PUF responses that are unique to the device. Stochastic variations are random, while systematic variation exhibits a strong spatial correlation. Therefore, systematic process variation reduces the randomness of the PUF response. This lowers the ability of a PUF response to uniquely identify and authenticate individual devices. Further, the impact of systematic variation is paramount when the two ROs in comparison are placed far apart. Comparing the ROs that are close to each other does improve the randomness, but the responses generated are unreliable and limiting the possible Challenge-Response Pairs (CRPs). In this article, we are proposing a method to reduce the impact of systematic process variation on the RO oscillation frequencies by using Principal Component Analysis (PCA). Principal Components (PCs) model the directions of systematic and stochastic variation present on a device. By projecting the oscillation frequencies in the direction of stochastic variation, the impact of systematic variation can be reduced. Our proposed method neither restricts the placement of ROs to close groups nor limits the possible CRPs. The method is evaluated on a large population of 218 Xilinx Artix-7 FPGAs. To evaluate the efficiency of the proposed method, we purposely paired the ROs that are placed far apart on the FPGA fabric. Results obtained prove the ability of the proposed method in removing the impact of systematic variation on the oscillation frequencies and thereby producing truly random responses.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = may,
articleno = {34},
numpages = {25},
keywords = {RO-PUF, Principal component analysis (PCA), randomness, systematic variation}
}

@article{10.1145/2700234,
author = {Kim, Yongtae and Zhang, Yong and Li, Peng},
title = {A Reconfigurable Digital Neuromorphic Processor with Memristive Synaptic Crossbar for Cognitive Computing},
year = {2015},
issue_date = {April 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {4},
issn = {1550-4832},
url = {https://doi.org/10.1145/2700234},
doi = {10.1145/2700234},
abstract = {This article presents a brain-inspired reconfigurable digital neuromorphic processor (DNP) architecture for large-scale spiking neural networks. The proposed architecture integrates an arbitrary number of N digital leaky integrate-and-fire (LIF) silicon neurons to mimic their biological counterparts and on-chip learning circuits to realize spike-timing-dependent plasticity (STDP) learning rules. We leverage memristor nanodevices to build an N\texttimes{}N crossbar array to store not only multibit synaptic weight values but also network configuration data with significantly reduced area overhead. Additionally, the crossbar array is designed to be accessible both column- and row-wise to expedite the synaptic weight update process for learning. The proposed digital pulse width modulator (PWM) produces binary pulses with various durations for reading and writing the multilevel memristive crossbar. The proposed column based analog-to-digital conversion (ADC) scheme efficiently accumulates the presynaptic weights of each neuron and reduces silicon area overhead by using a shared arithmetic unit to process the LIF operations of all N neurons. With 256 silicon neurons, learning circuits and 64K synapses, the power dissipation and area of our DNP are 6.45 mW and 1.86 mm2, respectively, when implemented in a 90-nm CMOS technology. The functionality of the proposed DNP architecture is demonstrated by realizing an unsupervised-learning based character recognition system.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = apr,
articleno = {38},
numpages = {25},
keywords = {silicon neuron, synaptic crossbar array, memristor, spiking neural network, spike-timing-dependent plasticity, Digital neuromorphic processor, reconfigurable}
}

@article{10.1145/3398665,
author = {Cerrolaza, Jon Perez and Obermaisser, Roman and Abella, Jaume and Cazorla, Francisco J. and Gr\"{u}ttner, Kim and Agirre, Irune and Ahmadian, Hamidreza and Allende, Imanol},
title = {Multi-Core Devices for Safety-Critical Systems: A Survey},
year = {2020},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3398665},
doi = {10.1145/3398665},
abstract = {Multi-core devices are envisioned to support the development of next-generation safety-critical systems, enabling the on-chip integration of functions of different criticality. This integration provides multiple system-level potential benefits such as cost, size, power, and weight reduction. However, safety certification becomes a challenge and several fundamental safety technical requirements must be addressed, such as temporal and spatial independence, reliability, and diagnostic coverage. This survey provides a categorization and overview at different device abstraction levels (nanoscale, component, and device) of selected key research contributions that support the compliance with these fundamental safety requirements.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {79},
numpages = {38},
keywords = {Fault tolerance, spatial independence, diagnostic coverage, time independence}
}

@article{10.1145/2843890,
author = {Faniyi, Funmilade and Bahsoon, Rami},
title = {A Systematic Review of Service Level Management in the Cloud},
year = {2015},
issue_date = {February 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2843890},
doi = {10.1145/2843890},
abstract = {Cloud computing make it possible to flexibly procure, scale, and release computational resources on demand in response to workload changes. Stakeholders in business and academia are increasingly exploring cloud deployment options for their critical applications. One open problem is that service level agreements (SLAs) in the cloud ecosystem are yet to mature to a state where critical applications can be reliably deployed in clouds. This article systematically surveys the landscape of SLA-based cloud research to understand the state of the art and identify open problems. The survey is particularly aimed at the resource allocation phase of the SLA life cycle while highlighting implications on other phases. Results indicate that (i) minimal number of SLA parameters are accounted for in most studies; (ii) heuristics, policies, and optimisation are the most commonly used techniques for resource allocation; and (iii) the monitor-analysis-plan-execute (MAPE) architecture style is predominant in autonomic cloud systems. The results contribute to the fundamentals of engineering cloud SLA and their autonomic management, motivating further research and industrial-oriented solutions.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {43},
numpages = {27},
keywords = {SLA, self-adaptive, autonomic, self-awareness, software architecture, survey, Cloud computing, QoS}
}

@article{10.1145/2976742,
author = {Kumar, Arvind and Wan, Zhe and Wilcke, Winfried W. and Iyer, Subramanian S.},
title = {Toward Human-Scale Brain Computing Using 3D Wafer Scale Integration},
year = {2017},
issue_date = {May 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {3},
issn = {1550-4832},
url = {https://doi.org/10.1145/2976742},
doi = {10.1145/2976742},
abstract = {The Von Neumann architecture, defined by strict and hierarchical separation of memory and processor, has been a hallmark of conventional computer design since the 1940s. It is becoming increasingly unsuitable for cognitive applications, which require massive parallel processing of highly interdependent data. Inspired by the brain, we propose a significantly different architecture characterized by a large number of highly interconnected simple processors intertwined with very large amounts of low-latency memory. We contend that this memory-centric architecture can be realized using 3D wafer scale integration for which the technology is nearing readiness, combined with current CMOS device technologies. The natural fault tolerance and lower power requirements of neuromorphic processing make 3D wafer stacking particularly attractive. In order to assess the performance of this architecture, we propose a specific embodiment of a neuronal system using 3D wafer scale integration; formulate a simple model of brain connectivity including short- and long-range connections; and estimate the memory, bandwidth, latency, and power requirements of the system using the connectivity model. We find that 3D wafer scale integration, combined with technologies nearing readiness, offers the potential for scaleup to a primate-scale brain, while further scaleup to a human-scale brain would require significant additional innovations.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = apr,
articleno = {45},
numpages = {21},
keywords = {Neuromorphic computing}
}

@article{10.1145/3320073,
author = {Mengistu, Tessema M. and Che, Dunren},
title = {Survey and Taxonomy of Volunteer Computing},
year = {2019},
issue_date = {July 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3320073},
doi = {10.1145/3320073},
abstract = {Volunteer Computing is a kind of distributed computing that harnesses the aggregated spare computing resources of volunteer devices. It provides a cheaper and greener alternative computing infrastructure that can complement the dedicated, centralized, and expensive data centres. The aggregated idle computing resources of devices ranging from desktop computers to routers and smart TVs are being utilized to provide the much needed computing infrastructure for compute intensive tasks such as scientific simulations and big data analysis. However, the use of Volunteer Computing is still dominated by scientific applications and only a very small fraction of the potential volunteer nodes are participating. This article provides a comprehensive survey of Volunteer Computing, covering key technical and operational issues such as security, task distribution, resource management, and incentive models. The article also presents a taxonomy of Volunteer Computing systems, together with discussions of the characteristics of specific systems in each category. To harness the full potentials of Volunteer Computing and make it a reliable alternative computing infrastructure for general applications, we need to improve the existing techniques and device new mechanisms. Thus, this article also sheds light on important issues regarding the future research and development of Volunteer Computing systems with the aim of making them a viable alternative computing infrastructure.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {59},
numpages = {35},
keywords = {desktop grid, Volunteer computing, P2P volunteer computing, volunteer cloud computing, mobile volunteer computing, edge/fog computing}
}

@article{10.1145/3436729,
author = {Li, Chenning and Cao, Zhichao and Liu, Yunhao},
title = {Deep AI Enabled Ubiquitous Wireless Sensing: A Survey},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3436729},
doi = {10.1145/3436729},
abstract = {With the development of the Internet of Things (IoT), many kinds of wireless signals (e.g., Wi-Fi, LoRa, RFID) are filling our living and working spaces nowadays. Beyond communication, wireless signals can sense the status of surrounding objects, known as wireless sensing, with their reflection, scattering, and refraction while propagating in space. In the last decade, many sophisticated wireless sensing techniques and systems were widely studied for various applications (e.g., gesture recognition, localization, and object imaging). Recently, deep Artificial Intelligence (AI), also known as Deep Learning (DL), has shown great success in computer vision. And some works have initially proved that deep AI can benefit wireless sensing as well, leading to a brand-new step toward ubiquitous sensing. In this survey, we focus on the evolution of wireless sensing enhanced by deep AI techniques. We first present a general workflow of Wireless Sensing Systems (WSSs) which consists of signal pre-processing, high-level feature, and sensing model formulation. For each module, existing deep AI-based techniques are summarized, further compared with traditional approaches. Then, we provide a view of issues and challenges induced by combining deep AI and wireless sensing together. Finally, we discuss the future trends of deep AI to enable ubiquitous wireless sensing.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {32},
numpages = {35},
keywords = {deep learning, Wi-Fi, Wireless sensing, acoustic, AI, LoRa, deep neural network, human localization, pose estimation, activity recognition}
}

@article{10.1145/2847562,
author = {Ren, Yi and Liu, Ling and Zhang, Qi and Wu, Qingbo and Guan, Jianbo and Kong, Jinzhu and Dai, Huadong and Shao, Lisong},
title = {Shared-Memory Optimizations for Inter-Virtual-Machine Communication},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2847562},
doi = {10.1145/2847562},
abstract = {Virtual machines (VMs) and virtualization are one of the core computing technologies today. Inter-VM communication is not only prevalent but also one of the leading costs for data-intensive systems and applications in most data centers and cloud computing environments. One way to improve inter-VM communication efficiency is to support coresident VM communication using shared-memory-based methods and resort to the traditional TCP/IP for communications between VMs that are located on different physical machines. In recent years, several independent kernel development efforts have been dedicated to improving communication efficiency between coresident VMs using shared-memory channels, and the development efforts differ from one another in terms of where and how the shared-memory channel is established. In this article, we provide a comprehensive overview of the design choices and techniques for performance optimization of coresident inter-VM communication. We examine the key issues for improving inter-VM communication using shared-memory-based mechanisms, such as implementation choices in the software stack, seamless agility for dynamic addition or removal of coresident VMs, and multilevel transparency, as well as advanced requirements in reliability, security, and stability. An in-depth comparison of state-of-the-art research efforts, implementation techniques, evaluation methods, and performance is conducted. We conjecture that this comprehensive survey will not only provide the foundation for developing the next generation of inter-VM communication optimization mechanisms but also offers opportunities to both cloud infrastructure providers and cloud service providers and consumers for improving communication efficiency between coresident VMs in virtualized computing platforms.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {49},
numpages = {42},
keywords = {shared memory, seamless agility, multilevel transparency, Residency aware, inter-virtual-machine communication}
}

@article{10.1145/3359982,
author = {Zhu, Qingyi and Loke, Seng W. and Trujillo-Rasua, Rolando and Jiang, Frank and Xiang, Yong},
title = {Applications of Distributed Ledger Technologies to the Internet of Things: A Survey},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3359982},
doi = {10.1145/3359982},
abstract = {Distributed Ledger Technologies (DLTs) and blockchain systems have received enormous academic, government, and commercial interest in recent years. This article surveys the integration of DLTs within another life-changing technology, the Internet of Things (IoT). IoT-based applications, such as smart home, smart transport, supply chain, smart healthcare, and smart energy, promise to boost the efficiency of existing infrastructures and change every facet of our daily life. This article looks into the challenges faced by such applications and reviews a comprehensive selection of existing DLT solutions to those challenges. We also identify issues for future research, including DLT security and scalability, multi-DLT applications, and survival of DLT in the post-quantum world.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {120},
numpages = {34},
keywords = {Internet of things, Distributed ledger technologies, blockchain}
}

@article{10.1145/2601412,
author = {Aggarwal, Charu and Subbian, Karthik},
title = {Evolutionary Network Analysis: A Survey},
year = {2014},
issue_date = {July 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2601412},
doi = {10.1145/2601412},
abstract = {Evolutionary network analysis has found an increasing interest in the literature because of the importance of different kinds of dynamic social networks, email networks, biological networks, and social streams. When a network evolves, the results of data mining algorithms such as community detection need to be correspondingly updated. Furthermore, the specific kinds of changes to the structure of the network, such as the impact on community structure or the impact on network structural parameters, such as node degrees, also needs to be analyzed. Some dynamic networks have a much faster rate of edge arrival and are referred to as network streams or graph streams. The analysis of such networks is especially challenging, because it needs to be performed with an online approach, under the one-pass constraint of data streams. The incorporation of content can add further complexity to the evolution analysis process. This survey provides an overview of the vast literature on graph evolution analysis and the numerous applications that arise in different contexts.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {10},
numpages = {36},
keywords = {dynamic graphs, Network analysis, temporal graphs}
}

@article{10.1145/2843889,
author = {Singh, Sukhpal and Chana, Inderveer},
title = {QoS-Aware Autonomic Resource Management in Cloud Computing: A Systematic Review},
year = {2015},
issue_date = {February 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2843889},
doi = {10.1145/2843889},
abstract = {As computing infrastructure expands, resource management in a large, heterogeneous, and distributed environment becomes a challenging task. In a cloud environment, with uncertainty and dispersion of resources, one encounters problems of allocation of resources, which is caused by things such as heterogeneity, dynamism, and failures. Unfortunately, existing resource management techniques, frameworks, and mechanisms are insufficient to handle these environments, applications, and resource behaviors. To provide efficient performance of workloads and applications, the aforementioned characteristics should be addressed effectively. This research depicts a broad methodical literature analysis of autonomic resource management in the area of the cloud in general and QoS (Quality of Service)-aware autonomic resource management specifically. The current status of autonomic resource management in cloud computing is distributed into various categories. Methodical analysis of autonomic resource management in cloud computing and its techniques are described as developed by various industry and academic groups. Further, taxonomy of autonomic resource management in the cloud has been presented. This research work will help researchers find the important characteristics of autonomic resource management and will also help to select the most suitable technique for autonomic resource management in a specific application along with significant future research directions.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {42},
numpages = {46},
keywords = {autonomic computing, quality of service, self-protecting, autonomic cloud computing, self-optimizing, Resource provisioning, self-management, grid computing, self-healing, cloud computing, self-configuring, resource scheduling, service-level agreement, autonomic management, resource management}
}

@article{10.1145/3450288,
author = {Lo, Sin Kit and Lu, Qinghua and Wang, Chen and Paik, Hye-Young and Zhu, Liming},
title = {A Systematic Literature Review on Federated Machine Learning: From a Software Engineering Perspective},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3450288},
doi = {10.1145/3450288},
abstract = {Federated learning is an emerging machine learning paradigm where clients train models locally and formulate a global model based on the local model updates. To identify the state-of-the-art in federated learning and explore how to develop federated learning systems, we perform a systematic literature review from a software engineering perspective, based on 231 primary studies. Our data synthesis covers the lifecycle of federated learning system development that includes background understanding, requirement analysis, architecture design, implementation, and evaluation. We highlight and summarise the findings from the results and identify future trends to encourage researchers to advance their current work.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {95},
numpages = {39},
keywords = {distributed learning, systematic literature review, edge learning, Federated learning, software engineering, privacy}
}

@article{10.1145/3361216,
author = {Manral, Bharat and Somani, Gaurav and Choo, Kim-Kwang Raymond and Conti, Mauro and Gaur, Manoj Singh},
title = {A Systematic Survey on Cloud Forensics Challenges, Solutions, and Future Directions},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3361216},
doi = {10.1145/3361216},
abstract = {The challenges of cloud forensics have been well-documented by both researchers and government agencies (e.g., U.S. National Institute of Standards and Technology), although many of the challenges remain unresolved. In this article, we perform a comprehensive survey of cloud forensic literature published between January 2007 and December 2018, categorized using a five-step forensic investigation process. We also present a taxonomy of existing cloud forensic solutions, with the aim of better informing both the research and practitioner communities, as well as an in-depth discussion of existing conventional digital forensic tools and cloud-specific forensic investigation tools. Based on the findings from the survey, we present a set of design guidelines to inform future cloud forensic investigation processes, and a summary of digital artifacts that can be obtained from different stakeholders in the cloud computing architecture/ecosystem.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {124},
numpages = {38},
keywords = {digital forensics in cloud, forensic challenges in cloud, Cloud forensics, SDN forensics, VM forensics in cloud, cloud network forensics, cloud storage artifacts forensics}
}

@article{10.1145/3419634,
author = {Bansal, Maggi and Chana, Inderveer and Clarke, Siobh\'{a}n},
title = {A Survey on IoT Big Data: Current Status, 13 V’s Challenges, and Future Directions},
year = {2020},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3419634},
doi = {10.1145/3419634},
abstract = {Driven by the core technologies, i.e., sensor-based autonomous data acquisition and the cloud-based big data analysis, IoT automates the actuation of data-driven intelligent actions on the connected objects. This automation enables numerous useful real-life use-cases, such as smart transport, smart living, smart cities, and so on. However, recent industry surveys reflect that data-related challenges are responsible for slower growth of IoT in recent years. For this reason, this article presents a systematic and comprehensive survey on IoT Big Data (IoTBD) with the aim to identify the uncharted challenges for IoTBD. This article analyzes the state-of-the-art academic works in IoT and big data management across various domains and proposes a taxonomy for IoTBD management. Then, the survey explores the IoT portfolio of major cloud vendors and provides a classification of vendor services for the integration of IoT and IoTBD on their cloud platforms. After that, the survey identifies the IoTBD challenges in terms of 13 V’s challenges and envisions IoTBD as “Big Data 2.0.” Then the survey provides comprehensive analysis of recent works that address IoTBD challenges by highlighting their strengths and weaknesses to assess the recent trends and future research directions. Finally, the survey concludes with discussion on open research issues for IoTBD.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {131},
numpages = {59},
keywords = {IoT big data, IoT big data survey, V’s challenges for IoT big data, big data 2.0, cloud IoT services, cloud computing in IoT}
}

@article{10.1145/2851510,
author = {Farias, Claudio M. De and Li, Wei and Delicato, Fl\'{a}via C. and Pirmez, Luci and Zomaya, Albert Y. and Pires, Paulo F. and Souza, Jos\'{e} N. De},
title = {A Systematic Review of Shared Sensor Networks},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2851510},
doi = {10.1145/2851510},
abstract = {While Wireless Sensor Networks (WSNs) have been traditionally tasked with single applications, in recent years we have witnessed the emergence of Shared Sensor Networks (SSNs) as integrated cyber-physical system infrastructures for a multitude of applications. Instead of assuming an application-specific network design, SSNs allow the underlying infrastructure to be shared among multiple applications that can potentially belong to different users. On one hand, a potential benefit of such a design approach is to increase the utilization of sensing and communication resources, whenever the underlying network infrastructure covers the same geographic area and the sensor nodes monitor the same physical variables of common interest for different applications. On the other hand, compared with the existing application-specific design, the SSNs approach poses several research challenges with regard to different aspects of WSNs. In this article, we present a systematic literature survey on SSNs. The main goal of the article is to provide the reader with the opportunity to understand what has been done and what remains as open issues in this field, as well as which are the pivotal factors of this evolutionary design and how this kind of design can be exploited by a wide range of WSN applications.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {51},
numpages = {50},
keywords = {multiple applications, Wireless sensor networks, task allocation, middleware, shared sensor network, routing, virtual sensor network, network virtualization, task scheduling, information sharing, security, applications}
}

@article{10.1145/3355399,
author = {Liu, Xunyun and Buyya, Rajkumar},
title = {Resource Management and Scheduling in Distributed Stream Processing Systems: A Taxonomy, Review, and Future Directions},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3355399},
doi = {10.1145/3355399},
abstract = {Stream processing is an emerging paradigm to handle data streams upon arrival, powering latency-critical application such as fraud detection, algorithmic trading, and health surveillance. Though there are a variety of Distributed Stream Processing Systems (DSPSs) that facilitate the development of streaming applications, resource management and task scheduling is not automatically handled by the DSPS middleware and requires a laborious process to tune toward specific deployment targets. As the advent of cloud computing has supported renting resources on-demand, it is of great interest to review the research progress of hosting streaming systems in clouds under certain Service Level Agreements (SLA) and cost constraints. In this article, we introduce the hierarchical structure of streaming systems, define the scope of the resource management problem, and present a comprehensive taxonomy in this context covering critical research topics such as resource provisioning, operator parallelisation, and task scheduling. The literature is then reviewed following the taxonomy structure, facilitating a deeper understanding of the research landscape through classification and comparison of existing works. Finally, we discuss the open issues and future research directions toward realising an automatic, SLA-aware resource management framework.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {50},
numpages = {41},
keywords = {Resource management, distributed stream processing systems, stream processing, task scheduling}
}

@article{10.1145/3017678,
author = {Li, Tao and Xie, Ning and Zeng, Chunqiu and Zhou, Wubai and Zheng, Li and Jiang, Yexi and Yang, Yimin and Ha, Hsin-Yu and Xue, Wei and Huang, Yue and Chen, Shu-Ching and Navlakha, Jainendra and Iyengar, S. S.},
title = {Data-Driven Techniques in Disaster Information Management},
year = {2017},
issue_date = {April 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3017678},
doi = {10.1145/3017678},
abstract = {Improving disaster management and recovery techniques is one of national priorities given the huge toll caused by man-made and nature calamities. Data-driven disaster management aims at applying advanced data collection and analysis technologies to achieve more effective and responsive disaster management, and has undergone considerable progress in the last decade. However, to the best of our knowledge, there is currently no work that both summarizes recent progress and suggests future directions for this emerging research area. To remedy this situation, we provide a systematic treatment of the recent developments in data-driven disaster management. Specifically, we first present a general overview of the requirements and system architectures of disaster management systems and then summarize state-of-the-art data-driven techniques that have been applied on improving situation awareness as well as in addressing users’ information needs in disaster management. We also discuss and categorize general data-mining and machine-learning techniques in disaster management. Finally, we recommend several research directions for further investigations.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {1},
numpages = {45},
keywords = {Disaster information management, data management, application, data mining}
}

@article{10.1145/2886780,
author = {Platania, Marco and Obenshain, Daniel and Tantillo, Thomas and Amir, Yair and Suri, Neeraj},
title = {On Choosing Server- or Client-Side Solutions for BFT},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2886780},
doi = {10.1145/2886780},
abstract = {Byzantine Fault Tolerant (BFT) protocols have the ability to work correctly even when up to a threshold f of system servers are compromised. This makes them appealing for the construction of critical systems connected to the Internet, which are constantly a target for cyber attacks.BFT protocols differ based on the kind of application, deployment settings, performance, access control mechanisms, number of servers in the system, and protocol implementation. The large number of protocols present in the literature and their differences make it difficult for a system builder to choose the solution that best satisfies the requirements of the system that he wants to build. In particular, the main difference among BFT protocols lies in their system models: server-side versus client-side. In the server-side model each client relies on the system to consistently order and replicate updates, while in the client-side model each client actively participates in the protocol.In this article, we classify BFT protocols as server-side or client-side. We analyze the trade-offs between the two models, describe systems that use these models and the trade-offs they choose, highlight the research gaps, and provide guidelines to system builders in order to choose the solution that best satisfies their needs.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {61},
numpages = {30},
keywords = {BFT quorums, BFT state machine replication, deployment strategies, performance, trade-offs}
}

@article{10.1145/3341145,
author = {Duc, Thang Le and Leiva, Rafael Garc\'{\i}a and Casari, Paolo and \"{O}stberg, Per-Olov},
title = {Machine Learning Methods for Reliable Resource Provisioning in Edge-Cloud Computing: A Survey},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3341145},
doi = {10.1145/3341145},
abstract = {Large-scale software systems are currently designed as distributed entities and deployed in cloud data centers. To overcome the limitations inherent to this type of deployment, applications are increasingly being supplemented with components instantiated closer to the edges of networks—a paradigm known as edge computing. The problem of how to efficiently orchestrate combined edge-cloud applications is, however, incompletely understood, and a wide range of techniques for resource and application management are currently in use.This article investigates the problem of reliable resource provisioning in joint edge-cloud environments, and surveys technologies, mechanisms, and methods that can be used to improve the reliability of distributed applications in diverse and heterogeneous network environments. Due to the complexity of the problem, special emphasis is placed on solutions to the characterization, management, and control of complex distributed applications using machine learning approaches. The survey is structured around a decomposition of the reliable resource provisioning problem into three categories of techniques: workload characterization and prediction, component placement and system consolidation, and application elasticity and remediation. Survey results are presented along with a problem-oriented discussion of the state-of-the-art. A summary of identified challenges and an outline of future research directions are presented to conclude the article.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {94},
numpages = {39},
keywords = {optimization, placement, remediation, Reliability, autoscaling, machine learning, cloud computing, edge computing, consolidation, distributed systems}
}

@article{10.1145/3447243,
author = {Avola, Danilo and Cinque, Luigi and Fagioli, Alessio and Foresti, Gianluca and Mecca, Alessio},
title = {Ultrasound Medical Imaging Techniques: A Survey},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3447243},
doi = {10.1145/3447243},
abstract = {Ultrasound (US) imaging for medical purposes has been increasing in popularity over the years. The US technology has some valuable strengths, such as it is harmless, very cheap, and can provide real-time feedback. At the same time, it has also some drawbacks that the research in this field is trying to mitigate, such as the high level of noise and the low quality of the images. This survey aims at presenting the advances in the techniques used for US medical imaging. It describes the studies on the different organs that the US uses the most and tries to categorize the research in this field into three groups, i.e., segmentation, classification, and miscellaneous. This latter group includes the works that either provide aid during surgical operations or try to enhance the quality of the acquired US images/volumes. To the best of our knowledge, this is the first review that analyzes the different techniques exploited on a large selection of body locations (i.e., brain, thyroid, heart, breast, fetal, and prostate) in the three sub-fields of research.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {67},
numpages = {38},
keywords = {surgeon aid, segmentation, Medical image, classification, US, abus, ultrasound, trus, computer aided diagnosis, computer aided detection, echocardiography}
}

@article{10.1145/3243043,
author = {Nambiar, Athira and Bernardino, Alexandre and Nascimento, Jacinto C.},
title = {Gait-Based Person Re-Identification: A Survey},
year = {2019},
issue_date = {May 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3243043},
doi = {10.1145/3243043},
abstract = {The way people walk is a strong correlate of their identity. Several studies have shown that both humans and machines can recognize individuals just by their gait, given that proper measurements of the observed motion patterns are available. For surveillance applications, gait is also attractive, because it does not require active collaboration from users and is hard to fake. However, the acquisition of good-quality measures of a person’s motion patterns in unconstrained environments, (e.g., in person re-identification applications) has proved very challenging in practice. Existing technology (video cameras) suffer from changes in viewpoint, daylight, clothing, accessories, and other variations in the person’s appearance. Novel three-dimensional sensors are bringing new promises to the field, but still many research issues are open. This article presents a survey of the work done in gait analysis for re-identification in the past decade, looking at the main approaches, datasets, and evaluation methodologies. We identify several relevant dimensions of the problem and provide a taxonomic analysis of the current state of the art. Finally, we discuss the levels of performance achievable with the current technology and give a perspective of the most challenging and promising directions of research for the future.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {33},
numpages = {34},
keywords = {computer vision, gait analysis, Video surveillance, machine learning, biometrics, person re-identification}
}

@article{10.1145/2871183,
author = {Crocco, Marco and Cristani, Marco and Trucco, Andrea and Murino, Vittorio},
title = {Audio Surveillance: A Systematic Review},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2871183},
doi = {10.1145/2871183},
abstract = {Despite surveillance systems becoming increasingly ubiquitous in our living environment, automated surveillance, currently based on video sensory modality and machine intelligence, lacks most of the time the robustness and reliability required in several real applications. To tackle this issue, audio sensory devices have been incorporated, both alone or in combination with video, giving birth in the past decade, to a considerable amount of research. In this article, audio-based automated surveillance methods are organized into a comprehensive survey: A general taxonomy, inspired by the more widespread video surveillance field, is proposed to systematically describe the methods covering background subtraction, event classification, object tracking, and situation analysis. For each of these tasks, all the significant works are reviewed, detailing their pros and cons and the context for which they have been proposed. Moreover, a specific section is devoted to audio features, discussing their expressiveness and their employment in the above-described tasks. Differing from other surveys on audio processing and analysis, the present one is specifically targeted to automated surveillance, highlighting the target applications of each described method and providing the reader with a systematic and schematic view useful for retrieving the most suited algorithms for each specific requirement.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {52},
numpages = {46},
keywords = {audio surveillance, Automated surveillance, multimodal surveillance}
}

@article{10.1145/3440207,
author = {Wang, Sheng and Bao, Zhifeng and Culpepper, J. Shane and Cong, Gao},
title = {A Survey on Trajectory Data Management, Analytics, and Learning},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3440207},
doi = {10.1145/3440207},
abstract = {Recent advances in sensor and mobile devices have enabled an unprecedented increase in the availability and collection of urban trajectory data, thus increasing the demand for more efficient ways to manage and analyze the data being produced. In this survey, we comprehensively review recent research trends in trajectory data management, ranging from trajectory pre-processing, storage, common trajectory analytic tools, such as querying spatial-only and spatial-textual trajectory data, and trajectory clustering. We also explore four closely related analytical tasks commonly used with trajectory data in interactive or real-time processing. Deep trajectory learning is also reviewed for the first time. Finally, we outline the essential qualities that a trajectory data management system should possess to maximize flexibility.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {39},
numpages = {36},
keywords = {Trajectory, similarity search, storage system, deep learning, urban analytics}
}

@article{10.1145/3125641,
author = {Tunali, Onur and Altun, Mustafa},
title = {A Survey of Fault-Tolerance Algorithms for Reconfigurable Nano-Crossbar Arrays},
year = {2017},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3125641},
doi = {10.1145/3125641},
abstract = {Nano-crossbar arrays have emerged as a promising and viable technology to improve computing performance of electronic circuits beyond the limits of current CMOS. Arrays offer both structural efficiency with reconfiguration and prospective capability of integration with different technologies. However, certain problems need to be addressed, and the most important one is the prevailing occurrence of faults. Considering fault rate projections as high as 20% that is much higher than those of CMOS, it is fair to expect sophisticated fault-tolerance methods. The focus of this survey article is the assessment and evaluation of these methods and related algorithms applied in logic mapping and configuration processes. As a start, we concisely explain reconfigurable nano-crossbar arrays with their fault characteristics and models. Following that, we demonstrate configuration techniques of the arrays in the presence of permanent faults and elaborate on two main fault-tolerance methodologies, namely defect-unaware and defect-aware approaches, with a short review on advantages and disadvantages. For both methodologies, we present detailed experimental results of related algorithms regarding their strengths and weaknesses with a comprehensive yield, success rate and runtime analysis. Next, we overview fault-tolerance approaches for transient faults. As a conclusion, we overview the proposed algorithms with future directions and upcoming challenges.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {79},
numpages = {35},
keywords = {Fault tolerance, nano-crossbar}
}

@article{10.1145/3127881,
author = {Yadav, Pranjul and Steinbach, Michael and Kumar, Vipin and Simon, Gyorgy},
title = {Mining Electronic Health Records (EHRs): A Survey},
year = {2018},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3127881},
doi = {10.1145/3127881},
abstract = {The continuously increasing cost of the US healthcare system has received significant attention. Central to the ideas aimed at curbing this trend is the use of technology in the form of the mandate to implement electronic health records (EHRs). EHRs consist of patient information such as demographics, medications, laboratory test results, diagnosis codes, and procedures. Mining EHRs could lead to improvement in patient health management as EHRs contain detailed information related to disease prognosis for large patient populations. In this article, we provide a structured and comprehensive overview of data mining techniques for modeling EHRs. We first provide a detailed understanding of the major application areas to which EHR mining has been applied and then discuss the nature of EHR data and its accompanying challenges. Next, we describe major approaches used for EHR mining, the metrics associated with EHRs, and the various study designs. With this foundation, we then provide a systematic and methodological organization of existing data mining techniques used to model EHRs and discuss ideas for future research.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {85},
numpages = {40},
keywords = {machine learning, Healthcare analytics, healthcare informatics, data mining, EHRs}
}

@article{10.1145/2971482,
author = {Coppola, Riccardo and Morisio, Maurizio},
title = {Connected Car: Technologies, Issues, Future Trends},
year = {2016},
issue_date = {December 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2971482},
doi = {10.1145/2971482},
abstract = {The connected car—a vehicle capable of accessing to the Internet, of communicating with smart devices as well as other cars and road infrastructures, and of collecting real-time data from multiple sources—is likely to play a fundamental role in the foreseeable Internet Of Things. In a context ruled by very strong competitive forces, a significant amount of car manufacturers and software and hardware developers have already embraced the challenge of providing innovative solutions for new-generation vehicles. Today’s cars are asked to relieve drivers from the most stressful operations needed for driving, providing them with interesting and updated entertainment functions. In the meantime, they have to comply with the increasingly stringent standards about safety and reliability. The aim of this article is to provide an overview of the possibilities offered by connected functionalities on cars and the associated technological issues and problems, as well as to enumerate the currently available hardware and software solutions and their main features.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {46},
numpages = {36},
keywords = {on-car infotainment, autonomous vehicles, car-mobile integration, Intelligent vehicular networks}
}

@article{10.1145/3423167,
author = {Wright, Christopher and Moeglein, William A. and Bagchi, Saurabh and Kulkarni, Milind and Clements, Abraham A.},
title = {Challenges in Firmware Re-Hosting, Emulation, and Analysis},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3423167},
doi = {10.1145/3423167},
abstract = {System emulation and firmware re-hosting have become popular techniques to answer various security and performance related questions, such as determining whether a firmware contain security vulnerabilities or meet timing requirements when run on a specific hardware platform. While this motivation for emulation and binary analysis has previously been explored and reported, starting to either work or research in the field is difficult. To this end, we provide a comprehensive guide for the practitioner or system emulation researcher. We layout common challenges faced during firmware re-hosting, explaining successive steps and surveying common tools used to overcome these challenges. We provide classification techniques on five different axes, including emulator methods, system type, fidelity, emulator purpose, and control. These classifications and comparison criteria enable the practitioner to determine the appropriate tool for emulation. We use our classifications to categorize popular works in the field and present 28 common challenges faced when creating, emulating, and analyzing a system from obtaining firmwares to post emulation analysis.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {5},
numpages = {36},
keywords = {emulation challenges, emulation fidelity, embedded systems, system emulation, Firmware re-hosting, emulator classification, reverse engineering, binary analysis}
}

@article{10.1145/3453161,
author = {Dotan, Maya and Pignolet, Yvonne-Anne and Schmid, Stefan and Tochner, Saar and Zohar, Aviv},
title = {Survey on Blockchain Networking: Context, State-of-the-Art, Challenges},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3453161},
doi = {10.1145/3453161},
abstract = {Blockchains, in general, and cryptocurrencies such as Bitcoin, in particular, are realized using distributed systems and hence critically rely on the performance and security of the interconnecting network. The requirements on these networks and their usage, however, can differ significantly from traditional communication networks, with implications on all layers of the protocol stack. This article is motivated by these differences and, in particular, by the observation that many fundamental design aspects of these networks are not well-understood today. To support the networking community to contribute to this emerging application domain, we present a structured overview of the field, from topology and neighbor discovery, over block and transaction propagation, to sharding and off-chain networks, also reviewing existing empirical results from different measurement studies. In particular, for each of these domains, we provide the context, highlighting differences and commonalities with traditional networks, review the state-of-the-art, and identify open research challenges. Our article can hence also be seen as a call-to-arms to improve the foundation on top of which blockchains are built.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {107},
numpages = {34},
keywords = {payment networks, Blockchains, distributed computing}
}

@article{10.1145/3439726,
author = {Minaee, Shervin and Kalchbrenner, Nal and Cambria, Erik and Nikzad, Narjes and Chenaghlu, Meysam and Gao, Jianfeng},
title = {Deep Learning--Based Text Classification: A Comprehensive Review},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3439726},
doi = {10.1145/3439726},
abstract = {Deep learning--based models have surpassed classical machine learning--based approaches in various text classification tasks, including sentiment analysis, news categorization, question answering, and natural language inference. In this article, we provide a comprehensive review of more than 150 deep learning--based models for text classification developed in recent years, and we discuss their technical contributions, similarities, and strengths. We also provide a summary of more than 40 popular datasets widely used for text classification. Finally, we provide a quantitative analysis of the performance of different deep learning models on popular benchmarks, and we discuss future research directions.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {62},
numpages = {40},
keywords = {news categorization, topic classification, deep learning, sentiment analysis, question answering, Text classification, natural language inference}
}

@article{10.1145/3366370,
author = {Kolb, John and AbdelBaky, Moustafa and Katz, Randy H. and Culler, David E.},
title = {Core Concepts, Challenges, and Future Directions in Blockchain: A Centralized Tutorial},
year = {2020},
issue_date = {May 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3366370},
doi = {10.1145/3366370},
abstract = {Blockchains are a topic of immense interest in academia and industry, but their true nature is often obscured by marketing and hype. In this tutorial, we explain the fundamental elements of blockchains. We discuss their ability to achieve availability, consistency, and data integrity as well as their inherent limitations. Using Ethereum as a case study, we describe the inner workings of blockchains in detail before comparing blockchains to traditional distributed systems. In the second part of our tutorial, we discuss the major challenges facing blockchains and summarize ongoing research and commercial offerings that seek to address these challenges.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {9},
numpages = {39},
keywords = {Blockchain, distributed ledger, cryptocurrency, smart contracts}
}

@article{10.1145/2818183,
author = {Guo, Mingming and Jin, Xinyu and Pissinou, Niki and Zanlongo, Sebastian and Carbunar, Bogdan and Iyengar, S. S.},
title = {In-Network Trajectory Privacy Preservation},
year = {2015},
issue_date = {November 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2818183},
doi = {10.1145/2818183},
abstract = {Recent advances in mobile device, wireless networking, and positional technologies have helped location-aware applications become pervasive. However, location trajectory privacy concerns hinder the adoptability of such applications. In this article, we survey existing trajectory privacy work in the context of wireless sensor networks, location-based services, and geosocial networks. In each context, we categorize and summarize the main techniques according to their own feathers. Furthermore, we discuss future trajectory privacy research challenges and directions.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {23},
numpages = {29},
keywords = {geosocial networks, wireless sensor networks, Trajectory privacy, location-based services}
}

@article{10.1145/3146025,
author = {Paci, Federica and Squicciarini, Anna and Zannone, Nicola},
title = {Survey on Access Control for Community-Centered Collaborative Systems},
year = {2018},
issue_date = {April 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3146025},
doi = {10.1145/3146025},
abstract = {The last decades have seen a growing interest and demand for community-centered collaborative systems and platforms. These systems and platforms aim to provide an environment in which users can collaboratively create, share, and manage resources. While offering attractive opportunities for online collaboration and information sharing, they also open several security and privacy issues. This has attracted several research efforts toward the design and implementation of novel access control solutions that can handle the complexity introduced by collaboration. Despite these efforts, transition to practice has been hindered by the lack of maturity of the proposed solutions. The access control mechanisms typically adopted by commercial collaborative systems like online social network websites and collaborative editing platforms, are still rather rudimentary and do not provide users with a sufficient control over their resources. This survey examines the growing literature on access control for collaborative systems centered on communities, and identifies the main challenges to be addressed in order to facilitate the adoption of collaborative access control solutions in real-life settings. Based on the literature study, we delineate a roadmap for future research in the area of access control for community-centered collaborative systems.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {6},
numpages = {38},
keywords = {policy specification, usability, data governance, literature study, Collaborative access control}
}

@article{10.1145/3408314,
author = {Davoudian, Ali and Liu, Mengchi},
title = {Big Data Systems: A Software Engineering Perspective},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3408314},
doi = {10.1145/3408314},
abstract = {Big Data Systems (BDSs) are an emerging class of scalable software technologies whereby massive amounts of heterogeneous data are gathered from multiple sources, managed, analyzed (in batch, stream or hybrid fashion), and served to end-users and external applications. Such systems pose specific challenges in all phases of software development lifecycle and might become very complex by evolving data, technologies, and target value over time. Consequently, many organizations and enterprises have found it difficult to adopt BDSs. In this article, we provide insight into three major activities of software engineering in the context of BDSs as well as the choices made to tackle them regarding state-of-the-art research and industry efforts. These activities include the engineering of requirements, designing and constructing software to meet the specified requirements, and software/data quality assurance. We also disclose some open challenges of developing effective BDSs, which need attention from both researchers and practitioners.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {110},
numpages = {39},
keywords = {Big Data, quality assurance, software engineering, requirements engineering, software reference architecture, Big Data systems}
}

@article{10.1145/2996357,
author = {Li, Tuo and Ambrose, Jude Angelo and Ragel, Roshan and Parameswaran, Sri},
title = {Processor Design for Soft Errors: Challenges and State of the Art},
year = {2016},
issue_date = {December 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2996357},
doi = {10.1145/2996357},
abstract = {Today, soft errors are one of the major design technology challenges at and beyond the 22nm technology nodes. This article introduces the soft error problem from the perspective of processor design. This article also provides a survey of the existing soft error mitigation methods across different levels of design abstraction involved in processor design, including the device level, the circuit level, the architectural level, and the program level.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {57},
numpages = {44},
keywords = {soft error, Processor, recovery}
}

@article{10.1145/2886781,
author = {Werner, Sebastian and Navaridas, Javier and Luj\'{a}n, Mikel},
title = {A Survey on Design Approaches to Circumvent Permanent Faults in Networks-on-Chip},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2886781},
doi = {10.1145/2886781},
abstract = {Increasing fault rates in current and future technology nodes coupled with on-chip components in the hundreds calls for robust and fault-tolerant Network-on-Chip (NoC) designs. Given the central role of NoCs in today’s many-core chips, permanent faults impeding their original functionality may significantly influence performance, energy consumption, and correct operation of the entire system. As a result, fault-tolerant NoC design gained much attention in recent years. In this article, we review the vast research efforts regarding a NoC’s components, namely, topology, routing algorithm, router microarchitecture, as well as system-level approaches combined with reconfiguration; discuss the proposed architectures; and identify outstanding research questions.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {59},
numpages = {36},
keywords = {topology, system-level redundancy, routing algorithms, router microarchitecture, reconfiguration, Permanent failures}
}

@article{10.1145/3057266,
author = {Perera, Charith and Qin, Yongrui and Estrella, Julio C. and Reiff-Marganiec, Stephan and Vasilakos, Athanasios V.},
title = {Fog Computing for Sustainable Smart Cities: A Survey},
year = {2017},
issue_date = {October 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3057266},
doi = {10.1145/3057266},
abstract = {The Internet of Things (IoT) aims to connect billions of smart objects to the Internet, which can bring a promising future to smart cities. These objects are expected to generate large amounts of data and send the data to the cloud for further processing, especially for knowledge discovery, in order that appropriate actions can be taken. However, in reality sensing all possible data items captured by a smart object and then sending the complete captured data to the cloud is less useful. Further, such an approach would also lead to resource wastage (e.g., network, storage, etc.). The Fog (Edge) computing paradigm has been proposed to counterpart the weakness by pushing processes of knowledge discovery using data analytics to the edges. However, edge devices have limited computational capabilities. Due to inherited strengths and weaknesses, neither Cloud computing nor Fog computing paradigm addresses these challenges alone. Therefore, both paradigms need to work together in order to build a sustainable IoT infrastructure for smart cities. In this article, we review existing approaches that have been proposed to tackle the challenges in the Fog computing domain. Specifically, we describe several inspiring use case scenarios of Fog computing, identify ten key characteristics and common features of Fog computing, and compare more than 30 existing research efforts in this domain. Based on our review, we further identify several major functionalities that ideal Fog computing platforms should support and a number of open challenges toward implementing them, to shed light on future research directions on realizing Fog computing for building sustainable smart cities.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {32},
numpages = {43},
keywords = {smart cities, sustainability, fog computing, Internet of things}
}

@article{10.1145/3344255,
author = {Pisani, Paulo Henrique and Mhenni, Abir and Giot, Romain and Cherrier, Estelle and Poh, Norman and Ferreira de Carvalho, Andr\'{e} Carlos Ponce de Leon and Rosenberger, Christophe and Amara, Najoua Essoukri Ben},
title = {Adaptive Biometric Systems: Review and Perspectives},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3344255},
doi = {10.1145/3344255},
abstract = {With the widespread of computing and mobile devices, authentication using biometrics has received greater attention. Although biometric systems usually provide good solutions, the recognition performance tends to be affected over time due to changing conditions and aging of biometric data, which results in intra-class variability. Adaptive biometric systems, which adapt the biometric reference over time, have been proposed to deal with such intra-class variability. This article provides the most up-to-date and complete discussion on adaptive biometrics systems we are aware of, including formalization, terminology, sources or variations that motivates the use of adaptation, adaptation strategies, evaluation methodology, and open challenges. This field of research is sometimes referred to as template update.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {102},
numpages = {38},
keywords = {template update, template aging, evaluation methodology, biometric reference adaptation, Adaptive biometric systems}
}

@article{10.1145/3399669,
author = {Pekar, Adrian and Mocnej, Jozef and Seah, Winston K. G. and Zolotova, Iveta},
title = {Application Domain-Based Overview of IoT Network Traffic Characteristics},
year = {2020},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3399669},
doi = {10.1145/3399669},
abstract = {Over the past decade, the Internet of Things (IoT) has advanced rapidly. New technologies have been proposed and existing approaches optimised to meet user, society and industry requirements. However, as the complexity and heterogeneity of the traffic that flows through the networks are continuously growing, the innovation becomes difficult to achieve in both IoT and legacy networks. This article provides an overview of IoT application domains from a traffic characteristics perspective. Specifically, it identifies several groups of major IoT application use cases and discusses the exhibited traffic characteristics, used network technologies for implementation, and their feasibility as well as challenges. We stress that a key factor in future IoT development is network technologies and the way they handle and forward network traffic. The traffic characteristics emerging from this work can serve as a basis for future design proposals to develop more efficient solutions and improve the network technologies.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {87},
numpages = {33},
keywords = {IoT traffic characteristics, IoT, IoT network properties}
}

@article{10.1145/3347712,
author = {K., Vivekraj V. and Sen, Debashis and Raman, Balasubramanian},
title = {Video Skimming: Taxonomy and Comprehensive Survey},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3347712},
doi = {10.1145/3347712},
abstract = {Video skimming, also known as dynamic video summarization, generates a temporally abridged version of a given video. Skimming can be achieved by identifying significant components either in uni-modal or multi-modal features extracted from the video. Being dynamic in nature, video skimming, through temporal connectivity, allows better understanding of the video from its summary. Having this obvious advantage, recently, video skimming has drawn the focus of many researchers benefiting from the easy availability of the required computing resources. In this article, we provide a comprehensive survey on video skimming focusing on the substantial amount of literature from the past decade. We present a taxonomy of video skimming approaches and discuss their evolution highlighting key advances. We also provide a study on the components required for the evaluation of a video skimming performance.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {106},
numpages = {38},
keywords = {affective content, machine learning, attention model, Dynamic video summarization/video skimming, semantic concept, deep learning}
}

@article{10.1145/3440754,
author = {Meurisch, Christian and M\"{u}hlh\"{a}user, Max},
title = {Data Protection in AI Services: A Survey},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3440754},
doi = {10.1145/3440754},
abstract = {Advances in artificial intelligence (AI) have shaped today’s user services, enabling enhanced personalization and better support. As such AI-based services inevitably require user data, the resulting privacy implications are de facto the unacceptable face of this technology. In this article, we categorize and survey the cutting-edge research on privacy and data protection in the context of personalized AI services. We further review the different protection approaches at three different levels, namely, the management, system, and AI levels—showing that (i)&nbsp;not all of them meet our identified requirements of evolving AI services and that (ii)&nbsp;many challenges are addressed separately or fragmentarily by different research communities. Finally, we highlight open research challenges and future directions in data protection research, especially that comprehensive protection requires more interdisciplinary research and a combination of approaches at different levels.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {40},
numpages = {38},
keywords = {privacy, data decentralization, AI services, data protection, personalization}
}

@article{10.1145/3131346,
author = {Werner, Sebastian and Navaridas, Javier and Luj\'{a}n, Mikel},
title = {A Survey on Optical Network-on-Chip Architectures},
year = {2017},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3131346},
doi = {10.1145/3131346},
abstract = {Optical on-chip data transmission enabled by silicon photonics (SiP) is widely considered a key technology to overcome the bandwidth and energy limitations of electrical interconnects. The possibility of integrating optical links into the on-chip communication fabric has opened up a fascinating new research field—Optical Networks-on-Chip (ONoCs)—which has been gaining large interest by the community. SiP devices and materials, however, are still evolving, and dealing with optical data transmission on chip makes designers and researchers face a whole new set of obstacles and challenges. Designing efficient ONoCs is a challenging task and requires a detailed knowledge from on-chip traffic demands and patterns down to the physical layout and implications of integrating both electronic and photonic devices. In this paper, we provide an exhaustive review of recently proposed ONoC architectures, discuss their strengths and weaknesses, and outline active research areas. Moreover, we discuss recent research efforts in key enabling technologies, such as on-chip and adaptive laser sources, automatic synthesis tools, and ring heating techniques, which are essential to enable a widespread commercial adoption of ONoCs in the future.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {89},
numpages = {37},
keywords = {Photonic Design Automation Tools, Network-on-Chip, Optical buses, Hybrid Networks-on-Chip, Adaptive Laser Sources, Optical Networks-on-Chip, Silicon Photonics}
}

@article{10.1145/3212695,
author = {Allamanis, Miltiadis and Barr, Earl T. and Devanbu, Premkumar and Sutton, Charles},
title = {A Survey of Machine Learning for Big Code and Naturalness},
year = {2018},
issue_date = {September 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3212695},
doi = {10.1145/3212695},
abstract = {Research at the intersection of machine learning, programming languages, and software engineering has recently taken important steps in proposing learnable probabilistic models of source code that exploit the abundance of patterns of code. In this article, we survey this work. We contrast programming languages against natural languages and discuss how these similarities and differences drive the design of probabilistic models. We present a taxonomy based on the underlying design principles of each model and use it to navigate the literature. Then, we review how researchers have adapted these models to application areas and discuss cross-cutting and application-specific challenges and opportunities.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {81},
numpages = {37},
keywords = {Big code, software engineering tools, machine learning, code naturalness}
}

@article{10.1145/3314023,
author = {Gonzalez-Manzano, Lorena and Fuentes, Jose M. De and Ribagorda, Arturo},
title = {Leveraging User-Related Internet of Things for Continuous Authentication: A Survey},
year = {2019},
issue_date = {July 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3314023},
doi = {10.1145/3314023},
abstract = {Among all Internet of Things (IoT) devices, a subset of them are related to users. Leveraging these user-related IoT elements, it is possible to ensure the identity of the user for a period of time, thus avoiding impersonation. This need is known as Continuous Authentication (CA). Since 2009, a plethora of IoT-based CA academic research and industrial contributions have been proposed. We offer a comprehensive overview of 58 research papers regarding the main components of such a CA system. The status of the industry is studied as well, covering 32 market contributions, research projects, and related standards. Lessons learned, challenges, and open issues to foster further research in this area are finally presented.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {53},
numpages = {38},
keywords = {user-related IoT, CA algorithms, IoT-based CA, CA industry, CA evaluation metrics, Internet Of Things (IoT), Continuous Authentication (CA)}
}

@article{10.1145/3396302,
author = {Ngamakeur, Kan and Yongchareon, Sira and Yu, Jian and Rehman, Saeed Ur},
title = {A Survey on Device-Free Indoor Localization and Tracking in the Multi-Resident Environment},
year = {2020},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3396302},
doi = {10.1145/3396302},
abstract = {Indoor device-free localization and tracking can bring both convenience and privacy to users compared with traditional solutions such as camera-based surveillance and RFID tag-based tracking. Technologies such as Wi-Fi, wireless sensor, and infrared have been used to localize and track people living in care homes and office buildings. However, the presence of multiple residents introduces further challenges, such as the ambiguity in sensor measurements and target identity, to localization and tracking. In this article, we survey the latest development of device-free indoor localization and tracking in the multi-resident environment. We first present the fundamentals of device-free localization and tracking. Then, we discuss and compare the technologies used in device-free indoor localization and tracking. After discussing the steps involved in multi-resident localization and tracking including target detection, target counting, target identification, localization, and tracking, the techniques related to each step are classified and discussed in detail along with the performance metrics. Finally, we identify the research gap and point out future research directions. To the best of our knowledge, this survey is the most comprehensive work that covers a wide spectrum of the research area of device-free indoor localization and tracking.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {71},
numpages = {29},
keywords = {multi-resident, indoor tracking, Device-free, indoor localization, non-intrusive}
}

@article{10.1145/3450287,
author = {Zhao, Liang},
title = {Event Prediction in the Big Data Era: A Systematic Survey},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3450287},
doi = {10.1145/3450287},
abstract = {Events are occurrences in specific locations, time, and semantics that nontrivially impact either our society or the nature, such as earthquakes, civil unrest, system failures, pandemics, and crimes. It is highly desirable to be able to anticipate the occurrence of such events in advance to reduce the potential social upheaval and damage caused. Event prediction, which has traditionally been prohibitively challenging, is now becoming a viable option in the big data era and is thus experiencing rapid growth, also thanks to advances in high performance computers and new Artificial Intelligence techniques. There is a large amount of existing work that focuses on addressing the challenges involved, including heterogeneous multi-faceted outputs, complex (e.g., spatial, temporal, and semantic) dependencies, and streaming data feeds. Due to the strong interdisciplinary nature of event prediction problems, most existing event prediction methods were initially designed to deal with specific application domains, though the techniques and evaluation procedures utilized are usually generalizable across different domains. However, it is imperative yet difficult to cross-reference the techniques across different domains, given the absence of a comprehensive literature survey for event prediction. This article aims to provide a systematic and comprehensive survey of the technologies, applications, and evaluations of event prediction in the big data era. First, systematic categorization and summary of existing techniques are presented, which facilitate domain experts’ searches for suitable techniques and help model developers consolidate their research at the frontiers. Then, comprehensive categorization and summary of major application domains are provided to introduce wider applications to model developers to help them expand the impacts of their research. Evaluation metrics and procedures are summarized and standardized to unify the understanding of model performance among stakeholders, model developers, and domain experts in various application domains. Finally, open problems and future directions are discussed. Additional resources related to event prediction are included in the paper website: http://cs.emory.edu/∼lzhao41/projects/event_prediction_site.html.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {94},
numpages = {37},
keywords = {artificial intelligence, big data, Event prediction}
}

@article{10.1145/3139222,
author = {He, Suining and Shin, Kang G.},
title = {Geomagnetism for Smartphone-Based Indoor Localization: Challenges, Advances, and Comparisons},
year = {2017},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3139222},
doi = {10.1145/3139222},
abstract = {Geomagnetism has recently attracted considerable attention for indoor localization due to its pervasiveness and independence from extra infrastructure. Its location signature has been observed to be temporally stable and spatially discernible for localization purposes. This survey examines and analyzes the recent challenges and advances in geomagnetism-based indoor localization using smartphones. We first study smartphone-based geomagnetism measurements. We then review recent efforts in database construction and computation reduction, followed by state-of-the-art schemes in localizing the target. For each category, we identify practical deployment challenges and compare related studies. Finally, we summarize future directions and provide a guideline for new researchers in this field.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {97},
numpages = {37},
keywords = {indoor localization, mobile computing, Geomagnetism, smartphone}
}

@article{10.1145/3331447,
author = {Bertolino, Antonia and Angelis, Guglielmo De and Gallego, Micael and Garc\'{\i}a, Boni and Gort\'{a}zar, Francisco and Lonetti, Francesca and Marchetti, Eda},
title = {A Systematic Review on Cloud Testing},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3331447},
doi = {10.1145/3331447},
abstract = {A systematic literature review is presented that surveyed the topic of cloud testing over the period 2012--2017. Cloud testing can refer either to testing cloud-based systems (testing of the cloud) or to leveraging the cloud for testing purposes (testing in the cloud): both approaches (and their combination into testing of the cloud in the cloud) have drawn research interest. An extensive paper search was conducted by both automated query of popular digital libraries and snowballing, which resulted in the final selection of 147 primary studies. Along the survey, a framework has been incrementally derived that classifies cloud testing research among six main areas and their topics. The article includes a detailed analysis of the selected primary studies to identify trends and gaps, as well as an extensive report of the state-of-the-art as it emerges by answering the identified Research Questions. We find that cloud testing is an active research field, although not all topics have received enough attention and conclude by presenting the most relevant open research challenges for each area of the classification framework.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {93},
numpages = {42},
keywords = {systematic literature review, testing, Cloud computing}
}

@article{10.1145/3446662,
author = {Gharibshah, Zhabiz and Zhu, Xingquan},
title = {User Response Prediction in Online Advertising},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3446662},
doi = {10.1145/3446662},
abstract = {Online advertising, as a vast market, has gained significant attention in various platforms ranging from search engines, third-party websites, social media, and mobile apps. The prosperity of online campaigns is a challenge in online marketing and is usually evaluated by user response through different metrics, such as clicks on advertisement (ad) creatives, subscriptions to products, purchases of items, or explicit user feedback through online surveys. Recent years have witnessed a significant increase in the number of studies using computational approaches, including machine learning methods, for user response prediction. However, existing literature mainly focuses on algorithmic-driven designs to solve specific challenges, and no comprehensive review exists to answer many important questions. What are the parties involved in the online digital advertising eco-systems? What type of data are available for user response prediction? How do we predict user response in a reliable and/or transparent way? In this survey, we provide a comprehensive review of user response prediction in online advertising and related recommender applications. Our essential goal is to provide a thorough understanding of online advertising platforms, stakeholders, data availability, and typical ways of user response prediction. We propose a taxonomy to categorize state-of-the-art user response prediction methods, primarily focusing on the current progress of machine learning methods used in different online platforms. In addition, we also review applications of user response prediction, benchmark datasets, and open source codes in the field.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {64},
numpages = {43},
keywords = {recurrent neural network, conversion, convolutional neural network, supplier side platform, demand side platform, dwell time, data management platform, factorization machines, deep learning, graph neural network, knowledge graph, Click, landing page, bounce rate, impression, user engagement}
}

@article{10.1145/3037755,
author = {Muram, Faiz ul and Tran, Huy and Zdun, Uwe},
title = {Systematic Review of Software Behavioral Model Consistency Checking},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3037755},
doi = {10.1145/3037755},
abstract = {In software development, models are often used to represent multiple views of the same system. Such models need to be properly related to each other in order to provide a consistent description of the developed system. Models may contain contradictory system specifications, for instance, when they evolve independently. Therefore, it is very crucial to ensure that models conform to each other. In this context, we focus on consistency checking of behavior models. Several techniques and approaches have been proposed in the existing literature to support behavioral model consistency checking. This article presents a Systematic Literature Review (SLR) that was carried out to obtain an overview of the various consistency concepts, problems, and solutions proposed regarding behavior models. In our study, the identification and selection of the primary studies was based on a well-planned search strategy. The search process identified a total of 1770 studies, out of which 96 have been thoroughly analyzed according to our predefined SLR protocol. The SLR aims to highlight the state-of-the-art of software behavior model consistency checking and identify potential gaps for future research. Based on research topics in selected studies, we have identified seven main categories: targeted software models, types of consistency checking, consistency checking techniques, inconsistency handling, type of study and evaluation, automation support, and practical impact. The findings of the systematic review also reveal suggestions for future research, such as improving the quality of study design and conducting evaluations, and application of research outcomes in industrial settings. For this purpose, appropriate strategy for inconsistency handling, better tool support for consistency checking and/or development tool integration should be considered in future studies.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {17},
numpages = {39},
keywords = {consistency types, Software behavioral model, systematic literature review, consistency checking}
}

@article{10.1145/3392064,
author = {Boukerche, Azzedine and Soto, Victor},
title = {Computation Offloading and Retrieval for Vehicular Edge Computing: Algorithms, Models, and Classification},
year = {2020},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3392064},
doi = {10.1145/3392064},
abstract = {The rapid evolution of mobile devices, their applications, and the amount of data generated by them causes a significant increase in bandwidth consumption and congestions in the network core. Edge Computing offers a solution to these performance drawbacks by extending the cloud paradigm to the edge of the network using capable nodes of processing compute-intensive tasks. In the recent years, vehicular edge computing has emerged for supporting mobile applications. Such paradigm relies on vehicles as edge node devices for providing storage, computation, and bandwidth resources for resource-constrained mobile applications. In this article, we study the challenges of computation offloading for vehicular edge computing. We propose a new classification for the better understanding of the literature designing vehicular edge computing. We propose a taxonomy to classify partitioning solutions in filter-based and automatic techniques; scheduling is separated in adaptive, social-based, and deadline-sensitive methods, and finally data retrieval is organized in secure, distance, mobility prediction, and social-based procedures. By reviewing and analyzing literature, we found that vehicular edge computing is feasible and a viable option to address the increasing volume of data traffic. Moreover, we discuss the open challenges and future directions that must be addressed towards efficient and effective computation offloading and retrieval from mobile users to vehicular edge computing.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {80},
numpages = {35},
keywords = {data retrieval, Computation offloading, vehicular cloud}
}

@article{10.1145/3047307,
author = {Chi, Lianhua and Zhu, Xingquan},
title = {Hashing Techniques: A Survey and Taxonomy},
year = {2017},
issue_date = {April 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3047307},
doi = {10.1145/3047307},
abstract = {With the rapid development of information storage and networking technologies, quintillion bytes of data are generated every day from social networks, business transactions, sensors, and many other domains. The increasing data volumes impose significant challenges to traditional data analysis tools in storing, processing, and analyzing these extremely large-scale data. For decades, hashing has been one of the most effective tools commonly used to compress data for fast access and analysis, as well as information integrity verification. Hashing techniques have also evolved from simple randomization approaches to advanced adaptive methods considering locality, structure, label information, and data security, for effective hashing. This survey reviews and categorizes existing hashing techniques as a taxonomy, in order to provide a comprehensive view of mainstream hashing techniques for different types of data and applications. The taxonomy also studies the uniqueness of each method and therefore can serve as technique references in understanding the niche of different hashing mechanisms for future development.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {11},
numpages = {36},
keywords = {cryptographic hashing, data coding, compression, Hashing, dimension reduction}
}

@article{10.1145/2379776.2379787,
author = {Harman, Mark and Mansouri, S. Afshin and Zhang, Yuanyuan},
title = {Search-Based Software Engineering: Trends, Techniques and Applications},
year = {2012},
issue_date = {November 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2379776.2379787},
doi = {10.1145/2379776.2379787},
abstract = {In the past five years there has been a dramatic increase in work on Search-Based Software Engineering (SBSE), an approach to Software Engineering (SE) in which Search-Based Optimization (SBO) algorithms are used to address problems in SE. SBSE has been applied to problems throughout the SE lifecycle, from requirements and project planning to maintenance and reengineering. The approach is attractive because it offers a suite of adaptive automated and semiautomated solutions in situations typified by large complex problem spaces with multiple competing and conflicting objectives.This article1 provides a review and classification of literature on SBSE. The work identifies research trends and relationships between the techniques applied and the applications to which they have been applied and highlights gaps in the literature and avenues for further research.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {11},
numpages = {61},
keywords = {Software engineering, search-based techniques, survey}
}

@article{10.1145/3057269,
author = {Kazmi, Rafaqut and Jawawi, Dayang N. A. and Mohamad, Radziah and Ghani, Imran},
title = {Effective Regression Test Case Selection: A Systematic Literature Review},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3057269},
doi = {10.1145/3057269},
abstract = {Regression test case selection techniques attempt to increase the testing effectiveness based on the measurement capabilities, such as cost, coverage, and fault detection. This systematic literature review presents state-of-the-art research in effective regression test case selection techniques. We examined 47 empirical studies published between 2007 and 2015. The selected studies are categorized according to the selection procedure, empirical study design, and adequacy criteria with respect to their effectiveness measurement capability and methods used to measure the validity of these results.The results showed that mining and learning-based regression test case selection was reported in 39% of the studies, unit level testing was reported in 18% of the studies, and object-oriented environment (Java) was used in 26% of the studies. Structural faults, the most common target, was used in 55% of the studies. Overall, only 39% of the studies conducted followed experimental guidelines and are reproducible.There are 7 different cost measures, 13 different coverage types, and 5 fault-detection metrics reported in these studies. It is also observed that 70% of the studies being analyzed used cost as the effectiveness measure compared to 31% that used fault-detection capability and 16% that used coverage.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {29},
numpages = {32},
keywords = {SLR, fault detection ability, coverage, cost effectiveness, Software testing}
}

@article{10.1145/2841425,
author = {Natella, Roberto and Cotroneo, Domenico and Madeira, Henrique S.},
title = {Assessing Dependability with Software Fault Injection: A Survey},
year = {2016},
issue_date = {February 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2841425},
doi = {10.1145/2841425},
abstract = {With the rise of software complexity, software-related accidents represent a significant threat for computer-based systems. Software Fault Injection is a method to anticipate worst-case scenarios caused by faulty software through the deliberate injection of software faults. This survey provides a comprehensive overview of the state of the art on Software Fault Injection to support researchers and practitioners in the selection of the approach that best fits their dependability assessment goals, and it discusses how these approaches have evolved to achieve fault representativeness, efficiency, and usability. The survey includes a description of relevant applications of Software Fault Injection in the context of fault-tolerant systems.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {44},
numpages = {55},
keywords = {software fault tolerance, Software faults, dependability assessment}
}

@article{10.1145/3322240,
author = {Chandrakala, S. and Jayalakshmi, S. L.},
title = {Environmental Audio Scene and Sound Event Recognition for Autonomous Surveillance: A Survey and Comparative Studies},
year = {2019},
issue_date = {July 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3322240},
doi = {10.1145/3322240},
abstract = {Monitoring of human and social activities is becoming increasingly pervasive in our living environment for public security and safety applications. The recognition of suspicious events is important in both indoor and outdoor environments, such as child-care centers, smart-homes, old-age homes, residential areas, office environments, elevators, and smart cities. Environmental audio scene and sound event recognition are the fundamental tasks involved in many audio surveillance applications. Although numerous approaches have been proposed, robust environmental audio surveillance remains a huge challenge due to various reasons, such as various types of overlapping audio sounds, background noises, and lack of universal and multi-modal datasets. The goal of this article is to review various features of representing audio scenes and sound events and provide appropriate machine learning algorithms for audio surveillance tasks. Benchmark datasets are categorized based on the real-world scenarios of audio surveillance applications. To have a quantitative understanding, some of the state-of-the-art approaches are evaluated based on two benchmark datasets for audio scenes and sound event recognition tasks. Finally, we outline the possible future directions for improving the recognition of environmental audio scenes and sound events.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {63},
numpages = {34},
keywords = {environmental audio scene recognition, audio features, audio tagging, Environmental audio surveillance, acoustic source localization, sound event recognition}
}

@article{10.1145/2501654.2501668,
author = {Lazaro, Daniel and Marques, Joan Manuel and Jorba, Josep and Vilajosana, Xavier},
title = {Decentralized Resource Discovery Mechanisms for Distributed Computing in Peer-to-Peer Environments},
year = {2013},
issue_date = {August 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2501654.2501668},
doi = {10.1145/2501654.2501668},
abstract = {Resource discovery is an important part of distributed computing and resource sharing systems, like grids and utility computing. Because of the increasing importance of decentralized and peer-to-peer environments, characterized by high dynamism and churn, a number of resource discovery mechanisms, mainly based on peer-to-peer techniques, have been presented recently. We present and classify them according to criteria like their topology and the degree of achievement of various common requirements of great importance for the targeted environments, as well as compare their reported performance. These classifications intend to provide an intuitive vision of the strengths and weaknesses of each system.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {54},
numpages = {40},
keywords = {resource discovery, Ad hoc grids, overlay networks, P2P networks, utility computing}
}

@article{10.1145/3066904,
author = {Barforoush, Ahmad and Shirazi, Hossein and Emami, Hojjat},
title = {A New Classification Framework to Evaluate the Entity Profiling on the Web: Past, Present and Future},
year = {2017},
issue_date = {October 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3066904},
doi = {10.1145/3066904},
abstract = {Recently, we have witnessed entity profiling (EP) becoming increasingly one of the most important topics in information extraction, personalized applications, and web data analysis. EP aims to identify, extract, and represent a compact summary of valuable information about an entity based on the data related to it. To determine how EP systems have developed, during the last few years, this article reviews EP systems through a survey of the literature, from 2000 to 2015. To fulfill this aim, we introduce a comparison framework to compare and classify EP systems. Our comparison framework is composed of thirteen criteria that include: profiling source, the entity being modeled, the information that constitutes the profile, representation schema, profile construction technique, scale, scope/target domain, language, updating mechanism, enrichment technique, dynamicity, evaluation method, and application among others. Then, using the comparison framework, we discuss the recent development of the field and list some of the open problems and main trends that have emerged in EP to provide a proper guideline for researchers to develop or use robust profiling systems with suitable features according to their needs.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {39},
numpages = {39},
keywords = {semantic web, personalization, Entity profiling}
}

@article{10.1145/3403953,
author = {Aljeri, Noura and Boukerche, Azzedine},
title = {Mobility Management in 5G-Enabled Vehicular Networks: Models, Protocols, and Classification},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3403953},
doi = {10.1145/3403953},
abstract = {Over the past few years, the next generation of vehicular networks is envisioned to play an essential part in autonomous driving, traffic management, and infotainment applications. The next generation of intelligent vehicular networks enabled by 5G systems will integrate various heterogeneous wireless techniques to enable time-sensitive services with guaranteed quality of service and ultimate bandwidth usage. However, to allow the dense diversity of wireless technologies, seamless and reliable wireless communication protocols need to be thoroughly investigated in vehicular networks environment. Henceforth, efficient mobility management protocols that mitigate the challenges of vehicles’ mobility is essential to support massive data loads throughout various applications. In this article, we review different mobility management protocols and their ability to address issues related to 5G-enabled vehicular networks within the related works. First, we provide a broad view of existing models of vehicular networks and their applicability to the next generation of wireless networks. Next, we propose a classification of several vehicular network models that suit the 5G wireless network, followed by a thorough discussion of the mobility management challenges in each of these network models that need to be addressed and then discuss each of their benefits and drawbacks accordingly.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {92},
numpages = {35},
keywords = {machine learning, VANETs, Mobility management, handoff management, 5G networks}
}

@article{10.1145/3403956,
author = {Canal, Ramon and Hernandez, Carles and Tornero, Rafa and Cilardo, Alessandro and Massari, Giuseppe and Reghenzani, Federico and Fornaciari, William and Zapater, Marina and Atienza, David and Oleksiak, Ariel and Piundefinedtek, Wojciech and Abella, Jaume},
title = {Predictive Reliability and Fault Management in Exascale Systems: State of the Art and Perspectives},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3403956},
doi = {10.1145/3403956},
abstract = {Performance and power constraints come together with Complementary Metal Oxide Semiconductor technology scaling in future Exascale systems. Technology scaling makes each individual transistor more prone to faults and, due to the exponential increase in the number of devices per chip, to higher system fault rates. Consequently, High-performance Computing (HPC) systems need to integrate prediction, detection, and recovery mechanisms to cope with faults efficiently. This article reviews fault detection, fault prediction, and recovery techniques in HPC systems, from electronics to system level. We analyze their strengths and limitations. Finally, we identify the promising paths to meet the reliability levels of Exascale systems.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {95},
numpages = {32},
keywords = {reliability, supercomputing, HPC, failures, survey, exascale, prediction, faults}
}

@article{10.1145/3421764,
author = {Zhu, Liehuang and Karim, Md M. and Sharif, Kashif and Xu, Chang and Li, Fan and Du, Xiaojiang and Guizani, Mohsen},
title = {SDN Controllers: A Comprehensive Analysis and Performance Evaluation Study},
year = {2020},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3421764},
doi = {10.1145/3421764},
abstract = {Software-defined networks offer flexible and intelligent network operations by splitting a traditional network into a centralized control plane and a programmable data plane. The controller in the control plane is the fundamental element used to manage all operations of the data plane. Hence, the performance and capabilities of the controller itself are essential in achieving optimal performance. Furthermore, the tools used to benchmark their performance must be accurate and useful in measuring different evaluation parameters. There are dozens of controller proposals for general and specialized networks in the literature. However, there is a very limited comprehensive quantitative analysis for them. In this article, we present a comprehensive qualitative comparison of different SDN controllers, along with a quantitative analysis of their performance in different network scenarios. We categorize and classify 34 controllers and present a qualitative comparison. We also present a comparative analysis of controllers for specialized networks such as the Internet of Things, blockchain networks, vehicular networks, and wireless sensor networks. We also discuss in-depth capabilities of benchmarking tools and provide a comparative analysis of their capabilities. This work uses three benchmarking tools to compare 9 controllers and presents a detailed analysis of their performance, along with discussion on performance of specialized network controllers.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {133},
numpages = {40},
keywords = {Software-defined networks, vehicular networks, SDN controller, wireless sensor networks, benchmarking tools, Internet of Things, blockchain}
}

@article{10.1145/2871167,
author = {Mittal, Sparsh},
title = {A Survey of Architectural Techniques for Managing Process Variation},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2871167},
doi = {10.1145/2871167},
abstract = {Process variation—deviation in parameters from their nominal specifications—threatens to slow down and even pause technological scaling, and mitigation of it is the way to continue the benefits of chip miniaturization. In this article, we present a survey of architectural techniques for managing process variation (PV) in modern processors. We also classify these techniques based on several important parameters to bring out their similarities and differences. The aim of this article is to provide insights to researchers into the state of the art in PV management techniques and motivate them to further improve these techniques for designing PV-resilient processors of tomorrow.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {54},
numpages = {29},
keywords = {parametric variation, 3D processor, nonvolatile memory (NVM), GPU, DRAM, resilience, core to core (C2C), Review, die to die (D2D), delay and leakage variation, CPU, within die (WID)}
}

@article{10.1145/3397269,
author = {Guo, Ruocheng and Cheng, Lu and Li, Jundong and Hahn, P. Richard and Liu, Huan},
title = {A Survey of Learning Causality with Data: Problems and Methods},
year = {2020},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3397269},
doi = {10.1145/3397269},
abstract = {This work considers the question of how convenient access to copious data impacts our ability to learn causal effects and relations. In what ways is learning causality in the era of big data different from—or the same as—the traditional one? To answer this question, this survey provides a comprehensive and structured review of both traditional and frontier methods in learning causality and relations along with the connections between causality and machine learning. This work points out on a case-by-case basis how big data facilitates, complicates, or motivates each approach.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {75},
numpages = {37},
keywords = {Causal machine learning, causal discovery, causal inference}
}

@article{10.1145/2480741.2480744,
author = {Hoseini-Tabatabaei, Seyed Amir and Gluhak, Alexander and Tafazolli, Rahim},
title = {A Survey on Smartphone-Based Systems for Opportunistic User Context Recognition},
year = {2013},
issue_date = {June 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2480741.2480744},
doi = {10.1145/2480741.2480744},
abstract = {The ever-growing computation and storage capability of mobile phones have given rise to mobile-centric context recognition systems, which are able to sense and analyze the context of the carrier so as to provide an appropriate level of service. As nonintrusive autonomous sensing and context recognition are desirable characteristics of a personal sensing system; efforts have been made to develop opportunistic sensing techniques on mobile phones. The resulting combination of these approaches has ushered in a new realm of applications, namely opportunistic user context recognition with mobile phones.This article surveys the existing research and approaches towards realization of such systems. In doing so, the typical architecture of a mobile-centric user context recognition system as a sequential process of sensing, preprocessing, and context recognition phases is introduced. The main techniques used for the realization of the respective processes during these phases are described, and their strengths and limitations are highlighted. In addition, lessons learned from previous approaches are presented as motivation for future research. Finally, several open challenges are discussed as possible ways to extend the capabilities of current systems and improve their real-world experience.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {27},
numpages = {51},
keywords = {smartphone, Pervasive computing, opportunistic sensing, user context recognition}
}

@article{10.1145/2522968.2522977,
author = {Yahyavi, Amir and Kemme, Bettina},
title = {Peer-to-Peer Architectures for Massively Multiplayer Online Games: A Survey},
year = {2013},
issue_date = {October 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2522968.2522977},
doi = {10.1145/2522968.2522977},
abstract = {Scalability, fast response time, and low cost are of utmost importance in designing a successful massively multiplayer online game. The underlying architecture plays an important role in meeting these conditions. Peer-to-peer architectures, due to their distributed and collaborative nature, have low infrastructure costs and can achieve high scalability. They can also achieve fast response times by creating direct connections between players. However, these architectures face many challenges. Distributing a game among peers makes maintaining control over the game more complex. Peer-to-peer architectures also tend to be vulnerable to churn and cheating. Moreover, different genres of games have different requirements that should be met by the underlying architecture, rendering the task of designing a general-purpose architecture harder. Many peer-to-peer gaming solutions have been proposed that utilize a range of techniques while using somewhat different and confusing terminologies. This article presents a comprehensive overview of current peer-to-peer solutions for massively multiplayer games using a uniform terminology.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {9},
numpages = {51},
keywords = {Peer-to-peer networking, cheating, consistency control, replication, fault tolerance, multicasting, massively multiplayer online games, network overlays, incentives, interest management, commercial applications}
}

@article{10.1145/2906151,
author = {Jiang, Wenjun and Wang, Guojun and Bhuiyan, Md Zakirul Alam and Wu, Jie},
title = {Understanding Graph-Based Trust Evaluation in Online Social Networks: Methodologies and Challenges},
year = {2016},
issue_date = {July 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2906151},
doi = {10.1145/2906151},
abstract = {Online Social Networks (OSNs) are becoming a popular method of meeting people and keeping in touch with friends. OSNs resort to trust evaluation models and algorithms to improve service quality and enhance user experiences. Much research has been done to evaluate trust and predict the trustworthiness of a target, usually from the view of a source. Graph-based approaches make up a major portion of the existing works, in which the trust value is calculated through a trusted graph (or trusted network, web of trust, or multiple trust chains). In this article, we focus on graph-based trust evaluation models in OSNs, particularly in the computer science literature. We first summarize the features of OSNs and the properties of trust. Then we comparatively review two categories of graph-simplification-based and graph-analogy-based approaches and discuss their individual problems and challenges. We also analyze the common challenges of all graph-based models. To provide an integrated view of trust evaluation, we conduct a brief review of its pre- and postprocesses (i.e., the preparation and validation of trust models, including information collection, performance evaluation, and related applications). Finally, we identify some open challenges that all trust models are facing.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {10},
numpages = {35},
keywords = {analogy, online social networks (OSNs), simplification, trust evaluation, trust models, Trusted graph}
}

@article{10.1145/3292652,
author = {Testa, Rafael Luiz and Corr\^{e}a, Cl\'{e}ber Gimenez and Machado-Lima, Ariane and Nunes, F\'{a}tima L. S.},
title = {Synthesis of Facial Expressions in Photographs: Characteristics, Approaches, and Challenges},
year = {2019},
issue_date = {February 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3292652},
doi = {10.1145/3292652},
abstract = {The synthesis of facial expressions has applicationsin areas such as interactive games, biometrics systems, and training of people with disorders, among others. Although this is an area relatively well explored in the literature, there are no recent studies proposing to systematize an overview of research in the area. This systematic review analyzes the approaches to the synthesis of facial expressions in photographs, as well as important aspects of the synthesis process, such as preprocessing techniques, databases, and evaluation metrics. Forty-eight studies from three different scientific databases were analyzed. From these studies, we established an overview of the process, including all the stages used to synthesize expressions in facial images. We also analyze important aspects involved in these stages such as methods and techniques of each stage, databases, and evaluation metrics. We observed that machine learning approaches are the most widely used to synthesize expressions. Landmark identification, deformation, mapping, fusion, and training are common tasks considered in the approaches. We also found that few studies used metrics to evaluate the results, and most studies used public databases. Although the studies analyzed generated consistent and realistic results while preserving the identity of the subject, there are still research themes to be exploited.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {124},
numpages = {35},
keywords = {facial expression mapping, expression transfer, facial expression generation, Facial expression synthesis, facial expression cloning}
}

@article{10.1145/3383458,
author = {Le, Triet H. M. and Chen, Hao and Babar, Muhammad Ali},
title = {Deep Learning for Source Code Modeling and Generation: Models, Applications, and Challenges},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3383458},
doi = {10.1145/3383458},
abstract = {Deep Learning (DL) techniques for Natural Language Processing have been evolving remarkably fast. Recently, the DL advances in language modeling, machine translation, and paragraph understanding are so prominent that the potential of DL in Software Engineering cannot be overlooked, especially in the field of program learning. To facilitate further research and applications of DL in this field, we provide a comprehensive review to categorize and investigate existing DL methods for source code modeling and generation. To address the limitations of the traditional source code models, we formulate common program learning tasks under an encoder-decoder framework. After that, we introduce recent DL mechanisms suitable to solve such problems. Then, we present the state-of-the-art practices and discuss their challenges with some recommendations for practitioners and researchers as well.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {62},
numpages = {38},
keywords = {Deep learning, source code modeling, source code generation, big code}
}

@article{10.1145/2932707,
author = {Fang, Ruogu and Pouyanfar, Samira and Yang, Yimin and Chen, Shu-Ching and Iyengar, S. S.},
title = {Computational Health Informatics in the Big Data Age: A Survey},
year = {2016},
issue_date = {July 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2932707},
doi = {10.1145/2932707},
abstract = {The explosive growth and widespread accessibility of digital health data have led to a surge of research activity in the healthcare and data sciences fields. The conventional approaches for health data management have achieved limited success as they are incapable of handling the huge amount of complex data with high volume, high velocity, and high variety. This article presents a comprehensive overview of the existing challenges, techniques, and future directions for computational health informatics in the big data age, with a structured analysis of the historical and state-of-the-art methods. We have summarized the challenges into four Vs (i.e., volume, velocity, variety, and veracity) and proposed a systematic data-processing pipeline for generic big data in health informatics, covering data capturing, storing, sharing, analyzing, searching, and decision support. Specifically, numerous techniques and algorithms in machine learning are categorized and compared. On the basis of this material, we identify and discuss the essential prospects lying ahead for computational health informatics in this big data age.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {12},
numpages = {36},
keywords = {4V challenges, data mining, Big data analytics, survey, machine learning, clinical decision support, computational health informatics}
}

@article{10.1145/3447242,
author = {Dunne, Rob and Morris, Tim and Harper, Simon},
title = {A Survey of Ambient Intelligence},
year = {2021},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3447242},
doi = {10.1145/3447242},
abstract = {Ambient Intelligence (AmI) is the application and embedding of artificial intelligence into everyday environments to seamlessly provide assistive and predictive support in a multitude of scenarios via an invisible user interface. These can be as diverse as autonomous vehicles, smart homes, industrial settings, and healthcare facilities—referred to as Ambient Assistive Living. This survey gives an overview of the field; defines key terms; discusses social, cultural, and ethical issues; and outlines the state of the art in AmI technology, and where opportunities for further research exist. We guide the reader through AmI from its inception more than 20 years ago, focussing on the important topics and research achievements of the past 10 years since the last major survey, before finally detailing the most recents research trends and forecasting where this technology is likely to develop. This survey covers domains, use cases, scenarios, and datasets; cultural concerns and usability issues; security, privacy, and ethics; interaction and recognition; prediction and intelligence; and hardware, infrastructure, and mobile devices. This survey serves as an introduction for researchers and the technical layperson into the topic of AmI and identifies notable opportunities for further research.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {73},
numpages = {27},
keywords = {Human-computer interaction, smart environments, machine learning}
}

@article{10.1145/3092697,
author = {Li, Tao and Zeng, Chunqiu and Jiang, Yexi and Zhou, Wubai and Tang, Liang and Liu, Zheng and Huang, Yue},
title = {Data-Driven Techniques in Computing System Management},
year = {2017},
issue_date = {October 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3092697},
doi = {10.1145/3092697},
abstract = {Modern forms of computing systems are becoming progressively more complex, with an increasing number of heterogeneous hardware and software components. As a result, it is quite challenging to manage these complex systems and meet the requirements in manageability, dependability, and performance that are demanded by enterprise customers. This survey presents a variety of data-driven techniques and applications with a focus on computing system management. In particular, the survey introduces intelligent methods for event generation that can transform diverse log data sources into structured events, reviews different types of event patterns and the corresponding event-mining techniques, and summarizes various event summarization methods and data-driven approaches for problem diagnosis in system management. We hope this survey will provide a good overview for data-driven techniques in computing system management.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {45},
numpages = {43},
keywords = {application, Computing system management, data mining}
}

@article{10.1145/1922649.1922659,
author = {Duarte, Elias P. and Ziwich, Roverli P. and Albini, Luiz C.P.},
title = {A Survey of Comparison-Based System-Level Diagnosis},
year = {2011},
issue_date = {April 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/1922649.1922659},
doi = {10.1145/1922649.1922659},
abstract = {The growing complexity and dependability requirements of hardware, software, and networks demand efficient techniques for discovering disruptive behavior in those systems. Comparison-based diagnosis is a realistic approach to detect faulty units based on the outputs of tasks executed by system units. This survey integrates the vast amount of research efforts that have been produced in this field, from the earliest theoretical models to new promising applications. Key results also include the quantitative evaluation of a relevant reliability metric—the diagnosability—of several popular interconnection network topologies. Relevant diagnosis algorithms are also described. The survey aims at clarifying and uncovering the potential of this technology, which can be applied to improve the dependability of diverse complex computer systems.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {22},
numpages = {56},
keywords = {Comparison-based diagnosis, dependability, multiprocessor systems}
}

@article{10.1145/2632296,
author = {Abid, Shahbaz Akhtar and Othman, Mazliza and Shah, Nadir},
title = {A Survey on DHT-Based Routing for Large-Scale Mobile Ad Hoc Networks},
year = {2014},
issue_date = {January 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2632296},
doi = {10.1145/2632296},
abstract = {Mobile ad hoc networks (MANETs) are infrastructureless and distributed communication systems that require sophisticated approaches to routing to cope with node mobility and heterogeneous application requirements. In the past few years, distributed hash table (DHT) has come forth as a useful additional technique to the design and specification of spontaneous and self-organized networks. Researchers have exploited its advantages by implementing it at the network layer and developing scalable routing protocols for MANETs. The implementation of DHT-based routing in a MANET requires different algorithms and specifications compared to routing in the Internet because a MANET has its unique characteristics, such as node mobility, spontaneous networking, decentralized architecture, limited transmission range, dynamic topology, and frequent network partitioning/merging.In this article, we present a comprehensive survey of research related to DHT-based routing that aims at enhancing the scalability of MANETs. We present a vivid taxonomy of DHT-based routing protocols and the guidelines to design such protocols for MANETs. We compare the features, strengths, and weaknesses of existing DHT-based routing protocols and highlight key research challenges that are vital to address. The outcome of the analysis serves as a guide for anyone willing to delve into research on DHT-based routing in MANETs.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {20},
numpages = {46},
keywords = {overlays, mismatch problem, scalability, routing, Wireless networks, logical network, distributed hash tables}
}

@article{10.1145/2187671.2187675,
author = {Kong, Joonho and Chung, Sung Woo and Skadron, Kevin},
title = {Recent Thermal Management Techniques for Microprocessors},
year = {2012},
issue_date = {June 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2187671.2187675},
doi = {10.1145/2187671.2187675},
abstract = {Microprocessor design has recently encountered many constraints such as power, energy, reliability, and temperature. Among these challenging issues, temperature-related issues have become especially important within the past several years. We summarize recent thermal management techniques for microprocessors, focusing on those that affect or rely on the microarchitecture. We categorize thermal management techniques into six main categories: temperature monitoring, microarchitectural techniques, floorplanning, OS/compiler techniques, liquid cooling techniques, and thermal reliability/security. Temperature monitoring, a requirement for Dynamic Thermal Management (DTM), includes temperature estimation and sensor placement techniques for accurate temperature measurement or estimation. Microarchitectural techniques include both static and dynamic thermal management techniques that control hardware structures. Floorplanning covers a range of thermal-aware floorplanning techniques for 2D and 3D microprocessors. OS/compiler techniques include thermal-aware task scheduling and instruction scheduling techniques. Liquid cooling techniques are higher-capacity alternatives to conventional air cooling techniques. Thermal reliability/security issues cover temperature-dependent reliability modeling, Dynamic Reliability Management (DRM), and malicious codes that specifically cause overheating. Temperature-related issues will only become more challenging as process technology continues to evolve and transistor densities scale up faster than power per transistor scales down. The overall objective of this survey is to give microprocessor designers a broad perspective on various aspects of designing thermal-aware microprocessors and to guide future thermal management studies.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {13},
numpages = {42},
keywords = {performance and reliability, microprocessor, Thermal management}
}

@article{10.1145/3373265,
author = {Rai, Sunny and Chakraverty, Shampa},
title = {A Survey on Computational Metaphor Processing},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3373265},
doi = {10.1145/3373265},
abstract = {In the last decade, the problem of computational metaphor processing has garnered immense attention from the domains of computational linguistics and cognition. A wide panorama of approaches, ranging from a hand-coded rule system to deep learning techniques, have been proposed to automate different aspects of metaphor processing. In this article, we systematically examine the major theoretical views on metaphor and present their classification. We discuss the existing literature to provide a concise yet representative picture of computational metaphor processing. We conclude the article with possible research directions.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {24},
numpages = {37},
keywords = {metaphor processing, conceptual metaphor, linguistic metaphor, figurative language, metaphor interpretation, Metaphor, metaphor detection, creative text}
}

@article{10.1145/2723701,
author = {Coile\'{a}in, Diarmuid \'{O} and O'mahony, Donal},
title = {Accounting and Accountability in Content Distribution Architectures: A Survey},
year = {2015},
issue_date = {July 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2723701},
doi = {10.1145/2723701},
abstract = {Many content distribution architectures offer desirable elements that lead to less bandwidth usage, reduced network congestion, higher content availability, and reduced costs. However, their level of adoption and utilization in commercial environments depends on the level of content accounting and accountability they offer. Content accounting refers to any information that a content distributor needs to track relating to the delivery of content to its intended consumers. In contrast, content accountability refers to the willingness of the communicating infrastructure to produce accurate and verifiable information about the content distribution process. This article surveys existing and proposed future content delivery architectures detailing their methodologies for providing efficient low-cost content distribution, content accounting, and accountability across trustworthy and untrustworthy infrastructures. We use two methods to help identify the drawbacks and merits of these architectures. The first is a taxonomy for accounting information based on our analysis of logging information gathered from the surveyed systems. The second is a generic model for content distribution based on a synthesis of desirable elements from the surveyed architectures. These methods help highlight key architectural elements required for efficient low-cost content distribution. Finally, we identify outstanding challenges related to establishing accountability in accounting information produced for content distributed across trusted and untrusted infrastructures.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {59},
numpages = {35},
keywords = {peer-to-peer, information-centric networking, content distribution network, caching, content distribution, CDN-P2P, Accountability}
}

@article{10.1145/3172867,
author = {Rossetti, Giulio and Cazabet, R\'{e}my},
title = {Community Discovery in Dynamic Networks: A Survey},
year = {2018},
issue_date = {June 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3172867},
doi = {10.1145/3172867},
abstract = {Several research studies have shown that complex networks modeling real-world phenomena are characterized by striking properties: (i) they are organized according to community structure, and (ii) their structure evolves with time. Many researchers have worked on methods that can efficiently unveil substructures in complex networks, giving birth to the field of community discovery. A novel and fascinating problem started capturing researcher interest recently: the identification of evolving communities. Dynamic networks can be used to model the evolution of a system: nodes and edges are mutable, and their presence, or absence, deeply impacts the community structure that composes them.This survey aims to present the distinctive features and challenges of dynamic community discovery and propose a classification of published approaches. As a “user manual,” this work organizes state-of-the-art methodologies into a taxonomy, based on their rationale, and their specific instantiation. Given a definition of network dynamics, desired community characteristics, and analytical needs, this survey will support researchers to identify the set of approaches that best fit their needs. The proposed classification could also help researchers choose in which direction to orient their future research.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {35},
numpages = {37},
keywords = {Dynamic networks, temporal networks, community discovery}
}

@article{10.1145/2567666,
author = {Chung, Haera and Teuscher, Christof and Pande, Partha},
title = {Design and Evaluation of Technology-Agnostic Heterogeneous Networks-on-Chip},
year = {2014},
issue_date = {April 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {3},
issn = {1550-4832},
url = {https://doi.org/10.1145/2567666},
doi = {10.1145/2567666},
abstract = {Traditional metal-wire-based networks-on-chip (NoC) suffer from high latency and power dissipation as the system size scales up in the number of cores. This limitation stems from the inherent multihop communication nature of larger NoCs. It has previously been shown that the performance of NoCs can be significantly improved by introducing long-range, low power, and high-bandwidth single-hop links between distant cores. While previous work has focused on specific NoC architectures and configurations, it remains an open question whether heterogeneous link types are beneficial in a broad range of NoC architectures. In this article, we show that a generic NoC architecture with heterogeneous link types allows for NoCs with higher bandwidth at a lower cost compared to homogeneous networks. We further show that such NoCs scale up significantly better in terms of performance and cost. We demonstrate these broadly-applicable results by using a technology-agnostic complex network approach that targets NoC architectures with various emerging link types.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = may,
articleno = {20},
numpages = {27},
keywords = {Networks-on-chip, heterogeneous, optical, wireless}
}

@article{10.1145/3436728,
author = {Distler, Tobias},
title = {Byzantine Fault-Tolerant State-Machine Replication from a Systems Perspective},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3436728},
doi = {10.1145/3436728},
abstract = {Byzantine fault-tolerant&nbsp;(BFT) state-machine replication makes it possible to design systems that are resilient against arbitrary faults, a requirement considered crucial for an increasing number of use cases such as permissioned blockchains, firewalls, and SCADA systems. Unfortunately, the strong fault-tolerance guarantees provided by BFT replication protocols come at the cost of a high complexity, which is why it is inherently difficult to correctly implement BFT systems in practice. This is all the more true with regard to the plethora of solutions and ideas that have been developed in recent years to improve performance, availability, or resource efficiency. This survey aims at facilitating the task of building BFT systems by presenting an overview of state-of-the-art techniques and analyzing their practical implications, for example, with respect to applicability and composability. In particular, this includes problems that arise in the context of concrete implementations, but which are often times passed over in literature. Starting with an in-depth discussion of the most important architectural building blocks of a BFT system&nbsp;(i.e.,&nbsp;clients, agreement protocol, execution stage), the survey then focuses on selected approaches and mechanisms addressing specific tasks such as checkpointing and recovery.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {24},
numpages = {38},
keywords = {state-machine replication, Byzantine fault tolerance}
}

@article{10.1145/3344548,
author = {Labatut, Vincent and Bost, Xavier},
title = {Extraction and Analysis of Fictional Character Networks: A Survey},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3344548},
doi = {10.1145/3344548},
abstract = {A character network is a graph extracted from a narrative in which vertices represent characters and edges correspond to interactions between them. A number of narrative-related problems can be addressed automatically through the analysis of character networks, such as summarization, classification, or role detection. Character networks are particularly relevant when considering works of fiction (e.g., novels, plays, movies, TV series), as their exploitation allows developing information retrieval and recommendation systems. However, works of fiction possess specific properties that make these tasks harder.This survey aims at presenting and organizing the scientific literature related to the extraction of character networks from works of fiction, as well as their analysis. We first describe the extraction process in a generic way and explain how its constituting steps are implemented in practice, depending on the medium of the narrative, the goal of the network analysis, and other factors. We then review the descriptive tools used to characterize character networks, with a focus on the way they are interpreted in this context. We illustrate the relevance of character networks by also providing a review of applications derived from their analysis. Finally, we identify the limitations of the existing approaches and the most promising perspectives.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {89},
numpages = {40},
keywords = {Information retrieval, character network, graph analysis, graph extraction, work of fiction, narrative}
}

@article{10.1145/3447240,
author = {Bertolino, Antonia and Braione, Pietro and Angelis, Guglielmo De and Gazzola, Luca and Kifetew, Fitsum and Mariani, Leonardo and Orr\`{u}, Matteo and Pezz\`{e}, Mauro and Pietrantuono, Roberto and Russo, Stefano and Tonella, Paolo},
title = {A Survey of Field-Based Testing Techniques},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3447240},
doi = {10.1145/3447240},
abstract = {Field testing refers to testing techniques that operate in the field to reveal those faults that escape in-house testing. Field testing techniques are becoming increasingly popular with the growing complexity of contemporary software systems. In this article, we present the first systematic survey of field testing approaches over a body of 80 collected studies, and propose their categorization based on the environment and the system on which field testing is performed. We discuss four research questions addressing how software is tested in the field, what is tested in the field, which are the requirements, and how field tests are managed, and identify many challenging research directions.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {92},
numpages = {39},
keywords = {in-vivo testing, Software testing, field testing, ex-vivo testing}
}

@article{10.1145/3379344,
author = {Lu, Ying and Luo, Lingkun and Huang, Di and Wang, Yunhong and Chen, Liming},
title = {Knowledge Transfer in Vision Recognition: A Survey},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3379344},
doi = {10.1145/3379344},
abstract = {In this survey, we propose to explore and discuss the common rules behind knowledge transfer works for vision recognition tasks. To achieve this, we firstly discuss the different kinds of reusable knowledge existing in a vision recognition task, and then we categorize different knowledge transfer approaches depending on where the knowledge comes from and where the knowledge goes. Compared to previous surveys on knowledge transfer that are from the problem-oriented perspective or from the technique-oriented perspective, our viewpoint is closer to the nature of knowledge transfer and reveals common rules behind different transfer learning settings and applications. Besides different knowledge transfer categories, we also show some research works that study the transferability between different vision recognition tasks. We further give a discussion about the introduced research works and show some potential research directions in this field.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {37},
numpages = {35},
keywords = {vision recognition, Knowledge transfer, machine learning, transfer learning, computer vision}
}

@article{10.1145/3020266,
author = {Su, Ting and Wu, Ke and Miao, Weikai and Pu, Geguang and He, Jifeng and Chen, Yuting and Su, Zhendong},
title = {A Survey on Data-Flow Testing},
year = {2017},
issue_date = {April 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3020266},
doi = {10.1145/3020266},
abstract = {Data-flow testing (DFT) is a family of testing strategies designed to verify the interactions between each program variable’s definition and its uses. Such a test objective of interest is referred to as a def-use pair. DFT selects test data with respect to various test adequacy criteria (i.e., data-flow coverage criteria) to exercise each pair. The original conception of DFT was introduced by Herman in 1976. Since then, a number of studies have been conducted, both theoretically and empirically, to analyze DFT’s complexity and effectiveness. In the past four decades, DFT has been continuously concerned, and various approaches from different aspects are proposed to pursue automatic and efficient data-flow testing. This survey presents a detailed overview of data-flow testing, including challenges and approaches in enforcing and automating it: (1) it introduces the data-flow analysis techniques that are used to identify def-use pairs; (2) it classifies and discusses techniques for data-flow-based test data generation, such as search-based testing, random testing, collateral-coverage-based testing, symbolic-execution-based testing, and model-checking-based testing; (3) it discusses techniques for tracking data-flow coverage; (4) it presents several DFT applications, including software fault localization, web security testing, and specification consistency checking; and (5) it summarizes recent advances and discusses future research directions toward more practical data-flow testing.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {5},
numpages = {35},
keywords = {data-flow analysis, coverage tracking, Data-flow testing, coverage criteria, test data generation}
}

@article{10.1145/3372790,
author = {Cini, Nevin and Yalcin, Gulay},
title = {A Methodology for Comparing the Reliability of GPU-Based and CPU-Based HPCs},
year = {2020},
issue_date = {May 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3372790},
doi = {10.1145/3372790},
abstract = {Today, GPUs are widely used as coprocessors/accelerators in High-Performance Heterogeneous Computing due to their many advantages. However, many researches emphasize that GPUs are not as reliable as desired yet. Despite the fact that GPUs are more vulnerable to hardware errors than CPUs, the use of GPUs in HPCs is increasing more and more. Moreover, due to native reliability problems of GPUs, combining a great number of GPUs with CPUs can significantly increase HPCs’ failure rates. For this reason, analyzing the reliability characteristics of GPU-based HPCs has become a very important issue. Therefore, in this study we evaluate the reliability of GPU-based HPCs. For this purpose, we first examined field data analysis studies for GPU-based and CPU-based HPCs and identified factors that could increase systems failure/error rates. We then compared GPU-based HPCs with CPU-based HPCs in terms of reliability with the help of these factors in order to point out reliability challenges of GPU-based HPCs. Our primary goal is to present a study that can guide the researchers in this field by indicating the current state of GPU-based heterogeneous HPCs and requirements for the future, in terms of reliability. Our second goal is to offer a methodology to compare the reliability of GPU-based HPCs and CPU-based HPCs. To the best of our knowledge, this is the first survey study to compare the reliability of GPU-based and CPU-based HPCs in a systematic manner.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {22},
numpages = {33},
keywords = {System failure, checkpoint/recovery, log file analysis}
}

@article{10.1145/3136625,
author = {Li, Jundong and Cheng, Kewei and Wang, Suhang and Morstatter, Fred and Trevino, Robert P. and Tang, Jiliang and Liu, Huan},
title = {Feature Selection: A Data Perspective},
year = {2017},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3136625},
doi = {10.1145/3136625},
abstract = {Feature selection, as a data preprocessing strategy, has been proven to be effective and efficient in preparing data (especially high-dimensional data) for various data-mining and machine-learning problems. The objectives of feature selection include building simpler and more comprehensible models, improving data-mining performance, and preparing clean, understandable data. The recent proliferation of big data has presented some substantial challenges and opportunities to feature selection. In this survey, we provide a comprehensive and structured overview of recent advances in feature selection research. Motivated by current challenges and opportunities in the era of big data, we revisit feature selection research from a data perspective and review representative feature selection algorithms for conventional data, structured data, heterogeneous data and streaming data. Methodologically, to emphasize the differences and similarities of most existing feature selection algorithms for conventional data, we categorize them into four main groups: similarity-based, information-theoretical-based, sparse-learning-based, and statistical-based methods. To facilitate and promote the research in this community, we also present an open source feature selection repository that consists of most of the popular feature selection algorithms (http://featureselection.asu.edu/). Also, we use it as an example to show how to evaluate feature selection algorithms. At the end of the survey, we present a discussion about some open problems and challenges that require more attention in future research.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {94},
numpages = {45},
keywords = {Feature selection}
}

@article{10.1145/3410159,
author = {Zimmerling, Marco and Mottola, Luca and Santini, Silvia},
title = {Synchronous Transmissions in Low-Power Wireless: A Survey of Communication Protocols and Network Services},
year = {2020},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3410159},
doi = {10.1145/3410159},
abstract = {Low-power wireless communication is a central building block of cyber-physical systems and the Internet of Things. Conventional low-power wireless protocols make avoiding packet collisions a cornerstone design choice. The concept of synchronous transmissions challenges this view. As collisions are not necessarily destructive, under specific circumstances, commodity low-power wireless radios are often able to receive useful information even in the presence of superimposed signals from different transmitters. We survey the growing number of protocols that exploit synchronous transmissions for higher robustness and efficiency as well as unprecedented functionality and versatility compared to conventional designs. The illustration of protocols based on synchronous transmissions is cast in a conceptional framework we establish, with the goal of highlighting differences and similarities among the proposed solutions. We conclude this article with a discussion on open questions and challenges in this research field.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {121},
numpages = {39},
keywords = {message-in-message effect, simplicity, capture effect, multi-hop communication, synchronous transmissions, sender diversity, constructive interference, Low-power wireless networks}
}

@article{10.1145/3230633,
author = {Wan, Changsheng and Wang, Li and Phoha, Vir V.},
title = {A Survey on Gait Recognition},
year = {2018},
issue_date = {January 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3230633},
doi = {10.1145/3230633},
abstract = {Recognizing people by their gait has become more and more popular nowadays due to the following reasons. First, gait recognition can work well remotely. Second, gait recognition can be done from low-resolution videos and with simple instrumentation. Third, gait recognition can be done without the cooperation of individuals. Fourth, gait recognition can work well while other features such as faces and fingerprints are hidden. Finally, gait features are typically difficult to be impersonated.Recent ubiquity of smartphones that capture gait patterns through accelerometers and gyroscope and advances in machine learning have opened new research directions and applications in gait recognition. A timely survey that addresses current advances is missing.In this article, we survey research works in gait recognition. In addition to recognition based on video, we address new modalities, such as recognition based on floor sensors, radars, and accelerometers; new approaches that include machine learning methods; and examine challenges and vulnerabilities in this field. In addition, we propose a set of future research directions. Our review reveals the current state-of-art and can be helpful to both experts and newcomers of gait recognition. Moreover, it lists future works and publicly available databases in gait recognition for researchers.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {89},
numpages = {35},
keywords = {Biometrics, individual identification, gait recognition}
}

@article{10.1145/3379445,
author = {Bonifati, Angela and Holubov\'{a}, Irena and Prat-P\'{e}rez, Arnau and Sakr, Sherif},
title = {Graph Generators: State of the Art and Open Challenges},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3379445},
doi = {10.1145/3379445},
abstract = {The abundance of interconnected data has fueled the design and implementation of graph generators reproducing real-world linking properties or gauging the effectiveness of graph algorithms, techniques, and applications manipulating these data. We consider graph generation across multiple subfields, such as Semantic Web, graph databases, social networks, and community detection, along with general graphs. Despite the disparate requirements of modern graph generators throughout these communities, we analyze them under a common umbrella, reaching out the functionalities, the practical usage, and their supported operations. We argue that this classification is serving the need of providing scientists, researchers, and practitioners with the right data generator at hand for their work. This survey provides a comprehensive overview of the state-of-the-art graph generators by focusing on those that are pertinent and suitable for several data-intensive tasks. Finally, we discuss open challenges and missing requirements of current graph generators along with their future extensions to new emerging fields.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {36},
numpages = {30},
keywords = {Big data management, graph data, synthetic data, generators, benchmarks}
}

@article{10.1145/2856127,
author = {Calzarossa, Maria Carla and Massari, Luisa and Tessera, Daniele},
title = {Workload Characterization: A Survey Revisited},
year = {2016},
issue_date = {February 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2856127},
doi = {10.1145/2856127},
abstract = {Workload characterization is a well-established discipline that plays a key role in many performance engineering studies. The large-scale social behavior inherent in the applications and services being deployed nowadays leads to rapid changes in workload intensity and characteristics and opens new challenging management and performance issues. A deep understanding of user behavior and workload properties and patterns is therefore compelling. This article presents a comprehensive survey of the state of the art of workload characterization by addressing its exploitation in some popular application domains. In particular, we focus on conventional web workloads as well as on the workloads associated with online social networks, video services, mobile apps, and cloud computing infrastructures. We discuss the peculiarities of these workloads and present the methodological approaches and modeling techniques applied for their characterization. The role of workload models in various scenarios (e.g., performance evaluation, capacity planning, content distribution, resource provisioning) is also analyzed.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {48},
numpages = {43},
keywords = {Workload characterization, workload measurements, video services, mobile apps, performance evaluation, cloud computing, statistical techniques, web workload, online social networks, user behavior, graph analysis}
}

@article{10.1145/3363562,
author = {Chen, Junjie and Patra, Jibesh and Pradel, Michael and Xiong, Yingfei and Zhang, Hongyu and Hao, Dan and Zhang, Lu},
title = {A Survey of Compiler Testing},
year = {2020},
issue_date = {May 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3363562},
doi = {10.1145/3363562},
abstract = {Virtually any software running on a computer has been processed by a compiler or a compiler-like tool. Because compilers are such a crucial piece of infrastructure for building software, their correctness is of paramount importance. To validate and increase the correctness of compilers, significant research efforts have been devoted to testing compilers. This survey article provides a comprehensive summary of the current state-of-the-art of research on compiler testing. The survey covers different aspects of the compiler testing problem, including how to construct test programs, what test oracles to use for determining whether a compiler behaves correctly, how to execute compiler tests efficiently, and how to help compiler developers take action on bugs discovered by compiler testing. Moreover, we survey work that empirically studies the strengths and weaknesses of current compiler testing research and practice. Based on the discussion of existing work, we outline several open challenges that remain to be addressed in future work.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {4},
numpages = {36},
keywords = {Compiler testing, test program generation, test oracle, compiler debugging, test optimization}
}

@article{10.1145/3094263,
author = {Gala, Neel and Krithivasan, Sarada and Tsai, Wei-Yu and Li, Xueqing and Narayanan, Vijaykrishnan and Kamakoti, V.},
title = {An Accuracy Tunable Non-Boolean Co-Processor Using Coupled Nano-Oscillators},
year = {2017},
issue_date = {March 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {1},
issn = {1550-4832},
url = {https://doi.org/10.1145/3094263},
doi = {10.1145/3094263},
abstract = {As we enter an era witnessing the closer end of Dennard scaling, where further reduction in power supply-voltage to reduce power consumption becomes more challenging in conventional systems, a goal of developing a system capable of performing large computations with minimal area and power overheads needs more optimization aspects. A rigorous exploration of alternate computing techniques, which can mitigate the limitations of Complementary Metal-Oxide Semiconductor (CMOS) technology scaling and conventional Boolean systems, is imperative. Reflecting on these lines of thought, in this article we explore the potential of non-Boolean computing employing nano-oscillators for performing varied functions. We use a two coupled nano-oscillator as our basic computational model and propose an architecture for a non-Boolean coupled oscillator based co-processor capable of executing certain functions that are commonly used across a variety of approximate application domains. The proposed architecture includes an accuracy tunable knob, which can be tuned by the programmer at runtime. The functionality of the proposed co-processor is verified using a soft coupled oscillator model based on Kuramoto oscillators. The article also demonstrates how real-world applications such as Vector Quantization, Digit Recognition, Structural Health Monitoring, and the like, can be deployed on the proposed model. The proposed co-processor architecture is generic in nature and can be implemented using any of the existing modern day nano-oscillator technologies such as Resonant Body Transistors (RBTs), Spin-Torque Nano-Oscillators (STNOs), and Metal-Insulator Transition (MITs) . In this article, we perform a validation of the proposed architecture using the HyperField Effect Transistor (FET) technology-based coupled oscillators, which provide improvements of up to 3.5\texttimes{} increase in clock speed and up to 10.75\texttimes{} and 14.12\texttimes{} reduction in area and power consumption, respectively, as compared to a conventional Boolean CMOS accelerator executing the same functions.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = sep,
articleno = {1},
numpages = {28},
keywords = {Kuramoto, co-processor, Non-boolean computing, digit recognition, coupled oscillators, structural health monitoring, micro-architecture, vector quantization}
}

@article{10.1145/2971481,
author = {Cho, Keewon and Kang, Wooheon and Cho, Hyungjun and Lee, Changwook and Kang, Sungho},
title = {A Survey of Repair Analysis Algorithms for Memories},
year = {2016},
issue_date = {December 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2971481},
doi = {10.1145/2971481},
abstract = {Current rapid advancements in deep submicron technologies have enabled the implementation of very large memory devices and embedded memories. However, the memory growth increases the number of defects, reducing the yield and reliability of such devices. Faulty cells are commonly repaired by using redundant cells, which are embedded in memory arrays by adding spare rows and columns. The repair process requires an efficient redundancy analysis (RA) algorithm. Spare architectures for the repair of faulty memory include one-dimensional (1D) spare architectures, two-dimensional (2D) spare architectures, and configurable spare architectures. Of these types, 2D spare architectures, which prepare extra rows and columns for repair, are popular because of their better repairing efficiency than 1D spare architectures and easier implementation than configurable spare architectures. However, because the complexity of the RA is NP-complete, the RA algorithm should consider various factors in order to determine a repair solution. The performance depends on three factors: analysis time, repair rate, and area overhead. In this article, we survey RA algorithms for memory devices as well as built-in repair algorithms for improving these performance factors. Built-in redundancy analysis techniques for emergent three-dimensional integrated circuits are also discussed. Based on this analysis, we then discuss future research challenges for faulty-memory repair studies.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {47},
numpages = {41},
keywords = {built-in self-test (BIST), normalized repair rate, repair rate, Built-in redundancy analysis (BIRA), built-in self-repair (BISR)}
}

@article{10.1145/3158645,
author = {Abdallah, Zahraa S. and Gaber, Mohamed Medhat and Srinivasan, Bala and Krishnaswamy, Shonali},
title = {Activity Recognition with Evolving Data Streams: A Review},
year = {2018},
issue_date = {September 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3158645},
doi = {10.1145/3158645},
abstract = {Activity recognition aims to provide accurate and opportune information on people’s activities by leveraging sensory data available in today’s sensory rich environments. Nowadays, activity recognition has become an emerging field in the areas of pervasive and ubiquitous computing. A typical activity recognition technique processes data streams that evolve from sensing platforms such as mobile sensors, on body sensors, and/or ambient sensors. This article surveys the two overlapped areas of research of activity recognition and data stream mining. The perspective of this article is to review the adaptation capabilities of activity recognition techniques in streaming environment. Categories of techniques are identified based on different features in both data streams and activity recognition. The pros and cons of the algorithms in each category are analysed, and the possible directions of future research are indicated.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {71},
numpages = {36},
keywords = {adaptive learning, stream mining, Activity recognition, transfer learning}
}

@article{10.1145/3357375,
author = {Liu, Leibo and Zhu, Jianfeng and Li, Zhaoshi and Lu, Yanan and Deng, Yangdong and Han, Jie and Yin, Shouyi and Wei, Shaojun},
title = {A Survey of Coarse-Grained Reconfigurable Architecture and Design: Taxonomy, Challenges, and Applications},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3357375},
doi = {10.1145/3357375},
abstract = {As general-purpose processors have hit the power wall and chip fabrication cost escalates alarmingly, coarse-grained reconfigurable architectures (CGRAs) are attracting increasing interest from both academia and industry, because they offer the performance and energy efficiency of hardware with the flexibility of software. However, CGRAs are not yet mature in terms of programmability, productivity, and adaptability. This article reviews the architecture and design of CGRAs thoroughly for the purpose of exploiting their full potential. First, a novel multidimensional taxonomy is proposed. Second, major challenges and the corresponding state-of-the-art techniques are surveyed and analyzed. Finally, the future development is discussed.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {118},
numpages = {39},
keywords = {reconfigurable computing, spatial architecture, scheduling, CGRA, dataflow}
}

@article{10.1145/3448302,
author = {Tang, Yunbo and Chen, Dan and Li, Xiaoli},
title = {Dimensionality Reduction Methods for Brain Imaging Data Analysis},
year = {2021},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3448302},
doi = {10.1145/3448302},
abstract = {The past century has witnessed the grand success of brain imaging technologies, such as electroencephalography and magnetic resonance imaging, in probing cognitive states and pathological brain dynamics for neuroscience research and neurology practices. Human brain is “the most complex object in the universe,” and brain imaging data&nbsp;(BID) are routinely of multiple/many attributes and highly non-stationary. These are determined by the nature of BID as the recordings of the evolving processes of the brain(s) under examination in various views. Driven by the increasingly high demands for precision, efficiency, and reliability in neuro-science and engineering tasks, dimensionality reduction has become a priority issue in BID analysis to handle the notoriously high dimensionality and large scale of big BID sets as well as the enormously complicated interdependencies among data elements. This has become particularly urgent and challenging in this big data era.Dimensionality reduction theories and methods manifest unrivaled potential in revealing key insights to BID via offering the low-dimensional/tiny representations/features, which may preserve critical characterizations of massive neuronal activities and brain functional and/or malfunctional states of interest. This study surveys the most salient work along this direction conforming to a 3-dimensional taxonomy with respect to (1) the scale of BID, of which the design with this consideration is important for the potential applications; (2) the order of BID, in which a higher order denotes more BID attributes manipulatable by the method; and (3) linearity, in which the method’s degree of linearity largely determines the “fidelity” in BID exploration. This study defines criteria for qualitative evaluations of these works in terms of effectiveness, interpretability, efficiency, and scalability. The classifications and evaluations based on the taxonomy provide comprehensive guides to (1) how existing research and development efforts are distributed and (2) their performance, features, and potential in influential applications especially when involving big data. In the end, this study crystallizes the open technical issues and proposes research challenges that must be solved to enable further researches in this area of great potential.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {87},
numpages = {36},
keywords = {dimensionality reduction, feature learning, factorization, statistical tensor analysis, Brain imaging data, big data}
}

@article{10.1145/2693443,
author = {Maglo, Adrien and Lavou\'{e}, Guillaume and Dupont, Florent and Hudelot, C\'{e}line},
title = {3D Mesh Compression: Survey, Comparisons, and Emerging Trends},
year = {2015},
issue_date = {April 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2693443},
doi = {10.1145/2693443},
abstract = {3D meshes are commonly used to represent virtual surface and volumes. However, their raw data representations take a large amount of space. Hence, 3D mesh compression has been an active research topic since the mid 1990s. In 2005, two very good review articles describing the pioneering works were published. Yet, new technologies have emerged since then. In this article, we summarize the early works and put the focus on these novel approaches. We classify and describe the algorithms, evaluate their performance, and provide synthetic comparisons. We also outline the emerging trends for future research.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {44},
numpages = {41},
keywords = {compression, single rate, 3D mesh, progressive, dynamic, random accessible}
}

@article{10.1145/2543581.2543593,
author = {Pedro, Ricardo Wandr\'{e} Dias and Nunes, F\'{a}tima L. S. and Machado-Lima, Ariane},
title = {Using Grammars for Pattern Recognition in Images: A Systematic Review},
year = {2013},
issue_date = {November 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2543581.2543593},
doi = {10.1145/2543581.2543593},
abstract = {Grammars are widely used to describe string languages such as programming and natural languages and, more recently, biosequences. Moreover, since the 1980s grammars have been used in computer vision and related areas. Some factors accountable for this increasing use regard its relatively simple understanding and its ability to represent some semantic pattern models found in images, both spatially and temporally. The objective of this article is to present an overview regarding the use of syntactic pattern recognition methods in image representations in several applications. To achieve this purpose, we used a systematic review process to investigate the main digital libraries in the area and to document the phases of the study in order to allow the auditing and further investigation. The results indicated that in some of the studies retrieved, manually created grammars were used to comply with a particular purpose. Other studies performed a learning process of the grammatical rules. In addition, this article also points out still unexplored research opportunities in the literature.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {26},
numpages = {34},
keywords = {computer vision, formal languages, image representation, pattern recognition, Image grammars, syntactic methods}
}

@article{10.1145/2539117,
author = {Cotroneo, Domenico and Natella, Roberto and Pietrantuono, Roberto and Russo, Stefano},
title = {A Survey of Software Aging and Rejuvenation Studies},
year = {2014},
issue_date = {January 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {1},
issn = {1550-4832},
url = {https://doi.org/10.1145/2539117},
doi = {10.1145/2539117},
abstract = {Software aging is a phenomenon plaguing many long-running complex software systems, which exhibit performance degradation or an increasing failure rate. Several strategies based on the proactive rejuvenation of the software state have been proposed to counteract software aging and prevent failures. This survey article provides an overview of studies on Software Aging and Rejuvenation (SAR) that have appeared in major journals and conference proceedings, with respect to the statistical approaches that have been used to forecast software aging phenomena and to plan rejuvenation, the kind of systems and aging effects that have been studied, and the techniques that have been proposed to rejuvenate complex software systems. The analysis is useful to identify key results from SAR research, and it is leveraged in this article to highlight trends and open issues.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = jan,
articleno = {8},
numpages = {34},
keywords = {Software aging, software aging literature, software rejuvenation, performance degradation, aging-related bugs}
}

@article{10.1145/2655691,
author = {Calabrese, Francesco and Ferrari, Laura and Blondel, Vincent D.},
title = {Urban Sensing Using Mobile Phone Network Data: A Survey of Research},
year = {2014},
issue_date = {January 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2655691},
doi = {10.1145/2655691},
abstract = {The recent development of telecommunication networks is producing an unprecedented wealth of information and, as a consequence, an increasing interest in analyzing such data both from telecoms and from other stakeholders' points of view. In particular, mobile phone datasets offer access to insights into urban dynamics and human activities at an unprecedented scale and level of detail, representing a huge opportunity for research and real-world applications. This article surveys the new ideas and techniques related to the use of telecommunication data for urban sensing. We outline the data that can be collected from telecommunication networks as well as their strengths and weaknesses with a particular focus on urban sensing. We survey existing filtering and processing techniques to extract insights from this data and summarize them to provide recommendations on which datasets and techniques to use for specific urban sensing applications. Finally, we discuss a number of challenges and open research areas currently being faced in this field. We strongly believe the material and recommendations presented here will become increasingly important as mobile phone network datasets are becoming more accessible to the research community.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {25},
numpages = {20},
keywords = {urban planning, urban transportation, data mining, Mobile phone data}
}

@article{10.1145/3379463,
author = {Kannengie\ss{}er, Niclas and Lins, Sebastian and Dehling, Tobias and Sunyaev, Ali},
title = {Trade-Offs between Distributed Ledger Technology Characteristics},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3379463},
doi = {10.1145/3379463},
abstract = {When developing peer-to-peer applications on distributed ledger technology (DLT), a crucial decision is the selection of a suitable DLT design (e.g., Ethereum), because it is hard to change the underlying DLT design post hoc. To facilitate the selection of suitable DLT designs, we review DLT characteristics and identify trade-offs between them. Furthermore, we assess how DLT designs account for these trade-offs and we develop archetypes for DLT designs that cater to specific requirements of applications on DLT. The main purpose of our article is to introduce scientific and practical audiences to the intricacies of DLT designs and to support development of viable applications on DLT.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {42},
numpages = {37},
keywords = {distributed ledger technology, viability, peer-to-peer, Blockchain, application development, suitability}
}

@article{10.1145/3432814,
author = {Mukhopadhyay, Anand Kumar and Sharma, Atul and Chakrabarti, Indrajit and Basu, Arindam and Sharad, Mrigank},
title = {Power-Efficient Spike Sorting Scheme Using Analog Spiking Neural Network Classifier},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {2},
issn = {1550-4832},
url = {https://doi.org/10.1145/3432814},
doi = {10.1145/3432814},
abstract = {The method to map the neural signals to the neuron from which it originates is spike sorting. A low-power spike sorting system is presented for a neural implant device. The spike sorter constitutes a two-step trainer module that is shared by the signal acquisition channel associated with multiple electrodes. A low-power Spiking Neural Network (SNN) module is responsible for assigning the spike class. The two-step shared supervised on-chip training module is presented for improved training accuracy for the SNN. Post implant, the relatively power-hungry training module can be activated conditionally based on a statistics-driven retraining algorithm that allows on the fly training and adaptation. A low-power analog implementation for the SNN classifier is proposed based on resistive crossbar memory exploiting its approximate computing nature. Owing to the direct mapping of SNN functionality using physical characteristics of devices, the analog mode implementation can achieve ∼21 \texttimes{} lower power than its fully digital counterpart. We also incorporate the effect of device variation in the training process to suppress the impact of inevitable inaccuracies in such resistive crossbar devices on the classification accuracy. A variation-aware, digitally calibrated analog front-end is also presented, which consumes less than ∼50 nW power and interfaces with the digital training module as well as the analog SNN spike sorting module. Hence, the proposed scheme is a low-power, variation-tolerant, adaptive, digitally trained, all-analog spike sorter device, applicable to implantable and wearable multichannel brain-machine interfaces.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = jan,
articleno = {12},
numpages = {29},
keywords = {Adaptation, neuromorphic computing, spike sorting, spiking neural network (SNN), resistive crossbar network (RCN)}
}

@article{10.1145/3444689,
author = {Zhao, Liping and Alhoshan, Waad and Ferrari, Alessio and Letsholo, Keletso J. and Ajagbe, Muideen A. and Chioasca, Erol-Valeriu and Batista-Navarro, Riza T.},
title = {Natural Language Processing for Requirements Engineering: A Systematic Mapping Study},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3444689},
doi = {10.1145/3444689},
abstract = {Natural Language Processing for Requirements Engineering (NLP4RE) is an area of research and development that seeks to apply natural language processing (NLP) techniques, tools, and resources to the requirements engineering (RE) process, to support human analysts to carry out various linguistic analysis tasks on textual requirements documents, such as detecting language issues, identifying key domain concepts, and establishing requirements traceability links. This article reports on a mapping study that surveys the landscape of NLP4RE research to provide a holistic understanding of the field. Following the guidance of systematic review, the mapping study is directed by five research questions, cutting across five aspects of NLP4RE research, concerning the state of the literature, the state of empirical research, the research focus, the state of tool development, and the usage of NLP technologies. Our main results are as follows: (i) we identify a total of 404 primary studies relevant to NLP4RE, which were published over the past 36 years and from 170 different venues; (ii) most of these studies (67.08%) are solution proposals, assessed by a laboratory experiment or an example application, while only a small percentage (7%) are assessed in industrial settings; (iii) a large proportion of the studies (42.70%) focus on the requirements analysis phase, with quality defect detection as their central task and requirements specification as their commonly processed document type; (iv) 130 NLP4RE tools (i.e., RE specific NLP tools) are extracted from these studies, but only 17 of them (13.08%) are available for download; (v) 231 different NLP technologies are also identified, comprising 140 NLP techniques, 66 NLP tools, and 25 NLP resources, but most of them—particularly those novel NLP techniques and specialized tools—are used infrequently; by contrast, commonly used NLP technologies are traditional analysis techniques (e.g., POS tagging and tokenization), general-purpose tools (e.g., Stanford CoreNLP and GATE) and generic language lexicons (WordNet and British National Corpus). The mapping study not only provides a collection of the literature in NLP4RE but also, more importantly, establishes a structure to frame the existing literature&nbsp;through categorization, synthesis and conceptualization of the main theoretical concepts and relationships that encompass&nbsp;both RE and NLP aspects. Our work thus produces a conceptual framework of NLP4RE. The framework is used to identify research gaps and directions, highlight technology transfer needs, and encourage more synergies between the RE community, the NLP one, and the software&nbsp;and systems&nbsp;practitioners. Our results can be used as a starting point to frame future studies according to a well-defined terminology and can be expanded as new technologies and novel solutions emerge.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {55},
numpages = {41},
keywords = {software engineering (SE), systematic review, systematic mapping study, Requirements engineering (RE), natural language processing (NLP)}
}

@article{10.1145/2534189,
author = {Uneson, Marcus},
title = {When Errors Become the Rule: Twenty Years with Transformation-Based Learning},
year = {2014},
issue_date = {April 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2534189},
doi = {10.1145/2534189},
abstract = {Transformation-based learning (TBL) is a machine learning method for, in particular, sequential classification, invented by Eric Brill [Brill 1993b, 1995a]. It is widely used within computational linguistics and natural language processing, but surprisingly little in other areas.TBL is a simple yet flexible paradigm, which achieves competitive or even state-of-the-art performance in several areas and does not overtrain easily. It is especially successful at catching local, fixed-distance dependencies and seamlessly exploits information from heterogeneous discrete feature types. The learned representation—an ordered list of transformation rules—is compact and efficient, with clear semantics. Individual rules are interpretable and often meaningful to humans.The present article offers a survey of the most important theoretical work on TBL, addressing a perceived gap in the literature. Because the method should be useful also outside the world of computational linguistics and natural language processing, a chief aim is to provide an informal but relatively comprehensive introduction, readable also by people coming from other specialities.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {50},
numpages = {51},
keywords = {natural language processing, supervised learning, Transformation-based learning, error-driven rule learning, computational linguistics, sequential classification, brill tagging}
}

@article{10.1145/3379443,
author = {Li, Guangjie and Liu, Hui and Nyamawe, Ally S.},
title = {A Survey on Renamings of Software Entities},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3379443},
doi = {10.1145/3379443},
abstract = {More than 70% of characters in the source code are used to label identifiers. Consequently, identifiers are one of the most important source for program comprehension. Meaningful identifiers are crucial to understand and maintain programs. However, for reasons like constrained schedule, inexperience, and unplanned evolution, identifiers may fail to convey the semantics of the entities associated with them. As a result, such entities should be renamed to improve software quality. However, manual renaming and recommendation are fastidious, time consuming, and error prone, whereas automating the process of renamings is challenging: (1) It involves complex natural language processing to understand the meaning of identifers; (2) It also involves difficult semantic analysis to determine the role of software entities. Researchers proposed a number of approaches and tools to facilitate renamings. We present a survey on existing approaches and classify them into identification of renaming opportunities, execution of renamings, and detection of renamings. We find that there is an imbalance between the three type of approaches, and most of implementation of approaches and evaluation dataset are not publicly available. We also discuss the challenges and present potential research directions. To the best of our knowledge, this survey is the first comprehensive study on renamings of software entities.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {41},
numpages = {38},
keywords = {software quality, identifier, Rename refactoring}
}

@article{10.1145/2968216,
author = {Maqsood, Tahir and Khalid, Osman and Irfan, Rizwana and Madani, Sajjad A. and Khan, Samee U.},
title = {Scalability Issues in Online Social Networks},
year = {2016},
issue_date = {November 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2968216},
doi = {10.1145/2968216},
abstract = {The last decade witnessed a tremendous increase in popularity and usage of social network services, such as Facebook, Twitter, and YouTube. Moreover, advances in Web technologies coupled with social networks has enabled users to not only access, but also generate, content in many forms. The overwhelming amount of produced content and resulting network traffic gives rise to precarious scalability issues for social networks, such as handling a large number of users, infrastructure management, internal network traffic, content dissemination, and data storage. There are few surveys conducted to explore the different dimensions of social networks, such as security, privacy, and data acquisition. Most of the surveys focus on privacy or security-related issues and do not specifically address scalability challenges faced by social networks. In this survey, we provide a comprehensive study of social networks along with their significant characteristics and categorize social network architectures into three broad categories: (a) centralized, (b) decentralized, and (c) hybrid. We also highlight various scalability issues faced by social network architectures. Finally, a qualitative comparison of presented architectures is provided, which is based on various scalability metrics, such as availability, latency, interserver communication, cost of resources, and energy consumption, just to name a few.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {40},
numpages = {42},
keywords = {decentralized social networks, hybrid social networks, social network, Scalability, centralized social networks}
}

@article{10.1145/2818185,
author = {McCune, Robert Ryan and Weninger, Tim and Madey, Greg},
title = {Thinking Like a Vertex: A Survey of Vertex-Centric Frameworks for Large-Scale Distributed Graph Processing},
year = {2015},
issue_date = {November 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2818185},
doi = {10.1145/2818185},
abstract = {The vertex-centric programming model is an established computational paradigm recently incorporated into distributed processing frameworks to address challenges in large-scale graph processing. Billion-node graphs that exceed the memory capacity of commodity machines are not well supported by popular Big Data tools like MapReduce, which are notoriously poor performing for iterative graph algorithms such as PageRank. In response, a new type of framework challenges one to “think like a vertex” (TLAV) and implements user-defined programs from the perspective of a vertex rather than a graph. Such an approach improves locality, demonstrates linear scalability, and provides a natural way to express and compute many iterative graph algorithms. These frameworks are simple to program and widely applicable but, like an operating system, are composed of several intricate, interdependent components, of which a thorough understanding is necessary in order to elicit top performance at scale. To this end, the first comprehensive survey of TLAV frameworks is presented. In this survey, the vertex-centric approach to graph processing is overviewed, TLAV frameworks are deconstructed into four main components and respectively analyzed, and TLAV implementations are reviewed and categorized.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {25},
numpages = {39},
keywords = {pregel, distributed algorithms, distributed systems, Graph processing, Big Data}
}

@article{10.1145/3148149,
author = {Qu, Chenhao and Calheiros, Rodrigo N. and Buyya, Rajkumar},
title = {Auto-Scaling Web Applications in Clouds: A Taxonomy and Survey},
year = {2018},
issue_date = {September 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3148149},
doi = {10.1145/3148149},
abstract = {Web application providers have been migrating their applications to cloud data centers, attracted by the emerging cloud computing paradigm. One of the appealing features of the cloud is elasticity. It allows cloud users to acquire or release computing resources on demand, which enables web application providers to automatically scale the resources provisioned to their applications without human intervention under a dynamic workload to minimize resource cost while satisfying Quality of Service (QoS) requirements. In this article, we comprehensively analyze the challenges that remain in auto-scaling web applications in clouds and review the developments in this field. We present a taxonomy of auto-scalers according to the identified challenges and key properties. We analyze the surveyed works and map them to the taxonomy to identify the weaknesses in this field. Moreover, based on the analysis, we propose new future directions that can be explored in this area.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {73},
numpages = {33},
keywords = {Auto-scaling, web application, cloud computing}
}

@article{10.1145/3419368,
author = {Preum, Sarah Masud and Munir, Sirajum and Ma, Meiyi and Yasar, Mohammad Samin and Stone, David J. and Williams, Ronald and Alemzadeh, Homa and Stankovic, John A.},
title = {A Review of Cognitive Assistants for Healthcare: Trends, Prospects, and Future Directions},
year = {2021},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3419368},
doi = {10.1145/3419368},
abstract = {Healthcare cognitive assistants (HCAs) are intelligent systems or agents that interact with users in a context-aware and adaptive manner to improve their health outcomes by augmenting their cognitive abilities or complementing a cognitive impairment. They assist a wide variety of users ranging from patients to their healthcare providers (e.g., general practitioner, specialist, surgeon) in several situations (e.g., remote patient monitoring, emergency response, robotic surgery). While HCAs are critical to ensure personalized, scalable, and efficient healthcare, there exists a knowledge gap in finding the emerging trends, key challenges, design guidelines, and state-of-the-art technologies suitable for developing HCAs. This survey aims to bridge this gap for researchers from multiple domains, including but not limited to cyber-physical systems, artificial intelligence, human-computer interaction, robotics, and smart health. It provides a comprehensive definition of HCAs and outlines a novel, practical categorization of existing HCAs according to their target user role and the underlying application goals. This survey summarizes and assorts existing HCAs based on their characteristic features (i.e., interactive, context-aware, and adaptive) and enabling technological aspects (i.e., sensing, actuation, control, and computation). Finally, it identifies critical research questions and design recommendations to accelerate the development of the next generation of cognitive assistants for healthcare.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {130},
numpages = {37},
keywords = {Cognitive assistant, virtual assistant, healthcare application, personal assistant, intelligent agent, smart health, virtual agent, intelligent assistant, agent based systems for healthcare}
}

@article{10.1145/3407190,
author = {Deldjoo, Yashar and Schedl, Markus and Cremonesi, Paolo and Pasi, Gabriella},
title = {Recommender Systems Leveraging Multimedia Content},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3407190},
doi = {10.1145/3407190},
abstract = {Recommender systems have become a popular and effective means to manage the ever-increasing amount of multimedia content available today and to help users discover interesting new items. Today’s recommender systems suggest items of various media types, including audio, text, visual (images), and videos. In fact, scientific research related to the analysis of multimedia content has made possible effective content-based recommender systems capable of suggesting items based on an analysis of the features extracted from the item itself. The aim of this survey is to present a thorough review of the state-of-the-art of recommender systems that leverage multimedia content, by classifying the reviewed papers with respect to their media type, the techniques employed to extract and represent their content features, and the recommendation algorithm. Moreover, for each media type, we discuss various domains in which multimedia content plays a key role in human decision-making and is therefore considered in the recommendation process. Examples of the identified domains include fashion, tourism, food, media streaming, and e-commerce.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {106},
numpages = {38},
keywords = {fashion, video, image, food, audio, deep learning, multimedia, machine learning, e-commerce, tourism, social media, music, signal processing, Content-based recommender systems}
}

@article{10.1145/3064004,
author = {Kafi, Mohamed Amine and Othman, Jalel Ben and Badache, Nadjib},
title = {A Survey on Reliability Protocols in Wireless Sensor Networks},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3064004},
doi = {10.1145/3064004},
abstract = {Wireless Sensor Network (WSN) applications have become more and more attractive with the miniaturization of circuits and the large variety of sensors. The different application domains, especially critical fields of WSN use, make the reliability of data acquisition and communication a hot research field that must be tackled efficiently. Indeed, the quality of largely used, cheap-cost wireless sensors and their scarce energy supply support these reliability challenges that lead to data loss or corruption. For solving this problem, the conception of a reliability mechanism that detects these shortcomings and recovers to them becomes necessary. In this article, we present a survey on existing reliability protocols conceived especially for WSNs due to their special features. The deep classification and discussion in this study allow for understanding the pros and cons of state-of-the-art works in order to enhance the existing schemes and fill the gaps. We have classified the works according to the required level of reliability, the manner to identify the origins of the lack of reliability, and the control to recover this lack of reliability. Across the discussion along this study, we deduce that the cross-layer design between MAC, routing, and transport layers presents a good concept to efficiently overcome the different reliability holes.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {31},
numpages = {47},
keywords = {reliability, redundancy, transport layer protocols, retransmission, Wireless sensor networks (WSNs)}
}

@article{10.1145/3394659,
author = {Emami, Patrick and Pardalos, Panos M. and Elefteriadou, Lily and Ranka, Sanjay},
title = {Machine Learning Methods for Data Association in Multi-Object Tracking},
year = {2020},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3394659},
doi = {10.1145/3394659},
abstract = {Data association is a key step within the multi-object tracking pipeline that is notoriously challenging due to its combinatorial nature. A popular and general way to formulate data association is as the NP-hard multi-dimensional assignment problem. Over the past few years, data-driven approaches to assignment have become increasingly prevalent as these techniques have started to mature. We focus this survey solely on learning algorithms for the assignment step of multi-object tracking, and we attempt to unify various methods by highlighting their connections to linear assignment and to the multi-dimensional assignment problem. First, we review probabilistic and end-to-end optimization approaches to data association, followed by methods that learn association affinities from data. We then compare the performance of the methods presented in this survey and conclude by discussing future research directions.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {69},
numpages = {34},
keywords = {machine learning, Multi-object tracking, data association, deep learning}
}

@article{10.1145/2906148,
author = {Liu, Junbin and Sridharan, Sridha and Fookes, Clinton},
title = {Recent Advances in Camera Planning for Large Area Surveillance: A Comprehensive Review},
year = {2016},
issue_date = {July 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2906148},
doi = {10.1145/2906148},
abstract = {With recent advances in consumer electronics and the increasingly urgent need for public security, camera networks have evolved from their early role of providing simple and static monitoring to current complex systems capable of obtaining extensive video information for intelligent processing, such as target localization, identification, and tracking. In all cases, it is of vital importance that the optimal camera configuration (i.e., optimal location, orientation, etc.) is determined before cameras are deployed as a suboptimal placement solution will adversely affect intelligent video surveillance and video analytic algorithms. The optimal configuration may also provide substantial savings on the total number of cameras required to achieve the same level of utility.In this article, we examine most, if not all, of the recent approaches (post 2000) addressing camera placement in a structured manner. We believe that our work can serve as a first point of entry for readers wishing to start researching into this area or engineers who need to design a camera system in practice. To this end, we attempt to provide a complete study of relevant formulation strategies and brief introductions to most commonly used optimization techniques by researchers in this field. We hope our work to be inspirational to spark new ideas in the field.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {6},
numpages = {37},
keywords = {optimization, simulated annealing, binary integer programming, swarm intelligence, camera placement, video surveillance, Camera planning}
}

@article{10.1145/1978802.1978815,
author = {Sadri, Fariba},
title = {Ambient Intelligence: A Survey},
year = {2011},
issue_date = {October 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/1978802.1978815},
doi = {10.1145/1978802.1978815},
abstract = {In this article we survey ambient intelligence (AmI), including its applications, some of the technologies it uses, and its social and ethical implications. The applications include AmI at home, care of the elderly, healthcare, commerce, and business, recommender systems, museums and tourist scenarios, and group decision making. Among technologies, we focus on ambient data management and artificial intelligence; for example planning, learning, event-condition-action rules, temporal reasoning, and agent-oriented technologies. The survey is not intended to be exhaustive, but to convey a broad range of applications, technologies, and technical, social, and ethical challenges.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {36},
numpages = {66},
keywords = {Ambient intelligence, agents, assisted living, multiagent systems, social and ethical issues}
}

@article{10.1145/2956185,
author = {Tang, Jiliang and Chang, Yi and Aggarwal, Charu and Liu, Huan},
title = {A Survey of Signed Network Mining in Social Media},
year = {2016},
issue_date = {December 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2956185},
doi = {10.1145/2956185},
abstract = {Many real-world relations can be represented by signed networks with positive and negative links, as a result of which signed network analysis has attracted increasing attention from multiple disciplines. With the increasing prevalence of social media networks, signed network analysis has evolved from developing and measuring theories to mining tasks. In this article, we present a review of mining signed networks in the context of social media and discuss some promising research directions and new frontiers. We begin by giving basic concepts and unique properties and principles of signed networks. Then we classify and review tasks of signed network mining with representative algorithms. We also delineate some tasks that have not been extensively studied with formal definitions and also propose research directions to expand the field of signed network mining.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {42},
numpages = {37},
keywords = {signed network mining, social media, Negative links, signed networks}
}

@article{10.1145/2816826,
author = {Granatyr, Jones and Botelho, Vanderson and Lessing, Otto Robert and Scalabrin, Edson Em\'{\i}lio and Barth\`{e}s, Jean-Paul and Enembreck, Fabr\'{\i}cio},
title = {Trust and Reputation Models for Multiagent Systems},
year = {2015},
issue_date = {November 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2816826},
doi = {10.1145/2816826},
abstract = {Finding reliable partners to interact with in open environments is a challenging task for software agents, and trust and reputation mechanisms are used to handle this issue. From this viewpoint, we can observe the growing body of research on this subject, which indicates that these mechanisms can be considered key elements to design multiagent systems (MASs). Based on that, this article presents an extensive but not exhaustive review about the most significant trust and reputation models published over the past two decades, and hundreds of models were analyzed using two perspectives. The first one is a combination of trust dimensions and principles proposed by some relevant authors in the field, and the models are discussed using an MAS perspective. The second one is the discussion of these dimensions taking into account some types of interaction found in MASs, such as coalition, argumentation, negotiation, and recommendation. By these analyses, we aim to find significant relations between trust dimensions and types of interaction so it would be possible to construct MASs using the most relevant dimensions according to the types of interaction, which may help developers in the design of MASs.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {27},
numpages = {42},
keywords = {trust model, Trust, reputation}
}

@article{10.1145/2794080,
author = {Finocchi, Irene and Finocchi, Marco and Fusco, Emanuele G.},
title = {Clique Counting in MapReduce: Algorithms and Experiments},
year = {2015},
issue_date = {2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
issn = {1084-6654},
url = {https://doi.org/10.1145/2794080},
doi = {10.1145/2794080},
abstract = {We tackle the problem of counting the number qk of k-cliques in large-scale graphs, for any constant k ≥ 3. Clique counting is essential in a variety of applications, including social network analysis. Our algorithms make it possible to compute qk for several real-world graphs and shed light on its growth rate as a function of k. Even for small values of k, the number qk of k-cliques can be in the order of tens or hundreds of trillions. As k increases, different graph instances show different behaviors: while on some graphs qk + 1 &lt; qk, on other benchmarks qk + 1 » qk, up to two orders of magnitude in our observations. Graphs with steep clique growth rates represent particularly tough instances in practice.Due to the computationally intensive nature of the clique counting problem, we settle for parallel solutions in the MapReduce framework, which has become in the last few years a de facto standard for batch processing of massive datasets. We give both theoretical and experimental contributions.On the theory side, we design the first exact scalable algorithm for counting (and listing) k-cliques in MapReduce. Our algorithm uses O(m3/2) total space and O(mk/2) work, where m is the number of graph edges. This matches the best-known bounds for triangle listing when k = 3 and is work optimal in the worst case for any k, while keeping the communication cost independent of k. We also design sampling-based estimators that can dramatically reduce the running time and space requirements of the exact approach, while providing very accurate solutions with high probability.We then assess the effectiveness of different clique counting approaches through an extensive experimental analysis over the Amazon EC2 platform, considering both our algorithms and their state-of-the-art competitors. The experimental results clearly highlight the algorithm of choice in different scenarios and prove our exact approach to be the most effective when the number of k-cliques is large, gracefully scaling to nontrivial values of k even on clusters of small/medium size. Our approximation algorithms achieve extremely accurate estimates and large speedups, especially on the toughest instances for the exact algorithms.},
journal = {ACM J. Exp. Algorithmics},
month = oct,
articleno = {1.7},
numpages = {20},
keywords = {experimental algorithmics, graph algorithms, MapReduce, Clique listing, parallel algorithms}
}

@article{10.1145/2379776.2379784,
author = {Hawe, Glenn I. and Coates, Graham and Wilson, Duncan T. and Crouch, Roger S.},
title = {Agent-Based Simulation for Large-Scale Emergency Response: A Survey of Usage and Implementation},
year = {2012},
issue_date = {November 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2379776.2379784},
doi = {10.1145/2379776.2379784},
abstract = {When attempting to determine how to respond optimally to a large-scale emergency, the ability to predict the consequences of certain courses of action in silico is of great utility. Agent-based simulations (ABSs) have become the de facto tool for this purpose; however, they may be used and implemented in a variety of ways. This article reviews existing implementations of ABSs for large-scale emergency response, and presents a taxonomy classifying them by usage. Opportunities for improving ABS for large-scale emergency response are identified.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {8},
numpages = {51},
keywords = {Agent-based simulation, emergency response}
}

@article{10.1145/2811282,
author = {Momeni, Elaheh and Cardie, Claire and Diakopoulos, Nicholas},
title = {A Survey on Assessment and Ranking Methodologies for User-Generated Content on the Web},
year = {2015},
issue_date = {February 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2811282},
doi = {10.1145/2811282},
abstract = {User-generated content (UGC) on the Web, especially on social media platforms, facilitates the association of additional information with digital resources; thus, it can provide valuable supplementary content. However, UGC varies in quality and, consequently, raises the challenge of how to maximize its utility for a variety of end-users. This study aims to provide researchers and Web data curators with comprehensive answers to the following questions: What are the existing approaches and methods for assessing and ranking UGC? What features and metrics have been used successfully to assess and predict UGC value across a range of application domains? What methods can be effectively employed to maximize that value? This survey is composed of a systematic review of approaches for assessing and ranking UGC: results are obtained by identifying and comparing methodologies within the context of short text-based UGC on the Web. Existing assessment and ranking approaches adopt one of four framework types: the community-based framework takes into consideration the value assigned to content by a crowd of humans, the end-user--based framework adapts and personalizes the assessment and ranking process with respect to a single end-user, the designer-based framework encodes the software designer’s values in the assessment and ranking method, and the hybrid framework employs methods from more than one of these types. This survey suggests a need for further experimentation and encourages the development of new approaches for the assessment and ranking of UGC.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {41},
numpages = {49},
keywords = {ranking, human centered, interactive, social media, assessment, adaptive, machine centered, User-generated content}
}

@article{10.1145/3311955,
author = {Pimentel, Jo\~{a}o Felipe and Freire, Juliana and Murta, Leonardo and Braganholo, Vanessa},
title = {A Survey on Collecting, Managing, and Analyzing Provenance from Scripts},
year = {2019},
issue_date = {July 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3311955},
doi = {10.1145/3311955},
abstract = {Scripts are widely used to design and run scientific experiments. Scripting languages are easy to learn and use, and they allow complex tasks to be specified and executed in fewer steps than with traditional programming languages. However, they also have important limitations for reproducibility and data management. As experiments are iteratively refined, it is challenging to reason about each experiment run (or trial), to keep track of the association between trials and experiment instances as well as the differences across trials, and to connect results to specific input data and parameters. Approaches have been proposed that address these limitations by collecting, managing, and analyzing the provenance of scripts. In this article, we survey the state of the art in provenance for scripts. We have identified the approaches by following an exhaustive protocol of forward and backward literature snowballing. Based on a detailed study, we propose a taxonomy and classify the approaches using this taxonomy.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {47},
numpages = {38},
keywords = {collecting, survey, managing, Provenance, analyzing, scripts}
}

@article{10.1145/2629503,
author = {Chabi, Djaafar and Zhao, Weisheng and Querlioz, Damien and Klein, Jacques-Olivier},
title = {On-Chip Universal Supervised Learning Methods for Neuro-Inspired Block of Memristive Nanodevices},
year = {2015},
issue_date = {April 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {4},
issn = {1550-4832},
url = {https://doi.org/10.1145/2629503},
doi = {10.1145/2629503},
abstract = {Scaling down beyond CMOS transistors requires the combination of new computing paradigms and novel devices. In this context, neuromorphic architecture is developed to achieve robust and ultra-low power computing systems. Memristive nanodevices are often associated with this architecture to implement efficiently synapses for ultra-high density. In this article, we investigate the design of a neuro-inspired logic block (NLB) dedicated to on-chip function learning and propose learning strategy. It is composed of an array of memristive nanodevices as synapses associated to neuronal circuits. Supervised learning methods are proposed for different type of memristive nanodevices and simulations are performed to demonstrate the ability to learn logic functions with memristive nanodevices. Benefiting from a compact implementation of neuron circuits and the optimization of learning process, this architecture requires small number of nanodevices and moderate power consumption.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = apr,
articleno = {34},
numpages = {20},
keywords = {on-chip learning, Memristive nanodevices, neural network, supervised learning, nanoscale crossbar}
}

@article{10.1145/3431231,
author = {Mariani, Stefano and Cabri, Giacomo and Zambonelli, Franco},
title = {Coordination of Autonomous Vehicles: Taxonomy and Survey},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3431231},
doi = {10.1145/3431231},
abstract = {In the near future, our streets will be populated by myriads of autonomous self-driving vehicles to serve our diverse mobility needs. This will raise the need to coordinate their movements in order to properly handle both access to shared resources (e.g., intersections and parking slots) and the execution of mobility tasks (e.g., platooning and ramp merging). The aim of this article is to provide a global view of the coordination issues and the related solutions in the field of autonomous vehicles. To this end, we firstly introduce the general problems associated with coordination of autonomous vehicles by identifying and framing the key classes of coordination problems. Then, we overview the different approaches that can be adopted to deal with such problems by classifying them in terms of the degree of autonomy in decision making that is left to autonomous vehicles during the coordination process. Finally, we overview some further research challenges to address before autonomous coordinated vehicles can safely hit our streets.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {19},
numpages = {33},
keywords = {coordination, cooperative driving, survey, Autonomous vehicles, autonomy}
}

@article{10.1145/2814572,
author = {Dehghani, Abbas and Jamshidi, Kamal},
title = {A Novel Approach to Optimize Fault-Tolerant Hybrid Wireless Network-on-Chip Architectures},
year = {2016},
issue_date = {July 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {4},
issn = {1550-4832},
url = {https://doi.org/10.1145/2814572},
doi = {10.1145/2814572},
abstract = {Wireless Network-on-Chip (WNoC) architectures have emerged as a promising interconnection infrastructure to address the performance limitations of traditional wire-based multihop NOCs. Nevertheless, the WNoC systems encounter high failure rates due to problems pertaining to integration and manufacturing of wireless interconnection in nano-domain technology. As a result, the permanent failures may lead to the formation of any shape of faulty regions in the interconnection network, which can break down the whole system. This issue is not investigated in previous studies on WNoC architectures. Our solution advocates the adoption of communication structures with both node and link on disjoint paths. On the other hand, the imposed costs of WNoC design must be reasonable. Hence, a novel approach to design an optimized fault-tolerant hybrid hierarchical WNoC architecture for enhancing performance as well as minimizing system costs is proposed. The experimental results indicate that the robustness of this newly proposed design is significantly enhanced in comparison with its the fault-tolerant wire-based counterparts in the presence of various faulty regions under both synthetic and application-specific traffic patterns.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = mar,
articleno = {45},
numpages = {37},
keywords = {network-on-chip, fault-tolerance, multi-objective optimization, wireless interconnection, Multicore systems, permanent fault}
}

@article{10.1145/2535417,
author = {Liu, Elvis S. and Theodoropoulos, Georgios K.},
title = {Interest Management for Distributed Virtual Environments: A Survey},
year = {2014},
issue_date = {April 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2535417},
doi = {10.1145/2535417},
abstract = {The past two decades have witnessed an explosion in the deployment of large-scale distributed simulations and distributed virtual environments in different domains, including military and academic simulation systems, social media, and commercial applications such as massively multiplayer online games. As these systems become larger, more data intensive, and more latency sensitive, the optimisation of the flow of data, a paradigm referred to as interest management, has become increasingly critical to address the scalability requirements and enable their successful deployment. Numerous interest management schemes have been proposed for different application scenarios. This article provides a comprehensive survey of the state of the art in the design of interest management algorithms and systems. The scope of the survey includes current and historical projects providing a taxonomy of the existing schemes and summarising their key features. Identifying the primary requirements of interest management, the article discusses the trade-offs involved in the design of existing approaches.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {51},
numpages = {42},
keywords = {Interest management, distributed virtual environments, massively multiplayer online games, data distribution management, high-level architecture}
}

@article{10.1145/3199523,
author = {Heidari, Safiollah and Simmhan, Yogesh and Calheiros, Rodrigo N. and Buyya, Rajkumar},
title = {Scalable Graph Processing Frameworks: A Taxonomy and Open Challenges},
year = {2018},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3199523},
doi = {10.1145/3199523},
abstract = {The world is becoming a more conjunct place and the number of data sources such as social networks, online transactions, web search engines, and mobile devices is increasing even more than had been predicted. A large percentage of this growing dataset exists in the form of linked data, more generally, graphs, and of unprecedented sizes. While today's data from social networks contain hundreds of millions of nodes connected by billions of edges, inter-connected data from globally distributed sensors that forms the Internet of Things can cause this to grow exponentially larger. Although analyzing these large graphs is critical for the companies and governments that own them, big data tools designed for text and tuple analysis such as MapReduce cannot process them efficiently. So, graph distributed processing abstractions and systems are developed to design iterative graph algorithms and process large graphs with better performance and scalability. These graph frameworks propose novel methods or extend previous methods for processing graph data. In this article, we propose a taxonomy of graph processing systems and map existing systems to this classification. This captures the diversity in programming and computation models, runtime aspects of partitioning and communication, both for in-memory and distributed frameworks. Our effort helps to highlight key distinctions in architectural approaches, and identifies gaps for future research in scalable graph systems.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {60},
numpages = {53},
keywords = {large-scale graphs, parallel processing, distributed systems, graph processing, Big data}
}

@article{10.1145/2522968.2522969,
author = {Kritikos, Kyriakos and Pernici, Barbara and Plebani, Pierluigi and Cappiello, Cinzia and Comuzzi, Marco and Benrernou, Salima and Brandic, Ivona and Kert\'{e}sz, Attila and Parkin, Michael and Carro, Manuel},
title = {A Survey on Service Quality Description},
year = {2013},
issue_date = {October 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2522968.2522969},
doi = {10.1145/2522968.2522969},
abstract = {Quality of service (QoS) can be a critical element for achieving the business goals of a service provider, for the acceptance of a service by the user, or for guaranteeing service characteristics in a composition of services, where a service is defined as either a software or a software-support (i.e., infrastructural) service which is available on any type of network or electronic channel. The goal of this article is to compare the approaches to QoS description in the literature, where several models and metamodels are included. consider a large spectrum of models and metamodels to describe service quality, ranging from ontological approaches to define quality measures, metrics, and dimensions, to metamodels enabling the specification of quality-based service requirements and capabilities as well as of SLAs (Service-Level Agreements) and SLA templates for service provisioning. Our survey is performed by inspecting the characteristics of the available approaches to reveal which are the consolidated ones and which are the ones specific to given aspects and to analyze where the need for further research and investigation lies. The approaches here illustrated have been selected based on a systematic review of conference proceedings and journals spanning various research areas in computer science and engineering, including: distributed, information, and telecommunication systems, networks and security, and service-oriented and grid computing.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {1},
numpages = {58},
keywords = {description, provisioning, model, service-level agreement, quality, QoS, Service, SLA, metamodel, life-cycle}
}

@article{10.1145/3117809,
author = {Alevizos, Elias and Skarlatidis, Anastasios and Artikis, Alexander and Paliouras, Georgios},
title = {Probabilistic Complex Event Recognition: A Survey},
year = {2017},
issue_date = {November 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3117809},
doi = {10.1145/3117809},
abstract = {Complex event recognition (CER) applications exhibit various types of uncertainty, ranging from incomplete and erroneous data streams to imperfect complex event patterns. We review CER techniques that handle, to some extent, uncertainty. We examine techniques based on automata, probabilistic graphical models, and first-order logic, which are the most common ones, and approaches based on Petri nets and grammars, which are less frequently used. Several limitations are identified with respect to the employed languages, their probabilistic models, and their performance, as compared to the purely deterministic cases. Based on those limitations, we highlight promising directions for future work.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {71},
numpages = {31},
keywords = {uncertainty, probabilistic graphical models, probabilistic automata, Event processing, probabilistic logics, probabilistic Petri nets, stochastic grammars}
}

@article{10.1145/3447238,
author = {Mitra, Shyamali and Das, Nibaran and Dey, Soumyajyoti and Chakraborty, Sukanta and Nasipuri, Mita and Naskar, Mrinal Kanti},
title = {Cytology Image Analysis Techniques Toward Automation: Systematically Revisited},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3447238},
doi = {10.1145/3447238},
abstract = {Cytology is a branch of pathology that deals with the microscopic examination of cells for diagnosis of carcinoma or inflammatory conditions. In the present work, the term cytology is used to indicate solid organ cytology. Automation in cytology started in the early 1950s with an aim to reduce manual efforts in the diagnosis of cancer. The influx of intelligent systems with high computational power and improved specimen collection techniques helped to achieve technological heights in the cytology automation process. In the present survey, we focus on image analysis techniques paving the way to automation in cytology. We take a short tour of 17 types of solid organ cytology to explore various segmentation and/or classification techniques that evolved during the past three decades to automate cytology image analysis. It is observed that most of the works are aligned toward three types of cytology: Cervical, Breast, and Respiratory tract cytology. These are discussed elaborately in the article. Commercial systems developed during the period are also summarized to comprehend the overall growth in respective domains. Finally, we discuss different state-of-the-art methods and related challenges to provide prolific and competent future research directions in bringing cytology-based commercial systems into the mainstream.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {52},
numpages = {41},
keywords = {computer aided diagnosis, image segmentation, Cytology survey, image classification, malignant and benign}
}

@article{10.1145/3418896,
author = {Christophides, Vassilis and Efthymiou, Vasilis and Palpanas, Themis and Papadakis, George and Stefanidis, Kostas},
title = {An Overview of End-to-End Entity Resolution for Big Data},
year = {2020},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3418896},
doi = {10.1145/3418896},
abstract = {One of the most critical tasks for improving data quality and increasing the reliability of data analytics is Entity Resolution (ER), which aims to identify different descriptions that refer to the same real-world entity. Despite several decades of research, ER remains a challenging problem. In this survey, we highlight the novel aspects of resolving Big Data entities when we should satisfy more than one of the Big Data characteristics simultaneously (i.e., Volume and Velocity with Variety). We present the basic concepts, processing steps, and execution strategies that have been proposed by database, semantic Web, and machine learning communities in order to cope with the loose structuredness, extreme diversity, high speed, and large scale of entity descriptions used by real-world applications. We provide an end-to-end view of ER workflows&nbsp;for&nbsp;Big Data, critically review the pros and cons of existing methods, and conclude with the main open research&nbsp;directions.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {127},
numpages = {42},
keywords = {crowdsourcing, block processing, strongly and nearly similar entities, deep learning, batch and incremental entity resolution workflows, Entity blocking and matching}
}

@article{10.1145/3440756,
author = {Chen, Xiaoxue and Jin, Lianwen and Zhu, Yuanzhi and Luo, Canjie and Wang, Tianwei},
title = {Text Recognition in the Wild: A Survey},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3440756},
doi = {10.1145/3440756},
abstract = {The history of text can be traced back over thousands of years. Rich and precise semantic information carried by text is important in a wide range of vision-based application scenarios. Therefore, text recognition in natural scenes has been an active research topic in computer vision and pattern recognition. In recent years, with the rise and development of deep learning, numerous methods have shown promising results in terms of innovation, practicality, and efficiency. This article aims to (1) summarize the fundamental problems and the state-of-the-art associated with scene text recognition, (2) introduce new insights and ideas, (3) provide a comprehensive review of publicly available resources, and (4) point out directions for future work. In summary, this literature review attempts to present an entire picture of the field of scene text recognition. It provides a comprehensive reference for people entering this field and could be helpful in inspiring future research. Related resources are available at our GitHub repository: https://github.com/HCIILAB/Scene-Text-Recognition.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {42},
numpages = {35},
keywords = {end-to-end systems, Scene text recognition, deep learning}
}

@article{10.1145/3054132,
author = {Gudmundsson, Joachim and Horton, Michael},
title = {Spatio-Temporal Analysis of Team Sports},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3054132},
doi = {10.1145/3054132},
abstract = {Team-based invasion sports such as football, basketball, and hockey are similar in the sense that the players are able to move freely around the playing area and that player and team performance cannot be fully analysed without considering the movements and interactions of all players as a group. State-of-the-art object tracking systems now produce spatio-temporal traces of player trajectories with high definition and high frequency, and this, in turn, has facilitated a variety of research efforts, across many disciplines, to extract insight from the trajectories. We survey recent research efforts that use spatio-temporal data from team sports as input and involve non-trivial computation. This article categorises the research efforts in a coherent framework and identifies a number of open research questions.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {22},
numpages = {34},
keywords = {hockey, spatio-temporal data, american football, spatial subdivision, football, machine learning, basketball, network analysis, data mining, sports analysis, performance metrics, handball, Trajectory, soccer}
}

@article{10.1145/3422824,
author = {Skaik, Ruba and Inkpen, Diana},
title = {Using Social Media for Mental Health Surveillance: A Review},
year = {2020},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3422824},
doi = {10.1145/3422824},
abstract = {Data on social media contain a wealth of user information. Big data research of social media data may also support standard surveillance approaches and provide decision-makers with usable information. These data can be analyzed using Natural Language Processing (NLP) and Machine Learning (ML) techniques to detect signs of mental disorders that need attention, such as depression and suicide ideation. This article presents the recent trends and tools that are used in this field, the different means for data collection, and the current applications of ML and NLP in the surveillance of public mental health. We highlight the best practices and the challenges. Furthermore, we discuss the current gaps that need to be addressed and resolved.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {129},
numpages = {31},
keywords = {Mental health, social media}
}

@article{10.1145/3409382,
author = {Yu, Kui and Guo, Xianjie and Liu, Lin and Li, Jiuyong and Wang, Hao and Ling, Zhaolong and Wu, Xindong},
title = {Causality-Based Feature Selection: Methods and Evaluations},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3409382},
doi = {10.1145/3409382},
abstract = {Feature selection is a crucial preprocessing step in data analytics and machine learning. Classical feature selection algorithms select features based on the correlations between predictive features and the class variable and do not attempt to capture causal relationships between them. It has been shown that the knowledge about the causal relationships between features and the class variable has potential benefits for building interpretable and robust prediction models, since causal relationships imply the underlying mechanism of a system. Consequently, causality-based feature selection has gradually attracted greater attentions and many algorithms have been proposed. In this article, we present a comprehensive review of recent advances in causality-based feature selection. To facilitate the development of new algorithms in the research area and make it easy for the comparisons between new methods and existing ones, we develop the first open-source package, called CausalFS, which consists of most of the representative causality-based feature selection algorithms (available at https://github.com/kuiy/CausalFS). Using CausalFS, we conduct extensive experiments to compare the representative algorithms with both synthetic and real-world datasets. Finally, we discuss some challenging problems to be tackled in future research.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {111},
numpages = {36},
keywords = {Markov boundary, Bayesian network, Feature selection}
}

@article{10.1145/3154815,
author = {Li, Chao and Xue, Yushu and Wang, Jing and Zhang, Weigong and Li, Tao},
title = {Edge-Oriented Computing Paradigms: A Survey on Architecture Design and System Management},
year = {2018},
issue_date = {June 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3154815},
doi = {10.1145/3154815},
abstract = {While cloud computing has brought paradigm shifts to computing services, researchers and developers have also found some problems inherent to its nature such as bandwidth bottleneck, communication overhead, and location blindness. The concept of fog/edge computing is therefore coined to extend the services from the core in cloud data centers to the edge of the network. In recent years, many systems are proposed to better serve ubiquitous smart devices closer to the user. This article provides a complete and up-to-date review of edge-oriented computing systems by encapsulating relevant proposals on their architecture features, management approaches, and design objectives.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {39},
numpages = {34},
keywords = {architecture design, fog computing, edge computing, Distributed cloud, ubiquitous data processing, resource management}
}

@article{10.1145/2821510,
author = {Mittal, Sparsh},
title = {A Survey of Architectural Techniques for Near-Threshold Computing},
year = {2016},
issue_date = {July 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {4},
issn = {1550-4832},
url = {https://doi.org/10.1145/2821510},
doi = {10.1145/2821510},
abstract = {Energy efficiency has now become the primary obstacle in scaling the performance of all classes of computing systems. Low-voltage computing, specifically, near-threshold voltage computing (NTC), which involves operating the transistor very close to and yet above its threshold voltage, holds the promise of providing many-fold improvement in energy efficiency. However, use of NTC also presents several challenges such as increased parametric variation, failure rate, and performance loss. This article surveys several recent techniques that aim to offset these challenges for fully leveraging the potential of NTC. By classifying these techniques along several dimensions, we also highlight their similarities and differences. It is hoped that this article will provide insights into state-of-the-art NTC techniques to researchers and system designers and inspire further research in this field.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = dec,
articleno = {46},
numpages = {26},
keywords = {voltage scaling, low-voltage, memory, classification, Review, near-threshold voltage computing (NT) (NTV) (NTC), reliability, hard-error, cache}
}

@article{10.1145/2676430,
author = {Yang, Zheng and Wu, Chenshu and Zhou, Zimu and Zhang, Xinglin and Wang, Xu and Liu, Yunhao},
title = {Mobility Increases Localizability: A Survey on Wireless Indoor Localization Using Inertial Sensors},
year = {2015},
issue_date = {April 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2676430},
doi = {10.1145/2676430},
abstract = {Wireless indoor positioning has been extensively studied for the past 2 decades and continuously attracted growing research efforts in mobile computing context. As the integration of multiple inertial sensors (e.g., accelerometer, gyroscope, and magnetometer) to nowadays smartphones in recent years, human-centric mobility sensing is emerging and coming into vogue. Mobility information, as a new dimension in addition to wireless signals, can benefit localization in a number of ways, since location and mobility are by nature related in the physical world. In this article, we survey this new trend of mobility enhancing smartphone-based indoor localization. Specifically, we first study how to measure human mobility: what types of sensors we can use and what types of mobility information we can acquire. Next, we discuss how mobility assists localization with respect to enhancing location accuracy, decreasing deployment cost, and enriching location context. Moreover, considering the quality and cost of smartphone built-in sensors, handling measurement errors is essential and accordingly investigated. Combining existing work and our own working experiences, we emphasize the principles and conduct comparative study of the mainstream technologies. Finally, we conclude this survey by addressing future research directions and opportunities in this new and largely open area.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {54},
numpages = {34},
keywords = {smartphones, wireless indoor localization, Mobility}
}

@article{10.1145/3062394,
author = {Mittal, Sparsh},
title = {A Survey of Techniques for Cache Partitioning in Multicore Processors},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3062394},
doi = {10.1145/3062394},
abstract = {As the number of on-chip cores and memory demands of applications increase, judicious management of cache resources has become not merely attractive but imperative. Cache partitioning, that is, dividing cache space between applications based on their memory demands, is a promising approach to provide capacity benefits of shared cache with performance isolation of private caches. However, naively partitioning the cache may lead to performance loss, unfairness, and lack of quality-of-service guarantees. It is clear that intelligent techniques are required for realizing the full potential of cache partitioning. In this article, we present a survey of techniques for partitioning shared caches in multicore processors. We categorize the techniques based on important characteristics and provide a bird’s eye view of the field of cache partitioning.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {27},
numpages = {39},
keywords = {partitioning, fairness, shared cache, Review, multicore processor, QoS, classification}
}

@article{10.1145/2543581.2543594,
author = {Pereira, Orlando R. E. and Rodrigues, Joel J. P. C.},
title = {Survey and Analysis of Current Mobile Learning Applications and Technologies},
year = {2013},
issue_date = {November 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2543581.2543594},
doi = {10.1145/2543581.2543594},
abstract = {Distance learning, electronic learning, and mobile learning offer content, methods, and technologies that decrease the limitations of traditional education. Mobile learning (m-learning) is an extension of distance education, supported by mobile devices equipped with wireless technologies. It is an emerging learning model and process that requires new forms of teaching, learning, contents, and dynamics between actors. In order to ascertain the current state of knowledge and research, an extensive review of the literature in m-learning has been undertaken to identify and harness potential factors and gaps in implementation. This article provides a critical analysis of m-learning projects and related literature, presenting the findings of this aforementioned analysis. It seeks to facilitate the inquiry into the following question: “What is possible in m-learning using recent technologies?” The analysis will be divided into two main parts: applications from the recent online mobile stores and operating system standalone applications.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {27},
numpages = {35},
keywords = {mobile computing, mobile applications, Mobile learning}
}

@article{10.1145/3355398,
author = {Basavarajaiah, Madhushree and Sharma, Priyanka},
title = {Survey of Compressed Domain Video Summarization Techniques},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3355398},
doi = {10.1145/3355398},
abstract = {Video summarization is the method of extracting key frames or clips from a video to generate a synopsis of the content of the video. Generally, video is compressed before storing or transmitting it in most of the practical applications. Traditional techniques require the videos to be decoded to summarize them, which is a tedious job. Instead, compressed domain video processing can be used for summarizing videos by partially decoding them. A classification and analysis of various summarization techniques are presented in this article with special focus on compressed domain techniques along with a discussion on machine-learning-based techniques that can be applied to summarize the videos.<!--?vsp -1.2pt?--> },
journal = {ACM Comput. Surv.},
month = oct,
articleno = {116},
numpages = {29},
keywords = {video abstraction, video processing, Compressed domain, machine learning}
}

@article{10.1145/3433000,
author = {Zhou, Fan and Xu, Xovee and Trajcevski, Goce and Zhang, Kunpeng},
title = {A Survey of Information Cascade Analysis: Models, Predictions, and Recent Advances},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3433000},
doi = {10.1145/3433000},
abstract = {The deluge of digital information in our daily life—from user-generated content, such as microblogs and scientific papers, to online business, such as viral marketing and advertising—offers unprecedented opportunities to explore and exploit the trajectories and structures of the evolution of information cascades. Abundant research efforts, both academic and industrial, have aimed to reach a better understanding of the mechanisms driving the spread of information and quantifying the outcome of information diffusion. This article presents a comprehensive review and categorization of information popularity prediction methods, from feature engineering and stochastic processes, through graph representation, to deep learning-based approaches. Specifically, we first formally define different types of information cascades and summarize the perspectives of existing studies. We then present a taxonomy that categorizes existing works into the aforementioned three main groups as well as the main subclasses in each group, and we systematically review cutting-edge research work. Finally, we summarize the pros and cons of existing research efforts and outline the open challenges and opportunities in this field.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {27},
numpages = {36},
keywords = {information cascade, Popularity prediction, information diffusion}
}

@article{10.1145/3372390,
author = {Heldens, Stijn and Hijma, Pieter and Werkhoven, Ben Van and Maassen, Jason and Belloum, Adam S. Z. and Van Nieuwpoort, Rob V.},
title = {The Landscape of Exascale Research: A Data-Driven Literature Analysis},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3372390},
doi = {10.1145/3372390},
abstract = {The next generation of supercomputers will break the exascale barrier. Soon we will have systems capable of at least one quintillion (billion billion) floating-point operations per second (1018 FLOPS). Tremendous amounts of work have been invested into identifying and overcoming the challenges of the exascale era. In this work, we present an overview of these efforts and provide insight into the important trends, developments, and exciting research opportunities in exascale computing. We use a three-stage approach in which we (1) discuss various exascale landmark studies, (2) use data-driven techniques to analyze the large collection of related literature, and (3) discuss eight research areas in depth based on influential articles. Overall, we observe that great advancements have been made in tackling the two primary exascale challenges: energy efficiency and fault tolerance. However, as we look forward, we still foresee two major concerns: the lack of suitable programming tools and the growing gap between processor performance and data bandwidth (i.e., memory, storage, networks). Although we will certainly reach exascale soon, without additional research, these issues could potentially limit the applicability of exascale computing.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {23},
numpages = {43},
keywords = {high-performance computing, Exascale computing, data-driven analysis, literature review, extreme-scale computing}
}

@article{10.1145/2996355,
author = {Aleti, Aldeida and Moser, Irene},
title = {A Systematic Literature Review of Adaptive Parameter Control Methods for Evolutionary Algorithms},
year = {2016},
issue_date = {December 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2996355},
doi = {10.1145/2996355},
abstract = {Evolutionary algorithms (EAs) are robust stochastic optimisers that perform well over a wide range of problems. Their robustness, however, may be affected by several adjustable parameters, such as mutation rate, crossover rate, and population size. Algorithm parameters are usually problem-specific, and often have to be tuned not only to the problem but even the problem instance at hand to achieve ideal performance. In addition, research has shown that different parameter values may be optimal at different stages of the optimisation process. To address these issues, researchers have shifted their focus to adaptive parameter control, in which parameter values are adjusted during the optimisation process based on the performance of the algorithm. These methods redefine parameter values repeatedly based on implicit or explicit rules that decide how to make the best use of feedback from the optimisation algorithm.In this survey, we systematically investigate the state of the art in adaptive parameter control. The approaches are classified using a new conceptual model that subdivides the process of adapting parameter values into four steps that are present explicitly or implicitly in all existing approaches that tune parameters dynamically during the optimisation process. The analysis reveals the major focus areas of adaptive parameter control research as well as gaps and potential directions for further development in this area.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {56},
numpages = {35},
keywords = {adaptive parameter control, Evolutionary algorithms}
}

@article{10.1145/2593512,
author = {Toosi, Adel Nadjaran and Calheiros, Rodrigo N. and Buyya, Rajkumar},
title = {Interconnected Cloud Computing Environments: Challenges, Taxonomy, and Survey},
year = {2014},
issue_date = {July 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2593512},
doi = {10.1145/2593512},
abstract = {A brief review of the Internet history reveals the fact that the Internet evolved after the formation of primarily independent networks. Similarly, interconnected clouds, also called Inter-cloud, can be viewed as a natural evolution of cloud computing. Recent studies show the benefits in utilizing multiple clouds and present attempts for the realization of an Inter-cloud or federated cloud environment. However, cloud vendors have not taken into account cloud interoperability issues, and each cloud comes with its own solution and interfaces for services. This survey initially discusses all the relevant aspects motivating cloud interoperability. Furthermore, it categorizes and identifies possible cloud interoperability scenarios and architectures. The spectrum of challenges and obstacles that the Inter-cloud realization is faced with are covered, a taxonomy of them is provided, and fitting enablers that tackle each challenge are identified. All these aspects require a comprehensive review of the state of the art, including ongoing projects and studies in the area. We conclude by discussing future directions and trends toward the holistic approach in this regard.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {7},
numpages = {47},
keywords = {cross-clouds, multi-cloud, cloud federation, Cloud computing, Inter-cloud, utility computing}
}

@article{10.1145/3342103,
author = {Wu, Caesar and Buyya, Rajkumar and Ramamohanarao, Kotagiri},
title = {Cloud Pricing Models: Taxonomy, Survey, and Interdisciplinary Challenges},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3342103},
doi = {10.1145/3342103},
abstract = {This article provides a systematic review of cloud pricing in an interdisciplinary approach. It examines many historical cases of pricing in practice and tracks down multiple roots of pricing in research. The aim is to help both cloud service provider (CSP) and cloud customers to capture the essence of cloud pricing when they need to make a critical decision either to achieve competitive advantages or to manage cloud resource effectively. Currently, the number of available pricing schemes in the cloud market is overwhelming. It is an intricate issue to understand these schemes and associated pricing models clearly due to involving several domains of knowledge, such as cloud technologies, microeconomics, operations research, and value theory. Some earlier studies have introduced this topic unsystematically. Their approaches inevitably lead to much confusion for many cloud decision-makers. To address their weaknesses, we present a comprehensive taxonomy of cloud pricing, which is driven by a framework of three fundamental pricing strategies that are built on nine cloud pricing categories. These categories can be further mapped onto a total of 60 pricing models. Many of the pricing models have been already adopted by CSPs. Others have been widespread across in other industries. We give descriptions of these model categories and highlight both advantages and disadvantages. Moreover, this article offers an extensive survey of many cloud pricing models that were proposed by many researchers during the past decade. Based on the survey, we identify four trends of cloud pricing and the general direction, which is moving from intrinsic value per physical box to extrinsic value per serverless sandbox. We conclude that hyper-converged cloud resources pool supported by cloud orchestration, virtual machine, Open Application Programming Interface, and serverless sandbox will drive the future of cloud pricing.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {108},
numpages = {36},
keywords = {cost-based pricing, value-based pricing, cloud price model, market-based pricing, Cloud services provider (CSP)}
}

@article{10.1145/3152397,
author = {Zhou, Bowen and Buyya, Rajkumar},
title = {Augmentation Techniques for Mobile Cloud Computing: A Taxonomy, Survey, and Future Directions},
year = {2018},
issue_date = {April 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3152397},
doi = {10.1145/3152397},
abstract = {Despite the rapid growth of hardware capacity and popularity in mobile devices, limited resources in battery and processing capacity still lack the ability to meet increasing mobile users’ demands. Both conventional techniques and emerging approaches are brought together to fill this gap between user demand and mobile devices’ limited capabilities. Recent research has focused on enhancing the performance of mobile devices via augmentation techniques. Augmentation techniques for mobile cloud computing refer to the computing paradigms and solutions to outsource mobile device computation and storage to more powerful computing resources in order to enhance a mobile device’s computing capability and energy efficiency (e.g., code offloading). Adopting augmentation techniques in the heterogeneous and intermittent mobile cloud computing environment creates new challenges for computation management, energy efficiency, and system reliability. In this article, we aim to provide a comprehensive taxonomy and survey of the existing techniques and frameworks for mobile cloud augmentation regarding both computation and storage. Different from the existing taxonomies in this field, we focus on the techniques aspect, following the idea of realizing a complete mobile cloud computing system. The objective of this survey is to provide a guide on what available augmentation techniques can be adopted in mobile cloud computing systems as well as supporting mechanisms such as decision-making and fault tolerance policies for realizing reliable mobile cloud services. We also present a discussion on the open challenges and future research directions in this field.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {13},
numpages = {38},
keywords = {Mobile cloud computing, mobile device augmentation technique}
}

@article{10.1145/3186332,
author = {Venieris, Stylianos I. and Kouris, Alexandros and Bouganis, Christos-Savvas},
title = {Toolflows for Mapping Convolutional Neural Networks on FPGAs: A Survey and Future Directions},
year = {2018},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3186332},
doi = {10.1145/3186332},
abstract = {In the past decade, Convolutional Neural Networks (CNNs) have demonstrated state-of-the-art performance in various Artificial Intelligence tasks. To accelerate the experimentation and development of CNNs, several software frameworks have been released, primarily targeting power-hungry CPUs and GPUs. In this context, reconfigurable hardware in the form of FPGAs constitutes a potential alternative platform that can be integrated in the existing deep-learning ecosystem to provide a tunable balance between performance, power consumption, and programmability. In this article, a survey of the existing CNN-to-FPGA toolflows is presented, comprising a comparative study of their key characteristics, which include the supported applications, architectural choices, design space exploration methods, and achieved performance. Moreover, major challenges and objectives introduced by the latest trends in CNN algorithmic research are identified and presented. Finally, a uniform evaluation methodology is proposed, aiming at the comprehensive, complete, and in-depth evaluation of CNN-to-FPGA toolflows.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {56},
numpages = {39},
keywords = {FPGA toolflows, deep learning, Convolutional neural networks}
}

@article{10.1145/2988544,
author = {Abreu, Pedro Henriques and Santos, Miriam Seoane and Abreu, Miguel Henriques and Andrade, Bruno and Silva, Daniel Castro},
title = {Predicting Breast Cancer Recurrence Using Machine Learning Techniques: A Systematic Review},
year = {2016},
issue_date = {December 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2988544},
doi = {10.1145/2988544},
abstract = {Background: Recurrence is an important cornerstone in breast cancer behavior, intrinsically related to mortality. In spite of its relevance, it is rarely recorded in the majority of breast cancer datasets, which makes research in its prediction more difficult. Objectives: To evaluate the performance of machine learning techniques applied to the prediction of breast cancer recurrence. Material and Methods: Revision of published works that used machine learning techniques in local and open source databases between 1997 and 2014. Results: The revision showed that it is difficult to obtain a representative dataset for breast cancer recurrence and there is no consensus on the best set of predictors for this disease. High accuracy results are often achieved, yet compromising sensitivity. The missing data and class imbalance problems are rarely addressed and most often the chosen performance metrics are inappropriate for the context. Discussion and Conclusions: Although different techniques have been used, prediction of breast cancer recurrence is still an open problem. The combination of different machine learning techniques, along with the definition of standard predictors for breast cancer recurrence seem to be the main future directions to obtain better results.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {52},
numpages = {40},
keywords = {Breast cancer recurrence, pattern recognition, clinical decision-making}
}

@article{10.1145/3193827,
author = {Vipin, Kizheppatt and Fahmy, Suhaib A.},
title = {FPGA Dynamic and Partial Reconfiguration: A Survey of Architectures, Methods, and Applications},
year = {2018},
issue_date = {September 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3193827},
doi = {10.1145/3193827},
abstract = {Dynamic and partial reconfiguration are key differentiating capabilities of field programmable gate arrays (FPGAs). While they have been studied extensively in academic literature, they find limited use in deployed systems. We review FPGA reconfiguration, looking at architectures built for the purpose, and the properties of modern commercial architectures. We then investigate design flows and identify the key challenges in making reconfigurable FPGA systems easier to design. Finally, we look at applications where reconfiguration has found use, as well as proposing new areas where this capability places FPGAs in a unique position for adoption.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {72},
numpages = {39},
keywords = {dynamic reconfiguration, partial reconfiguration, Field programmable gate arrays}
}

@article{10.1145/2670128,
author = {Navarro, Gonzalo and Puglisi, Simon J. and Valenzuela, Daniel},
title = {General Document Retrieval in Compact Space},
year = {2015},
issue_date = {2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
issn = {1084-6654},
url = {https://doi.org/10.1145/2670128},
doi = {10.1145/2670128},
abstract = {Given a collection of documents and a query pattern, document retrieval is the problem of obtaining documents that are relevant to the query. The collection is available beforehand so that a data structure, called an index, can be built on it to speed up queries. While initially restricted to natural language text collections, document retrieval problems arise nowadays in applications like bioinformatics, multimedia databases, and web mining. This requires a more general setup where text and pattern can be general sequences of symbols, and the classical inverted indexes developed for words cannot be applied. While linear-space time-optimal solutions have been developed for most interesting queries in this general case, space usage is a serious problem in practice.In this article, we develop compact data structures that solve various important document retrieval problems on general text collections. More specifically, we provide practical solutions for listing the documents where a query pattern appears, together with its frequency in each document, and for listing k documents where a query pattern appears most frequently. Some of our techniques build on existing theoretical proposals, while others are new. In particular, we introduce a novel grammar-based compressed bitmap representation that may be of independent interest when dealing with repetitive sequences.Ours are the first practical indexes that use less space when the text collection is compressible. Our experimental results show that, in various real-life text collections, our data structures are significantly smaller than the most space-efficient previous solutions, using up to half the space without noticeably increasing the query time. Overall, document listing can be carried out in 10 to 40 milliseconds for patterns that appear 100 to 10,000 times in the collection, whereas top-k retrieval is carried out in k to 10 k milliseconds.},
journal = {ACM J. Exp. Algorithmics},
month = jan,
articleno = {2.3},
numpages = {46},
keywords = {wavelet trees, compressed text databases, top-k retrieval, Document retrieval}
}

@article{10.1145/3190507,
author = {Chen, Tao and Bahsoon, Rami and Yao, Xin},
title = {A Survey and Taxonomy of Self-Aware and Self-Adaptive Cloud Autoscaling Systems},
year = {2018},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3190507},
doi = {10.1145/3190507},
abstract = {Autoscaling system can reconfigure cloud-based services and applications, through various configurations of cloud software and provisions of hardware resources, to adapt to the changing environment at runtime. Such a behavior offers the foundation for achieving elasticity in a modern cloud computing paradigm. Given the dynamic and uncertain nature of the shared cloud infrastructure, the cloud autoscaling system has been engineered as one of the most complex, sophisticated, and intelligent artifacts created by humans, aiming to achieve self-aware, self-adaptive, and dependable runtime scaling. Yet the existing Self-aware and Self-adaptive Cloud Autoscaling System (SSCAS) is not at a state where it can be reliably exploited in the cloud. In this article, we survey the state-of-the-art research studies on SSCAS and provide a comprehensive taxonomy for this field. We present detailed analysis of the results and provide insights on open challenges, as well as the promising directions that are worth investigated in the future work of this area of research. Our survey and taxonomy contribute to the fundamentals of engineering more intelligent autoscaling systems in the cloud.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {61},
numpages = {40},
keywords = {Cloud computing, distributed systems, self-adaptive systems, auto-scaling, resources provisioning, self-aware systems}
}

@article{10.1145/2522968.2522971,
author = {Tamburri, Damian A. and Lago, Patricia and Vliet, Hans van},
title = {Organizational Social Structures for Software Engineering},
year = {2013},
issue_date = {October 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2522968.2522971},
doi = {10.1145/2522968.2522971},
abstract = {Software engineering evolved from a rigid process to a dynamic interplay of people (e.g., stakeholders or developers). Organizational and social literature call this interplay an Organizational Social Structure (OSS). Software practitioners still lack a systematic way to select, analyze, and support OSSs best fitting their problems (e.g., software development). We provide the state-of-the-art in OSSs, and discuss mechanisms to support OSS-related decisions in software engineering (e.g., choosing the OSS best fitting development scenarios). Our data supports two conclusions. First, software engineering focused on building software using project teams alone, yet these are one of thirteen OSS flavors from literature. Second, an emerging OSS should be further explored for software development: social networks. This article represents a first glimpse at OSS-aware software engineering, that is, to engineer software using OSSs best fit for the problem.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {3},
numpages = {35},
keywords = {user perspective, social context, users, social networks, cultural implications, governance, Organizational social structures, social structures, information trust, communities, software organizations, knowledge management, organizational decision-making, software practice, social adaptivity}
}

@article{10.1145/3329124,
author = {McDaniel, Melinda and Storey, Veda C.},
title = {Evaluating Domain Ontologies: Clarification, Classification, and Challenges},
year = {2019},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3329124},
doi = {10.1145/3329124},
abstract = {The number of applications being developed that require access to knowledge about the real world has increased rapidly over the past two decades. Domain ontologies, which formalize the terms being used in a discipline, have become essential for research in areas such as Machine Learning, the Internet of Things, Robotics, and Natural Language Processing, because they enable separate systems to exchange information. The quality of these domain ontologies, however, must be ensured for meaningful communication. Assessing the quality of domain ontologies for their suitability to potential applications remains difficult, even though a variety of frameworks and metrics have been developed for doing so. This article reviews domain ontology assessment efforts to highlight the work that has been carried out and to clarify the important issues that remain. These assessment efforts are classified into five distinct evaluation approaches and the state of the art of each described. Challenges associated with domain ontology assessment are outlined and recommendations are made for future research and applications.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {70},
numpages = {44},
keywords = {domain ontology, task-ontology fit, evaluation, ontology development, metrics, ontology application, Ontology, applied ontology, assessment}
}

@article{10.1145/3372788,
author = {Luo, Chu and Goncalves, Jorge and Velloso, Eduardo and Kostakos, Vassilis},
title = {A Survey of Context Simulation for Testing Mobile Context-Aware Applications},
year = {2020},
issue_date = {May 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3372788},
doi = {10.1145/3372788},
abstract = {Equipped with an abundance of small-scale microelectromechanical sensors, modern mobile devices such as smartphones and smartwatches can now offer context-aware services to users in mobile environments. Although advances in mobile context-aware applications have made our everyday environments increasingly intelligent, these applications are prone to bugs that are highly difficult to reproduce and repair. Compared to conventional computer software, mobile context-aware applications often have more complex structures to process a wide variety of dynamic context data in specific scenarios. Accordingly, researchers have proposed diverse context simulation techniques to enable low-cost and effective tests instead of conducting costly and time-consuming real-world experiments. This article aims to give a comprehensive overview of the state-of-the-art context simulation methods for testing mobile context-aware applications. In particular, this article highlights the technical distinctions and commonalities in previous research conducted across multiple disciplines, particularly at the intersection of software testing, ubiquitous computing, and mobile computing. This article also discusses how each method can be implemented and deployed by testing tool developers and mobile application testers. Finally, this article identifies several unexplored issues and directions for further advancements in this field.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {21},
numpages = {39},
keywords = {software testing, Mobile devices, sensors, multimedia}
}

@article{10.1145/3068281,
author = {Hong, Cheol-Ho and Spence, Ivor and Nikolopoulos, Dimitrios S.},
title = {GPU Virtualization and Scheduling Methods: A Comprehensive Survey},
year = {2017},
issue_date = {October 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3068281},
doi = {10.1145/3068281},
abstract = {The integration of graphics processing units (GPUs) on high-end compute nodes has established a new accelerator-based heterogeneous computing model, which now permeates high-performance computing. The same paradigm nevertheless has limited adoption in cloud computing or other large-scale distributed computing paradigms. Heterogeneous computing with GPUs can benefit the Cloud by reducing operational costs and improving resource and energy efficiency. However, such a paradigm shift would require effective methods for virtualizing GPUs, as well as other accelerators. In this survey article, we present an extensive and in-depth survey of GPU virtualization techniques and their scheduling methods. We review a wide range of virtualization techniques implemented at the GPU library, driver, and hardware levels. Furthermore, we review GPU scheduling methods that address performance and fairness issues between multiple virtual machines sharing GPUs. We believe that our survey delivers a perspective on the challenges and opportunities for virtualization of heterogeneous computing environments.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {35},
numpages = {37},
keywords = {cloud computing, CPU-GPU heterogeneous computing, GPU virtualization, GPU scheduling methods}
}

@article{10.1145/3291124,
author = {Zhang, Jing and Li, Wanqing and Ogunbona, Philip and Xu, Dong},
title = {Recent Advances in Transfer Learning for Cross-Dataset Visual Recognition: A Problem-Oriented Perspective},
year = {2019},
issue_date = {February 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3291124},
doi = {10.1145/3291124},
abstract = {This article takes a problem-oriented perspective and presents a comprehensive review of transfer-learning methods, both shallow and deep, for cross-dataset visual recognition. Specifically, it categorises the cross-dataset recognition into 17 problems based on a set of carefully chosen data and label attributes. Such a problem-oriented taxonomy has allowed us to examine how different transfer-learning approaches tackle each problem and how well each problem has been researched to date. The comprehensive problem-oriented review of the advances in transfer learning with respect to the problem has not only revealed the challenges in transfer learning for visual recognition but also the problems (e.g., 8 of the 17 problems) that have been scarcely studied. This survey not only presents an up-to-date technical review for researchers but also a systematic approach and a reference for a machine-learning practitioner to categorise a real problem and to look up for a possible solution accordingly.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {7},
numpages = {38},
keywords = {Cross-dataset recognition, domain adaptation}
}

@article{10.1145/3098207,
author = {Tariq, Zain Bin and Cheema, Dost Muhammad and Kamran, Muhammad Zahir and Naqvi, Ijaz Haider},
title = {Non-GPS Positioning Systems: A Survey},
year = {2017},
issue_date = {November 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3098207},
doi = {10.1145/3098207},
abstract = {An enormous amount of research has been conducted in the area of positioning systems and thus it calls for a detailed literature review of recent localization systems. This article focuses on recent developments of non-Global Positioning System (GPS) localization/positioning systems. We have presented a new hierarchical method to classify various positioning systems. A comprehensive performance comparison of the techniques and technologies against multiple performance metrics along with the limitations is presented. A few indoor positioning systems have emerged as more successful in particular application environments than others, which are presented at the end.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {57},
numpages = {34},
keywords = {received signal strength, angle of arrival, ultra-wide band (UWB), acoustic, cellular networks, proximity, bluetooth, zigbee, time difference of arrival, Time of arrival, fingerprinting, visible light communication, infra-red, Wi-Fi}
}

@article{10.1145/3129343,
author = {Draghici, Adriana and Steen, Maarten Van},
title = {A Survey of Techniques for Automatically Sensing the Behavior of a Crowd},
year = {2018},
issue_date = {April 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3129343},
doi = {10.1145/3129343},
abstract = {Crowd-centric research is receiving increasingly more attention as datasets on crowd behavior are becoming readily available. We have come to a point where many of the models on pedestrian analytics introduced in the last decade, which have mostly not been validated, can now be tested using real-world datasets. In this survey, we concentrate exclusively on automatically gathering such datasets, which we refer to as sensing the behavior of pedestrians. We roughly distinguish two approaches: one that requires users to explicitly use local applications and wearables, and one that scans the presence of handheld devices such as smartphones. We come to the conclusion that despite the numerous reports in popular media, relatively few groups have been looking into practical solutions for sensing pedestrian behavior. Moreover, we find that much work is still needed, in particular when it comes to combining privacy, transparency, scalability, and ease of deployment. We report on over 90 relevant articles and discuss and compare in detail 30 reports on sensing pedestrian behavior.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {21},
numpages = {40},
keywords = {Pedestrian sensing, pedestrian tracking, crowd sensing}
}

@article{10.1145/3329118,
author = {Ribeiro, Madalena and Gomes, Abel J. P.},
title = {Recoloring Algorithms for Colorblind People: A Survey},
year = {2019},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3329118},
doi = {10.1145/3329118},
abstract = {Color is a powerful communication component, not only as part of the message meaning but also as a way of discriminating contents therein. However, 5% of the world’s population suffers from color vision deficiency (CVD), commonly known as colorblindness. This handicap adulterates the way the color is perceived, compromising the reading and understanding of the message contents. This issue becomes even more pertinent due to the increasing availability of multimedia contents in computational environments (e.g., web browsers). Aware of this problem, a significant number of CVD research works came up in the literature in the past two decades to improve color perception in text documents, still images, video, and so forth. This survey mainly addresses recoloring algorithms toward still images for colorblind people, including the current trends in the field of color adaptation.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {72},
numpages = {37},
keywords = {color blindness, color perception, Color vision deficiency}
}

@article{10.1145/2906152,
author = {Li, Xirong and Uricchio, Tiberio and Ballan, Lamberto and Bertini, Marco and Snoek, Cees G. M. and Bimbo, Alberto Del},
title = {Socializing the Semantic Gap: A Comparative Survey on Image Tag Assignment, Refinement, and Retrieval},
year = {2016},
issue_date = {July 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2906152},
doi = {10.1145/2906152},
abstract = {Where previous reviews on content-based image retrieval emphasize what can be seen in an image to bridge the semantic gap, this survey considers what people tag about an image. A comprehensive treatise of three closely linked problems (i.e., image tag assignment, refinement, and tag-based image retrieval) is presented. While existing works vary in terms of their targeted tasks and methodology, they rely on the key functionality of tag relevance, that is, estimating the relevance of a specific tag with respect to the visual content of a given image and its social context. By analyzing what information a specific method exploits to construct its tag relevance function and how such information is exploited, this article introduces a two-dimensional taxonomy to structure the growing literature, understand the ingredients of the main works, clarify their connections and difference, and recognize their merits and limitations. For a head-to-head comparison with the state of the art, a new experimental protocol is presented, with training sets containing 10,000, 100,000, and 1 million images, and an evaluation on three test sets, contributed by various research groups. Eleven representative works are implemented and evaluated. Putting all this together, the survey aims to provide an overview of the past and foster progress for the near future.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {14},
numpages = {39},
keywords = {tag retrieval, tag refinement, Social media, social tagging, tag relevance, content-based image retrieval, tag assignment}
}

@article{10.1145/1883612.1883614,
author = {Viana, Aline Carneiro and Maag, Stephane and Zaidi, Fatiha},
title = {One Step Forward: Linking Wireless Self-Organizing Network Validation Techniques with Formal Testing Approaches},
year = {2011},
issue_date = {January 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/1883612.1883614},
doi = {10.1145/1883612.1883614},
abstract = {Wireless self-organizing networks (WSONs) have attracted considerable attention from the network research community; however, the key for their success is the rigorous validation of the properties of the network protocols. Applications of risk or those demanding precision (like alert-based systems) require a rigorous and reliable validation of deployed network protocols. While the main goal is to ensure the reliability of the protocols, validation techniques also allow the establishment of their correctness regarding the related protocols' requirements. Nevertheless, even if different communities have carried out intensive research activities on the validation domain, WSONs still raise new issues for and challenging constraints to these communities. We thus, advocate the use of complementary techniques coming from different research communities to efficiently address the validation of WSON protocols. The goal of this tutorial is to present a comprehensive review of the literature on protocol engineering techniques and to discuss difficulties imposed by the characteristics of WSONs on the protocol engineering community. Following the formal and nonformal classification of techniques, we provide a discussion about components and similarities of existing protocol validation approaches. We also investigate how to take advantage of such similarities to obtain complementary techniques and outline new challenges.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {7},
numpages = {36},
keywords = {Protocol validation, wireless self-organizing networks}
}

@article{10.1145/3136623,
author = {Mansouri, Yaser and Toosi, Adel Nadjaran and Buyya, Rajkumar},
title = {Data Storage Management in Cloud Environments: Taxonomy, Survey, and Future Directions},
year = {2017},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3136623},
doi = {10.1145/3136623},
abstract = {Storage as a Service (StaaS) is a vital component of cloud computing by offering the vision of a virtually infinite pool of storage resources. It supports a variety of cloud-based data store classes in terms of availability, scalability, ACID (Atomicity, Consistency, Isolation, Durability) properties, data models, and price options. Application providers deploy these storage classes across different cloud-based data stores not only to tackle the challenges arising from reliance on a single cloud-based data store but also to obtain higher availability, lower response time, and more cost efficiency. Hence, in this article, we first discuss the key advantages and challenges of data-intensive applications deployed within and across cloud-based data stores. Then, we provide a comprehensive taxonomy that covers key aspects of cloud-based data store: data model, data dispersion, data consistency, data transaction service, and data management cost. Finally, we map various cloud-based data stores projects to our proposed taxonomy to validate the taxonomy and identify areas for future research.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {91},
numpages = {51},
keywords = {and data management cost, data storage, transaction service, data consistency, Data management, data replication}
}

@article{10.1145/3423166,
author = {Varela-Vaca, \'{A}ngel Jes\'{u}s and Quintero, Antonia M. Reina},
title = {Smart Contract Languages: A Multivocal Mapping Study},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3423166},
doi = {10.1145/3423166},
abstract = {Blockchain is a disruptive technology that has attracted the attention of the scientific community and companies, as proven by the exponential growth of publications on this topic in recent years. This growing interest is mainly due to the promise that the use of blockchain enables it to be verified, without including any trusted intermediaries, that the information received from the network is authentic and up-to-date. In this respect, blockchain is a distributed database that can be seen as a ledger that records all transactions that have ever been executed. In this context, smart contracts are pieces of software used to facilitate, verify, and enforce the negotiation of a transaction on a blockchain platform. These pieces of software are implemented by using programming languages, which are sometimes provided by the blockchain platforms themselves. This study aims to (1) identify and categorise the state-of-the-art related to smart contract languages, in terms of the existing languages and their main features, and (2) identify new research opportunities. The review has been conducted as a multivocal mapping study that follows the guidelines proposed by Garousi et&nbsp;al. for conducting multivocal literature reviews, as well as the guidelines proposed by Kitchenham and Charters for conducting mapping studies. As a result of the implementation of the review protocol, 4,119 papers were gathered, and 109 of them were selected for extraction. The contributions of this article are twofold: (1) 101 different smart contract languages have been identified and classified according to a variety of criteria; (2) a discussion on the findings and their implications for future research have been outlined. As a conclusion, it could be stated that a rigorous and replicable overview of the state-of-the-art of smart contract languages has been provided that can benefit not only researchers but also practitioners in the field, thanks to its multivocal nature.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {3},
numpages = {38},
keywords = {multivocal literature mapping study, Smart contract language, blockchain, systematic literature review}
}

@article{10.1145/3204940,
author = {Tamine, Lynda and Daoud, Mariam},
title = {Evaluation in Contextual Information Retrieval: Foundations and Recent Advances within the Challenges of Context Dynamicity and Data Privacy},
year = {2018},
issue_date = {September 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3204940},
doi = {10.1145/3204940},
abstract = {Context such as the user’s search history, demographics, devices, and surroundings, has become prevalent in various domains of information seeking and retrieval such as mobile search, task-based search, and social search. While evaluation is central and has a long history in information retrieval, it faces the big challenge of designing an appropriate methodology that embeds the context into evaluation settings. In this article, we present a unified summary of a wide range of main and recent progress in contextual information retrieval evaluation that leverages diverse context dimensions and uses different principles, methodologies, and levels of measurements. More specifically, this survey article aims to fill two main gaps in the literature: First, it provides a critical summary and comparison of existing contextual information retrieval evaluation methodologies and metrics according to a simple stratification model; second, it points out the impact of context dynamicity and data privacy on the evaluation design. Finally, we recommend promising research directions for future investigations.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {78},
numpages = {36},
keywords = {context, tasks, users, evaluation, relevance, Information retrieval}
}

@article{10.1145/3177852,
author = {Antunes, Rodolfo S. and Seewald, Lucas A. and Rodrigues, Vinicius F. and Costa, Cristiano A. Da and Jr., Luiz Gonzaga and Righi, Rodrigo R. and Maier, Andreas and Eskofier, Bj\"{o}rn and Ollenschl\"{a}ger, Malte and Naderi, Farzad and Fahrig, Rebecca and Bauer, Sebastian and Klein, Sigrun and Campanatti, Gelson},
title = {A Survey of Sensors in Healthcare Workflow Monitoring},
year = {2018},
issue_date = {June 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3177852},
doi = {10.1145/3177852},
abstract = {Activities of a clinical staff in healthcare environments must regularly be adapted to new treatment methods, medications, and technologies. This constant evolution requires the monitoring of the workflow, or the sequence of actions from actors involved in a procedure, to ensure quality of medical services. In this context, recent advances in sensing technologies, including Real-time Location Systems and Computer Vision, enable high-precision tracking of actors and equipment. The current state-of-the-art about healthcare workflow monitoring typically focuses on a single technology and does not discuss its integration with others. Such an integration can lead to better solutions to evaluate medical workflows. This study aims to fill the gap regarding the analysis of monitoring technologies with a systematic literature review about sensors for capturing the workflow of healthcare environments. Its main scientific contribution is to identify both current technologies used to track activities in a clinical environment and gaps on their combination to achieve better results. It also proposes a taxonomy to classify work regarding sensing technologies and methods. The literature review does not present proposals that combine data obtained from Real-time Location Systems and Computer Vision sensors. Further analysis shows that a multimodal analysis is more flexible and could yield better results.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {42},
numpages = {37},
keywords = {healthcare, workflow monitoring, Computer Vision, Real-time Location Systems}
}

@article{10.1145/1922649.1922654,
author = {Karimi, Sarvnaz and Scholer, Falk and Turpin, Andrew},
title = {Machine Transliteration Survey},
year = {2011},
issue_date = {April 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/1922649.1922654},
doi = {10.1145/1922649.1922654},
abstract = {Machine transliteration is the process of automatically transforming the script of a word from a source language to a target language, while preserving pronunciation. The development of algorithms specifically for machine transliteration began over a decade ago based on the phonetics of source and target languages, followed by approaches using statistical and language-specific methods. In this survey, we review the key methodologies introduced in the transliteration literature. The approaches are categorized based on the resources and algorithms used, and the effectiveness is compared.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {17},
numpages = {46},
keywords = {Automatic translation, machine learning, transliteration evaluation, machine transliteration, natural language processing}
}

@article{10.1145/3446370,
author = {Hassanin, Mohammed and Khan, Salman and Tahtali, Murat},
title = {Visual Affordance and Function Understanding: A Survey},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3446370},
doi = {10.1145/3446370},
abstract = {Nowadays, robots are dominating the manufacturing, entertainment, and healthcare industries. Robot vision aims to equip robots with the capabilities to discover information, understand it, and interact with the environment, which require an agent to effectively understand object affordances and functions in complex visual domains. In this literature survey, first, “visual affordances” are focused on and current state-of-the-art approaches for solving relevant problems as well as open problems and research gaps are summarized. Then, sub-problems, such as affordance detection, categorization, segmentation, and high-level affordance reasoning, are specifically discussed. Furthermore, functional scene understanding and its prevalent descriptors used in the literature are covered. This survey also provides the necessary background to the problem, sheds light on its significance, and highlights the existing challenges for affordance and functionality learning.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {47},
numpages = {35},
keywords = {visual reasoning, deep learning, Affordance prediction, functional scene understanding}
}

@article{10.1145/3281010,
author = {Kumar, Pawan and Kumar, Rakesh},
title = {Issues and Challenges of Load Balancing Techniques in Cloud Computing: A Survey},
year = {2019},
issue_date = {February 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3281010},
doi = {10.1145/3281010},
abstract = {With the growth in computing technologies, cloud computing has added a new paradigm to user services that allows accessing Information Technology services on the basis of pay-per-use at any time and any location. Owing to flexibility in cloud services, numerous organizations are shifting their business to the cloud and service providers are establishing more data centers to provide services to users. However, it is essential to provide cost-effective execution of tasks and proper utilization of resources. Several techniques have been reported in the literature to improve performance and resource use based on load balancing, task scheduling, resource management, quality of service, and workload management. Load balancing in the cloud allows data centers to avoid overloading/underloading in virtual machines, which itself is a challenge in the field of cloud computing. Therefore, it becomes a necessity for developers and researchers to design and implement a suitable load balancer for parallel and distributed cloud environments. This survey presents a state-of-the-art review of issues and challenges associated with existing load-balancing techniques for researchers to develop more effective algorithms.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {120},
numpages = {35},
keywords = {resource allocation, task scheduling, optimization, cloud computing, Load balancing, virtual machine, workload management}
}

@article{10.1145/3444692,
author = {Varghese, Blesson and Wang, Nan and Bermbach, David and Hong, Cheol-Ho and Lara, Eyal De and Shi, Weisong and Stewart, Christopher},
title = {A Survey on Edge Performance Benchmarking},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3444692},
doi = {10.1145/3444692},
abstract = {Edge computing is the next Internet frontier that will leverage computing resources located near users, sensors, and data stores to provide more responsive services. Therefore, it is envisioned that a large-scale, geographically dispersed, and resource-rich distributed system will emerge and play a key role in the future Internet. However, given the loosely coupled nature of such complex systems, their operational conditions are expected to change significantly over time. In this context, the performance characteristics of such systems will need to be captured rapidly, which is referred to as performance benchmarking, for application deployment, resource orchestration, and adaptive decision-making. Edge performance benchmarking is a nascent research avenue that has started gaining momentum over the past five years. This article first reviews articles published over the past three decades to trace the history of performance benchmarking from tightly coupled to loosely coupled systems. It then systematically classifies previous research to identify the system under test, techniques analyzed, and benchmark runtime in edge performance benchmarking.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {66},
numpages = {33},
keywords = {Edge computing, benchmark runtime, techniques analyzed, edge performance benchmarking, system under test}
}

@article{10.1145/3012429,
author = {Liew, Chee Sun and Atkinson, Malcolm P. and Galea, Michelle and Ang, Tan Fong and Martin, Paul and Hemert, Jano I. Van},
title = {Scientific Workflows: Moving Across Paradigms},
year = {2016},
issue_date = {February 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3012429},
doi = {10.1145/3012429},
abstract = {Modern scientific collaborations have opened up the opportunity to solve complex problems that require both multidisciplinary expertise and large-scale computational experiments. These experiments typically consist of a sequence of processing steps that need to be executed on selected computing platforms. Execution poses a challenge, however, due to (1) the complexity and diversity of applications, (2) the diversity of analysis goals, (3) the heterogeneity of computing platforms, and (4) the volume and distribution of data.A common strategy to make these in silico experiments more manageable is to model them as workflows and to use a workflow management system to organize their execution. This article looks at the overall challenge posed by a new order of scientific experiments and the systems they need to be run on, and examines how this challenge can be addressed by workflows and workflow management systems. It proposes a taxonomy of workflow management system (WMS) characteristics, including aspects previously overlooked. This frames a review of prevalent WMSs used by the scientific community, elucidates their evolution to handle the challenges arising with the emergence of the “fourth paradigm,” and identifies research needed to maintain progress in this area.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {66},
numpages = {39},
keywords = {workflow management systems, Data-intensive science, workflows}
}

@article{10.1145/2932710,
author = {Hassani, Kaveh and Lee, Won-Sook},
title = {Visualizing Natural Language Descriptions: A Survey},
year = {2016},
issue_date = {July 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2932710},
doi = {10.1145/2932710},
abstract = {A natural language interface exploits the conceptual simplicity and naturalness of the language to create a high-level user-friendly communication channel between humans and machines. One of the promising applications of such interfaces is generating visual interpretations of semantic content of a given natural language that can be then visualized either as a static scene or a dynamic animation. This survey discusses requirements and challenges of developing such systems and reports 26 graphical systems that exploit natural language interfaces and addresses both artificial intelligence and visualization aspects. This work serves as a frame of reference to researchers and to enable further advances in the field.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {17},
numpages = {34},
keywords = {text-to-animation conversion, Text-to-picture conversion, symbol grounding, natural language understanding, text-to-scene conversion}
}

@article{10.1145/3377455,
author = {Papadakis, George and Skoutas, Dimitrios and Thanos, Emmanouil and Palpanas, Themis},
title = {Blocking and Filtering Techniques for Entity Resolution: A Survey},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3377455},
doi = {10.1145/3377455},
abstract = {Entity Resolution (ER), a core task of Data Integration, detects different entity profiles that correspond to the same real-world object. Due to its inherently quadratic complexity, a series of techniques accelerate it so that it scales to voluminous data. In this survey, we review a large number of relevant works under two different but related frameworks: Blocking and Filtering. The former restricts comparisons to entity pairs that are more likely to match, while the latter identifies quickly entity pairs that are likely to satisfy predetermined similarity thresholds. We also elaborate on hybrid approaches that combine different characteristics. For each framework we provide a comprehensive list of the relevant works, discussing them in the greater context. We conclude with the most promising directions for future work in the field.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {31},
numpages = {42},
keywords = {entity resolution, filtering, Blocking}
}

@article{10.1145/3355610,
author = {Binmakhashen, Galal M. and Mahmoud, Sabri A.},
title = {Document Layout Analysis: A Comprehensive Survey},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3355610},
doi = {10.1145/3355610},
abstract = {Document layout analysis (DLA) is a preprocessing step of document understanding systems. It is responsible for detecting and annotating the physical structure of documents. DLA has several important applications such as document retrieval, content categorization, text recognition, and the like. The objective of DLA is to ease the subsequent analysis/recognition phases by identifying the document-homogeneous blocks and by determining their relationships. The DLA pipeline consists of several phases that could vary among DLA methods, depending on the documents’ layouts and final analysis objectives. In this regard, a universal DLA algorithm that fits all types of document-layouts or that satisfies all analysis objectives has not been developed, yet. In this survey paper, we present a critical study of different document layout analysis techniques. The study highlights the motivational reasons for pursuing DLA and discusses comprehensively the different phases of the DLA algorithms based on a general framework that is formed as an outcome of reviewing the research in the field. The DLA framework consists of preprocessing, layout analysis strategies, post-processing, and performance evaluation phases. Overall, the article delivers an essential baseline for pursuing further research in document layout analysis.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {109},
numpages = {36},
keywords = {Document segmentation, document image retrieval, document structure analysis, document image understanding, layout analysis, physical document structure}
}

@article{10.1145/2893356,
author = {Mittal, Sparsh},
title = {A Survey of Techniques for Approximate Computing},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2893356},
doi = {10.1145/2893356},
abstract = {Approximate computing trades off computation quality with effort expended, and as rising performance demands confront plateauing resource budgets, approximate computing has become not merely attractive, but even imperative. In this article, we present a survey of techniques for approximate computing (AC). We discuss strategies for finding approximable program portions and monitoring output quality, techniques for using AC in different processing units (e.g., CPU, GPU, and FPGA), processor components, memory technologies, and so forth, as well as programming frameworks for AC. We classify these techniques based on several key characteristics to emphasize their similarities and differences. The aim of this article is to provide insights to researchers into working of AC techniques and inspire more efforts in this area to make AC the mainstream computing approach in future systems.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {62},
numpages = {33},
keywords = {GPU, quality configurability, approximate storage, approximate computing technique (ACT), FPGA, CPU, Review, classification, neural networks}
}

@article{10.1145/3158661,
author = {Davoudian, Ali and Chen, Liu and Liu, Mengchi},
title = {A Survey on NoSQL Stores},
year = {2018},
issue_date = {June 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3158661},
doi = {10.1145/3158661},
abstract = {Recent demands for storing and querying big data have revealed various shortcomings of traditional relational database systems. This, in turn, has led to the emergence of a new kind of complementary nonrelational data store, named as NoSQL. This survey mainly aims at elucidating the design decisions of NoSQL stores with regard to the four nonorthogonal design principles of distributed database systems: data model, consistency model, data partitioning, and the CAP theorem. For each principle, its available strategies and corresponding features, strengths, and drawbacks are explained. Furthermore, various implementations of each strategy are exemplified and crystallized through a collection of representative academic and industrial NoSQL technologies. Finally, we disclose some existing challenges in developing effective NoSQL stores, which need attention of the research community, application designers, and architects.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {40},
numpages = {43},
keywords = {elasticity, replication, NoSQL, data model, ACID, consistency model, CAP theorem, partitioning}
}

@article{10.1145/3124391,
author = {Santana, Eduardo Felipe Zambom and Chaves, Ana Paula and Gerosa, Marco Aurelio and Kon, Fabio and Milojicic, Dejan S.},
title = {Software Platforms for Smart Cities: Concepts, Requirements, Challenges, and a Unified Reference Architecture},
year = {2017},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3124391},
doi = {10.1145/3124391},
abstract = {Information and communication technologies (ICT) can be instrumental in progressing towards smarter city environments, which improve city services, sustainability, and citizens’ quality of life. Smart City software platforms can support the development and integration of Smart City applications. However, the ICT community must overcome current technological and scientific challenges before these platforms can be widely adopted. This article surveys the state of the art in software platforms for Smart Cities. We analyzed 23 projects concerning the most used enabling technologies, as well as functional and non-functional requirements, classifying them into four categories: Cyber-Physical Systems, Internet of Things, Big Data, and Cloud Computing. Based on these results, we derived a reference architecture to guide the development of next-generation software platforms for Smart Cities. Finally, we enumerated the most frequently cited open research challenges and discussed future opportunities. This survey provides important references to help application developers, city managers, system operators, end-users, and Smart City researchers make project, investment, and research decisions.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {78},
numpages = {37},
keywords = {software platforms, Wireless sensor networks}
}

@article{10.1145/3329119,
author = {Fan, Ching-Ling and Lo, Wen-Chih and Pai, Yu-Tung and Hsu, Cheng-Hsin},
title = {A Survey on 360° Video Streaming: Acquisition, Transmission, and Display},
year = {2019},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3329119},
doi = {10.1145/3329119},
abstract = {Head-mounted displays and 360° videos have become increasingly more popular, delivering a more immersive viewing experience to end users. Streaming 360° videos over the best-effort Internet, however, faces tremendous challenges, because of the high resolution and the short response time requirements. This survey presents the current literature related to 360° video streaming. We start with 360° video streaming systems built for real experiments to investigate the practicality and efficiency of 360° video streaming. We then present the video and viewer datasets, which may be used to drive large-scale simulations and experiments. Different optimization tools in various stages of the 360° video streaming pipeline are discussed in detail. We also present various applications enabled by 360° video streaming. In the appendices, we review the off-the-shelf hardware available at the time of writing and the open research problems.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {71},
numpages = {36},
keywords = {video streaming, 360° videos, Virtual reality}
}

@article{10.1145/3076253,
author = {Cao, Longbing},
title = {Data Science: A Comprehensive Overview},
year = {2017},
issue_date = {October 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3076253},
doi = {10.1145/3076253},
abstract = {The 21st century has ushered in the age of big data and data economy, in which data DNA, which carries important knowledge, insights, and potential, has become an intrinsic constituent of all data-based organisms. An appropriate understanding of data DNA and its organisms relies on the new field of data science and its keystone, analytics. Although it is widely debated whether big data is only hype and buzz, and data science is still in a very early phase, significant challenges and opportunities are emerging or have been inspired by the research, innovation, business, profession, and education of data science. This article provides a comprehensive survey and tutorial of the fundamental aspects of data science: the evolution from data analysis to data science, the data science concepts, a big picture of the era of data science, the major challenges and directions in data innovation, the nature of data analytics, new industrialization and service opportunities in the data economy, the profession and competency of data education, and the future of data science. This article is the first in the field to draw a comprehensive big picture, in addition to offering rich observations, lessons, and thinking about data science and analytics.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {43},
numpages = {42},
keywords = {data service, computing, big data analytics, informatics, data engineering, data science, data scientist, advanced analytics, Big data, data economy, data innovation, data education, data profession, data analysis, data DNA, statistics, data analytics, data industry}
}

@article{10.1145/2492705,
author = {Medina, Violeta and Garc\'{\i}a, Juan Manuel},
title = {A Survey of Migration Mechanisms of Virtual Machines},
year = {2014},
issue_date = {January 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2492705},
doi = {10.1145/2492705},
abstract = {In the virtualization area, replication has been considered as a mechanism to provide high availability. A high-availability system should be active most of the time, and this is the reason that its design should consider almost zero downtime and a minimal human intervention if a recovery process is demanded. Several migration and replication mechanisms have been developed to provide high availability inside virtualized environments. In this article, a survey of migration mechanisms is reported. These approaches are classified in three main classes: process migration, memory migration, and suspend/resume migration.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {30},
numpages = {33},
keywords = {virtualization, replication, High availability, migration, virtual machine}
}

@article{10.1145/2738040,
author = {Zhao, Chenyuan and Wysocki, Bryant T. and Liu, Yifang and Thiem, Clare D. and McDonald, Nathan R. and Yi, Yang},
title = {Spike-Time-Dependent Encoding for Neuromorphic Processors},
year = {2015},
issue_date = {September 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {3},
issn = {1550-4832},
url = {https://doi.org/10.1145/2738040},
doi = {10.1145/2738040},
abstract = {This article presents our research towards developing novel and fundamental methodologies for data representation using spike-timing-dependent encoding. Time encoding efficiently maps a signal's amplitude information into a spike time sequence that represents the input data and offers perfect recovery for band-limited stimuli. In this article, we pattern the neural activities across multiple timescales and encode the sensory information using time-dependent temporal scales. The spike encoding methodologies for autonomous classification of time-series signatures are explored using near-chaotic reservoir computing. The proposed spiking neuron is compact, low power, and robust. A hardware implementation of these results is expected to produce an agile hardware implementation of time encoding as a signal conditioner for dynamical neural processor designs.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = sep,
articleno = {23},
numpages = {21},
keywords = {analog neuron, Neuromorphic computing, reservoir computing, spiking train, neural encoding}
}

@article{10.1145/2856125,
author = {Mittal, Sparsh},
title = {A Survey of Techniques for Architecting and Managing Asymmetric Multicore Processors},
year = {2016},
issue_date = {February 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2856125},
doi = {10.1145/2856125},
abstract = {To meet the needs of a diverse range of workloads, asymmetric multicore processors (AMPs) have been proposed, which feature cores of different microarchitecture or ISAs. However, given the diversity inherent in their design and application scenarios, several challenges need to be addressed to effectively architect AMPs and leverage their potential in optimizing both sequential and parallel performance. Several recent techniques address these challenges. In this article, we present a survey of architectural and system-level techniques proposed for designing and managing AMPs. By classifying the techniques on several key characteristics, we underscore their similarities and differences. We clarify the terminology used in this research field and identify challenges that are worthy of future investigation. We hope that more than just synthesizing the existing work on AMPs, the contribution of this survey will be to spark novel ideas for architecting future AMPs that can make a definite impact on the landscape of next-generation computing systems.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {45},
numpages = {38},
keywords = {Review, heterogeneous multicore architecture, reconfigurable AMP, big/little system, classification, asymmetric multicore processor}
}

@article{10.1145/3337773,
author = {Georgiou, Stefanos and Rizou, Stamatia and Spinellis, Diomidis},
title = {Software Development Lifecycle for Energy Efficiency: Techniques and Tools},
year = {2019},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3337773},
doi = {10.1145/3337773},
abstract = {Motivation: In modern it systems, the increasing demand for computational power is tightly coupled with ever higher energy consumption. Traditionally, energy efficiency research has focused on reducing energy consumption at the hardware level. Nevertheless, the software itself provides numerous opportunities for improving energy efficiency.Goal: Given that energy efficiency for it systems is a rising concern, we investigate existing work in the area of energy-aware software development and identify open research challenges. Our goal is to reveal limitations, features, and tradeoffs regarding energy-performance for software development and provide insights on existing approaches, tools, and techniques for energy-efficient programming.Method: We analyze and categorize research work mostly extracted from top-tier conferences and journals concerning energy efficiency across the software development lifecycle phases.Results: Our analysis shows that related work in this area has focused mainly on the implementation and verification phases of the software development lifecycle. Existing work shows that the use of parallel and approximate programming, source code analyzers, efficient data structures, coding practices, and specific programming languages can significantly increase energy efficiency. Moreover, the utilization of energy monitoring tools and benchmarks can provide insights for the software practitioners and raise energy-awareness during the development phase.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {81},
numpages = {33},
keywords = {energy optimization, parallel programming, code refactoring, source code analysis, energy efficiency, approximate programming, GreenIT, coding practices, energy profiling, design patterns, software development lifecycle}
}

@article{10.1145/3303849,
author = {R\"{o}ger, Henriette and Mayer, Ruben},
title = {A Comprehensive Survey on Parallelization and Elasticity in Stream Processing},
year = {2019},
issue_date = {May 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3303849},
doi = {10.1145/3303849},
abstract = {Stream Processing (SP) has evolved as the leading paradigm to process and gain value from the high volume of streaming data produced, e.g., in the domain of the Internet of Things. An SP system is a middleware that deploys a network of operators between data sources, such as sensors, and the consuming applications. SP systems typically face intense and highly dynamic data streams. Parallelization and elasticity enable SP systems to process these streams with continuous high quality of service. The current research landscape provides a broad spectrum of methods for parallelization and elasticity in SP. Each method makes specific assumptions and focuses on particular aspects. However, the literature lacks a comprehensive overview and categorization of the state of the art in SP parallelization and elasticity, which is necessary to consolidate the state of the research and to plan future research directions on this basis. Therefore, in this survey, we study the literature and develop a classification of current methods for both parallelization and elasticity in SP systems.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {36},
numpages = {37},
keywords = {parallelization, complex event processing, Stream processing, elasticity, data stream management system}
}

@article{10.1145/3303848,
author = {Rizk, Yara and Awad, Mariette and Tunstel, Edward W.},
title = {Cooperative Heterogeneous Multi-Robot Systems: A Survey},
year = {2019},
issue_date = {May 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3303848},
doi = {10.1145/3303848},
abstract = {The emergence of the Internet of things and the widespread deployment of diverse computing systems have led to the formation of heterogeneous multi-agent systems (MAS) to complete a variety of tasks. Motivated to highlight the state of the art on existing MAS while identifying their limitations, remaining challenges, and possible future directions, we survey recent contributions to the field. We focus on robot agents and emphasize the challenges of MAS sub-fields including task decomposition, coalition formation, task allocation, perception, and multi-agent planning and control. While some components have seen more advancements than others, more research is required before effective autonomous MAS can be deployed in real smart city settings that are less restrictive than the assumed validation environments of MAS. Specifically, more autonomous end-to-end solutions need to be experimentally tested and developed while incorporating natural language ontology and dictionaries to automate complex task decomposition and leveraging big data advancements to improve perception algorithms for robotics.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {29},
numpages = {31},
keywords = {cooperation, coalition formation, heterogeneous agents, decision-making models, task decomposition, Multi-robot systems, task allocation, perception}
}

@article{10.1145/3092695,
author = {Tran, Nguyen Khoi and Sheng, Quan Z. and Babar, Muhammad Ali and Yao, Lina},
title = {Searching the Web of Things: State of the Art, Challenges, and Solutions},
year = {2017},
issue_date = {November 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3092695},
doi = {10.1145/3092695},
abstract = {Technological advances allow more physical objects to connect to the Internet and provide their services on the Web as resources. Search engines are the key to fully utilize this emerging Web of Things, as they bridge users and applications with resources needed for their operation. Developing these systems is a challenging and diverse endeavor due to the diversity of Web of Things resources that they work with. Each combination of resources in query resolution process requires a different type of search engine with its own technical challenges and usage scenarios. This diversity complicates both the development of new systems and assessment of the state of the art. In this article, we present a systematic survey on Web of Things Search Engines (WoTSE), focusing on the diversity in forms of these systems. We collect and analyze over 200 related academic works to build a flexible conceptual model for WoTSE. We develop an analytical framework on this model to review the development of the field and its current status, reflected by 30 representative works in the area. We conclude our survey with a discussion on open issues to bridge the gap between the existing progress and an ideal WoTSE.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {55},
numpages = {34},
keywords = {Web of Things, Search, retrieval, Internet of Things, discovery}
}

@article{10.1145/3445965,
author = {Nasar, Zara and Jaffry, Syed Waqar and Malik, Muhammad Kamran},
title = {Named Entity Recognition and Relation Extraction: State-of-the-Art},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3445965},
doi = {10.1145/3445965},
abstract = {With the advent of Web 2.0, there exist many online platforms that result in massive textual-data production. With ever-increasing textual data at hand, it is of immense importance to extract information nuggets from this data. One approach towards effective harnessing of this unstructured textual data could be its transformation into structured text. Hence, this study aims to present an overview of approaches that can be applied to extract key insights from textual data in a structured way. For this, Named Entity Recognition and Relation Extraction are being majorly addressed in this review study. The former deals with identification of named entities, and the latter deals with problem of extracting relation between set of entities. This study covers early approaches as well as the developments made up till now using machine learning models. Survey findings conclude that deep-learning-based hybrid and joint models are currently governing the state-of-the-art. It is also observed that annotated benchmark datasets for various textual-data generators such as Twitter and other social forums are not available. This scarcity of dataset has resulted into relatively less progress in these domains. Additionally, the majority of the state-of-the-art techniques are offline and computationally expensive. Last, with increasing focus on deep-learning frameworks, there is need to understand and explain the under-going processes in deep architectures.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {20},
numpages = {39},
keywords = {joint modeling, deep learning, relation extraction, Information extraction, named entity recognition}
}

@article{10.1145/3450517,
author = {Alashaikh, Abdulaziz and Alanazi, Eisa and Al-Fuqaha, Ala},
title = {A Survey on the Use of Preferences for Virtual Machine Placement in Cloud Data Centers},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3450517},
doi = {10.1145/3450517},
abstract = {With the rapid development of virtualization techniques, cloud data centers allow for cost-effective, flexible, and customizable deployments of applications on virtualized infrastructure. Virtual machine (VM) placement aims to assign each virtual machine to a server in the cloud environment. VM Placement is of paramount importance to the design of cloud data centers. Typically, VM placement involves complex relations and multiple design factors as well as local policies that govern the assignment decisions. It also involves different constituents including cloud administrators and customers that might have disparate preferences while opting for a placement solution. Thus, it is often valuable to return not only an optimized solution to the VM placement problem but also a solution that reflects the given preferences of the constituents. In this article, we provide a detailed review on the role of preferences in the recent literature on VM placement. We examine different preference representations found in the literature, explain their existing usage, and explain the adopted solving approaches. We further discuss key challenges and identify possible research opportunities to better incorporate preferences within the context of VM placement.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {96},
numpages = {39},
keywords = {Virtual machines, preferences, decision making}
}

@article{10.1145/3190616,
author = {Quadrana, Massimo and Cremonesi, Paolo and Jannach, Dietmar},
title = {Sequence-Aware Recommender Systems},
year = {2018},
issue_date = {September 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3190616},
doi = {10.1145/3190616},
abstract = {Recommender systems are one of the most successful applications of data mining and machine-learning technology in practice. Academic research in the field is historically often based on the matrix completion problem formulation, where for each user-item-pair only one interaction (e.g., a rating) is considered. In many application domains, however, multiple user-item interactions of different types can be recorded over time. And, a number of recent works have shown that this information can be used to build richer individual user models and to discover additional behavioral patterns that can be leveraged in the recommendation process.In this work, we review existing works that consider information from such sequentially ordered user-item interaction logs in the recommendation process. Based on this review, we propose a categorization of the corresponding recommendation tasks and goals, summarize existing algorithmic solutions, discuss methodological approaches when benchmarking what we call sequence-aware recommender systems, and outline open challenges in the area.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {66},
numpages = {36},
keywords = {dataset, evaluation, Sequence, algorithms, trend, recommendation, session}
}

@article{10.1145/3378935,
author = {Cong, Peijin and Zhou, Junlong and Li, Liying and Cao, Kun and Wei, Tongquan and Li, Keqin},
title = {A Survey of Hierarchical Energy Optimization for Mobile Edge Computing: A Perspective from End Devices to the Cloud},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3378935},
doi = {10.1145/3378935},
abstract = {With the development of wireless technology, various emerging mobile applications are attracting significant attention and drastically changing our daily lives. Applications such as augmented reality and object recognition demand stringent delay and powerful processing capability, which exerts enormous pressure on mobile devices with limited resources and energy. In this article, a survey of techniques for mobile device energy optimization is presented in a hierarchy of device design and operation, computation offloading, wireless data transmission, and cloud execution of offloaded computation. Energy management strategies for mobile devices from hardware and software aspects are first discussed, followed by energy-efficient computation offloading frameworks for mobile applications that trade application response time for device energy consumption. Then, techniques for efficient wireless data communication to reduce transmission energy are summarized. Finally, the execution mechanisms of application components or tasks in various clouds are further described to provide energy-saving opportunities for mobile devices. We classify the research works based on key characteristics of devices and applications to emphasize their similarities and differences. We hope that this survey will give insights to researchers into energy management mechanisms on mobile devices, and emphasize the crucial importance of optimizing device energy consumption for more research efforts in this area.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {38},
numpages = {44},
keywords = {mobile computing (MC), mobile devices, Computation offloading, mobile edge computing (MEC), energy optimization, mobile cloud computing (MCC), wireless communication}
}

@article{10.1145/2674559,
author = {Zhou, Xiaowei and Yang, Can and Zhao, Hongyu and Yu, Weichuan},
title = {Low-Rank Modeling and Its Applications in Image Analysis},
year = {2014},
issue_date = {January 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2674559},
doi = {10.1145/2674559},
abstract = {Low-rank modeling generally refers to a class of methods that solves problems by representing variables of interest as low-rank matrices. It has achieved great success in various fields including computer vision, data mining, signal processing, and bioinformatics. Recently, much progress has been made in theories, algorithms, and applications of low-rank modeling, such as exact low-rank matrix recovery via convex programming and matrix completion applied to collaborative filtering. These advances have brought more and more attention to this topic. In this article, we review the recent advances of low-rank modeling, the state-of-the-art algorithms, and the related applications in image analysis. We first give an overview of the concept of low-rank modeling and the challenging problems in this area. Then, we summarize the models and algorithms for low-rank matrix recovery and illustrate their advantages and limitations with numerical experiments. Next, we introduce a few applications of low-rank modeling in the context of image analysis. Finally, we conclude this article with some discussions.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {36},
numpages = {33},
keywords = {optimization, matrix factorization, image analysis, Low-rank modeling}
}

@article{10.1145/2597999,
author = {Akiki, Pierre A. and Bandara, Arosha K. and Yu, Yijun},
title = {Adaptive Model-Driven User Interface Development Systems},
year = {2014},
issue_date = {July 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2597999},
doi = {10.1145/2597999},
abstract = {Adaptive user interfaces (UIs) were introduced to address some of the usability problems that plague many software applications. Model-driven engineering formed the basis for most of the systems targeting the development of such UIs. An overview of these systems is presented and a set of criteria is established to evaluate the strengths and shortcomings of the state of the art, which is categorized under architectures, techniques, and tools. A summary of the evaluation is presented in tables that visually illustrate the fulfillment of each criterion by each system. The evaluation identified several gaps in the existing art and highlighted the areas of promising improvement.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {9},
numpages = {33},
keywords = {Adaptive user interfaces, model-driven engineering}
}

@article{10.1145/3291049,
author = {Malla, Sulav and Christensen, Ken},
title = {A Survey on Power Management Techniques for Oversubscription of Multi-Tenant Data Centers},
year = {2019},
issue_date = {February 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3291049},
doi = {10.1145/3291049},
abstract = {Power management for data centers has been extensively studied in the past 10 years. Most research has focused on owner-operated data centers with less focus on Multi-Tenant Data Centers (MTDC) or colocation data centers. In an MTDC, an operator owns the building and leases out space, power, and cooling to tenants to install their own IT equipment. MTDC’s present new challenges for data center power management due to an inherent lack of coordination between the operator and tenants. In this article, we conduct a comprehensive survey of existing MTDC power management techniques for demand response programs, sustainability, and/or power hierarchy oversubscription. Power oversubscription is of particular interest, as it can maximize resource utilization, increase operator profit, and reduce tenant costs. We create a taxonomy to classify and compare key works. Our taxonomy and review differ from existing works in that our emphasis is on safe power oversubscription, which has been neglected in previous surveys. We propose future research for prediction and control of power overload events in an oversubscribed MTDC.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {1},
numpages = {31},
keywords = {power management, colocation data center, oversubscription, Multi-tenant data center}
}

@article{10.1145/1922649.1922652,
author = {Mcgill, Kathleen and Taylor, Stephen},
title = {Robot Algorithms for Localization of Multiple Emission Sources},
year = {2011},
issue_date = {April 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/1922649.1922652},
doi = {10.1145/1922649.1922652},
abstract = {The problem of time-varying, multisource localization using robotic swarms has received relatively little attention when compared to single-source localization. It involves distinct challenges regarding how to partition the robots during search to ensure that all sources are located in minimal time, how to avoid obstacles and other robots, and how to proceed after each source is found. Unfortunately, no common set of validation problems and reference algorithms has evolved, and there are no general theoretical foundations that guarantee progress, convergence, and termination. This article surveys the current multisource literature from the viewpoint of these central questions.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {15},
numpages = {25},
keywords = {Bayesian filters, Source localization, hill-climbing algorithms, Bayesian occupancy mapping, mobile robotic networks, biologically inspired algorithms, swarm algorithms}
}

@article{10.1145/3325097,
author = {Adhikari, Mainak and Amgoth, Tarachand and Srirama, Satish Narayana},
title = {A Survey on Scheduling Strategies for Workflows in Cloud Environment and Emerging Trends},
year = {2019},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3325097},
doi = {10.1145/3325097},
abstract = {Workflow scheduling is one of the challenging issues in emerging trends of the distributed environment that focuses on satisfying various quality of service (QoS) constraints. The cloud receives the applications as a form of a workflow, consisting of a set of interdependent tasks, to solve the large-scale scientific or enterprise problems. Workflow scheduling in the cloud environment has been studied extensively over the years, and this article provides a comprehensive review of the approaches. This article analyses the characteristics of various workflow scheduling techniques and classifies them based on their objectives and execution model. In addition, the recent technological developments and paradigms such as serverless computing and Fog computing are creating new requirements/opportunities for workflow scheduling in a distributed environment. The serverless infrastructures are mainly designed for processing background tasks such as Internet-of-Things (IoT), web applications, or event-driven applications. To address the ever-increasing demands of resources and to overcome the drawbacks of the cloud-centric IoT, the Fog computing paradigm has been developed. This article also discusses workflow scheduling in the context of these emerging trends of cloud computing.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {68},
numpages = {36},
keywords = {QoS constraint, Fog computing, Cloud computing, workflow scheduling, scientific problems, serverless computing}
}

@article{10.1145/3428147,
author = {Jiang, Shengming},
title = {Networking in Oceans: A Survey},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3428147},
doi = {10.1145/3428147},
abstract = {The ocean is a huge saltwater body that is different from terrestrial environments in terms of deployment circumstance, weather conditions, and user distributions. Therefore, it is difficult to apply terrestrial networking technologies directly in oceans. The cost-effectiveness of satellites is still an issue to be addressed to increase their popularity due to their high cost in construction, launching, and maintenance and high deployment risks. Such situations stimulate many research efforts on networking technologies in the ocean space consisting of coastline, water surface, sky, and underwater. This article conducts a comprehensive survey on the related issues through reviewing the networking environments and communication networks already operating in the ocean space as well as ongoing R8D activities and results reported in the literature. These systems include coastal networks, water surface networks, sky networks, and underwater networks, which are reviewed and discussed along with summaries on the related topics and research issues necessary for further studies. This article, taking into account maritime communication networks and underwater networking together, aims to provide the reader with an overview on the state of the art and corresponding challenging issues for networking in the ocean space.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {13},
numpages = {33},
keywords = {satellite networks, maritime radio systems, cellular networks, wireless ad hoc networks, Networking in oceans, underwater networks, marine Internet}
}

@article{10.1145/2828994,
author = {Souza, Ramon Hugo De and Dantas, M\'{a}rio Ant\^{o}nio Ribeiro},
title = {Mapping QoE through QoS in an Approach to DDB Architectures: Research Analysis and Conceptualization},
year = {2015},
issue_date = {November 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2828994},
doi = {10.1145/2828994},
abstract = {In the context of distributed databases (DDBs), the absence of mathematically well defined equations to evaluate quality of service (QoS), especially with statistical models, seems to have taken database community attention from the possible performance guarantees that could be handled by concepts related to quality of experience (QoE). In this article, we targeted the definition of QoE based on completeness of QoS to deal with decisions concerning with performance correction in a system level. This study also presents a statistical bibliometric analysis before the proposed model. The idea was to show the origin of first studies with correlated focus, which also have initial conceptualizations, and then propose a new model. This model concerns concise QoS definitions, grouped to provide a basis for QoE analysis. Afterward, it is foreseen that a DDB system will be able to autoevaluate and be aware of recovering situations before they happen.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {31},
numpages = {41},
keywords = {distributed database architectures, Big data, user’s perspective, cloud services, quality of service, quality of experience}
}

@article{10.1145/3200920,
author = {Lozano, Roberto Casta\~{n}eda and Schulte, Christian},
title = {Survey on Combinatorial Register Allocation and Instruction Scheduling},
year = {2019},
issue_date = {July 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3200920},
doi = {10.1145/3200920},
abstract = {Register allocation (mapping variables to processor registers or memory) and instruction scheduling (reordering instructions to increase instruction-level parallelism) are essential tasks for generating efficient assembly code in a compiler. In the past three decades, combinatorial optimization has emerged as an alternative to traditional, heuristic algorithms for these two tasks. Combinatorial optimization approaches can deliver optimal solutions according to a model, can precisely capture trade-offs between conflicting decisions, and are more flexible at the expense of increased compilation time.This article provides an exhaustive literature review and a classification of combinatorial optimization approaches to register allocation and instruction scheduling, with a focus on the techniques that are most applied in this context: integer programming, constraint programming, partitioned Boolean quadratic programming, and enumeration. Researchers in compilers and combinatorial optimization can benefit from identifying developments, trends, and challenges in the area; compiler practitioners may discern opportunities and grasp the potential benefit of applying combinatorial optimization.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {62},
numpages = {50},
keywords = {register allocation, Combinatorial optimization, instruction scheduling}
}

@article{10.1145/3381027,
author = {Herodotou, Herodotos and Chen, Yuxing and Lu, Jiaheng},
title = {A Survey on Automatic Parameter Tuning for Big Data Processing Systems},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3381027},
doi = {10.1145/3381027},
abstract = {Big data processing systems (e.g., Hadoop, Spark, Storm) contain a vast number of configuration parameters controlling parallelism, I/O behavior, memory settings, and compression. Improper parameter settings can cause significant performance degradation and stability issues. However, regular users and even expert administrators grapple with understanding and tuning them to achieve good performance. We investigate existing approaches on parameter tuning for both batch and stream data processing systems and classify them into six categories: rule-based, cost modeling, simulation-based, experiment-driven, machine learning, and adaptive tuning. We summarize the pros and cons of each approach and raise some open research problems for automatic parameter tuning.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {43},
numpages = {37},
keywords = {Storm, MapReduce, Spark, stream, self-tuning, Parameter tuning}
}

@article{10.1145/2983387,
author = {Trobec, Roman and Vasiljevi\'{c}, Radivoje and Toma\v{s}evi\'{c}, Milo and Milutinovi\'{c}, Veljko and Beivide, Ramon and Valero, Mateo},
title = {Interconnection Networks in Petascale Computer Systems: A Survey},
year = {2016},
issue_date = {December 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2983387},
doi = {10.1145/2983387},
abstract = {This article provides background information about interconnection networks, an analysis of previous developments, and an overview of the state of the art. The main contribution of this article is to highlight the importance of the interpolation and extrapolation of technological changes and physical constraints in order to predict the optimum future interconnection network. The technological changes are related to three of the most important attributes of interconnection networks: topology, routing, and flow-control algorithms. On the other hand, the physical constraints, that is, port counts, number of communication nodes, and communication speed, determine the realistic properties of the network. We present the state-of-the-art technology for the most commonly used interconnection networks and some background related to often-used network topologies. The interconnection networks of the best-performing petascale parallel computers from past and present Top500 lists are analyzed. The lessons learned from this analysis indicate that computer networks need better performance in future exascale computers. Such an approach leads to the conclusion that a high-radix topology with optical connections for longer links is set to become the optimum interconnect for a number of relevant application domains.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {44},
numpages = {24},
keywords = {high performance parallel computers, Interconnection networks, exascale computers, Top500 list}
}

@article{10.1145/2617662,
author = {Wang, You-Chiun},
title = {Mobile Sensor Networks: System Hardware and Dispatch Software},
year = {2014},
issue_date = {July 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2617662},
doi = {10.1145/2617662},
abstract = {Wireless sensor networks (WSNs) provide a convenient way to monitor the physical environment. They consist of a large number of sensors that have sensing, computing, and communication abilities. In the past, sensors were considered as static, but the network functionality would degrade when some sensors were broken. Today, the emerging hardware techniques have promoted the development of mobile sensors. Introducing mobility to sensors not only improves their capability but also gives them flexibility to deal with node failure. The article studies the research progress of mobile sensor networks, which embraces both system hardware and dispatch software. For system hardware, we review two popular types of mobile sensor platforms. One is to integrate mobile robots with sensors, whereas the other is to use existing conveyances to carry sensors. Dispatch software includes two topics. We first address how to solve different coverage problems by using a purely mobile WSN and then investigate how to dispatch mobile sensors in a hybrid WSN to perform various missions including data collection, faulty recovery, and event analysis. A discussion about research challenges in mobile sensor networks is also presented in the article.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {12},
numpages = {36},
keywords = {Dispatch algorithms, mobility management, path planning, wireless sensor and actuator network, sensor hardware}
}

@article{10.1145/2835374,
author = {Brienza, Simone and Cebeci, Sena Efsun and Masoumzadeh, Seyed Saeid and Hlavacs, Helmut and \"{O}zkasap, \"{O}znur and Anastasi, Giuseppe},
title = {A Survey on Energy Efficiency in P2P Systems: File Distribution, Content Streaming, and Epidemics},
year = {2015},
issue_date = {February 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2835374},
doi = {10.1145/2835374},
abstract = {Several Peer-to-Peer (P2P) protocols and applications have been developed to allow file distribution/sharing, video and music streaming, and data and information dissemination. These P2P systems are regularly used by a large number of users, both in desktop and mobile environments, and they generate a remarkable portion of the overall Internet traffic. However, many common P2P protocols and applications were designed neglecting the energy problem. In fact, they often require always-on devices in order to work properly, thus producing significant energy waste. The problem is even more relevant in the mobile context, since the battery lifetime of mobile devices is limited. Therefore, energy efficiency in P2P systems is a highly debated topic in the literature. New P2P approaches—more energy efficient than traditional client/server solutions—have been proposed. In addition, several improvements to existing P2P protocols have been introduced to reduce their energy consumption. In this article, we present a general taxonomy to classify state-of-the-art approaches to the energy problem in P2P systems and applications. Then, we survey the main solutions available in the literature, focusing on three relevant classes of P2P systems and applications: file sharing/distribution, content streaming, and epidemics. Furthermore, we outline open issues and provide future research guidelines for each class of P2P systems.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {36},
numpages = {37},
keywords = {P2P, epidemics, Peer-to-peer, content streaming, file distribution, energy efficiency}
}

@article{10.1145/3447241,
author = {Astolfi, Gilberto and Rezende, F\'{a}bio Prestes Cesar and Porto, Jo\~{a}o Vitor De Andrade and Matsubara, Edson Takashi and Pistori, Hemerson},
title = {Syntactic Pattern Recognition in Computer Vision: A Systematic Review},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3447241},
doi = {10.1145/3447241},
abstract = {Using techniques derived from the syntactic methods for visual pattern recognition is not new and was much explored in the area called syntactical or structural pattern recognition. Syntactic methods have been useful because they are intuitively simple to understand and have transparent, interpretable, and elegant representations. Their capacity to represent patterns in a semantic, hierarchical, compositional, spatial, and temporal way have made them very popular in the research community. In this article, we try to give an overview of how syntactic methods have been employed for computer vision tasks. We conduct a systematic literature review to survey the most relevant studies that use syntactic methods for pattern recognition tasks in images and videos. Our search returned 597 papers, of which 71 papers were selected for analysis. The results indicated that in most of the studies surveyed, the syntactic methods were used as a high-level structure that makes the hierarchical or semantic relationship among objects or actions to perform the most diverse tasks.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {65},
numpages = {35},
keywords = {Computer vision, syntactic methods, image representation, formal languages, pattern recognition}
}

@article{10.1145/3400031,
author = {Harada, Tomohiro and Alba, Enrique},
title = {Parallel Genetic Algorithms: A Useful Survey},
year = {2020},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3400031},
doi = {10.1145/3400031},
abstract = {In this article, we encompass an analysis of the recent advances in parallel genetic algorithms (PGAs). We have selected these algorithms because of the deep interest in many research fields for techniques that can face complex applications where running times and other computational resources are greedily consumed by present solvers, and PGAs act then as efficient procedures that fully use modern computational platforms at the same time that allow the resolution of cutting-edge open problems. We have faced this survey on PGAs with the aim of helping newcomers or busy researchers who want to have a wide vision on the field. Then, we discuss the most well-known models and their implementations from a recent (last six years) and useful point of view: We discuss on highly cited articles, keywords, the venues where they can be found, a very comprehensive (and new) taxonomy covering different research domains involved in PGAs, and a set of recent applications. We also introduce a new vision on open challenges and try to give hints that guide practitioners and specialized researchers. Our conclusion is that there are many advantages to using these techniques and lots of potential interactions to other evolutionary algorithms; as well, we contribute to creating a body of knowledge in PGAs by summarizing them in a structured way, so the reader can find this article useful for practical research, graduate teaching, and as a pedagogical guide to this exciting domain.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {86},
numpages = {39},
keywords = {complex problem solving, optimization, time consuming applications, and learning, last five years, new areas for search, Parallelism, artificial intelligence, genetic algorithms}
}

@article{10.1145/3095798,
author = {Ba\v{c}a, Radim and Kr\'{a}tk\'{y}, Michal and Holubov\'{a}, Irena and Ne\v{c}ask\'{y}, Martin and Skopal, Tom\'{a}\v{s} and Svoboda, Martin and Sakr, Sherif},
title = {Structural XML Query Processing},
year = {2017},
issue_date = {November 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3095798},
doi = {10.1145/3095798},
abstract = {Since the boom in new proposals on techniques for efficient querying of XML data is now over and the research world has shifted its attention toward new types of data formats, we believe that it is crucial to review what has been done in the area to help users choose an appropriate strategy and scientists exploit the contributions in new areas of data processing. The aim of this work is to provide a comprehensive study of the state-of-the-art of approaches for the structural querying of XML data. In particular, we start with a description of labeling schemas to capture the structure of the data and the respective storage strategies. Then we deal with the key part of every XML query processing: a twig query join, XML query algebras, optimizations of query plans, and selectivity estimation of XML queries. To the best of our knowledge, this is the first work that provides such a detailed description of XML query processing techniques that are related to structural aspects and that contains information about their theoretical and practical features as well as about their mutual compatibility and general usability.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {64},
numpages = {41},
keywords = {structural XML query processing, XML}
}

@article{10.1145/3092693,
author = {Stein, Michael and Fischer, Mathias and Schweizer, Immanuel and M\"{u}hlh\"{a}user, Max},
title = {A Classification of Locality in Network Research},
year = {2017},
issue_date = {November 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3092693},
doi = {10.1145/3092693},
abstract = {Limiting the knowledge of individual nodes is a major concern for the design of distributed algorithms. With the LOCAL model, theoretical research already established a common model of locality that has gained little practical relevance. As a result, practical research de facto lacks any common locality model. The only common denominator among practitioners is that a local algorithm is distributed with a restricted scope of interaction. This article closes the gap by introducing four practically motivated classes of locality that successively weaken the strict requirements of the LOCAL model. These classes are applied to categorize and survey 36 local algorithms from 12 different application domains. A detailed comparison shows the practicality of the classification and provides interesting insights. For example, the majority of algorithms limit the scope of interaction to at most two hops, independent of their locality class. Moreover, the application domain of algorithms tends to influence their degree of locality.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {53},
numpages = {37},
keywords = {Local algorithms, localized algorithms}
}

@article{10.1145/3092694,
author = {Schoknecht, Andreas and Thaler, Tom and Fettke, Peter and Oberweis, Andreas and Laue, Ralf},
title = {Similarity of Business Process Models—A State-of-the-Art Analysis},
year = {2017},
issue_date = {November 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3092694},
doi = {10.1145/3092694},
abstract = {Business process models play an important role in today’s enterprises, hence, model repositories may contain hundreds of models. These models are, for example, reused during process modeling activities or utilized to check the conformance of processes with legal regulations. With respect to the amount of models, such applications benefit from or even require detailed insights into the correspondences between process models or between process models’ nodes. Therefore, various process similarity and matching measures have been proposed during the past few years. This article provides an overview of the state-of-the-art regarding business process model similarity measures and aims at analyzing which similarity measures exist, how they are characterized, and what kind of calculations are typically applied to determine similarity values. Finally, the analysis of 123 similarity measures results in the suggestions to conduct further comparative analyses of similarity measures, to investigate the integration of human input into similarity measurement, and to further analyze the requirements of similarity measurement usage scenarios as future research opportunities.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {52},
numpages = {33},
keywords = {process similarity measurement, process model matching, Process model similarity}
}

@article{10.1145/2480741.2480751,
author = {Dionisio, John David N. and III, William G. Burns and Gilbert, Richard},
title = {3D Virtual Worlds and the Metaverse: Current Status and Future Possibilities},
year = {2013},
issue_date = {June 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2480741.2480751},
doi = {10.1145/2480741.2480751},
abstract = {Moving from a set of independent virtual worlds to an integrated network of 3D virtual worlds or Metaverse rests on progress in four areas: immersive realism, ubiquity of access and identity, interoperability, and scalability. For each area, the current status and needed developments in order to achieve a functional Metaverse are described. Factors that support the formation of a viable Metaverse, such as institutional and popular interest and ongoing improvements in hardware performance, and factors that constrain the achievement of this goal, including limits in computational methods and unrealized collaboration among virtual world stakeholders and developers, are also considered.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {34},
numpages = {38},
keywords = {second life, Immersion, virtual worlds, Internet}
}

@article{10.1145/2499621,
author = {Bulling, Andreas and Blanke, Ulf and Schiele, Bernt},
title = {A Tutorial on Human Activity Recognition Using Body-Worn Inertial Sensors},
year = {2014},
issue_date = {January 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2499621},
doi = {10.1145/2499621},
abstract = {The last 20 years have seen ever-increasing research activity in the field of human activity recognition. With activity recognition having considerably matured, so has the number of challenges in designing, implementing, and evaluating activity recognition systems. This tutorial aims to provide a comprehensive hands-on introduction for newcomers to the field of human activity recognition. It specifically focuses on activity recognition using on-body inertial sensors. We first discuss the key research challenges that human activity recognition shares with general pattern recognition and identify those challenges that are specific to human activity recognition. We then describe the concept of an Activity Recognition Chain (ARC) as a general-purpose framework for designing and evaluating activity recognition systems. We detail each component of the framework, provide references to related research, and introduce the best practice methods developed by the activity recognition research community. We conclude with the educational example problem of recognizing different hand gestures from inertial sensors attached to the upper and lower arm. We illustrate how each component of this framework can be implemented for this specific activity recognition problem and demonstrate how different implementations compare and how they impact overall recognition performance.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {33},
numpages = {33},
keywords = {gesture recognition, Activity Recognition Chain (ARC), on-body inertial sensors, Activity recognition}
}

@article{10.1145/2797211,
author = {Mann, Zolt\'{a}n \'{A}d\'{a}m},
title = {Allocation of Virtual Machines in Cloud Data Centers—A Survey of Problem Models and Optimization Algorithms},
year = {2015},
issue_date = {September 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2797211},
doi = {10.1145/2797211},
abstract = {Data centers in public, private, and hybrid cloud settings make it possible to provision virtual machines (VMs) with unprecedented flexibility. However, purchasing, operating, and maintaining the underlying physical resources incurs significant monetary costs and environmental impact. Therefore, cloud providers must optimize the use of physical resources by a careful allocation of VMs to hosts, continuously balancing between the conflicting requirements on performance and operational costs. In recent years, several algorithms have been proposed for this important optimization problem. Unfortunately, the proposed approaches are hardly comparable because of subtle differences in the used problem models. This article surveys the used problem formulations and optimization algorithms, highlighting their strengths and limitations, and pointing out areas that need further research.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {11},
numpages = {34},
keywords = {live migration, Cloud computing, virtual machine, VM consolidation, data center, VM placement, green computing}
}

@article{10.1145/2693843,
author = {Pejovic, Veljko and Musolesi, Mirco},
title = {Anticipatory Mobile Computing: A Survey of the State of the Art and Research Challenges},
year = {2015},
issue_date = {April 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2693843},
doi = {10.1145/2693843},
abstract = {Today’s mobile phones are far from the mere communication devices they were 10 years ago. Equipped with sophisticated sensors and advanced computing hardware, phones can be used to infer users’ location, activity, social setting, and more. As devices become increasingly intelligent, their capabilities evolve beyond inferring context to predicting it, and then reasoning and acting upon the predicted context. This article provides an overview of the current state of the art in mobile sensing and context prediction paving the way for full-fledged anticipatory mobile computing. We present a survey of phenomena that mobile phones can infer and predict, and offer a description of machine learning techniques used for such predictions. We then discuss proactive decision making and decision delivery via the user-device feedback loop. Finally, we discuss the challenges and opportunities of anticipatory mobile computing.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {47},
numpages = {29},
keywords = {Anticipatory computing, context-aware systems, mobile sensing}
}

@article{10.1145/2963147,
author = {Xavier, Emerson M. A. and Ariza-L\'{o}pez, Francisco J. and Ure\~{n}a-C\'{a}mara, Manuel A.},
title = {A Survey of Measures and Methods for Matching Geospatial Vector Datasets},
year = {2016},
issue_date = {November 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2963147},
doi = {10.1145/2963147},
abstract = {The field of Geographical Information Systems (GIS) has experienced a rapid and ongoing growth of available sources for geospatial data. This growth has demanded more data integration in order to explore the benefits of these data further. However, many data providers implies many points of view for the same phenomena: geospatial features. We need sophisticated procedures aiming to find the correspondences between two vector datasets, a process named geospatial data matching. Similarity measures are key-tools for matching methods, so it is interesting to review these concepts together. This article provides a survey of 30 years of research into the measures and methods facing geospatial data matching. Our survey presents related work and develops a common taxonomy that permits us to compare measures and methods. This study points out relevant issues that may help to discover the potential of these approaches in many applications, like data integration, conflation, quality evaluation, and data management.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {39},
numpages = {34},
keywords = {geometric algorithms, Spatial data integration, map conflation}
}

@article{10.1145/3309551,
author = {Wang, Erwei and Davis, James J. and Zhao, Ruizhe and Ng, Ho-Cheung and Niu, Xinyu and Luk, Wayne and Cheung, Peter Y. K. and Constantinides, George A.},
title = {Deep Neural Network Approximation for Custom Hardware: Where We've Been, Where We're Going},
year = {2019},
issue_date = {May 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3309551},
doi = {10.1145/3309551},
abstract = {Deep neural networks have proven to be particularly effective in visual and audio recognition tasks. Existing models tend to be computationally expensive and memory intensive, however, and so methods for hardware-oriented approximation have become a hot topic. Research has shown that custom hardware-based neural network accelerators can surpass their general-purpose processor equivalents in terms of both throughput and energy efficiency. Application-tailored accelerators, when co-designed with approximation-based network training methods, transform large, dense, and computationally expensive networks into small, sparse, and hardware-efficient alternatives, increasing the feasibility of network deployment. In this article, we provide a comprehensive evaluation of approximation methods for high-performance network inference along with in-depth discussion of their effectiveness for custom hardware implementation. We also include proposals for future research based on a thorough analysis of current trends. This article represents the first survey providing detailed comparisons of custom hardware accelerators featuring approximation for both convolutional and recurrent neural networks, through which we hope to inspire exciting new developments in the field.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {40},
numpages = {39},
keywords = {approximation methods, ASICs, recurrent neural networks, convolutional neural networks, FPGAs}
}

@article{10.1145/1978802.1978813,
author = {Skopal, Tom\'{a}\v{s} and Bustos, Benjamin},
title = {On Nonmetric Similarity Search Problems in Complex Domains},
year = {2011},
issue_date = {October 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/1978802.1978813},
doi = {10.1145/1978802.1978813},
abstract = {The task of similarity search is widely used in various areas of computing, including multimedia databases, data mining, bioinformatics, social networks, etc. In fact, retrieval of semantically unstructured data entities requires a form of aggregated qualification that selects entities relevant to a query. A popular type of such a mechanism is similarity querying. For a long time, the database-oriented applications of similarity search employed the definition of similarity restricted to metric distances. Due to its topological properties, metric similarity can be effectively used to index a database which can then be queried efficiently by so-called metric access methods. However, together with the increasing complexity of data entities across various domains, in recent years there appeared many similarities that were not metrics—we call them nonmetric similarity functions. In this article we survey domains employing nonmetric functions for effective similarity search, and methods for efficient nonmetric similarity search. First, we show that the ongoing research in many of these domains requires complex representations of data entities. Simultaneously, such complex representations allow us to model also complex and computationally expensive similarity functions (often represented by various matching algorithms). However, the more complex similarity function one develops, the more likely it will be a nonmetric. Second, we review state-of-the-art techniques for efficient (fast) nonmetric similarity search, concerning both exact and approximate search. Finally, we discuss some open problems and possible future research trends.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {34},
numpages = {50},
keywords = {approximate and exact search, similarity measuring, Similarity retrieval, nonmetric distances}
}

@article{10.1145/2501654.2501669,
author = {Shaul, Levi and Tauber, Doron},
title = {Critical Success Factors in Enterprise Resource Planning Systems: Review of the Last Decade},
year = {2013},
issue_date = {August 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2501654.2501669},
doi = {10.1145/2501654.2501669},
abstract = {Organizations perceive ERP as a vital tool for organizational competition as it integrates dispersed organizational systems and enables flawless transactions and production. This review examines studies investigating Critical Success Factors (CSFs) in implementing Enterprise Resource Planning (ERP) systems. Keywords relating to the theme of this study were defined and used to search known Web engines and journal databases for studies on both implementing ERP systems per se and integrating ERP systems with other well- known systems (e.g., SCM, CRM) whose importance to business organizations and academia is acknowledged to work in a complementary fashion. A total of 341 articles were reviewed to address three main goals. This study structures previous research by presenting a comprehensive taxonomy of CSFs in the area of ERP. Second, it maps studies, identified through an exhaustive and comprehensive literature review, to different dimensions and facets of ERP system implementation. Third, it presents studies investigating CSFs in terms of a specific ERP lifecycle phase and across the entire ERP life cycle. This study not only reviews articles in which an ERP system is the sole or primary field of research, but also articles that refer to an integration of ERP systems and other popular systems (e.g., SCM, CRM). Finally it provides a comprehensive bibliography of the articles published during this period that can serve as a guide for future research.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {55},
numpages = {39},
keywords = {literature review, Critical success factors, ERP, enterprise resource planning, information systems, CSFs}
}

@article{10.1145/3284387,
author = {Wang, Jianyu and Pan, Jianli and Esposito, Flavio and Calyam, Prasad and Yang, Zhicheng and Mohapatra, Prasant},
title = {Edge Cloud Offloading Algorithms: Issues, Methods, and Perspectives},
year = {2019},
issue_date = {February 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3284387},
doi = {10.1145/3284387},
abstract = {Mobile devices supporting the “Internet of Things” often have limited capabilities in computation, battery energy, and storage space, especially to support resource-intensive applications involving virtual reality, augmented reality, multimedia delivery, and artificial intelligence, which could require broad bandwidth, low response latency, and large computational power. Edge cloud or edge computing is an emerging topic and a technology that can tackle the deficiencies of the currently centralized-only cloud computing model and move the computation and storage resources closer to the devices in support of the above-mentioned applications. To make this happen, efficient coordination mechanisms and “offloading” algorithms are needed to allow mobile devices and the edge cloud to work together smoothly. In this survey article, we investigate the key issues, methods, and various state-of-the-art efforts related to the offloading problem. We adopt a new characterizing model to study the whole process of offloading from mobile devices to the edge cloud. Through comprehensive discussions, we aim to draw an overall “big picture” on the existing efforts and research directions. Our study also indicates that the offloading algorithms in the edge cloud have demonstrated profound potentials for future technology and application development.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {2},
numpages = {23},
keywords = {offloading algorithms, edge computing, Internet of Things, mobile edge computing, mathematical models}
}

@article{10.1145/3385896,
author = {Macedo, Ricardo and Paulo, Jo\~{a}o and Pereira, Jos\'{e} and Bessani, Alysson},
title = {A Survey and Classification of Software-Defined Storage Systems},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3385896},
doi = {10.1145/3385896},
abstract = {The exponential growth of digital information is imposing increasing scale and efficiency demands on modern storage infrastructures. As infrastructure complexity increases, so does the difficulty in ensuring quality of service, maintainability, and resource fairness, raising unprecedented performance, scalability, and programmability challenges. Software-Defined Storage (SDS) addresses these challenges by cleanly disentangling control and data flows, easing management, and improving control functionality of conventional storage systems. Despite its momentum in the research community, many aspects of the paradigm are still unclear, undefined, and unexplored, leading to misunderstandings that hamper the research and development of novel SDS technologies. In this article, we present an in-depth study of SDS systems, providing a thorough description and categorization of each plane of functionality. Further, we propose a taxonomy and classification of existing SDS solutions according to different criteria. Finally, we provide key insights about the paradigm and discuss potential future research directions for the field.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {48},
numpages = {38},
keywords = {storage infrastructures, Software-defined storage, distributed storage}
}

@article{10.1145/3280989,
author = {Tavara, Shirin},
title = {Parallel Computing of Support Vector Machines: A Survey},
year = {2019},
issue_date = {February 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3280989},
doi = {10.1145/3280989},
abstract = {The immense amount of data created by digitalization requires parallel computing for machine-learning methods. While there are many parallel implementations for support vector machines (SVMs), there is no clear suggestion for every application scenario. Many factor—including optimization algorithm, problem size and dimension, kernel function, parallel programming stack, and hardware architecture—impact the efficiency of implementations. It is up to the user to balance trade-offs, particularly between computation time and classification accuracy. In this survey, we review the state-of-the-art implementations of SVMs, their pros and cons, and suggest possible avenues for future research.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {123},
numpages = {38},
keywords = {CPU parallelism, speedup, data movement, GPU parallelism, primal optimization, decomposition, Dual optimization}
}

@article{10.1145/2963143,
author = {Khalifa, Shadi and Elshater, Yehia and Sundaravarathan, Kiran and Bhat, Aparna and Martin, Patrick and Imam, Fahim and Rope, Dan and Mcroberts, Mike and Statchuk, Craig},
title = {The Six Pillars for Building Big Data Analytics Ecosystems},
year = {2016},
issue_date = {November 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2963143},
doi = {10.1145/2963143},
abstract = {With almost everything now online, organizations look at the Big Data collected to gain insights for improving their services. In the analytics process, derivation of such insights requires experimenting-with and integrating different analytics techniques, while handling the Big Data high arrival velocity and large volumes. Existing solutions cover bits-and-pieces of the analytics process, leaving it to organizations to assemble their own ecosystem or buy an off-the-shelf ecosystem that can have unnecessary components to them. We build on this point by dividing the Big Data Analytics problem into six main pillars. We characterize and show examples of solutions designed for each of these pillars. We then integrate these six pillars into a taxonomy to provide an overview of the possible state-of-the-art analytics ecosystems. In the process, we highlight a number of ecosystems to meet organizations different needs. Finally, we identify possible areas of research for building future Big Data Analytics Ecosystems.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {33},
numpages = {36},
keywords = {Orchestration, consumable analytics, analytics talent gap}
}

@article{10.1145/3155897,
author = {Al-Garadi, Mohammed Ali and Varathan, Kasturi Dewi and Ravana, Sri Devi and Ahmed, Ejaz and Mujtaba, Ghulam and Khan, Muhammad Usman Shahid and Khan, Samee U.},
title = {Analysis of Online Social Network Connections for Identification of Influential Users: Survey and Open Research Issues},
year = {2018},
issue_date = {April 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3155897},
doi = {10.1145/3155897},
abstract = {Online social networks (OSNs) are structures that help users to interact, exchange, and propagate new ideas. The identification of the influential users in OSNs is a significant process for accelerating the propagation of information that includes marketing applications or hindering the dissemination of unwanted contents, such as viruses, negative online behaviors, and rumors. This article presents a detailed survey of influential users’ identification algorithms and their performance evaluation approaches in OSNs. The survey covers recent techniques, applications, and open research issues on analysis of OSN connections for identification of influential users.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {16},
numpages = {37},
keywords = {identification algorithms, OSNs, Influential users, social media, big data, complex networks}
}

@article{10.1145/2431211.2431214,
author = {Attene, Marco and Campen, Marcel and Kobbelt, Leif},
title = {Polygon Mesh Repairing: An Application Perspective},
year = {2013},
issue_date = {February 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2431211.2431214},
doi = {10.1145/2431211.2431214},
abstract = {Nowadays, digital 3D models are in widespread and ubiquitous use, and each specific application dealing with 3D geometry has its own quality requirements that restrict the class of acceptable and supported models. This article analyzes typical defects that make a 3D model unsuitable for key application contexts, and surveys existing algorithms that process, repair, and improve its structure, geometry, and topology to make it appropriate to case-by-case requirements.The analysis is focused on polygon meshes, which constitute by far the most common 3D object representation. In particular, this article provides a structured overview of mesh repairing techniques from the point of view of the application context. Different types of mesh defects are classified according to the upstream application that produced the mesh, whereas mesh quality requirements are grouped by representative sets of downstream applications where the mesh is to be used. The numerous mesh repair methods that have been proposed during the last two decades are analyzed and classified in terms of their capabilities, properties, and guarantees. Based on these classifications, guidelines can be derived to support the identification of repairing algorithms best-suited to bridge the compatibility gap between the quality provided by the upstream process and the quality required by the downstream applications in a given geometry processing scenario.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {15},
numpages = {33},
keywords = {languages, fixing, systems, geometry, topology, Boundary representation, geometric algorithms}
}

@article{10.1145/2996451,
author = {Boukerche, Azzedine and Magnano, Alexander and Aljeri, Noura},
title = {Mobile IP Handover for Vehicular Networks: Methods, Models, and Classifications},
year = {2017},
issue_date = {February 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2996451},
doi = {10.1145/2996451},
abstract = {The popularity and development of wireless devices has led to a demand for widespread high-speed Internet access, including access for vehicles and other modes of high-speed transportation. The current widely deployed method for providing Internet Protocol (IP) services to mobile devices is the mobile IP. This includes a handover process for a mobile device to maintain its IP session while it switches between points of access. However, the mobile IP handover causes performance degradation due to its disruptive latency and high packet drop rate. This is largely problematic for vehicles, as they will be forced to transition between access points more frequently due to their higher speeds and frequent topological changes in vehicular networks. In this article, we discuss the different mobile IP handover solutions found within related literature and their potential for resolving issues pertinent to vehicular networks. First, we provide an overview of the mobile IP handover and its problematic components. This is followed by categorization and comparison between different mobile IP handover solutions, with an analysis of their benefits and drawbacks.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {73},
numpages = {34},
keywords = {Wireless, predictive handover, handover, mobile IP, rapid mobility, fast handover, hierarchical handover, proxy handover, prediction algorithm}
}

@article{10.1145/3122848,
author = {Boer, Frank De and Serbanescu, Vlad and H\"{a}hnle, Reiner and Henrio, Ludovic and Rochas, Justine and Din, Crystal Chang and Johnsen, Einar Broch and Sirjani, Marjan and Khamespanah, Ehsan and Fernandez-Reyes, Kiko and Yang, Albert Mingkun},
title = {A Survey of Active Object Languages},
year = {2017},
issue_date = {November 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3122848},
doi = {10.1145/3122848},
abstract = {To program parallel systems efficiently and easily, a wide range of programming models have been proposed, each with different choices concerning synchronization and communication between parallel entities. Among them, the actor model is based on loosely coupled parallel entities that communicate by means of asynchronous messages and mailboxes. Some actor languages provide a strong integration with object-oriented concepts; these are often called active object languages. This article reviews four major actor and active object languages and compares them according to carefully chosen dimensions that cover central aspects of the programming paradigms and their implementation.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {76},
numpages = {39},
keywords = {active objects, concurrency, actors, Programming languages, distributed systems}
}

@article{10.1145/3391196,
author = {Salaht, Farah A\"{\i}t and Desprez, Fr\'{e}d\'{e}ric and Lebre, Adrien},
title = {An Overview of Service Placement Problem in Fog and Edge Computing},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3391196},
doi = {10.1145/3391196},
abstract = {To support the large and various applications generated by the Internet of Things (IoT), Fog Computing was introduced to complement the Cloud Computing and offer Cloud-like services at the edge of the network with low latency and real-time responses. Large-scale, geographical distribution, and heterogeneity of edge computational nodes make service placement in such infrastructure a challenging issue. Diversity of user expectations and IoT devices characteristics also complicate the deployment problem. This article presents a survey of current research conducted on Service Placement Problem (SPP) in the Fog/Edge Computing. Based on a new classification scheme, a categorization of current proposals is given and identified issues and challenges are discussed.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {65},
numpages = {35},
keywords = {edge computing, deployment taxonomy, Fog computing, classification, optimization, service placement}
}

@article{10.1145/2501654.2501658,
author = {Liu, Jiajun and Huang, Zi and Cai, Hongyun and Shen, Heng Tao and Ngo, Chong Wah and Wang, Wei},
title = {Near-Duplicate Video Retrieval: Current Research and Future Trends},
year = {2013},
issue_date = {August 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2501654.2501658},
doi = {10.1145/2501654.2501658},
abstract = {The exponential growth of online videos, along with increasing user involvement in video-related activities, has been observed as a constant phenomenon during the last decade. User's time spent on video capturing, editing, uploading, searching, and viewing has boosted to an unprecedented level. The massive publishing and sharing of videos has given rise to the existence of an already large amount of near-duplicate content. This imposes urgent demands on near-duplicate video retrieval as a key role in novel tasks such as video search, video copyright protection, video recommendation, and many more. Driven by its significance, near-duplicate video retrieval has recently attracted a lot of attention. As discovered in recent works, latest improvements and progress in near-duplicate video retrieval, as well as related topics including low-level feature extraction, signature generation, and high-dimensional indexing, are employed to assist the process.As we survey the works in near-duplicate video retrieval, we comparatively investigate existing variants of the definition of near-duplicate video, describe a generic framework, summarize state-of-the-art practices, and explore the emerging trends in this research topic.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {44},
numpages = {23},
keywords = {Near-duplicate video, indexing, video retrieval}
}

@article{10.1145/3241741,
author = {Smirnova, Alisa and Cudr\'{e}-Mauroux, Philippe},
title = {Relation Extraction Using Distant Supervision: A Survey},
year = {2018},
issue_date = {January 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3241741},
doi = {10.1145/3241741},
abstract = {Relation extraction is a subtask of information extraction where semantic relationships are extracted from natural language text and then classified. In essence, it allows us to acquire structured knowledge from unstructured text. In this article, we present a survey of relation extraction methods that leverage pre-existing structured or semi-structured data to guide the extraction process. We introduce a taxonomy of existing methods and describe distant supervision approaches in detail. We describe, in addition, the evaluation methodologies and the datasets commonly used for quality assessment. Finally, we give a high-level outlook on the field, highlighting open problems as well as the most promising research directions.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {106},
numpages = {35},
keywords = {distant supervision, Relation extraction, knowledge graph}
}

@article{10.1145/2522968.2522974,
author = {Esposito, Flavio and Matta, Ibrahim and Ishakian, Vatche},
title = {Slice Embedding Solutions for Distributed Service Architectures},
year = {2013},
issue_date = {October 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2522968.2522974},
doi = {10.1145/2522968.2522974},
abstract = {Network virtualization provides a novel approach to running multiple concurrent virtual networks over a common physical network infrastructure. From a research perspective, this enables the networking community to concurrently experiment with new Internet architectures and protocols. From a market perspective, on the other hand, this paradigm is appealing as it enables infrastructure service providers to experiment with new business models that range from leasing virtual slices of their infrastructure to hosting multiple concurrent network services.In this article, we present the slice embedding problem and recent developments in the area. A slice is a set of virtual instances spanning a set of physical resources. The embedding problem consists of three main tasks: (1) resource discovery, which involves monitoring the state of the physical resources, (2) virtual network mapping, which involves matching users' requests with the available resources, and (3) allocation, which involves assigning the resources that match the users' requests.We also outline how these three tasks are tightly coupled, and how there exists a wide spectrum of solutions that either solve a particular task or jointly solve multiple tasks along with the interactions among them. To dissect the space of solutions, we introduce three main classification criteria, namely: (1) the type of constraints imposed by the user, (2) the type of dynamics considered in the embedding process, and (3) the allocation strategy adopted. Finally, we conclude with a few interesting research directions.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {6},
numpages = {29},
keywords = {optimization, virtual network embedding, resource allocation, resource discovery, Network virtualization, slice embedding}
}

@article{10.1145/2828993,
author = {Shilkrot, Roy and Huber, Jochen and Steimle, J\"{u}rgen and Nanayakkara, Suranga and Maes, Pattie},
title = {Digital Digits: A Comprehensive Survey of Finger Augmentation Devices},
year = {2015},
issue_date = {November 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2828993},
doi = {10.1145/2828993},
abstract = {Finger augmentation devices, those that are worn and operated by fingers, are a rapidly growing field in the human--computer interaction domain. This field is rooted in ancient history; however, still the academic research arena is booming with new finger augmentations every year. This article strives to survey the entire body of work on finger augmentation devices and uncover the trends and the underexplored territories. We contribute a methodical classification of over 150 pieces of academic, product, patent, and concept work. We discuss the underlying sensing and feedback modalities and provide a definition, taxonomy, and reference for researchers of finger augmentation devices.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {30},
numpages = {29},
keywords = {finger augmentation, human augmentation, Wearable computing, assistive technology, input methodologies}
}

@article{10.1145/3397495,
author = {Weisenburger, Pascal and Wirth, Johannes and Salvaneschi, Guido},
title = {A Survey of Multitier Programming},
year = {2020},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3397495},
doi = {10.1145/3397495},
abstract = {Multitier programming deals with developing the components that pertain to different tiers in the system (e.g., client and server), mixing them in the same compilation unit. In this paradigm, the code for different tiers is then either generated at run time or it results from the compiler splitting the codebase into components that belong to different tiers based on user annotations, static analysis, types, or a combination of these. In the Web context, multitier languages aim at reducing the distinction between client and server code, by translating the code that is to be executed on the clients to JavaScript or by executing JavaScript on the server, too. Ultimately, the goal of the multitier approach is to improve program comprehension, simplify maintenance and enable formal reasoning about the properties of the whole distributed application.A number of multitier research languages have been proposed over the last decade, which support various degrees of multitier programming and explore different design tradeoffs. In this article, we provide an overview of the existing solutions, discuss their positioning in the design space, and outline open research problems.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {81},
numpages = {35},
keywords = {distributed programming, tierless languages, Multitier languages}
}

@article{10.1145/3234149,
author = {Doherty, Kevin and Doherty, Gavin},
title = {Engagement in HCI: Conception, Theory and Measurement},
year = {2018},
issue_date = {January 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3234149},
doi = {10.1145/3234149},
abstract = {Engaging users is a priority for designers of products and services of every kind. The need to understand users’ experiences has motivated a focus on user engagement across computer science. However, to date, there has been limited review of how Human--Computer Interaction and computer science research interprets and employs the concept. Questions persist concerning its conception, abstraction, and measurement. This article presents a systematic review of engagement spanning a corpus of 351 articles and 102 definitions. We map the current state of engagement research, including the diverse interpretation, theory, and measurement of the concept. We describe the ecology of engagement and strategies for the design of engaging experiences, discuss the value of the concept and its relationship to other terms, and present a set of guidelines and opportunities for future research.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {99},
numpages = {39},
keywords = {measurement, Engagement, theory, user experience, HCI, design}
}

@article{10.1145/2976743,
author = {Fang, Yan and Yashin, Victor V. and Jennings, Brandon B. and Chiarulli, Donald M. and Levitan, Steven P.},
title = {A Simplified Phase Model for Simulation of Oscillator-Based Computing Systems},
year = {2016},
issue_date = {March 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {1550-4832},
url = {https://doi.org/10.1145/2976743},
doi = {10.1145/2976743},
abstract = {Building oscillator-based computing systems with emerging nano-device technologies has become a promising solution for unconventional computing tasks like computer vision and pattern recognition. However, simulation and analysis of these computing systems is both time and compute intensive due to the nonlinearity of new devices and the complex behavior of coupled oscillators. In order to speed up the simulation of coupled oscillator systems, we propose a simplified phase model to perform phase and frequency synchronization prediction based on a synthesis of earlier models. Our model can predict the frequency-locking behavior with several orders of magnitude speedup compared to direct evaluation, enabling the effective and efficient simulation of the large numbers of oscillators required for practical computing systems. We demonstrate the oscillator-based computing paradigm with three applications, pattern matching, convolution, and image segmentation. The simulation with these models are respectively sped up by factors of 780, 300, and 1120 in our tests.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = dec,
articleno = {14},
numpages = {20},
keywords = {Non-Boolean computing, phase model, synchronization, oscillator-based computing, coupled oscillators}
}

@article{10.1145/3386867,
author = {Seaborn, Katie and Miyake, Norihisa P. and Pennefather, Peter and Otake-Matsuura, Mihoko},
title = {Voice in Human–Agent Interaction: A Survey},
year = {2021},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3386867},
doi = {10.1145/3386867},
abstract = {Social robots, conversational agents, voice assistants, and other embodied AI are increasingly a feature of everyday life. What connects these various types of intelligent agents is their ability to interact with people through voice. Voice is becoming an essential modality of embodiment, communication, and interaction between computer-based agents and end-users. This survey presents a meta-synthesis on agent voice in the design and experience of agents from a human-centered perspective: voice-based human–agent interaction (vHAI). Findings emphasize the social role of voice in HAI as well as circumscribe a relationship between agent voice and body, corresponding to human models of social psychology and cognition. Additionally, changes in perceptions of and reactions to agent voice over time reveals a generational shift coinciding with the commercial proliferation of mobile voice assistants. The main contributions of this work are a vHAI classification framework for voice across various agent forms, contexts, and user groups, a critical analysis grounded in key theories, and an identification of future directions for the oncoming wave of vocal machines.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {81},
numpages = {43},
keywords = {human--agent interaction (HAI), conversational agents, human--robot interaction (HRI), computer voice, voice assistants, embodied agents, human--computer interaction (HCI), voice-user interface (VUI), Computer agent, human--machine communication (HMC), vocalics, synthetic speech, embodied AI, robots, voice perception}
}

@article{10.1145/3419633,
author = {Tolmeijer, Suzanne and Kneer, Markus and Sarasua, Cristina and Christen, Markus and Bernstein, Abraham},
title = {Implementations in Machine Ethics: A Survey},
year = {2021},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3419633},
doi = {10.1145/3419633},
abstract = {Increasingly complex and autonomous systems require machine ethics to maximize the benefits and minimize the risks to society arising from the new technology. It is challenging to decide which type of ethical theory to employ and how to implement it effectively. This survey provides a threefold contribution. First, it introduces a trimorphic taxonomy to analyze machine ethics implementations with respect to their object (ethical theories), as well as their nontechnical and technical aspects. Second, an exhaustive selection and description of relevant works is presented. Third, applying the new taxonomy to the selected works, dominant research patterns, and lessons for the field are identified, and future directions for research are suggested.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {132},
numpages = {38},
keywords = {Machine ethics, artificial morality}
}

@article{10.1145/3347711,
author = {Lorena, Ana C. and Garcia, Lu\'{\i}s P. F. and Lehmann, Jens and Souto, Marcilio C. P. and Ho, Tin Kam},
title = {How Complex Is Your Classification Problem? A Survey on Measuring Classification Complexity},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3347711},
doi = {10.1145/3347711},
abstract = {Characteristics extracted from the training datasets of classification problems have proven to be effective predictors in a number of meta-analyses. Among them, measures of classification complexity can be used to estimate the difficulty in separating the data points into their expected classes. Descriptors of the spatial distribution of the data and estimates of the shape and size of the decision boundary are among the known measures for this characterization. This information can support the formulation of new data-driven pre-processing and pattern recognition techniques, which can in turn be focused on challenges highlighted by such characteristics of the problems. This article surveys and analyzes measures that can be extracted from the training datasets to characterize the complexity of the respective classification problems. Their use in recent literature is also reviewed and discussed, allowing to prospect opportunities for future work in the area. Finally, descriptions are given on an R package named Extended Complexity Library (ECoL) that implements a set of complexity measures and is made publicly available.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {107},
numpages = {34},
keywords = {classification, complexity measures, Supervised machine learning}
}

@article{10.1145/3402179,
author = {Uprety, Sagar and Gkoumas, Dimitris and Song, Dawei},
title = {A Survey of Quantum Theory Inspired Approaches to Information Retrieval},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3402179},
doi = {10.1145/3402179},
abstract = {Since 2004, researchers have been using the mathematical framework of quantum theory in information retrieval (IR). Quantum theory offers a generalized probability and logic framework. Such a framework has been shown to be capable of unifying the representation, ranking, and user cognitive aspects of IR, and helpful in developing more dynamic, adaptive, and context-aware IR systems. Although quantum-inspired IR is still a growing area, a wide array of work in different aspects of IR has been done and produced promising results. This article presents a survey of the research done in this area, aiming to show the landscape of the field and draw a road map of future directions.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {98},
numpages = {39},
keywords = {quantum theory, quantum-inspired models, Information retrieval}
}

@article{10.1145/2431211.2431223,
author = {Suomela, Jukka},
title = {Survey of Local Algorithms},
year = {2013},
issue_date = {February 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2431211.2431223},
doi = {10.1145/2431211.2431223},
abstract = {A local algorithm is a distributed algorithm that runs in constant time, independently of the size of the network. Being highly scalable and fault tolerant, such algorithms are ideal in the operation of large-scale distributed systems. Furthermore, even though the model of local algorithms is very limited, in recent years we have seen many positive results for nontrivial problems. This work surveys the state-of-the-art in the field, covering impossibility results, deterministic local algorithms, randomized local algorithms, and local algorithms for geometric graphs.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {24},
numpages = {40},
keywords = {Local algorithms}
}

@article{10.1145/3145813,
author = {Mertz, Jhonny and Nunes, Ingrid},
title = {Understanding Application-Level Caching in Web Applications: A Comprehensive Introduction and Survey of State-of-the-Art Approaches},
year = {2017},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3145813},
doi = {10.1145/3145813},
abstract = {A new form of caching, namely application-level caching, has been recently employed in web applications to improve their performance and increase scalability. It consists of the insertion of caching logic into the application base code to temporarily store processed content in memory and then decrease the response time of web requests by reusing this content. However, caching at this level demands knowledge of the domain and application specificities to achieve caching benefits, given that this information supports decisions such as what and when to cache content. Developers thus must manually manage the cache, possibly with the help of existing libraries and frameworks. Given the increasing popularity of application-level caching, we thus provide a survey of approaches proposed in this context. We provide a comprehensive introduction to web caching and application-level caching, and present state-of-the-art work on designing, implementing, and managing application-level caching. Our focus is not only on static solutions but also approaches that adaptively adjust caching solutions to avoid the gradual performance decay that caching can suffer over time. This survey can be used as a start point for researchers and developers, who aim to improve application-level caching or need guidance in designing application-level caching solutions, possibly with humans out-of-the-loop.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {98},
numpages = {34},
keywords = {web caching, adaptation, Application-level caching, web application, self-adaptive systems}
}

@article{10.1145/3009906,
author = {Wiriyathammabhum, Peratham and Summers-Stay, Douglas and Ferm\"{u}ller, Cornelia and Aloimonos, Yiannis},
title = {Computer Vision and Natural Language Processing: Recent Approaches in Multimedia and Robotics},
year = {2016},
issue_date = {February 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3009906},
doi = {10.1145/3009906},
abstract = {Integrating computer vision and natural language processing is a novel interdisciplinary field that has received a lot of attention recently. In this survey, we provide a comprehensive introduction of the integration of computer vision and natural language processing in multimedia and robotics applications with more than 200 key references. The tasks that we survey include visual attributes, image captioning, video captioning, visual question answering, visual retrieval, human-robot interaction, robotic actions, and robot navigation. We also emphasize strategies to integrate computer vision and natural language processing models as a unified theme of distributional semantics. We make an analog of distributional semantics in computer vision and natural language processing as image embedding and word embedding, respectively. We also present a unified view for the field and propose possible future directions.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {71},
numpages = {44},
keywords = {multimedia, semantic parsing, imitation learning, Language and vision, word2vec, symbol grounding, distributional semantics, robotics, word embedding, image embedding, survey, natural language processing, computer vision, lexical semantics, visual attribute, image captioning}
}

@article{10.1145/2931098,
author = {Kanvar, Vini and Khedker, Uday P.},
title = {Heap Abstractions for Static Analysis},
year = {2016},
issue_date = {November 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2931098},
doi = {10.1145/2931098},
abstract = {Heap data is potentially unbounded and seemingly arbitrary. Hence, unlike stack and static data, heap data cannot be abstracted in terms of a fixed set of program variables. This makes it an interesting topic of study and there is an abundance of literature employing heap abstractions. Although most studies have addressed similar concerns, insights gained in one description of heap abstraction may not directly carry over to some other description.In our search of a unified theme, we view heap abstraction as consisting of two steps: (a) heap modelling, which is the process of representing a heap memory (i.e., an unbounded set of concrete locations) as a heap model (i.e., an unbounded set of abstract locations), and (b) summarization, which is the process of bounding the heap model by merging multiple abstract locations into summary locations. We classify the heap models as storeless, store based, and hybrid. We describe various summarization techniques based on k-limiting, allocation sites, patterns, variables, other generic instrumentation predicates, and higher-order logics. This approach allows us to compare the insights of a large number of seemingly dissimilar heap abstractions and also paves the way for creating new abstractions by mix and match of models and summarization techniques.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {29},
numpages = {47},
keywords = {summarization, heap, store based, shape analysis, storeless, static analysis, Abstraction, pointers}
}

@article{10.1145/3178454,
author = {Potok, Thomas E. and Schuman, Catherine and Young, Steven and Patton, Robert and Spedalieri, Federico and Liu, Jeremy and Yao, Ke-Thia and Rose, Garrett and Chakma, Gangotree},
title = {A Study of Complex Deep Learning Networks on High-Performance, Neuromorphic, and Quantum Computers},
year = {2018},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {1550-4832},
url = {https://doi.org/10.1145/3178454},
doi = {10.1145/3178454},
abstract = {Current deep learning approaches have been very successful using convolutional neural networks trained on large graphical-processing-unit-based computers. Three limitations of this approach are that (1) they are based on a simple layered network topology, i.e., highly connected layers, without intra-layer connections; (2) the networks are manually configured to achieve optimal results, and (3) the implementation of the network model is expensive in both cost and power. In this article, we evaluate deep learning models using three different computing architectures to address these problems: quantum computing to train complex topologies, high performance computing to automatically determine network topology, and neuromorphic computing for a low-power hardware implementation. We use the MNIST dataset for our experiment, due to input size limitations of current quantum computers. Our results show the feasibility of using the three architectures in tandem to address the above deep learning limitations. We show that a quantum computer can find high quality values of intra-layer connection weights in a tractable time as the complexity of the network increases, a high performance computer can find optimal layer-based topologies, and a neuromorphic computer can represent the complex topology and weights derived from the other architectures in low power memristive hardware.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = jul,
articleno = {19},
numpages = {21},
keywords = {neuromorphic computing, Deep learning, quantum computing, high-performance computing}
}

@article{10.1145/3399709,
author = {Denning, Peter J.},
title = {Working Set Analytics},
year = {2021},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3399709},
doi = {10.1145/3399709},
abstract = {The working set model for program behavior was invented in 1965. It has stood the test of time in virtual memory management for over 50 years. It is considered the ideal for managing memory in operating systems and caches. Its superior performance was based on the principle of locality, which was discovered at the same time; locality is the observed tendency of programs to use distinct subsets of their pages over extended periods of time. This tutorial traces the development of working set theory from its origins to the present day. We will discuss the principle of locality and its experimental verification. We will show why working set memory management resists thrashing and generates near-optimal system throughput. We will present the powerful, linear-time algorithms for computing working set statistics and applying them to the design of memory systems. We will debunk several myths about locality and the performance of memory systems. We will conclude with a discussion of the application of the working set model in parallel systems, modern shared CPU caches, network edge caches, and inventory and logistics management.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {113},
numpages = {36},
keywords = {working set model, optimal paging, locality, locality principle, program behavior, paging policy, virtual memory, memory management, thrashing, Working set, multiprogramming, cache}
}

@article{10.1145/2576868,
author = {Bielza, Concha and Larra\~{n}aga, Pedro},
title = {Discrete Bayesian Network Classifiers: A Survey},
year = {2014},
issue_date = {July 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2576868},
doi = {10.1145/2576868},
abstract = {We have had to wait over 30 years since the naive Bayes model was first introduced in 1960 for the so-called Bayesian network classifiers to resurge. Based on Bayesian networks, these classifiers have many strengths, like model interpretability, accommodation to complex data and classification problem settings, existence of efficient algorithms for learning and classification tasks, and successful applicability in real-world problems. In this article, we survey the whole set of discrete Bayesian network classifiers devised to date, organized in increasing order of structure complexity: naive Bayes, selective naive Bayes, seminaive Bayes, one-dependence Bayesian classifiers, k-dependence Bayesian classifiers, Bayesian network-augmented naive Bayes, Markov blanket-based Bayesian classifier, unrestricted Bayesian classifiers, and Bayesian multinets. Issues of feature subset selection and generative and discriminative structure and parameter learning are also covered.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {5},
numpages = {43},
keywords = {naive Bayes, feature subset selection, generative and discriminative classifiers, Bayesian multinets, Bayesian network, Supervised classification, Markov blanket}
}


