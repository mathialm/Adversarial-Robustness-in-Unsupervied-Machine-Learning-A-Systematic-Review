% Encoding: UTF-8

@Article{9127546,
  author   = {Long, Huan and Wu, Zhi and Fang, Chen and Gu, Wei and Wei, Xinchi and Zhan, Huiyu},
  journal  = {Journal of Modern Power Systems and Clean Energy},
  title    = {Cyber-attack Detection Strategy Based on Distribution System State Estimation},
  year     = {2020},
  issn     = {2196-5420},
  month    = {July},
  number   = {4},
  pages    = {669-678},
  volume   = {8},
  abstract = {Cyber-attacks that tamper with measurement information threaten the security of state estimation for the current distribution system. This paper proposes a cyber-attack detection strategy based on distribution system state estimation (DSSE). The uncertainty of the distribution network is represented by the interval of each state variable. A three-phase interval DSSE model is proposed to construct the interval of each state variable. An improved iterative algorithm (IIA) is developed to solve the interval DSSE model and to obtain the lower and upper bounds of the interval. A cyber-attack is detected when the value of the state variable estimated by the traditional DSSE is out of the corresponding interval determined by the interval DSSE. To validate the proposed cyber-attack detection strategy, the basic principle of the cyber-attack is studied, and its general model is formulated. The proposed cyber-attack model and detection strategy are conducted on the IEEE 33-bus and 123-bus systems. Comparative experiments of the proposed IIA, Monte Carlo simulation algorithm, and interval Gauss elimination algorithm prove the validation of the proposed method.},
  doi      = {10.35833/MPCE.2019.000216},
  groups   = {First Filtering},
  keywords = {State estimation;Mathematical model;Power systems;Current measurement;Distribution networks;Uncertainty;Voltage measurement;Cyber-attack detection;distribution network;interval state estimation;distribution system state estimation;cyber-attack model},
}

@Article{8604075,
  author   = {Zhang, Fan and Kodituwakku, Hansaka Angel Dias Edirisinghe and Hines, J. Wesley and Coble, Jamie},
  journal  = {IEEE Transactions on Industrial Informatics},
  title    = {Multilayer Data-Driven Cyber-Attack Detection System for Industrial Control Systems Based on Network, System, and Process Data},
  year     = {2019},
  issn     = {1941-0050},
  month    = {July},
  number   = {7},
  pages    = {4362-4369},
  volume   = {15},
  abstract = {The growing number of attacks against cyber-physical systems in recent years elevates the concern for cybersecurity of industrial control systems (ICSs). The current efforts of ICS cybersecurity are mainly based on firewalls, data diodes, and other methods of intrusion prevention, which may not be sufficient for growing cyber threats from motivated attackers. To enhance the cybersecurity of ICS, a cyber-attack detection system built on the concept of defense-in-depth is developed utilizing network traffic data, host system data, and measured process parameters. This attack detection system provides multiple-layer defense in order to gain the defenders precious time before unrecoverable consequences occur in the physical system. The data used for demonstrating the proposed detection system are from a real-time ICS testbed. Five attacks, including man in the middle (MITM), denial of service (DoS), data exfiltration, data tampering, and false data injection, are carried out to simulate the consequences of cyber attack and generate data for building data-driven detection models. Four classical classification models based on network data and host system data are studied, including k-nearest neighbor (KNN), decision tree, bootstrap aggregating (bagging), and random forest (RF), to provide a secondary line of defense of cyber-attack detection in the event that the intrusion prevention layer fails. Intrusion detection results suggest that KNN, bagging, and RF have low missed alarm and false alarm rates for MITM and DoS attacks, providing accurate and reliable detection of these cyber attacks. Cyber attacks that may not be detectable by monitoring network and host system data, such as command tampering and false data injection attacks by an insider, are monitored for by traditional process monitoring protocols. In the proposed detection system, an auto-associative kernel regression model is studied to strengthen early attack detection. The result shows that this approach detects physically impactful cyber attacks before significant consequences occur. The proposed multiple-layer data-driven cyber-attack detection system utilizing network, system, and process data is a promising solution for safeguarding an ICS.},
  doi      = {10.1109/TII.2019.2891261},
  groups   = {First Filtering},
  keywords = {Integrated circuits;Data models;Monitoring;Computer security;Malware;Informatics;Analytical models;Cyber-attack detection;data-driven monitoring;defense-in-depth;industrial control system (ICS)},
}

@InProceedings{9070571,
  author    = {Lee, Dongseop and Kim, Hyunjin and Ryou, Jaecheol},
  booktitle = {2020 IEEE International Conference on Big Data and Smart Computing (BigComp)},
  title     = {Poisoning Attack on Show and Tell Model and Defense Using Autoencoder in Electric Factory},
  year      = {2020},
  month     = {Feb},
  pages     = {538-541},
  abstract  = {Recently, deep neural network technology has been developed and used in various fields. The image recognition model can be used for automatic safety checks at the electric factory. However, as the deep neural network develops, the importance of security increases. A poisoning attack is one of security problems. It is an attack that breaks down by entering malicious data into the training data set of the model. This paper generates adversarial data that modulates feature values to different targets by manipulating less RGB values. Then, poisoning attacks in one of the image recognition models, the show and tell model. Then use autoencoder to defend adversarial data.},
  doi       = {10.1109/BigComp48618.2020.000-9},
  groups    = {First Filtering},
  issn      = {2375-9356},
  keywords  = {Data models;Training data;Neural networks;Toxicology;Image recognition;Dogs;Image restoration;AI, show and tell model, poisoning attack, defense, autoencoder},
}

@Article{8735819,
  author   = {Oozeer, Mohammad Irshaad and Haykin, Simon},
  journal  = {IEEE Access},
  title    = {Cognitive Dynamic System for Control and Cyber-Attack Detection in Smart Grid},
  year     = {2019},
  issn     = {2169-3536},
  pages    = {78320-78335},
  volume   = {7},
  abstract = {This paper introduces a new way of thinking that characterizes itself by uniting two entities, namely state estimation in the smart grid (SG) and cognitive dynamic system (CDS). False data injection (FDI) attacks are a family of new attacks that have been considered to be the most dangerous cyber-attack as it leads to cascaded bad decision making throughout the SG network, which can lead to severe repercussions. The conventional state estimation and bad data detection techniques, which have been applied to reduce observation errors and detect bad data in energy system state estimators, cannot detect FDI attacks. Here, we bring into play an objective-seeking system to act as the supervisor of the SG network. To this end, we propose to introduce a new metric for the SG: the entropic state. The entropic state has two purposes: 1) it provides an indication of the grid's health on a cycle-to-cycle basis and 2) it can be used to detect FDI attacks. Consequently, improving the entropic state is the goal of the supervisor. To achieve that objective, the supervisor dynamically optimizes the state estimation process by reconfiguring the weights of the sensors in the network. With optimality in mind, the CDS is the superior choice for the supervisory system. In this structure, the CDS interacts with the SG network, which is considered as the environment. Computer simulations are carried out on a 4-bus and the IEEE 14-bus systems to highlight the performance of the proposed approach in detecting both bad data and FDI attacks in the SG, respectively.},
  doi      = {10.1109/ACCESS.2019.2922410},
  groups   = {First Filtering},
  keywords = {State estimation;Transmission line measurements;Power measurement;Smart grids;Measurement uncertainty;Mathematical model;Voltage measurement;Bad data detection (BDD);false data injection;cognitive dynamic systems;cognitive control;cumulative sum (CUSUM);cyber-physical attack;cyber-physical systems;online estimation;smart grid;smart grid security},
}

@InProceedings{6735823,
  author    = {Lim, Jungmin and Doo, Seokjoo and Yoon, Hyunsoo},
  booktitle = {MILCOM 2013 - 2013 IEEE Military Communications Conference},
  title     = {The Design of a Robust Intrusion Tolerance System through Advanced Adaptive Cluster Transformation and Vulnerability-Based VM Selection},
  year      = {2013},
  month     = {Nov},
  pages     = {1422-1428},
  abstract  = {In this paper, we suggested novel schemes which use advanced adaptive cluster transformation and VM selection policy for intrusion tolerant systems (ITSs). The cluster size is transformed adaptively in order to maintain a certain level of services by using the adaptive cluster expansion scheme. Also, all the servers in clusters can be substituted in case serious threat such as massive packets incoming is expected by using the adaptive cluster substitution method. If there exists reliable historical data, more fast transformation is possible. In addition, the less-vulnerable virtual machines (VMs) are chosen using evaluation policies to reduce data leakage occured from system's vulnerabilities. Simulation results done with CSIM 20 prove that the suggested schemes improve intrusion tolerance efficiently compared to other conventional methods.},
  doi       = {10.1109/MILCOM.2013.241},
  groups    = {First Filtering},
  issn      = {2155-7586},
  keywords  = {Delays;Adaptive systems;Servers;Computer crime;Adaptation models;Time factors;Clustering algorithms;Intrusion tolerant system;adaptive cluster transformation;VM selection},
}

@InProceedings{8965459,
  author    = {Aladag, Merve and Catak, Ferhat Ozgur and Gul, Ensar},
  booktitle = {2019 1st International Informatics and Software Engineering Conference (UBMYK)},
  title     = {Preventing Data Poisoning Attacks By Using Generative Models},
  year      = {2019},
  month     = {Nov},
  pages     = {1-5},
  abstract  = {At the present time, machine learning methods have been becoming popular and the usage areas of these methods have also increased with this popularity. The machine learning methods are expected to increase in the cyber security components like firewalls, antivirus software etc. Nowadays, the use of this type of machine learning methods brings with it various risks. Attackers develop different methods to manipulate different systems, not only cyber security components, but also image detection systems. Therefore, securing machine learning models has become critical. In this paper, we demonstrate a data poisoning attack towards classification method of machine learning models and we also proposed a defense algorithm which makes machine learning models more robust against data poisoning attacks. In this study, we have conducted data poisoning attacks on MNIST, a widely used character detection data set. Using the poisoned MNIST dataset, we built classification models more reliable by using a generative model such as AutoEncoder.},
  doi       = {10.1109/UBMYK48245.2019.8965459},
  groups    = {First Filtering},
  keywords  = {Data models;Machine learning;Training data;Support vector machines;Optimization;Machine learning algorithms;Computer crime;data poisoning;support vector machine;machine learning;optimization},
}

@Article{9162532,
  author   = {Hassan, Mohammad Mehedi and Huda, Shamsul and Sharmeen, Shaila and Abawajy, Jemal and Fortino, Giancarlo},
  journal  = {IEEE Transactions on Industrial Informatics},
  title    = {An Adaptive Trust Boundary Protection for IIoT Networks Using Deep-Learning Feature-Extraction-Based Semisupervised Model},
  year     = {2021},
  issn     = {1941-0050},
  month    = {April},
  number   = {4},
  pages    = {2860-2870},
  volume   = {17},
  abstract = {The rapid development of Internet of Things (IoT) platforms provides the industrial domain with many critical solutions, such as joint venture virtual production systems. However, the extensive interconnection of industrial systems with corporate systems in industrial Internet of Things (IIoT) networks exposes the industrial domain to severe cyber risks. Because of many proprietary multilevel protocols, limited upgrade opportunities, heterogeneous communication infrastructures, and a very large trust boundary, conventional IT security fails to prevent cyberattacks against IIoT networks. Recent secure protocols, such as secure distributed network protocol (DNP 3.0), are limited to weak hash functions for critical response time requirements. As a complementary, we propose an adaptive trust boundary protection for IIoT networks using a deep-learning, feature-extraction-based semisupervised model. Our proposed approach is novel in that it is compatible with multilevel protocols of IIoT. The proposed approach does not require any manual effort to update the attack databases and can learn the rapidly changing natures of unknown attack models using unsupervised learnings and unlabeled data from the wild. Therefore, the proposed approach is resilient to emerging cyberattacks and their dynamic nature. The proposed approach has been verified using a real IIoT testbed. Extensive experimental analysis of the attack models and results shows that the proposed approach significantly improves the identification of attacks over conventional security control techniques.},
  doi      = {10.1109/TII.2020.3015026},
  groups   = {First Filtering},
  keywords = {Protocols;Informatics;Internet of Things;Security;Machine learning;Adaptation models;Process control;Cyberattack models;deep learning;IIoT;industrial control system;protocol vulnerabilities;secure DNP3.0;semisupervised model;trust boundary protection},
}

@InProceedings{8688299,
  author    = {Ibarra, Jaime and Javed Butt, Usman and Do, Anh and Jahankhani, Hamid and Jamal, Arshad},
  booktitle = {2019 IEEE 12th International Conference on Global Security, Safety and Sustainability (ICGS3)},
  title     = {Ransomware Impact to SCADA Systems and its Scope to Critical Infrastructure},
  year      = {2019},
  month     = {Jan},
  pages     = {1-12},
  abstract  = {SCADA systems are being constantly migrated to modern information and communication technologies (ICT) -based systems named cyber-physical systems. Unfortunately, this allows attackers to execute exploitation techniques into these architectures. In addition, ransomware insertion is nowadays the most popular attacking vector because it denies the availability of critical files and systems until attackers receive the demanded ransom. In this paper, it is analysed the risk impact of ransomware insertion into SCADA systems and it is suggested countermeasures addressed to the protection of SCADA systems and its components to reduce the impact of ransomware insertion.},
  doi       = {10.1109/ICGS3.2019.8688299},
  groups    = {First Filtering},
  keywords  = {Supervisory Control and Data Acquisition;Industrial Control Systems;Critical National Infrastructure;WannaCry;Ransomware;Ransomware Attack;security pre-processor;tactics;techniques and procedures;Cyber Physical Systems;Cybersecurity;Remote Terminal Units;intrusion detection and prevention systems;Privilege Escalation;Denial of Service;Extortion;Exploitation;Information Security;Cyber Attack;Crypto;Locker;Command and Control Server;Advanced Encryption Standard;RSA;Social Engineering;Vulnerability;footprinting;Malicious;Patch Management;Ransomware Injection;Stuxnet;Rootkit;Cryptocurrency;Virtual Private Networks},
}

@InProceedings{9306253,
  author    = {Khosravy, Mahdi and Nakamura, Kazuaki and Nitta, Naoko and Babaguchi, Noboru},
  booktitle = {2020 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)},
  title     = {Deep Face Recognizer Privacy Attack: Model Inversion Initialization by a Deep Generative Adversarial Data Space Discriminator},
  year      = {2020},
  month     = {Dec},
  pages     = {1400-1405},
  abstract  = {A variety of Machine Learning (ML) applications involve data of privacy-sensitive content. Face recognizer is one of them which due to training by user identities face images, it is inherent to user face image as a critical biometric data. A face recognition system can be subject to privacy attacks even though it deploys a complex model structure like a deeplearning-based one. Because as the ML models advance to carry more complexity in structure and parameters, the privacy attack trends develop too. Model Inversion Attack (MIA) pioneered by Fredrikson et al [1] was applied on a shallow neural network of face recognizer, and its capability of privacy leakage was approved. Their work was on a white-box scenario wherein besides the model structure, the privacy-non-sensitive data of the users are partially available and used by the attacker for generation and leakage of the user identity face images. The present work improves the extension of MIA to deep learning models of face recognizers while performing without any data of the users. Despite the complexity of the deep models as an obstacle, this work improves the capability of MIA in this matter. To aim this goal, it initializes its training procedure by a seed image approved by a GAN-trained discriminator of face image data-space via its output probability value. In targeting two users' identities by MIA, the proposed technique approves its efficiency on a deep face recognition system. The recognition rates of the images generated by MIA associated with GAN data-space discriminator (GAN-DD) are higher than sole MIA and demonstrate efficiency improvement of deep MIA.},
  groups    = {First Filtering},
  issn      = {2640-0103},
  keywords  = {Face recognition;Data models;Training;Image recognition;Generative adversarial networks;Gallium nitride;Deep learning;Cyber-security;cyber-attack;deep learning;face recognition;privacy protection;invasive software;Model Inversion},
}

@InProceedings{9302997,
  author    = {Roberts, Ciaran and Ngo, Sy-Toan and Milesi, Alexandre and Peisert, Sean and Arnold, Daniel and Saha, Shammya and Scaglione, Anna and Johnson, Nathan and Kocheturov, Anton and Fradkin, Dmitriy},
  booktitle = {2020 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids (SmartGridComm)},
  title     = {Deep Reinforcement Learning for DER Cyber-Attack Mitigation},
  year      = {2020},
  month     = {Nov},
  pages     = {1-7},
  abstract  = {The increasing penetration of DER with smart-inverter functionality is set to transform the electrical distribution network from a passive system, with fixed injection/consumption, to an active network with hundreds of distributed controllers dynamically modulating their operating setpoints as a function of system conditions. This transition is being achieved through standardization of functionality through grid codes and/or international standards. DER, however, are unique in that they are typically neither owned nor operated by distribution utilities and, therefore, represent a new emerging attack vector for cyber-physical attacks. Within this work we consider deep reinforcement learning as a tool to learn the optimal parameters for the control logic of a set of uncompromised DER units to actively mitigate the effects of a cyber-attack on a subset of network DER.},
  doi       = {10.1109/SmartGridComm47815.2020.9302997},
  groups    = {First Filtering},
  keywords  = {Inverters;Reinforcement learning;Reactive power;Smart grids;Neural networks;Voltage control;Standards},
}

@InProceedings{9376158,
  author    = {Alsulami, Abdulaziz A. and Zein-Sabatto, Saleh},
  booktitle = {2021 IEEE 11th Annual Computing and Communication Workshop and Conference (CCWC)},
  title     = {Resilient Cyber-Security Approach For Aviation Cyber-Physical Systems Protection Against Sensor Spoofing Attacks},
  year      = {2021},
  month     = {Jan},
  pages     = {0565-0571},
  abstract  = {The aviation industries are transitioning from conventional aircraft systems to Aviation Cyber-Physical Systems (ACPS) based aircraft. However, like any Cyber-Physical Systems (CPS), the ACPS are vulnerable to cyber-attacks that can be mounted by adversaries through the communication network infrastructure. This paper proposes a novel and resilient security protocol for detecting and defending ACPS against sensor spoofing cyber-attacks. First, a communication environment was developed to establish an aircraft Networked Control System (NCS) using the SimEvents toolbox. Then, a cyber-attack detection algorithm based on the positive selection of the Artificial Immune System (AIS) approach was developed and used to detect and drop suspicious communication packets on the aircraft network traffic. Finally, the NCS and the detection algorithm were integrated and tested on real cyber-security attack scenarios. The algorithm's accuracy was 0.96 based on the True Positive and True Negative algorithm detection rate. For further defending the aircraft against cyber-attacks, Nonlinear Autoregressive Exogenous (NARX) algorithm was developed to reconstruct or estimate the network dropped packets. The estimation accuracy of the NARX reached 0.99 using the coefficient of determination (R-value) based on the linear regression approach. The real-time simulation test results showed that the sensor spoofing cyber-attack was successfully detected. Also, the communication network of the ACPS was defended against the attack because the ACPS was maintaining the normal performance during the course of the cyber-attack.},
  doi       = {10.1109/CCWC51732.2021.9376158},
  groups    = {First Filtering},
  keywords  = {Atmospheric modeling;Conferences;Cyber-physical systems;Communication networks;Air traffic control;Aircraft;Detection algorithms;Sensor Spoofing Attacks;CPS;NARX;ACPS;Artificial Immune System;Positive Selection Algorithm;TCM;Cyber-attacks;FDI Attacks},
}

@InProceedings{9150936,
  author    = {Truong, Loc and Jones, Chace and Hutchinson, Brian and August, Andrew and Praggastis, Brenda and Jasper, Robert and Nichols, Nicole and Tuor, Aaron},
  booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  title     = {Systematic Evaluation of Backdoor Data Poisoning Attacks on Image Classifiers},
  year      = {2020},
  month     = {June},
  pages     = {3422-3431},
  abstract  = {Backdoor data poisoning attacks have recently been demonstrated in computer vision research as a potential safety risk for machine learning (ML) systems. Traditional data poisoning attacks manipulate training data to induce unreliability of an ML model, whereas backdoor data poisoning attacks maintain system performance unless the ML model is presented with an input containing an embedded "trigger " that provides a predetermined response advantageous to the adversary. Our work builds upon prior backdoor data-poisoning research for ML image classifiers and systematically assesses different experimental conditions including types of trigger patterns, persistence of trigger patterns during retraining, poisoning strategies, architectures (ResNet-50, NasNet, NasNet-Mobile), datasets (Flowers, CIFAR-10), and potential defensive regularization techniques (Contrastive Loss, Logit Squeezing, Manifold Mixup, Soft-Nearest-Neighbors Loss). Experiments yield four key findings. First, the success rate of backdoor poisoning attacks varies widely, depending on several factors, including model architecture, trigger pattern and regularization technique. Second, we find that poisoned models are hard to detect through performance inspection alone. Third, regularization typically reduces backdoor success rate, although it can have no effect or even slightly increase it, depending on the form of regularization. Finally, backdoors inserted through data poisoning can be rendered ineffective after just a few epochs of additional training on a small set of clean data without affecting the model's performance.},
  doi       = {10.1109/CVPRW50498.2020.00402},
  groups    = {First Filtering},
  issn      = {2160-7516},
  keywords  = {Data models;Training;Computational modeling;Machine learning;Training data;Computer vision;Safety},
}

@Article{9194069,
  author   = {Amsaleg, Laurent and Bailey, James and Barbe, Amélie and Erfani, Sarah M. and Furon, Teddy and Houle, Michael E. and Radovanović, Miloš and Nguyen, Xuan Vinh},
  journal  = {IEEE Transactions on Information Forensics and Security},
  title    = {High Intrinsic Dimensionality Facilitates Adversarial Attack: Theoretical Evidence},
  year     = {2021},
  issn     = {1556-6021},
  pages    = {854-865},
  volume   = {16},
  abstract = {Machine learning systems are vulnerable to adversarial attack. By applying to the input object a small, carefully-designed perturbation, a classifier can be tricked into making an incorrect prediction. This phenomenon has drawn wide interest, with many attempts made to explain it. However, a complete understanding is yet to emerge. In this paper we adopt a slightly different perspective, still relevant to classification. We consider retrieval, where the output is a set of objects most similar to a user-supplied query object, corresponding to the set of k-nearest neighbors. We investigate the effect of adversarial perturbation on the ranking of objects with respect to a query. Through theoretical analysis, supported by experiments, we demonstrate that as the intrinsic dimensionality of the data domain rises, the amount of perturbation required to subvert neighborhood rankings diminishes, and the vulnerability to adversarial attack rises. We examine two modes of perturbation of the query: either `closer' to the target point, or `farther' from it. We also consider two perspectives: `query-centric', examining the effect of perturbation on the query's own neighborhood ranking, and `target-centric', considering the ranking of the query point in the target's neighborhood set. All four cases correspond to practical scenarios involving classification and retrieval.},
  doi      = {10.1109/TIFS.2020.3023274},
  groups   = {First Filtering},
  keywords = {Perturbation methods;Feature extraction;Machine learning;Neural networks;Databases;Content-based retrieval;Learning systems;Adversarial attack;intrinsic dimensionality;nearest neighbor},
}

@InProceedings{9343128,
  author    = {Huang, Shin-Ying and Ban, Tao},
  booktitle = {2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)},
  title     = {Monitoring Social Media for Vulnerability-Threat Prediction and Topic Analysis},
  year      = {2020},
  month     = {Dec},
  pages     = {1771-1776},
  abstract  = {Publicly available software vulnerabilities and exploit code are often abused by malicious actors to launch cyberattacks to vulnerable targets. Organizations not only have to update their software to the latest versions, but do effective patch management and prioritize security-related patching as well. In addition to intelligence sources such as Computer Emergency Response Team (CERT) alerts, cybersecurity news, national vulnerability database (NBD), and commercial cybersecurity vendors, social media is another valuable source that facilitates early stage intelligence gathering. To early detect future cyber threats based on publicly available resources on the Internet, we propose a dynamic vulnerability-threat assessment model to predict the tendency to be exploited for vulnerability entries listed in Common Vulnerability Exposures, and also to analyze social media contents such as Twitter to extract meaningful information. The model takes multiple aspects of vulnerabilities gathered from different sources into consideration. Features range from profile information to contextual information about these vulnerabilities. For the social media data, this study leverages machine learning techniques specially for Twitter which helps to filter out non-cybersecurity-related tweets and also label the topic categories of each tweet. When applied to predict the vulnerabilities exploitation and analyzed the real-world social media discussion data, it showed promising prediction accuracy with purified social media intelligence. Moreover, the AI-enabling modules have been deployed into a threat intelligence platform for further applications.},
  doi       = {10.1109/TrustCom50675.2020.00243},
  groups    = {First Filtering},
  issn      = {2324-9013},
  keywords  = {Analytical models;Social networking (online);Blogs;Predictive models;Threat assessment;Software;Data models;vulnerability exploit prediction;social media;machine learning;threat intelligence},
}

@Article{7968482,
  author   = {Tang, MingJian and Alazab, Mamoun and Luo, Yuxiu},
  journal  = {IEEE Transactions on Big Data},
  title    = {Big Data for Cybersecurity: Vulnerability Disclosure Trends and Dependencies},
  year     = {2019},
  issn     = {2332-7790},
  month    = {Sep.},
  number   = {3},
  pages    = {317-329},
  volume   = {5},
  abstract = {Complex Big Data systems in modern organisations are progressively becoming attack targets by existing and emerging threat agents. Elaborate and specialised attacks will increasingly be crafted to exploit vulnerabilities and weaknesses. With the ever-increasing trend of cybercrime and incidents due to these vulnerabilities, effective vulnerability management is imperative for modern organisations regardless of their size. However, organisations struggle to manage the sheer volume of vulnerabilities discovered on their networks. Moreover, vulnerability management tends to be more reactive in practice. Rigorous statistical models, simulating anticipated volume and dependence of vulnerability disclosures, will undoubtedly provide important insights to organisations and help them become more proactive in the management of cyber risks. By leveraging the rich yet complex historical vulnerability data, our proposed novel and rigorous framework has enabled this new capability. By utilising this sound framework, we initiated an important study on not only handling persistent volatilities in the data but also further unveiling multivariate dependence structure amongst different vulnerability risks. In sharp contrast to the existing studies on univariate time series, we consider the more general multivariate case striving to capture their intriguing relationships. Through our extensive empirical studies using the real world vulnerability data, we have shown that a composite model can effectively capture and preserve long-term dependency between different vulnerability and exploit disclosures. In addition, the paper paves the way for further study on the stochastic perspective of vulnerability proliferation towards building more accurate measures for better cyber risk management as a whole.},
  doi      = {10.1109/TBDATA.2017.2723570},
  groups   = {First Filtering},
  keywords = {Time series analysis;Market research;Biological system modeling;Big Data;Data models;Computer security;Software;Big data;cyber risk;cybersecurity;vulnerability;zero-day;time series;copula},
}

@Article{9171297,
  author   = {Liu, Ming and Liu, Jinjin and Zhang, Ping and Li, Qingbao},
  journal  = {IEEE Access},
  title    = {PA-GAN: A Patch-Attention Based Aggregation Network for Face Recognition in Surveillance},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {152780-152789},
  volume   = {8},
  abstract = {Face recognition in unconstraint surveillance is a complicated problem on account of motion blur, expression variations and low resolution. Recent works have demonstrated that patch-attention is strictly more powerful than convolution in recognition models. In this study, we investigate the task of unconstraint surveillance face recognition. First, a Patch-Attention Generative Adversarial Network (PA-GAN) model is devised to aggregate some robust features on behalf of a set of raw surveillance frames, which not only increases the recognition accuracy but also reduces the computational costs of face matching. Second, an improved center loss function combined with abundant unlabeled surveillance faces is utilized to accurately classify the known identities. With the proposed method, the discriminativeness of the face representations is largely enhanced. Finally, the proposed method is verified in two widely used datasets, IJB-A dataset and QMUL-SurvFace dataset to demonstrate the effectiveness. Evaluation of the algorithm performances in comparison with other state-of-the-art methods indicates that the proposed design can achieve competitive accuracy on both the verification and identification protocols.},
  doi      = {10.1109/ACCESS.2020.3017779},
  groups   = {First Filtering},
  keywords = {Face recognition;Face;Surveillance;Computational modeling;Convolution;Feature extraction;Generative adversarial networks;Face recognition;video surveillance;attention model;generative adversarial network},
}

@Article{8933418,
  author   = {Li, Xiaowen and Yan, Diqun and Dong, Li and Wang, Rangding},
  journal  = {IEEE Access},
  title    = {Anti-Forensics of Audio Source Identification Using Generative Adversarial Network},
  year     = {2019},
  issn     = {2169-3536},
  pages    = {184332-184339},
  volume   = {7},
  abstract = {Digital audio recording is the main evidence used in the field of judicial forensics. Recently, a number of digital audio forensic techniques have been developed and the audio source identification (ASI) is one of the most active research topics. Most of existing ASI works mainly focus on improving the performance of detection accuracy and robustness. Little consideration has been given to ASI anti-forensics, which aims at attacking the forensic techniques. To expose the weaknesses of these source identification methods, we propose an anti-forensic framework based on generative adversarial network (GAN) to falsify the source information of an audio by adding specific disturbance. The experimental results show that the falsified audio can deceive the forensic methods effectively, and can even control their conclusions. Three state-of-art ASI methods have been evaluated as the attacking targets. For the confusing attack, the proposed method can significantly reduce their detection accuracies from about 97% to less than 5%. For the misleading attack, a misleading rate about 81.32% has been achieved while ensuring the perceptual quality of the anti-forensic audio.},
  doi      = {10.1109/ACCESS.2019.2960097},
  groups   = {First Filtering},
  keywords = {Detectors;Generators;Forensics;Generative adversarial networks;Feature extraction;Transform coding;Image coding;Generative adversarial network;anti-forensics;audio source identification},
}

@Article{8935148,
  author   = {Liu, Miao and Zhang, Boyu and Chen, Wenbin and Zhang, Xunlai},
  journal  = {IEEE Access},
  title    = {A Survey of Exploitation and Detection Methods of XSS Vulnerabilities},
  year     = {2019},
  issn     = {2169-3536},
  pages    = {182004-182016},
  volume   = {7},
  abstract = {As web applications become more prevalent, web security becomes more and more important. Cross-site scripting vulnerability abbreviated as XSS is a kind of common injection web vulnerability. The exploitation of XSS vulnerabilities can hijack users' sessions, modify, read and delete business data of web applications, place malicious codes in web applications, and control victims to attack other targeted servers. This paper discusses classification of XSS, and designs a demo website to demonstrate attack processes of common XSS exploitation scenarios. The paper also compares and analyzes recent research results on XSS detection, divides them into three categories according to different mechanisms. The three categories are static analysis methods, dynamic analysis methods and hybrid analysis methods. The paper classifies 30 detection methods into above three categories, makes overall comparative analysis among them, lists their strengths and weaknesses and detected XSS vulnerability types. In the end, the paper explores some ways to prevent XSS vulnerabilities from being exploited.},
  doi      = {10.1109/ACCESS.2019.2960449},
  groups   = {First Filtering},
  keywords = {Malware;Grippers;Cross-site scripting;Servers;Static analysis;Browsers;Vulnerability detection;vulnerability exploitation;web security;XSS},
}

@InProceedings{8698563,
  author    = {Damer, Naser and Saladié, Alexandra Moseguí and Braun, Andreas and Kuijper, Arjan},
  booktitle = {2018 IEEE 9th International Conference on Biometrics Theory, Applications and Systems (BTAS)},
  title     = {MorGAN: Recognition Vulnerability and Attack Detectability of Face Morphing Attacks Created by Generative Adversarial Network},
  year      = {2018},
  month     = {Oct},
  pages     = {1-10},
  abstract  = {Face morphing attacks aim at creating face images that are verifiable to be the face of multiple identities, which can lead to building faulty identity links in operations like border crossing. Research has been focused on creating more accurate attack detection approaches by considering different image properties. However, all the attacks considered so far are based on manipulating facial landmarks localized in the morphed face images. In contrast, this work presents novel face morphing attacks based on image generated by generative adversarial networks. We present the MorGAN structure that considers the representation loss to successfully create realistic morphing attacks. Based on that, we present a novel face morphing attacks database (MorGAN database) that contains 1000 morph images for both, the proposed MorGAN and landmark-based attacks. We present vulnerability analysis of two face recognition approaches facing the proposed attacks. Moreover, the detectability of the proposed MorGAN attacks is studied, in the scenarios where this type of attacks is know and un- known. We concluded with pointing out the challenge of detecting such unknown novel attacks and an analysis of detection performances of different features in detecting such attacks.},
  doi       = {10.1109/BTAS.2018.8698563},
  groups    = {First Filtering},
  issn      = {2474-9699},
  keywords  = {Face;Generators;Gallium nitride;Face recognition;Training;Feature extraction;Interpolation},
}

@InProceedings{9098480,
  author    = {Qiang, Ning and Dong, Qinglin and Sun, Yifei and Ge, Bao and Liu, Tianming},
  booktitle = {2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)},
  title     = {Deep Variational Autoencoder for Modeling Functional Brain Networks and ADHD Identification},
  year      = {2020},
  month     = {April},
  pages     = {554-557},
  abstract  = {In the neuroimaging and brain mapping communities, researchers have proposed a variety of computational methods and tools to learn functional brain networks (FBNs). Recently, it has already been proven that deep learning can be applied on fMRI data with superb representation power over traditional machine learning methods. Limited by the high-dimension of fMRI volumes, deep learning suffers from the lack of data and overfitting. Generative models are known to have intrinsic ability of modeling small dataset and a Deep Variational Autoencoder (DVAE) is proposed in this work to tackle the challenge of insufficient data and incomplete supervision. The FBNs learned from fMRI were examined to be interpretable and meaningful and it was proven that DVAE has better performance on neuroimaging dataset over traditional models. With an evaluation on ADHD-200 dataset, DVAE performed excellent on classification accuracies on 4 sites.},
  doi       = {10.1109/ISBI45749.2020.9098480},
  groups    = {First Filtering},
  issn      = {1945-8452},
  keywords  = {Functional magnetic resonance imaging;Data models;Feature extraction;Brain modeling;Machine learning;Pipelines;Decoding;Resting-state fMRI;Variational Autoencoder;ADHD;Deep Learning;Generative Learning},
}

@Article{9169810,
  author   = {Zhang, Fuzhi and Wang, Shilei},
  journal  = {IEEE Transactions on Computational Social Systems},
  title    = {Detecting Group Shilling Attacks in Online Recommender Systems Based on Bisecting K-Means Clustering},
  year     = {2020},
  issn     = {2329-924X},
  month    = {Oct},
  number   = {5},
  pages    = {1189-1199},
  volume   = {7},
  abstract = {Existing shilling attack detection approaches focus mainly on identifying individual attackers in online recommender systems and rarely address the detection of group shilling attacks in which a group of attackers colludes to bias the output of an online recommender system by injecting fake profiles. In this article, we propose a group shilling attack detection method based on the bisecting K-means clustering algorithm. First, we extract the rating track of each item and divide the rating tracks to generate candidate groups according to a fixed time interval. Second, we propose item attention degree and user activity to calculate the suspicious degrees of candidate groups. Finally, we employ the bisecting K-means algorithm to cluster the candidate groups according to their suspicious degrees and obtain the attack groups. The results of experiments on the Netflix and Amazon data sets indicate that the proposed method outperforms the baseline methods.},
  doi      = {10.1109/TCSS.2020.3013878},
  groups   = {First Filtering},
  keywords = {Recommender systems;Feature extraction;Clustering algorithms;Principal component analysis;Target tracking;Support vector machines;Bisecting K-means clustering;group shilling attack detection;group shilling attacks;recommender systems},
}

@InProceedings{8791700,
  author    = {Kwon, Hyun and Yoon, Hyunsoo and Park, Ki-Woong},
  booktitle = {2019 IEEE Second International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)},
  title     = {Selective Poisoning Attack on Deep Neural Network to Induce Fine-Grained Recognition Error},
  year      = {2019},
  month     = {June},
  pages     = {136-139},
  abstract  = {Deep neural networks (DNNs) provide good performance for image recognition, speech recognition, and pattern recognition. However, a poisoning attack is a serious threat to DNN's security. The poisoning attack is a method to reduce the accuracy of DNN by adding malicious training data during DNN training process. In some situations such as a military, it may be necessary to drop only a chosen class of accuracy in the model. For example, if an attacker does not allow only nuclear facilities to be selectively recognized, it may be necessary to intentionally prevent UAV from correctly recognizing nuclear-related facilities. In this paper, we propose a selective poisoning attack that reduces the accuracy of only chosen class in the model. The proposed method reduces the accuracy of a chosen class in the model by training malicious training data corresponding to a chosen class, while maintaining the accuracy of the remaining classes. For experiment, we used tensorflow as a machine learning library and MNIST and CIFAR10 as datasets. Experimental results show that the proposed method can reduce the accuracy of the chosen class to 43.2% and 55.3% in MNIST and CIFAR10, while maintaining the accuracy of the remaining classes.},
  doi       = {10.1109/AIKE.2019.00033},
  groups    = {First Filtering},
  keywords  = {Training data;Data models;Training;Distortion;Neurons;Support vector machines;Neural networks;Poisoning attack;Machine learning;Deep neural network;chosen class},
}

@InProceedings{9369569,
  author    = {Li, Yi and Lin, Jing and Xiong, Kaiqi},
  booktitle = {2021 IEEE 18th Annual Consumer Communications Networking Conference (CCNC)},
  title     = {An Adversarial Attack Defending System for Securing In-Vehicle Networks},
  year      = {2021},
  month     = {Jan},
  pages     = {1-6},
  abstract  = {In a modern vehicle, there are over seventy Electronics Control Units (ECUs). For an in-vehicle network, ECUs communicate with each other by following a standard communication protocol, such as Controller Area Network (CAN). However, an attacker can easily access the in-vehicle network to compromise ECUs through a WLAN or Bluetooth. Though there are various deep learning (DL) methods suggested for securing in-vehicle networks, recent studies on adversarial examples have shown that attackers can easily fool DL models. In this research, we further explore adversarial examples in an in-vehicle network. We first discover and implement two adversarial attack models that are harmful to a Long Short Term Memory (LSTM)-based detection model used in the in-vehicle network. As shown in our experiments, adversaries can attack the LSTM-based detection model with a success rate of over 98%. Then, we propose an Adversarial Attack Defending System (AADS) for securing an in-vehicle network. Specifically, we focus on brake-related ECUs in an in-vehicle network. Our extensive experimental results demonstrate that the proposed AADS achieves over 99 % accuracy for detecting adversarial attacks.},
  doi       = {10.1109/CCNC49032.2021.9369569},
  groups    = {First Filtering},
  issn      = {2331-9860},
  keywords  = {Deep learning;Wireless LAN;Protocols;Bluetooth;Security;Long short term memory;Standards},
}

@InProceedings{8473549,
  author    = {Jacobs, Nicholas and Hossain-McKenzie, Shamina and Vugrin, Eric},
  booktitle = {2018 Resilience Week (RWS)},
  title     = {Measurement and Analysis of Cyber Resilience for Control Systems: An Illustrative Example},
  year      = {2018},
  month     = {Aug},
  pages     = {38-46},
  abstract  = {Control systems for critical infrastructure are becoming increasingly interconnected while cyber threats against critical infrastructure are becoming more sophisticated and difficult to defend against. Historically, cyber security has emphasized building defenses to prevent loss of confidentiality, integrity, and availability in digital information and systems, but in recent years cyber attacks have demonstrated that no system is impenetrable and that control system operation may be detrimentally impacted. Cyber resilience has emerged as a complementary priority that seeks to ensure that digital systems can maintain essential performance levels, even while capabilities are degraded by a cyber attack. This paper examines how cyber security and cyber resilience may be measured and quantified in a control system environment. Load Frequency Control is used as an illustrative example to demonstrate how cyber attacks may be represented within mathematical models of control systems, to demonstrate how these events may be quantitatively measured in terms of cyber security or cyber resilience, and the differences and similarities between the two mindsets. These results demonstrate how various metrics are applied, the extent of their usability, and how it is important to analyze cyber-physical systems in a comprehensive manner that accounts for all the various parts of the system.},
  doi       = {10.1109/RWEEK.2018.8473549},
  groups    = {First Filtering},
  keywords  = {Resilience;Control systems;Cyberattack;Frequency measurement;Cyber Security;Cyber Resilience;Cyber-Physical Systems;Control Systems;Load Frequency Control},
}

@InProceedings{9334608,
  author    = {Younan, Mina and Houssein, Essam H. and Elhoseny, Mohamed and Ali, Abd El-mageid A.},
  booktitle = {2020 15th International Conference on Computer Engineering and Systems (ICCES)},
  title     = {Improved Models for Time Series Cluster Representation Based Dynamic Time Warping},
  year      = {2020},
  month     = {Dec},
  pages     = {1-6},
  abstract  = {Revolution of Smart Things (SThs) connected to the Internet to build Internet of Things (IoT) applications, causes a flood of data streams every moment. Main root causes of massive SThs integration for increasing accuracy of sensed features and for enabling fault tolerance. In general, resulting deluge of real-time data streams has the property of five V of the big data (i.e., volume, velocity, variety, veracity, and value). Such properties make mining and analysis of massive and heterogeneous data be challenging tasks. In our previous work, we present three novel data reduction models based on Dynamic Time Warping (DTW) for enabling balanced indexing in the IoT. This paper presents two extensions to improve the Hybrid algorithm (ClRe 3.0) using DTW warped path. First extension (ClRe 3.1): targets improving accuracy of indexed clusters representatives by taking the average of individual warped items and keeping only 50% of the warped items for each warped slot. Second extension (ClRe 3.2): targets decreasing size of indexed clusters representatives as possible by compensating every warped slot by its corresponding item keeping only common items with minimum distances. The proposed extensions are explained using real samples and evaluated using Szeged-weather dataset as well. The evaluation results proves that ClRe 3.1 could enhance the accuracy of ClRe 3.0 by approximate 9% in average, keeping indexes sizes as possible as fitted (i.e., <; the average length of all datasets). In case of indexing only highly common readings, ClRe 3.2 out-performs other extensions in decreasing indexes sizes.},
  doi       = {10.1109/ICCES51560.2020.9334608},
  groups    = {First Filtering},
  keywords  = {Time series analysis;Clustering algorithms;Real-time systems;Data models;Internet of Things;Floods;Indexing;Industrial IoT;DTW;Data reduction;Time series;Similarity search;Balanced indexing;Cluster representative},
}

@Article{7552587,
  author   = {Yuan, Bin and Zou, Deqing and Yu, Shui and Jin, Hai and Qiang, Weizhong and Shen, Jinan},
  journal  = {IEEE Transactions on Services Computing},
  title    = {Defending Against Flow Table Overloading Attack in Software-Defined Networks},
  year     = {2019},
  issn     = {1939-1374},
  month    = {March},
  number   = {2},
  pages    = {231-246},
  volume   = {12},
  abstract = {The Software-Defined Network (SDN) is a new and promising network architecture. At the same time, SDN will surely become a new target of cyber attackers. In this paper, we point out one critical vulnerability in SDNs, the size of flow table, which is most likely to be attacked. Due to the expensive and power-hungry features of Ternary Content Addressable Memory (TCAM), a flow table usually has a limited size, which can be easily disabled by a flow table overloading attack (a transformed DDoS attack). To provide a security service in SDN, we proposed a QoS-aware mitigation strategy, namely, peer support strategy, which integrates the available idle flow table resource of the whole SDN system to mitigate such an attack on a single switch of the system. We established a practical mathematical model to represent the studied system, and conducted a thorough analysis for the system in various circumstances. Based on our analysis, we found that the proposed strategy can effectively defeat the flow table overloading attacks. Extensive simulations and testbed-based experiments solidly support our claims. Moreover, our work also shed light on the implementation of SDN networks against possible brute-force attacks.},
  doi      = {10.1109/TSC.2016.2602861},
  groups   = {First Filtering},
  keywords = {Switches;Computer crime;Quality of service;Mathematical model;Servers;SDN security;DDoS attacks;QoS;security service;flow table},
}

@InProceedings{9338937,
  author    = {Liu, Sijie and Zhang, Zhixiang and Zhang, Xian and Feng, Haojun},
  booktitle = {2020 IEEE 9th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)},
  title     = {F-MIFGSM: adversarial attack algorithm for the feature region},
  year      = {2020},
  month     = {Dec},
  pages     = {2164-2170},
  volume    = {9},
  abstract  = {The current mainstream attack algorithms IFGSM and MI-FGSM will carry out global perturbation to the original example when they carry out adversarial attack. F-MIFGSM algorithm is proposed to solve the problem of poor attack concealment. This algorithm extracts the output information of the convolutional layer of the neural network, marks out the feature region of the original example through the deconvolution network and mapping algorithm, and uses the MI-FGSM algorithm to carry out the specific region attack. In the experiment, 60,000 training sets in MNIST data set are used to train the self-constructed convolutional neural network, and 10,000 test sets in the data set are attacked, and the generated adversarial examples are input into the neural network for classification prediction. The experimental results show that the F-MIFGSM algorithm can significantly reduce the disturbance range to the original example and reduce the defects between the adversarial example and the original example under the condition of increasing the attack success rate.},
  doi       = {10.1109/ITAIC49862.2020.9338937},
  groups    = {First Filtering},
  issn      = {2693-2865},
  keywords  = {Training;Perturbation methods;Neural networks;Feature extraction;Prediction algorithms;Classification algorithms;Convolutional neural networks;adversarial attack;adversarial example;(CNN)Convolutional Neural Network;image classification},
}

@InProceedings{9006352,
  author    = {Robic-Butez, Pierrick and Win, Thu Yein},
  booktitle = {2019 IEEE International Conference on Big Data (Big Data)},
  title     = {Detection of Phishing websites using Generative Adversarial Network},
  year      = {2019},
  month     = {Dec},
  pages     = {3216-3221},
  abstract  = {Phishing is typically deployed as an attack vector in the initial stages of a hacking endeavour. Due to it low-risk rightreward nature it has seen a widespread adoption, and detecting it has become a challenge in recent times. This paper proposes a novel means of detecting phishing websites using a Generative Adversarial Network. Taking into account the internal structure and external metadata of a website, the proposed approach uses a generator network which generates both legitimate as well as synthetic phishing features to train a discriminator network. The latter then determines if the features are either normal or phishing websites, before improving its detection accuracy based on the classification error. The proposed approach is evaluated using two different phishing datasets and is found to achieve a detection accuracy of up to 94%.},
  doi       = {10.1109/BigData47090.2019.9006352},
  groups    = {First Filtering},
  keywords  = {Phishing;Feature extraction;Training;Uniform resource locators;Gallium nitride;Generators;Generative adversarial networks;security analytics;phishing detection;generative adversarial networks;cloud security;big data analytics},
}

@Article{6392461,
  author   = {Zhuang, Weiwei and Ye, Yanfang and Chen, Yong and Li, Tao},
  journal  = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  title    = {Ensemble Clustering for Internet Security Applications},
  year     = {2012},
  issn     = {1558-2442},
  month    = {Nov},
  number   = {6},
  pages    = {1784-1796},
  volume   = {42},
  abstract = {Due to their damage to Internet security, malware and phishing website detection has been the Internet security topics that are of great interests. Compared with malware attacks, phishing website fraud is a relatively new Internet crime. However, they share some common properties: 1) both malware samples and phishing websites are created at a rate of thousands per day driven by economic benefits; and 2) phishing websites represented by the term frequencies of the webpage content share similar characteristics with malware samples represented by the instruction frequencies of the program. Over the past few years, many clustering techniques have been employed for automatic malware and phishing website detection. In these techniques, the detection process is generally divided into two steps: 1) feature extraction, where representative features are extracted to capture the characteristics of the file samples or the websites; and 2) categorization, where intelligent techniques are used to automatically group the file samples or websites into different classes based on computational analysis of the feature representations. However, few have been applied in real industry products. In this paper, we develop an automatic categorization system to automatically group phishing websites or malware samples using a cluster ensemble by aggregating the clustering solutions that are generated by different base clustering algorithms. We propose a principled cluster ensemble framework to combine individual clustering solutions that are based on the consensus partition, which can not only be applied for malware categorization, but also for phishing website clustering. In addition, the domain knowledge in the form of sample-level/website-level constraints can be naturally incorporated into the ensemble framework. The case studies on large and real daily phishing websites and malware collection from the Kingsoft Internet Security Laboratory demonstrate the effectiveness and efficiency of our proposed method.},
  doi      = {10.1109/TSMCC.2012.2222025},
  groups   = {First Filtering},
  keywords = {Malware;Feature extraction;Internet;Clustering algorithms;Knowledge engineering;Data mining;Cluster ensemble;malware categorization;phishing website detection},
}

@Article{9096314,
  author   = {Cao, Jie and Wang, Da and Qu, Zhaoyang and Cui, Mingshi and Xu, Pengcheng and Xue, Kai and Hu, Kewei},
  journal  = {IEEE Access},
  title    = {A Novel False Data Injection Attack Detection Model of the Cyber-Physical Power System},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {95109-95125},
  volume   = {8},
  abstract = {The False data injection attack (FDIA) against the Cyber-Physical Power System (CPPS) is a kind of data integrity attack. With more and more cyber vulnerabilities detected out, different types of FDIAs are emerging as severe threats to the stable operation of CPPS gradually. In this paper, the invasion pathway of the FDIA against CPPS is explored in detail, and a novel FDIA detection model based on ensemble learning is further provided. First, a pseudo-sample database is built to assist the training and evaluation of this model, and it's more important to update the model in the future. Furthermore, the optimal feature set is extracted to characterize the behavior of the FDIA, which improves the precision of the FDIA detection model. Finally, a focal-loss-lightgbm (FLGB) ensemble classifier is constructed to detect the FDIA behavior automatically and accurately. We illustrated the performance of this model by a fusion of measurement data and power system audit logs. This model utilizes the offline training way, the conclusion shows the high precision and stability of this model, which ensures the stable operation of the smart grid and improves the FDIA resistance ability of the CPPS.},
  doi      = {10.1109/ACCESS.2020.2995772},
  groups   = {First Filtering},
  keywords = {Mathematical model;Power system stability;Training;State estimation;Data models;Machine learning;CPPS;FDIA detection model;invasion pathway analysis;ensemble learning},
}

@Article{8990004,
  author   = {Kazemi, Zahra and Safavi, Ali Akbar and Naseri, Farshid and Urbas, Leon and Setoodeh, Peyman},
  journal  = {IEEE Transactions on Industrial Informatics},
  title    = {A Secure Hybrid Dynamic-State Estimation Approach for Power Systems Under False Data Injection Attacks},
  year     = {2020},
  issn     = {1941-0050},
  month    = {Dec},
  number   = {12},
  pages    = {7275-7286},
  volume   = {16},
  abstract = {Dynamic-state estimation plays a critical role in achieving real-time wide-area monitoring of power systems. On the other hand, false data injection (FDI) attacks are substantial threats, which can undesirably ruin the state estimation results. To tackle this problem, an effective secure hybrid dynamic-state estimation approach that involves a dynamic model of the attack vector is proposed in this article. In the proposed method, an initial estimation of the system states is first obtained using a designed unknown input observer (UIO). Subsequently, based on the system, UIO models, and the initial estimations of the states, a dynamic model for the attack vector is extracted. Ultimately, the attack model is augmented with the main system model for coestimation of the attack and the system states using a Kalman filter. The onset of the FDI attack is rapidly detected by the accurate estimation of the attack vector. The effectiveness of the proposed approach is demonstrated under different FDI attack scenarios by a thorough theoretical analysis as well as simulations on IEEE 14-bus and 57-bus test systems. In order to show that the proposed method can keep up with typical scan rates of commercial phasor measurement units, a series of software-in-the-loop experiments are also conducted and the real-time feasibility of the proposed approach is guaranteed.},
  doi      = {10.1109/TII.2020.2972809},
  groups   = {First Filtering},
  keywords = {Power system dynamics;State estimation;Covariance matrices;Mathematical model;Informatics;Real-time systems;Dynamic-state estimation (DSE);false data injection (FDI) attack;phasor measurement unit (PMU)},
}

@InProceedings{8432316,
  author    = {Torkura, Kennedy A. and Sukmana, Muhammad I.H and Meinig, Michael and Kayem, Anne V.D.M and Cheng, Feng and Graupner, Hendrik and Meinel, Christoph},
  booktitle = {2018 IEEE 32nd International Conference on Advanced Information Networking and Applications (AINA)},
  title     = {Securing Cloud Storage Brokerage Systems Through Threat Models},
  year      = {2018},
  month     = {May},
  pages     = {759-768},
  abstract  = {Cloud storage brokerage is an abstraction aimed at providing value-added services. However, Cloud Service Brokers are challenged by several security issues including enlarged attack surfaces due to integration of disparate components and API interoperability issues. Therefore, appropriate security risk assessment methods are required to identify and evaluate these security issues, and examine the efficiency of countermeasures. A possible approach for satisfying these requirements is employment of threat modeling concepts, which have been successfully applied in traditional paradigms. In this work, we employ threat models including attack trees, attack graphs and Data Flow Diagrams against a Cloud Service Broker (CloudRAID) and analyze these security threats and risks. Furthermore, we propose an innovative technique for combining Common Vulnerability Scoring System (CVSS) and Common Configuration Scoring System (CCSS) base scores in probabilistic attack graphs to cater for configuration-based vulnerabilities which are typically leveraged for attacking cloud storage systems. This approach is necessary since existing schemes do not provide sufficient security metrics, which are imperatives for comprehensive risk assessments. We demonstrate the efficiency of our proposal by devising CCSS base scores for two common attacks against cloud storage: Cloud Storage Enumeration Attack and Cloud Storage Exploitation Attack. These metrics are then used in Attack Graph Metric-based risk assessment. Our experimental evaluation shows that our approach caters for the aforementioned gaps and provides efficient security hardening options. Therefore, our proposals can be employed to improve cloud security.},
  doi       = {10.1109/AINA.2018.00114},
  groups    = {First Filtering},
  issn      = {2332-5658},
  keywords  = {Cloud computing;Security;Computational modeling;Risk management;Measurement;Data models;Proposals;Cloud Security;Threat Models;Security Metrics;Security Risk Assessment;Secure Configuration},
}

@Article{6612700,
  author   = {Mo, Yilin and Chabukswar, Rohan and Sinopoli, Bruno},
  journal  = {IEEE Transactions on Control Systems Technology},
  title    = {Detecting Integrity Attacks on SCADA Systems},
  year     = {2014},
  issn     = {1558-0865},
  month    = {July},
  number   = {4},
  pages    = {1396-1407},
  volume   = {22},
  abstract = {Ensuring security of systems based on supervisory control and data acquisition is a major challenge. The goal of this paper is to develop the model-based techniques capable of detecting integrity attacks on the sensors of a control system. In this paper, the effect of integrity attacks on the control systems is analyzed and countermeasures capable of exposing such attacks are proposed. The main contributions of this paper, beyond the novelty of the problem formulation, lies in enumerating the conditions of the feasibility of the replay attack, and suggesting countermeasures that optimize the probability of detection by conceding control performance. The methodologies are shown and the theoretical results are validated using several sets of simulations.},
  doi      = {10.1109/TCST.2013.2280899},
  groups   = {First Filtering},
  keywords = {Kalman filters;Detectors;Sensor systems;Security;SCADA systems;Control;cyber-physical systems (CPS);secure;supervisory control and data acquisition (SCADA).;Control;cyber-physical systems (CPS);secure;supervisory control and data acquisition (SCADA)},
}

@InProceedings{6934278,
  author    = {Attar, Ali El and Khatoun, Rida and Lemercier, Marc},
  booktitle = {2014 Global Information Infrastructure and Networking Symposium (GIIS)},
  title     = {A Gaussian mixture model for dynamic detection of abnormal behavior in smartphone applications},
  year      = {2014},
  month     = {Sep.},
  pages     = {1-6},
  abstract  = {Nowadays smartphones get increasingly popular which also attracted hackers. With the increasing capabilities of such phones, more and more malicious softwares targeting these devices have been developed. Malwares can seriously damage an infected device within seconds. This paper focus on the aggregation of a popular probabilistic model: the Gaussian mixture model, for a dynamic detection of the abnormal behavior in smartphone applications. More precisely, we propose to apply a mixture model estimation technique on the behavior of applications, for density modeling and data clustering. The mixture models of the different smartphones are then aggregated to estimate the global model that reflecting the probability density of the global data set. Furthermore, we carry out a model-based clustering outlier detection to compute an anomaly score for each application, leading to identify the malware applications. Initial experiments results prove the efficiency and the accuracy of the model-based clustering in detecting abnormal applications with a low false alerts rate.},
  doi       = {10.1109/GIIS.2014.6934278},
  groups    = {First Filtering},
  issn      = {2150-329X},
  keywords  = {Computational modeling;Malware;Data models;Gaussian mixture model;Measurement;Mathematical model},
}

@InProceedings{6903625,
  author    = {Hong, Jin B. and Kim, Dong Seong and Haqiq, Abdelkrim},
  booktitle = {2014 44th Annual IEEE/IFIP International Conference on Dependable Systems and Networks},
  title     = {What Vulnerability Do We Need to Patch First?},
  year      = {2014},
  month     = {June},
  pages     = {684-689},
  abstract  = {Computing a prioritized set of vulnerabilities to patch is important for system administrators to determine the order of vulnerabilities to be patched that are more critical to the network security. One way to assess and analyze security to find vulnerabilities to be patched is to use attack representation models (ARMs). However, security solutions using ARMs are optimized for only the current state of the networked system. Therefore, the ARM must reanalyze the network security, causing multiple iterations of the same task to obtain the prioritized set of vulnerabilities to patch. To address this problem, we propose to use importance measures to rank network hosts and vulnerabilities, then combine these measures to prioritize the order of vulnerabilities to be patched. We show that nearly equivalent prioritized set of vulnerabilities can be computed in comparison to an exhaustive search method in various network scenarios, while the performance of computing the set is dramatically improved, while equivalent solutions are computed in various network scenarios.},
  doi       = {10.1109/DSN.2014.68},
  groups    = {First Filtering},
  issn      = {2158-3927},
  keywords  = {Security;Measurement;Computational modeling;Equations;Mathematical model;Scalability;Analytical models;Attack Representation Model;Network Centrality;Security Analysis;Security Management;Security Metrics;Vulnerability Patch},
}

@InProceedings{7600221,
  author    = {Tang, MingJian and Alazab, Mamoun and Luo, Yuxiu},
  booktitle = {2016 Cybersecurity and Cyberforensics Conference (CCC)},
  title     = {Exploiting Vulnerability Disclosures: Statistical Framework and Case Study},
  year      = {2016},
  month     = {Aug},
  pages     = {117-122},
  abstract  = {With an ever-increasing trend of cybercrimes and incidents due to software vulnerabilities and exposures, effective and proactive vulnerability management becomes imperative in modern organisations regardless large or small. Forecasting models leveraging rich historical vulnerability disclosure data undoubtedly provide important insights to inform the cyber community with the anticipated risks. In this paper, we proposed a novel framework for statistically analysing long-term vulnerability time series between January 1999 and January 2016. By utilising this sound framework, we initiated an important study on not only testing but also modelling persistent volatilities in the data. In sharp contrast to the existing models, we consider capturing both mean and conditional variance latent in the disclosure series. Through extensive empirical studies, a composite model is shown to effectively capture the sporadic nature of vulnerability time series. In addition, this paper paves the way for further study on the stochastic perspective of cyber vulnerability proliferation towards more accurate prediction models and better risk management.},
  doi       = {10.1109/CCC.2016.10},
  groups    = {First Filtering},
  keywords  = {Market research;Biological system modeling;Time series analysis;Security;Software;Data models;Correlation;Cyber security;vulnerability;time series;volatility;generalised autoregressive conditional heteroskedasticity},
}

@InProceedings{9407842,
  author    = {Cai, Mumuxin and Sang, Nan and Wang, Xupeng and Zhang, Jingyu},
  booktitle = {2020 IEEE 22nd International Conference on High Performance Computing and Communications; IEEE 18th International Conference on Smart City; IEEE 6th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)},
  title     = {Adversarial point cloud perturbations to attack deep object detection models},
  year      = {2020},
  month     = {Dec},
  pages     = {1042-1049},
  abstract  = {The reliability of existing Cyber-Physical Systems(CPSs) developed on the basis of deep neural networks is not guaranteed, because deep models have been proved vulnerable to adversarial attacks with imperceptible perturbations. Considering that deep 3D models have potential applications to a wide variety of CPSs with safety-critical requirements, such as autonomous driving systems, we explore the robustness of deep 3D object detection models under adversarial point cloud perturbations in this paper. A novel method to generate 3D adversarial examples is developed from point cloud perturbations, which are common in practice due to the inherent characteristics of the LiDAR data produced by the 3D sensors. The method has the ability to successfully attack deep 3D models in most cases, and thereby gives rise to a great real-world concern about object detection models due to their vulnerability to physical-world attacks in the form of point cloud perturbations. We conduct a thorough robustness evaluation of popular deep 3D object detectors in an adversarial setting on the KITTI dataset. Experimental results show that current deep 3D object detection models are susceptible to adversarial attacks, and their performances are decreased to a large extent in the presence of adversarial point clouds generated by the proposed method.},
  doi       = {10.1109/HPCC-SmartCity-DSS50907.2020.00140},
  groups    = {First Filtering},
  keywords  = {Solid modeling;Three-dimensional displays;Laser radar;Perturbation methods;High performance computing;Neural networks;Object detection;adversarial attack;robustness of deep learning;3D object detection;point cloud perturbations;Cyber-Physical Systems},
}

@Article{9091531,
  author   = {Yuan, Bin and Lin, Chen and Zhao, Huan and Zou, Deqing and Yang, Laurence Tianruo and Jin, Hai and Rong, Chunming},
  journal  = {IEEE Internet of Things Journal},
  title    = {Secure Data Transportation With Software-Defined Networking and k-n Secret Sharing for High-Confidence IoT Services},
  year     = {2020},
  issn     = {2327-4662},
  month    = {Sep.},
  number   = {9},
  pages    = {7967-7981},
  volume   = {7},
  abstract = {Internet of Things (IoT) has become a critical infrastructure in smart city services. Unlike traditional network nodes, most of the current IoT devices are constrained with limited capabilities. Moreover, frequent changes in the network status (e.g., nodes turns into the sleep mode to save battery) make it even more difficult to set up a stable, secure transmission among smart city IoT devices. On the one hand, these weaknesses make the IoT more vulnerable to attacks, such as data eavesdropping, which can monitor, tamper, and obtain the transporting data. On the other hand, the high-confidence smart city service strongly relies on the security of data transporting among the IoT devices, e.g., data being tempered would reduce the reliability of smart city services and data being monitored or stolen would infringe the privacy of smart city services. Toward high-confidence smart city IoT services, we proposed an approach to secure the data transportation among the smart city IoT devices, which combines a k-n secret-sharing mechanism and software-defined networking (SDN) technique to securely transport IoT data. Specifically, the data are transported by multiple routes calculated by the SDN controller adaptively. Data safety is guaranteed by the all-or-nothing feature of the k-n secret-sharing mechanism. Two SDN-based transmission strategies, which leverage the SDN's advantages on network management, and scheduling, are applied to overcome the challenges of the unstable network state in IoT. Extensive experiments conducted from many aspects show that the proposed approach can remarkably reduce the attack success rate with reasonable and acceptable overhead.},
  doi      = {10.1109/JIOT.2020.2993587},
  groups   = {First Filtering},
  keywords = {Smart cities;Internet of Things;Eavesdropping;Encryption;Transportation;High-confidence Internet-of-Things (IoT) services;IoT;secure data transportation;smart city;software-defined networking (SDN)},
}

@Article{8693904,
  author   = {Zolanvari, Maede and Teixeira, Marcio A. and Gupta, Lav and Khan, Khaled M. and Jain, Raj},
  journal  = {IEEE Internet of Things Journal},
  title    = {Machine Learning-Based Network Vulnerability Analysis of Industrial Internet of Things},
  year     = {2019},
  issn     = {2327-4662},
  month    = {Aug},
  number   = {4},
  pages    = {6822-6834},
  volume   = {6},
  abstract = {It is critical to secure the Industrial Internet of Things (IIoT) devices because of potentially devastating consequences in case of an attack. Machine learning (ML) and big data analytics are the two powerful leverages for analyzing and securing the Internet of Things (IoT) technology. By extension, these techniques can help improve the security of the IIoT systems as well. In this paper, we first present common IIoT protocols and their associated vulnerabilities. Then, we run a cyber-vulnerability assessment and discuss the utilization of ML in countering these susceptibilities. Following that, a literature review of the available intrusion detection solutions using ML models is presented. Finally, we discuss our case study, which includes details of a real-world testbed that we have built to conduct cyber-attacks and to design an intrusion detection system (IDS). We deploy backdoor, command injection, and Structured Query Language (SQL) injection attacks against the system and demonstrate how a ML-based anomaly detection system can perform well in detecting these attacks. We have evaluated the performance through representative metrics to have a fair point of view on the effectiveness of the methods.},
  doi      = {10.1109/JIOT.2019.2912022},
  groups   = {First Filtering},
  keywords = {Internet of Things;Electromagnetic interference;Cyber attack;Industrial Internet of Things (IIoT);intrusion detection;machine learning (ML);network security;supervisory control and data acquisition (SCADA);vulnerability assessment},
}

@InProceedings{8424630,
  author    = {Kos, Jernej and Fischer, Ian and Song, Dawn},
  booktitle = {2018 IEEE Security and Privacy Workshops (SPW)},
  title     = {Adversarial Examples for Generative Models},
  year      = {2018},
  month     = {May},
  pages     = {36-42},
  abstract  = {We explore methods of producing adversarial examples on deep generative models such as the variational autoencoder (VAE) and the VAE-GAN. Deep learning architectures are known to be vulnerable to adversarial examples, but previous work has focused on the application of adversarial examples to classification tasks. Deep generative models have recently become popular due to their ability to model input data distributions and generate realistic examples from those distributions. We present three classes of attacks on the VAE and VAE-GAN architectures and demonstrate them against networks trained on MNIST, SVHN and CelebA. Our first attack leverages classification-based adversaries by attaching a classifier to the trained encoder of the target generative model, which can then be used to indirectly manipulate the latent representation. Our second attack directly uses the VAE loss function to generate a target reconstruction image from the adversarial example. Our third attack moves beyond relying on classification or the standard loss for the gradient and directly optimizes against differences in source and target latent representations. We also motivate why an attacker might be interested in deploying such techniques against a target generative network.},
  doi       = {10.1109/SPW.2018.00014},
  groups    = {First Filtering},
  keywords  = {Image reconstruction;Receivers;Training;Image coding;Decoding;Machine learning;Data models;Adversarial examples;generative models;vae;vae gan},
}

@InProceedings{9018647,
  author    = {Zhang, Jinlan and Yan, Qiao and Wang, Mingde},
  booktitle = {2019 Computing, Communications and IoT Applications (ComComAp)},
  title     = {Evasion Attacks Based on Wasserstein Generative Adversarial Network},
  year      = {2019},
  month     = {Oct},
  pages     = {454-459},
  abstract  = {Security issues have been accompanied by the development of the artificial intelligence industry. Machine learning has been widely used for fraud detection, spam detection, and malicious file detection, since it has the ability to dig the value of big data. However, for malicious attackers, there is a strong motivation to evade such algorithms. Because attackers do not know the specific parameters of the machine model, they can only carry out a black box attack. This paper proposes a method based on Wasserstein Generative Adversarial Network(WGAN) to generate malicious PDF files which are similar to benign ones and can evade the malicious file detection system. The experimental results show that the adversarial examples generated by our method can evade the PDF classifier-PDFrate of 100%. We also test their performance in different classifiers and the results show that our proposed method can evade the classifiers of different machine learning algorithms such as Support Vector Machine(SVM), Linear Regression, Decision Tree, Random Forest.},
  doi       = {10.1109/ComComAp46287.2019.9018647},
  groups    = {First Filtering},
  keywords  = {Machine learning;Data models;Gallium nitride;Probability distribution;Generators;Training;Portable document format;WGAN;Evasion Attacks;Malicious Document Detection},
}

@InProceedings{8005665,
  author    = {Bou-Harb, Elias and Kaisar, Evangelos I. and Austin, Mark},
  booktitle = {2017 5th IEEE International Conference on Models and Technologies for Intelligent Transportation Systems (MT-ITS)},
  title     = {On the impact of empirical attack models targeting marine transportation},
  year      = {2017},
  month     = {June},
  pages     = {200-205},
  abstract  = {It is known that 75% of international freight is through maritime transportation. Indeed, as international trade increases, ports face the pressure to improve their infrastructure in order to maintain their operations and respond to market demands. Given such high level of competition, ports ought to leverage their resources efficiently and effectively, which has resulted in increased automation capabilities and the adoption of Cyber-Physical Systems (CPS). For such reasons, the container terminal sector is increasingly becoming susceptible to various types of debilitating threats. While a plethora of research efforts, from both, the control and cyber perspectives have been dedicated to tackling the security of CPS in such sectors, there still exists a significant gap, which is rendered by the lack of properly comprehending and accurately characterizing malicious attackers' capabilities, intents and aims, when targeting such systems. This is largely due to the lack of real malicious empirical data that can be captured, inferred, and analyzed from within the boundaries of such operational CPS realms. Undoubtedly, the goal which endeavors to capture notions of “true maliciousness” in the context of such CPS is significantly challenging, due to many factors, including, (1) the lack of complete maturity and the scarcity of elaborative technical details related to such CPS, (2) the significant diversity of such types of systems, and (3) logistic and privacy constraints which are often strictly enforced by CPS owners and operators. To this end, this paper presents a first step towards inferring tangible notions of maliciousness in the context of maritime transportation. This is accomplished through innovating various mechanisms, namely, investigating passive darknet Internet-scale traffic, instrumenting and analyzing millions of recent CPS malware samples, and deploying tailored, highly-interactive CPS honeypots. Additionally, we analyze the effect of a derived empirical attack, namely, a Distributed Denial of Service (DDoS) attack, using a discrete event simulation in the context of a vessel passing a canal. We postulate that the envisioned derived attack models and their associated impact could be effectively exploited to successfully provide CPS marine transportation security and resiliency.},
  doi       = {10.1109/MTITS.2017.8005665},
  groups    = {First Filtering},
  keywords  = {Security;Sensors;Ports (Computers);Marine transportation;Control systems;Transportation;Containers;Empirical analysis;Cyber-Physical Systems;CPS attacks;Marine Transportation;Model-Based Systems},
}

@InProceedings{8449537,
  author    = {Gao, Jun and Li, Li and Kong, Pingfan and Bissyandé, Tegawendé F. and Klein, Jacques},
  booktitle = {2018 IEEE/ACM 40th International Conference on Software Engineering: Companion (ICSE-Companion)},
  title     = {Poster: On Vulnerability Evolution in Android Apps},
  year      = {2018},
  month     = {May},
  pages     = {276-277},
  abstract  = {In this work, we reconstruct a set of Android app lineages which each of them represents a sequence of app versions that are historically released for the same app. Then, based on these lineages, we empirically investigate the evolution of app vulnerabilities, which are revealed by well-known vulnerability scanners, and subsequently summarise various interesting findings that constitute a tangible knowledge to the community.},
  groups    = {First Filtering},
  issn      = {2574-1934},
  keywords  = {Androids;Humanoid robots;Security;Tools;Ecosystems;Software;History;Android;Vulnerability;App Evolution},
}

@InProceedings{6246083,
  author    = {Mahboubian, Mohammad and Udzir, Nur Izura and Subramaniam, Shamala and Abdul Hamid, Nor Asila Wati},
  booktitle = {Proceedings Title: 2012 International Conference on Cyber Security, Cyber Warfare and Digital Forensic (CyberSec)},
  title     = {An alert fusion model inspired by artificial immune system},
  year      = {2012},
  month     = {June},
  pages     = {317-322},
  abstract  = {In the recent years one of the most focused topics in the field of network security and more specifically intrusion detection systems was to find a solution to reduce the overwhelming alerts generated by IDSs in the network. Inspired by human defence system and danger theory we propose a complementary subsystem for IDS which can be integrated into any existing IDS models to aggregate the alerts in order to reduce them, and subsequently reduce false alarms among the alerts. After evaluation using different datasets and attack scenarios, our model managed to aggregate the alerts by the average rate of 97.5 percent.},
  doi       = {10.1109/CyberSec.2012.6246083},
  groups    = {First Filtering},
  keywords  = {Correlation;IP networks;Computational modeling;Immune system;Aggregates;Intrusion detection;Intrusion detection system;Alert fusion;Alert correlation;Artificial Immune system;Danger theory},
}

@InProceedings{8455927,
  author    = {Wei, Shuang and Dai, Shuaifu and Wu, Xinfeng and Han, Xinhui},
  booktitle = {2018 17th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/ 12th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE)},
  title     = {STDC: A SDN-Oriented Two-Stage DDoS Detection and Defence System Based on Clustering},
  year      = {2018},
  month     = {Aug},
  pages     = {339-347},
  abstract  = {DDoS has now become the most severe security problem of the Internet. Without in time report, DDoS attack can knock down the victim in no time by exhausting the victim's computing and communicating resources. In this paper we propose STDC-a DDoS defense system. STDC is a two-stage system based on clustering. In the first stage STDC leverage the benefit of SDN and NFV to apply flow-based detection method. STDC use the flow information gathered to do clustering. Since we use cluster analysis as the basic detection algorithm, STDC can separate the DDoS attacks from the legitimate flush crowd easily. In the second stage, we extract attack traffic pattern from the clustering result of the first stage to make blocking rules and use the structure of SDN to quickly dispatch them to achieve effictive and efficient DDoS mitigation. We test STDC using public DDoS dataset and the traffic captured through the gateway. Both of the experiments achieve good detection percision and high filtering ratio.},
  doi       = {10.1109/TrustCom/BigDataSE.2018.00059},
  groups    = {First Filtering},
  issn      = {2324-9013},
  keywords  = {Computer crime;Hardware;Control systems;Feature extraction;Software;Electronic mail;DDoS;SDN;Clustering;Detection;Mitigation},
}

@InProceedings{7381996,
  author    = {Liang Hu and Taihui Li and Nannan Xie and Jiejun Hu},
  booktitle = {2015 12th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)},
  title     = {False positive elimination in intrusion detection based on clustering},
  year      = {2015},
  month     = {Aug},
  pages     = {519-523},
  abstract  = {In order to solve the problem of high false positive in network intrusion detection systems, we adopted clustering algorithms, the K-means algorithm and the Fuzzy C Mean (FCM) algorithm, to identify false alerts, to reduce invalid alerts and to purify alerts for a better analysis. In this paper, we first introduced typical clustering algorithms, including the partition clustering, the hierarchical clustering, the density and grid clustering, and the fuzzy clustering, and then analyzed their feasibilities in security data processing. Furthermore, we introduced an intrusion detection framework, and tested the validity and feasibility of false positive elimination in intrusion detection. The process steps of false positive elimination were clearly described, and additionally, two typical clustering algorithms, the K-means algorithm and the FCM algorithm, were implemented for false alerts identification and filtration. Also, we defined three evaluation indexes: the elimination rate, the false elimination rate and the miss elimination rate. Accordingly, we used DARPA 2000 LLDOS1.0 dataset for our experiments, and adopted Snort as our intrusion detection system. Eventually, the results showed that the method proposed by us has a satisfactory validity and feasibility in false positive elimination, and the clustering algorithms we adopted can achieve a high elimination rate.},
  doi       = {10.1109/FSKD.2015.7381996},
  groups    = {First Filtering},
  keywords  = {Clustering algorithms;Intrusion detection;Linear programming;Partitioning algorithms;Algorithm design and analysis;Indexes;Intrusion Detection;False Positive Elimination;K-means;FCM},
}

@InProceedings{8940544,
  author    = {Bansal, Saumya and Baliyan, Niyati},
  booktitle = {2019 International Conference on Computing, Power and Communication Technologies (GUCON)},
  title     = {Evaluation of Collaborative Filtering Based Recommender Systems against Segment-Based Shilling Attacks},
  year      = {2019},
  month     = {Sep.},
  pages     = {110-114},
  abstract  = {Collaborative filtering (CF) is a successful and hence most widely used technique for recommender systems. However, it is vulnerable to shilling attack due to its open nature, which results in generating biased or false recommendations for users. In literature, segment attack (push attack) has been widely studied and investigated while rare studies have been performed on nuke attack, to the best of our knowledge. Further, the robustness of binary collaborative filtering and hybrid approach has not been investigated against segment-focused attack. In this paper, from the perspective of robustness, binary collaborative filtering, hybrid approach, stand-alone rating user-based, and stand-alone rating item- based recommendation have been evaluated against segment attack on a large dataset (100K ratings) which is found to be more successful as it attacks target set of items. With an aim to find an approach which reflects a higher accuracy in recommending items and is less vulnerable to segment-based attack, the possibility of any relationship between accuracy and vulnerability of six CF approaches were studied. Such an approach needs to be re-examined by the researchers marking the future of recommender system (RS). Experimental results show negligible positive correlation between accuracy and vulnerability of techniques. Publicly available dataset namely MovieLens was used for conducting experiments. Robustness and accuracy of CF techniques were calculated using prediction shift and F-measure, respectively.},
  groups    = {First Filtering},
  keywords  = {Motion pictures;Correlation;Recommender systems;Robustness;Databases;Measurement;recommender system;segmentation attack;binary rating;hybrid system;accuracy;vulnerability},
}

@InProceedings{9402124,
  author    = {Huang, Yujin and Hu, Han and Chen, Chunyang},
  booktitle = {2021 IEEE/ACM 43rd International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)},
  title     = {Robustness of on-Device Models: Adversarial Attack to Deep Learning Models on Android Apps},
  year      = {2021},
  month     = {May},
  pages     = {101-110},
  abstract  = {Deep learning has shown its power in many applications, including object detection in images, natural-language understanding, and speech recognition. To make it more accessible to end users, many deep learning models are now embedded in mobile apps. Compared to offloading deep learning from smartphones to the cloud, performing machine learning on-device can help improve latency, connectivity, and power consumption. However, most deep learning models within Android apps can easily be obtained via mature reverse engineering, while the models' exposure may invite adversarial attacks. In this study, we propose a simple but effective approach to hacking deep learning models using adversarial attacks by identifying highly similar pre-trained models from TensorFlow Hub. All 10 real-world Android apps in the experiment are successfully attacked by our approach. Apart from the feasibility of the model attack, we also carry out an empirical study that investigates the characteristics of deep learning models used by hundreds of Android apps on Google Play. The results show that many of them are similar to each other and widely use fine-tuning techniques to pre-trained models on the Internet.},
  doi       = {10.1109/ICSE-SEIP52600.2021.00019},
  groups    = {First Filtering},
  keywords  = {Deep learning;Reverse engineering;Speech recognition;Robustness;Computer crime;Smart phones;Software engineering;deep learning, mobile apps, Android, security, adversarial attack},
}

@Article{9167280,
  author   = {Zhu, Tiantian and Fu, Lei and Liu, Qiang and Lin, Zi and Chen, Yan and Chen, Tieming},
  journal  = {IEEE Transactions on Information Forensics and Security},
  title    = {One Cycle Attack: Fool Sensor-Based Personal Gait Authentication With Clustering},
  year     = {2021},
  issn     = {1556-6021},
  pages    = {553-568},
  volume   = {16},
  abstract = {Gait authentication, especially sensor-based patterns, has been studied by researchers for decades. Nowadays, gait authentication has become an important facet of biometric systems due to the so-called unique characteristics of each user. With the development of various technologies (i.e., hardware, data processing, features extraction, and learning algorithms), the performance of sensor-based authentication methods is gradually improving. But we have found that the vulnerability of most existing methods can be compromised easily. In this paper, we propose a novel attack model, called one cycle attack, to bypass existing gait authentication methods. Firstly, the gait sequence is divided into multiple gait cycles. By adopting the K-mean algorithm, we get the average distance of each feature sample (extracted from the gait cycle) to its closest cluster center, and its result confirms that independent individuals may have similar gait cycles. Secondly, using six state-of-the-art models it was found that the adversarial gait cycle found with the clustering method can bypass the victim's model rapidly. Furthermore, to improve the accuracy of sensor-based gait authentication methods to fight against attacks, we present a WPD-LSTM (Wavelet Packet Decomposition and Long Short-Term Memory) multi-cycle defense model which considers the contextual contents of the neighboring gait cycles in the gait sequence. Experimental results on two datasets (the largest public sensor-based gait database OU-ISIR and new dataset from our laboratory) show that our attack model can bypass most of the victims' models within a limited number of attempts. Specifically, we can compromise 20%-80% of users within 5 attempts by utilizing imitation. On the contrary, the success rate of attackers has been greatly mitigated by deploying our multi-cycle defense model.},
  doi      = {10.1109/TIFS.2020.3016819},
  groups   = {First Filtering},
  keywords = {Authentication;Biological system modeling;Mobile handsets;Legged locomotion;Context modeling;Databases;Gait authentication;motion sensor;attack and defense;adversarial gait cycle;deep learning},
}

@InProceedings{6778962,
  author    = {Ahn, Sung-Hwan and Kim, Nam-Uk and Chung, Tai-Myoung},
  booktitle = {16th International Conference on Advanced Communication Technology},
  title     = {Big data analysis system concept for detecting unknown attacks},
  year      = {2014},
  month     = {Feb},
  pages     = {269-272},
  abstract  = {Recently, threat of previously unknown cyber-attacks are increasing because existing security systems are not able to detect them. Past cyber-attacks had simple purposes of leaking personal information by attacking the PC or destroying the system. However, the goal of recent hacking attacks has changed from leaking information and destruction of services to attacking large-scale systems such as critical infrastructures and state agencies. In the other words, existing defence technologies to counter these attacks are based on pattern matching methods which are very limited. Because of this fact, in the event of new and previously unknown attacks, detection rate becomes very low and false negative increases. To defend against these unknown attacks, which cannot be detected with existing technology, we propose a new model based on big data analysis techniques that can extract information from a variety of sources to detect future attacks. We expect our model to be the basis of the future Advanced Persistent Threat(APT) detection and prevention system implementations.},
  doi       = {10.1109/ICACT.2014.6778962},
  groups    = {First Filtering},
  issn      = {1738-9445},
  keywords  = {Information management;Data handling;Data storage systems;Security;Data mining;Data models;Monitoring;Computer crime;Alarm systems;Intrusion detection;Data mining},
}

@InProceedings{6702697,
  author    = {Basney, Jim and Welch, Von},
  booktitle = {2013 IEEE International Conference on Cluster Computing (CLUSTER)},
  title     = {Science gateway security recommendations},
  year      = {2013},
  month     = {Sep.},
  pages     = {1-3},
  abstract  = {A science gateway is a web portal that provides a convenient interface to data and applications in support of a research community. Standard security concerns apply to science gateways, including confidentiality of pre-publication research data, integrity of research results, and availability of services provided to researchers. In this paper we identify existing science gateway security recommendations and provide our own perspective.},
  doi       = {10.1109/CLUSTER.2013.6702697},
  groups    = {First Filtering},
  issn      = {2168-9253},
  keywords  = {Logic gates;Communities;Authentication;Portals;Servers;Educational institutions;science gateways;security},
}

@Article{8954698,
  author   = {Zhang, Xueqin and Zhou, Yue and Pei, Songwen and Zhuge, Jingjing and Chen, Jiahao},
  journal  = {IEEE Access},
  title    = {Adversarial Examples Detection for XSS Attacks Based on Generative Adversarial Networks},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {10989-10996},
  volume   = {8},
  abstract = {Models based on deep learning are prone to misjudging the results when faced with adversarial examples. In this paper, we propose an MCTS-T algorithm for generating adversarial examples of cross-site scripting (XSS) attacks based on Monte Carlo tree search (MCTS) algorithm. The MCTS algorithm enables the generation model to provide a reward value that reflects the probability of generative examples bypassing the detector. To guarantee the antagonism and feasibility of the generative adversarial examples, the bypassing rules are restricted. The experimental results indicate that the missed detection rate of adversarial examples is significantly improved after the MCTS-T generation algorithm. Additionally, we construct a generative adversarial network (GAN) to optimize the detector and improve the detection rate when dealing with adversarial examples. After several epochs of adversarial training, the accuracy of detecting adversarial examples is significantly improved.},
  doi      = {10.1109/ACCESS.2020.2965184},
  groups   = {First Filtering},
  keywords = {Deep learning;Training;Feature extraction;Gallium nitride;Encoding;Detectors;Malware;Network intrusion detection;generative adversarial network;Monte Carlo tree;convolutional neural networks},
}

@Article{9121236,
  author   = {Liu, Shumei and Yu, Yao and Hu, Wenjian and Peng, Yuhuai and Yang, Xiaolong},
  journal  = {IEEE Access},
  title    = {Intelligent Vulnerability Analysis for Connectivity and Critical-Area Integrity in IoV},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {114239-114248},
  volume   = {8},
  abstract = {The large-scale connectivity of Internet of Vehicles (IoV) is an important challenge for the Intelligent Transportation Systems (ITS). Intelligence vulnerability analysis is an excellent solution. However, existing methods for analyzing connectivity vulnerability have ignored the existence of critical areas in the system. Due to the heterogeneities of the IoV environments and services, the failure of some specific areas may seriously damage connectivity and system performance. To this end, in this paper we focus on both the dynamic connectivity and the critical-area integrity, and propose an intelligent vulnerability analysis method to effectively identify the critical area of extreme vulnerability. Specifically, we consider an intelligent analysis scenario in which roadside servers continuously learn IoV heterogeneous environment and dynamic topology, and then translate the learning results into a flexible disruption cost problem. Based on this, we utilize the spectral partitioning method to identify the minimum-cost set of topological elements whose failure not only severely damages system connectivity but also disrupts its critical areas. Furthermore, we confirm that the identified set can be used to optimize disruption cost problem, thus intelligently improving vulnerability. Simulation results show that our proposed method can effectively identify vulnerable elements and prevent significant loss in the IoV system connectivity and performance.},
  doi      = {10.1109/ACCESS.2020.3003808},
  groups   = {First Filtering},
  keywords = {Artificial intelligence;Vehicle dynamics;Security;Topology;Intelligent vehicles;Servers;Intelligent transportation systems (ITS);Internet of Vehicles (IoV);intelligence vulnerability analysis;connectivity;critical area},
}

@InProceedings{9060371,
  author    = {Balogh, Andrea and Mehta, Deepak and Sobonski, Piotr and Mady, Alieldin and Vuppala, Satyanarayana},
  booktitle = {2019 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)},
  title     = {Learning Constraint-Based Model for Detecting Malicious Activities in Cyber Physical Systems},
  year      = {2019},
  month     = {Aug},
  pages     = {1392-1399},
  abstract  = {Advances in computing, communications, sensors, and cloud computing have resulted in the proliferation of Internet of Things (IoT) which forms a foundation for Cyber-Physical Systems (CPS). Cyber-physical attacks can cause tangible effects in the physical world. The attacker's goal is to disrupt the normal operations of the CPS for example: equipment overstress, safety limits violation, damage to the product quality, safety compliance violation etc. The continued rise of cyber-attacks together with the evolving skills of the attackers, and the inefficiency of the traditional security algorithms to defend against advanced and sophisticated attacks such as Distributed Denial of service (DDoS), slow DoS and zero-day, necessitate the development of novel defense and resilient detection techniques compared to traditional approaches like signature and behavior-based methods. To deal with this, we propose a novel approach for learning detection model that includes operational and network data to detect advanced attacks. More precisely, our approach is able to learn a relational network that connects events at different system layers so that attacks can be identified with higher confidence level. In this paper, we propose a decision model by learning a set of constraints/relations from the data that conjunctively defines the normal operation of a CPS. The solutions of the decision model characterize the normal states of a given CPS. The malicious operations are detected when one or more constraints fail for a given state of CPS. The results demonstrates the effectiveness of the approach. The main advantage of our approach is the interpretability of the model.},
  doi       = {10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00253},
  groups    = {First Filtering},
  keywords  = {Data models;Feature extraction;Monitoring;Sensors;Intrusion detection;Safety;Constraint Programming;Cyber-Physical Systems;Model learning;Anomaly detection},
}

@Article{9352750,
  author   = {Weerasinghe, Sandamal and Alpcan, Tansu and Erfani, Sarah M. and Leckie, Christopher},
  journal  = {IEEE Transactions on Information Forensics and Security},
  title    = {Defending Support Vector Machines Against Data Poisoning Attacks},
  year     = {2021},
  issn     = {1556-6021},
  pages    = {2566-2578},
  volume   = {16},
  abstract = {Support Vector Machines (SVMs) are vulnerable to targeted training data manipulations such as poisoning attacks and label flips. By carefully manipulating a subset of training samples, the attacker forces the learner to compute an incorrect decision boundary, thereby causing misclassifications. Considering the increased importance of SVMs in engineering and life-critical applications, we develop a novel defense algorithm that improves resistance against such attacks. Local Intrinsic Dimensionality (LID) is a promising metric that characterizes the outlierness of data samples. In this work, we introduce a new approximation of LID called K-LID that uses kernel distance in the LID calculation, which allows LID to be calculated in high dimensional transformed spaces. We introduce a weighted SVM against such attacks using K-LID as a distinguishing characteristic that de-emphasizes the effect of suspicious data samples on the SVM decision boundary. Each sample is weighted on how likely its K-LID value is from the benign K-LID distribution rather than the attacked K-LID distribution. Experiments with benchmark data sets show that the proposed defense reduces classification error rates substantially (10% on average).},
  doi      = {10.1109/TIFS.2021.3058771},
  groups   = {First Filtering},
  keywords = {Support vector machines;Training;Training data;Kernel;Optimization;Resistance;Detectors;Label flip attack;poisoning attack;support vector machines;local intrinsic dimensionality},
}

@Article{9094360,
  author   = {Ullah, Syed Sajid and Ullah, Insaf and Khattak, Hizbullah and Khan, Muhammad Asghar and Adnan, Muhammad and Hussain, Saddam and Amin, Noor Ul and Khattak, Muazzam A. Khan},
  journal  = {IEEE Access},
  title    = {A Lightweight Identity-Based Signature Scheme for Mitigation of Content Poisoning Attack in Named Data Networking With Internet of Things},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {98910-98928},
  volume   = {8},
  abstract = {Named Data Networking (NDN) is one of the future envisioned networking paradigm used to provide fast and efficient content dissemination with interest-based content retrieval, name-based routing and in-network content caching. On the one hand, this new breed of future Internet architecture is becoming a key technology for data dissemination in the IoT networks; on the other hand, NDN suffers from new challenges in terms of data security. Among them, a content poisoning attack is the most common data security challenge. The aim of this attack is to inject poisoned content with an invalid signature to the network. Therefore, to prevent NDN against possible content poisoning attack, a signature of the contents is appended to each data packet for verifications. In this paper, we propose an identity-based signature scheme for IoT-based NDN networks, with a special emphasis on content integrity and authenticity. The proposed scheme is based on the concept of the Hyperelliptic curves, which provide the same level of security as Rivest-Shamir-Adleman (RSA), Bilinear pairing and Elliptic Curve Cryptosystems (ECC) with lower-key size. The proposed scheme is subject to both formal and informal security analysis in order to show the feasibility of our scheme. Finally, the performance of the proposed scheme is analyzed via comparison with the relevant existing schemes that authenticates the superiority of our scheme in terms of security and efficiency.},
  doi      = {10.1109/ACCESS.2020.2995080},
  groups   = {First Filtering},
  keywords = {Internet of Things;Elliptic curve cryptography;Routing protocols;Licenses;Content poisoning attack;named data networking (NDN);Internet of Things;identity-based signature},
}

@InProceedings{9275580,
  author    = {Pliatsios, Dimitrios and Sarigiannidis, Panagiotis and Psannis, Konstantinos and Goudos, Sotirios K. and Vitsas, Vasileios and Moscholios, Ioannis},
  booktitle = {2020 3rd World Symposium on Communication Engineering (WSCE)},
  title     = {Big Data against Security Threats: The SPEAR Intrusion Detection System},
  year      = {2020},
  month     = {Oct},
  pages     = {12-17},
  abstract  = {The environmental concerns, the limited availability of conventional energy sources, the integration of alternative energy sources and the increasing number of power-demanding appliances change the way electricity is generated and distributed. Smart Grid (SG) is an appealing concept, which was developed in response to the emerging issues of electricity generation and distribution. By leveraging the latest advancements of Information and Communication Technologies (ICT), it offers significant benefits to energy providers, retailers and consumers. Nevertheless, SG is vulnerable to cyber attacks, that could cause critical economic and ecological consequences. Traditional Intrusion Detection Systems (IDSs) are becoming less efficient in detecting and mitigating cyberattacks, due to their limited capabilities of analyzing the exponentially increasing volume of network traffic. In this paper, we present the Secure and PrivatE smArt gRid (SPEAR) platform, which features a Big Data enabled IDS that timely detects and identifies cyber attacks against SG components. In order to validate the efficiency of the SPEAR platform regarding the protection of critical infrastructure, we installed the platform in a small wind power plant.},
  doi       = {10.1109/WSCE51339.2020.9275580},
  groups    = {First Filtering},
  keywords  = {Smart grids;Big Data;Feature extraction;Intrusion detection;Classification algorithms;Smart meters;Tools;big data;cyber attack;intrusion detection system;smart grid},
}

@InProceedings{9342972,
  author    = {Fernandes, Tiago and Dias, Luis and Correia, Miguel},
  booktitle = {2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)},
  title     = {C2BID: Cluster Change-Based Intrusion Detection},
  year      = {2020},
  month     = {Dec},
  pages     = {310-319},
  abstract  = {The paper presents a network intrusion detection approach that flags malicious activity without previous knowledge about attacks or training data. The Cluster Change-Based Intrusion Detection approach (C2BID) detects intrusions by monitoring host behavior changes. For that purpose, C2BID defines and extracts features from network data, aggregates hosts with similar behavior using clustering, then analyses how hosts move between clusters along a period of time. This contrasts with previous work in the area that stops at the clustering step. We evaluated C2BID experimentally with two datasets, obtaining better F-Score than previous solutions.},
  doi       = {10.1109/TrustCom50675.2020.00051},
  groups    = {First Filtering},
  issn      = {2324-9013},
  keywords  = {Training data;Network intrusion detection;Traffic control;Feature extraction;Computer security;Monitoring;Unsupervised learning;network intrusion detection;clustering;behavior change;security analytics},
}

@InProceedings{8835220,
  author    = {Joslin, Matthew and Li, Neng and Hao, Shuang and Xue, Minhui and Zhu, Haojin},
  booktitle = {2019 IEEE Symposium on Security and Privacy (SP)},
  title     = {Measuring and Analyzing Search Engine Poisoning of Linguistic Collisions},
  year      = {2019},
  month     = {May},
  pages     = {1311-1325},
  abstract  = {Misspelled keywords have become an appealing target in search poisoning, since they are less competitive to promote than the correct queries and account for a considerable amount of search traffic. Search engines have adopted several countermeasure strategies, e.g., Google applies automated corrections on queried keywords and returns search results of the corrected versions directly. However, a sophisticated class of attack, which we term as linguistic-collision misspelling, can evade auto-correction and poison search results. Cybercriminals target special queries where the misspelled terms are existent words, even in other languages (e.g., "idobe", a misspelling of the English word "adobe", is a legitimate word in the Nigerian language). In this paper, we perform the first large-scale analysis on linguistic-collision search poisoning attacks. In particular, we check 1.77 million misspelled search terms on Google and Baidu and analyze both English and Chinese languages, which are the top two languages used by Internet users. We leverage edit distance operations and linguistic properties to generate misspelling candidates. To more efficiently identify linguistic-collision search terms, we design a deep learning model that can improve collection rate by 2.84x compared to random sampling. Our results show that the abuse is prevalent: around 1.19% of linguistic-collision search terms on Google and Baidu have results on the first page directing to malicious websites. We also find that cybercriminals mainly target categories of gambling, drugs, and adult content. Mobile-device users disproportionately search for misspelled keywords, presumably due to small screen for input. Our work highlights this new class of search engine poisoning and provides insights to help mitigate the threat.},
  doi       = {10.1109/SP.2019.00025},
  groups    = {First Filtering},
  issn      = {2375-1207},
  keywords  = {Search engines;Google;Deep learning;Toxicology;Recurrent neural networks;Linguistics;Drugs;search-engine-poisoning;recurrent-neural-network;pinyin;linguistic-collision-misspelling},
}

@Article{9218975,
  author   = {Appiah-Kubi, Jennifer and Liu, Chen-Ching},
  journal  = {IEEE Open Access Journal of Power and Energy},
  title    = {Decentralized Intrusion Prevention (DIP) Against Co-Ordinated Cyberattacks on Distribution Automation Systems},
  year     = {2020},
  issn     = {2687-7910},
  pages    = {389-402},
  volume   = {7},
  abstract = {Integration of Information and Communications Technology (ICT) into the distribution system makes today's power grid more remotely monitored and controlled than it has been. The fast increasing connectivity, however, also implies that the distribution grid today, or smart grid, is more vulnerable. Thus, research into intrusion/anomaly detection systems at the distribution level is in critical need. Current research on Intrusion Detection Systems for the power grid has been focused primarily on cyber security at the Supervisory Control And Data Acquisition, and single node levels with little attention on coordinated cyberattacks at multiple nodes. A holistic approach toward system-wide cyber security for distribution systems is yet to be developed. This paper presents a novel approach toward intrusion prevention, using a multi-agent system, at the distribution system level. Simulations of the method have been performed on the IEEE 13-Node Test Feeder, and the results compared to those obtained from existing methods. The results have validated the performance of the proposed method for protection against cyber intrusions at the distribution system level.},
  doi      = {10.1109/OAJPE.2020.3029805},
  groups   = {First Filtering},
  keywords = {Computer crime;Intrusion detection;SCADA systems;Indexes;Correlation;Substations;Cyber-physical system security;smart grid;distribution systems;intrusion detection;anomaly detection;multi-agent system},
}

@InProceedings{6258133,
  author    = {Zhuang, Weiwei and Jiang, Qingshan and Xiong, Tengke},
  booktitle = {2012 32nd International Conference on Distributed Computing Systems Workshops},
  title     = {An Intelligent Anti-phishing Strategy Model for Phishing Website Detection},
  year      = {2012},
  month     = {June},
  pages     = {51-56},
  abstract  = {As a new form of malicious software, phishing websites appear frequently in recent years, which cause great harm to online financial services and data security. In this paper, we design and implement an intelligent model for detecting phishing websites. In this model, we extract 10 different types of features such as title, keyword and link text information to represent the website. Heterogeneous classifiers are then built based on these different features. We propose a principled ensemble classification algorithm to combine the predicted results from different phishing detection classifiers. Hierarchical clustering technique has been employed for automatic phishing categorization. Case studies on large and real daily phishing websites collected from King soft Internet Security Lab demonstrate that our proposed model outperforms other commonly used anti-phishing methods and tools in phishing website detection.},
  doi       = {10.1109/ICDCSW.2012.66},
  groups    = {First Filtering},
  issn      = {2332-5666},
  keywords  = {Feature extraction;Training;Security;Clustering algorithms;Support vector machines;Classification algorithms;Internet;Phishing Website;Data Security;Clustering;Classification Ensemble},
}

@Article{8726136,
  author   = {Jin, Hai and Li, Zhi and Zou, Deqing and Yuan, Bin},
  journal  = {IEEE Transactions on Dependable and Secure Computing},
  title    = {DSEOM: A Framework for Dynamic Security Evaluation and Optimization of MTD in Container-Based Cloud},
  year     = {2021},
  issn     = {1941-0018},
  month    = {May},
  number   = {3},
  pages    = {1125-1136},
  volume   = {18},
  abstract = {Due to the lightweight features, the combination of container technology and microservice architecture makes container-based cloud environment more efficient and agile than VM-based cloud environment. However, it also greatly amplifies the dynamism and complexity of the cloud environment and increases the uncertainty of security issues in the system concurrently. In this case, the effectiveness of defense mechanisms with fixed strategies would fluctuate as the updates occur in cloud environment. We refer this problem as effectiveness drift problem of defense mechanisms, which is particularly acute in the proactive defense mechanisms, such as moving target defense (MTD). To tackle this problem, we present DSEOM, a framework that can automatically perceive updates of container-based cloud environment, rapidly evaluate the effectiveness change of MTD and dynamically optimize MTD strategies. Specifically, we establish a multi-dimensional attack graphs model to formalize various complex attack scenarios. Combining with this model, we introduce the concept of betweenness centrality to effectively evaluate and optimize the implementation strategies of MTD. In addition, we present a series of security and performance metrics to quantify the effectiveness of MTD strategies in DSEOM. And we conduct extensive experiments to illustrate the existence of the effectiveness drift problem and demonstrate the usability and scalability of DSEOM.},
  doi      = {10.1109/TDSC.2019.2916666},
  groups   = {First Filtering},
  keywords = {Cloud computing;Containers;Security;Computer architecture;Complexity theory;Virtualization;Tools;Container;microservice;moving target defense;cloud computing},
}

@Article{5605649,
  author   = {Chen, Guo and Dong, Zhao Yang and Hill, David J. and Xue, Yu Sheng},
  journal  = {IEEE Transactions on Power Systems},
  title    = {Exploring Reliable Strategies for Defending Power Systems Against Targeted Attacks},
  year     = {2011},
  issn     = {1558-0679},
  month    = {Aug},
  number   = {3},
  pages    = {1000-1009},
  volume   = {26},
  abstract = {Recently, game theory has been used to design optimized strategies for defending an electric power system against deliberate attacks. In this paper, we extend the current static model to a more generalized framework which includes several interaction models between defenders and attackers. A new criterion of reliable strategies for defending power systems has been derived. In addition, two allocation algorithms have been developed to seek reliable strategies for two types of defense tasks. The new criterion and algorithms are complementary to current security criteria and can provide useful information for decision-makers to protect their power systems against possible targeted attacks. Numerical simulation examples using the proposed methods are given as well.},
  doi      = {10.1109/TPWRS.2010.2078524},
  groups   = {First Filtering},
  keywords = {Games;Power system reliability;Power system dynamics;Terrorism;Resource management;Programming;Game theory;power system security;reliable strategies;risk management;targeted attacks},
}

@Article{8443329,
  author   = {Qiang, Weizhong and Yang, Jiawei and Jin, Hai and Shi, Xuanhua},
  journal  = {IEEE Access},
  title    = {PrivGuard: Protecting Sensitive Kernel Data From Privilege Escalation Attacks},
  year     = {2018},
  issn     = {2169-3536},
  pages    = {46584-46594},
  volume   = {6},
  abstract = {Kernels of operating systems are written in low-level unsafe languages, which make them inevitably vulnerable to memory corruption attacks. Most existing kernel defense mechanisms focus on preventing control-data attacks. Recently, attackers have turned the direction to non-control-data attacks by hijacking data flow, so as to bypass current defense mechanisms. Previous work has proved that noncontrol-data attacks are the critical threat to kernels. One of the important purposes of these attacks is to achieve privilege escalation by overwriting sensitive kernel data. The goal of our research is to develop a lightweight protection mechanism to mitigate non-control-data attacks that compromise sensitive kernel data. We propose an approach that enforces data integrity of sensitive kernel data by preventing the illegal write to these data to mitigate privilege escalation attacks. The main challenge of the proposed approach is to validate the modification of sensitive kernel data at runtime. The validation routine must verify the legitimacy of the duplicated sensitive data and ensure the credibility of the verification. To address this challenge, we modify the system call entry point to monitor the change of the sensitive kernel data without any change to Linux access control mechanism. Then, we use stack canaries to protect the duplication of sensitive kernel data that are used for integrity checking. In addition, we protect the integrity of sensitive kernel data by forbidding illegal updates to them. We have implemented the prototype for Linux kernel on Ubuntu Linux platform. The evaluation results of our prototype demonstrate that it can mitigate privilege escalation attacks and its performance overhead is moderate.},
  doi      = {10.1109/ACCESS.2018.2866498},
  groups   = {First Filtering},
  keywords = {Kernel;Linux;Data integrity;Access control;Prototypes;Kernel;non-control-data;credential;privilege escalation},
}

@InProceedings{7418280,
  author    = {Wei, Jin},
  booktitle = {2015 IEEE Global Conference on Signal and Information Processing (GlobalSIP)},
  title     = {A data-driven cyber-physical detection and defense strategy against data integrity attacks in smart grid systems},
  year      = {2015},
  month     = {Dec},
  pages     = {667-671},
  abstract  = {I consider a cyber-physical perspective to the problem of detecting and defending against data integrity attacks in smart grid systems. In this paper, the problem of transient stability with distributed control using real-time data from geographically distributed Phasor Measurement Units (PMUs) is studied via a flocking-based modeling paradigm. I demonstrate how cyber corruption can be identified through the effective use of telltale physical couplings within the power system. I also develop a data-driven real-time cyber-physical detection and defense strategy with distributed control using real-time data from PMUs. The proposed strategy leverages the physical coherence to probe and detect PMU data corruption and estimate the true information values for attack mitigation.},
  doi       = {10.1109/GlobalSIP.2015.7418280},
  groups    = {First Filtering},
  keywords  = {Phasor measurement units;Lead;Real-time systems;Power system stability;Smart grids;Coherence;Generators;Data-driven;Data integrity attacks;Deep belief networks;Smart grid systems},
}

@InProceedings{7848753,
  author    = {Loh, Peter K. K. and Loh, Brian W. Y.},
  booktitle = {2016 IEEE Region 10 Conference (TENCON)},
  title     = {Cells — A novel IOT security approach},
  year      = {2016},
  month     = {Nov},
  pages     = {3716-3719},
  abstract  = {Recent commercial products have been developed for computational and enterprise systems which use virtual execution environments for monitoring, detecting and responding to known and unknown security threats. This paper presents a novel lightweight micro-agent approach that monitors, detects and responds to these threats based on resource usage attributes on the actual operating environment of digital platforms and low footprint devices.},
  doi       = {10.1109/TENCON.2016.7848753},
  groups    = {First Filtering},
  issn      = {2159-3450},
  keywords  = {Lead;Security;Monitoring;IP networks;cyber-attack;threat monitoring and detection;APT;Internet-of-Things security;micro-agents;sandbox},
}

@InProceedings{9346960,
  author    = {Deng, Bin and Ou, Yifan},
  booktitle = {2020 IEEE 4th Conference on Energy Internet and Energy System Integration (EI2)},
  title     = {Optimal Defense Strategy Based on the Load Nodes’ Importance against Dummy Data Attacks in Smart Grids},
  year      = {2020},
  month     = {Oct},
  pages     = {3134-3138},
  abstract  = {Today's power system is increasingly vulnerable to cyber-attack due to the high integration of the information and communication technologies. Therefore, it is of great significance to study the defense strategy of cyber-physical system under malicious attack. This paper proposes an optimal defense strategy based on the importance of load nodes to resist Dummy Data Attacks with high concealment. First, obtaining the node's importance ranking table based on the index of active power flow and topological connection. Then, adding the node in turn for robust protection until the false data hidden in normal data cannot be constructed to threaten the system security. The effectiveness of the proposed method is verified using the IEEE 39-bus system.},
  doi       = {10.1109/EI250167.2020.9346960},
  groups    = {First Filtering},
  keywords  = {System integration;Resists;Smart grids;Power systems;Security;Load modeling;Load flow;cyber security;false data injection attacks;dummy data attacks;nodes’ importance;multi-level modeling},
}

@InProceedings{9034445,
  author    = {Choudhary, Atul S and Choudhary, Pankaj P and Salve, Shrikant},
  booktitle = {2018 3rd International Conference on Inventive Computation Technologies (ICICT)},
  title     = {A Study On Various Cyber Attacks And A Proposed Intelligent System For Monitoring Such Attacks},
  year      = {2018},
  month     = {Nov},
  pages     = {612-617},
  abstract  = {World is moving rapidly towards the digital transformation. The internet across the world is growing rapidly which gives rise to many opportunities in every field including entertainment, finance, education, sports etc. As every coin has two aspects, the internet also has many advantages and disadvantages. We know about the advantages, but the only major disadvantage that everyone should be aware of is the increase in cyber-attacks. It is nothing, but the illegal activity committed on the internet. Many government websites and systems were hacked in the past few years and it has caused a huge loss to the nations like India, USA and China. These governments have already taken various steps to counter these crimes & attacks. But still, the attackers are coming up with new ways of attacking every time. There is need for some concrete solution which is not in the reach of the attackers. For developing such systems and tools we have done a deep analysis of various types of cybercrime and attacks happened in past along with existing solutions proposed by many researchers. Therefore, this paper presents a study on various cyber-attacks that were triggered in India and other countries in the past few years. The various prevention methods proposed in past to deal with these kinds of attacks. These prevention methods are based on machine learning algorithms like a random forest, k-means clustering, support vector machine and artificial neural network applied in order to prevent cyber-attacks. Also, in this paper, we have reported proposed intelligent system which is based supervised and unsupervised learning techniques to avoid these cyber-attacks. This proposed system might provide high efficiency with a minimum human intervention which can be implemented and used as a universal solution to most of the common cyber-attacks},
  doi       = {10.1109/ICICT43934.2018.9034445},
  groups    = {First Filtering},
  keywords  = {Computer crime;Electronic mail;Ransomware;Internet;Computer viruses;Conferences;Cybercrimes;Attacker;Machine Learning;Cyber-attack},
}

@InProceedings{7745493,
  author    = {Jha, Manjari and Acharya, Raj},
  booktitle = {2016 IEEE Conference on Intelligence and Security Informatics (ISI)},
  title     = {An immune inspired unsupervised intrusion detection system for detection of novel attacks},
  year      = {2016},
  month     = {Sep.},
  pages     = {292-297},
  abstract  = {The immune system is built to defend an organism against both known and new attacks, and functions as an adaptive distributed defense system. Artificial Immune Systems abstract the structure of immune systems to incorporate memory, fault detection and adaptive learning. We propose an immune system based real time intrusion detection system using unsupervised clustering. The model consists of two layers: a probabilistic model based T-cell algorithm which identifies possible attacks, and a decision tree based B-cell model which uses the output from T-cells together with feature information to confirm true attacks. The algorithm is tested on the KDD 99 data, where it achieves a low false alarm rate while maintaining a high detection rate. This is true even in case of novel attacks,which is a significant improvement over other algorithms.},
  doi       = {10.1109/ISI.2016.7745493},
  groups    = {First Filtering},
  keywords  = {Classification tree analysis},
}

@InProceedings{8623514,
  author    = {Wei, Lei and Gao, Donghuai and Luo, Cheng},
  booktitle = {2018 Chinese Automation Congress (CAC)},
  title     = {False Data Injection Attacks Detection with Deep Belief Networks in Smart Grid},
  year      = {2018},
  month     = {Nov},
  pages     = {2621-2625},
  abstract  = {As a typical information physics system, the smart grid can realize the two-way transmission of information. The deep integration of the information physics system brings more risks to the system while improving the automation management level of the power system. The false data injection attack is a new type of attack method for power system state estimation. The attacker can bypass the traditional detection method to change the state estimation result, so that the control center makes wrong decisions and threatens the safe operation of the power grid. In this paper, we focus on the detection of false data injection attacks in smart grids. A DBN-based attack detection method is proposed. Unsupervised learning is performed from the bottom of the restricted Boltzmann machine to provide initial weight for the network. The backpropagation algorithm propagates the error from top to bottom and fine-tunes the model parameters. To evaluate the effectiveness of the proposed detection method, simulation experiment is performed in the IEEE standard test system. We set different contrast scenarios to verify the feasibility and effectiveness of the detection model. The results demonstrate that the proposed approach achieves better performance with comparison to the SVM based detection approach.},
  doi       = {10.1109/CAC.2018.8623514},
  groups    = {First Filtering},
  keywords  = {Training;State estimation;Data models;Predictive models;IEEE Standards;Smart grids;Smart grid;state estimation;false data injection attack;DBM},
}

@Article{9106374,
  author   = {Yang, Jingjing and Liu, Jiaxing and Wu, Jinzhao},
  journal  = {IEEE Access},
  title    = {Facial Image Privacy Protection Based on Principal Components of Adversarial Segmented Image Blocks},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {103385-103394},
  volume   = {8},
  abstract = {The features in facial images, which are utilized for a variety of technological applications, pose a significant privacy concern for users. This paper proposes a method for protecting privacy in facial images based on the principal components of adversarial segmented image blocks. Generative adversarial network parameters are compressed by segmenting the facial images into blocks and extracting the principal components of the segmented image. The generator and discriminator in the generative adversarial network then generate images similar to the original facial images; the facial images generated by the generator, as-driven by the target recognition network, markedly different from the original facial images. As the generator, discriminator, and target recognition network compete with each other, minor perturbation is added to the principal components of the facial images to protect the users' privacy and prevent distinct face-related features of the images from being easily extracted. Experimental results show that the proposed method outperforms other similar methods in terms of generated image quality, operation speed, and target recognition network accuracy.},
  doi      = {10.1109/ACCESS.2020.2999449},
  groups   = {First Filtering},
  keywords = {Privacy;Perturbation methods;Image segmentation;Feature extraction;Face recognition;Generators;Principal component analysis;Facial image privacy protection;generative adversarial network;principal components;adversarial samples},
}

@InProceedings{8860051,
  author    = {Jabłoński, Janusz and Robak, Silva},
  booktitle = {2019 Federated Conference on Computer Science and Information Systems (FedCSIS)},
  title     = {Information Systems Development and Usage with Consideration of Privacy and Cyber Security Aspects},
  year      = {2019},
  month     = {Sep.},
  pages     = {1-8},
  abstract  = {One of the contemporary problems, and at the same time a challenge, with development und usage of supply chain Information Systems are the issues associated with privacy and cyber security, which emerged due to new requirements of legal regulations and directives. The human factor belongs to the biggest risks within these issues. Leak of information, phishing, unauthorized access are the main problems. Also vulnerability of the systems due to new information technologies is an important topic. In this paper we discuss development and usage of Information Systems with regard to the security aspects associated to the software development lifecycle. We present our approach on examples of a user authentication process in logistics.},
  doi       = {10.15439/2019F261},
  groups    = {First Filtering},
  issn      = {2300-5963},
  keywords  = {Authentication;Information systems;Privacy;Supply chains;Consumer electronics;Cryptography},
}

@InProceedings{9297264,
  author    = {Chauhan, Ravi and Shah Heydari, Shahram},
  booktitle = {2020 International Symposium on Networks, Computers and Communications (ISNCC)},
  title     = {Polymorphic Adversarial DDoS attack on IDS using GAN},
  year      = {2020},
  month     = {Oct},
  pages     = {1-6},
  abstract  = {Intrusion Detection systems are important tools in preventing malicious traffic from penetrating into networks and systems. Recently, Intrusion Detection Systems are rapidly enhancing their detection capabilities using machine learning algorithms. However, these algorithms are vulnerable to new unknown types of attacks that can evade machine learning IDS. In particular, they may be vulnerable to attacks based on Generative Adversarial Networks (GAN). GANs have been widely used in domains such as image processing, natural language processing to generate adversarial data of different types such as graphics, videos, texts, etc. We propose a model using GAN to generate adversarial DDoS attacks that can change the attack profile and can be undetected. Our simulation results indicate that by continuous changing of attack profile, defensive systems that use incremental learning will still be vulnerable to new attacks.},
  doi       = {10.1109/ISNCC49221.2020.9297264},
  groups    = {First Filtering},
  keywords  = {Generators;Generative adversarial networks;Data models;Feature extraction;Training;Malware;Intrusion detection;Adversarial Attacks;Generative Adversarial Networks (GAN);IDS;DDoS attacks;Machine Learning},
}

@InProceedings{8683044,
  author    = {Jin, Guoqing and Shen, Shiwei and Zhang, Dongming and Dai, Feng and Zhang, Yongdong},
  booktitle = {ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {APE-GAN: Adversarial Perturbation Elimination with GAN},
  year      = {2019},
  month     = {May},
  pages     = {3842-3846},
  abstract  = {Although Deep Neural Networks could achieve state-of-the-art performance while recongnizing images, they often suffer a tremendous defeat from adversarial examples-inputs generated by utilizing imperceptible but intentional perturbations to samples from the datasets. So far, very few methods have provided a significant defense to adversarial examples. In this paper, an effective framework based Generative Adversarial Nets(GAN) is proposed to defense against the adversarial examples. The essense of the model is to eliminate the adversarial perturbations being highly aligned with the weight vectors of nueral models. Extensive experiments on benchmark datasets MNIST, CIFAR10 and ImageNet indicate that our framework is able to defense against adversarial examples effectively.},
  doi       = {10.1109/ICASSP.2019.8683044},
  groups    = {First Filtering},
  issn      = {2379-190X},
  keywords  = {Perturbation methods;Error analysis;Generators;Neural networks;Training;Gallium nitride;Task analysis;Adversarial examples;Adversarial perturbations elminination;Adversarial attack;Generative Adversarial Nets;Deep neural networks},
}

@InProceedings{7369840,
  author    = {Orojloo, Hamed and Azgomi, Mohammad Abdollahi},
  booktitle = {2015 CSI Symposium on Real-Time and Embedded Systems and Technologies (RTEST)},
  title     = {Evaluating the complexity and impacts of attacks on cyber-physical systems},
  year      = {2015},
  month     = {Oct},
  pages     = {1-8},
  abstract  = {In this paper, a new method for quantitative evaluation of the security of cyber-physical systems (CPSs) is proposed. The proposed method models the different classes of adversarial attacks against CPSs, including cross-domain attacks, i.e., cyber-to-cyber and cyber-to-physical attacks. It also takes the secondary consequences of attacks on CPSs into consideration. The intrusion process of attackers has been modeled using attack graph and the consequence estimation process of the attack has been investigated using process model. The security attributes and the special parameters involved in the security analysis of CPSs, have been identified and considered. The quantitative evaluation has been done using the probability of attacks, time-to-shutdown of the system and security risks. The validation phase of the proposed model is performed as a case study by applying it to a boiling water power plant and estimating the suitable security measures.},
  doi       = {10.1109/RTEST.2015.7369840},
  groups    = {First Filtering},
  keywords  = {Sensor phenomena and characterization;Cyber-physical systems;Process control;Actuators;Computer crime;Cyber-physical systems;modeling;quantitative security evaluation;attack consequences},
}

@InProceedings{9449287,
  author    = {Lv, Luochen},
  booktitle = {2021 IEEE 6th International Conference on Computer and Communication Systems (ICCCS)},
  title     = {Smart Watermark to Defend against Deepfake Image Manipulation},
  year      = {2021},
  month     = {April},
  pages     = {380-384},
  abstract  = {Deepfake image manipulation has become a serious security threat to the social network. Currently, there are limited studies on protective methods that are against Deepfake image manipulation. To tackle this problem, we here propose an adversary attack based smart watermark model, which adds unperceptive watermarks to images so that the images become adversary examples to Deepfake models. When the Deepfake manipulates these watermarked images, the manipulated images become blur. The manipulation thus can be easily recognized by human and machines. Our experiments have shown that our model outperforms the SOTA and can be used to effectively prevent Deepfake manipulation.},
  doi       = {10.1109/ICCCS52626.2021.9449287},
  groups    = {First Filtering},
  keywords  = {Measurement;Social networking (online);Communication systems;Computational modeling;Conferences;Watermarking;Videos;Deepfake;security;watermark},
}

@InProceedings{6965352,
  author    = {Kuntz, Kaci and Smith, Michael and Wedeward, Kevin and Collins, Michael},
  booktitle = {2014 North American Power Symposium (NAPS)},
  title     = {Detecting, locating, quantifying false data injections utilizing grid topology through optimized D-FACTS device placement},
  year      = {2014},
  month     = {Sep.},
  pages     = {1-6},
  abstract  = {Power grids are monitored by gathering data through remote sensors and estimating the state of the grid. Bad data detection schemes detect and remove poor data. False data is a special type of data injection designed to evade typical bad data detection schemes and compromise state estimates, possibly leading to improper control of the grid. Topology perturbation is a situational awareness method that implements the use of distributed flexible AC transmission system devices to alter impedance on optimally chosen lines, updating the grid topology and exposing the presence of false data. The success of the topology perturbation for improving grid control and exposing false data in AC state estimation is demonstrated. A technique is developed for identifying the false data injection attack vector and quantifying the compromised measurements. The proposed method provides successful false data detection and identification in IEEE 14, 24, and 39-bus test systems using AC state estimation.},
  doi       = {10.1109/NAPS.2014.6965352},
  groups    = {First Filtering},
  keywords  = {Vectors;Topology;Transmission line measurements;State estimation;Power grids;Jacobian matrices;Perturbation methods;Distributed Flexible AC Transmission Systems;Power Grids;Power System Security;Voltage Control},
}

@Article{9294026,
  author   = {Liu, Ximeng and Xie, Lehui and Wang, Yaopeng and Zou, Jian and Xiong, Jinbo and Ying, Zuobin and Vasilakos, Athanasios V.},
  journal  = {IEEE Access},
  title    = {Privacy and Security Issues in Deep Learning: A Survey},
  year     = {2021},
  issn     = {2169-3536},
  pages    = {4566-4593},
  volume   = {9},
  abstract = {Deep Learning (DL) algorithms based on artificial neural networks have achieved remarkable success and are being extensively applied in a variety of application domains, ranging from image classification, automatic driving, natural language processing to medical diagnosis, credit risk assessment, intrusion detection. However, the privacy and security issues of DL have been revealed that the DL model can be stolen or reverse engineered, sensitive training data can be inferred, even a recognizable face image of the victim can be recovered. Besides, the recent works have found that the DL model is vulnerable to adversarial examples perturbed by imperceptible noised, which can lead the DL model to predict wrongly with high confidence. In this paper, we first briefly introduces the four types of attacks and privacy-preserving techniques in DL. We then review and summarize the attack and defense methods associated with DL privacy and security in recent years. To demonstrate that security threats really exist in the real world, we also reviewed the adversarial attacks under the physical condition. Finally, we discuss current challenges and open problems regarding privacy and security issues in DL.},
  doi      = {10.1109/ACCESS.2020.3045078},
  groups   = {First Filtering},
  keywords = {Security;Computational modeling;Privacy;Data models;Training;Training data;Face recognition;Deep learning;DL privacy;DL security;model extraction attack;model inversion attack;adversarial attack;poisoning attack;adversarial defense;privacy-preserving},
}

@Article{8962204,
  author   = {Bui, Tu and Cooper, Daniel and Collomosse, John and Bell, Mark and Green, Alex and Sheridan, John and Higgins, Jez and Das, Arindra and Keller, Jared Robert and Thereaux, Olivier},
  journal  = {IEEE Transactions on Multimedia},
  title    = {Tamper-Proofing Video With Hierarchical Attention Autoencoder Hashing on Blockchain},
  year     = {2020},
  issn     = {1941-0077},
  month    = {Nov},
  number   = {11},
  pages    = {2858-2872},
  volume   = {22},
  abstract = {We present ARCHANGEL; a novel distributed ledger based system for assuring the long-term integrity of digital video archives. First, we introduce a novel deep network architecture using a hierarchical attention autoencoder (HAAE) to compute temporal content hashes (TCHs) from minutes or hour-long audio-visual streams. Our TCHs are sensitive to accidental or malicious content modification (tampering). The focus of our self-supervised HAAE is to guard against content modification such as frame truncation or corruption but ensure invariance against format shift (i.e. codec change). This is necessary due to the curatorial requirement for archives to format shift video over time to ensure future accessibility. Second, we describe how the TCHs (and the models used to derive them) are secured via a proof-of-authority blockchain distributed across multiple independent archives. We report on the efficacy of ARCHANGEL within the context of a trial deployment in which the national government archives of the United Kingdom, United States of America, Estonia, Australia and Norway participated.},
  doi      = {10.1109/TMM.2020.2967640},
  groups   = {First Filtering},
  keywords = {Blockchain;Feature extraction;Visualization;Distributed ledger;Task analysis;Transcoding;Streaming media;Distributed Ledger Technology;content aware hashing;autoencoder;LSTM;attention network;content integrity;blockchain},
}

@Article{8918446,
  author   = {Keshk, Marwa and Turnbull, Benjamin and Moustafa, Nour and Vatsalan, Dinusha and Choo, Kim-Kwang Raymond},
  journal  = {IEEE Transactions on Industrial Informatics},
  title    = {A Privacy-Preserving-Framework-Based Blockchain and Deep Learning for Protecting Smart Power Networks},
  year     = {2020},
  issn     = {1941-0050},
  month    = {Aug},
  number   = {8},
  pages    = {5110-5118},
  volume   = {16},
  abstract = {Modern power systems depend on cyber-physical systems to link physical devices and control technologies. A major concern in the implementation of smart power networks is to minimize the risk of data privacy violation (e.g., by adversaries using data poisoning and inference attacks). In this article, we propose a privacy-preserving framework to achieve both privacy and security in smart power networks. The framework includes two main modules: a two-level privacy module and an anomaly detection module. In the two-level privacy module, an enhanced-proof-of-work-technique-based blockchain is designed to verify data integrity and mitigate data poisoning attacks, and a variational autoencoder is simultaneously applied for transforming data into an encoded format for preventing inference attacks. In the anomaly detection module, a long short-term memory deep learning technique is used for training and validating the outputs of the two-level privacy module using two public datasets. The results highlight that the proposed framework can efficiently protect data of smart power networks and discover abnormal behaviors, in comparison to several state-of-the-art techniques.},
  doi      = {10.1109/TII.2019.2957140},
  groups   = {First Filtering},
  keywords = {Data privacy;Machine learning;Power systems;Anomaly detection;Privacy;Anomaly detection;blockchain;cyber-physical system (CPS);deep learning;privacy preservation;proof of work (PoW)},
}

@InProceedings{6836623,
  author    = {Mohammed, Mohssen M.Z.E. and Chan, H. Anthony and Ventura, Neco and Pathan, Al-Sakib Khan},
  booktitle = {2013 International Conference on Advanced Computer Science Applications and Technologies},
  title     = {An Automated Signature Generation Method for Zero-Day Polymorphic Worms Based on Multilayer Perceptron Model},
  year      = {2013},
  month     = {Dec},
  pages     = {450-455},
  abstract  = {Polymorphic worms are considered as the most dangerous threats to the Internet security, and the danger lies in changing their payloads in every infection attempt to avoid the security systems. In this paper, we propose an accurate signature generation system for zero-day polymorphic worms. We have designed a novel Double-honeynet system, which is able to detect zero-day polymorphic worms that have not been seen before. To generate signatures for polymorphic worms we have two steps. The first step is the polymorphic worms sample collection which is done by the Double-honeynet system. The second step is the signature generation for the collected samples which is done by k-means clustering algorithm and a Multilayer Perceptron Model. The system collects different types of polymorphic worms, we used the k-means clustering algorithm to separate each type into a cluster. The Multilayer Perceptron Model is used to generate signatures for each cluster. The main goal for this system is to reduce the false positives and false negatives.},
  doi       = {10.1109/ACSAT.2013.94},
  groups    = {First Filtering},
  keywords  = {Grippers;Payloads;Internet;Multilayer perceptrons;Computers;Clustering algorithms;Machine learning algorithms;Honeynet;Polymorphic;Worms;Machine Learning;Algorithm},
}

@InProceedings{9338282,
  author    = {Le, Thai and Wang, Suhang and Lee, Dongwon},
  booktitle = {2020 IEEE International Conference on Data Mining (ICDM)},
  title     = {MALCOM: Generating Malicious Comments to Attack Neural Fake News Detection Models},
  year      = {2020},
  month     = {Nov},
  pages     = {282-291},
  abstract  = {In recent years, the proliferation of so-called “fake news” has caused much disruptions in society and weakened the news ecosystem. Therefore, to mitigate such problems, researchers have developed state-of-the-art (SOTA) models to autodetect fake news on social media using sophisticated data science and machine learning techniques. In this work, then, we ask “what if adversaries attempt to attack such detection models?” and investigate related issues by (i) proposing a novel attack scenario against fake news detectors, in which adversaries can post malicious comments toward news articles to mislead SOTA fake news detectors, and (ii) developing Malcom, an end-to-end adversarial comment generation framework to achieve such an attack. Through a comprehensive evaluation, we demonstrate that about 94% and 93.5% of the time on average Malcom can successfully mislead five of the latest neural detection models to always output targeted real and fake news labels. Furthermore, Malcom can also fool black box fake news detectors to always output real news labels 90% of the time on average. We also compare our attack model with four baselines across two real-world datasets, not only on attack performance but also on generated quality, coherency, transferability, and robustness. We release the source code of Malcom at https://github.com/lethaiq/MALCOM1.},
  doi       = {10.1109/ICDM50108.2020.00037},
  groups    = {First Filtering},
  issn      = {2374-8486},
  keywords  = {Social networking (online);Biological system modeling;Ecosystems;Detectors;Machine learning;Data models;Robustness;Fake News;Adversarial;Attack;Malicious Comments;MALCOM;Misinformation;social media},
}

@Article{8025384,
  author   = {Paridari, Kaveh and O’Mahony, Niamh and El-Din Mady, Alie and Chabukswar, Rohan and Boubekeur, Menouer and Sandberg, Henrik},
  journal  = {Proceedings of the IEEE},
  title    = {A Framework for Attack-Resilient Industrial Control Systems: Attack Detection and Controller Reconfiguration},
  year     = {2018},
  issn     = {1558-2256},
  month    = {Jan},
  number   = {1},
  pages    = {113-128},
  volume   = {106},
  abstract = {Most existing industrial control systems (ICSs), such as building energy management systems (EMSs), were installed when potential security threats were only physical. With advances in connectivity, ICSs are now, typically, connected to communications networks and, as a result, can be accessed remotely. This extends the attack surface to include the potential for sophisticated cyber attacks, which can adversely impact ICS operation, resulting in service interruption, equipment damage, safety concerns, and associated financial implications. In this work, a novel cyber-physical security framework for ICSs is proposed, which incorporates an analytics tool for attack detection and executes a reliable estimation-based attack-resilient control policy, whenever an attack is detected. The proposed framework is adaptable to already implemented ICS and the stability and optimal performance of the controlled system under attack has been proved. The performance of the proposed framework is evaluated using a reduced order model of a real EMS site and simulated attacks.},
  doi      = {10.1109/JPROC.2017.2725482},
  groups   = {First Filtering},
  keywords = {Integrated circuits;Security;Industrial control;Energy management;Control systems;Risk management;Cyber-physical systems;Safety;Control systems;Industrial control;Artifical intelligence;building management systems;cyber–physical security;energy management;industrial control;knowledge-based systems;resilient control;SCADA systems;security analytics;stability;virtual sensor},
}

@Article{9127768,
  author   = {Ni, Ming and Li, Manli and Li, Jun'e and Wu, Yingjun and Wang, Qi},
  journal  = {Journal of Modern Power Systems and Clean Energy},
  title    = {Concept and Research Framework for Coordinated Situation Awareness and Active Defense of Cyber-physical Power Systems Against Cyber-attacks},
  year     = {2021},
  issn     = {2196-5420},
  month    = {May},
  number   = {3},
  pages    = {477-484},
  volume   = {9},
  abstract = {Due to the tight coupling between the cyber and physical sides of a cyber-physical power system (CPPS), the safe and reliable operation of CPPSs is being increasingly impacted by cyber security. This situation poses a challenge to traditional security defense systems, which considers the threat from only one side, i.e., cyber or physical. To cope with cyber-attacks, this paper reaches beyond the traditional one-side security defense systems and proposes the concept of cyber-physical coordinated situation awareness and active defense to improve the ability of CPPSs. An example of a regional frequency control system is used to show the validness and potential of this concept. Then, the research framework is presented for studying and implementing this concept. Finally, key technologies for cyber-physical coordinated situation awareness and active defense against cyber-attacks are introduced.},
  doi      = {10.35833/MPCE.2018.000830},
  groups   = {First Filtering},
  keywords = {Substations;Power system stability;Correlation;Computer crime;Object recognition;Cyber-physical power system (CPPS);cyber security;cyber-attack;situation awareness;active defense},
}

@InProceedings{8875216,
  author    = {Gressl, Lukas and Steger, Christian and Neffe, Ulrich},
  booktitle = {2019 22nd Euromicro Conference on Digital System Design (DSD)},
  title     = {Consideration of Security Attacks in the Design Space Exploration of Embedded Systems},
  year      = {2019},
  month     = {Aug},
  pages     = {530-537},
  abstract  = {Designing secure systems is a complex task, particularly for designers who are no security experts. Cyber security plays a key role in embedded systems, especially for the domain of the Internet of Things (IoT). IoT systems of this kind are becoming increasingly important in daily life as they simplify various tasks. They are usually small, either embedded into bigger systems or battery driven, and perform monitoring or one shot tasks. Thus, they are subject to manifold constraints in terms of performance, power consumption, chip area, etc. As they are continuously connected to the internet and utilize our private data to perform their tasks, they are interesting for potential attackers. Cyber security thus plays an important role for the design of an IoT system. As the usage of security measures usually increases both computation time, as well as power consumption, a conflict between these constraints must be solved. For the designers of such systems, balancing these constraints constitutes a highly complex task. In this paper we propose a novel approach for considering possible security attacks on embedded systems, simplifying the consideration of security requirements immediately at the start of the design process. We introduce a security aware design space exploration framework which based on an architectural, behavioral and security attack description, finds the optimal design for IoT systems. We also demonstrate the feasibility and the benefits of our framework based on a door access system use case.},
  doi       = {10.1109/DSD.2019.00082},
  groups    = {First Filtering},
  keywords  = {Task analysis;Computer crime;Power demand;Space exploration;Tools;Bayes methods;Cyber Security;Embedded System Design;Secure IoT Systems;Mixed Criticality Design Space Exploration},
}

@InProceedings{9289908,
  author    = {Khamaiseh, Samer Y and Alsmadi, Izzat and Al-Alaj, Abdullah},
  booktitle = {2020 IEEE Conference on Network Function Virtualization and Software Defined Networks (NFV-SDN)},
  title     = {Deceiving Machine Learning-Based Saturation Attack Detection Systems in SDN},
  year      = {2020},
  month     = {Nov},
  pages     = {44-50},
  abstract  = {Recently, different machine learning-based detection systems are proposed to detect DDoS saturation attacks in Software-defined Networking (SDN). Meanwhile, different research studies highlight the vulnerabilities of adapting such systems in SDN. For instance, an adversary can fool the machine learning classifiers of these systems by crafting specific adversarial attack samples, preventing the detection of DoS saturation attacks. To better understand the security properties of these classifiers in adversarial settings, this paper investigates the robustness of the supervised and unsupervised machine learning classifiers against adversarial attacks. First, we propose an adversarial testing tool that can generate adversarial attacks that avoid the detection of four saturation attacks (i.e., SYN, UDP, ICMP, and TCP-SARFU), by perturbing different traffic features. Second, we propose a machine learning-based saturation attack detection system that utilizes different supervised and unsupervised machine learning classifiers as a testing platform. The experimental results demonstrate that the generated adversarial attacks can reduce the detection performance of the proposed detection system dramatically. Specifically, the detection performance of the four saturation attacks was decreased by more than 90% across several machine learning classifiers. This indicates that the proposed adversarial testing tool can effectively compromise the machine learning-based saturation attack detection systems.},
  doi       = {10.1109/NFV-SDN50289.2020.9289908},
  groups    = {First Filtering},
  keywords  = {Machine learning;Tools;Robustness;Network function virtualization;Security;Software defined networking;Testing;software-defined networking;adversarial attacks;DoS saturation attacks;machine learning-based detection systems},
}

@InProceedings{7983125,
  author    = {Lin, Jie and Yu, Wei and Zhang, Nan and Yang, Xinyu and Ge, Linqiang},
  booktitle = {2017 14th IEEE Annual Consumer Communications Networking Conference (CCNC)},
  title     = {On data integrity attacks against route guidance in transportation-based cyber-physical systems},
  year      = {2017},
  month     = {Jan},
  pages     = {313-318},
  abstract  = {Transportation-based Cyber-Physical Systems (TCPS), also known as Intelligent Transportation Systems (ITS), have been introduced to increase traffic efficiency and safety. To reduce traffic congestion and traveling time, a number of real-time route guidance schemes have been developed to assist travelers in determining the optimal route for their transit. In this paper, we address the vulnerability issue of the route guiding process and study data integrity attacks against route guidance schemes. To be specific, we consider a generic attack, in which the adversary may compromise vehicles via wireless communication networks and then manipulate the real-time traffic information generated or forwarded by these vehicles, and finally broadcast the forged real-time traffic information into vehicular networks. We formally model the attack and quantitatively analyze its impact on the effectiveness of route guidance schemes. Our findings show that the investigated data integrity attack can effectively disrupt route guidance, resulting in significant traffic congestion, the increase of travel time, and the imbalanced use of transportation resources.},
  doi       = {10.1109/CCNC.2017.7983125},
  groups    = {First Filtering},
  issn      = {2331-9860},
  keywords  = {Roads;Real-time systems;Wireless communication;Cyber-physical systems;Electronic mail;Intelligent sensors;Transportation-based cyber-physical systems;intelligent transportation system;route guidance;data integrity attack},
}

@InProceedings{6726110,
  author    = {Roy, Debdutta Barman and Chaki, Rituparna},
  booktitle = {2013 Annual IEEE India Conference (INDICON)},
  title     = {MCBHIDS: Modified layered cluster based algorithm for black hole IDS},
  year      = {2013},
  month     = {Dec},
  pages     = {1-6},
  abstract  = {Mobile ad hoc networks are highly vulnerable to attacks due to infrastructure less environment. The features of MANETs are like open media, dynamic changes in topology, cooperative and collaborative algorithm and no centralized monitoring system. These features make the network more prone to malicious attack. The traditional way of protecting networks with firewalls and encryption software is no longer sufficient and effective for those features. In this paper, we present a new cluster based intrusion detection algorithm that takes care of black hole attacks in a MANET. This proposed algorithm is based on trustworthiness of the nodes in a network. The network is considered to be a layered structured. The nodes are member of a cluster. Each cluster has cluster head that takes care of all the members of its own cluster and communicates with cluster head at layer 2 whenever required. The cluster head at layer 2 communicate with all cluster head at layer 1. The selection of cluster head depends on three parameters battery power, mobility and trust value of a node in a cluster. Periodically the cluster head updation is done according to three parameters. We have implemented our algorithm using the NS simulator. The performance of the proposed Intrusion Detection System (IDS) has also been evaluated in the process. The performance graph shows marked improvement as far as packet dropping is concerned.},
  doi       = {10.1109/INDCON.2013.6726110},
  groups    = {First Filtering},
  issn      = {2325-9418},
  keywords  = {Ad hoc networks;Routing protocols;Clustering algorithms;Mobile computing;Intrusion detection;Batteries;Routing;MANET;Cluster;Black hole;Layered Architecture},
}

@InProceedings{8268746,
  author    = {Alom, Md Zahangir and Taha, Tarek M.},
  booktitle = {2017 IEEE National Aerospace and Electronics Conference (NAECON)},
  title     = {Network intrusion detection for cyber security using unsupervised deep learning approaches},
  year      = {2017},
  month     = {June},
  pages     = {63-69},
  abstract  = {In the paper, we demonstrate novel approach for network Intrusion Detection System (IDS) for cyber security using unsupervised Deep Learning (DL) techniques. Very often, the supervised learning and rules based approach like SNORT fetch problem to identify new type of attacks. In this implementation, the input samples are numerical encoded and applied un-supervised deep learning techniques called Auto Encoder (AE) and Restricted Boltzmann Machine (RBM) for feature extraction and dimensionality reduction. Then iterative k-means clustering is applied for clustering on lower dimension space with only 3 features. In addition, Unsupervised Extreme Learning Machine (UELM) is used for network intrusion detection in this implementation. We have experimented on KDD-99 dataset, the experimental results show around 91.86% and 92.12% detection accuracy using unsupervised deep learning technique AE and RBM with K-means respectively. The experimental results also demonstrate, the proposed approach shows around 4.4% and 2.95% improvement of detection accuracy using RBM with K-means against only K-mean clustering and Unsupervised Extreme Learning Machine (USELM) respectively.},
  doi       = {10.1109/NAECON.2017.8268746},
  groups    = {First Filtering},
  issn      = {2379-2027},
  keywords  = {Intrusion detection;Machine learning;Computer security;Training;Feature extraction;Encoding},
}

@InProceedings{9348276,
  author    = {Liu, Shumei and Yu, Yao and Guo, Lei and Yeoh, Phee Lep and Vucetic, Branka and Li, Yonghui},
  booktitle = {GLOBECOM 2020 - 2020 IEEE Global Communications Conference},
  title     = {Vulnerability Analysis for Network Connectivity: A Prioritizing Critical Area Approach},
  year      = {2020},
  month     = {Dec},
  pages     = {1-6},
  abstract  = {Analyzing network vulnerability, especially connectivity vulnerability, is vital for network security planning. Traditionally, network vulnerability analysis methods separate the studies of global connectivity vulnerability and critical area vulnerability, and thus ignore joint failure of network connectivity and critical-area integrity that may cause grave damage to a network. To this end, this paper proposes a prioritizing critical area approach for connectivity analysis to identify the corresponding vulnerable elements. Specifically, we consider the worst-case scenario of a network and aim at finding the minimum disruption-cost set of elements whose removal not only severely damages network connectivity but also disrupts the critical-area integrity. Since the above optimization problem is NP-hard, a heuristic algorithm based on spectral partitioning is developed to solve it. Simulation results validate the effectiveness of our proposed scheme in accurately identifying the vulnerable elements in critical areas to prevent significant loss in the overall network connectivity and performance.},
  doi       = {10.1109/GLOBECOM42002.2020.9348276},
  groups    = {First Filtering},
  issn      = {2576-6813},
  keywords  = {Measurement;Simulation;Planning;Partitioning algorithms;Security;Communication networks;Optimization;network security;network vulnerability analysis;connectivity;critical area;spectral partitioning},
}

@Article{8941077,
  author   = {Hu, Jingjing and Guo, Shuangshuang and Kuang, Xiaohui and Meng, Fankun and Hu, Dongsheng and Shi, Zhiyu},
  journal  = {IEEE Access},
  title    = {I-HMM-Based Multidimensional Network Security Risk Assessment},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {1431-1442},
  volume   = {8},
  abstract = {Cyber-physical systems (CPS) are vulnerable to network attacks because communication relies on the network that links the various components in the CPS. The importance of network security is self-evident. In this study, we conduct a network security risk assessment from the perspectives of the host and the network, and we propose a new framework for a multidimensional network security risk assessment that includes two stages, i.e., risk identification and risk calculation. For the risk identification stage, we propose a multidimensional hierarchical index system for assessing cybersecurity risk; the system's security status is determined in three dimensions, i.e., basic operation, vulnerabilities, and threats, and these dimensions guide the data collection. In the risk calculation stage, we use a hidden Markov model (HMM) to assess the network security risk. We provide a new definition of the quality of alert and optimize the observation sequence of the HMM. The model uses a learning algorithm instead of setting the parameters manually. We introduce the concept of network node association to increase the reliability and accuracy of the risk assessment. The simulation results show that the proposed index system provides quantitative data that reflect the security status of the network. The proposed network security risk assessment method based on the improved HMM (I-HMM) reflects the security risk status in a timely and intuitive manner and detects the degree of risk that different hosts pose to the network.},
  doi      = {10.1109/ACCESS.2019.2961997},
  groups   = {First Filtering},
  keywords = {Security;Communication networks;Risk management;Hidden Markov models;Indexes;Tools;Cyber-physical systems;Hidden Markov model;network node correlation;network security risk;risk assessment},
}

@Article{8259333,
  author   = {Basu, Prabal and Pandey, Pramesh and Bal, Aatreyi and Rajamanikkam, Chidhambaranathan and Chakraborty, Koushik and Roy, Sanghamitra},
  journal  = {IEEE Transactions on Emerging Topics in Computing},
  title    = {TITAN: Uncovering the Paradigm Shift in Security Vulnerability at Near-Threshold Computing},
  year     = {2020},
  issn     = {2168-6750},
  month    = {Oct},
  number   = {4},
  pages    = {986-997},
  volume   = {8},
  abstract = {In this paper, we investigate the emerging security threats at Near-Threshold Computing (NTC) that are poised to jeopardize the trustworthy operation of future low-power electronic devices. A substantial research effort over the last decade has bolstered energy efficient operation in low-power computing. However, innovation in low-power security has received only marginal attention, thwarting a ubiquitous adoption of critical Internet of Things applications, such as wearable gadgets. Using a cross-layer methodology, we demonstrate that the timing fault vulnerability of a circuit rapidly increases as the operating conditions of the transistor devices shift from super-threshold to near-threshold values. Exploiting this vulnerability, we propose a novel threat model for NTC, referred to as a Timing Fault Attack atNTC (TITAN). TITAN relies on a malicious application software to induce timing fault attacks in the underlying NTC hardware. We evaluate the efficacy of TITAN using real hardware. Additionally, we propose two security parameters that dictate the fault resilience of a system. Based on those parameters, we show a 1.6× and a 2.8× deterioration in the fault resilience of a low-power operation, over a traditional super-threshold operation. Using a GDB driven analysis, we also present different user-level impacts of TITAN, on some real-life applications.},
  doi      = {10.1109/TETC.2018.2794070},
  groups   = {First Filtering},
  keywords = {Circuit faults;System-on-chip;Security;Malware;Integrated circuit modeling;Computer security;Fault tolerance;System-on-chip;fault diagnosis;fault tolerance;computer security},
}

@InProceedings{6726619,
  author    = {Pramod, T C and Sunitha, N R},
  booktitle = {2013 Fourth International Conference on Computing, Communications and Networking Technologies (ICCCNT)},
  title     = {An approach to detect malicious activities in SCADA systems},
  year      = {2013},
  month     = {July},
  pages     = {1-7},
  abstract  = {Supervisory Control and Data Acquisition System (SCADA) is an emerging application for industrial automation. It is being widely used in critical infrastructure for monitoring and controlling the activities. The collaborative environment and interconnectivity of SCADA system needs communications and transmission of sensed real time data like status of machines, breaks and leakages in the system across various devices in the industrial plant. Such real time data provoke security breaches to SCADA systems and results in compromise of availability, integrity, confidentiality and trust relationship between the devices of SCADA systems. As the numbers of deliberate cyber attacks on these systems are increasing, providing a scheme to identify malicious activities and defend the attacks; thereby create secure environment for SCADA systems is an essential task. By considering constraints and efficiency requirements for such networks, we are proposing a scheme that uses Log to identify some malicious activities through continuous monitoring. In Log, we have only prioritized some parameters that help us to detect some vulnerable activities and at node level by using cooperative monitoring the nodes itself takes care of some attacks. In this new approach Log analysis for the identification of malicious activities is made using cluster based architecture. This work also considers the constraints of the SCADA system thereby providing an elegant identification of malicious activities for the current SCADA system.},
  doi       = {10.1109/ICCCNT.2013.6726619},
  groups    = {First Filtering},
  keywords  = {SCADA systems;Monitoring;Sensors;Magnetic heads;Security;Jamming;Computer architecture;SCADA;Log Management;ICS-Industrial control system;attack;Aggregation},
}

@Article{9245527,
  author   = {Chen, Jinyin and Chen, Yixian and Zheng, Haibin and Shen, Shijing and Yu, Shanqing and Zhang, Dan and Xuan, Qi},
  journal  = {IEEE Transactions on Computational Social Systems},
  title    = {MGA: Momentum Gradient Attack on Network},
  year     = {2021},
  issn     = {2329-924X},
  month    = {Feb},
  number   = {1},
  pages    = {99-109},
  volume   = {8},
  abstract = {The adversarial attack methods based on gradient information can adequately find the perturbations, that is, the combinations of rewired links, thereby reducing the effectiveness of the deep learning model-based graph embedding algorithms, but it is also easy to fall into a local optimum. Therefore, this article proposes a momentum gradient attack (MGA) against the graph convolutional network (GCN) model, which can achieve more aggressive attacks with fewer rewiring links. Compared with directly updating the original network using gradient information, integrating the momentum term into the iterative process can stabilize the updating direction, which makes the model jump out of poor local optimum and enhances the method with stronger transferability. Experiments on node classification and community detection methods based on three well-known network embedding algorithms show that MGA has a better attack effect and transferability.},
  doi      = {10.1109/TCSS.2020.3031058},
  groups   = {First Filtering},
  keywords = {Perturbation methods;Deep learning;Computational modeling;Security;Prediction algorithms;Genetic algorithms;Indexes;Adversarial attack;community detection;graph embedding;momentum gradient;node classification},
}

@Article{8375813,
  author   = {Lin, Jie and Yu, Wei and Zhang, Nan and Yang, Xinyu and Ge, Linqiang},
  journal  = {IEEE Transactions on Vehicular Technology},
  title    = {Data Integrity Attacks Against Dynamic Route Guidance in Transportation-Based Cyber-Physical Systems: Modeling, Analysis, and Defense},
  year     = {2018},
  issn     = {1939-9359},
  month    = {Sep.},
  number   = {9},
  pages    = {8738-8753},
  volume   = {67},
  abstract = {Real-time route guidance schemes, as one of the critical services in Transportation-based Cyber-Physical Systems, have been introduced to assist travelers in determining optimal routing with low traffic congestion and travel time. To secure the route guidance process, which enables traffic efficiency and safety, in this paper we first investigate security issues of route guidance schemes via modeling and analysis of data integrity attacks on the route guidance process, and then develop corresponding mitigation mechanisms to combat the investigated attack. Via the manipulation of traffic state data measured or generated by compromised vehicles, the data integrity attack can give rise to erroneous predictions of traffic states and induce improper determination of guided routes for vehicles, increasing traffic congestion, and reducing traffic efficiency and safety. We formally model the attack and analyze its impacts on the effectiveness of route guidance schemes. Our results show that the data integrity attack can effectively disrupt route guidance schemes, leading to significant traffic congestion, increased traveling time, and imbalanced use of transportation resources. To mitigate the data integrity attack, we investigate the forged data filtering scheme, in which the forged traffic state data can be filtered out during data delivery in vehicular networks. Extensive performance evaluations are conducted to demonstrate the effectiveness of the proposed forged data filtering scheme in comparing with an exiting scheme.},
  doi      = {10.1109/TVT.2018.2845744},
  groups   = {First Filtering},
  keywords = {Data integrity;Roads;Real-time systems;Analytical models;Vehicle dynamics;Data models;Transportation-based cyber-physical systems;intelligent transportation system;route guidance;data integrity attack;mitigation scheme},
}

@Article{6529076,
  author   = {Chen, Gang and Jin, Hai and Zou, Deqing and Zhou, Bing Bing and Liang, Zhenkai and Zheng, Weide and Shi, Xuanhua},
  journal  = {IEEE Transactions on Dependable and Secure Computing},
  title    = {SafeStack: Automatically Patching Stack-Based Buffer Overflow Vulnerabilities},
  year     = {2013},
  issn     = {1941-0018},
  month    = {Nov},
  number   = {6},
  pages    = {368-379},
  volume   = {10},
  abstract = {Buffer overflow attacks still pose a significant threat to the security and availability of today's computer systems. Although there are a number of solutions proposed to provide adequate protection against buffer overflow attacks, most of existing solutions terminate the vulnerable program when the buffer overflow occurs, effectively rendering the program unavailable. The impact on availability is a serious problem on service-oriented platforms. This paper presents SafeStack, a system that can automatically diagnose and patch stack-based buffer overflow vulnerabilities. The key technique of our solution is to virtualize memory accesses and move the vulnerable buffer into protected memory regions, which provides a fundamental and effective protection against recurrence of the same attack without stopping normal system execution. We developed a prototype on a Linux system, and conducted extensive experiments to evaluate the effectiveness and performance of the system using a range of applications. Our experimental results showed that SafeStack can quickly generate runtime patches to successfully handle the attack's recurrence. Furthermore, SafeStack only incurs acceptable overhead for the patched applications.},
  doi      = {10.1109/TDSC.2013.25},
  groups   = {First Filtering},
  keywords = {Software reliability;Computer security;Computer viruses;Fault diagnosis;Software reliability;buffer overflow vulnerability diagnosis;attack prevention},
}

@InProceedings{9238807,
  author    = {Li, Yiwei and Xu, Guoliang and Li, Wanlin},
  booktitle = {2020 IEEE/CIC International Conference on Communications in China (ICCC)},
  title     = {FA: A Fast Method to Attack Real-time Object Detection Systems},
  year      = {2020},
  month     = {Aug},
  pages     = {1268-1273},
  abstract  = {With the development of deep learning, image and video processing plays an important role in the age of 5G communication. However, deep neural networks are vulnerable: subtle perturbations can lead to incorrect classification results. Nowadays, adversarial attacks on artificial intelligence models have seen increasing interest. In this study, we propose a new method named FA to generate adversarial examples of object detection models. Based on the generative adversarial network (GAN), we combine the classification and location information to make the generated image look as real as possible. Experimental results on the PASCAL VOC dataset show that our method efficiently and quickly generates the image. Then, we test the transferability of adversarial samples on different datasets and object detection models such as YOLOv4, which also achieve certain transfer performance. Our work provides a basis for further exploring the defects of deep learning and improving the robustness of the systems.},
  doi       = {10.1109/ICCC49849.2020.9238807},
  groups    = {First Filtering},
  issn      = {2377-8644},
  keywords  = {Deep learning;Object detection;Streaming media;Generative adversarial networks;Robustness;Real-time systems;Security;object detection;adversarial samples;GAN;information security and privacy},
}

@InProceedings{8927871,
  author    = {Mao, Yaoru and Zhu, Xiaoyan and Zheng, Wenbin and Yuan, Danni and Ma, Jianfeng},
  booktitle = {2019 11th International Conference on Wireless Communications and Signal Processing (WCSP)},
  title     = {A Novel User Membership Leakage Attack in Collaborative Deep Learning},
  year      = {2019},
  month     = {Oct},
  pages     = {1-6},
  abstract  = {Collaborative deep learning can provide high learning accuracy even participanted users' datasets are small. In the training process, users only share their locally obtained parameters, therefore it is believed that the privacy of users' original datasets can be protected. However, we present an attack approach against users' privacy in collaborative deep learning by utilizing Generative Adversarial Network (GAN) and Membership Inference. In this attack, an attacker builds a discriminator based on users' shared parameters and then trains a GAN network locally. The GAN can refactor the training records of the collaborative deep learning system. According to the generated records, the attacker uses the extent of model overfitting on an input and gets the membership of each group of records by the simplified Membership Inference attack. We evaluate the presented attack model over datasets of complex representations of handwritten digits (MINIST) and face images (CelebA). The results show that an attacker can easily generate the original training sets and classify them to obtain the membership between users' records and their identities in the collaborative deep learning.},
  doi       = {10.1109/WCSP.2019.8927871},
  groups    = {First Filtering},
  issn      = {2472-7628},
  keywords  = {Machine learning;Training;Collaboration;Feature extraction;Gallium nitride;Generative adversarial networks;Servers;Privacy;Collaborative deep learning;GAN;Membership Inference},
}

@InProceedings{6720316,
  author    = {Shuai, Bo and Li, Haifeng and Li, Mengjun and Zhang, Quan and Tang, Chaojing},
  booktitle = {2013 IEEE International Conference on Information and Automation (ICIA)},
  title     = {Automatic classification for vulnerability based on machine learning},
  year      = {2013},
  month     = {Aug},
  pages     = {312-318},
  abstract  = {In order to solve the problems of traditional machine learning methods for automatic classification of vulnerability, this paper presents a novel machine learning method based on LDA model and SVM. Firstly, word location information is introduced into LDA model called WL-LDA (Weighted Location LDA), which could acquire better effect through generating vector space on themes other than on words. Secondly, a multi-class classifier called HT-SVM (Huffman Tree SVM) is constructed, which could make a faster and more stable classification by making good use of the prior knowledge about distribution of the number of vulnerabilities. Experiments show that the method could obtain higher classification accuracy and efficiency.},
  doi       = {10.1109/ICInfA.2013.6720316},
  groups    = {First Filtering},
  keywords  = {Databases;Classification algorithms;Training;Probabilistic logic;Support vector machine classification;Educational institutions;Vulnerability classification;Words location;Vulnerability distribution;LDA model;SVM},
}

@Article{8781934,
  author   = {Wang, Zhibo and Song, Mengkai and Zheng, Siyan and Zhang, Zhifei and Song, Yang and Wang, Qian},
  journal  = {IEEE Transactions on Dependable and Secure Computing},
  title    = {Invisible Adversarial Attack against Deep Neural Networks: An Adaptive Penalization Approach},
  year     = {2021},
  issn     = {1941-0018},
  month    = {May},
  number   = {3},
  pages    = {1474-1488},
  volume   = {18},
  abstract = {Recent studies demonstrated that deep neural networks (DNNs) are vulnerable to adversarial examples, which would seriously threaten security-sensitive applications. Existing works synthesized the adversarial examples by perturbing the original/benign images by leveraging the $\mathcal {L}_p$Lp-norm to penalize the perturbations, which restricts the pixel-wise distance between the adversarial images and correspondingly benign images. However, they added perturbations globally to the benign images without explicitly considering their content/spacial structure, resulting in noticeable artifacts especially in those originally clean regions, e.g., sky and smooth surface. In this paper, we propose an invisible adversarial attack, which synthesizes adversarial examples that are visually indistinguishable from benign ones. We adaptively distribute the perturbation according to human sensitivity to a local stimulus in the benign image, i.e., the higher insensitivity, the more perturbation. Two types of adaptive adversarial attacks are proposed: 1) coarse-grained and 2) fine-grained. The former conducts $\mathcal {L}_p$Lp-norm regularized by the novel spatial constraints, which utilizes the rich information of the cluttered regions to mask perturbation. The latter, called Just Noticeable Distortion (JND)-based adversarial attack, utilizes the proposed JND$_p$p metric for better measuring the perceptual similarity, and adaptively sets penalty by weighting the pixel-wise perceptual redundancy of an image. We conduct extensive experiments on the MNIST, CIFAR-10 and ImageNet datasets and a comprehensive user study with 50 participants. The experimental results demonstrate that JND$_p$p is a better metric for measuring the perceptual similarity than $\mathcal {L}_p$Lp-norm, and the proposed adaptive adversarial attacks can synthesize indistinguishable adversarial examples from benign ones and outperform the state-of-the-art methods.},
  doi      = {10.1109/TDSC.2019.2929047},
  groups   = {First Filtering},
  keywords = {Perturbation methods;Neural networks;Redundancy;Distortion;Atmospheric measurements;Particle measurements;Adversarial examples;perceptual similarity;just noticeable distortion},
}

@InProceedings{9170732,
  author    = {Sharma, Priyamwada},
  booktitle = {2nd International Conference on Data, Engineering and Applications (IDEA)},
  title     = {Critical Review of Various Intrusion Detection Techniques for Internet of Things},
  year      = {2020},
  month     = {Feb},
  pages     = {1-6},
  abstract  = {Technology is rapidly moving towards the systems enabling maximum comfort to human being. IoT scenario has evolved into a technology for developing such comfortable eco system and became popular day by day, and at the point of attraction for the researchers world-wide who are involved in developing technology for creating comfortable and sustainable eco system for human being. Now a days IoT has shown a strong technological presence globally which embraced humanity in many ways, spread from home automation, smart city, industry and healthcare. These applications is endless and imaginable. A number of challenges and issues perceived by the system in which security and privacy are key issues. This security and vulnerability in IoT based system implies security threats which affects the overall performance of the system. In majority system related attacks could be addressed by an effective Intrusion detection system (IDS). Due to limited resources like computing, energy, storage and specially designed protocols for operations, common Intrusion detection system those are well suited for conventional network are not enough for the intrusion detection in IoT. A well designed mechanism is needed for addressing the specific challenges and issues IoT faces. This paper surveys some suitable mechanism designed for detection of intrusions in an IoT system. As a result of the survey, this paper highlights the various issues and challenges associated with IDS of IOT.},
  doi       = {10.1109/IDEA49133.2020.9170732},
  groups    = {First Filtering},
  keywords  = {Internet of things;Intrusion Detection System;Cyber-attack;Machine Learning;Anomaly Detection},
}

@InProceedings{9123023,
  author    = {Piplai, Aritran and Chukkapalli, Sai Sree Laya and Joshi, Anupam},
  booktitle = {2020 IEEE 6th Intl Conference on Big Data Security on Cloud (BigDataSecurity), IEEE Intl Conference on High Performance and Smart Computing, (HPSC) and IEEE Intl Conference on Intelligent Data and Security (IDS)},
  title     = {NAttack! Adversarial Attacks to bypass a GAN based classifier trained to detect Network intrusion},
  year      = {2020},
  month     = {May},
  pages     = {49-54},
  abstract  = {With the recent developments in artificial intelligence and machine learning, anomalies in network traffic can be detected using machine learning approaches. Before the rise of machine learning, network anomalies which could imply an attack, were detected using well-crafted rules. An attacker who has knowledge in the field of cyber-defence, could make educated guesses to sometimes accurately predict which particular features of network traffic data the cyber-defence mechanism is looking at. With this information, the attacker can circumvent a rulebased cyber-defense system. However, after the advancements of machine learning for network anomaly, it is not easy for a human to understand how to bypass a cyber-defence system. Recently, adversarial attacks have become increasingly common to defeat machine learning algorithms. In this paper, we show that even if we build a classifier and train it with adversarial examples for network data, we can use adversarial attacks and successfully break the system. We propose a Generative Adversarial Network (GAN) based algorithm to generate data to train an efficient neural network based classifier, and we subsequently break the system using adversarial attacks.},
  doi       = {10.1109/BigDataSecurity-HPSC-IDS49724.2020.00020},
  groups    = {First Filtering},
  keywords  = {adversarial attacks;network intrusion;GANs},
}

@Article{6678518,
  author   = {Hu, Jiankun and Pota, Hemanshu R. and Guo, Song},
  journal  = {IEEE Transactions on Parallel and Distributed Systems},
  title    = {Taxonomy of Attacks for Agent-Based Smart Grids},
  year     = {2014},
  issn     = {1558-2183},
  month    = {July},
  number   = {7},
  pages    = {1886-1895},
  volume   = {25},
  abstract = {Being the most important critical infrastructure in Cyber-Physical Systems (CPSs), a smart grid exhibits the complicated nature of large scale, distributed, and dynamic environment. Taxonomy of attacks is an effective tool in systematically classifying attacks and it has been placed as a top research topic in CPS by a National Science Foundation (NSG) Workshop. Most existing taxonomy of attacks in CPS are inadequate in addressing the tight coupling of cyber-physical process or/and lack systematical construction. This paper attempts to introduce taxonomy of attacks of agent-based smart grids as an effective tool to provide a structured framework. The proposed idea of introducing the structure of space-time and information flow direction, security feature, and cyber-physical causality is innovative, and it can establish a taxonomy design mechanism that can systematically construct the taxonomy of cyber attacks, which could have a potential impact on the normal operation of the agent-based smart grids. Based on the cyber-physical relationship revealed in the taxonomy, a concrete physical process based cyber attack detection scheme has been proposed. A numerical illustrative example has been provided to validate the proposed physical process based cyber detection scheme.},
  doi      = {10.1109/TPDS.2013.301},
  groups   = {First Filtering},
  keywords = {Taxonomy;Smart grids;Mathematical model;Security;Equations;Generators;Load modeling;Cyber Physical Systems (CPS);security;smart grid;critical infrastructure;taxonomy;power systems;agents},
}

@InProceedings{8748308,
  author    = {Nazarov, Alexey and Sychev, Artem},
  booktitle = {2018 International Conference on Advances in Computing, Communication Control and Networking (ICACCCN)},
  title     = {The risk-models and risk-criteria for information confrontation in social media},
  year      = {2018},
  month     = {Oct},
  pages     = {302-306},
  abstract  = {On the basis of logical-probabilistic approach proposed risk model successful attacks on social media on the Internet in terms of information warfare. We formulated and investigated the criterion of decision-making framework to achieve the goals of information warfare. Proposed algorithmic foundations of the developed criteria in Hadoop cluster.},
  doi       = {10.1109/ICACCCN.2018.8748308},
  groups    = {First Filtering},
  keywords  = {Security;Social networking (online);Internet;Organizations;Mathematical model;Psychology;Information management;warfare;polynomial;risk-models;risk-criteria},
}

@Article{6894210,
  author   = {Cen, Lei and Gates, Christoher S. and Si, Luo and Li, Ninghui},
  journal  = {IEEE Transactions on Dependable and Secure Computing},
  title    = {A Probabilistic Discriminative Model for Android Malware Detection with Decompiled Source Code},
  year     = {2015},
  issn     = {1941-0018},
  month    = {July},
  number   = {4},
  pages    = {400-412},
  volume   = {12},
  abstract = {Mobile devices are an important part of our everyday lives, and the Android platform has become a market leader. In recent years a number of approaches for Android malware detection have been proposed, using permissions, source code analysis, or dynamic analysis. In this paper, we propose to use a probabilistic discriminative model based on regularized logistic regression for Android malware detection. Through extensive experimental evaluation, we demonstrate that it can generate probabilistic outputs with highly accurate classification results. In particular, we propose to use Android API calls as features extracted from decompiled source code, and analyze and explore issues in feature granularity, feature representation, feature selection, and regularization. We show that the probabilistic discriminative model also works well with permissions, and substantially outperforms the state-of-the-art methods for Android malware detection with application permissions. Furthermore, the discriminative learning model achieves the best detection results by combining both decompiled source code and application permissions. To the best of our knowledge, this is the first research that proposes probabilistic discriminative model for Android malware detection with a thorough study of desired representation of decompiled source code and is the first research work for Android malware detection task that combines both analysis of decompiled source code and application permissions.},
  doi      = {10.1109/TDSC.2014.2355839},
  groups   = {First Filtering},
  keywords = {Feature extraction;Malware;Androids;Humanoid robots;Smart phones;Probabilistic logic;Measurement;Android;malicious application;machine learning;discriminative model},
}

@Article{8576563,
  author   = {Du, Yali and Fang, Meng and Yi, Jinfeng and Xu, Chang and Cheng, Jun and Tao, Dacheng},
  journal  = {IEEE Transactions on Multimedia},
  title    = {Enhancing the Robustness of Neural Collaborative Filtering Systems Under Malicious Attacks},
  year     = {2019},
  issn     = {1941-0077},
  month    = {March},
  number   = {3},
  pages    = {555-565},
  volume   = {21},
  abstract = {Recommendation systems have become ubiquitous in online shopping in recent decades due to their power in reducing excessive choices of customers and industries. Recent collaborative filtering methods based on the deep neural network are studied and introduce promising results due to their power in learning hidden representations for users and items. However, it has revealed its vulnerabilities under malicious user attacks. With the knowledge of a collaborative filtering algorithm and its parameters, the performance of this recommendation system can be easily downgraded. Unfortunately, this problem is not addressed well, and the study on defending recommendation systems is insufficient. In this paper, we aim to improve the robustness of recommendation systems based on two concepts - stage-wise hints training and randomness. To protect a target model, we introduce noise layers in the training of a target model to increase its resistance to adversarial perturbations. To reduce the noise layers' influence on model performance, we introduce intermediate layer outputs as hints from a teacher model to regularize the intermediate layers of a student target model. We consider white box attacks under which attackers have the knowledge of the target model. The generalizability and robustness properties of our method have been analytically inspected in experiments and discussions, and the computational cost is comparable to training a standard neural network-based collaborative filtering model. Through our investigation, the proposed defensive method can reduce the success rate of malicious user attacks and keep the prediction accuracy comparable to standard neural recommendation systems.},
  doi      = {10.1109/TMM.2018.2887018},
  groups   = {First Filtering},
  keywords = {Collaboration;Training;Neural networks;Perturbation methods;Robustness;Standards;Information technology;Recommendation systems;adversarial learning;collaborative filtering;malicious attacks},
}

@Article{7924372,
  author   = {Humayed, Abdulmalik and Lin, Jingqiang and Li, Fengjun and Luo, Bo},
  journal  = {IEEE Internet of Things Journal},
  title    = {Cyber-Physical Systems Security—A Survey},
  year     = {2017},
  issn     = {2327-4662},
  month    = {Dec},
  number   = {6},
  pages    = {1802-1831},
  volume   = {4},
  abstract = {With the exponential growth of cyber-physical systems (CPSs), new security challenges have emerged. Various vulnerabilities, threats, attacks, and controls have been introduced for the new generation of CPS. However, there lacks a systematic review of the CPS security literature. In particular, the heterogeneity of CPS components and the diversity of CPS systems have made it difficult to study the problem with one generalized model. In this paper, we study and systematize existing research on CPS security under a unified framework. The framework consists of three orthogonal coordinates: 1) from the security perspective, we follow the well-known taxonomy of threats, vulnerabilities, attacks and controls; 2) from the CPS components perspective, we focus on cyber, physical, and cyberphysical components; and 3) from the CPS systems perspective, we explore general CPS features as well as representative systems (e.g., smart grids, medical CPS, and smart cars). The model can be both abstract to show general interactions of components in a CPS application, and specific to capture any details when needed. By doing so, we aim to build a model that is abstract enough to be applicable to various heterogeneous CPS applications; and to gain a modular view of the tightly coupled CPS components. Such abstract decoupling makes it possible to gain a systematic understanding of CPS security, and to highlight the potential sources of attacks and ways of protection. With this intensive literature review, we attempt to summarize the state-of-the-art on CPS security, provide researchers with a comprehensive list of references, and also encourage the audience to further explore this emerging field.},
  doi      = {10.1109/JIOT.2017.2703172},
  groups   = {First Filtering},
  keywords = {Security;Cyber-physical systems ;Smart grids;Integrated circuits;Computer security;Control systems;Wireless communication;Attacks;controls;cyber physical systems (CPSs);industrial control systems (ICSs);medical devices;security;smart cars;smart grids;threats;vulnerabilities},
}

@InProceedings{7508120,
  author    = {Gupta, Nitika and Singh, Shailendra Narayan},
  booktitle = {2016 6th International Conference - Cloud System and Big Data Engineering (Confluence)},
  title     = {Wormhole attacks in MANET},
  year      = {2016},
  month     = {Jan},
  pages     = {236-239},
  abstract  = {A mobile ad hoc network or MANET are those wireless networks which posses no infrastructure which are connected by the wireless nodes. And these nodes are generally mobile and the connectionless links are used basically to connect these nodes and these nodes have the capability to self organize and self configure and self arrangement capability. They are not having uniform structure. Because of their mobility and their dynamic nature they are prone to many kinds of malicious attacks by the malicious users because in this every node acts as a sender receiver and the router so no node can be able to understand whether the data has been sent by the malicious sender or the true sender or the receiving node is the true node. Hence by this the data can be lost as well as can be dropped by the malicious user and it can send the fake data to the receiver as well. So there are actually many kinds of attacks at the network layer. MANETS are generally more prone to cyber attacks rather than the wired networks because of their mobile nature. So these attacks like wormhole attacks are a very big issue in the case of networks. As the demand of wireless networks is increasing day by day. So it is a big concern of about how to prevent these kinds of attacks. So that they may not affect the network layer further. So in this paper we are focusing upon these attacks and also about how by using hardware rather than software we can solve the wormhole attacks by using cryptography and the digital signature method.},
  doi       = {10.1109/CONFLUENCE.2016.7508120},
  groups    = {First Filtering},
  keywords  = {Mobile ad hoc networks;Logic gates;Receivers;Hardware;Digital signatures;Public key;Digital Signature;warmhole attack;cryptography;MANETS;Cyber attack},
}

@InProceedings{6424846,
  author    = {Clarke, Dylan and Ezhilchelvan, Paul},
  booktitle = {2012 IEEE 31st Symposium on Reliable Distributed Systems},
  title     = {FORTRESS: Adding Intrusion-Resilience to Primary-Backup Server Systems},
  year      = {2012},
  month     = {Oct},
  pages     = {121-130},
  abstract  = {Primary-backup replication enables arbitrary services, which need not be built as deterministic state machines, to be reliable against server crashes. Further, when the primary does not crash, the performance can be close to that of an un-replicated, 1-server system and is arguably far better than what state machine replication can offer. These advantages have made primary-backup replication a widely used technique in commercial provisioning of services, even though the technique assumes that residual software bugs in a server system can lead only to crashes and cannot result in state corruption. This assumption cannot hold against an attacker intent on exploiting vulnerabilities and corrupting the service state when attacks lead to intrusions. This paper presents a system, called FORTRESS, which can encapsulate a primary-backup system and safeguard it from being intruded. At its core, FORTRESS applies proactive obfuscation techniques in a manner appropriate to primary-backup replication and deploys proxy servers for additional defence. Gain in intrusion resilience is shown to be substantial when assessed through analytical evaluations and simulations for a range of attacker scenarios. Further, by implementing two web-based applications, the average performance drop is demonstrated to be in the order of tens of milliseconds even when obfuscation intervals are as small as tens of seconds.},
  doi       = {10.1109/SRDS.2012.32},
  groups    = {First Filtering},
  issn      = {1060-9857},
  keywords  = {Servers;Computer crashes;Software;Reliability;Educational institutions;Resilience;Timing;service replication;proactive obfuscation;UCIT vulnerabilities;randomization;derandomization attacks;performance measurement;simulations;web-based service-provisioning},
}

@InProceedings{8551432,
  author    = {Arrott, Anthony and Lakhotia, Arun and Leitold, Ferenc and LeDoux, Charles},
  booktitle = {2018 International Conference On Cyber Situational Awareness, Data Analytics And Assessment (Cyber SA)},
  title     = {Cluster analysis for deobfuscation of malware variants during ransomware attacks},
  year      = {2018},
  month     = {June},
  pages     = {1-9},
  abstract  = {Risk managers attempting to reduce cyber-security vulnerability in enterprise IT networks rely on the "malware detection rate" as a primary measure at each layer of protection (e.g., network firewalls, breach detection systems, secure mail-servers, endpoint security suites). However, to be directly usable in risk assessments, separate malware detection rates are required for different malware categories that are quantitatively related to specific impacts of infection. A three-tier hierarchy of malware classification is formulated to assist cyber-risk decision-making. Malware is first categorized by victim impact (e.g., adware, data exfiltration, ransomware); second by malware technique (e.g., malware families), and third by evasion and obfuscation variants within individual malware families (e.g., polymorphs, metamorphs). The three-tier hierarchy is applied to a specific vertical: ransomware (impact); ransomware family (technique); and malware binary variants within one family, WannaCry (obfuscation and evasion).},
  doi       = {10.1109/CyberSA.2018.8551432},
  groups    = {First Filtering},
}

@Article{8574898,
  author   = {Latsmi Manohar, Anita and Yau, Kok-Lim Alvin and Ling, Mee Hong and Khan, Suleman},
  journal  = {IEEE Access},
  title    = {A Security-Enhanced Cluster Size Adjustment Scheme for Cognitive Radio Networks},
  year     = {2019},
  issn     = {2169-3536},
  pages    = {117-130},
  volume   = {7},
  abstract = {Cognitive radio network (CRN) is the next generation wireless network that allows unlicensed users [secondary users (SUs)] to explore and use the underutilised licensed channels (white spaces) owned by licensed users (primary users). The purpose is to increase the spectrum utilization for enhanced network performance. Clustering segregates SUs in a CRN into logical groups (clusters) with each consisting of a leader (cluster head) and member nodes. A budget-based cluster size adjustment scheme is applied to enable each cluster to adjust its number of member nodes in its cluster based on the availability of white spaces in order to improve network scalability. However, cluster size adjustment is prone to attacks by malicious SUs that launch random and intelligent attacks. Hence, we incorporate an artificial intelligence approach called reinforcement learning (RL) into a trust model to countermeasure the random and intelligent attacks. The simulation results show that RL-based trust model increases the utilization of white spaces and cluster size to improve network scalability and enhance network performance despite the presence of RL-based intelligent attacks.},
  doi      = {10.1109/ACCESS.2018.2885070},
  groups   = {First Filtering},
  keywords = {White spaces;Scalability;Adaptation models;Sensors;Cognitive radio;Base stations;Artificial intelligence;reinforcement learning;attacks;trust model;cognitive radio},
}

@Article{8031986,
  author   = {Holgado, Pilar and Villagrá, Víctor A. and Vázquez, Luis},
  journal  = {IEEE Transactions on Dependable and Secure Computing},
  title    = {Real-Time Multistep Attack Prediction Based on Hidden Markov Models},
  year     = {2020},
  issn     = {1941-0018},
  month    = {Jan},
  number   = {1},
  pages    = {134-147},
  volume   = {17},
  abstract = {A novel method based on the Hidden Markov Model is proposed to predict multistep attacks using IDS alerts. We consider the hidden states as similar phases of a particular type of attack. As a result, it can be easily adapted to multistep attacks and foresee the next steps of an attacker. To achieve this goal, a preliminary off-line training phase based on observations will be required. These observations are obtained by matching the IDS alert information with a database previously built for this purpose using a clusterization method from the CVE global database to avoid overfitting. The training model is performed using both unsupervised and supervised algorithms. Once the training is completed and probability matrices are computed, the prediction module compute the best state sequence based on the state probability for each step of the multistep attack in progress using the Viterbi and forward-backward algorithms. The training model includes the mean number of alerts and the number of alerts in progress to assist in obtaining the final attack probability. The model is analyzed for DDoS phases because it is a great problem in all Internet services. The proposed method is validated into a virtual DDoS scenario using current vulnerabilities. The results proving the system's ability to perform real-time prediction.},
  doi      = {10.1109/TDSC.2017.2751478},
  groups   = {First Filtering},
  keywords = {Hidden Markov models;Training;Computer crime;Proposals;Predictive models;Mathematical model;Prediction algorithms;Multistep attack prediction;hidden Markov model;distributed denial of service;proactive response;machine learning},
}

@Article{6158635,
  author   = {Ben-Porat, Udi and Bremler-Barr, Anat and Levy, Hanoch},
  journal  = {IEEE Transactions on Computers},
  title    = {Vulnerability of Network Mechanisms to Sophisticated DDoS Attacks},
  year     = {2013},
  issn     = {1557-9956},
  month    = {May},
  number   = {5},
  pages    = {1031-1043},
  volume   = {62},
  abstract = {In recent years, we have experienced a wave of DDoS attacks threatening the welfare of the internet. These are launched by malicious users whose only incentive is to degrade the performance of other, innocent, users. The traditional systems turn out to be quite vulnerable to these attacks. The objective of this work is to take a first step to close this fundamental gap, aiming at laying a foundation that can be used in future computer/network designs taking into account the malicious users. Our approach is based on proposing a metric that evaluates the vulnerability of a system. We then use our vulnerability metric to evaluate a data structure which is commonly used in network mechanisms-the Hash table data structure. We show that Closed Hash is much more vulnerable to DDoS attacks than Open Hash, even though the two systems are considered to be equivalent by traditional performance evaluation. We also apply the metric to queuing mechanisms common to computer and communications systems. Furthermore, we apply it to the practical case of a hash table whose requests are controlled by a queue, showing that even after the attack has ended, the regular users still suffer from performance degradation or even a total denial of service.},
  doi      = {10.1109/TC.2012.49},
  groups   = {First Filtering},
  keywords = {Computer crime;Measurement;Degradation;Complexity theory;Data structures;Servers;Bandwidth;Computer crime;Measurement;Degradation;Complexity theory;Data structures;Servers;Bandwidth;malicious;DDoS;hash;queue;vulnerability;metric},
}

@Article{9194704,
  author   = {Al-Hamadi, Hamid and Chen, Ing-Ray and Wang, Ding-Chau and Almashan, Meshal},
  journal  = {IEEE Access},
  title    = {Attack and Defense Strategies for Intrusion Detection in Autonomous Distributed IoT Systems},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {168994-169009},
  volume   = {8},
  abstract = {In this paper, we develop a methodology to capture and analyze the interplay of attack-defense strategies for intrusion detection in an autonomous distributed Internet of Things (IoT) system. In our formulation, every node must participate in lightweight intrusion detection of a neighbor target node. Consequently, every good node would play a set of defense strategies to faithfully defend the system while every bad node would play a set of attack strategies for achieving their own goals. We develop an analytical model based on Stochastic Petri Net (SPN) modeling techniques. Our methodology allows the optimal defense strategies to be played by good nodes to maximize the system lifetime when given a set of parameter values characterizing the distributed IoT system operational environment. We conduct a detailed performance evaluation based on an experiment dataset deriving from a reference autonomous distributed IoT system comprising 128 sensor-carrying mobile nodes and show how IDS defense mechanisms can counter malicious attack mechanisms under the ADIoTS system while considering multiple failure conditions.},
  doi      = {10.1109/ACCESS.2020.3023616},
  groups   = {First Filtering},
  keywords = {Intrusion detection;Internet of Things;Machine learning;Analytical models;Task analysis;Performance evaluation;Intrusion detection;Internet of Things;mission-oriented IoT systems;stochastic Petri net;attack/defense behavior models},
}

@InProceedings{9185994,
  author    = {Damer, Naser and Boutros, Fadi and Saladié, Alexandra Moseguí and Kirchbuchner, Florian and Kuijper, Arjan},
  booktitle = {2019 IEEE 10th International Conference on Biometrics Theory, Applications and Systems (BTAS)},
  title     = {Realistic Dreams: Cascaded Enhancement of GAN-generated Images with an Example in Face Morphing Attacks},
  year      = {2019},
  month     = {Sep.},
  pages     = {1-10},
  abstract  = {The quality of images produced by generative adversarial networks (GAN) is commonly a trade-off between the model size, its training data needs, and the generation resolution. This trad-off is clear when applying GANs to issues like generating face morphing attacks, where the latent vector used by the generator is manipulated. In this paper, we propose an image enhancement solution designed to increase the quality and resolution of GAN-generated images. The solution is designed to require limited training data and be extendable to higher resolutions. We successfully apply our solution on GAN-based face morphing attacks. Beside the face recognition vulnerability and attack detectability analysis, we prove that the images enhanced by our solution are of higher visual and quantitative quality in comparison to unprocessed attacks and attack images enhanced by state-of-the-art super-resolution approaches.},
  doi       = {10.1109/BTAS46853.2019.9185994},
  groups    = {First Filtering},
  issn      = {2474-9699},
  keywords  = {Image resolution;Face;Gallium nitride;Generative adversarial networks;Training;Image enhancement;Generators},
}

@InProceedings{7155851,
  author    = {Katkar, Vijay and Zinjade, Amol and Dalvi, Suyed and Bafna, Tejal and Mahajan, Rashmi},
  booktitle = {2015 International Conference on Computing Communication Control and Automation},
  title     = {Detection of DoS/DDoS Attack against HTTP Servers Using Naive Bayesian},
  year      = {2015},
  month     = {Feb},
  pages     = {280-285},
  abstract  = {With a growth of E-commerce and availability of resources over internet number of attacks on servers providing these services, resources are also increased. Denial of service and Distributed Denial of Service are most widely launched attacks against these servers for preventing legitimate users from accessing these services. This paper presents architecture of offline Signature based Network Intrusion Detection System for detection of Denial/Distributed Denial of Service attacks against HTTP servers using distributed processing and Naïve Bayesian classifier. Experimental results are provided to prove the efficiency of proposed architecture.},
  doi       = {10.1109/ICCUBEA.2015.60},
  groups    = {First Filtering},
  keywords  = {Computer crime;Bayes methods;Web servers;Accuracy;Telecommunication traffic;Intrusion detection;Denial of service attack;Naive Bayesian;Network Intrusion Detection System},
}

@Article{8089343,
  author   = {Sui, Peipei and Li, Xianxian and Bai, Yan},
  journal  = {IEEE Access},
  title    = {A Study of Enhancing Privacy for Intelligent Transportation Systems: $k$ -Correlation Privacy Model Against Moving Preference Attacks for Location Trajectory Data},
  year     = {2017},
  issn     = {2169-3536},
  pages    = {24555-24567},
  volume   = {5},
  abstract = {Internet of Things (IoT) has been widely used in various application domains including smart city, environment monitoring and intelligent transportation systems. Thousands of interconnected IoT devices produce an enormous volume of data termed as big data. However, privacy protection has become one of the biggest problems with the progress of big data. Personal privacy is usually challenged by the development of technology. In this paper, we focus on privacy protection for location trajectory data, which is collected in intelligent transportation system. First, we demonstrate that the moving preference of individuals can be exploited to perform re-identification attacks, which may cause serious damage to the identity privacy of users. To address this re-identification problem, we present a new trajectory anonymity model, in which the degree of correlation between parking locations and individuals is precisely characterized by a concept of Location Frequency-inverse user frequency (LF-IUF, for short). We then propose an anonymizing method to replace parking locations by a k-correlation region. Our method provides a novel anonymity solution for publishing trajectory data, which achieves a better trade off between privacy and utility. Finally, we run a set of experiments on real-world data sets, and demonstrate the effectiveness of our method.},
  doi      = {10.1109/ACCESS.2017.2767641},
  groups   = {First Filtering},
  keywords = {Trajectory;Privacy;Data privacy;Intelligent transportation systems;Publishing;Correlation;Data models;Data privacy;location;information security;Internet of Things},
}

@Article{9261431,
  author   = {Yang, Shaojie and Li, Shanxi and Chen, Wenbo and Liu, Yuhong},
  journal  = {IEEE Access},
  title    = {A Real-Time and Adaptive-Learning Malware Detection Method Based on API-Pair Graph},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {208120-208135},
  volume   = {8},
  abstract = {The detection of malware have developed for many years, and the appearance of new machine learning and deep learning techniques have improved the effect of detectors. However, most of current researches have focused on the general features of malware and ignored the development of the malware themselves, so that the features could be useless with the time passed as well as the advance of malware techniques. Besides, the detection methods based on machine learning are mainly static detection and analysis, while the study of real-time detection of malware is relatively rare. In this article, we proposed a new model that could detect malware real-time in principle and learn new features adaptively. Firstly, a new data structure of API-Pair was adopted, and the constructed data was trained with Maximum Entropy model, which could satisfy the goal of weighting and adaptive learning. Then a clustering was practised to filter relatively unrelated and confusing features. Moreover, a detector based on Lont Short Term Memory Network (LSTM) was devised to achieve the goal of real-time detection. Finally, a series of experiments were designed to verify our method. The experimental results showed that our model could obtain the highest accuracy of 99.07% in general tests and keep the accuracies above 97% with the development of malware; the results also proved the feasibility of our model in real-time detection through the simulation experiment, and robustness against a typical adversarial attack.},
  doi      = {10.1109/ACCESS.2020.3038453},
  groups   = {First Filtering},
  keywords = {Malware;Detectors;Feature extraction;Real-time systems;Adaptation models;Entropy;Markov processes;Malware detection;adaptive learning;real-time detection;API-pair graph;deep learning},
}

@InProceedings{9323017,
  author    = {Ahmad, Ishfaq and Clark, Addison and Sabol, Alex and Ferris, David and Aved, Alex},
  booktitle = {2020 3rd International Conference on Data Intelligence and Security (ICDIS)},
  title     = {Maximizing Resilience under Defender Attacker Model in Heterogeneous Multi-Networks},
  year      = {2020},
  month     = {June},
  pages     = {117-126},
  abstract  = {Our economy, military, and our society as a whole is entirely dependent on our utility infrastructure. This fact makes network security of critical importance to both the public and private sectors. Information about the vulnerability of multi-networks is critical from a defensive point of view, and it may not be immediately obvious which component is the most critical module of an infrastructure system without a sophisticated analysis. Many real-world systems have an inherently hierarchical structure in which the leader and the follower have opposite goals. This makes it of critical importance to develop bi-level models which are representative of reality and also computationally tractable. In this paper we design a nested hierarchical evolutionary model in which the attacker evolves as the defender attempts to maximize flow in their multi-commodity network. This scheme takes advantage of the ability to solve Mixed Integer Linear Programing problems (MILPs) extremely quickly using existing maximum flow techniques, while solving the NP-hard bi-level optimization problem heuristically, as our algorithm evolves towards optimality from the attacker's perspective.},
  doi       = {10.1109/ICDIS50059.2020.00022},
  groups    = {First Filtering},
  keywords  = {Optimization;Communication networks;Computational modeling;Security;Power grids;Mathematical model;Linear programming;Critical Infrastructures;Security;Safety;Optimization;Multi-Commodity Network},
}

@Article{8534360,
  author   = {Gao, Tianchong and Li, Feng and Chen, Yu and Zou, XuKai},
  journal  = {IEEE Transactions on Computational Social Systems},
  title    = {Local Differential Privately Anonymizing Online Social Networks Under HRG-Based Model},
  year     = {2018},
  issn     = {2329-924X},
  month    = {Dec},
  number   = {4},
  pages    = {1009-1020},
  volume   = {5},
  abstract = {Following the trend of online social networks (OSNs) data sharing and publishing, users raise serious concerns on OSN privacy. Differential privacy is a mechanism to anonymize sensitive data. It employs graph abstraction models, such as the hierarchical random graph (HRG) model, to extract graph features and then add sufficient noise. However, the noise amount, determined by the sensitivity, is usually proportional to the size of the whole network. Therefore, achieving global differential privacy may harm the utility of releasing graphs. In this paper, we define the notion of group-based local differential privacy. In particular, by resolving the network into 1-neighborhood graphs and applying HRG-based methods, our scheme preserves differential privacy and reduces the noise scale on the local graphs. By deploying the grouping algorithm, our scheme abandons the attempt to anonymize every relationship to be ordinary, but we focus on the similarities in HRG models. In the final released graph, each individual user in one group is not distinguishable, which greatly enhances the OSN privacy. We experimentally evaluate our approach on three real-world OSNs. It produces synthetic graphs that are more closely matched with the originals compared with the existing differential-privacy results.},
  doi      = {10.1109/TCSS.2018.2877045},
  groups   = {First Filtering},
  keywords = {Privacy;Social network services;Feature extraction;Network topology;Sensitivity;Probability;Anonymization;differential privacy;local topological features;social network data publishing},
}

@Article{9211454,
  author   = {Yu, Feng and Dutta, Raj Gautam and Zhang, Teng and Hu, Yaodan and Jin, Yier},
  journal  = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  title    = {Fast Attack-Resilient Distributed State Estimator for Cyber-Physical Systems},
  year     = {2020},
  issn     = {1937-4151},
  month    = {Nov},
  number   = {11},
  pages    = {3555-3565},
  volume   = {39},
  abstract = {The performance of resilient state estimators developed for cyber-physical systems (CPSs) decreases as the number of compromised sensors of the system increases. Furthermore, some of these algorithms leverage computationally expensive optimization techniques to incorporate resiliency. As such, we propose a fast resilient distributed state estimator (FRDSE), which is a novel resilient distributed algorithm that produces bounded state estimation errors regardless of the magnitude of the attack and the number of compromised sensors. Our algorithm converges to the true state in an attack-free and noise-free scenario and it produces bounded estimation errors during an attack. Compared to existing algorithms, FRDSE is more computationally efficient. We provide theoretical guarantees on the convergence of FRDSE in attack-free scenario and prove its resiliency during an attack. We demonstrate the performance of our algorithm against false data injection (FDI) attack in a platoon of vehicles and compare its runtime against existing algorithms. We observe that on a platoon of eight vehicles, runtime of our algorithm is 0.102 s, much lower than the state-of-the-art solutions.},
  doi      = {10.1109/TCAD.2020.3013072},
  groups   = {First Filtering},
  keywords = {Kalman filters;Optimization;Sensor systems;State estimation;Convergence;Cyber-physical system (CPS);distributed estimation;Kalman filter;linear time-invariant (LTI) system;security;vehicle platoon},
}

@InProceedings{9412560,
  author    = {Watson, Matthew and Al Moubayed, Noura},
  booktitle = {2020 25th International Conference on Pattern Recognition (ICPR)},
  title     = {Attack-agnostic Adversarial Detection on Medical Data Using Explainable Machine Learning},
  year      = {2021},
  month     = {Jan},
  pages     = {8180-8187},
  abstract  = {Explainable machine learning has become increasingly prevalent, especially in healthcare where explainable models are vital for ethical and trusted automated decision making. Work on the susceptibility of deep learning models to adversarial attacks has shown the ease of designing samples to mislead a model into making incorrect predictions. In this work, we propose a model agnostic explainability-based method for the accurate detection of adversarial samples on two datasets with different complexity and properties: Electronic Health Record (EHR) and chest X-ray (CXR) data. On the MIMIC-III and Henan-Renmin EHR datasets, we report a detection accuracy of 77% against the Longitudinal Adversarial Attack. On the MIMIC-CXR dataset, we achieve an accuracy of 88%; significantly improving on the state of the art of adversarial detection in both datasets by over 10% in all settings. We propose an anomaly detection based method using explainability techniques to detect adversarial samples which is able to generalise to different attack methods without a need for retraining.},
  doi       = {10.1109/ICPR48806.2021.9412560},
  groups    = {First Filtering},
  issn      = {1051-4651},
  keywords  = {Training;Deep learning;Perturbation methods;MIMICs;Medical services;Predictive models;Feature extraction;Adversarial Attacks;Explainability;SHAP;Medical Data},
}

@InProceedings{6952790,
  author    = {Attar, Ali El and Khatoun, Rida and Birregah, Babiga and Lemercier, Marc},
  booktitle = {2014 IEEE Wireless Communications and Networking Conference (WCNC)},
  title     = {Robust clustering methods for detecting smartphone's abnormal behavior},
  year      = {2014},
  month     = {April},
  pages     = {2552-2557},
  abstract  = {Smartphones have become increasingly popular, and, nowadays, thanks to the use of 3G networks, the need for connectivity in a business environment is significant. Smartphones provide access to a tremendous amount of sensitive information related to business, such as customer contacts, financial data and Intranet networks. If any of this information were to fall into the hands of hackers, it would be devastating for the company. In this paper, we propose a cluster-based approach to detecting abnormal behaviour in smartphone applications. First we carry out various robust clustering techniques that help to identify and regroup applications that exhibit similar behaviour. The clustering results are then used to define a cluster-based outlier factor for each application, which in turn identifies the top n malware applications. Initial results of the experiments prove the efficiency and accuracy of cluster-based approaches in detecting abnormal smartphone applications and those with a low false-alert rate.},
  doi       = {10.1109/WCNC.2014.6952790},
  groups    = {First Filtering},
  issn      = {1558-2612},
  keywords  = {Smart phones;Malware;Clustering algorithms;Robustness;Clustering methods;Batteries;Mobile communication},
}

@InProceedings{9157671,
  author    = {Zhou, Hang and Chen, Dongdong and Liao, Jing and Chen, Kejiang and Dong, Xiaoyi and Liu, Kunlin and Zhang, Weiming and Hua, Gang and Yu, Nenghai},
  booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {LG-GAN: Label Guided Adversarial Network for Flexible Targeted Attack of Point Cloud Based Deep Networks},
  year      = {2020},
  month     = {June},
  pages     = {10353-10362},
  abstract  = {Deep neural networks have made tremendous progress in 3D point-cloud recognition. Recent works have shown that these 3D recognition networks are also vulnerable to adversarial samples produced from various attack methods, including optimization-based 3D Carlini-Wagner attack, gradient-based iterative fast gradient method, and skeleton-detach based point-dropping. However, after a careful analysis, these methods are either extremely slow because of the optimization/iterative scheme, or not flexible to support targeted attack of a specific category. To overcome these shortcomings, this paper proposes a novel label guided adversarial network (LG-GAN) for real-time flexible targeted point cloud attack. To the best of our knowledge, this is the first generation based 3D point cloud attack method. By feeding the original point clouds and target attack label into LG-GAN, it can learn how to deform the point clouds to mislead the recognition network into the specific label only with a single forward pass. In detail, LG-GAN first leverages one multi-branch adversarial network to extract hierarchical features of the input point clouds, then incorporates the specified label information into multiple intermediate features using the label encoder. Finally, the encoded features will be fed into the coordinate reconstruction decoder to generate the target adversarial sample. By evaluating different point-cloud recognition models (e.g., PointNet, PointNet++ and DGCNN), we demonstrate that the proposed LG-GAN can support flexible targeted attack on the fly while guaranteeing good attack performance and higher efficiency simultaneously.},
  doi       = {10.1109/CVPR42600.2020.01037},
  groups    = {First Filtering},
  issn      = {2575-7075},
  keywords  = {Three-dimensional displays;Feature extraction;Perturbation methods;Decoding;Training;Neural networks;Target recognition},
}

@Article{8765784,
  author   = {Samaraweera, G. Dumindu and Chang, J. Morris},
  journal  = {IEEE Transactions on Knowledge and Data Engineering},
  title    = {Security and Privacy Implications on Database Systems in Big Data Era: A Survey},
  year     = {2021},
  issn     = {1558-2191},
  month    = {Jan},
  number   = {1},
  pages    = {239-258},
  volume   = {33},
  abstract = {For over many decades, relational database model has been considered as the leading model for data storage and management. However, as the Big Data explosion has generated a large volume of data, alternative models like NoSQL and NewSQL have emerged. With the advancement of communication technology, these database systems have given the potential to change the existing architecture from centralized mechanism to distributed in nature, to deploy as cloud-based solutions. Though all of these evolving technologies mostly focus on performance guarantees, it is still being a major concern how these systems can ensure the security and privacy of the information they handle. Different datastores support different types of integrated security mechanisms, however, most of the non-relational database systems have overlooked the security requirements of modern Big Data applications. This paper reviews security implementations in today's leading database models giving more emphasis on security and privacy attributes. A set of standard security mechanisms have been identified and evaluated based on different security classifications. Further, it provides a thorough review and a comprehensive analysis on maturity of security and privacy implementations in these database models along with future directions/enhancements so that data owners can decide on most appropriate datastore for their data-driven Big Data applications.},
  doi      = {10.1109/TKDE.2019.2929794},
  groups   = {First Filtering},
  keywords = {Data privacy;Solid modeling;Big Data applications;Data models;Database systems;Security;Standards;Big data;database systems;attacks;threats;security;privacy;performance},
}

@InProceedings{9283064,
  author    = {Al-Abassi, Abdulrahman and Sakhnini, Jacob and Karimipour, Hadis},
  booktitle = {2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  title     = {Unsupervised Stacked Autoencoders for Anomaly Detection on Smart Cyber-physical Grids},
  year      = {2020},
  month     = {Oct},
  pages     = {3123-3129},
  abstract  = {Smart Cyber Physical Grids are the new wave of power system technology that integrates networks of sensors with power stations for more efficient power generation and distribution. While utilizing communication networks is accompanied with tremendous advantages, it also increases the vulnerability of power systems to cyber attacks. Many methods for security and attack detection have been proposed in literature; however, most papers do not consider the imbalance of data in real power systems. In this paper, we propose a deep learning based method, referred to as Ensemble Stacked AutoEncoder (ESAE), aimed at tackling the problem of data imbalance. This method achieves superior performance on imbalanced data by developing a deep representation learning model to construct new balanced representations. The detection accuracy and model performance is improved by utilizing an ensemble architecture based on Stacked Autoencoders and Random Forest classifiers to detect attacks from the new representations. The proposed method is tested on all degrees of data imbalance using test cases of IEEE 14-bus, 30-bus, and 57-bus systems. Comparisons are made to several classifiers to demonstrate the effectiveness of the proposed algorithm.},
  doi       = {10.1109/SMC42975.2020.9283064},
  groups    = {First Filtering},
  issn      = {2577-1655},
  keywords  = {Deep learning;Power systems;Classification algorithms;Smart grids;Security;Random forests;Power generation;cyber security;smart grid;machine learning;deep learning},
}

@Article{8827915,
  author   = {Yan, Xiaodan and Cui, Baojiang and Xu, Yang and Shi, Peilin and Wang, Ziqi},
  journal  = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
  title    = {A Method of Information Protection for Collaborative Deep Learning under GAN Model Attack},
  year     = {2021},
  issn     = {1557-9964},
  month    = {May},
  number   = {3},
  pages    = {871-881},
  volume   = {18},
  abstract = {Deep learning is widely used in the medical field owing to its high accuracy in medical image classification and biological applications. However, under collaborative deep learning, there is a serious risk of information leakage based on the deep convolutional generation against the network's privacy protection method. Moreover, the risk of such information leakage is greater in the medical field. This paper proposes a deep convolution generative adversarial networks (DCGAN) based privacy protection method to protect the information of collaborative deep learning training and enhance its stability. The proposed method adopts encrypted transmission in the process of deep network parameter transmission. By setting the buried point to detect a generative adversarial network (GAN) attack in the network and adjusting the training parameters, training based on the GAN model attack is forced to be invalid, and the information is effectively protected.},
  doi      = {10.1109/TCBB.2019.2940583},
  groups   = {First Filtering},
  keywords = {Deep learning;Generative adversarial networks;Training;Collaboration;Privacy;Biomedical imaging;Gallium nitride;GAN;collaborative deep learning;security;privacy},
}

@Article{8936543,
  author   = {Yun, Xiaochun and Huang, Ji and Wang, Yipeng and Zang, Tianning and Zhou, Yuan and Zhang, Yongzheng},
  journal  = {IEEE Transactions on Information Forensics and Security},
  title    = {Khaos: An Adversarial Neural Network DGA With High Anti-Detection Ability},
  year     = {2020},
  issn     = {1556-6021},
  pages    = {2225-2240},
  volume   = {15},
  abstract = {A botnet is a network of remote-controlled devices that are infected with malware controlled by botmasters in order to launch cyber attacks. To evade detection, the botmaster frequently changes the domain name of his Command and Control (C&C) server. Notice that most of these types of domain names are generated by domain generation algorithms (DGAs). In this paper, we propose Khaos, a novel DGA with high anti-detection ability based on neural language models and the Wasserstein Generative Adversarial Network (WGAN). The key insight of our research is that real domain names are composed of readable syllables and acronyms, and thus we can arrange syllables and acronyms using neural language models to mimic real domain names. In Khaos, we first find the most common n-grams in real domain names, then tokenize these domain names into n-grams, and finally synthesize new domain names after learning arrangements of n-grams from real domain names. We carry out experiments using a variety of state-of-the-art DGA detection approaches: the statistics-based, the distribution-based, the LSTM-based and the graph-based detection approach. Our experimental results show that the average distance for detecting Khaos under the distribution-based detection approach is 0.64, the AUCs of Khaos under the statistics-based and the LSTM-based detection approach are 0.76 and 0.57, respectively, and the precision of Khaos under the graph-based detection approach is 0.68. Our work proves that the existing detection approaches have big troubles in detecting Khaos, and Khaos has better anti-detection ability than state-of-the-art DGAs. In addition, we find that training the existing detection approach on a dataset including the domain names generated by Khaos can improve its detection ability.},
  doi      = {10.1109/TIFS.2019.2960647},
  groups   = {First Filtering},
  keywords = {Hidden Markov models;Terminology;Servers;Generative adversarial networks;Botnet;Training;Gallium nitride;Domain generation algorithms;generative adversarial network;neural language models;deep learning;cyber security},
}

@InProceedings{6666533,
  author    = {Karapistoli, Eirini and Economides, Anastasios A.},
  booktitle = {2013 IEEE 24th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC)},
  title     = {Anomaly detection and localization in UWB wireless sensor networks},
  year      = {2013},
  month     = {Sep.},
  pages     = {2326-2330},
  abstract  = {Wireless sensor networks (WSNs) are gaining more and more interest in the research community due to their unique characteristics. Besides energy consumption considerations, security has emerged as an equally important aspect in their network design. WSNs are vulnerable to various types of attacks, and as such, they require mechanisms to defend against them. Several anomaly detection algorithms have been proposed to date as a solution to the problem. However, none of them is specifically designed for the ultra-wideband (UWB) technology. UWB is a key solution for wireless connectivity characterized by ultra low power consumption, and high precision ranging. Based on these principles, we propose a novel anomaly detection and localization algorithm for cluster-based UWB wireless sensor networks. Towards securing the cluster formation protocol, we also define a novel, trust-aware leader election metric. The performance of the proposed algorithm in identifying intrusions using a rule-based detection technique is studied via simulations.},
  doi       = {10.1109/PIMRC.2013.6666533},
  groups    = {First Filtering},
  issn      = {2166-9589},
  keywords  = {Wireless sensor networks;Monitoring;Protocols;Peer-to-peer computing;Accuracy;Distance measurement;Clustering algorithms},
}

@InProceedings{7543760,
  author    = {Jiexin Zhang and Shaoduo Gan and Liu, Xiaoxue and Zhu, Peidong},
  booktitle = {2016 IEEE Symposium on Computers and Communication (ISCC)},
  title     = {Intrusion detection in SCADA systems by traffic periodicity and telemetry analysis},
  year      = {2016},
  month     = {June},
  pages     = {318-325},
  abstract  = {Supervisory control and data acquisition (SCADA) system is a vital component of critical infrastructures (CIs). However, most protocols in SCADA systems lack either authentication or integrity checking mechanisms, which makes them extremely vulnerable to cyber attacks when increasingly more SCADA systems are connected with external networks. Intrusion detection systems (IDSs) have been proposed to enhance the system security, but few of them can effectively resist response injection and denial of service attacks at the same time. In this paper we present an IDS named PT-IDS to fill this gap by investigating the periodicity and telemetry patterns of network traffic within typical SCADA systems. Firstly, we analyze the periodicity characteristics in SCADA networks and classify them into four categories through designing an analyzer algorithm. Furthermore, in order to effectively detect response injection attacks, we design an auxiliary module to analyze the network telemetry pattern. Results from both modules are considered simultaneously to promote the accuracy of intrusion detection, especially for denial of service attacks. Beyond that, our proposed system can give alarm reports including both warnings and matching severity information. The time complexity of both analyzer algorithms is polynomial and simulations demonstrate the effectiveness and efficiency of our IDS mechanism.},
  doi       = {10.1109/ISCC.2016.7543760},
  groups    = {First Filtering},
  keywords  = {Telemetry;SCADA systems;Protocols;Intrusion detection;Computer crime;Computers;SCADA;Cyber-Physical Security;Traffic Periodicity;Network Telemetry;Intrusion Detection},
}

@Article{9404267,
  author   = {Zhang, Haoyu and Venkatesh, Sushma and Ramachandra, Raghavendra and Raja, Kiran and Damer, Naser and Busch, Christoph},
  journal  = {IEEE Transactions on Biometrics, Behavior, and Identity Science},
  title    = {MIPGAN—Generating Strong and High Quality Morphing Attacks Using Identity Prior Driven GAN},
  year     = {2021},
  issn     = {2637-6407},
  month    = {July},
  number   = {3},
  pages    = {365-383},
  volume   = {3},
  abstract = {Face morphing attacks target to circumvent Face Recognition Systems (FRS) by employing face images derived from multiple data subjects (e.g., accomplices and malicious actors). Morphed images can be verified against contributing data subjects with a reasonable success rate, given they have a high degree of facial resemblance. The success of morphing attacks is directly dependent on the quality of the generated morph images. We present a new approach for generating strong attacks extending our earlier framework for generating face morphs. We present a new approach using an Identity Prior Driven Generative Adversarial Network, which we refer to as MIPGAN (Morphing through Identity Prior driven GAN). The proposed MIPGAN is derived from the StyleGAN with a newly formulated loss function exploiting perceptual quality and identity factor to generate a high quality morphed facial image with minimal artefacts and with high resolution. We demonstrate the proposed approach’s applicability to generate strong morphing attacks by evaluating its vulnerability against both commercial and deep learning based Face Recognition System (FRS) and demonstrate the success rate of attacks. Extensive experiments are carried out to assess the FRS’s vulnerability against the proposed morphed face generation technique on three types of data such as digital images, re-digitized (printed and scanned) images, and compressed images after re-digitization from newly generated MIPGAN Face Morph Dataset. The obtained results demonstrate that the proposed approach of morph generation poses a high threat to FRS.},
  doi      = {10.1109/TBIOM.2021.3072349},
  groups   = {First Filtering},
  keywords = {Faces;Face recognition;Gallium nitride;Generative adversarial networks;Manuals;Visualization;Security;Morphing attack;GAN;attack detection;face recognition;vulnerability;deep learning},
}

@InProceedings{9206780,
  author    = {Kuppa, Aditya and Le-Khac, Nhien-An},
  booktitle = {2020 International Joint Conference on Neural Networks (IJCNN)},
  title     = {Black Box Attacks on Explainable Artificial Intelligence(XAI) methods in Cyber Security},
  year      = {2020},
  month     = {July},
  pages     = {1-8},
  abstract  = {Cybersecurity community is slowly leveraging Machine Learning (ML) to combat ever evolving threats. One of the biggest drivers for successful adoption of these models is how well domain experts and users are able to understand and trust their functionality. As these black-box models are being employed to make important predictions, the demand for transparency and explainability is increasing from the stakeholders.Explanations supporting the output of ML models are crucial in cyber security, where experts require far more information from the model than a simple binary output for their analysis. Recent approaches in the literature have focused on three different areas: (a) creating and improving explainability methods which help users better understand the internal workings of ML models and their outputs; (b) attacks on interpreters in white box setting; (c) defining the exact properties and metrics of the explanations generated by models. However, they have not covered, the security properties and threat models relevant to cybersecurity domain, and attacks on explainable models in black box settings.In this paper, we bridge this gap by proposing a taxonomy for Explainable Artificial Intelligence (XAI) methods, covering various security properties and threat models relevant to cyber security domain. We design a novel black box attack for analyzing the consistency, correctness and confidence security properties of gradient based XAI methods. We validate our proposed system on 3 security-relevant data-sets and models, and demonstrate that the method achieves attacker's goal of misleading both the classifier and explanation report and, only explainability method without affecting the classifier output. Our evaluation of the proposed approach shows promising results and can help in designing secure and robust XAI methods.},
  doi       = {10.1109/IJCNN48605.2020.9206780},
  groups    = {First Filtering},
  issn      = {2161-4407},
  keywords  = {Data models;Computer security;Analytical models;Robustness;Privacy;Predictive models;Adversarial Attack;Explainable Artificial Intelligence;Cyber security;gradient-based XAI;deep learning},
}

@Article{6419708,
  author   = {Chung, Chun-Jen and Khatkar, Pankaj and Xing, Tianyi and Lee, Jeongkeun and Huang, Dijiang},
  journal  = {IEEE Transactions on Dependable and Secure Computing},
  title    = {NICE: Network Intrusion Detection and Countermeasure Selection in Virtual Network Systems},
  year     = {2013},
  issn     = {1941-0018},
  month    = {July},
  number   = {4},
  pages    = {198-211},
  volume   = {10},
  abstract = {Cloud security is one of most important issues that has attracted a lot of research and development effort in past few years. Particularly, attackers can explore vulnerabilities of a cloud system and compromise virtual machines to deploy further large-scale Distributed Denial-of-Service (DDoS). DDoS attacks usually involve early stage actions such as multistep exploitation, low-frequency vulnerability scanning, and compromising identified vulnerable virtual machines as zombies, and finally DDoS attacks through the compromised zombies. Within the cloud system, especially the Infrastructure-as-a-Service (IaaS) clouds, the detection of zombie exploration attacks is extremely difficult. This is because cloud users may install vulnerable applications on their virtual machines. To prevent vulnerable virtual machines from being compromised in the cloud, we propose a multiphase distributed vulnerability detection, measurement, and countermeasure selection mechanism called NICE, which is built on attack graph-based analytical models and reconfigurable virtual network-based countermeasures. The proposed framework leverages OpenFlow network programming APIs to build a monitor and control plane over distributed programmable virtual switches to significantly improve attack detection and mitigate attack consequences. The system and security evaluations demonstrate the efficiency and effectiveness of the proposed solution.},
  doi      = {10.1109/TDSC.2013.8},
  groups   = {First Filtering},
  keywords = {Servers;Intrusion detection;Correlation;Silicon;Software;Control systems;Network security;cloud computing;intrusion detection;attack graph;zombie detection},
}

@InProceedings{9152761,
  author    = {Pan, Xudong and Zhang, Mi and Ji, Shouling and Yang, Min},
  booktitle = {2020 IEEE Symposium on Security and Privacy (SP)},
  title     = {Privacy Risks of General-Purpose Language Models},
  year      = {2020},
  month     = {May},
  pages     = {1314-1331},
  abstract  = {Recently, a new paradigm of building general-purpose language models (e.g., Google's Bert and OpenAI's GPT-2) in Natural Language Processing (NLP) for text feature extraction, a standard procedure in NLP systems that converts texts to vectors (i.e., embeddings) for downstream modeling, has arisen and starts to find its application in various downstream NLP tasks and real world systems (e.g., Google's search engine [6]). To obtain general-purpose text embeddings, these language models have highly complicated architectures with millions of learnable parameters and are usually pretrained on billions of sentences before being utilized. As is widely recognized, such a practice indeed improves the state-of-the-art performance of many downstream NLP tasks. However, the improved utility is not for free. We find the text embeddings from general-purpose language models would capture much sensitive information from the plain text. Once being accessed by the adversary, the embeddings can be reverse-engineered to disclose sensitive information of the victims for further harassment. Although such a privacy risk can impose a real threat to the future leverage of these promising NLP tools, there are neither published attacks nor systematic evaluations by far for the mainstream industry-level language models. To bridge this gap, we present the first systematic study on the privacy risks of 8 state-of-the-art language models with 4 diverse case studies. By constructing 2 novel attack classes, our study demonstrates the aforementioned privacy risks do exist and can impose practical threats to the application of general-purpose language models on sensitive data covering identity, genome, healthcare and location. For example, we show the adversary with nearly no prior knowledge can achieve about 75% accuracy when inferring the precise disease site from Bert embeddings of patients' medical descriptions. As possible countermeasures, we propose 4 different defenses (via rounding, differential privacy, adversarial training and subspace projection) to obfuscate the unprotected embeddings for mitigation purpose. With extensive evaluations, we also provide a preliminary analysis on the utility-privacy trade-off brought by each defense, which we hope may foster future mitigation researches.},
  doi       = {10.1109/SP40000.2020.00095},
  groups    = {First Filtering},
  issn      = {2375-1207},
  keywords  = {Privacy;Natural language processing;Google;Bioinformatics;Machine learning;Genomics;Training},
}

@InProceedings{7346868,
  author    = {Costin, Andrei},
  booktitle = {2015 IEEE Conference on Communications and Network Security (CNS)},
  title     = {All your cluster-grids are belong to us: Monitoring the (in)security of infrastructure monitoring systems},
  year      = {2015},
  month     = {Sep.},
  pages     = {550-558},
  abstract  = {Monitoring of the high-performance computing systems and their components, such as clusters, grids and federations of clusters, is performed using monitoring systems for servers and networks, or Network Monitoring Systems (NMS). These monitoring tools assist system administrators in assessing and improving the health of their infrastructure. A successful attack on the infrastructure monitoring tools grants the attacker elevated power over the monitoring tasks, and eventually over some management functionality of the interface or over hosts running those interfaces. Additionally, detailed and accurate fingerprinting and reconnaissance of a target infrastructure is possible when such interfaces are publicly exposed. A successful reconnaissance allows an attacker to craft an efficient secondstage attacks, such as targeted, mimicry and blended attacks. We provide in this paper a comprehensive security analysis of some of the most popular infrastructure monitoring tools for grids, clusters and High-Performance Computing (HPC) systems. We also provide insights based on the infrastructure data openly exposed over the Internet. The wide use of some of the most popular infrastructure monitoring tools makes this data exposure possible. For example, we found such monitoring interfaces to expose infrastructure details of systems inside many high-profile organizations, including two top national laboratories for nuclear research and one top Internet non-profit foundation. We also present our findings on a plethora of web vulnerabilities in the entire version-span of such monitoring tools, and discuss at a high-level the possible attacks. The results of our research allow us to “monitor” an “alarming” mismanagement reality of grid infrastructure. The aim of this work is to raise the awareness about this novel risk to cloud infrastructure.},
  doi       = {10.1109/CNS.2015.7346868},
  groups    = {First Filtering},
  keywords  = {Monitoring;Kernel;Security;Cloud computing;Ports (Computers);Privacy;Servers},
}

@InProceedings{9030355,
  author    = {Shrivastava, Rajesh Kumar and Ramakrishna, Saradhi and Hota, Chittaranjan},
  booktitle = {2019 IEEE 16th India Council International Conference (INDICON)},
  title     = {Game Theory based Modified Naïve-bayes Algorithm to detect DoS attacks using Honeypot},
  year      = {2019},
  month     = {Dec},
  pages     = {1-4},
  abstract  = {The omnipresent nature of the Internet makes everything vulnerable against DoS attacks in IoT environments. An adversary tries to mount attacks to serve his/her nefarious purposes. Preventing IoT network from this type of attack is a complex and challenging problem. A game theory model is best suited to explore the network security problems. Attack and defense is a continuous game in network security. A defender tries to neutralise an attack by using his secret defensive method while an attacker attempts to defeat the security mechanism. They both compete against each other's methods. In this paper, we propose a game-theoretic model which uses the nash equilibrium to expose an adversary's attack attempt and verify the defense mechanism against the same attack. In this work, a combination of Naïve- bayes with K-means clustering algorithm is used to evaluate the unlabelled data and explore malware attacks. We have also proposed a solution to mitigate IoT attacks using a firewall and an IDS.},
  doi       = {10.1109/INDICON47234.2019.9030355},
  groups    = {First Filtering},
  issn      = {2325-9418},
  keywords  = {Games;IP networks;Nash equilibrium;Computer crime;Monitoring;Game Theory;Naïve Bayes;Clustering;K-means},
}

@Article{9403404,
  author   = {Dehmollaian, Eshagh and Etzlinger, Bernhard and Torres, Núria Ballber and Springer, Andreas},
  journal  = {IEEE Wireless Communications Letters},
  title    = {Using Channel State Information for Physical Tamper Attack Detection in OFDM Systems: A Deep Learning Approach},
  year     = {2021},
  issn     = {2162-2345},
  month    = {July},
  number   = {7},
  pages    = {1503-1507},
  volume   = {10},
  abstract = {This letter proposes a deep learning approach to detect a change in the antenna orientation of transmitter or receiver as a physical tamper attack in OFDM systems using channel state information. We treat the physical tamper attack problem as a semi-supervised anomaly detection problem and utilize a deep convolutional autoencoder (DCAE) to tackle it. The past observations of the estimated channel state information (CSI) are used to train the DCAE. Then, a post-processing is deployed on the trained DCAE output to perform the physical tamper detection. Our experimental results show that the proposed approach, deployed in an office and a hall environment, is able to detect on average 99.6% of tamper events (TPR = 99.6%) while creating zero false alarms (FPR = 0%).},
  doi      = {10.1109/LWC.2021.3072937},
  groups   = {First Filtering},
  keywords = {Receivers;Radio transmitters;Training;Convolution;Wireless networks;Decoding;Channel state information;OFDM;channel state information;deep learning, deep convolutional autoencoder;physical tamper attack},
}

@InProceedings{6603524,
  author    = {Otsuka, Akira},
  booktitle = {2013 International Conference on Biometrics and Kansei Engineering},
  title     = {Wolf Attack: Algorithmic Vulnerability in Biometric Authentication Systems},
  year      = {2013},
  month     = {July},
  pages     = {309-313},
  abstract  = {Biometrics is a key technology for the authentication of individuals. As far as malicious impersonation attempt cannot be put an end, security is essential for biometric authentication systems. The security of biometric authentication systems is conventionally measured by false acceptance rate (FAR), the average probability of falsely accepting an individual claiming different identity. Since malicious attackers are not limited to use their own biometric features, clearly, FAR is not sufficient for the measure of security. On the other hand, it is pointed out that deep analysis of biometric authentication algorithms often shows that some irregular artificial patterns give very high acceptance rate against large portion of registered human templates. This is called wolf attack. Including this class of attack, in this paper, we formulate the security of biometric authentication systems, and demonstrate our recent results in fingerprint recognition systems. Finally, we introduce the theoretical framework for securing biometric authentication systems.},
  doi       = {10.1109/ICBAKE.2013.90},
  groups    = {First Filtering},
  keywords  = {Biometrics (access control);Authentication;Algorithm design and analysis;Wireless application protocol;NIST;Lattices;biometrics;security},
}

@InProceedings{8409169,
  author    = {Kargaard, Joakim and Drange, Tom and Kor, Ah-Lian and Twafik, Hissam and Butterfield, Emlyn},
  booktitle = {2018 IEEE 9th International Conference on Dependable Systems, Services and Technologies (DESSERT)},
  title     = {Defending IT systems against intelligent malware},
  year      = {2018},
  month     = {May},
  pages     = {411-417},
  abstract  = {The increasing amount of malware variants seen in the wild is causing problems for Antivirus Software vendors, unable to keep up by creating signatures for each. The methods used to develop a signature, static and dynamic analysis, have various limitations. Machine learning has been used by Antivirus vendors to detect malware based on the information gathered from the analysis process. However, adversarial examples can cause machine learning algorithms to miss-classify new data. In this paper we describe a method for malware analysis by converting malware binaries to images and then preparing those images for training within a Generative Adversarial Network. These unsupervised deep neural networks are not susceptible to adversarial examples. The conversion to images from malware binaries should be faster than using dynamic analysis and it would still be possible to link malware families together. Using the Generative Adversarial Network, malware detection could be much more effective and reliable.},
  doi       = {10.1109/DESSERT.2018.8409169},
  groups    = {First Filtering},
  keywords  = {Malware;Gallium nitride;Machine learning;Training;Machine learning algorithms;Classification algorithms;Art;Malware;machine learning;Generative Adversarial Networks;malware images},
}

@InProceedings{6838385,
  author    = {El Attar, Ali and Khatoun, Rida and Lemercier, Marc},
  booktitle = {2014 IEEE Network Operations and Management Symposium (NOMS)},
  title     = {Clustering-based anomaly detection for smartphone applications},
  year      = {2014},
  month     = {May},
  pages     = {1-4},
  abstract  = {Nowadays, Smartphones have been widely used due to their capabilities in communication and multimedia processing. Smartphones provide access to a tremendous amount of sensitive information related to business, such as customer contacts, financial data, and Intranet networks. Hence, the Internet of the future will be mobile Internet. However, threat of malicious software has become an important factor in the smartphones security. In this paper, a new behavior-based malware detection framework using three clustering methods (PAM, DBSCAN and t-distribution) is proposed. Experimental results show that the approach has high detection rate and low rate of false positive and false negative.},
  doi       = {10.1109/NOMS.2014.6838385},
  groups    = {First Filtering},
  issn      = {2374-9709},
  keywords  = {Malware;Clustering algorithms;Clustering methods;Measurement;Robustness;Noise},
}

@Article{8643523,
  author   = {Dai, Qiangsheng and Shi, Libao and Ni, Yixin},
  journal  = {IEEE Transactions on Power Systems},
  title    = {Risk Assessment for Cyberattack in Active Distribution Systems Considering the Role of Feeder Automation},
  year     = {2019},
  issn     = {1558-0679},
  month    = {July},
  number   = {4},
  pages    = {3230-3240},
  volume   = {34},
  abstract = {The extensive application of information and communication technology (ICT) can effectively improve the operational performance of active distribution systems (ADSs). On the other hand, the use of ICT may expose the systems to cyberattacks. Since feeder automation (FA) in advanced ADS provides fast-responding self-healing capability to restore service during an outage, the potential effect of cyberattacks on ADS becomes more devastating. In this paper, two simple yet powerful cyberattack methods targeting remote terminal units (RTUs) are proposed. The physical response of ADS to malicious cyberattacks on FA is elaborately investigated considering the output fluctuation of distributed generators. The impact of this specific cyberattack on ADS is quantified by a risk assessment index measured in scale and in duration to full restoration. The probability of RTU potentially being attacked is modeled based on search theory. Furthermore, a Bayesian attack graph model is applied and designed to quantify the probability of successfully exploiting the currently known and zero-day vulnerabilities. The proposed methodology is tested and validated via using a modified three-feeder ADS and the IEEE 123 Node Test Feeder.},
  doi      = {10.1109/TPWRS.2019.2899983},
  groups   = {First Filtering},
  keywords = {Cyberattack;Power system reliability;Circuit breakers;Computer hacking;Risk management;Automation;Cyber-physical system;cyber security;feeder automation;Bayesian attack graph;risk assessment},
}

@InProceedings{8974951,
  author    = {Ou, Yifan and Deng, Bin and Liu, Xuan and Zhou, Ke},
  booktitle = {2019 IEEE Sustainable Power and Energy Conference (iSPEC)},
  title     = {Local Outlier Factor Based False Data Detection in Power Systems},
  year      = {2019},
  month     = {Nov},
  pages     = {2003-2007},
  abstract  = {The rapid developments of smart grids provide multiple benefits to the delivery of electric power, but at the same time makes the power grids under the threat of cyber attackers. The transmitted data could be deliberately modified without triggering the alarm of bad data detection procedure. In order to ensure the stable operation of the power systems, it is extremely significant to develop effective abnormal detection algorithms against injected false data. In this paper, we introduce the density-based LOF algorithm to detect the false data and dummy data. The simulation results show that the traditional density-clustering based LOF algorithm can effectively identify FDA, but the detection performance on DDA is not satisfactory. Therefore, we propose the improved LOF algorithm to detect DDA by setting reasonable density threshold.},
  doi       = {10.1109/iSPEC48194.2019.8974951},
  groups    = {First Filtering},
  keywords  = {local outlier factor;anomaly detection;false data attack;dummy data attack;density clustering;power systems},
}

@Article{7126970,
  author   = {Legg, Philip A. and Buckley, Oliver and Goldsmith, Michael and Creese, Sadie},
  journal  = {IEEE Systems Journal},
  title    = {Automated Insider Threat Detection System Using User and Role-Based Profile Assessment},
  year     = {2017},
  issn     = {1937-9234},
  month    = {June},
  number   = {2},
  pages    = {503-512},
  volume   = {11},
  abstract = {Organizations are experiencing an ever-growing concern of how to identify and defend against insider threats. Those who have authorized access to sensitive organizational data are placed in a position of power that could well be abused and could cause significant damage to an organization. This could range from financial theft and intellectual property theft to the destruction of property and business reputation. Traditional intrusion detection systems are neither designed nor capable of identifying those who act maliciously within an organization. In this paper, we describe an automated system that is capable of detecting insider threats within an organization. We define a tree-structure profiling approach that incorporates the details of activities conducted by each user and each job role and then use this to obtain a consistent representation of features that provide a rich description of the user's behavior. Deviation can be assessed based on the amount of variance that each user exhibits across multiple attributes, compared against their peers. We have performed experimentation using ten synthetic data-driven scenarios and found that the system can identify anomalous behavior that may be indicative of a potential threat. We also show how our detection system can be combined with visual analytics tools to support further investigation by an analyst.},
  doi      = {10.1109/JSYST.2015.2438442},
  groups   = {First Filtering},
  keywords = {Organizations;Electronic mail;Computer security;Feature extraction;Intellectual property;Psychology;Anomaly detection;cyber security;insider threat},
}

@InProceedings{5929036,
  author    = {Hershey, Paul C. and Silio, Charles B.},
  booktitle = {2011 IEEE International Systems Conference},
  title     = {Monitoring and management approach for cyber security events over complex systems},
  year      = {2011},
  month     = {April},
  pages     = {38-45},
  abstract  = {DoD, agency and commercial operations centers that manage complex enterprise systems face the problem of protecting both the systems and the data they carry against cyber attacks while, at the same time, providing high quality end-to-end services that meet service level agreements and help ensure mission success. Presently there exists no comprehensive tool suite that encompasses the procedures, methods, and policies to provide an effective enterprise cyber security monitoring and management solution. This paper provides a basis from which to fill that void by introducing a new framework for monitoring and managing cyber security events in complex systems. We demonstrate application of this framework using several realistic scenarios.},
  doi       = {10.1109/SYSCON.2011.5929036},
  groups    = {First Filtering},
  keywords  = {Monitoring;Computer security;Measurement;Servers;Databases;Authorization;Complex Systems;Cyber Security;Information Assurance;Enterprise Systems;Network Centric;Communications Systems;Monitoring and Response;Network Management},
}

@InProceedings{9460523,
  author    = {Gu, Zhipin and Yang, Yuexiang},
  booktitle = {2021 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  title     = {Detecting Malicious Model Updates from Federated Learning on Conditional Variational Autoencoder},
  year      = {2021},
  month     = {May},
  pages     = {671-680},
  abstract  = {In federated learning, the central server combines local model updates from the clients in the network to create an aggregated model. To protect clients’ privacy, the server is designed to have no visibility into how these updates are generated. The nature of federated learning makes detecting and defending against malicious model updates a challenging task. Unlike existing works that struggle to defend against Byzantine clients, the paper considers defending against targeted model poisoning attack in the federated learning setting. The adversary aims to reduce the model performance on targeted subtasks while maintaining the main task’s performance. This paper proposes Fedcvae, a robust and unsupervised federated learning framework where the central server uses conditional variational autoencoder to detect and exclude malicious model updates. Since the reconstruction error of malicious updates is much larger than that of benign ones, it can be used as an anomaly score. We formulate a dynamic threshold of reconstruction error to differentiate malicious updates from normal ones based on this idea. Fedcvae is tested with extensive experiments on IID and non-IID federated benchmarks, showing a competitive performance over existing aggregation methods under Byzantine attack and targeted model poisoning attack.},
  doi       = {10.1109/IPDPS49936.2021.00075},
  groups    = {First Filtering},
  issn      = {1530-2075},
  keywords  = {Privacy;Distributed processing;Benchmark testing;Collaborative work;Servers;Task analysis;Anomaly detection;federated learning;anomaly detection},
}

@InProceedings{8756439,
  author    = {Zhao-hui, Ma and Gan-sen, Zhao and Wei-wen, Li and Ze-feng, Mo and Xin-ming, Wang and Bing-chuan, Chen and Cheng-chuang, Lin},
  booktitle = {2018 International Conference on Cloud Computing, Big Data and Blockchain (ICCBB)},
  title     = {Research on DDoS Attack Detection in Software Defined Network},
  year      = {2018},
  month     = {Nov},
  pages     = {1-6},
  abstract  = {Software Defined Network (SDN) is a new network construction. But due to its construction, SDN is vulnerable to be attacked by Distributed Denial of Service (DDoS) attack. So it is important to detect DDoS attack in SDN network. This paper presents a DDoS detection scheme based on k-means algorithm in SDN environment. The establishment of this scheme is based on the two hypotheses that the daily network works normally most of the time, and there is a significant difference between the data characteristics of normal situation and abnormal situation. At the same time, these two hypotheses are also true to the daily network condition. After demonstrating the validity of k-means clustering algorithm, the paper proposes 5 flow table features that can be used to detect DDoS attacks. Finally, the DDoS detection scheme was tested by simulation experiment. The test results showed that the method proposed by the author could effectively detect DDoS, with an average success rate of 97.78%.},
  doi       = {10.1109/ICCBB.2018.8756439},
  groups    = {First Filtering},
  issn      = {7281-1277},
  keywords  = {Feature extraction;Denial-of-service attack;Training;Switches;Computer crime;IP networks;Clustering algorithms;Software Defined Network;Distributed Denial of Service;k-means;attack detection},
}

@InProceedings{5986244,
  author    = {Ulaş, Cihan and Temeltaş, Hakan},
  booktitle = {2011 IEEE International Conference on Mechatronics and Automation},
  title     = {A fast and robust scan matching algorithm based on ML-NDT and feature extraction},
  year      = {2011},
  month     = {Aug},
  pages     = {1751-1756},
  abstract  = {In this paper, we introduce a fast and robust scan matching method that combines the Multi-Layered Normal Distributions Transform (ML-NDT) and a feature extraction algorithm into a single framework. This is achieved by first applying the conventional NDT generation process to the reference scan, and the plane segments are extracted with the help of Random Sample Consensus (RANSAC) algorithm for the input scan. Thus, the proposed method provides three significant advantages with respect to conventional methods. The first one is that the proposed method is more robust to outliers since it is based on the matching of certain geometric structures. The second one is that the registration step is much faster because the number of points to be matched is very less with respect to all scanned points. Therefore, this process can be considered as a special sampling strategy. Finally, it is showed that the extracted features can also be used in feature based probabilistic SLAM methods such as Kalman Filters, Information Filters, and Particle Filters after applying merging procedure. Since the plane segments are already registered, the data association problem can be easily solved even without any odometry measurement. This can be considered as the most powerful part of the algorithm because data association problem in three dimensions is quite difficult problem. As a result, on the one hand, it is obtained a robust and fast scan matching; on the other hand, it is possible to extend the method for feature extraction algorithm in SLAM problems with a little extra computation. The method is applied to real experimental data and the results are quite affirmative.},
  doi       = {10.1109/ICMA.2011.5986244},
  groups    = {First Filtering},
  issn      = {2152-744X},
  keywords  = {Feature extraction;Simultaneous localization and mapping;Three dimensional displays;Iterative closest point algorithm;Robustness;Probabilistic logic;Convergence;3D SLAM;Feature Extraction;Scan Matching},
}

@InProceedings{7956551,
  author    = {Sample, Char and Cowley, Jennifer and Hutchinson, Steve},
  booktitle = {2017 11th International Conference on Research Challenges in Information Science (RCIS)},
  title     = {Cultural exploration of attack vector preferences for self-identified attackers},
  year      = {2017},
  month     = {May},
  pages     = {305-314},
  abstract  = {The examination of digital events through the prism of a quantitatively represented cultural framework allows for a new perspective on existing cyber security issues and events. When the cultural framework is applied to a large set of data, simple statistical analysis can be applied, allowing the researchers to quantify, characterize, and model specific aspects of human behavior. One advantage of quantitatively analyzing culture is that quantitative methods limit the ability of the researcher to inject implicit biases. By analyzing a large number of attacks over a 10-year period of time, exploration into patterns that may reflect cultural norms can be undertaken. This study examines a group of self-attributed attackers to determine if the chosen attack vector coincides with specific cultural values. If an attack vector can be viewed as a tool, then different cultures may exhibit preferences for specific tools. The Zone-H data collected from 2005 to 2014 for self-identified attackers in 36 countries were examined along 7 different attack vectors. These data were examined using Hofstede's cultural framework for contextual purposes. The findings showed several attack vectors that associated with unique cultural characteristics, and other attack vectors results were limited to more general characteristics. These findings contribute to the growing body of knowledge that support examination of cyber behaviors in cultural and provide additional insights into cyber actors' online behaviors.},
  doi       = {10.1109/RCIS.2017.7956551},
  groups    = {First Filtering},
  issn      = {2151-1357},
  keywords  = {Cultural differences;Computer security;Tools;Statistical analysis;Software;Psychology;Decision making;culture;Hofstede;attack vectors;attackers;preferences},
}

@Article{7847438,
  author   = {Hammad, Eman and Khalil, Ahmed M. and Farraj, Abdallah and Kundur, Deepa and Iravani, Reza},
  journal  = {IEEE Transactions on Smart Grid},
  title    = {A Class of Switching Exploits Based on Inter-Area Oscillations},
  year     = {2018},
  issn     = {1949-3061},
  month    = {Sep.},
  number   = {5},
  pages    = {4659-4668},
  volume   = {9},
  abstract = {This work presents a new class of cyber-physical switching attacks that targets power transmission systems. The proposed approach relies on exciting inter-area oscillation modes in a coordinated manner to drive groups of system generators out of step. Our paradigm targets inter-area oscillations by switching a relatively small part (in the order of 2%) of the system load at a (low) frequency that resonates with one of the inter-area oscillation modes observed in the power system. The switching frequency of the targeted mode is chosen through measurement-based analysis of the frequency deviation at a select bus that is observable by the adversary. The inter-area switching attack is implemented as single-load switching and coordinated multi-load switching and is studied with a variety of switching signals. Numerical results show the potential and characteristics of the proposed switching exploitation when applied to the four-machine two-area power system and the Northeast Power Coordinating Council 68-bus system.},
  doi      = {10.1109/TSG.2017.2666046},
  groups   = {First Filtering},
  keywords = {Switches;Power system stability;Oscillators;Generators;Load modeling;Cyber-physical security;inter-area oscillations;power system stability;smart grid;switching attacks},
}

@Article{7873357,
  author   = {Pal, Seemita and Sikdar, Biplab and Chow, Joe H.},
  journal  = {IEEE Transactions on Smart Grid},
  title    = {Classification and Detection of PMU Data Manipulation Attacks Using Transmission Line Parameters},
  year     = {2018},
  issn     = {1949-3061},
  month    = {Sep.},
  number   = {5},
  pages    = {5057-5066},
  volume   = {9},
  abstract = {Modern power grids are increasingly relying on real-time data, such as those from phasor measurement units (PMUs), for their control and management operations. Due to its dependence on the Internet for data transfer, the grid is susceptible to a wide range of cyber-attacks. Among these, data manipulation attacks are of particular interest in the context of PMU data, due to their potential for causing widespread damage. In such attacks, the adversary changes the measurements in order to bias the estimate of system states. In this paper, we propose an effective and simple-to-implement mechanism for detecting such attacks. The proposed methodology is based on evaluating the equivalent impedances of transmission lines. Being independent of the conventional bad data detection scheme, it is also able to detect the so called “false data injection attacks.” Extensive simulation results using real PMU data have been provided in order to verify the accuracy of the proposed detector.},
  doi      = {10.1109/TSG.2017.2679122},
  groups   = {First Filtering},
  keywords = {Phasor measurement units;Transmission line measurements;Power transmission lines;Voltage measurement;Capacitance;Detectors;Phasor measurement unit (PMU);cyber-attack;impedance;data manipulation;smart grid},
}

@Article{8027024,
  author   = {Carlin, Domhnall and Cowan, Alexandra and O’Kane, Philip and Sezer, Sakir},
  journal  = {IEEE Access},
  title    = {The Effects of Traditional Anti-Virus Labels on Malware Detection Using Dynamic Runtime Opcodes},
  year     = {2017},
  issn     = {2169-3536},
  pages    = {17742-17752},
  volume   = {5},
  abstract = {The arms race between the distributors of malware and those seeking to provide defenses has so far favored the former. Signature detection methods have been unable to cope with the onslaught of new binaries aided by rapidly developing obfuscation techniques. Recent research has focused on the analysis of low-level opcodes, both static and dynamic, as a way to detect malware. Although sometimes successful at detecting malware, static analysis still fails to unravel obfuscated code, whereas dynamic analysis can allow researchers to investigate the revealed code at runtime. Research in the field has been limited by the underpinning data sets; old and inadequately sampled malware can lessen the extrapolation potential of such data sets. The main contribution of this paper is the creation of a new parsed runtime trace data set of over 100 000 labeled samples, which will address these shortcomings, and we offer the data set itself for use by the wider research community. This data set underpins the examination of the run traces using classifiers on count-based and sequence-based data. We find that malware detection rates are lessened when samples are labeled with traditional anti-virus (AV) labels. Neither count-based nor sequence-based algorithms can sufficiently distinguish between AV label classes. Detection increases when malware is re-classed with labels yielded from unsupervised learning. With sequenced-based learning, detection exceeds that of labeling as simply “malware”alone. This approach may yield future work, where the triaging of malware can be more effective.},
  doi      = {10.1109/ACCESS.2017.2749538},
  groups   = {First Filtering},
  keywords = {Malware;Hidden Markov models;Grippers;Runtime;Feature extraction;Heuristic algorithms;Network security;machine learning;computer security},
}

@InProceedings{8711068,
  author    = {Zhang, Hao and Dai, Shumin and Li, Yongdan and Zhang, Wenjun},
  booktitle = {2018 IEEE 37th International Performance Computing and Communications Conference (IPCCC)},
  title     = {Real-time Distributed-Random-Forest-Based Network Intrusion Detection System Using Apache Spark},
  year      = {2018},
  month     = {Nov},
  pages     = {1-7},
  abstract  = {With the rapid increase in Internet services, network traffic data has become very large and complex, increasing the possibility of intrusions. The traditional intrusion detection system (IDS) cannot detect intrusion behaviors among such high-speed traffic data. A real-time network IDS should be able to process large amounts of network traffic data as quickly as possible to detect malicious traffic as early as possible. Therefore, in this paper, we propose a network intrusion detection framework based on a distributed random forest capable of handling high-speed traffic data. This framework consists of three parts: a data capturing part based on NetFlow, a preprocessing data part and a classification-based intrusion detection part. In this paper, we apply the random forest classification algorithm and adapt it to the Apache Spark distributed processing system to realize real-time detection. To verify the effectiveness of the framework, we implement the system and perform several comparison experiments. The results show that the system has satisfactory efficiency and accuracy compared to existing systems and thus is very suitable for the real-time detection of network intrusion, with a large capacity and high speed.},
  doi       = {10.1109/PCCC.2018.8711068},
  groups    = {First Filtering},
  issn      = {2374-9628},
  keywords  = {Intrusion detection;Real-time systems;Classification algorithms;Clustering algorithms;Computer crime;Telecommunication traffic;Cluster computing;network intrusion;real-time detection;NetFlow;random forest;Apache Spark},
}

@InProceedings{9412227,
  author    = {Qi, Panpan and Zhang, Zhaoqi and Wang, Wei and Yao, Chang},
  booktitle = {2020 25th International Conference on Pattern Recognition (ICPR)},
  title     = {Malware Detection by Exploiting Deep Learning over Binary Programs},
  year      = {2021},
  month     = {Jan},
  pages     = {9068-9075},
  abstract  = {Malware evolves rapidly over time, which makes existing solutions being ineffective in detecting newly released malware. Machine learning models that can learn to capture malicious patterns directly from the data play an increasingly important role in malware analysis. However, traditional machine learning models heavily depend on feature engineering. The extracted static features are vulnerable as hackers could create new malware with different feature values to deceive the machine learning models. In this paper, we propose an end-to-end malware detection framework consisting of convolutional neural network, autoencoder and neural decision trees. It learns the features from multiple domains for malware detection without feature engineering. In addition, since anti-virus products should have a very low false alarm rate to avoid annoying users, we propose a special loss function, which optimizes the recall for a fixed low false positive rate (e.g., less than 0.1%). Experiments show that the proposed framework has achieved a better recall than the baseline models, and the derived loss function also makes a difference.},
  doi       = {10.1109/ICPR48806.2021.9412227},
  groups    = {First Filtering},
  issn      = {1051-4651},
  keywords  = {Deep learning;Analytical models;Computer hacking;Feature extraction;Malware;Data models;Pattern recognition},
}

@InProceedings{9152805,
  author    = {Jan, Steve T.K. and Hao, Qingying and Hu, Tianrui and Pu, Jiameng and Oswal, Sonal and Wang, Gang and Viswanath, Bimal},
  booktitle = {2020 IEEE Symposium on Security and Privacy (SP)},
  title     = {Throwing Darts in the Dark? Detecting Bots with Limited Data using Neural Data Augmentation},
  year      = {2020},
  month     = {May},
  pages     = {1190-1206},
  abstract  = {Machine learning has been widely applied to building security applications. However, many machine learning models require the continuous supply of representative labeled data for training, which limits the models' usefulness in practice. In this paper, we use bot detection as an example to explore the use of data synthesis to address this problem. We collected the network traffic from 3 online services in three different months within a year (23 million network requests). We develop a stream-based feature encoding scheme to support machine learning models for detecting advanced bots. The key novelty is that our model detects bots with extremely limited labeled data. We propose a data synthesis method to synthesize unseen (or future) bot behavior distributions. The synthesis method is distribution-aware, using two different generators in a Generative Adversarial Network to synthesize data for the clustered regions and the outlier regions in the feature space. We evaluate this idea and show our method can train a model that outperforms existing methods with only 1% of the labeled data. We show that data synthesis also improves the model's sustainability over time and speeds up the retraining. Finally, we compare data synthesis and adversarial retraining and show they can work complementary with each other to improve the model generalizability.},
  doi       = {10.1109/SP40000.2020.00079},
  groups    = {First Filtering},
  issn      = {2375-1207},
  keywords  = {CAPTCHAs;Data models;IP networks;Machine learning;Security;Training;Encoding},
}

@Article{9316662,
  author   = {Chen, Long and Xia, Chunhe and Lei, Shengwei and Wang, Tianbo},
  journal  = {IEEE Access},
  title    = {Detection, Traceability, and Propagation of Mobile Malware Threats},
  year     = {2021},
  issn     = {2169-3536},
  pages    = {14576-14598},
  volume   = {9},
  abstract = {In recent years, the application of smartphones, Android operating systems and mobile applications have become more prevalent worldwide. To study the traceability, propagation, and detection of the threats, we perform research on all aspects of the end-to-end environment. With machine learning based on the mobile malware detection algorithms that integrate the dynamic and static research of the identification algorithm, application software samples are collected to study sentences. Through knowledge labeling and knowledge construction, the association relationship of knowledge is extracted to realize the research of knowledge map construction. Flooding is closely correlated with the complexity of the Android mobile version of the kernel and malicious programs. A static dynamic analysis of the mobile malicious program is carried out, and the social network social diagram is constructed to model the propagation of the mobile malicious program. We extended the approach of deriving common malware behavior through graph clustering. On this basis, Android behavior analysis is performed through our virtual machine execution engine. We extend the family characteristics to the concept of DNA race genes. By studying SMS/MMS, Bluetooth, 5G base station networks, metropolitan area networks, social networks, homogeneous communities, telecommunication networks, and application market ecosystem propagation scenarios, we discovered the law of propagation. In addition, we studied the construction of the mobile Internet big data knowledge graph. Quantitative data for the main family chronology of mobile malware are obtained. We conducted detailed research and comprehensive analysis of Android application package (APK) details and behavior, relationship, resource-centric, and syntactic aspects. Furthermore, we summarized the architecture of mobile malware security analysis. We also discuss encryption of malware traffic discrimination. These precise modeling and quantified research results constitute the architecture of mobile malware analysis.},
  doi      = {10.1109/ACCESS.2021.3049819},
  groups   = {First Filtering},
  keywords = {Smart phones;Malware;Security;Internet;Mobile applications;Data privacy;Computer architecture;Android mobile malware;threat traceability;family chronology;propagation models;detection analysis;infected system environment;knowledge map construction;architecture of mobile malware security analysis},
}

@InProceedings{9156913,
  author    = {Zhao, Shihao and Ma, Xingjun and Zheng, Xiang and Bailey, James and Chen, Jingjing and Jiang, Yu-Gang},
  booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Clean-Label Backdoor Attacks on Video Recognition Models},
  year      = {2020},
  month     = {June},
  pages     = {14431-14440},
  abstract  = {Deep neural networks (DNNs) are vulnerable to backdoor attacks which can hide backdoor triggers in DNNs by poisoning training data. A backdoored model behaves normally on clean test images, yet consistently predicts a particular target class for any test examples that contain the trigger pattern. As such, backdoor attacks are hard to detect, and have raised severe security concerns in real-world applications. Thus far, backdoor research has mostly been conducted in the image domain with image classification models. In this paper, we show that existing image backdoor attacks are far less effective on videos, and outline 4 strict conditions where existing attacks are likely to fail: 1) scenarios with more input dimensions (eg. videos), 2) scenarios with high resolution, 3) scenarios with a large number of classes and few examples per class (a ``sparse dataset"), and 4) attacks with access to correct labels (eg. clean-label attacks). We propose the use of a universal adversarial trigger as the backdoor trigger to attack video recognition models, a situation where backdoor attacks are likely to be challenged by the above 4 strict conditions. We show on benchmark video datasets that our proposed backdoor attack can manipulate state-of-the-art video models with high success rates by poisoning only a small proportion of training data (without changing the labels). We also show that our proposed backdoor attack is resistant to state-of-the-art backdoor defense/detection methods, and can even be applied to improve image backdoor attacks. Our proposed video backdoor attack not only serves as a strong baseline for improving the robustness of video models, but also provides a new perspective for more understanding more powerful backdoor attacks.},
  doi       = {10.1109/CVPR42600.2020.01445},
  groups    = {First Filtering},
  issn      = {2575-7075},
  keywords  = {Training;Data models;Toxicology;Perturbation methods;Training data;Image resolution;Pipelines},
}

@InProceedings{9022049,
  author    = {Jandial, Surgan and Mangla, Puneet and Varshney, Sakshi and Balasubramanian, Vineeth},
  booktitle = {2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)},
  title     = {AdvGAN++: Harnessing Latent Layers for Adversary Generation},
  year      = {2019},
  month     = {Oct},
  pages     = {2045-2048},
  abstract  = {Adversarial examples are fabricated examples, indistinguishable from the original image that mislead neural networks and drastically lower their performance. Recently proposed AdvGAN, a GAN based approach, takes input image as a prior for generating adversaries to target a model. In this work, we show how latent features can serve as better priors than input images for adversary generation by proposing AdvGAN++, a version of AdvGAN that achieves higher attack rates than AdvGAN and at the same time generates perceptually realistic images on MNIST and CIFAR-10 datasets.},
  doi       = {10.1109/ICCVW.2019.00257},
  groups    = {First Filtering},
  issn      = {2473-9944},
  keywords  = {Training;Generators;Feature extraction;Perturbation methods;Data models;Neural networks;Gallium nitride;Adversarial Examples;GANs;AdvGAN},
}

@InProceedings{8945602,
  author    = {Liang, Hongliang and Yang, Tianqi and Jiang, Lin and Chen, Yixiu and Xie, Zhuosi},
  booktitle = {2019 26th Asia-Pacific Software Engineering Conference (APSEC)},
  title     = {Witness: Detecting Vulnerabilities in Android Apps Extensively and Verifiably},
  year      = {2019},
  month     = {Dec},
  pages     = {434-441},
  abstract  = {Existing studies on detecting vulnerabilities in apps have two main disadvantages: one is that some studies are limited to detecting a certain vulnerability and lack comprehensive analysis; the other is the lack of valid evidence for vulnerability verification, which leads to high false alarms rate and requires massive manual efforts. We propose the concept of vulnerability pattern to abstract the characteristics of different attacks, e.g., their prerequisites and attack paths, so as to support detecting multiple kinds of vulnerabilities. Also, we present a zero false alarms framework which can find vulnerability instances precisely and generate test cases and triggers to validate the findings, by combing static analysis and dynamic binary instrumentation techniques. We implement our method in a tool named Witness, which currently can detect 8 different types of vulnerabilities and is extensible to support more. Evaluated on 3211 popular apps, Witness successfully detected 243 vulnerability instances, with better precision and more proofs than four existing tools.},
  doi       = {10.1109/APSEC48747.2019.00065},
  groups    = {First Filtering},
  issn      = {2640-0715},
  keywords  = {Tools;Static analysis;Instruments;Uniform resource locators;Manuals;Cloning;Security;Vulnerability pattern, Android apps, Dynamic binary instrumentation, Static analysis},
}

@Article{9373306,
  author   = {Bhusal, Narayan and Gautam, Mukesh and Benidris, Mohammed},
  journal  = {IEEE Access},
  title    = {Detection of Cyber Attacks on Voltage Regulation in Distribution Systems Using Machine Learning},
  year     = {2021},
  issn     = {2169-3536},
  pages    = {40402-40416},
  volume   = {9},
  abstract = {Several wired and wireless advanced communication technologies have been used for coordinated voltage regulation schemes in distribution systems. These technologies have been employed to both receive voltage measurements from field sensors and transmit control settings to voltage regulating devices (VRDs). Communication networks for voltage regulation can be susceptible to data falsification attacks, which can lead to voltage instability. In this context, an attacker can alter multiple field measurements in a coordinated manner to disturb voltage control algorithms. This paper proposes a machine learning-based two-stage approach to detect, locate, and distinguish coordinated data falsification attacks on control systems of coordinated voltage regulation schemes in distribution systems with distributed generators. In the first stage (regression), historical voltage measurements along with current meteorological data (solar irradiance and ambient temperature) are provided to random forest regressor to forecast voltage magnitudes of a given current state. In the second stage, a logistic regression compares the forecasted voltage with the measured voltage (used to set VRDs) to detect, locate, and distinguish coordinated data falsification attacks in real-time. The proposed approach is validated through several case studies on a 240-node real distribution system (based in the USA) and the standard IEEE 123-node benchmark distribution system. The results show that the proposed approach can detect low margin attacks (as low as 1% of actual measurements) with up to 99% accuracy. All of the developed source codes of the proposed solution are publicly available at Github. https://github.com/nbhusal/Data-Attack-on-Voltage-Regulation.},
  doi      = {10.1109/ACCESS.2021.3064689},
  groups   = {First Filtering},
  keywords = {Voltage control;Voltage measurement;Distributed databases;Cyberattack;State estimation;Sensors;Power systems;Coordinated control of voltage regulation;data falsification cyber attack;machine learning;photovoltaic},
}

@InProceedings{9219712,
  author    = {Siniosoglou, Ilias and Efstathopoulos, Georgios and Pliatsios, Dimitrios and Moscholios, Ioannis D. and Sarigiannidis, Antonios and Sakellari, Georgia and Loukas, Georgios and Sarigiannidis, Panagiotis},
  booktitle = {2020 IEEE Symposium on Computers and Communications (ISCC)},
  title     = {NeuralPot: An Industrial Honeypot Implementation Based On Deep Neural Networks},
  year      = {2020},
  month     = {July},
  pages     = {1-7},
  abstract  = {Honeypots are powerful security tools, developed to shield commercial and industrial networks from malicious activity. Honeypots act as passive and interactive decoys in a network attracting malicious activity and securing the rest of the network entities. Since an increase in intrusions has been observed lately, more advanced security systems are necessary. In this paper a new method of adapting a honeypot system in a modern industrial network, employing the Modbus protocol, is introduced. In the presented NeuralPot honeypot, two distinct deep neural network implementations are utilized to adapt to network Modbus entities and clone them, actively confusing the intruders. The proposed deep neural networks and their generated data are then compared.},
  doi       = {10.1109/ISCC50000.2020.9219712},
  groups    = {First Filtering},
  issn      = {2642-7389},
  keywords  = {Industrial Control System;SCADA;Honeypots;GAN Network;Autoencoder Network;Data Generation},
}

@InProceedings{7155822,
  author    = {Patle, Roshani R. and Satao, Rachana},
  booktitle = {2015 International Conference on Computing Communication Control and Automation},
  title     = {Aggregated Identity-Based Signature to Transmit Data Securely and Efficiently in Clustered WSNs},
  year      = {2015},
  month     = {Feb},
  pages     = {138-142},
  abstract  = {In wireless sensor network (WSN) transmission of data securely is a critical issue. Clustering is powerful and feasible way to improve performance of the WSN system. We study transmission of data securely for clustered WSNs (CWSNs). We use two Secure and Efficient data Transmission (SET) protocols for CWSNs called SET-IBS and SET-IBOOS. SET-IBS uses the Identity-Based digital Signature (IBS) scheme and SET-IBOOS uses Identity-Based Online/Offline digital Signature (IBOOS) scheme. In SET-IBS security depends on the hardness of Diffie-Hellman problem in the pairing region. SET-IBOOS diminishes the operating cost of computation for protocol security, which is important for WSN, while its defense depends on durability of problem of discrete logarithm. Cluster head selection and clustering are important in WSN to route data efficiently. Multi Weight Based Clustering Algorithm (MWBCA) is an extended LEACH where cluster head is elected on weight given to each sensor node. We used Multi Weight Based Clustering Algorithm (MWBCA) for Cluster Head selection, then aggregate data at cluster head and going to provide security using Identity based Digital Signature.},
  doi       = {10.1109/ICCUBEA.2015.32},
  groups    = {First Filtering},
  keywords  = {Wireless sensor networks;Cryptography;Digital signatures;Data communication;Routing protocols;CWSN;ID-based digital signature;ID-based online/offline digital signature;SET},
}

@InProceedings{9413468,
  author    = {Zhai, Tongqing and Li, Yiming and Zhang, Ziqi and Wu, Baoyuan and Jiang, Yong and Xia, Shu-Tao},
  booktitle = {ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Backdoor Attack Against Speaker Verification},
  year      = {2021},
  month     = {June},
  pages     = {2560-2564},
  abstract  = {Speaker verification has been widely and successfully adopted in many mission-critical areas for user identification. The training of speaker verification requires a large amount of data, therefore users usually need to adopt third-party data (e.g., data from the Internet or third-party data company). This raises the question of whether adopting untrusted third-party data can pose a security threat. In this paper, we demonstrate that it is possible to inject the hidden backdoor for infecting speaker verification models by poisoning the training data. Specifically, we design a clustering-based attack scheme where poisoned samples from different clusters will contain different triggers (i.e., pre-defined utterances), based on our understanding of verification tasks. The infected models behave normally on benign samples, while attacker-specified unenrolled triggers will successfully pass the verification even if the attacker has no information about the enrolled speaker. We also demonstrate that existing back-door attacks cannot be directly adopted in attacking speaker verification. Our approach not only provides a new perspective for designing novel attacks, but also serves as a strong baseline for improving the robustness of verification methods. The code for reproducing main results is available at https://github.com/zhaitongqing233/Backdoor-attack-against-speaker-verification.},
  doi       = {10.1109/ICASSP39728.2021.9413468},
  groups    = {First Filtering},
  issn      = {2379-190X},
  keywords  = {Training;Mission critical systems;Training data;Signal processing;Robustness;Data models;Internet;Speaker Verification;Backdoor Attack;AI Security;Deep Learning},
}

@Article{9139923,
  author   = {Gao, Jun and Gan, Luyun and Buschendorf, Fabiola and Zhang, Liao and Liu, Hua and Li, Peixue and Dong, Xiaodai and Lu, Tao},
  journal  = {IEEE Internet of Things Journal},
  title    = {Omni SCADA Intrusion Detection Using Deep Learning Algorithms},
  year     = {2021},
  issn     = {2327-4662},
  month    = {Jan},
  number   = {2},
  pages    = {951-961},
  volume   = {8},
  abstract = {In this article, we investigate deep-learning-based omni intrusion detection system (IDS) for supervisory control and data acquisition (SCADA) networks that are capable of detecting both temporally uncorrelated and correlated attacks. Regarding the IDSs developed in this article, a feedforward neural network (FNN) can detect temporally uncorrelated attacks at an F1 of 99.967±0.005% but correlated attacks as low as 58±2%. In contrast, long short-term memory (LSTM) detects correlated attacks at 99.56±0.01% while uncorrelated attacks at 99.3±0.1%. Combining LSTM and FNN through an ensemble approach further improves the IDS performance with F1 of 99.68±0.04% regardless the temporal correlations among the data packets.},
  doi      = {10.1109/JIOT.2020.3009180},
  groups   = {First Filtering},
  keywords = {Feature extraction;IP networks;Registers;Machine learning;Intrusion detection;Software;Denial of Service (DoS);feedforward neural networks (FNNs);intrusion detection;intrusion detection system (IDS);long-short term memory (LSTM);Modbus;multilayer perceptron;network security;supervised learning;supervisory control and data acquisition (SCADA) systems},
}

@Article{9194015,
  author   = {Sidi, Lior and Nadler, Asaf and Shabtai, Asaf},
  journal  = {IEEE Access},
  title    = {MaskDGA: An Evasion Attack Against DGA Classifiers and Adversarial Defenses},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {161580-161592},
  volume   = {8},
  abstract = {Domain generation algorithms (DGAs) are commonly used by botnets to generate domain names that bots can use to establish communication channels with their command and control servers. Recent publications presented deep learning classifiers that detect algorithmically generated domain (AGD) names in real time with high accuracy and thus significantly reduce the effectiveness of DGAs for botnet communication. In this paper, we present MaskDGA, an evasion technique that uses adversarial learning to modify AGD names in order to evade inline DGA classifiers, without the need for the attacker to possess any knowledge about the DGA classifier's architecture or parameters. MaskDGA was evaluated on four state-of-the-art DGA classifiers and outperformed the recently proposed CharBot and DeepDGA evasion techniques. We also evaluated MaskDGA on enhanced versions of the same classifiers equipped with common adversarial defenses (distillation and adversarial retraining). While the results show that adversarial retraining has some limited effectiveness against the evasion technique, it is clear that a more resilient detection mechanism is required. We also propose an extension to MaskDGA that allows an attacker to omit a subset of the modified AGD names based on the classification results of the attacker's trained model, in order to achieve a desired evasion rate.},
  doi      = {10.1109/ACCESS.2020.3020964},
  groups   = {First Filtering},
  keywords = {Botnet;Computational modeling;Robustness;Computer architecture;Real-time systems;Neural networks;Training;Adversarial learning;deep learning;botnets;DGA},
}

@Article{8391393,
  author   = {Torabi, Sadegh and Boukhtouta, Amine and Assi, Chadi and Debbabi, Mourad},
  journal  = {IEEE Communications Surveys Tutorials},
  title    = {Detecting Internet Abuse by Analyzing Passive DNS Traffic: A Survey of Implemented Systems},
  year     = {2018},
  issn     = {1553-877X},
  month    = {Fourthquarter},
  number   = {4},
  pages    = {3389-3415},
  volume   = {20},
  abstract = {Despite the ubiquitous role of domain name system (DNS) in sustaining the operations of various Internet services (domain name to IP address resolution, e-mail, Web), DNS was abused/misused to perform large-scale attacks that affected millions of Internet users. To detect and prevent threats associated to DNS, researchers introduced passive DNS replication and analysis as an effective alternative approach for analyzing live DNS traffic. In this paper, we survey state of the art systems that utilized passive DNS traffic for the purpose of detecting malicious behaviors on the Internet. We highlight the main strengths and weaknesses of the implemented systems through an in-depth analysis of the detection approach, collected data, and detection outcomes. We highlight an incremental implementation pattern in the studied systems with similarities in terms of the used datasets and detection approach. Furthermore, we show that almost all studied systems implemented supervised machine learning, which has its own limitations. In addition, while all surveyed systems required several hours or even days before detecting threats, we illustrate the ability to enhance performance by implementing a system prototype that utilizes big data analytics frameworks to detect threats in near real-time. We demonstrate the feasibility of our threat detection prototype through real-life examples, and provide further insights for future work toward analyzing DNS traffic in near real-time.},
  doi      = {10.1109/COMST.2018.2849614},
  groups   = {First Filtering},
  keywords = {Internet;IP networks;Real-time systems;Servers;Prototypes;Computer security;Domain name system;DNS;threat detection;malicious behavior;vulnerabilities;machine learning},
}

@Article{9093828,
  author   = {Almohri, Hussain M. J. and Watson, Layne T. and Evans, David},
  journal  = {IEEE Transactions on Information Forensics and Security},
  title    = {An Attack-Resilient Architecture for the Internet of Things},
  year     = {2020},
  issn     = {1556-6021},
  pages    = {3940-3954},
  volume   = {15},
  abstract = {With current IoT architectures, once a single device in a network is compromised, it can be used to disrupt the behavior of other devices on the same network. Even though system administrators can secure critical devices in the network using best practices and state-of-the-art technology, a single vulnerable device can undermine the security of the entire network. The goal of this work is to limit the ability of an attacker to exploit a vulnerable device on an IoT network and fabricate deceitful messages to co-opt other devices. The approach is to limit attackers by using device proxies that are used to retransmit and control network communications. We present an architecture that prevents deceitful messages generated by compromised devices from affecting the rest of the network. The design assumes a centralized and trustworthy machine that can observe the behavior of all devices on the network. The central machine collects application layer data, as opposed to low-level network traffic, from each IoT device. The collected data is used to train models that capture the normal behavior of each individual IoT device. The normal behavioral data is then used to monitor the IoT devices and detect anomalous behavior. This paper reports on our experiments using both a binary classifier and a density-based clustering algorithm to model benign IoT device behavior with a realistic test-bed, designed to capture normal behavior in an IoT-monitored environment. Results from the IoT testbed show that both the classifier and the clustering algorithms are promising and encourage the use of application-level data for detecting compromised IoT devices.},
  doi      = {10.1109/TIFS.2020.2994777},
  groups   = {First Filtering},
  keywords = {Data models;Internet of Things;Machine learning;Analytical models;Anomaly detection;Access control;Internet of Things;intrusion detection;unsupervised learning;network security},
}

@Article{6419701,
  author   = {Creech, Gideon and Hu, Jiankun},
  journal  = {IEEE Transactions on Computers},
  title    = {A Semantic Approach to Host-Based Intrusion Detection Systems Using Contiguousand Discontiguous System Call Patterns},
  year     = {2014},
  issn     = {1557-9956},
  month    = {April},
  number   = {4},
  pages    = {807-819},
  volume   = {63},
  abstract = {Host-based anomaly intrusion detection system design is very challenging due to the notoriously high false alarm rate. This paper introduces a new host-based anomaly intrusion detection methodology using discontiguous system call patterns, in an attempt to increase detection rates whilst reducing false alarm rates. The key concept is to apply a semantic structure to kernel level system calls in order to reflect intrinsic activities hidden in high-level programming languages, which can help understand program anomaly behaviour. Excellent results were demonstrated using a variety of decision engines, evaluating the KDD98 and UNM data sets, and a new, modern data set. The ADFA Linux data set was created as part of this research using a modern operating system and contemporary hacking methods, and is now publicly available. Furthermore, the new semantic method possesses an inherent resilience to mimicry attacks, and demonstrated a high level of portability between different operating system versions.},
  doi      = {10.1109/TC.2013.13},
  groups   = {First Filtering},
  keywords = {Gaussian processes;Computer architecture;Registers;Logic gates;Complexity theory;Clocks;Cryptography;Intrusion detection;anomaly detection;computer security;system calls;host-based IDS;ADFA-LD},
}

@InProceedings{7988779,
  author    = {Vávra, Jan and Hromada, Martin},
  booktitle = {2017 International Conference on Military Technologies (ICMT)},
  title     = {Evaluation of anomaly detection based on classification in relation to SCADA},
  year      = {2017},
  month     = {May},
  pages     = {330-334},
  abstract  = {The accelerating development of information and communication technologies have an eminent influence on contemporary society. As a result, we have an opportunity to increase our effectiveness. However, there is a drawback. Contemporary systems becoming much more interconnected and opened. However, it negatively affects cyber security of Supervisory Control and Data Acquisition (SCADA) systems. Therefore, the reliable security system must be applied in order to increase system resilience. The article deals with widely used systems for intrusion detection (IDS). These systems are an indispensable basis for cyber security of every organization. The aim of the article is to evaluate an anomaly detection predictive models based on classification.},
  doi       = {10.1109/MILTECHS.2017.7988779},
  groups    = {First Filtering},
  keywords  = {SCADA systems;Computer security;Predictive models;Monitoring;Intrusion detection;Training;cyber security;intrusion detection;anomaly detection;supervisory control and data acquisition},
}

@InProceedings{8766353,
  author    = {Usama, Muhammad and Asim, Muhammad and Latif, Siddique and Qadir, Junaid and Ala-Al-Fuqaha},
  booktitle = {2019 15th International Wireless Communications Mobile Computing Conference (IWCMC)},
  title     = {Generative Adversarial Networks For Launching and Thwarting Adversarial Attacks on Network Intrusion Detection Systems},
  year      = {2019},
  month     = {June},
  pages     = {78-83},
  abstract  = {Intrusion detection systems (IDSs) are an essential cog of the network security suite that can defend the network from malicious intrusions and anomalous traffic. Many machine learning (ML)-based IDSs have been proposed in the literature for the detection of malicious network traffic. However, recent works have shown that ML models are vulnerable to adversarial perturbations through which an adversary can cause IDSs to malfunction by introducing a small impracticable perturbation in the network traffic. In this paper, we propose an adversarial ML attack using generative adversarial networks (GANs) that can successfully evade an ML-based IDS. We also show that GANs can be used to inoculate the IDS and make it more robust to adversarial perturbations.},
  doi       = {10.1109/IWCMC.2019.8766353},
  groups    = {First Filtering},
  issn      = {2376-6506},
  keywords  = {Feature extraction;Perturbation methods;Gallium nitride;Malware;Probes;Generative adversarial networks;Robustness;Adversarial machine learning;GAN;IDS},
}

@InProceedings{6682711,
  author    = {Herzberg, Amir and Shulman, Haya},
  booktitle = {2013 IEEE Conference on Communications and Network Security (CNS)},
  title     = {Fragmentation Considered Poisonous, or: One-domain-to-rule-them-all.org},
  year      = {2013},
  month     = {Oct},
  pages     = {224-232},
  abstract  = {We present effective off-path DNS cache poisoning attacks, circumventing widely-deployed challenge-response defenses, e.g., transaction identifier randomisation, port and query randomisation. Our attacks depend on the use of UDP to retrieve long DNS responses, resulting in IP fragmentation. We show how attackers are often able to generate such fragmented responses, and then abuse them to inject spoofed, 'poisonous' records, into legitimate DNS responses. We also studied how resolvers, name servers, domains and registrars, can defend against our attacks. The best defense is deployment and enforcement of DNSSEC validation. However, DNSSEC must be deployed correctly by both domain and resolver, which is challenging; we hope our results will catalyse this process, but it will surely take long time. In fact, recent study found less than 1 % of resolvers reject responses upon DNSSEC validation failures. Note also that, ironically, adoption of DNSSEC by a domain, is the main reason for fragmented DNS responses (abused in our attacks). We therefore present several short-term countermeasures, which can complement DNSSEC, especially until DNSSEC deployment is complete. We validated our attacks against popular resolvers (Bind and Unbound), and real domains in the Internet.},
  doi       = {10.1109/CNS.2013.6682711},
  groups    = {First Filtering},
  keywords  = {DNS security;DNS cache poisoning;fragmentation atacks;off-path attacks},
}

@InProceedings{9449214,
  author    = {Bai, Yang and Fan, Mingyu},
  booktitle = {2021 IEEE 6th International Conference on Computer and Communication Systems (ICCCS)},
  title     = {A Method to Improve the Privacy and Security for Federated Learning},
  year      = {2021},
  month     = {April},
  pages     = {704-708},
  abstract  = {Federated learning is proposed as an approach that enables several participants to collaboratively train the machine learning model, but without directly expose the local data to others. Although federated learning is developed to prevent the participants' local sensitive data leakage. However, recent researches show that federated learning systems are still faced with privacy and security challenges. In the privacy view, if participants or the central server are curious, they can inference information about the training data or the model by the exchanged update parameters. From a security perspective, the malicious participants can make poisoning attacks during the model training phase. Differential privacy and security multiparty computation (SMC) is exploited to solve the privacy problem. But they often result in large communication overhead or low federated learning accuracy. Besides, there lacks a comprehensive scheme that has effects on both privacy and security issues. In this article, we proposed a homomorphic encryption-based privacy enhancement mechanism which has effectiveness on membership inference attacks. Our method works in two phases. In phase I, our method exploits homomorphic encryption to encrypts participants' update parameters before sending out to the aggregator. In phase II, we add a parameter selection method to the aggregator of the federated learning system to choose participants' updated information with a certain probability. The experimental results show that the proposed method effectively defends both against membership inference attacks and poisoning attacks and makes less model accuracy effects than other existing solutions.},
  doi       = {10.1109/ICCCS52626.2021.9449214},
  groups    = {First Filtering},
  keywords  = {Training;Privacy;Differential privacy;Toxicology;Computational modeling;Training data;Collaborative work;federated learning;privacy and security;homomorphic encryption;membership inference attacks;poisoning attacks},
}

@Article{9195445,
  author   = {Sibi Chakkaravarthy, S. and Sangeetha, D. and Cruz, Meenalosini Vimal and Vaidehi, V. and Raman, Balasubramanian},
  journal  = {IEEE Access},
  title    = {Design of Intrusion Detection Honeypot Using Social Leopard Algorithm to Detect IoT Ransomware Attacks},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {169944-169956},
  volume   = {8},
  abstract = {In recent times, ransomware has become the most significant cyber-attack targeting individuals, enterprises, healthcare industries, and the Internet of Things (IoT). Existing security systems like Intrusion Detection and Prevention System (IDPS) and Anti-virus (AV) as a single monitoring agent is complicated and time-consuming, thus fails in ransomware detection. A robust Intrusion Detection Honeypot (IDH) is proposed to address the issues mentioned above. IDH consists of i) Honeyfolder, ii) Audit Watch, and iii) Complex Event Processing (CEP). Honeyfolder is a decoy folder modeled using Social Leopard Algorithm (SoLA), especially for getting attacked and acting as an early warning system to alert the user during the suspicious file activities. AuditWatch is an Entropy module that verifies the entropy of the files and folders. CEP engine is used to aggregate data from different security systems to confirm the ransomware behavior, attack pattern, and promptly respond to them. The proposed IDH is experimentally tested in a secured testbed using more than 20 variants of recent ransomware of all types. The experimental result confirms that the proposed IDH significantly improves the ransomware detection time, rate, and accuracy compared with the existing state of the art ransomware detection model.},
  doi      = {10.1109/ACCESS.2020.3023764},
  groups   = {First Filtering},
  keywords = {Ransomware;Intrusion detection;Computer hacking;Encryption;Complex event processing;CEP;Honeypot;Honeyfolder;SoLA;intrusion detection Honeypot;ransomware},
}

@InProceedings{8945736,
  author    = {Lv, Chengcheng and Zhang, Long and Zeng, Fanping and Zhang, Jian},
  booktitle = {2019 26th Asia-Pacific Software Engineering Conference (APSEC)},
  title     = {Adaptive Random Testing for XSS Vulnerability},
  year      = {2019},
  month     = {Dec},
  pages     = {63-69},
  abstract  = {XSS is one of the common vulnerabilities in web applications. Many black-box testing tools may collect a large number of payloads and traverse them to find a payload that can be successfully injected, but they are not very efficient. And previous research has paid less attention to how to improve the efficiency of black-box testing to detect XSS vulnerability. To improve the efficiency of testing, we develop an XSS testing tool. It collects 6128 payloads and uses a headless browser to detect XSS vulnerability. The tool can discover XSS vulnerability quickly with the ART(Adaptive Random Testing) method. We conduct an experiment using 3 extensively adopted open source vulnerable benchmarks and 2 actual websites to evaluate the ART method. The experimental results indicate that the ART method can effectively improve the fuzzing method by more than 27.1% in reducing the number of attempts before accomplishing a successful injection.},
  doi       = {10.1109/APSEC48747.2019.00018},
  groups    = {First Filtering},
  issn      = {2640-0715},
  keywords  = {Payloads;Tools;Browsers;Subspace constraints;Cross-site scripting;Fuzzing;XSS Vulnerability, Adaptive Random Testing, Fuzzing},
}

@InProceedings{9402031,
  author    = {Zhan, Xian and Fan, Lingling and Chen, Sen and We, Feng and Liu, Tianming and Luo, Xiapu and Liu, Yang},
  booktitle = {2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)},
  title     = {ATVHunter: Reliable Version Detection of Third-Party Libraries for Vulnerability Identification in Android Applications},
  year      = {2021},
  month     = {May},
  pages     = {1695-1707},
  abstract  = {Third-party libraries (TPLs) as essential parts in the mobile ecosystem have become one of the most significant contributors to the huge success of Android, which facilitate the fast development of Android applications. Detecting TPLs in Android apps is also important for downstream tasks, such as malware and repackaged apps identification. To identify in-app TPLs, we need to solve several challenges, such as TPL dependency, code obfuscation, precise version representation. Unfortunately, existing TPL detection tools have been proved that they have not solved these challenges very well, let alone specify the exact TPL versions. To this end, we propose a system, named ATVHunter, which can pinpoint the precise vulnerable in-app TPL versions and provide detailed information about the vulnerabilities and TPLs. We propose a two-phase detection approach to identify specific TPL versions. Specifically, we extract the Control Flow Graphs as the coarse-grained feature to match potential TPLs in the pre-defined TPL database, and then extract opcode in each basic block of CFG as the fine-grained feature to identify the exact TPL versions. We build a comprehensive TPL database (189,545 unique TPLs with 3,006,676 versions) as the reference database. Meanwhile, to identify the vulnerable in-app TPL versions, we also construct a comprehensive and known vulnerable TPL database containing 1,180 CVEs and 224 security bugs. Experimental results show AtVHunter outperforms state-of-the-art TPL detection tools, achieving 90.55% precision and 88.79% recall with high efficiency, and is also resilient to widely-used obfuscation techniques and scalable for large-scale TPL detection. Furthermore, to investigate the ecosystem of the vulnerable TPLs used by apps, we exploit newtool to conduct a large-scale analysis on 104,446 apps and find that 9,050 apps include vulnerable TPL versions with 53,337 vulnerabilities and 7,480 security bugs, most of which are with high risks and are not recognized by app developers.},
  doi       = {10.1109/ICSE43902.2021.00150},
  groups    = {First Filtering},
  issn      = {1558-1225},
  keywords  = {Databases;Ecosystems;Computer bugs;Tools;Feature extraction;Libraries;Security;Android;Third party libraries;vulnerability;version detection;ecosystem},
}

@InProceedings{7858320,
  author    = {Chhetri, Sujit Rokka and Wan, Jiang and Al Faruque, Mohammad Abdullah},
  booktitle = {2017 22nd Asia and South Pacific Design Automation Conference (ASP-DAC)},
  title     = {Cross-domain security of cyber-physical systems},
  year      = {2017},
  month     = {Jan},
  pages     = {200-205},
  abstract  = {The interaction between the cyber domain and the physical domain components and processes can be leveraged to enhance the security of the cyber-physical system. In order to do so, we must first analyze various cyber domain and physical domain information flows, and characterize the relation between them using model functions. In this paper, we present a notion of cross-domain security of cyber-physical systems, whereby we present a security analysis framework that can be used for generating novel cross-domain attack models, attack detection methods, etc. We demonstrate how information flows such as discrete domain signal flows and continuous domain energy flows in the cyber and physical domain can be used to generate model functions using data-driven estimation, and use this model functions for performing various cross-domain security analysis. We also demonstrate the practical applicability of the cross-domain security analysis framework using the cyber-physical manufacturing system as a case study.},
  doi       = {10.1109/ASPDAC.2017.7858320},
  groups    = {First Filtering},
  issn      = {2153-697X},
  keywords  = {Security;Analytical models;Data models;Computational modeling;Estimation;Iron;Training data},
}

@InProceedings{7809535,
  author    = {Yamamoto, Yasuhiro and Miyamoto, Daisuke and Nakayama, Masaya},
  booktitle = {2015 4th International Workshop on Building Analysis Datasets and Gathering Experience Returns for Security (BADGERS)},
  title     = {Text-Mining Approach for Estimating Vulnerability Score},
  year      = {2015},
  month     = {Nov},
  pages     = {67-73},
  abstract  = {This paper develops a method that can automatically estimate the security metrics of documents written in natural language. Currently, security metrics play an important role in assessing the impact and risks of cyberthreats. Security metrics also enable operators to recognize emerging cyberthreats and to prioritize operations in order to mitigate such threats. In this paper, we focus on estimating the ratings in the Common Vulnerability Scoring System by inspecting the threats described in the Common Vulnerability and Exposures dictionary. Our approach employs various techniques for processing natural language, and it uses the descriptions in the dictionary to estimate the base metrics. This paper also extends the algorithm to increase the accuracy of the estimate.},
  doi       = {10.1109/BADGERS.2015.018},
  groups    = {First Filtering},
  keywords  = {Measurement;Security;Large scale integration;Estimation;Algorithm design and analysis;Dictionaries;Software},
}

@InProceedings{9351316,
  author    = {Aryeh, Felix Larbi and Alese, Boniface Kayode},
  booktitle = {2020 15th International Conference for Internet Technology and Secured Transactions (ICITST)},
  title     = {A Multi-layer Stack Ensemble Approach to Improve Intrusion Detection System's Prediction Accuracy},
  year      = {2020},
  month     = {Dec},
  pages     = {1-6},
  abstract  = {Intrusion is a series of activities that violate an organisation's existing security goals and procedures. Hence, an Intrusion Detection System (IDS) should be capable of analysing incoming network traffic (packet) and determining if it is an attack or otherwise. Lack of recent and up to date data sets for the training of IDS is a critical issue in the development of effective IDS. This paper focuses on creating a more realistic data set in our case UMaT-OD-20 using ONDaSCA and also the building a Multi-layer Stack Ensemble (MLS) IDS Model for Intrusion Detection Systems. Multi-layer Stacked Ensemble exploits the strengths of various base-level model predictions to build a more robust meta-classifier that meliorate classification accuracy and reduces False Alarm Rate (FAR). Five (5) Supervised Machine Learning (ML) based algorithms videlicet K Nearest Neighbor (KNN), Decision Tree (DT), Logistic Regression (LR), Random Forest (RF) and Naive Bayes' (NB) were employed to generate predictive models for all features. The Python programming language was used for the entire research and all programming and evaluation of data was done with an Inter Core i7, 16GB RAM and 1TB HDD Windows 10 Pro Laptop computer. The predictions of the Multi-layer stacked ensemble showed an improvement of 0.97% over the best base model. This improvement reduced the FAR during the classification of network connections types. Again, the evaluation of our work shows a significant improvement over similar works in literature.},
  doi       = {10.23919/ICITST51030.2020.9351316},
  groups    = {First Filtering},
  keywords  = {Training;Intrusion detection;Telecommunication traffic;Predictive models;Windows;Security;Regression tree analysis;Intrusion Detection System;Ensemble;Stacking;Machine Learning;Feature Selection},
}

@InProceedings{7357409,
  author    = {Pagliari, Roberto and Ghosh, Abhrajit and Gottlieb, Yitzchak M. and Chadha, Ritu and Vashist, Akshay and Hadynski, Gregory},
  booktitle = {MILCOM 2015 - 2015 IEEE Military Communications Conference},
  title     = {Insider attack detection using weak indicators over network flow data},
  year      = {2015},
  month     = {Oct},
  pages     = {1-6},
  abstract  = {Insider attack detection in an enterprise network environment is a critical problem that currently has no promising solution. It represents a significant challenge since host availability and performance requirements cannot be ignored. A network based approach allows these requirements to be met but is limited by the granularity of data available and the near impossibility of defining exact signatures for known attack types. Anomaly detection approaches suffer from the well known problem of false positives making them hard to apply in enterprise environments where even a moderate false positive rate is not acceptable. Sophisticated attacks and complex network topologies make it hard to apply simplistic approaches to anomaly detection. This paper presents an approach that applies the unsupervised learning techniques of bi-clustering and one-class SVM to so-called weak indicators of network attacks. This approach is well suited for network flow data that is coarse grained and not amenable to simplistic anomaly detection or signature-based techniques. Further, our approach allows a security analyst to determine the cause of the anomaly, a capability that is typically not supportable by simplistic applications of unsupervised learning.},
  doi       = {10.1109/MILCOM.2015.7357409},
  groups    = {First Filtering},
  keywords  = {Feature extraction;Ports (Computers);Databases;Servers;Data mining;Couplings;IP networks},
}

@InProceedings{9293933,
  author    = {Pan, Jonathan},
  booktitle = {2020 IEEE REGION 10 CONFERENCE (TENCON)},
  title     = {Blackbox Trojanising of Deep Learning Models: Using Non-Intrusive Network Structure and Binary Alterations},
  year      = {2020},
  month     = {Nov},
  pages     = {891-896},
  abstract  = {Recent advancements in Artificial Intelligence namely in Deep Learning has heightened its adoption in many applications. Some are playing important roles to the extent that we are heavily dependent on them for our livelihood. However, as with all technologies, there are vulnerabilities that malicious actors could exploit. A form of exploitation is to turn these technologies, intended for good, to become dual-purposed instruments to support deviant acts like malicious software trojans. As part of proactive defense, researchers are proactively identifying such vulnerabilities so that protective measures could be developed subsequently. This research explores a novel blackbox trojanising approach using a simple network structure modification to any deep learning image classification model that would transform a benign model into a deviant one with a simple manipulation of the weights to induce specific types of errors. Propositions to protect the occurrence of such simple exploits are discussed in this research. This research highlights the importance of providing sufficient safeguards to these models so that the intended good of AI innovation and adoption may be protected.},
  doi       = {10.1109/TENCON50793.2020.9293933},
  groups    = {First Filtering},
  issn      = {2159-3450},
  keywords  = {Artificial intelligence;Deep learning;Mathematical model;Biological system modeling;Training;Trojan horses;Payloads;Deep Learning;Adversarial Artificial Intelligence},
}

@InProceedings{9157546,
  author    = {Zhao, Yue and Wu, Yuwei and Chen, Caihua and Lim, Andrew},
  booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {On Isometry Robustness of Deep 3D Point Cloud Models Under Adversarial Attacks},
  year      = {2020},
  month     = {June},
  pages     = {1198-1207},
  abstract  = {While deep learning in 3D domain has achieved revolutionary performance in many tasks, the robustness of these models has not been sufficiently studied or explored. Regarding the 3D adversarial samples, most existing works focus on manipulation of local points, which may fail to invoke the global geometry properties, like robustness under linear projection that preserves the Euclidean distance, i.e., isometry. In this work, we show that existing state-of-the-art deep 3D models are extremely vulnerable to isometry transformations. Armed with the Thompson Sampling, we develop a black-box attack with success rate over 95% on ModelNet40 data set. Incorporating with the Restricted Isometry Property, we propose a novel framework of white-box attack on top of spectral norm based perturbation. In contrast to previous works, our adversarial samples are experimentally shown to be strongly transferable. Evaluated on a sequence of prevailing 3D models, our white-box attack achieves success rates from 98.88% to 100%. It maintains a successful attack rate over 95% even within an imperceptible rotation range [±2.81°].},
  doi       = {10.1109/CVPR42600.2020.00128},
  groups    = {First Filtering},
  issn      = {2575-7075},
  keywords  = {Three-dimensional displays;Robustness;Data models;Solid modeling;Computational modeling;Perturbation methods},
}

@Article{8423654,
  author   = {Mopuri, Konda Reddy and Ganeshan, Aditya and Babu, R. Venkatesh},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title    = {Generalizable Data-Free Objective for Crafting Universal Adversarial Perturbations},
  year     = {2019},
  issn     = {1939-3539},
  month    = {Oct},
  number   = {10},
  pages    = {2452-2465},
  volume   = {41},
  abstract = {Machine learning models are susceptible to adversarial perturbations: small changes to input that can cause large changes in output. It is also demonstrated that there exist input-agnostic perturbations, called universal adversarial perturbations, which can change the inference of target model on most of the data samples. However, existing methods to craft universal perturbations are (i) task specific, (ii) require samples from the training data distribution, and (iii) perform complex optimizations. Additionally, because of the data dependence, fooling ability of the crafted perturbations is proportional to the available training data. In this paper, we present a novel, generalizable and data-free approach for crafting universal adversarial perturbations. Independent of the underlying task, our objective achieves fooling via corrupting the extracted features at multiple layers. Therefore, the proposed objective is generalizable to craft image-agnostic perturbations across multiple vision tasks such as object recognition, semantic segmentation, and depth estimation. In the practical setting of black-box attack scenario (when the attacker does not have access to the target model and it's training data), we show that our objective outperforms the data dependent objectives to fool the learned models. Further, via exploiting simple priors related to the data distribution, our objective remarkably boosts the fooling ability of the crafted perturbations. Significant fooling rates achieved by our objective emphasize that the current deep learning models are now at an increased risk, since our objective generalizes across multiple tasks without the requirement of training data for crafting the perturbations. To encourage reproducible research, we have released the codes for our proposed algorithm1.},
  doi      = {10.1109/TPAMI.2018.2861800},
  groups   = {First Filtering},
  keywords = {Perturbation methods;Task analysis;Data models;Training data;Feature extraction;Image segmentation;Machine learning;Adversarial perturbations;fooling CNNs;stability of neural networks;perturbations;universal;generalizable attacks;attacks on ML systems;data-free objectives;adversarial noise},
}

@InProceedings{9358268,
  author    = {Liu, Yuan and Zhou, Pingqiang},
  booktitle = {2020 Asian Hardware Oriented Security and Trust Symposium (AsianHOST)},
  title     = {Defending Against Adversarial Attacks in Deep Learning with Robust Auxiliary Classifiers Utilizing Bit Plane Slicing},
  year      = {2020},
  month     = {Dec},
  pages     = {1-4},
  abstract  = {Deep Neural Networks (DNNs) have been widely used in variety of fields with great success. However, recent researches indicate that DNNs are susceptible to adversarial attacks, which can easily fool the well-trained DNNs without being detected by human eyes. In this paper, we propose to combine the target DNN model with robust bit plane classifiers to defend against adversarial attacks. It comes from our finding that successful attacks generate imperceptible perturbations, which mainly affects the low-order bits of pixel value in clean images. Hence, using bit planes instead of traditional RGB channels for convolution can effectively reduce channel modification rate. We conduct experiments on dataset CIFAR-10 and GTSRB. The results show that our defense method can effectively increase the model accuracy on average from 8.72% to 85.99% under attacks on CIFAR-10 without sacrificina accuracy of clean images.},
  doi       = {10.1109/AsianHOST51057.2020.9358268},
  groups    = {First Filtering},
  keywords  = {Deep learning;Convolution;Perturbation methods;Neural networks;Hardware;Security;adversarial defense;security of neural networks;bit plane slicing},
}

@InProceedings{8916877,
  author    = {Hasegawa, Keita and Harada, Takafumi and Washio, Tomoaki and Oshima, Yoshihito},
  booktitle = {2019 IEEE Intelligent Transportation Systems Conference (ITSC)},
  title     = {Geo-spatial Screening using Anomaly Detection for Efficient Security Analysis of V2X Sensor Data on C-ITS Service},
  year      = {2019},
  month     = {Oct},
  pages     = {1178-1185},
  abstract  = {Security for cooperative intelligent transport systems (C-ITS), which are expected to contribute to realizing a safe and efficient transportation environment, will become more important in the near future. Among various proposed C-ITS services, this study examines security measures against cyber attacks for navigation services that collect sensor data from vehicles to estimate real-time traffic and distribute trip planning and route selection. In such services, a threat is assumed in which a malicious attacker prevents the traffic condition from being correctly recognized by injecting false data. As a result of such attacks, the services may fail to decide appropriate routes, and there is a concern that this cyber attack will likely disrupt traffic in the real world. By using a simulator on the basis of actual traffic data, we experimentally clarify that false data injection attacks against C-ITS services cause artificial congestion. Due to the potential for serious consequences of traffic disruption, security countermeasure technology is vital. To respond to cyber attacks that use false sensor data, technology to analyze sensor data and detect abnormalities is required. For this reason, we propose an analysis technique that efficiently analyzes sensor data transmitted from a huge number of vehicles to identify an attacker. The idea of the proposed method is to narrow down the sensor data for detailed analysis by screening on the basis of simple statistical analysis. The evaluation results show that the proposed method can efficiently detect false data injection attacks against C-ITS navigation services.},
  doi       = {10.1109/ITSC.2019.8916877},
  groups    = {First Filtering},
  keywords  = {Cyberattack;Navigation;Anomaly detection;Roads;Laboratories},
}

@InProceedings{7536387,
  author    = {Wu, Xi and Fredrikson, Matthew and Jha, Somesh and Naughton, Jeffrey F.},
  booktitle = {2016 IEEE 29th Computer Security Foundations Symposium (CSF)},
  title     = {A Methodology for Formalizing Model-Inversion Attacks},
  year      = {2016},
  month     = {June},
  pages     = {355-370},
  abstract  = {Confidentiality of training data induced by releasing machine-learning models, and has recently received increasing attention. Motivated by existing MI attacks and other previous attacks that turn out to be MI "in disguise," this paper initiates a formal study of MI attacks by presenting a game-based methodology. Our methodology uncovers a number of subtle issues, and devising a rigorous game-based definition, analogous to those in cryptography, is an interesting avenue for future work. We describe methodologies for two types of attacks. The first is for black-box attacks, which consider an adversary who infers sensitive values with only oracle access to a model. The second methodology targets the white-box scenario where an adversary has some additional knowledge about the structure of a model. For the restricted class of Boolean models and black-box attacks, we characterize model invertibility using the concept of influence from Boolean analysis in the noiseless case, and connect model invertibility with stable influence in the noisy case. Interestingly, we also discovered an intriguing phenomenon, which we call "invertibility interference," where a highly invertible model quickly becomes highly non-invertible by adding little noise. For the white-box case, we consider a common phenomenon in machine-learning models where the model is a sequential composition of several sub-models. We show, quantitatively, that even very restricted communication between layers could leak a significant amount of information. Perhaps more importantly, our study also unveils unexpected computational power of these restricted communication channels, which, to the best of our knowledge, were not previously known.},
  doi       = {10.1109/CSF.2016.32},
  groups    = {First Filtering},
  issn      = {2374-8303},
  keywords  = {Computational modeling;Data privacy;Privacy;Data models;Context;Correlation;Training},
}

@InProceedings{8844607,
  author    = {Song, Liwei and Shokri, Reza and Mittal, Prateek},
  booktitle = {2019 IEEE Security and Privacy Workshops (SPW)},
  title     = {Membership Inference Attacks Against Adversarially Robust Deep Learning Models},
  year      = {2019},
  month     = {May},
  pages     = {50-56},
  abstract  = {In recent years, the research community has increasingly focused on understanding the security and privacy challenges posed by deep learning models. However, the security domain and the privacy domain have typically been considered separately. It is thus unclear whether the defense methods in one domain will have any unexpected impact on the other domain. In this paper, we take a step towards enhancing our understanding of deep learning models when the two domains are combined together. We do this by measuring the success of membership inference attacks against two state-of-the-art adversarial defense methods that mitigate evasion attacks: adversarial training and provable defense. On the one hand, membership inference attacks aim to infer an individual's participation in the target model's training dataset and are known to be correlated with target model's overfitting. On the other hand, adversarial defense methods aim to enhance the robustness of target models by ensuring that model predictions are unchanged for a small area around each sample in the training dataset. Intuitively, adversarial defenses may rely more on the training dataset and be more vulnerable to membership inference attacks. By performing empirical membership inference attacks on both adversarially robust models and corresponding undefended models, we find that the adversarial training method is indeed more susceptible to membership inference attacks, and the privacy leakage is directly correlated with model robustness. We also find that the provable defense approach does not lead to enhanced success of membership inference attacks. However, this is achieved by significantly sacrificing the accuracy of the model on benign data points, indicating that privacy, security, and prediction accuracy are not jointly achieved in these two approaches.},
  doi       = {10.1109/SPW.2019.00021},
  groups    = {First Filtering},
  keywords  = {Training;Predictive models;Deep learning;Data models;Privacy;Security;Training data;security and privacy;membership inference attack;adversarial defense},
}

@Article{9390408,
  author   = {Lv, Huanhuan and Wen, Mi and Lu, Rongxing and Li, Jinguo},
  journal  = {IEEE Transactions on Vehicular Technology},
  title    = {An Adversarial Attack Based on Incremental Learning Techniques for Unmanned in 6G Scenes},
  year     = {2021},
  issn     = {1939-9359},
  month    = {June},
  number   = {6},
  pages    = {5254-5264},
  volume   = {70},
  abstract = {With the development of artificial intelligence(AI), unmanned vehicles can relieve traffic jamming and decrease the risk of traffic accidents, where deep neural networks (DNNs) play an important role and have become one of the most critical technologies. Nevertheless, DNNs are still susceptible to adversarial examples. Even worse, they also show severe performance degradation when the system needs DNNs to learn new knowledge without forgetting the old one. As unmanned vehicles travel on the road, they need to frequently learn new categories and different representations. Learning all data after the new sample arrives will expend a lot of time and space. As a result, it will affect the deployment of artificial intelligence in unmanned scenes. In recent years, it has been observed that incremental learning technology can solve the above challenges. However, previously reported works mainly focused on batch learning. It is not clear how much impact the adversarial attack will have on the deep learning model when performing incremental learning tasks. This issue exposes the hidden safety risks of unmanned driving and increases discuss opportunities. Therefore, we propose an adversarial attack based on incremental learning techniques for unmanned scenes in this paper. Specifically, it can retain information previously learned by the model. At the same time, it can renew the old model to learn new model, thereby continually adding small perturbation to legitimate examples. A couple of experiments on the Pascal VOC 2012 dataset has been conducted, and the experiment results show that the adversarial attack based on incremental learning techniques has a higher attack success rate. Further, it can improve the successful attack rate by 8.43%.},
  doi      = {10.1109/TVT.2021.3069426},
  groups   = {First Filtering},
  keywords = {Unmanned vehicles;Deep learning;Task analysis;Semantics;Roads;Motorcycles;Image segmentation;Adversarial examples;catastrophic forgetting;incremental learning;unmanned},
}

@InProceedings{7958568,
  author    = {Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  booktitle = {2017 IEEE Symposium on Security and Privacy (SP)},
  title     = {Membership Inference Attacks Against Machine Learning Models},
  year      = {2017},
  month     = {May},
  pages     = {3-18},
  abstract  = {We quantitatively investigate how machine learning models leak information about the individual data records on which they were trained. We focus on the basic membership inference attack: given a data record and black-box access to a model, determine if the record was in the model's training dataset. To perform membership inference against a target model, we make adversarial use of machine learning and train our own inference model to recognize differences in the target model's predictions on the inputs that it trained on versus the inputs that it did not train on. We empirically evaluate our inference techniques on classification models trained by commercial "machine learning as a service" providers such as Google and Amazon. Using realistic datasets and classification tasks, including a hospital discharge dataset whose membership is sensitive from the privacy perspective, we show that these models can be vulnerable to membership inference attacks. We then investigate the factors that influence this leakage and evaluate mitigation strategies.},
  doi       = {10.1109/SP.2017.41},
  groups    = {First Filtering},
  issn      = {2375-1207},
  keywords  = {Training;Data models;Predictive models;Privacy;Sociology;Statistics;Google},
}

@InProceedings{7255217,
  author    = {Yun Tian and Xiao Qin and Yafei Jia},
  booktitle = {2015 IEEE International Conference on Networking, Architecture and Storage (NAS)},
  title     = {Secure replica allocation in cloud storage systems with heterogeneous vulnerabilities},
  year      = {2015},
  month     = {Aug},
  pages     = {205-214},
  abstract  = {Highly available cloud storage is often implemented with complex, multi-tiered distributed systems built on top of clusters of commodity servers and disk drives. Storage reliability, security and performance are among the top desired features when clients consider storing data on cloud storage. Although replication improves reliability and performance in cloud storage systems, data replication increases the risk of data storage in an insecure network environment. When a cloud storage scales up, storage nodes are very likely to become heterogeneous in nature. In this study, we propose a secure replica allocation scheme called SecRA to improve security, reliability, and performance of a cloud storage system where storage nodes have a wide variety of vulnerabilities. Our SecRA integrates the techniques of replication and fragmentation with secret sharing in a heterogeneous cloud system, where storage nodes are comprised of various server types in terms of vulnerability characteristics. SecRA allocates data replicas of fragments of a file to as many different types of nodes as possible. For the replicas of the same fragment, SecRA tries to allocate these replicas to the same type of nodes in the system. Data assurance is significantly improved, because the replicas of different fragments of a file are allocated to multiple types of storage nodes. To quantitatively evaluate the quality of security offered by SecRA, we develop a storage assurance model. Our analytically results show that replica allocations made by SecRA lead to enhanced security thanks to the consideration of heterogeneous vulnerabilities in cloud storage systems.},
  doi       = {10.1109/NAS.2015.7255217},
  groups    = {First Filtering},
  keywords  = {Cloud computing;Servers;Reliability;Resource management;Cryptography;Secure storage},
}

@InProceedings{8424654,
  author    = {Dutta, Preetam and Ryan, Gabriel and Zieba, Aleksander and Stolfo, Salvatore},
  booktitle = {2018 IEEE Security and Privacy Workshops (SPW)},
  title     = {Simulated User Bots: Real Time Testing of Insider Threat Detection Systems},
  year      = {2018},
  month     = {May},
  pages     = {228-236},
  abstract  = {The insider threat is one of the most serious security problems faced by modern organizations. High pro?le cases demonstrate the serious consequences of successful attacks. The problem has been studied for many years, leading to a number of technologies and products that have been deployed widely in government and commercial enterprises. A fundamental question is: how well do these systems work? How may they be tested? How expensive are widely deployed monitoring infrastructures in terms of computational cost? Measurement of real systems, which are dynamic in nature, encounter unknown con?guration bugs and have sensitivities to the vagaries of human nature and adversarial behavior, requires a formal means to continuously test and evaluate deployed detection systems. We present a framework to deploy in situ simulated user bots (SUBs) that can emulate the actions of real users. By creating a user account and by running a host in the enterprise network, a SUB can be introduced into an enterprise system that runs at a realistic pace and does not interfere with normal operations. Infusing malicious behavior into the SUB should be detected by the insider threat monitoring infrastructure. The SUB framework can be controlled to explore the limits of deployed systems and to test the effectiveness of insider evasion tactics, especially low and slow behaviors. We demonstrate our framework in a synthetic ecosystem as well as in a live enterprise deployment. We created a synthetic environment of users based on data collected in a West Point cadet study. Various machine learning based intrusion detection algorithms are used to validate the ability of the SUB framework to generate both normal and malicious users. In a live University network, we launched a number of attacks on its intrusion detection system and showcased the ability to devise malicious users. In addition, we further deployed low and slow attacks that perform malicious actions over an extended period of time and demonstrate how even a large enterprise is ill equipped to combat such attacks.},
  doi       = {10.1109/SPW.2018.00038},
  groups    = {First Filtering},
  keywords  = {Databases;Browsers;Monitoring;Data models;Testing;Computational efficiency;Statistics;Intrusion Detection System Monitoring;Machine Learning;Generative Adversarial Networks;Simulated User Bots;Machine Learning and Security},
}

@InProceedings{8455944,
  author    = {Adams, Stephen and Carter, Bryan and Fleming, Cody and Beling, Peter A},
  booktitle = {2018 17th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/ 12th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE)},
  title     = {Selecting System Specific Cybersecurity Attack Patterns Using Topic Modeling},
  year      = {2018},
  month     = {Aug},
  pages     = {490-497},
  abstract  = {One challenge for cybersecurity experts is deciding which type of attack would be successful against the system they wish to protect. Often, this challenge is addressed in an ad hoc fashion and is highly dependent upon the skill and knowledge base of the expert. In this study, we present a method for automatically ranking attack patterns in the Common Attack Pattern Enumeration and Classification (CAPEC) database for a given system. This ranking method is intended to produce suggested attacks to be evaluated by a cybersecurity expert and not a definitive ranking of the "best" attacks. The proposed method uses topic modeling to extract hidden topics from the textual description of each attack pattern and learn the parameters of a topic model. The posterior distribution of topics for the system is estimated using the model and any provided text. Attack patterns are ranked by measuring the distance between each attack topic distribution and the topic distribution of the system using KL divergence.},
  doi       = {10.1109/TrustCom/BigDataSE.2018.00076},
  groups    = {First Filtering},
  issn      = {2324-9013},
  keywords  = {Databases;Computer security;Mathematical model;Natural language processing;Data models;Cyber-physical systems;security;system;topic modeling;capec},
}

@Article{9311132,
  author   = {Qiu, Han and Dong, Tian and Zhang, Tianwei and Lu, Jialiang and Memmi, Gerard and Qiu, Meikang},
  journal  = {IEEE Internet of Things Journal},
  title    = {Adversarial Attacks Against Network Intrusion Detection in IoT Systems},
  year     = {2021},
  issn     = {2327-4662},
  month    = {July},
  number   = {13},
  pages    = {10327-10335},
  volume   = {8},
  abstract = {Deep learning (DL) has gained popularity in network intrusion detection, due to its strong capability of recognizing subtle differences between normal and malicious network activities. Although a variety of methods have been designed to leverage DL models for security protection, whether these systems are vulnerable to adversarial examples (AEs) is unknown. In this article, we design a novel adversarial attack against DL-based network intrusion detection systems (NIDSs) in the Internet-of-Things environment, with only black-box accesses to the DL model in such NIDS. We introduce two techniques: 1) model extraction is adopted to replicate the black-box model with a small amount of training data and 2) a saliency map is then used to disclose the impact of each packet attribute on the detection results, and the most critical features. This enables us to efficiently generate AEs using conventional methods. With these tehniques, we successfully compromise one state-of-the-art NIDS, Kitsune: the adversary only needs to modify less than 0.005% of bytes in the malicious packets to achieve an average 94.31% attack success rate.},
  doi      = {10.1109/JIOT.2020.3048038},
  groups   = {First Filtering},
  keywords = {Feature extraction;Computational modeling;Internet of Things;Training;Perturbation methods;Mathematical model;Detectors;Adversarial examples (AEs);deep learning (DL);Internet of Things (IoT);network intrusion detection},
}

@InProceedings{8038436,
  author    = {Song, Chungsik and Park, Younghee and Golani, Keyur and Kim, Youngsoo and Bhatt, Kalgi and Goswami, Kunal},
  booktitle = {2017 26th International Conference on Computer Communication and Networks (ICCCN)},
  title     = {Machine-Learning Based Threat-Aware System in Software Defined Networks},
  year      = {2017},
  month     = {July},
  pages     = {1-9},
  abstract  = {Software-Defined Networking (SDN) is an emerging network architecture that decouples the control plane and the data plane to provide unprecedented programmability, automation, and network control. The SDN controller exercises centralized control over network software, and in doing so, it can monitor and respond to malicious traffic for network protection. This paper proposes a threat-aware system based on machine-learning for timely detection and response against network intrusion in SDN. Our proposed system consists of data preprocessing for feature selection, predictive data modeling for machine-learning and anomaly detection, and decision making for intrusion response in SDN. Due to the time-critical nature of SDN, we propose a practical approach utilizing machine-learning techniques to protect against network intrusion and reduce uncertainty in decision-making outcomes. The maliciousness of most uncertain network traffic subsets is evaluated with selected significant feature sets. Our experimental results show that the proposed approach achieves high performance and significantly reduces uncertainty in the decision process with a small number of feature sets. The results help the SDN controller to properly react against known or unknown attacks that cannot be prevented by signature-based network intrusion detection systems.},
  doi       = {10.1109/ICCCN.2017.8038436},
  groups    = {First Filtering},
  keywords  = {Intrusion detection;Data models;Predictive models;Routing;Real-time systems;Classification algorithms;Systems architecture},
}

@InProceedings{9200909,
  author    = {Chen, Yi-Wen and Sheu, Jang-Ping and Kuo, Yung-Ching and Van Cuong, Nguyen},
  booktitle = {2020 European Conference on Networks and Communications (EuCNC)},
  title     = {Design and Implementation of IoT DDoS Attacks Detection System based on Machine Learning},
  year      = {2020},
  month     = {June},
  pages     = {122-127},
  abstract  = {DDoS attacks often happen in cloud servers and cause a devastating problem. However, an increasing number of Internet of Things (IoT) devices makes us not ignore the influence of large-scale DDoS attacks from IoT devices. In this paper, we propose a machine learning-based on a multi-layer IoT DDoS attack detection system, including IoT devices, IoT gateways, SDN switches, and cloud servers. Firstly, we build eight smart poles with various sensors on our campus and collect sensor data as our datasets through wireless networks or wired networks. Next, we extract the features based on DDoS attack types. The feature selection can result in high accuracy DDoS attack detection in the real IoT environment. The experimental results show that our multi-layer DDoS detection system can accurately detect DDoS attacks. And the SDN controller can block venomous devices effectively according to blacklists from the results of our IoT DDoS attacks detection system.},
  doi       = {10.1109/EuCNC48522.2020.9200909},
  groups    = {First Filtering},
  issn      = {2575-4912},
  keywords  = {Computer crime;Sensors;Feature extraction;Logic gates;Authentication;Internet of Things;Machine learning;Distributed Denial of Service;Internet of Things;Machine Learning;Software Defined Networking},
}

@InProceedings{6118545,
  author    = {Li, Shuhao and Yun, Xiaochun and Hao, Zhiyu and Cui, Xiang and Wang, Yipeng},
  booktitle = {2011 12th International Conference on Parallel and Distributed Computing, Applications and Technologies},
  title     = {A Propagation Model for Social Engineering Botnets in Social Networks},
  year      = {2011},
  month     = {Oct},
  pages     = {423-426},
  abstract  = {With the rapid development of social networking services and the diversification of social engineering attacks, new high-infection botnet (called SE-botnet by us), which exploits social engineering attacks to spread bots in social networks, has become an underlying threat. Predicting the threat of SE-botnet can help defenders mitigate it effectively. In this paper, we focus on SE-botnet's infection and defense, presenting a propagation model for it. We take full account of social networks' characteristics and human dynamics, and abstract the general process of social engineering attacks used by SE-botnet. Our preliminary simulation results demonstrate that the SE-botnet can capture tens of thousands of bots in one day with a great infection capacity. our propagation model can accurately predict this process with less than 5% deviation.},
  doi       = {10.1109/PDCAT.2011.8},
  groups    = {First Filtering},
  issn      = {2379-5352},
  keywords  = {Social network services;Peer to peer computing;Predictive models;Analytical models;Mathematical model;Computers;Electronic mail;botnet;propagation model;social engineering;social network formatting},
}

@Article{5963161,
  author   = {Soldo, Fabio and Le, Anh and Markopoulou, Athina},
  journal  = {IEEE Journal on Selected Areas in Communications},
  title    = {Blacklisting Recommendation System: Using Spatio-Temporal Patterns to Predict Future Attacks},
  year     = {2011},
  issn     = {1558-0008},
  month    = {August},
  number   = {7},
  pages    = {1423-1437},
  volume   = {29},
  abstract = {In this paper, we study the problem of forecasting attack sources based on past attack logs from several contributors. We formulate this problem as an implicit recommendation system, and we propose a multi-level prediction model to solve it. Our model evaluates and combines various factors, namely: (i) attacker-victim history using time-series, (ii) attackers and/or victims interactions using neighborhood models and (iii) global patterns using singular value decomposition. We evaluate our combined method, referred to as Blacklisting Recommendation System (or BRS), on one month of logs from Dshield, and we demonstrate that it improves significantly the prediction rate over state-of-the-art methods as well as the robustness against poisoning attacks. Along the way, we analyze the Dshield dataset, and we reveal dominant patterns of malicious traffic.},
  doi      = {10.1109/JSAC.2011.110808},
  groups   = {First Filtering},
  keywords = {IP networks;Predictive models;Prediction algorithms;Security;Noise;Robustness},
}

@InProceedings{9177827,
  author    = {Yu, Lin and Wang, Xingda and Wang, Xiaoping and Zeng, Zhigang},
  booktitle = {2020 12th International Conference on Advanced Computational Intelligence (ICACI)},
  title     = {Improving Robustness of Deep Transfer Model by Double Transfer Learning},
  year      = {2020},
  month     = {Aug},
  pages     = {356-363},
  abstract  = {In recent years, deep learning models have been widely adopted for transfer learning tasks. The deep models, however, were shown to be easily attacked by adversarial examples, which is generated from original samples with the carefully designed small perturbations. Thus, the transfer learning models based on deep networks will also face this problem. Because of the particularity of transfer learning tasks, using the conventional adversarial training to improve the robustness of deep transfer models is very difficult. In this paper, we propose a novel Double Transfer Learning with Adversarial Training (DTLAT) method to enhance the robustness of deep transfer learning models. Our intuition is using the instances of the source domain and target domain to help with adversarial training. At the same time, we design a reverse transfer learning method to weaken the effect of attack methods and improve the performance of deep transfer models of target domain. We regard the adversarial examples from some kind of attack method, like FGSM, as an adversarial domain while try to improve the generalization ability on other attacks method. Experiments demonstrate that DTLAT exceed many other methods about improving the robustness of the deep transfer model on several benchmark datasets.},
  doi       = {10.1109/ICACI49185.2020.9177827},
  groups    = {First Filtering},
  issn      = {2573-3311},
  keywords  = {Training;Robustness;Adaptation models;Machine learning;Task analysis;Perturbation methods;Feature extraction;transfer learning;deep transfer model;adversarial examples;robustness;adversariat training},
}

@Article{7084652,
  author   = {Xiong, Tao and Lou, Wei and Zhang, Jin and Tan, Hailun},
  journal  = {IEEE Transactions on Information Forensics and Security},
  title    = {MIO: Enhancing Wireless Communications Security Through Physical Layer Multiple Inter-Symbol Obfuscation},
  year     = {2015},
  issn     = {1556-6021},
  month    = {Aug},
  number   = {8},
  pages    = {1678-1691},
  volume   = {10},
  abstract = {Communications security is a critical and increasingly challenging issue in wireless networks. A well-known approach for achieving information-theoretic secrecy relies on deploying artificial noises to blind the intruders' interception in the physical layer. However, this approach requires a static channel condition for the transmitter and receiver to generate and offset the controllable artificial noise, which can hardly be implemented in real wireless environments. In this paper, we explore the feasibility of symbol obfuscation to defend against the passive eavesdropping attack and fake packet injection attack during the wireless communications. We propose a multiple inter-symbol obfuscation (MIO) scheme, which utilizes a set of artificial noisy symbols (symbols key) to obfuscate the original data symbols in the physical layer. MIO can effectively enhance the wireless communications security. On the one hand, an eavesdropper, without knowing the artificial noisy symbols, cannot correctly decrypt the obfuscated symbols from the eavesdropped packets. On the other hand, a legitimate receiver can easily check the integrity of the symbols key and then reject the fake packets from the received packets. The security analysis reveals that, without considering the initial key, the MIO scheme can achieve information-theoretic secrecy against the passive eavesdropping attack and computational secrecy against the fake packet injection attack. Moreover, we have implemented our approach in a USRP2 testbed and conducted simulations with Simulink tools to validate the effectiveness of MIO in enhancing wireless communications security.},
  doi      = {10.1109/TIFS.2015.2422264},
  groups   = {First Filtering},
  keywords = {Cryptography;Receivers;Wireless communication;Transmitters;Noise;Noise measurement;Wireless communications security;physical layer security;information-theoretic secrecy;artificial noise;Wireless communications security;physical layer security;information-theoretic secrecy;artificial noise},
}

@Article{7857804,
  author   = {Wang, Kun and Du, Miao and Maharjan, Sabita and Sun, Yanfei},
  journal  = {IEEE Transactions on Smart Grid},
  title    = {Strategic Honeypot Game Model for Distributed Denial of Service Attacks in the Smart Grid},
  year     = {2017},
  issn     = {1949-3061},
  month    = {Sep.},
  number   = {5},
  pages    = {2474-2482},
  volume   = {8},
  abstract = {Advanced metering infrastructure (AMI) is an important component for a smart grid system to measure, collect, store, analyze, and operate users consumption data. The need of communication and data transmission between consumers (smart meters) and utilities make AMI vulnerable to various attacks. In this paper, we focus on distributed denial of service attack in the AMI network. We introduce honeypots into the AMI network as a decoy system to detect and gather attack information. We analyze the interactions between the attackers and the defenders, and derive optimal strategies for both sides. We further prove the existence of several Bayesian-Nash equilibriums in the honeypot game. Finally, we evaluate our proposals on an AMI testbed in the smart grid, and the results show that our proposed strategy is effective in improving the efficiency of defense with the deployment of honeypots.},
  doi      = {10.1109/TSG.2017.2670144},
  groups   = {First Filtering},
  keywords = {Computer crime;Servers;Games;Smart grids;Smart meters;Bayes methods;Analytical models;Honeypot;game theory;advanced metering infrastructure;distributed denial of service attack;smart grid},
}

@InProceedings{7350473,
  author    = {Kantert, Jan and Edenhofer, Sarah and Tomforde, Sven and Hähner, Jörg and Müller-Schloer, Christian},
  booktitle = {2015 12th International Conference on Informatics in Control, Automation and Robotics (ICINCO)},
  title     = {Detecting and isolating inconsistently behaving agents using an intelligent control loop},
  year      = {2015},
  month     = {July},
  pages     = {246-253},
  volume    = {01},
  abstract  = {Desktop Computing Grids provide a framework for joining in and sharing resources with others. The result is a self-organised system that typically consists of numerous distributed autonomous entities. Openness and heterogeneity postulate severe challenges to the overall system's stability and efficiency since uncooperative and even malicious participants are free to join. In this paper, we present a concept for identifying agents with exploitation strategies that works on a system-wide analysis of trust and work relationships. Afterwards, we introduce a system-wide control loop to isolate these malicious elements using a norm-based approach - due to the agents' autonomy, we have to build on indirect control actions. Within simulations of a Desktop Computing Grid scenario, we show that the intelligent control loop works highly successful: these malicious elements are identified and isolated with a low error rate. We further demonstrate that the approach results in a significant increase of utility for all participating benevolent agents.},
  groups    = {First Filtering},
  keywords  = {Observers;Measurement;Intelligent control;Peer-to-peer computing;Open systems;Control systems;Computational modeling;Adaptive Control Loop;Multi-Agent-Systems;Trust;Norms;Desktop-grid System},
}

@InProceedings{9219593,
  author    = {Hou, Chengshang and Gou, Gaopeng and Shi, Junzheng and Fu, Peipei and Xiong, Gang},
  booktitle = {2020 IEEE Symposium on Computers and Communications (ISCC)},
  title     = {WF-GAN: Fighting Back Against Website Fingerprinting Attack Using Adversarial Learning},
  year      = {2020},
  month     = {July},
  pages     = {1-7},
  abstract  = {Website Fingerprinting (WF) attack is an side-channel attack which aims at encrypted web traffic. WF attackers recognize encrypted website traffic through constructing fingerprinting for each website using the flow-based features extracted from encrypted traffic. WF defense typically aims at modifying the features of the encrypted websites. However, those countermeasures either cause high overhead or fail to counter the subsequent WF attacks. Especially, the newest WF attacks, which are based on deep neural network, is able to classify the defended traffic by directly learning from the labeled defended traffic. In this paper, we propose an novel defense through making use of the trick that machine learning models are vulnerable to adversarial exmaples. We design WF-GAN, a GAN with an additional WF classifier component, to generate adversarial examples for WF classifiers through adversarial learning. As the website set is divided into source and target website, WF-GAN are trained to map websites features from source set to adversarial examples and make adversarial examples more similar to the website features in the target set. The experimental result shows that WF-GAN achieves 90% success rate with at most 15% overhead for untargeted defense, which outperforms previous defense. In addition, adversarial examples based defense support targeted defense, which is not support by traditional defense. The result shows that WF-GAN achieves over 90% targeted defense success rate when the target websites set is twice as many as the source website set.},
  doi       = {10.1109/ISCC50000.2020.9219593},
  groups    = {First Filtering},
  issn      = {2642-7389},
  keywords  = {network security;privacy;adversarial learning},
}

@InProceedings{9276834,
  author    = {Li, Mingxuan and Lv, Shichao and Shi, Zhiqiang},
  booktitle = {2020 IEEE International Conference on Information Technology,Big Data and Artificial Intelligence (ICIBA)},
  title     = {Malware Detection for Industrial Internet Based on GAN},
  year      = {2020},
  month     = {Nov},
  pages     = {475-481},
  volume    = {1},
  abstract  = {This thesis focuses on the detection of malware in industrial Internet. The basic flow of the detection of malware contains feature extraction and sample identification. API graph can effectively represent the behavior information of malware. However, due to the high algorithm complexity of solving the problem of subgraph isomorphism, the efficiency of analysis based on graph structure feature is low. Due to the different scales of API graph of different malicious codes, the API graph needs to be normalized. Considering the difficulties of sample collection and manual marking, it is necessary to expand the number of malware samples in industrial Internet. This paper proposes a method that combines PageRank with TF-IDF to process the API graph. Besides, this paper proposes a method to construct the adversarial samples of malwares based on GAN.},
  doi       = {10.1109/ICIBA50161.2020.9276834},
  groups    = {First Filtering},
  keywords  = {Malware;Detectors;Internet;Generative adversarial networks;Generators;Gallium nitride;Training;industrial Internet;malware detection;generative adversarial nets;adversarial sample},
}

@Article{9122502,
  author   = {El-Rewini, Zeinab and Sadatsharan, Karthikeyan and Sugunaraj, Niroop and Selvaraj, Daisy Flora and Plathottam, Siby Jose and Ranganathan, Prakash},
  journal  = {IEEE Sensors Journal},
  title    = {Cybersecurity Attacks in Vehicular Sensors},
  year     = {2020},
  issn     = {1558-1748},
  month    = {Nov},
  number   = {22},
  pages    = {13752-13767},
  volume   = {20},
  abstract = {Today's modern vehicles contain anywhere from sixty to one-hundred sensors and exhibit the characteristics of Cyber-Physical-Systems (CPS). There is a high degree of coupling, cohesiveness, and interactions among vehicle's CPS components (e.g., sensors, devices, systems, systems-of-systems) across sensing, communication, and control layers. Cyber-attacks in the sensing or communication layers can compromise the security of the control layer. This paper provides a detailed review of potential cyber threats related to the sensing layer. Notably, the focus is mainly towards two categories of sensors: vehicle dynamics sensors (e.g., Tire Pressure Monitoring Systems (TPMS), magnetic encoders, and inertial sensors) and environment sensors (e.g., Light Detection and Ranging (LiDAR), ultrasonic, camera, Radio Detection and Ranging (Radar) systems, and Global Positioning System (GPS) units). The paper also offers perspectives through existing countermeasures from literature and stresses the need for data-driven cybersecurity solutions.},
  doi      = {10.1109/JSEN.2020.3004275},
  groups   = {First Filtering},
  keywords = {Sensor phenomena and characterization;Sensor systems;Vehicle dynamics;Computer security;Autonomous vehicles;Cyber-attacks;environment sensors;sensing layer;vehicle dynamics sensors},
}

@Article{9099073,
  author   = {Gu, Zhaoquan and Hu, Weixiong and Zhang, Chuanjing and Lu, Hui and Yin, Lihua and Wang, Le},
  journal  = {IEEE Transactions on Network Science and Engineering},
  title    = {Gradient Shielding: Towards Understanding Vulnerability of Deep Neural Networks},
  year     = {2021},
  issn     = {2327-4697},
  month    = {April},
  number   = {2},
  pages    = {921-932},
  volume   = {8},
  abstract = {Deep neural networks (DNNs) have been widely adopted but they are vulnerable to intentionally crafted adversarial examples. Various attack methods against DNNs have been proposed, yet there still lacks theoretical explanation of adversarial examples. In this paper, we aim to understand adversarial examples from the attacking process and we assume adding perturbations to the key/sensitive regions of the image could fool image classification DNNs. We propose gradient shielding to verify the assumption which ignores insensitive information during generating adversarial examples. Specifically, we propose interactive gradient shielding (IGS) method which selects sensitive regions and then applies gradient-based attack. To remove region selection, we propose adaptive gradient shielding (AGS) method which ignores insensitive gradients automatically. We conduct extensive experiments to evaluate the performance and the results also corroborate our perspective. With this method, we won the first place in IJCAI-AAAC 2019 Non-targeted Adversarial Attack competition.},
  doi      = {10.1109/TNSE.2020.2996738},
  groups   = {First Filtering},
  keywords = {Perturbation methods;Neural networks;Optimization;Feature extraction;Electronic mail;Face recognition;Iterative methods;Gradient shielding;adversarial example;deep neural networks;vulnerability.},
}

@InProceedings{8795319,
  author    = {Bassey, Joshua and Adesina, Damilola and Li, Xiangfang and Qian, Lijun and Aved, Alexander and Kroecker, Timothy},
  booktitle = {2019 Fourth International Conference on Fog and Mobile Edge Computing (FMEC)},
  title     = {Intrusion Detection for IoT Devices based on RF Fingerprinting using Deep Learning},
  year      = {2019},
  month     = {June},
  pages     = {98-104},
  abstract  = {Internet of Things (IoT) and 4G/5G wireless networks have added huge number of devices and new services, where commercial-of-the-shelf (COTS) IoT devices have been deployed extensively. To ensure secure operations of these systems with wireless transmission capabilities, Radio Frequency (RF) surveillance is important to monitor their activities in RF spectrum and detect unauthorized IoT devices. Specifically, in order to prevent an adversary from impersonating legitimate users using identical devices from the same manufacturer, unique “signatures” must be obtained for every individual device in order to uniquely identify each device. In this study, a novel intrusion detection method is proposed to detect unauthorized IoT devices using deep learning. The proposed method is based on RF fingerprinting since physical layer based features are device specific and more difficult to impersonate. RF traces are collected from six “identical” ZigBee devices via a USRP based test bed. The traces span a range of Signal-to-Noise Ratio, to ensure robustness of the model. A convolutional neural network is used to extract features from the RF traces, and dimension reduction and de-correlation are performed on the extracted features. The reduced features are then clustered to identify IoT devices. We show that the proposed method is able to identify devices that are not observed during training. The results not only highlight the benefit of deep learning based feature extraction, but also show promising prospects for being able to distinguish new devices (classes) that are not observed during training.},
  doi       = {10.1109/FMEC.2019.8795319},
  groups    = {First Filtering},
  keywords  = {RF fingerprinting;Deep Learning;ZigBee;Internet of Things},
}

@InProceedings{7860533,
  author    = {Thompson, Brian and Morris-King, James and Cam, Hasan},
  booktitle = {2016 IEEE Conference on Communications and Network Security (CNS)},
  title     = {Effectiveness of proactive reset for mitigating impact of stealthy attacks on networks of autonomous systems},
  year      = {2016},
  month     = {Oct},
  pages     = {437-441},
  abstract  = {Recent examples have shown that sophisticated cyber attackers are capable of infiltrating the cyber defenses of major organizations and spreading stealthily through a network, potentially doing significant damage before exploited vulnerabilities can be identified or patches developed. Autonomous systems are particularly vulnerable because they are further removed from human intervention. One emerging technology designed to address this problem is proactive reset, where systems automatically undergo a reset operation that restores them to a known malware-free state, regardless of whether or not they were already infected. More frequent resets result in higher security, but may also reduce functionality of the network. In this work, we consider the effectiveness of three proactive reset policies for mitigating the spread of stealthy malware through a network of autonomous systems. We perform experiments using agent-based simulation and find that a proactive policy that uses risk-flow analysis to determine when systems should be reset achieves performance comparable to that of a perfect detector.},
  doi       = {10.1109/CNS.2016.7860533},
  groups    = {First Filtering},
  keywords  = {Malware;Security;Autonomous systems;Detectors;Drones;Conferences;Analytical models},
}

@InProceedings{9474292,
  author    = {Hossen, Md Imran and Hei, Xiali},
  booktitle = {2021 IEEE Security and Privacy Workshops (SPW)},
  title     = {A Low-Cost Attack against the hCaptcha System},
  year      = {2021},
  month     = {May},
  pages     = {422-431},
  abstract  = {CAPTCHAs are a defense mechanism to prevent malicious bot programs from abusing websites on the Internet. hCaptcha is a relatively new but emerging image CAPTCHA service. This paper presents an automated system that can break hCaptcha challenges with a high success rate. We evaluate our system against 270 hCaptcha challenges from live websites and demonstrate that it can solve them with 95.93% accuracy while taking only 18.76 seconds on average to crack a challenge. We run our attack from a docker instance with only 2GB memory (RAM), 3 CPUs, and no GPU devices, demonstrating that it requires minimal resources to launch a successful large-scale attack against the hCaptcha system.},
  doi       = {10.1109/SPW53761.2021.00061},
  groups    = {First Filtering},
  keywords  = {Privacy;Bot (Internet);Image recognition;Conferences;Memory management;Random access memory;Graphics processing units;CAPTCHA;hCaptcha;deep learning;security},
}

@InProceedings{7158098,
  author    = {Ali Alheeti, Khattab M. and Gruebler, Anna and McDonald-Maier, Klaus D.},
  booktitle = {2015 12th Annual IEEE Consumer Communications and Networking Conference (CCNC)},
  title     = {An intrusion detection system against malicious attacks on the communication network of driverless cars},
  year      = {2015},
  month     = {Jan},
  pages     = {916-921},
  abstract  = {Vehicular ad hoc networking (VANET) have become a significant technology in the current years because of the emerging generation of self-driving cars such as Google driverless cars. VANET have more vulnerabilities compared to other networks such as wired networks, because these networks are an autonomous collection of mobile vehicles and there is no fixed security infrastructure, no high dynamic topology and the open wireless medium makes them more vulnerable to attacks. It is important to design new approaches and mechanisms to rise the security these networks and protect them from attacks. In this paper, we design an intrusion detection mechanism for the VANETs using Artificial Neural Networks (ANNs) to detect Denial of Service (DoS) attacks. The main role of IDS is to detect the attack using a data generated from the network behavior such as a trace file. The IDSs use the features extracted from the trace file as auditable data. In this paper, we propose anomaly and misuse detection to detect the malicious attack.},
  doi       = {10.1109/CCNC.2015.7158098},
  groups    = {First Filtering},
  issn      = {2331-9860},
  keywords  = {Vehicles;Security;Artificial neural networks;Feature extraction;Training;Accuracy;Ad hoc networks;security;vehicular ad hoc networks;intrusion detection system;driverless car},
}

@InProceedings{9202750,
  author    = {Rumez, Marcel and Lin, Jinghua and Fuchß, Thomas and Kriesten, Reiner and Sax, Eric},
  booktitle = {2020 IEEE 44th Annual Computers, Software, and Applications Conference (COMPSAC)},
  title     = {Anomaly Detection for Automotive Diagnostic Applications Based on N-Grams},
  year      = {2020},
  month     = {July},
  pages     = {1423-1429},
  abstract  = {The increasing level of connectivity within vehicles and their environment such as backend or infrastructure increases the risk of potential vulnerabilities regarding information security. In order to minimize these risks, vehicle manufacturers are forced to implement appropriate countermeasures, which are increasingly embedded in approval regulations. As a reactive countermeasure, various approaches to Intrusion Detection Systems (IDSs) exist within the research area to detect attack attempts as early as possible. In this paper, we shift into a new research direction and present an approach for the detection of anomalies in automotive diagnostic applications by using a statistical language model. We analyze incoming diagnostic frames using two different n-gram models (sequence-based and byte-based) to determine whether sequences and the bytes embedded are contextually valid. Since there is currently no publicly available data set of diagnostic data, the detection rate is limited to learned diagnostic uses cases from our own data recordings. Since it is very challenging to generate such a large amount of data, a further enhancement of the approach based on unsupervised learning by using a dynamic anomaly threshold would be promising.},
  doi       = {10.1109/COMPSAC48688.2020.00-56},
  groups    = {First Filtering},
  issn      = {0730-3157},
  keywords  = {Protocols;Automotive engineering;Anomaly detection;Logic gates;Payloads;Conferences;Intrusion detection;Automotive Security, Vehicle Diagnostics, Anomaly Detection},
}

@Article{9252913,
  author   = {Park, Hyeseung and Park, Seungchul and Joo, Youngbok},
  journal  = {IEEE Access},
  title    = {Relativistic Approach for Training Self-Supervised Adversarial Depth Prediction Model Using Symmetric Consistency},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {206835-206847},
  volume   = {8},
  abstract = {This article proposes a novel approach for predicting depth from a single image in a self-supervised manner, specifically using generative adversarial networks (GANs) with enhancements to improve training performance. We train our model to generate disparity maps or inverse depth maps using left/right stereo image supervision rather than direct supervision from depth ground truth. We avoid the problem of training instability in standard GANs by employing a relativistic discriminator that evaluates how realistic an input image is. Since the reconstructed image quality determines the disparity map's accuracy, we adopt the GMSD, one of the standout IQA algorithms, as a part of the image reconstruction loss function. A VGG-19 pre-trained model-based perceptual loss is used to optimize our model in a feature space instead of pixel space and to enhance reconstructed images' perceptual quality with the learning-based perspective. Also, we add another symmetric generator that takes the right images as input, which helps to maintain the consistency of left/right views and enrich our training data with reasonable overhead on the training time. Our network is trained to predict depths of 640 × 192 images using the KITTI stereo dataset, which shows an outstanding performance compared to state-of-the-art works in various evaluation metrics. We verify our method's modules by performing an ablation study and evaluate the generalization performance on CityScapes and Make3D datasets.},
  doi      = {10.1109/ACCESS.2020.3036893},
  groups   = {First Filtering},
  keywords = {Training;Image reconstruction;Gallium nitride;Generative adversarial networks;Estimation;Three-dimensional displays;Generators;Self-supervised depth prediction;monocular depth estimation;relativistic GAN;GMSD;perceptual loss},
}

@InProceedings{8881319,
  author    = {Song, Yufei and Yu, Zongchao and Liu, Xuan and Tian, Jianwei and Chen, Mu},
  booktitle = {2019 IEEE Innovative Smart Grid Technologies - Asia (ISGT Asia)},
  title     = {Isolation Forest based Detection for False Data Attacks in Power Systems},
  year      = {2019},
  month     = {May},
  pages     = {4170-4174},
  abstract  = {Power systems become a primary target of cyber attacks because of the vulnerability of the integrated communication networks. An attacker is able to manipulate the integrity of real-time data by maliciously modifying the readings of meters transmitted to the control center. Moreover, it is demonstrated that such attack can escape the bad data detection in state estimation if the topology and network information of the entire power grid is known to the attacker. In this paper, we propose an isolation forest (IF) based detection algorithm as a countermeasure against false data attack (FDA). This method requires no tedious pre-training procedure to obtain the labels of outliers. In addition, comparing with other algorithms, the IF based detection method can find the outliers quickly. The performance of the proposed detection method is verified using the simulation results on the IEEE 118-bus system.},
  doi       = {10.1109/ISGT-Asia.2019.8881319},
  groups    = {First Filtering},
  issn      = {2378-8542},
  keywords  = {Vegetation;Forestry;Power systems;State estimation;Real-time systems;Transmission line measurements;Cyberattack;smart grids;false data injection attacks;outlier detection;isolation forest},
}

@Article{8750789,
  author   = {Jingping, Jia and Kehua, Chen and Jia, Chen and Dengwen, Zhou and Wei, Ma},
  journal  = {IEEE Access},
  title    = {Detection and Recognition of Atomic Evasions Against Network Intrusion Detection/Prevention Systems},
  year     = {2019},
  issn     = {2169-3536},
  pages    = {87816-87826},
  volume   = {7},
  abstract = {Network evasions can bypass network intrusion detection/prevention systems to deliver exploits, attacks, or malware to victims without being detected. This paper presents a novel method for the detection and recognition of atomic network evasions by the classification of a transmission control protocol (TCP) stream's packet behavior. The syntax for the conversion of TCP streams to codeword streams is proposed to facilitate the extraction of statistical features while preserving the evasion behavior attributes of original network flows. We developed a feature extraction method of employing the normalized term frequencies of codewords to characterize intra and inter packet attribute patterns hidden in actual TCP streams. A TCP stream is then transformed to a fixed length numeric feature vector. Supervised multi-class classifiers are built on the extracted feature vectors to differentiate different types of evasions from normal streams. The quantitative evaluations on an evasion dataset consisting of normal network flows and eight types of atomic evasion flows demonstrated that the proposed approach achieved an encouraging performance with an accuracy of 98.95%.},
  doi      = {10.1109/ACCESS.2019.2925639},
  groups   = {First Filtering},
  keywords = {Feature extraction;Atomic layer deposition;Protocols;IP networks;Resilience;Training;Task analysis;Network intrusion detection/prevention;network evasion;term frequency and inverse document frequency},
}

@InProceedings{8489414,
  author    = {Ndichu, Samuel and Ozawa, Seiichi and Misu, Takeshi and Okada, Kouichirou},
  booktitle = {2018 International Joint Conference on Neural Networks (IJCNN)},
  title     = {A Machine Learning Approach to Malicious JavaScript Detection using Fixed Length Vector Representation},
  year      = {2018},
  month     = {July},
  pages     = {1-8},
  abstract  = {To add more functionality and enhance usability of web applications, JavaScript (JS) is frequently used. Even with many advantages and usefulness of JS, an annoying fact is that many recent cyberattacks such as drive-by-download attacks exploit vulnerability of JS codes. In general, malicious JS codes are not easy to detect, because they sneakily exploit vulnerabilities of browsers and plugin software, and attack visitors of a web site unknowingly. To protect users from such threads, the development of an accurate detection system for malicious JS is soliciting. Conventional approaches often employ signature and heuristic-based methods, which are prone to suffer from zero-day attacks, i.e., causing many false negatives and/or false positives. For this problem, this paper adopts a machine-learning approach to feature learning called Doc2Vec, which is a neural network model that can learn context information of texts. The extracted features are given to a classifier model (e.g., SVM and neural networks) and it judges the maliciousness of a JS code. In the performance evaluation, we use the D3M Dataset (Drive-by-Download Data by Marionette) for malicious JS codes and JSUPACK for benign ones for both training and test purposes. We then compare the performance to other feature learning methods. Our experimental results show that the proposed Doc2Vec features provide better accuracy and fast classification in malicious JS code detection compared to conventional approaches.},
  doi       = {10.1109/IJCNN.2018.8489414},
  groups    = {First Filtering},
  issn      = {2161-4407},
  keywords  = {Feature extraction;Predictive models;Machine learning;Neural networks;Browsers;Context modeling;Support vector machines;cybersecurity;machine learning;Doc2Vec;malicious JavaScript detection;feature learning},
}

@InProceedings{7785721,
  author    = {Sallam, Asmaa and Xiao, Qian and Bertino, Elisa and Fadolalkarim, Daren},
  booktitle = {2016 IEEE 17th International Conference on Information Reuse and Integration (IRI)},
  title     = {Anomaly Detection Techniques for Database Protection Against Insider Threats (Invited Paper)},
  year      = {2016},
  month     = {July},
  pages     = {20-29},
  abstract  = {In this paper, we propose techniques for detecting anomalies in user accesses by learning profiles of normal access patterns of users based on both the syntactic and semantic features of past users queries stored in database logs. New accesses are checked upon these profiles and deviations are considered anomalous accesses which may be indications of potential insider attacks. We consider two scenarios. The first scenario is when the monitored database employs role-based access control (RBAC). In this scenario, we build profiles of roles rather than individual users, this makes our approach usable for databases which have a large user population. In this case, we use the naive Bayesian classification to detect anomalies. We also employ multilabeling classification to account for the case when roles have common access patterns. The second scenario is when RBAC is not used. In this case, we detect anomalies using the COBWEB clustering algorithm. We provide extensive evaluation for our techniques. Results show that our techniques are effective.},
  doi       = {10.1109/IRI.2016.12},
  groups    = {First Filtering},
  keywords  = {Databases;Training;Bayes methods;Computer science;Syntactics;Feature extraction;Engines;Anomaly Detection;Insider Threats;Databases;Classification;Clustering},
}

@Article{8892454,
  author   = {Alotaibi, Aziz},
  journal  = {IEEE Access},
  title    = {Identifying Malicious Software Using Deep Residual Long-Short Term Memory},
  year     = {2019},
  issn     = {2169-3536},
  pages    = {163128-163137},
  volume   = {7},
  abstract = {The use of smartphone applications based on the Android OS platform is rapidly growing among smartphone users. However, malicious apps for Android are being developed to perform attacks, such as destroying operating systems, stealing confidential data, gathering personal information, and hijacking or encrypting sensitive data. Several malware detection systems based on machine learning have been developed and deployed to extract a variety of features to prevent such attacks. However, new efficient detection methods are needed to extract complex features and hidden structures from malicious apps to detect malware. This paper proposes a novel framework, namely, MalResLSTM, based on deep residual long short-term memory to identify and classify malware variants. The framework imposes a set of constraints on the deep learning architecture to capture dependencies between the extracted features from the Android package kit (APK) file. These feature sets are mapped to a vector space to process the input sequence using a sequence model based on the residual LSTM network. To evaluate the performance of the proposed framework, several experiments are conducted on the Drebin dataset, which contains 129,013 applications. The results demonstrate that MalResLSTM can achieve a 99.32% detection accuracy and outperforms previous algorithms. An extensive experimental analysis was conducted, which included machine-learning-based algorithms and a variety of deep learning-based algorithms, to evaluate the efficiency and robustness of our proposed framework.},
  doi      = {10.1109/ACCESS.2019.2951751},
  groups   = {First Filtering},
  keywords = {Malware;Feature extraction;Classification algorithms;Hidden Markov models;Machine learning algorithms;Machine learning;Software algorithms;Malware Detection;android malware;malware analysis;malware classification;static analysis;deep learning-based algorithms},
}

@InProceedings{6364010,
  author    = {Mehta, Anil and Hantehzadeh, Neda and Gurbani, Vijay K. and Ho, Tin Kam and Sander, Flavia},
  booktitle = {2012 IEEE International Conference on Communications (ICC)},
  title     = {On using multiple classifier systems for Session Initiation Protocol (SIP) anomaly detection},
  year      = {2012},
  month     = {June},
  pages     = {1101-1106},
  abstract  = {The Session Initiation Protocol (SIP) is an important multimedia session establishment protocol used on the Internet. It is a text-based protocol, which is complex to parse due to the wide variability in representing the information elements. Building a parser for SIP may appear straight-forward; however, writing an efficient, robust, and scalable parser that is immune to low-effort attacks using malformed messages is surprisingly difficult. To mitigate this, self-learning systems based on Euclidean distance classifiers have been proposed to determine whether a message is well-formed or not. The efficacy of such machine learning algorithms must be studied on varied data sets before they can be successfully used. Our previous work has shown that Euclidean distance-based classifiers and standard classifiers used for self-learning problems are unable to detect malformed self-similar SIP messages (i.e., invalid SIP messages that differ by only a few bytes from normal SIP messages). This paper proposes using multiple classifier systems to detect malformed self-similar SIP messages. Our results show that a judiciously constructed multiple classifier system yields classification performance as high as 97.56% of the messages being classified correctly. We further show that for self-similar SIP messages, feature reduction measures based on the first moment are insufficient for improving classification accuracy.},
  doi       = {10.1109/ICC.2012.6364010},
  groups    = {First Filtering},
  issn      = {1938-1883},
  keywords  = {Protocols;Vectors;Transforms;Feature extraction;Accuracy;Grammar;Internet},
}

@InProceedings{7000784,
  author    = {Hosseini, Soodeh and Azgomi, Mohammad Abdollahi and Rahmani, Adel Torkaman},
  booktitle = {7'th International Symposium on Telecommunications (IST'2014)},
  title     = {On the global dynamics of an SEIRS epidemic model of malware propagation},
  year      = {2014},
  month     = {Sep.},
  pages     = {646-651},
  abstract  = {In this paper, we attempt to mathematically formulate a susceptible-exposed-infectious-recovered-susceptible (SEIRS) epidemic model to study dynamical behaviors of malware propagation in scale-free networks (SFNs). In the proposed discrete-time epidemic model, we consider defense mechanism of software diversity to limit epidemic spreading in SFNs. Dynamical behaviors of the SEIRS epidemic model is determined by basic reproductive ratio, which is often used as a threshold parameter. Also, the impact of the assignment of diverse software packages on the propagation process is examined. Theoretical results show that basic reproductive ratio is significantly dependent on diverse software packages and the network topology. The installation of diverse software packages on nodes leads to decrease reproductive ratio and malware spreading. The results of numerical simulations are given to validate the theoretical analysis.},
  doi       = {10.1109/ISTEL.2014.7000784},
  groups    = {First Filtering},
  keywords  = {Mathematical model;Malware;Numerical models;Software packages;Analytical models;Computational modeling;Scale-free network;malware propagation modeling;software diversity;basic reproductive ratio},
}

@Article{9107120,
  author   = {Alkadi, Osama and Moustafa, Nour and Turnbull, Benjamin},
  journal  = {IEEE Access},
  title    = {A Review of Intrusion Detection and Blockchain Applications in the Cloud: Approaches, Challenges and Solutions},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {104893-104917},
  volume   = {8},
  abstract = {This paper reviews the background and related studies in the areas of cloud systems, intrusion detection and blockchain applications against cyber attacks. This work aims to discuss collaborative anomaly detection systems for discovering insider and outsider attacks from cloud centres, including the technologies of virtualisation and containerisation, along with trusting intrusion detection and cloud systems using blockchain. Moreover, the ability to detect such malicious attacks is critical for conducting necessary mitigation, at an early stage, to minimise the impact of disruption and restore cloud operations and their live migration processes. This paper presents an overview of cloud architecture and categorises potential state-of-the-art security events based on their occurrence at different cloud deployment models. Network Intrusion Detection Systems (NIDS) in the cloud, involving types of classification and common detection approaches, are also described. Collaborative NIDSs for cloud-based blockchain applications are also explained to demonstrate how blockchain can address challenges related to data privacy and trust management. A summary of the research challenges and future research directions in these fields is also explained.},
  doi      = {10.1109/ACCESS.2020.2999715},
  groups   = {First Filtering},
  keywords = {Cloud computing;Blockchain;Intrusion detection;Grid computing;Operating systems;Intrusion detection systems;collaborative anomaly detection;cloud systems;blockchain applications;approaches;challenges;solutions},
}

@InProceedings{8761569,
  author    = {Wen, Yun and Yoshida, Makoto and Zhang, Junqing and Chu, Zheng and Xiao, Pei and Tafazolli, Rahim},
  booktitle = {ICC 2019 - 2019 IEEE International Conference on Communications (ICC)},
  title     = {Machine Learning Based Attack Against Artificial Noise-Aided Secure Communication},
  year      = {2019},
  month     = {May},
  pages     = {1-6},
  abstract  = {Physical layer security (PLS) technologies have attracted much attention in recent years for their potential to provide information-theoretically secure communications. Artificial Noise (AN)-aided transmission is considered as one of the most practicable PLS technologies, as it can realize secure transmission independent of the eavesdropper's channel status. In this paper, we reveal that AN transmission has the dependency of eavesdropper's channel condition by introducing our proposed attack method based on a supervised-learning algorithm which utilizes the modulation scheme, available from known packet preamble and/or header information, as supervisory signals of training data. Numerical simulation results with the comparison to conventional clustering methods show that our proposed method improves the success probability of attack from 4.8% to at most 95.8% for the QPSK modulation. It implies that the transmission to the receiver in the cell-edge with low order modulation will be cracked if the eavesdropper's channel is good enough by employing more antennas than the transmitter. This work brings new insights into the effectiveness of AN schemes and provides useful guidance for the design of robust PLS techniques for practical wireless systems.},
  doi       = {10.1109/ICC.2019.8761569},
  groups    = {First Filtering},
  issn      = {1938-1883},
  keywords  = {Modulation;Wireless communication;Antennas;Communication system security;Security;Signal to noise ratio;Channel estimation},
}

@InProceedings{7987533,
  author    = {Sepulveda, Johanna and Gross, Mathieu and Zankl, Andreas and Sigl, Georg},
  booktitle = {2017 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)},
  title     = {Exploiting Bus Communication to Improve Cache Attacks on Systems-on-Chips},
  year      = {2017},
  month     = {July},
  pages     = {284-289},
  abstract  = {Systems-on-Chips (SoCs) are one of the key enabling technologies for the Internet-of-Things (IoT). Given the continuous distribution of IoT devices, data confidentiality and user privacy are of utmost importance. However, with the growing complexity of SoCs, the risk of malware infections and trojans introduced at design time increases significantly. A vital threat to system security are so-called side-channel attacks based on cache observations. While mainly studied on desktop and server systems, recent publications have analyzed cache attacks on mobile devices and network-on-chip platforms. In this work, we investigate cache attacks on System-on-Chips implementing bus based communication. To this end, we present two contributions. First, we demonstrate an improved Prime+Probe based cache attack on AES-128 that, for the first time, exploits the bus communication to increase its efficiency. Second, we integrate two countermeasures (Shuffling and Mini-table) and evaluate their impact on the attack. The results show that our improved attack recovers the full key twice as fast as Prime+Probe without exploiting bus communication. Moreover, we propose protection techniques that are feasible and effectively mitigate both original and improved attack.},
  doi       = {10.1109/ISVLSI.2017.57},
  groups    = {First Filtering},
  issn      = {2159-3477},
  keywords  = {Cryptography;IP networks;Hardware;Complexity theory;Servers;System-on-chip;SoCs;Cache Attack;Access-driven;Bus;Security},
}

@InProceedings{9156458,
  author    = {Chen, Xuesong and Yan, Xiyu and Zheng, Feng and Jiang, Yong and Xia, Shu-Tao and Zhao, Yong and Ji, Rongrong},
  booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {One-Shot Adversarial Attacks on Visual Tracking With Dual Attention},
  year      = {2020},
  month     = {June},
  pages     = {10173-10182},
  abstract  = {Almost all adversarial attacks in computer vision are aimed at pre-known object categories, which could be offline trained for generating perturbations. But as for visual object tracking, the tracked target categories are normally unknown in advance. However, the tracking algorithms also have potential risks of being attacked, which could be maliciously used to fool the surveillance systems. Meanwhile, it is still a challenging task that adversarial attacks on tracking since it has the free-model tracked target. Therefore, to help draw more attention to the potential risks, we study adversarial attacks on tracking algorithms. In this paper, we propose a novel one-shot adversarial attack method to generate adversarial examples for free-model single object tracking, where merely adding slight perturbations on the target patch in the initial frame causes state-of-the-art trackers to lose the target in subsequent frames. Specifically, the optimization objective of the proposed attack consists of two components and leverages the dual attention mechanisms. The first component adopts a targeted attack strategy by optimizing the batch confidence loss with confidence attention while the second one applies a general perturbation strategy by optimizing the feature loss with channel attention. Experimental results show that our approach can significantly lower the accuracy of the most advanced Siamese network-based trackers on three benchmarks.},
  doi       = {10.1109/CVPR42600.2020.01019},
  groups    = {First Filtering},
  issn      = {2575-7075},
  keywords  = {Target tracking;Task analysis;Visualization;Perturbation methods;Object tracking;Computer vision;Optimization},
}

@Article{6506103,
  author   = {Rice, Justin L. and Phoha, Vir V. and Robinson, Philip},
  journal  = {IEEE Transactions on Information Forensics and Security},
  title    = {Using Mussel-Inspired Self-Organization and Account Proxies to Obfuscate Workload Ownership and Placement in Clouds},
  year     = {2013},
  issn     = {1556-6021},
  month    = {June},
  number   = {6},
  pages    = {963-972},
  volume   = {8},
  abstract = {Recent research has provided evidence indicating how a malicious user could perform coresidence profiling and public-to-private IP mapping to target and exploit customers which share physical resources. The attacks rely on two steps: resource placement on the target's physical machine and extraction. Our proposed solution, in part inspired by mussel self-organization, relies on user account and workload clustering to mitigate coresidence profiling. Users with similar preferences and workload characteristics are mapped to the same cluster. To obfuscate the public-to-private IP map, each cluster is managed and accessed by an account proxy. Each proxy uses one public IP address, which is shared by all clustered users when accessing their instances, and maintains the mapping to private IP addresses. We describe a set of capabilities and attack paths an attacker needs to execute for targeted coresidence, and present arguments to show how our approach disrupts the critical steps in the attack path for most cases. We then perform a risk assessment to determine the likelihood an individual user will be victimized, given that a successful nondirected exploit has occurred. Our results suggest that while possible, this event is highly unlikely.},
  doi      = {10.1109/TIFS.2013.2259158},
  groups   = {First Filtering},
  keywords = {IP networks;Computational modeling;Mathematical model;Data mining;Equations;Color;Security;Distributed systems;animal behavior;multi-agent systems;data privacy;data security;risk analysis},
}

@InProceedings{8465932,
  author    = {Chaudhuri, Sumanta},
  booktitle = {2018 55th ACM/ESDA/IEEE Design Automation Conference (DAC)},
  title     = {A Security Vulnerability Analysis of SoCFPGA Architectures},
  year      = {2018},
  month     = {June},
  pages     = {1-6},
  abstract  = {SoCFPGAs or FPGAs integrated on the same die with chip multi processors have made it to the market in the past years. In this article we analyse various security loopholes, existing precautions and countermeasures in these architectures. We consider Intel Cyclone/Arria devices and Xilinx Zynq/Ultrascale devices. We present an attacker model and we highlight three different types of attacks namely direct memory attacks, cache timing attacks, and rowhammer attacks that can be used on inadequately protected systems. We present and compare existing security mechanisms in this architectures, and their shortfalls. We present real life example of these attacks and further countermeasures to secure systems based on SoCFPGAs.},
  doi       = {10.1109/DAC.2018.8465932},
  groups    = {First Filtering},
  keywords  = {Field programmable gate arrays;Security;Computer architecture;Program processors;Cyclones;Timing;Kernel},
}

@InProceedings{9084722,
  author    = {Ji, Yuchen and Li, Xiaoyong},
  booktitle = {2020 IEEE 4th Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)},
  title     = {An efficient intrusion detection model based on deepFM},
  year      = {2020},
  month     = {June},
  pages     = {778-783},
  volume    = {1},
  abstract  = {With the development of the Internet, more and more network attacks are also emerging. The traditional intrusion detection system has been challenged tremendously, and it is unable to detect the new types of attacks. This paper proposes an intrusion detection model based on deepFM, which combines the advantages of FM algorithm for processing shallow features and the advantages of deep neural network for processing deep features, which can effectively extract features and classify them. We then performed experiments using the KDD CUP 99 dataset. First, the training set is deduplicated and oversampled to balance various types of samples, and then the processed data is used for training. Then optimize tuning parameters and find an optimal model. Finally, use the best model to make predictions on the test set. On the test set, we got a correct rate of 0.934 and a COST value of 0.191. By analyzing the results and comparing existing studies, we can conclude that the model proposed in this paper has a good effect on KDD 99 CUP and has certain practical value.},
  doi       = {10.1109/ITNEC48623.2020.9084722},
  groups    = {First Filtering},
  keywords  = {Feature extraction;Intrusion detection;Data models;Encoding;Frequency modulation;Neural networks;Training;intrusion detection;deep neural network;factorization machine;deepFM},
}

@Article{8728167,
  author   = {Liu, Gaoyang and Wang, Chen and Peng, Kai and Huang, Haojun and Li, Yutong and Cheng, Wenqing},
  journal  = {IEEE Transactions on Computational Social Systems},
  title    = {SocInf: Membership Inference Attacks on Social Media Health Data With Machine Learning},
  year     = {2019},
  issn     = {2329-924X},
  month    = {Oct},
  number   = {5},
  pages    = {907-921},
  volume   = {6},
  abstract = {Social media networks have shown rapid growth in the past, and massive social data are generated which can reveal behavior or emotion propensities of users. Numerous social researchers leverage machine learning technology to build social media analytic models which can detect the abnormal behaviors or mental illnesses from the social media data effectively. Although the researchers only public the prediction interfaces of the machine learning models, in general, these interfaces may leak information about the individual data records on which the models were trained. Knowing a certain user's social media record was used to train a model can breach user privacy. In this paper, we present SocInf and focus on the fundamental problem known as membership inference. The key idea of SocInf is to construct a mimic model which has a similar prediction behavior with the public model, and then we can disclose the prediction differences between the training and testing data set by abusing the mimic model. With elaborated analytics on the predictions of the mimic model, SocInf can thus infer whether a given record is in the victim model's training set or not. We empirically evaluate the attack performance of SocInf on machine learning models trained by Xgboost, logistics, and online cloud platform. Using the realistic data, the experiment results show that SocInf can achieve an inference accuracy and precision of 73% and 84%, respectively, in average, and of 83% and 91% at best.},
  doi      = {10.1109/TCSS.2019.2916086},
  groups   = {First Filtering},
  keywords = {Data models;Predictive models;Social networking (online);Machine learning;Training data;Training;Data privacy;Generative adversary network;machine learning;membership inference attack;social media health data},
}

@InProceedings{8455962,
  author    = {Lopez Perez, Rocio and Adamsky, Florian and Soua, Ridha and Engel, Thomas},
  booktitle = {2018 17th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/ 12th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE)},
  title     = {Machine Learning for Reliable Network Attack Detection in SCADA Systems},
  year      = {2018},
  month     = {Aug},
  pages     = {633-638},
  abstract  = {Critical Infrastructures (CIs) use Supervisory Control And Data Acquisition (SCADA) systems for remote control and monitoring. Sophisticated security measures are needed to address malicious intrusions, which are steadily increasing in number and variety due to the massive spread of connectivity and standardisation of open SCADA protocols. Traditional Intrusion Detection Systems (IDSs) cannot detect attacks that are not already present in their databases. Therefore, in this paper, we assess Machine Learning (ML) for intrusion detection in SCADA systems using a real data set collected from a gas pipeline system and provided by the Mississippi State University (MSU). The contribution of this paper is two-fold: 1) The evaluation of four techniques for missing data estimation and two techniques for data normalization, 2) The performances of Support Vector Machine (SVM), and Random Forest (RF) are assessed in terms of accuracy, precision, recall and F1 score for intrusion detection. Two cases are differentiated: binary and categorical classifications. Our experiments reveal that RF detect intrusions effectively, with an F1 score of respectively > 99%.},
  doi       = {10.1109/TrustCom/BigDataSE.2018.00094},
  groups    = {First Filtering},
  issn      = {2324-9013},
  keywords  = {SCADA systems;Protocols;Pipelines;Payloads;Anomaly detection;Support vector machines;Training;SCADA;SVM;Random Forest;Network Attacks},
}

@InProceedings{8356416,
  author    = {Dowling, Seamus and Schukat, Michael and Melvin, Hugh},
  booktitle = {2017 12th International Conference for Internet Technology and Secured Transactions (ICITST)},
  title     = {Using analysis of temporal variances within a honeypot dataset to better predict attack type probability},
  year      = {2017},
  month     = {Dec},
  pages     = {349-354},
  abstract  = {Honeypots are deployed to capture cyber attack data for analysis of attacker behavior. This paper analyses a honeypot dataset to establish attack types and corresponding temporal patterns. It calculates the probability of each attack type occurring at a particular time of day and tests these probabilities with a random sample from the honeypot dataset. Attacks can take many forms and can come from different geographical sources. Temporal patterns in attacks are often observed due to the diurnal nature of computer usage and thus attack types captured on a honeypot will also reflect these patterns. We propose that it is possible to determine the probability of differing attack types occurring at certain times of the day. Understanding attack behavior informs the implementation of more robust security measures. The paper also proposes automating this process to create dynamic and adaptive honeypots. An adaptive honeypot that can modify its security levels, can increase the attack vector at different times of the day. This will improve data collection for analysis that ultimately will lead to better cyber defenses.},
  doi       = {10.23919/ICITST.2017.8356416},
  groups    = {First Filtering},
  keywords  = {Botnet;Malware;IP networks;Cyberattack;Probability;honeypot;temporal;predictive;probability;adaptive},
}

@InProceedings{7120797,
  author    = {Spring, Jonathan and Kern, Sarah and Summers, Alec},
  booktitle = {2015 APWG Symposium on Electronic Crime Research (eCrime)},
  title     = {Global adversarial capability modeling},
  year      = {2015},
  month     = {May},
  pages     = {1-21},
  abstract  = {Intro: Computer network defense has models for attacks and incidents comprised of multiple attacks after the fact. However, we lack an evidence-based model the likelihood and intensity of attacks and incidents. Purpose: We propose a model of global capability advancement, the adversarial capability chain (ACC), to fit this need. The model enables cyber risk analysis to better understand the costs for an adversary to attack a system, which directly influences the cost to defend it. Method: The model is based on four historical studies of adversarial capabilities: capability to exploit Windows XP, to exploit the Android API, to exploit Apache, and to administer compromised industrial control systems. Result: We propose the ACC with five phases: Discovery, Validation, Escalation, Democratization, and Ubiquity. We use the four case studies as examples as to how the ACC can be applied and used to predict attack likelihood and intensity.},
  doi       = {10.1109/ECRIME.2015.7120797},
  groups    = {First Filtering},
  issn      = {2159-1245},
  keywords  = {Software systems;Biological system modeling;Computational modeling;Analytical models;Androids;Humanoid robots;Integrated circuit modeling;incident response;intrusion detection;intelligence;computer network defense;CND;modeling;security;cybersecurity},
}

@InProceedings{9225476,
  author    = {Ratti, Ritesh and Singh, Sanasam Ranbir and Nandi, Sukumar},
  booktitle = {2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT)},
  title     = {Towards implementing fast and scalable Network Intrusion Detection System using Entropy based Discretization Technique},
  year      = {2020},
  month     = {July},
  pages     = {1-7},
  abstract  = {With the advent of networking technologies and increasing network attacks, Intrusion Detection systems are apparently needed to stop attacks and malicious activities. Various frameworks and techniques have been developed to solve the problem of intrusion detection, still there is need for new frameworks as per the challenging scenario of enormous scale in data size and nature of attacks. Current IDS systems pose challenges on the throughput to work with high speed networks. In this paper we address the issue of high computational overhead of anomaly based IDS and propose the solution using discretization as a data preprocessing step which can drastically reduce the computation overhead. We propose method to provide near real time detection of attacks using only basic flow level features that can easily be extracted from network packets.},
  doi       = {10.1109/ICCCNT49239.2020.9225476},
  groups    = {First Filtering},
  keywords  = {Intrusion detection;Feature extraction;Entropy;Training;Hidden Markov models;Training data;Reconnaissance;Intrusion Detection System;Machine Learning;Discretization;Principal Component Analysis},
}

@InProceedings{7847185,
  author    = {Zhang, Jian and Liu, Pin and He, Jianbiao and Zhang, Yawei},
  booktitle = {2016 IEEE Trustcom/BigDataSE/ISPA},
  title     = {A Hadoop Based Analysis and Detection Model for IP Spoofing Typed DDoS Attack},
  year      = {2016},
  month     = {Aug},
  pages     = {1976-1983},
  abstract  = {As more and more cloud services are exposed to DDoS attacks, DDoS attack detect has become a new challenging task because large packet traces captured on fast links could not be easily handled on a single server with limited computing and memory resources. In this paper, we propose a Hadoop based model to identify abnormal packets and compute the statistics according to the number of abnormal packets. The novelties of the model are that:(1) by harnessing HBASE, an improved bloom filter based mapping mechanism named TCP2HC/UDP2HC are implemented, (2)with the characteristics of IP spoofing and the temporal correlation of transport layer connection state, an extensible set of rules and a reliable MapReduce based checking mechanism for abnormal packets are designed, (3) using statistic features extracted from the increased abnormal packets and TCP/UDP flow, a non-parameter CUSUM algorithm is used to detect most DDoS attacks accurately and efficiently. The model can detect the attack behavior in the early stage, which is beneficial to mitigate attack with the help of flow cleaning by converting a check rule to the filtering rule. Experiments show no matter how large the attack scale and what kind of DDoS attack, the detection model can soon detect DDoS attack accurately.},
  doi       = {10.1109/TrustCom.2016.0302},
  groups    = {First Filtering},
  issn      = {2324-9013},
  keywords  = {Computer crime;Cloud computing;IP networks;Computational modeling;Feature extraction;Correlation;Algorithm design and analysis;DDoS;Hadoop;MapReduce;HBASE;Cloud;CUSUM},
}

@InProceedings{8698539,
  author    = {Bontrager, Philip and Roy, Aditi and Togelius, Julian and Memon, Nasir and Ross, Arun},
  booktitle = {2018 IEEE 9th International Conference on Biometrics Theory, Applications and Systems (BTAS)},
  title     = {DeepMasterPrints: Generating MasterPrints for Dictionary Attacks via Latent Variable Evolution*},
  year      = {2018},
  month     = {Oct},
  pages     = {1-9},
  abstract  = {Recent research has demonstrated the vulnerability of fingerprint recognition systems to dictionary attacks based on MasterPrints. MasterPrints are real or synthetic fingerprints that can fortuitously match with a large number of fingerprints thereby undermining the security afforded by fingerprint systems. Previous work by Roy et al. generated synthetic MasterPrints at the feature-level. In this work we generate complete image-level MasterPrints known as DeepMasterPrints, whose attack accuracy is found to be much superior than that of previous methods. The proposed method, referred to as Latent Variable Evolution, is based on training a Generative Adversarial Network on a set of real fingerprint images. Stochastic search in the form of the Covariance Matrix Adaptation Evolution Strategy is then used to search for latent input variables to the generator network that can maximize the number of impostor matches as assessed by a fingerprint recognizer. Experiments convey the efficacy of the proposed method in generating DeepMasterPrints. The underlying method is likely to have broad applications in fingerprint security as well as fingerprint synthesis.},
  doi       = {10.1109/BTAS.2018.8698539},
  groups    = {First Filtering},
  issn      = {2474-9699},
  keywords  = {Neural networks;Generators;Training;Gallium nitride;Generative adversarial networks;Covariance matrices;Optimization},
}

@Article{9236652,
  author   = {Upadhyay, Darshana and Manero, Jaume and Zaman, Marzia and Sampalli, Srinivas},
  journal  = {IEEE Transactions on Network and Service Management},
  title    = {Gradient Boosting Feature Selection With Machine Learning Classifiers for Intrusion Detection on Power Grids},
  year     = {2021},
  issn     = {1932-4537},
  month    = {March},
  number   = {1},
  pages    = {1104-1116},
  volume   = {18},
  abstract = {Smart grids rely on SCADA (Supervisory Control and Data Acquisition) systems to monitor and control complex electrical networks in order to provide reliable energy to homes and industries. However, the increased inter-connectivity and remote accessibility of SCADA systems expose them to cyber attacks. As a consequence, developing effective security mechanisms is a priority in order to protect the network from internal and external attacks. We propose an integrated framework for an Intrusion Detection System (IDS) for smart grids which combines feature engineering-based preprocessing with machine learning classifiers. Whilst most of the machine learning techniques fine-tune the hyper-parameters to improve the detection rate, our approach focuses on selecting the most promising features of the dataset using Gradient Boosting Feature Selection (GBFS) before applying the classification algorithm, a combination which improves not only the detection rate but also the execution speed. GBFS uses the Weighted Feature Importance (WFI) extraction technique to reduce the complexity of classifiers. We implement and evaluate various decision-tree based machine learning techniques after obtaining the most promising features of the power grid dataset through a GBFS module, and show that this approach optimizes the False Positive Rate (FPR) and the execution time.},
  doi      = {10.1109/TNSM.2020.3032618},
  groups   = {First Filtering},
  keywords = {Power grids;Feature extraction;Boosting;Intrusion detection;Cyberattack;SCADA systems;power grids;random forest;gradient boosting;feature selection;cyber security;network intrusions},
}

@InProceedings{9139718,
  author    = {Liu, Weilun and Ge, Mengmeng and Kim, Dong Seong},
  booktitle = {2020 20th IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing (CCGRID)},
  title     = {Integrated Proactive Defense for Software Defined Internet of Things under Multi-Target Attacks},
  year      = {2020},
  month     = {May},
  pages     = {767-774},
  abstract  = {Due to the constrained resource and computational limitation of many Internet of Things (IoT) devices, conventional security protections, which require high computational overhead are not suitable to be deployed. Thus, vulnerable IoT devices could be easily exploited by attackers to break into networks. In this paper, we employ cyber deception and moving target defense (MTD) techniques to proactively change the network topology with both real and decoy nodes with the support of software-defined networking (SDN) technology and investigate the impact of single-target and multi-target attacks on the effectiveness of the integrated mechanism via a hierarchical graphical security model with security metrics. We also implement a web-based visualization interface to show topology changes with highlighted attack paths. Finally, the qualitative security analysis is performed for a small-scale and SDN-supported IoT network with different combinations of decoy types and levels of attack intelligence. Simulation results show the integrated defense mechanism can introduce longer mean-time-to-security-failure and larger attack impact under the multi-target attack, compared with the single-target attack model. In addition, adaptive shuffling has better performance than fixed interval shuffling in terms of a higher proportion of decoy paths, longer mean-time-to-security-failure and largely reduced defense cost.},
  doi       = {10.1109/CCGrid49817.2020.00-12},
  groups    = {First Filtering},
  keywords  = {Security;Measurement;Network topology;Control systems;Servers;Internet of Things;Visualization;Moving Target Defense;Cyber Deception;Internet of Things;Graphical Security Model},
}

@InProceedings{8944462,
  author    = {Nisha, D and Sivaraman, E and Honnavalli, Prasad B},
  booktitle = {2019 10th International Conference on Computing, Communication and Networking Technologies (ICCCNT)},
  title     = {Predicting and Preventing Malware in Machine Learning Model},
  year      = {2019},
  month     = {July},
  pages     = {1-7},
  abstract  = {Machine learning is a major area in artificial intelligence, which enables computer to learn itself explicitly without programming. As machine learning is widely used in making decision automatically, attackers have strong intention to manipulate the prediction generated my machine learning model. In this paper we study about the different types of attacks and its countermeasures on machine learning model. By research we found that there are many security threats in various algorithms such as K-nearest-neighbors (KNN) classifier, random forest, AdaBoost, support vector machine (SVM), decision tree, we revisit existing security threads and check what are the possible countermeasures during the training and prediction phase of machine learning model. In machine learning model there are 2 types of attacks that is causative attack which occurs during the training phase and exploratory attack which occurs during the prediction phase, we will also discuss about the countermeasures on machine learning model, the countermeasures are data sanitization, algorithm robustness enhancement, and privacy preserving techniques.},
  doi       = {10.1109/ICCCNT45670.2019.8944462},
  groups    = {First Filtering},
  keywords  = {Machine learning;Predictive models;Data models;Training;Machine learning algorithms;Security;Classification algorithms;Causative attack;exploratory attack;Data sanitization;Algorithm robustness enhancement;Privacy preserving technique},
}

@Article{8278156,
  author   = {Liu, Jianqing and Zhang, Chi and Fang, Yuguang},
  journal  = {IEEE Internet of Things Journal},
  title    = {EPIC: A Differential Privacy Framework to Defend Smart Homes Against Internet Traffic Analysis},
  year     = {2018},
  issn     = {2327-4662},
  month    = {April},
  number   = {2},
  pages    = {1206-1217},
  volume   = {5},
  abstract = {The Internet of Things (IoT) becomes a novel paradigm as more and more devices are connected to the Internet, enabling several innovative applications such as smart home, industrial automation, and connected health. However, the cyber-attack to these applications is a big issue and countermeasures are in dire need to provide system security and user privacy. In this paper, we address the traffic analysis attack to smart homes, where adversaries intercept the Internet traffic from/to the smart home gateway and profile residents' behaviors through digital traces. Traditional cryptographic tools may not work well due to the effectiveness of adversaries' machine learning algorithms in classifying encrypted traffic, so here we propose a privacy-preserving traffic obfuscation framework to achieve the goal. To be specific, we leverage the smart community network of wirelessly connected smart homes and intentionally direct each smart home's traffic to another home gateway before entering the Internet. The design jointly considers the network energy consumption and the resource constraints in IoT devices, while achieving strong differential privacy guarantee so that adversaries cannot link any traffic flow to a specific smart home. Besides, we consider a hostile smart community network and develop secure multihop routing protocols to guarantee the source/destination unlinkability and satisfy each user's personalized privacy requirement. To evaluate the effectiveness of our framework in protecting privacy and reducing network energy consumption, extensive simulations are conducted and the results demonstrate that our design outperforms other differential privacy mechanism in preserving privacy and minimizing network utility cost.},
  doi      = {10.1109/JIOT.2018.2799820},
  groups   = {First Filtering},
  keywords = {Smart homes;Logic gates;Privacy;Cryptography;Smart cities;Routing;Bayesian inference;differential privacy;energy efficiency;Internet of Things (IoT);secure routing;traffic analysis attack},
}

@Article{7069114,
  author   = {Villalba, L.J.G. and Orozco, A.L.S. and Vidal, J.M.},
  journal  = {IEEE Latin America Transactions},
  title    = {Malware Detection System by Payload Analysis of Network Traffic},
  year     = {2015},
  issn     = {1548-0992},
  month    = {March},
  number   = {3},
  pages    = {850-855},
  volume   = {13},
  abstract = {This paper presents a system for detecting intrusions when analyzing the network traffic payload looking for malware evidences. The system implements the detection algorithm as a Snort preprocessor component. Since they work together, a highly effective system against known attacks has been achieved (based on Snort rules) and a highly effective system against unknown threats (which was the main aim of the designed system). As the majority of such systems, the proposal consists of two phases: a training phase and a detection phase. During the training phase a statistical model of the legitimate network usage is created through Bloom Filters and N-grams techniques. Subsequently, the results obtained by analyzing a dataset of attacks are compared with such model. This will allow a set of rules to be developed which will be able to determine whether the packets payloads contain malware. In the detection phase, the traffic to analyze is compared with the model created in the training phase and the results obtained when applying rules. The performed experiments showed really satisfactory results, with 100% malware detection and just 0.15% false positives.},
  doi      = {10.1109/TLA.2015.7069114},
  groups   = {First Filtering},
  keywords = {Malware;Intrusion detection;Payloads;Detectors;Silicon compounds;Computer science;Training;Anomaly;Bloom Filter;IDS;Intrusion Detection System;Malware;N-Gram;Network Intrusion Detection System;NIDS;Payload;Preprocessor;Snort},
}

@InProceedings{9045745,
  author    = {HE, Wenjian and Zhang, Wei and Sinha, Sharad and Das, Sanjeev},
  booktitle = {2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC)},
  title     = {iGPU Leak: An Information Leakage Vulnerability on Intel Integrated GPU},
  year      = {2020},
  month     = {Jan},
  pages     = {56-61},
  abstract  = {Hardware accelerators such as integrated graphics processing units (iGPUs) are increasingly prevalent in modern systems. They typically provide multiplexing support where several user applications can share the iGPU acceleration resources. However, security in this setting has not received sufficient consideration. In this work, we disclose a critical information leakage vulnerability due to defective GPU context management. In essence, residual register values and shared local memory in the iGPU are not cleared during a context switch. As a result, adversaries can recover the secret key of a cryptographic algorithm running on an iGPU from a single snapshot of the leaking channel. User privacy is also under threat due to browser activity eavesdropping through website-fingerprinting attack with high accuracy and resolution. Moreover, this vulnerability can constitute a covert channel with a bandwidth of up to 8 Gbps.},
  doi       = {10.1109/ASP-DAC47756.2020.9045745},
  groups    = {First Filtering},
  issn      = {2153-697X},
  keywords  = {Multiplexing;Design automation;Graphics processing units;Switches;Hardware;Registers;Eavesdropping},
}

@InProceedings{6786081,
  author    = {Beaver, Justin M. and Borges-Hink, Raymond C. and Buckner, Mark A.},
  booktitle = {2013 12th International Conference on Machine Learning and Applications},
  title     = {An Evaluation of Machine Learning Methods to Detect Malicious SCADA Communications},
  year      = {2013},
  month     = {Dec},
  pages     = {54-59},
  volume    = {2},
  abstract  = {Critical infrastructure Supervisory Control and Data Acquisition (SCADA) systems have been designed to operate on closed, proprietary networks where a malicious insider posed the greatest threat potential. The centralization of control and the movement towards open systems and standards has improved the efficiency of industrial control, but has also exposed legacy SCADA systems to security threats that they were not designed to mitigate. This work explores the viability of machine learning methods in detecting the new threat scenarios of command and data injection. Similar to network intrusion detection systems in the cyber security domain, the command and control communications in a critical infrastructure setting are monitored, and vetted against examples of benign and malicious command traffic, in order to identify potential attack events. Multiple learning methods are evaluated using a dataset of Remote Terminal Unit communications, which included both normal operations and instances of command and data injection attack scenarios.},
  doi       = {10.1109/ICMLA.2013.105},
  groups    = {First Filtering},
  keywords  = {Pipelines;Learning systems;Telemetry;Intrusion detection;SCADA systems;Machine learning algorithms;SCADA;machine learning;intrusion detection;critical infrastructure protection;network},
}

@Article{9453841,
  author   = {Weizman, Yoav and Giterman, Robert and Chertkow, Oron and Wicentowski, Maoz and Levi, Itamar and Sever, Ilan and Kehati, Ishai and Keren, Osnat and Fish, Alexander},
  journal  = {IEEE Access},
  title    = {Low-Cost Side-Channel Secure Standard 6T-SRAM-Based Memory With a 1% Area and Less Than 5% Latency and Power Overheads},
  year     = {2021},
  issn     = {2169-3536},
  pages    = {91764-91776},
  volume   = {9},
  abstract = {Side-channel attacks constitute a concrete threat to IoT systems-on-a-chip (SoCs). Embedded memories implemented with 6T SRAM macrocells often dominate the area and power consumption of these SoCs. Regardless of the computational platform, the side-channel sensitivity of low-hierarchy cache memories can incur significant overhead to protect the memory content (i.e., data encryption, data masking, etc.). In this manuscript, we provide a silicon proof of the effectiveness of a low cost side-channel attack protection that is embedded within the memory macro to achieve a significant reduction in information leakage. The proposed solution incorporates low-cost impedance randomization units, which are integrated into the periphery of a conventional 6T SRAM macro in fine-grain memory partitions, providing possible protection against electromagnetic adversaries. Various blocks of unprotected and protected SRAM macros were designed and fabricated in a 55 nm test-chip. The protected ones had little as 1% area overhead and less than 5% performance and power penalties compared to a conventional SRAM design. To evaluate the security of the proposed solution, we applied a robust mutual information metric and an adaptation to the memory context to enhance this evaluation framework. Assessment of the protected memory demonstrated a significant information leakage reduction from 8 bits of information exposed after only 100 cycles of attack to less than ~1.5 bits of mutual information after 160K traces. The parametric nature of the protection mechanisms are discussed while specifying the proposed design parameters. Overall, the proposed methodology enables designs with higher security-level at a minimal cost.},
  doi      = {10.1109/ACCESS.2021.3088991},
  groups   = {First Filtering},
  keywords = {Random access memory;Security;Memory management;Arrays;Correlation;Measurement;Microprocessors;Secured Static Random Access Memories (SRAM);hardware security;power analysis;secured memory},
}

@Article{8788512,
  author   = {Ali, Shan and Li, Yuancheng},
  journal  = {IEEE Access},
  title    = {Learning Multilevel Auto-Encoders for DDoS Attack Detection in Smart Grid Network},
  year     = {2019},
  issn     = {2169-3536},
  pages    = {108647-108659},
  volume   = {7},
  abstract = {Bidirectional communication infrastructure of smart systems, such as smart grids, are vulnerable to network attacks like distributed denial of services (DDoS) and can be a major concern in the present competitive market. In DDoS attack, multiple compromised nodes in a communication network flood connection requests, bogus data packets or incoming messages to targets like database servers, resulting in denial of services for legitimate users. Recently, machine learning based techniques have been explored by researchers to secure the network from DDoS attacks. Under different attack scenarios on a system, measurements can be observed either in an online manner or batch mode and can be used to build predictive learning systems. In this work, we propose an efficient DDoS attack detection technique based on multilevel auto-encoder based feature learning. We learn multiple levels of shallow and deep auto-encoders in an unsupervised manner which are then used to encode the training and test data for feature generation. A final unified detection model is then learned by combining the multilevel features using and efficient multiple kernel learning (MKL) algorithm. We perform experiments on two benchmark DDoS attack databases and their subsets and compare the results with six recent methods. Results show that the proposed method outperforms the compared methods in terms of prediction accuracy.},
  doi      = {10.1109/ACCESS.2019.2933304},
  groups   = {First Filtering},
  keywords = {Smart grids;Hidden Markov models;Support vector machines;Cyberattack;Feature extraction;Kernel;Auto-encoder;cyber security;DDoS attack detection;multiple kernel learning;smart grid},
}

@InProceedings{7831716,
  author    = {Ahmad, Muhammad Aminu and Woodhead, Steve and Gan, Diane},
  booktitle = {2016 International Conference on Advanced Communication Control and Computing Technologies (ICACCCT)},
  title     = {The V-network testbed for malware analysis},
  year      = {2016},
  month     = {May},
  pages     = {629-635},
  abstract  = {This paper presents a virtualised network environment that serves as a stable and re-usable platform for the analysis of malware propagation. The platform, which has been developed using VMware virtualisation technology, enables the use of either a graphical user interface or scripts to create virtual networks, clone, restart and take snapshots of virtual machines, reset experiments, clean virtual machines and manage the entire infrastructure remotely. The virtualised environment uses open source routing software to support the deployment of intrusion detection systems and other malware attack sensors, and is therefore suitable for evaluating countermeasure systems before deployment on live networks. An empirical analysis of network worm propagation has been conducted using worm outbreak experiments on Class A size networks to demonstrate the capability of the developed platform.},
  doi       = {10.1109/ICACCCT.2016.7831716},
  groups    = {First Filtering},
  keywords  = {Servers;Grippers;Virtual machining;Emulation;Routing;Operating systems;Ports (Computers);testbed;malware analysis;virtualisation},
}

@InProceedings{6703695,
  author    = {Qiu, Hongyuan and Osorio, Fernando C. Colón},
  booktitle = {2013 8th International Conference on Malicious and Unwanted Software: "The Americas" (MALWARE)},
  title     = {Static malware detection with Segmented Sandboxing},
  year      = {2013},
  month     = {Oct},
  pages     = {132-141},
  abstract  = {Traditionally, dynamic detection approaches to Malware identification are commended for their simplicity and small sized signature database. In practice they suffer from two major defects. First, Malware might need to be emulated for a long time before traces of harmful behavior are first exhibited. Second, a few Anti-VM techniques are widely known and can be easily employed by any program to thwart the attempt of having it executed in a sandbox and observe its original behavior, rendering the approach less than effective. On the other hand, static detection approaches, have their own limitations, ranging from parsing obfuscated executables to the scalability issues due to the ever-increasing size of the signature database. Fundamentally, in the last 10-15 years polymorphic and metamorphic obfuscation techniques have become prevalent making static approaches less than effective due to the sheer magnitude of the sample set1. While the benefits of either dynamic or static approaches look quite tempting from each of their counterparts perspectives, their weakness are daunting in their own sight as well. In this manuscript we attempted to combine the best part of both worlds, without bringing in the disadvantage of either of them. We call this mixed approach “Segmented Sandboxing”.},
  doi       = {10.1109/MALWARE.2013.6703695},
  groups    = {First Filtering},
  keywords  = {Malware;Semantics;Software;Databases;Engines;Complexity theory},
}

@Article{9189773,
  author   = {Anand, Pooja and Singh, Yashwant and Selwal, Arvind and Alazab, Mamoun and Tanwar, Sudeep and Kumar, Neeraj},
  journal  = {IEEE Access},
  title    = {IoT Vulnerability Assessment for Sustainable Computing: Threats, Current Solutions, and Open Challenges},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {168825-168853},
  volume   = {8},
  abstract = {Over the last few decades, sustainable computing has been widely used in areas like social computing, artificial intelligence-based agent systems, mobile computing, and Internet of Things (IoT). There are social, economic, and commercial impacts of IoT on human lives. However, IoT nodes are generally power-constrained with data transmission using an open channel, i.e., Internet which opens the gates for various types of attacks on them. In this context, several efforts are initiated to deal with the evolving security issues in IoT systems and make them self-sufficient to harvest energy for smooth functioning. Motivated by these facts, in this paper, we explore the evolving vulnerabilities in IoT devices. We provide a state-of-the-art survey that addresses multiple dimensions of the IoT realm. Moreover, we provide a general overview of IoT, Sustainable IoT, its architecture, and the Internet Engineering Task Force (IETF) protocol suite. Subsequently, we explore the open-source tools and datasets for the proliferation in research and growth of IoT. A detailed taxonomy of attacks associated with various vulnerabilities is also presented in the text. Then we have specifically focused on the IoT Vulnerability Assessment techniques followed by a case study on sustainability of Smart Agriculture. Finally, this paper outlines the emerging challenges related to IoT and its sustainability, and opening the doors for the beginners to start research in this promising area.},
  doi      = {10.1109/ACCESS.2020.3022842},
  groups   = {First Filtering},
  keywords = {Security;Protocols;Internet of Things;Computer architecture;Temperature sensors;IoT;machine learning;sustainability;cyberattacks;vulnerabilities;security;privacy},
}

@InProceedings{9024779,
  author    = {Haider, Mohmmad Haseeb and Saleem, Saad Bin and Rafaqat, Johnson and Sabahat, Nosheen},
  booktitle = {2019 13th International Conference on Mathematics, Actuarial Science, Computer Science and Statistics (MACS)},
  title     = {Threat Modeling of Wireless Attacks on Advanced Metering Infrastructure},
  year      = {2019},
  month     = {Dec},
  pages     = {1-6},
  abstract  = {Cyber physical systems are playing an essential role to increase the efficiency of integrated computational and physical elements. Especially, Advanced Metering Infrastructure proves to be useful for customers and consumer companies for efficient usage of energy and its cost calculations. However, such systems are more prone to cyber-attacks because of frequent real time communication between the providers and customers. The wireless and wired networks are used as the source of communication between the various components of AMI. In this study, we have done threat modelling to identify possible wireless attacks to compromise the AMI assets. We have used STRIDE and DREAD models for threat modelling. One of the major contributions of this study is classification and risk ratings of wireless attacks using STRIDE and DREAD models.},
  doi       = {10.1109/MACS48846.2019.9024779},
  groups    = {First Filtering},
  keywords  = {Computer crime;Wireless communication;Smart meters;Meters;Communication system security;Phasor measurement units;AMI;STRIDE and DREAD modelling;Wireless attacks;Smart meters},
}

@Article{9089860,
  author   = {Li, Zhuorong and Feng, Chao and Zheng, Jianwei and Wu, Minghui and Yu, Hongchuan},
  journal  = {IEEE Access},
  title    = {Towards Adversarial Robustness via Feature Matching},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {88594-88603},
  volume   = {8},
  abstract = {Image classification systems are known to be vulnerable to adversarial attacks, which are imperceptibly perturbed but lead to spectacularly disgraceful classification. Adversarial training is one of the most effective defenses for improving the robustness of classifiers. We introduce an enhanced adversarial training approach in this work. Motivated by human's consistently accurate perception of surroundings, we explore the artificial attention of deep neural networks in the context of adversarial classification. We begin with an empirical analysis of how the attention of artificial systems will change as the model undergoes adversarial attacks. Observation is that the class-specific attention gets diverted and subsequently induces wrong prediction. To that end, we propose a regularizer encouraging the consistency in the artificial attention on the clean image and its adversarial counterpart. Our method shows improved empirical robustness over the state-of-the-art, secures 55.74% adversarial accuracy on CIFAR-10 with perturbation budget of 8/255 under the challenging untargeted attack in white-box settings. Further evaluations on CIFAR-100 also show our potential for a desirable boost in adversarial robustness for deep neural networks. Code and trained models of our work are available at: https://github.com/lizhuorong/Towards-Adversarial-Robustness-via-Feature-matching.},
  doi      = {10.1109/ACCESS.2020.2993304},
  groups   = {First Filtering},
  keywords = {Robustness;Training;Perturbation methods;Biological neural networks;Task analysis;Network architecture;Bio-inspired explanations;deep learning;defense;adversarial attack;learning representations},
}

@InProceedings{8450487,
  author    = {Ashrafuzzaman, Mohammad and Chakhchoukh, Yacine and Jillepalli, Ananth A. and Tosic, Predrag T. and de Leon, Daniel Conte and Sheldon, Frederick T. and Johnson, Brian K.},
  booktitle = {2018 14th International Wireless Communications Mobile Computing Conference (IWCMC)},
  title     = {Detecting Stealthy False Data Injection Attacks in Power Grids Using Deep Learning},
  year      = {2018},
  month     = {June},
  pages     = {219-225},
  abstract  = {The electric power grid, as a critical national infrastructure, is under constant threat from cyber-attacks. State estimation (SE) is at the foundation of a series of critical control processes in a power transmission system. A false data injection (FDI) attack against SE can disrupt these control processes, crippling a power system and wreaking havoc in a region. With knowledge of the system topology, a cyber-attacker can formulate and execute stealthy FDI attacks that are very difficult to detect. Statistical and, more recently, machine learning approaches have been undertaken to detect FDI attacks on SE of the power grid. In this paper, we propose a Deep Learning (DL) based method to accurately detect stealthy FDI attacks on the SE of power grid. We compare the performance of the DL method with three popular machine learning algorithms, which are: gradient boosting machines (GBM), generalized linear modelings (GLM) and distributed random forests (DRF). All four algorithms analyze a dataset simulating the IEEE 14-bus system. The results demonstrate that these algorithms perform well in accurately and precisely detecting stealthy FDI attacks on the smart grid, with the DL-based approach showing best results.},
  doi       = {10.1109/IWCMC.2018.8450487},
  groups    = {First Filtering},
  issn      = {2376-6506},
  keywords  = {Pollution measurement;Machine learning;State estimation;Data models;Smart grids;False data injection attack;power grid;state estimation;machine learning;deep learning},
}

@InProceedings{9157415,
  author    = {Wang, Hongjun and Wang, Guangrun and Li, Ya and Zhang, Dongyu and Lin, Liang},
  booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Transferable, Controllable, and Inconspicuous Adversarial Attacks on Person Re-identification With Deep Mis-Ranking},
  year      = {2020},
  month     = {June},
  pages     = {339-348},
  abstract  = {The success of DNNs has driven the extensive applications of person re-identification (ReID) into a new era. However, whether ReID inherits the vulnerability of DNNs remains unexplored. To examine the robustness of ReID systems is rather important because the insecurity of ReID systems may cause severe losses, e.g., the criminals may use the adversarial perturbations to cheat the CCTV systems. In this work, we examine the insecurity of current best-performing ReID models by proposing a learning-to-mis-rank formulation to perturb the ranking of the system output. As the cross-dataset transferability is crucial in the ReID domain, we also perform a back-box attack by developing a novel multi-stage network architecture that pyramids the features of different levels to extract general and transferable features for the adversarial perturbations. Our method can control the number of malicious pixels by using differentiable multi-shot sampling. To guarantee the inconspicuousness of the attack, we also propose a new perception loss to achieve better visual quality. Extensive experiments on four of the largest ReID benchmarks (i.e., Market1501, CUHK03, DukeMTMC, and MSMT17) not only show the effectiveness of our method, but also provides directions of the future improvement in the robustness of ReID systems. For example, the accuracy of one of the best-performing ReID systems drops sharply from 91.8% to 1.4% after being attacked by our method. Some attack results are shown in Fig. 1. The code is available at: https://github.com/whj363636/Adversarial-attack-on-Person-ReID-With-Deep-Mis-Ranking.},
  doi       = {10.1109/CVPR42600.2020.00042},
  groups    = {First Filtering},
  issn      = {2575-7075},
  keywords  = {Feature extraction;Task analysis;Robustness;Visualization;Perturbation methods;Training;Measurement},
}

@Article{9031416,
  author   = {Pei, Chao and Xiao, Yang and Liang, Wei and Han, Xiaojia},
  journal  = {IEEE Transactions on Industry Applications},
  title    = {PMU Placement Protection Against Coordinated False Data Injection Attacks in Smart Grid},
  year     = {2020},
  issn     = {1939-9367},
  month    = {July},
  number   = {4},
  pages    = {4381-4393},
  volume   = {56},
  abstract = {To maintain stable and reliable operations in smart grid, accurate state estimation is of paramount importance. However, synthesized false data injection attacks could wisely circumvent conventional bad data detection mechanisms by introducing arbitrary errors to state estimates to seriously affect the entire power system operation. To defend these attacks, phase measurement units (PMUs) are deployed in advance at various locations to reduce the chance of being attacked. However, when the budget of placement is not large enough so that the whole system cannot be covered by PMUs, the existing PMU placement algorithms based on greedy strategies are insufficient in some weak locations due to the nature of greedy strategies. In this article, we propose a new hybrid attack, which can be easily used by attackers to attack the buses with less connectivity and impose adverse impacts to state estimation with a low-attack cost so that existing defenses based on greedy strategies become invalid. We future propose a predeployment PMU greedy algorithm for this new attack in which the most vulnerable buses are first protected and, then, a greedy-based algorithm is used to deploy other PMUs until the whole system is observable. Experimental results on various IEEE standard systems demonstrate the effectiveness of our schemes.},
  doi      = {10.1109/TIA.2020.2979793},
  groups   = {First Filtering},
  keywords = {Phasor measurement units;Phase measurement;Voltage measurement;Time measurement;Smart grids;Power measurement;Q measurement;Cyber security;cyber-physical system;false data injection;phase measurement units (PMUs);state estimation;smart grid},
}

@InProceedings{6614288,
  author    = {Fayyad, Seraj and Meinel, Christoph},
  booktitle = {2013 10th International Conference on Information Technology: New Generations},
  title     = {Attack Scenario Prediction Methodology},
  year      = {2013},
  month     = {April},
  pages     = {53-59},
  abstract  = {Intrusion detection system generates significant data about malicious activities run against network. Generated data by IDS are stored in IDS database. This data represent attacks scenarios history against network. Main goal of IDS system is to enhance network defense technologies. Other techniques are also used to enhance the defense of network such as Attack graph. Network attack graph are used for many goals such as attacker next attack step prediction. In this paper we propose a real time prediction methodology for predicting most possible attack steps and attack scenarios. Proposed methodology benefits from attacks history against network and from attack graph source data. it comes without considerable computation overload such as checking of attack plans library. It provides parallel prediction for parallel attack scenarios.},
  doi       = {10.1109/ITNG.2013.16},
  groups    = {First Filtering},
  keywords  = {Object oriented modeling;Predictive models;Databases;Data models;Real-time systems;Correlation;Libraries;real time prediction;attack scenarios parallel prediction;attack graph;objects oriented prediction model;learning from IDS database;new prediction methodology},
}

@InProceedings{9221318,
  author    = {Kayode, Olumide and Tosun, Ali Saman},
  booktitle = {2020 IEEE 6th World Forum on Internet of Things (WF-IoT)},
  title     = {Deep Q-Network for Enhanced Data Privacy and Security of IoT Traffic},
  year      = {2020},
  month     = {June},
  pages     = {1-6},
  abstract  = {Data privacy and security of Internet enabled devices has become a major concern of many users and manufacturers. The proliferation of Internet of Things (IoT) devices and the increasing network traffic have heightened the attack surface. Proxy and man-in-the-middle attacks can be used to exploit vulnerability inherent in IoT devices. Due to the limited resources and features of IoT devices, transmitted data might be at risk of traffic interception and possible decryption of encrypted data on the fly using these attacks. In this paper, we discuss a vulnerability in IoT communication and propose an effective approach based on Deep Q-Network (DQN) and Generative Adversarial Network (GAN) for proxy detection. Our main aim is a robust detection mechanism using network connection information. We further propose a use case for distributed machine learning suitable for real-time monitoring and proxy detection.},
  doi       = {10.1109/WF-IoT48130.2020.9221318},
  groups    = {First Filtering},
  keywords  = {Internet of Things (IoT);Data Privacy;Security;Deep Reinforcement Learning;Distributed Machine Learning},
}

@InProceedings{8474693,
  author    = {Krishnan, S S Nagamuthu},
  booktitle = {2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA)},
  title     = {Defending Selective Forwarding Attacks in Underwater Acoustic Networks Applying Trust Model},
  year      = {2018},
  month     = {March},
  pages     = {1567-1571},
  abstract  = {Underwater Acoustic Networks (UAN) are formed by acoustically connected ocean-bottom sensors, autonomous vehicles that function underwater in tandem with a surface station to provide a link to an on-shore control center. Applications that deploy them require long-term monitoring of the deployment area. The safety and security of such networks should be guaranteed in the light of Denial of Service (DoS) attack a class of attack that commonly targets them. A specific kind of DoS attack termed as selective forwarding is considered and an improved solution to defend such attack is proposed and analyzed for its efficiency.},
  doi       = {10.1109/ICECA.2018.8474693},
  groups    = {First Filtering},
  keywords  = {Monitoring;Security;Conferences;Aerospace electronics;Data models;Underwater acoustics;Ocean temperature;Service denial;selective forwarding;trust model;alarm ratio;avoidance completion},
}

@Article{9270592,
  author   = {Khaw, Yew Meng and Abiri Jahromi, Amir and Arani, Mohammadreza F. M. and Sanner, Scott and Kundur, Deepa and Kassouf, Marthe},
  journal  = {IEEE Transactions on Smart Grid},
  title    = {A Deep Learning-Based Cyberattack Detection System for Transmission Protective Relays},
  year     = {2021},
  issn     = {1949-3061},
  month    = {May},
  number   = {3},
  pages    = {2554-2565},
  volume   = {12},
  abstract = {The digitalization of power systems over the past decade has made the cybersecurity of substations a top priority for regulatory agencies and utilities. Proprietary communication protocols are being increasingly replaced by standardized and interoperable protocols providing utility operators with remote access and control capabilities at the expense of growing cyberattack risks. In particular, the potential of supply chain cyberattacks is on the rise in industrial control systems. In this environment, there is a pressing need for the development of cyberattack detection systems for substations and in particular protective relays, a critical component of substation operation. This article presents a deep learning-based cyberattack detection system for transmission line protective relays. The proposed cyberattack detection system is first trained with current and voltage measurements representing various types of faults on the transmission lines. The cyberattack detection system is then employed to detect current and voltage measurements that are maliciously injected by an attacker to trigger the transmission line protective relays. The proposed cyberattack detection system is evaluated under a variety of cyberattack scenarios. The results demonstrate that a universal architecture can be designed for the deep learning-based cyberattack detection systems in substations.},
  doi      = {10.1109/TSG.2020.3040361},
  groups   = {First Filtering},
  keywords = {Cyberattack;Protective relaying;Substations;IEC Standards;Transmission line measurements;Power systems;Protocols;Cyberphysical systems;transmission protective relays;cyberattack detection systems;deep learning;operational technology},
}

@Article{8410366,
  author   = {Nisioti, Antonia and Mylonas, Alexios and Yoo, Paul D. and Katos, Vasilios},
  journal  = {IEEE Communications Surveys Tutorials},
  title    = {From Intrusion Detection to Attacker Attribution: A Comprehensive Survey of Unsupervised Methods},
  year     = {2018},
  issn     = {1553-877X},
  month    = {Fourthquarter},
  number   = {4},
  pages    = {3369-3388},
  volume   = {20},
  abstract = {Over the last five years there has been an increase in the frequency and diversity of network attacks. This holds true, as more and more organizations admit compromises on a daily basis. Many misuse and anomaly based intrusion detection systems (IDSs) that rely on either signatures, supervised or statistical methods have been proposed in the literature, but their trustworthiness is debatable. Moreover, as this paper uncovers, the current IDSs are based on obsolete attack classes that do not reflect the current attack trends. For these reasons, this paper provides a comprehensive overview of unsupervised and hybrid methods for intrusion detection, discussing their potential in the domain. We also present and highlight the importance of feature engineering techniques that have been proposed for intrusion detection. Furthermore, we discuss that current IDSs should evolve from simple detection to correlation and attribution. We descant how IDS data could be used to reconstruct and correlate attacks to identify attackers, with the use of advanced data analytics techniques. Finally, we argue how the present IDS attack classes can be extended to match the modern attacks and propose three new classes regarding the outgoing network communication.},
  doi      = {10.1109/COMST.2018.2854724},
  groups   = {First Filtering},
  keywords = {Intrusion detection;Feature extraction;Forensics;Computer crime;Telecommunication traffic;Monitoring;Anomaly IDS;correlation and attribution;attack reconstruction;digital forensics;network forensics;data analytics;unsupervised learning;feature selection},
}

@InProceedings{7129383,
  author    = {Shirani, Paria and Azgomi, Mohammad Abdollahi and Alrabaee, Saed},
  booktitle = {2015 IEEE 28th Canadian Conference on Electrical and Computer Engineering (CCECE)},
  title     = {A method for intrusion detection in web services based on time series},
  year      = {2015},
  month     = {May},
  pages     = {836-841},
  abstract  = {A prevalent issue in today's society that has attracted much attention is anomaly detection in time series. Service-oriented architecture (SOA) and web services are considered as one of the most important technologies. In this paper, we propose a model for intrusion detection in web services based on the autoregressive integrated moving average (ARIMA). First, we apply the ARIMA model to the training data. Second, we forecast their next behavior within a specific confidence interval. Third, we examine the testing data; if any instance falls out of the range of the confidence interval, it might be an anomaly, and the system will notify the administrator. We present experiments and results obtained using real world data.},
  doi       = {10.1109/CCECE.2015.7129383},
  groups    = {First Filtering},
  issn      = {0840-7789},
  keywords  = {Web services;Time series analysis;Intrusion detection;Predictive models;Data models;Mathematical model;XML},
}

@Article{6899663,
  author   = {Petit, Jonathan and Shladover, Steven E.},
  journal  = {IEEE Transactions on Intelligent Transportation Systems},
  title    = {Potential Cyberattacks on Automated Vehicles},
  year     = {2015},
  issn     = {1558-0016},
  month    = {April},
  number   = {2},
  pages    = {546-556},
  volume   = {16},
  abstract = {Vehicle automation has been one of the fundamental applications within the field of intelligent transportation systems (ITS) since the start of ITS research in the mid-1980s. For most of this time, it has been generally viewed as a futuristic concept that is not close to being ready for deployment. However, recent development of “self-driving” cars and the announcement by car manufacturers of their deployment by 2020 show that this is becoming a reality. The ITS industry has already been focusing much of its attention on the concepts of “connected vehicles” (United States) or “cooperative ITS” (Europe). These concepts are based on communication of data among vehicles (V2V) and/or between vehicles and the infrastructure (V2I/I2V) to provide the information needed to implement ITS applications. The separate threads of automated vehicles and cooperative ITS have not yet been thoroughly woven together, but this will be a necessary step in the near future because the cooperative exchange of data will provide vital inputs to improve the performance and safety of the automation systems. Thus, it is important to start thinking about the cybersecurity implications of cooperative automated vehicle systems. In this paper, we investigate the potential cyberattacks specific to automated vehicles, with their special needs and vulnerabilities. We analyze the threats on autonomous automated vehicles and cooperative automated vehicles. This analysis shows the need for considerably more redundancy than many have been expecting. We also raise awareness to generate discussion about these threats at this early stage in the development of vehicle automation systems.},
  doi      = {10.1109/TITS.2014.2342271},
  groups   = {First Filtering},
  keywords = {Vehicles;Automation;Computer crime;Vehicle dynamics;Safety;Privacy;Automated vehicle;autonomous vehicle;cooperative automated vehicle;cyberattacks;security;Automated vehicle;autonomous vehicle;cooperative automated vehicle;cyberattacks;security},
}

@InProceedings{8835247,
  author    = {Pal, Bijeeta and Daniel, Tal and Chatterjee, Rahul and Ristenpart, Thomas},
  booktitle = {2019 IEEE Symposium on Security and Privacy (SP)},
  title     = {Beyond Credential Stuffing: Password Similarity Models Using Neural Networks},
  year      = {2019},
  month     = {May},
  pages     = {417-434},
  abstract  = {Attackers increasingly use passwords leaked from one website to compromise associated accounts on other websites. Such targeted attacks work because users reuse, or pick similar, passwords for different websites. We recast one of the core technical challenges underlying targeted attacks as the task of modeling similarity of human-chosen passwords. We show how to learn good password similarity models using a compilation of 1.4 billion leaked email, password pairs. Using our trained models of password similarity, we exhibit the most damaging targeted attack to date. Simulations indicate that our attack compromises more than 16% of user accounts in less than a thousand guesses, should one of their other passwords be known to the attacker and despite the use of state-of-the art countermeasures. We show via a case study involving a large university authentication service that the attacks are also effective in practice. We go on to propose the first-ever defense against such targeted attacks, by way of personalized password strength meters (PPSMs). These are password strength meters that can warn users when they are picking passwords that are vulnerable to attacks, including targeted ones that take advantage of the user's previously compromised passwords. We design and build a PPSM that can be compressed to less than 3 MB, making it easy to deploy in order to accurately estimate the strength of a password against all known guessing attacks.},
  doi       = {10.1109/SP.2019.00056},
  groups    = {First Filtering},
  issn      = {2375-1207},
  keywords  = {Password;Meters;Task analysis;Adaptation models;Tools;Neural networks;Authentication;passwords;targeted-password-guessing;credential-tweaking;credential-stuffing;neural-network;word-embedding;password-model;password-strength-meter},
}

@Article{9380395,
  author   = {Seo, Wooseok and Pak, Wooguil},
  journal  = {IEEE Access},
  title    = {Real-Time Network Intrusion Prevention System Based on Hybrid Machine Learning},
  year     = {2021},
  issn     = {2169-3536},
  pages    = {46386-46397},
  volume   = {9},
  abstract = {Recent advancements in network technology and associated services have led to a rapid increase in the amount of data traffic. However, the detrimental effects caused by cyber-attacks have also significantly increased. Network attacks are evolving in various forms. Two primary approaches exist for addressing such threats: signature-based detection and anomaly detection. Although the aforementioned approaches can be effective, they also have certain drawbacks. Signature-based detection is vulnerable to variant attacks, while anomaly detection cannot be used for real-time data traffic. For resolving such issues, this paper proposes a two-level classifier that can simultaneously achieve high performance and real-time classification. It employs level 1 and 2 classifiers internally. The level 1 classifier initially performs real-time detection with moderate accuracy for incoming data traffic. If the data cannot be classified with high probability by the classifier, the classification is delayed until the traffic flow terminates. The level 2 classifier then collects the statistical features of the traffic flow for performing precise classification. Compared to existing techniques, the proposed two-level classification method can achieve superior performance in terms of accuracy and detection time.},
  doi      = {10.1109/ACCESS.2021.3066620},
  groups   = {First Filtering},
  keywords = {Machine learning algorithms;Real-time systems;Classification algorithms;Training;Machine learning;Feature extraction;Databases;Intrusion prevention system;intrusion detection system;machine learning;real-time;two-level classifier},
}

@InProceedings{7436291,
  author    = {Pal, Seemita and Sikdar, Biplab and Chow, Joe H.},
  booktitle = {2015 IEEE International Conference on Smart Grid Communications (SmartGridComm)},
  title     = {Detecting malicious manipulation of synchrophasor data},
  year      = {2015},
  month     = {Nov},
  pages     = {145-150},
  abstract  = {The electrical grid is one of the critical infrastructures of any country whose importance makes them an attractive target for malicious cyber attacks. This paper considers the particular case of data modification attacks in smart grids, where the data generated by Phasor Measurement Units (PMUs) is modified by the adversary in order to introduce errors in the monitoring and control applications that rely on PMU data. The proposed methodology is based on evaluating the equivalent impedance of a transmission line from buses at its either end. The deviations in the magnitude and angle of the equivalent impedances in the presence of a data modification attack are used to detect the attack. Extensive simulations using real PMU data are used to verify the accuracy of the proposed detection mechanism.},
  doi       = {10.1109/SmartGridComm.2015.7436291},
  groups    = {First Filtering},
  keywords  = {Phasor measurement units;Impedance;Power transmission lines;Transmission line measurements;Smart grids;Resistance;Cyber-security;smart grid;synchrophasor network},
}

@InProceedings{9294426,
  author    = {Pavlitskaya, Svetlana and Ünver, Sefa and Zöllner, J. Marius},
  booktitle = {2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)},
  title     = {Feasibility and Suppression of Adversarial Patch Attacks on End-to-End Vehicle Control},
  year      = {2020},
  month     = {Sep.},
  pages     = {1-8},
  abstract  = {In an end-to-end vehicle control scenario, where a deep neural network is trained on visual input solely, adversarial vulnerability leaves a possibility to manipulate the steering predictions. Patch-based adversarial attacks present an especially serious menace, because they can be performed in the real world by printing out a generated universal pattern. However, the boundary conditions and feasibility of such attacks to compromise the security of autonomous vehicles have been only sparsely studied so far.We demonstrate and evaluate such attacks in the CARLA simulative environment under different weather and lighting settings, while conducting experiments in open and closed loop attack scenarios. Our findings reveal that attack strength is highly dependent on the surrounding location as well as on environment conditions. We also observe that attack success in an open loop scenario only partially coincides with that in a closed loop scenario. This analysis helps to set the stage for future experiments on public roads.Furthermore, we propose a defense concept to remove malignant perturbations from an input image, which does not affect its salient regions. We analyze deviations from the unattacked vehicle trajectory both on adversarial and suppressed inputs.},
  doi       = {10.1109/ITSC45102.2020.9294426},
  groups    = {First Filtering},
  keywords  = {Perturbation methods;Autonomous vehicles;Visualization;Jacobian matrices;History;Task analysis;Roads},
}

@InProceedings{6179141,
  author    = {Kumar, Manish and Hanumanthappa, M. and Kumar, T. V. Suresh},
  booktitle = {2012 International Conference on Computing, Communication and Applications},
  title     = {Intrusion detection system for grid computing using SNORT},
  year      = {2012},
  month     = {Feb},
  pages     = {1-6},
  abstract  = {Because of distributed nature, grid computing environments are easy targets for intruders looking for possible vulnerabilities to exploit [1]. By impersonating legitimate users, the intruders can use a service's abundant resources maliciously. To combat attackers, intrusion-detection systems (IDSs) can offer additional security measures for these environments by investigating configurations, logs, network traffic, and user actions to identify typical attack behavior. However, IDS must be distributed to work in a grid computing environment. It must monitor each node and, when an attack occurs, alert other nodes in the environment. This kind of communication requires compatibility between heterogeneous hosts, various communication mechanisms, and permission control over system maintenance and updates. We present the problem of grid intrusion; analyze the requirements of a system to detect them. In this paper we are discussing how IDS can be implemented for grid computing environment.},
  doi       = {10.1109/ICCCA.2012.6179141},
  groups    = {First Filtering},
  issn      = {2325-601X},
  keywords  = {Intrusion detection;IP networks;Prototypes;Computers;Operating systems;IDS;Grid Computing;Snort},
}

@Article{7976343,
  author   = {Oksuz, Ilkay and Mukhopadhyay, Anirban and Dharmakumar, Rohan and Tsaftaris, Sotirios A.},
  journal  = {IEEE Transactions on Medical Imaging},
  title    = {Unsupervised Myocardial Segmentation for Cardiac BOLD},
  year     = {2017},
  issn     = {1558-254X},
  month    = {Nov},
  number   = {11},
  pages    = {2228-2238},
  volume   = {36},
  abstract = {A fully automated 2-D+time myocardial segmentation framework is proposed for cardiac magnetic resonance (CMR) blood-oxygen-level-dependent (BOLD) data sets. Ischemia detection with CINE BOLD CMR relies on spatio-temporal patterns in myocardial intensity, but these patterns also trouble supervised segmentation methods, the de facto standard for myocardial segmentation in cine MRI. Segmentation errors severely undermine the accurate extraction of these patterns. In this paper, we build a joint motion and appearance method that relies on dictionary learning to find a suitable subspace. Our method is based on variational pre-processing and spatial regularization using Markov random fields, to further improve performance. The superiority of the proposed segmentation technique is demonstrated on a data set containing cardiac phase-resolved BOLD MR and standard CINE MR image sequences acquired in baseline and ischemic condition across ten canine subjects. Our unsupervised approach outperforms even supervised state-of-the-art segmentation techniques by at least 10% when using Dice to measure accuracy on BOLD data and performs at par for standard CINE MR. Furthermore, a novel segmental analysis method attuned for BOLD time series is utilized to demonstrate the effectiveness of the proposed method in preserving key BOLD patterns.},
  doi      = {10.1109/TMI.2017.2726112},
  groups   = {First Filtering},
  keywords = {Myocardium;Image segmentation;Dictionaries;Magnetic resonance imaging;Motion segmentation;Standards;Manuals;Unsupervised segmentation;optical flow;dictionary learning;BOLD;CINE;cardiac MRI},
}

@InProceedings{7573322,
  author    = {Shirazi, Syed Noorulhassan and Gouglidis, Antonios and Syeda, Kanza Noor and Simpson, Steven and Mauthe, Andreas and Stephanakis, Ioannis M. and Hutchison, David},
  booktitle = {2016 Resilience Week (RWS)},
  title     = {Evaluation of Anomaly Detection techniques for SCADA communication resilience},
  year      = {2016},
  month     = {Aug},
  pages     = {140-145},
  abstract  = {Attacks on critical infrastructures' Supervisory Control and Data Acquisition (SCADA) systems are beginning to increase. They are often initiated by highly skilled attackers, who are capable of deploying sophisticated attacks to exfiltrate data or even to cause physical damage. In this paper, we rehearse the rationale for protecting against cyber attacks and evaluate a set of Anomaly Detection (AD) techniques in detecting attacks by analysing traffic captured in a SCADA network. For this purpose, we have implemented a tool chain with a reference implementation of various state-of-the-art AD techniques to detect attacks, which manifest themselves as anomalies. Specifically, in order to evaluate the AD techniques, we apply our tool chain on a dataset created from a gas pipeline SCADA system in Mississippi State University's lab, which include artefacts of both normal operations and cyber attack scenarios. Our evaluation elaborate on several performance metrics of the examined AD techniques such as precision; recall; accuracy; F-score and G-score. The results indicate that detection rate may change significantly when considering various attack types and different detections modes (i.e., supervised and unsupervised), and also provide indications that there is a need for a robust, and preferably real-time AD technique to introduce resilience in critical infrastructures.},
  doi       = {10.1109/RWEEK.2016.7573322},
  groups    = {First Filtering},
  keywords  = {Resilience;SCADA systems;Pipelines;Measurement;Principal component analysis;Detectors;Monitoring;Communication networks;critical infrastructure protection;resilience;anomaly detection;SCADA systems},
}

@Article{9006862,
  author   = {Li, Jiao and Liu, Yang and Chen, Tao and Xiao, Zhen and Li, Zhenjiang and Wang, Jianping},
  journal  = {IEEE Internet of Things Journal},
  title    = {Adversarial Attacks and Defenses on Cyber–Physical Systems: A Survey},
  year     = {2020},
  issn     = {2327-4662},
  month    = {June},
  number   = {6},
  pages    = {5103-5115},
  volume   = {7},
  abstract = {Cyber-security issues on adversarial attacks are actively studied in the field of computer vision with the camera as the main sensor source to obtain the input image or video data. However, in modern cyber-physical systems (CPSs), many other types of sensors are becoming popularly used, such as surveillance sensors, microphones, and textual interfaces. A series of recent works investigates the adversarial attacks and the potential defenses in these noncamera sensor-based CPSs. Therefore, this article provides a systematic discussion on these existing works and serves as a complimentary summary of the adversarial attacks and defenses for CPSs beyond the field of computer vision. We first introduce a general working flow for adversarial attacks on CPSs. On this basis, a clear taxonomy is provided to organize existing attacks effectively and indicate where the defenses can be potentially performed in CPSs as well. Then, we discuss these existing attacks and defenses with detailed comparison studies. Finally, we point out concrete research opportunities to be further explored along this research direction.},
  doi      = {10.1109/JIOT.2020.2975654},
  groups   = {First Filtering},
  keywords = {Robot sensing systems;Perturbation methods;Neural networks;Surveillance;Taxonomy;Detectors;Adversarial attacks and defense;cyber???physical systems (CPSs);cyber-security},
}

@InProceedings{8887328,
  author    = {Chai, Heyan and Yang, Shuqiang and Jiang, Zoe L. and Wang, Xuan},
  booktitle = {2019 18th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/13th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE)},
  title     = {A Robust and Reversible Watermarking Technique for Relational Dataset Based on Clustering},
  year      = {2019},
  month     = {Aug},
  pages     = {411-418},
  abstract  = {With rapid information development, data sharing becomes a crucial part in the Internet. In the process of sharing, data ownership protection and data traceability are two key issues that need to be solved urgently. To address these problem, digital watermarking technology can be a solution. Digital watermarking is used to guard the rights of owners of digital products. Many robust and reversible watermarking techniques are proposed recently to ensure the rights and recover original data set. But most methods require primary keys of the data as a required parameter, resulting in original data not recovered and partial data not traceable against data structure attack. In this paper, a cluster-based robust and reversible watermarking (RRWC) technique for relational data has been proposed that provides a solution to two major function: ownership rights protection and partial data traceability. The unsupervised classification algorithm is used to group dataset, where the primary key of the data will not be used and the watermarks can be embedded with low distortion and high capacity. RRWC addresses malicious attacks, such as subset insertion attack, deletion attack, alteration attack and data structure attack. Experimental results demonstrate the effectiveness and robustness of RRWC against attacks.},
  doi       = {10.1109/TrustCom/BigDataSE.2019.00062},
  groups    = {First Filtering},
  issn      = {2324-9013},
  keywords  = {Watermarking;Data structures;Data mining;Robustness;Clustering algorithms;Databases;Distortion;Reversible Watermarking;Digital Watermarking;Ownership Protection;Unsupervised Clustering},
}

@InProceedings{9149276,
  author    = {Shen, Yi and Wu, Chunming and Kong, Dezhang and Yang, Mingliang},
  booktitle = {ICC 2020 - 2020 IEEE International Conference on Communications (ICC)},
  title     = {TPDD: A Two-Phase DDoS Detection System in Software-Defined Networking},
  year      = {2020},
  month     = {June},
  pages     = {1-6},
  abstract  = {Distributed Denial of Service (DDoS) attack is one of the most severe threats to the current network security. As a new network architecture, Software-Defined Networking (SDN) draws notable attention from both industry and academia. The characteristics of SDN such as centralized management and flow-based traffic monitoring make it an ideal platform to defend against DDoS attacks. When designing a network intrusion detection system (NIDS) in SDN, how to obtain fine-grained flow information with minimal overhead to the SDN architecture is a problem to be solved. In this paper, we propose TPDD, a two-phase DDoS detection system to detect DDoS attacks in SDN. In the first phase, we utilize the characteristics of SDN to collect coarse-grained flow information from the core switches and locate the potential victim. Then we monitor the edge switches located close to the potential victim to obtain finer-grained traffic information in the second phase. The collection method of each phase fully considers the impact on the bandwidth between the controller and switches. Without modifying the existing flow rules, the collection module can obtain sufficient information about traffic. By using entropy-based and machine learning-based methods, the detection module can effectively detect anomalies and identify whether the potential victim marked in the first phase is the target of attacks. Experimental results show that TPDD can effectively detect DDoS attacks with little overhead.},
  doi       = {10.1109/ICC40277.2020.9149276},
  groups    = {First Filtering},
  issn      = {1938-1883},
  keywords  = {Computer crime;Monitoring;Control systems;Entropy;Image edge detection;IP networks;Feature extraction},
}

@InProceedings{9462227,
  author    = {Alrawashdeh, Khaled and Goldsmith, Stephen},
  booktitle = {2020 IEEE International Symposium on Technology and Society (ISTAS)},
  title     = {Defending Deep Learning Based Anomaly Detection Systems Against White-Box Adversarial Examples and Backdoor Attacks},
  year      = {2020},
  month     = {Nov},
  pages     = {294-301},
  abstract  = {Deep Neural Network (DNN) has witnessed rapid progress and significant successes in the recent years. Wide range of applications depends on the high performance of deep learning to solve real-life challenges. Deep learning is being applied in many safety-critical environments. However, deep neural networks have been recently found vulnerable to adversarial examples and backdoor attacks. Stealthy adversarial examples and backdoor attacks can easily fool deep neural networks to generate the wrong results. The risk of adversarial examples attacks that target deep learning models impedes the wide deployment of deep neural networks in safety-critical environments. In this work we propose a defensive technique for deep learning by combining activation function and neurons pruning to reduce the effects of adversarial examples and backdoor attacks. We evaluate the efficacy of the method on an anomaly detection application using Deep Belief Network (DBN) and Coupled Generative Adversarial Network (CoGAN). The method reduces the loss of accuracy from the attacks from an average 10% to 2% using DBN and from an average 14% to 2% using CoGAN. We evaluate the method using two benchmark datasets: NSL-KDD and ransomware.},
  doi       = {10.1109/ISTAS50296.2020.9462227},
  groups    = {First Filtering},
  issn      = {2158-3412},
  keywords  = {Deep learning;Neurons;Benchmark testing;Generative adversarial networks;Ransomware;Biological neural networks;Anomaly detection;Deep Learning;Neural Network;Intrusion Detection System;Adversarial Examples;GAN;Backdoor Attacks},
}

@InProceedings{8069085,
  author    = {Bohara, Atul and Noureddine, Mohammad A. and Fawaz, Ahmed and Sanders, William H.},
  booktitle = {2017 IEEE 36th Symposium on Reliable Distributed Systems (SRDS)},
  title     = {An Unsupervised Multi-Detector Approach for Identifying Malicious Lateral Movement},
  year      = {2017},
  month     = {Sep.},
  pages     = {224-233},
  abstract  = {Lateral movement-based attacks are increasingly leading to compromises in large private and government networks, often resulting in information exfiltration or service disruption. Such attacks are often slow and stealthy and usually evade existing security products. To enable effective detection of such attacks, we present a new approach based on graph-based modeling of the security state of the target system and correlation of diverse indicators of anomalous host behavior. We believe that irrespective of the specific attack vectors used, attackers typically establish a command and control channel to operate, and move in the target system to escalate their privileges and reach sensitive areas. Accordingly, we identify important features of command and control and lateral movement activities and extract them from internal and external communication traffic. Driven by the analysis of the features, we propose the use of multiple anomaly detection techniques to identify compromised hosts. These methods include Principal Component Analysis, k-means clustering, and Median Absolute Deviation-based outlier detection. We evaluate the accuracy of identifying compromised hosts by using injected attack traffic in a real enterprise network dataset, for various attack communication models. Our results show that the proposed approach can detect infected hosts with high accuracy and a low false positive rate.},
  doi       = {10.1109/SRDS.2017.31},
  groups    = {First Filtering},
  keywords  = {Monitoring;Feature extraction;Anomaly detection;Malware;Security;Servers;Command and control systems;advanced persistent threat;lateral movement;command and control;anomaly detection},
}

@InProceedings{7396919,
  author    = {Ring, Martin and Dürrwang, Jürgen and Sommer, Florian and Kriesten, Reiner},
  booktitle = {2015 IEEE International Conference on Vehicular Electronics and Safety (ICVES)},
  title     = {Survey on vehicular attacks - building a vulnerability database},
  year      = {2015},
  month     = {Nov},
  pages     = {208-212},
  abstract  = {Modern cars are significantly linked to the outside world because of rising number of connections in the vehicle, connections between the vehicle and the exterior environment , e.g. diagnostics and flash interfaces or the numerous amounts of bus systems for data exchange. All these connections are potential security breaches. Previous papers and this research work show that there are a lot of security vulnerabilities in modern car connections. The aim of this paper is to merge the found vulnerabilities and the available results in literature, categorise them in the same way as in Information Technology (IT) and give an outlook on how most problems can be solved. This paper also aims to introduce an example database for automotive IT vulnerabilities.},
  doi       = {10.1109/ICVES.2015.7396919},
  groups    = {First Filtering},
  keywords  = {Safety;Automotive engineering;Security;Ports (Computers);Standards;Automobiles;Wireless networks},
}

@Article{9352033,
  author   = {Wahab, Omar Abdel and Mourad, Azzam and Otrok, Hadi and Taleb, Tarik},
  journal  = {IEEE Communications Surveys Tutorials},
  title    = {Federated Machine Learning: Survey, Multi-Level Classification, Desirable Criteria and Future Directions in Communication and Networking Systems},
  year     = {2021},
  issn     = {1553-877X},
  month    = {Secondquarter},
  number   = {2},
  pages    = {1342-1397},
  volume   = {23},
  abstract = {The communication and networking field is hungry for machine learning decision-making solutions to replace the traditional model-driven approaches that proved to be not rich enough for seizing the ever-growing complexity and heterogeneity of the modern systems in the field. Traditional machine learning solutions assume the existence of (cloud-based) central entities that are in charge of processing the data. Nonetheless, the difficulty of accessing private data, together with the high cost of transmitting raw data to the central entity gave rise to a decentralized machine learning approach called Federated Learning. The main idea of federated learning is to perform an on-device collaborative training of a single machine learning model without having to share the raw training data with any third-party entity. Although few survey articles on federated learning already exist in the literature, the motivation of this survey stems from three essential observations. The first one is the lack of a fine-grained multi-level classification of the federated learning literature, where the existing surveys base their classification on only one criterion or aspect. The second observation is that the existing surveys focus only on some common challenges, but disregard other essential aspects such as reliable client selection, resource management and training service pricing. The third observation is the lack of explicit and straightforward directives for researchers to help them design future federated learning solutions that overcome the state-of-the-art research gaps. To address these points, we first provide a comprehensive tutorial on federated learning and its associated concepts, technologies and learning approaches. We then survey and highlight the applications and future directions of federated learning in the domain of communication and networking. Thereafter, we design a three-level classification scheme that first categorizes the federated learning literature based on the high-level challenge that they tackle. Then, we classify each high-level challenge into a set of specific low-level challenges to foster a better understanding of the topic. Finally, we provide, within each low-level challenge, a fine-grained classification based on the technique used to address this particular challenge. For each category of high-level challenges, we provide a set of desirable criteria and future research directions that are aimed to help the research community design innovative and efficient future solutions. To the best of our knowledge, our survey is the most comprehensive in terms of challenges and techniques it covers and the most fine-grained in terms of the multi-level classification scheme it presents.},
  doi      = {10.1109/COMST.2021.3058573},
  groups   = {First Filtering},
  keywords = {Collaborative work;Machine learning;Tutorials;Training;Servers;Data models;Cloud computing;Federated learning;federated learning tutorial;multi-level classification;statistical challenges;transfer learning;machine learning;security;communication and networking systems},
}

@Article{9105117,
  author   = {Yan, Liu and Xiong, Jay},
  journal  = {IEEE Letters of the Computer Society},
  title    = {Web-APT-Detect: A Framework For Web-Based Advanced Persistent Threat Detection Using Self-Translation Machine With Attention},
  year     = {2020},
  issn     = {2573-9689},
  month    = {July},
  number   = {2},
  pages    = {66-69},
  volume   = {3},
  abstract = {With more and more companies providing online services through the Internet, Web applications have been targeted by hackers. Although the existing signature-based Web Application Firewall (WAF) can well defend against known attack methods against Web applications, it is vulnerable to Web Advanced Persistent Threat (APT) using a large number of unknown Web attack methods to attack online services. In an effort to combat Web-based APT, we propose an unsupervised anomaly detection algorithm, Web-APT-Detect (WAD), which implements self-translation machine through an encoder-decoder using attention mechanism. Our attention mechanisms can improve the quality of self-translation machine used to detect malicious patterns in HTTP requests. Through experiments on the CSIC 2010 dataset, the F1-Score of our algorithm reaches 0.9844, which surpasses the known unsupervised algorithm and reaches the same level as the state-of-the-art supervised algorithm.},
  doi      = {10.1109/LOCS.2020.2998185},
  groups   = {First Filtering},
  keywords = {Vocabulary;Decoding;Training;Feature extraction;Anomaly detection;Task analysis;Kernel;Anomaly detection;web application attack;advanced persistent threat;self-translation machine},
}

@Article{9146823,
  author   = {Zhang, Jindi and Zhang, Yifan and Lu, Kejie and Wang, Jianping and Wu, Kui and Jia, Xiaohua and Liu, Bin},
  journal  = {IEEE Internet of Things Journal},
  title    = {Detecting and Identifying Optical Signal Attacks on Autonomous Driving Systems},
  year     = {2021},
  issn     = {2327-4662},
  month    = {Jan},
  number   = {2},
  pages    = {1140-1153},
  volume   = {8},
  abstract = {For autonomous driving, an essential task is to detect surrounding objects accurately. To this end, most existing systems use optical devices, including cameras and light detection and ranging (LiDAR) sensors, to collect environment data in real time. In recent years, many researchers have developed advanced machine learning models to detect surrounding objects. Nevertheless, the aforementioned optical devices are vulnerable to optical signal attacks, which could compromise the accuracy of object detection. To address this critical issue, we propose a framework to detect and identify sensors that are under attack. Specifically, we first develop a new technique to detect attacks on a system that consists of three sensors. Our main idea is to: 1) use data from three sensors to obtain two versions of depth maps (i.e., disparity) and 2) detect attacks by analyzing the distribution of disparity errors. In our study, we use real data sets and the state-of-the-art machine learning model to evaluate our attack detection scheme and the results confirm the effectiveness of our detection method. Based on the detection scheme, we further develop an identification model that is capable of identifying up to n-2 attacked sensors in a system with one LiDAR and n cameras. We prove the correctness of our identification scheme and conduct experiments to show the accuracy of our identification method. Finally, we investigate the overall sensitivity of our framework.},
  doi      = {10.1109/JIOT.2020.3011690},
  groups   = {First Filtering},
  keywords = {Optical sensors;Laser radar;Cameras;Three-dimensional displays;Optical pulses;Adaptive optics;Autonomous driving;deep learning;sensor attack detection;sensor attack identification},
}

@InProceedings{9293758,
  author    = {Lee, Tsern-Huei and Huang, Hsiao-Yen and Juang, Cheng},
  booktitle = {2020 IEEE REGION 10 CONFERENCE (TENCON)},
  title     = {A High-Performance Deep Learning Architecture for Host-based Intrusion Detection System},
  year      = {2020},
  month     = {Nov},
  pages     = {1198-1202},
  abstract  = {Host-based intrusion detection system (HIDS) is a necessary component for network security, especially when more and more data are encrypted which makes network-based intrusion detection system lose its functionality of packet content inspection. After many years of research, it is widely acknowledged that system calls are the preferred data source for HIDS. In a recent paper, a novel semantic analysis approach was proposed and shown to achieve the best performance, as compared with various previous syntactic analysis schemes. The performance difference is profound for modern attacks. However, the semantic analysis approach requires considerable computational complexity. In this paper, we present a deep learning architecture which requires no data pre-processing and is easy to train. Experimental results show that our design has a better performance than the semantic analysis approach.},
  doi       = {10.1109/TENCON50793.2020.9293758},
  groups    = {First Filtering},
  issn      = {2159-3450},
  keywords  = {Deep learning;Semantics;Training;Databases;Intrusion detection;Anomaly detection;Testing;Deep Learning;Behavior Anomaly;Autoencoder;HIDS},
}

@InProceedings{6059954,
  author    = {Nasr, Khalid and Abou El Kalam, Anas and Fraboul, Christian},
  booktitle = {2011 5th International Conference on Network and System Security},
  title     = {A holistic methodology for evaluating wireless Intrusion Detection Systems},
  year      = {2011},
  month     = {Sep.},
  pages     = {9-16},
  abstract  = {Nowadays, wireless network security has a considerable attention. However, wireless communication faces several security threats. Consequently, several security efforts have been exerted to combat the wireless attacks, but unfortunately complete attack prevention is not realistically attainable. Thus, the emphasis on detecting intrusions through a second line of defense, in the form of Intrusion Detection System (IDS), is increasing. Selecting an effective and appropriate IDS system should take its functionality and performance evaluation into account. Unbiased and reliable evaluation necessarily depends on a well-engineered evaluation methodology. Dealing with this challenge, this paper proposed a holistic methodology for IDSs evaluation in wireless networks. Our methodology includes all necessary and sufficient tasks for IDSs evaluation. Also, we present holistic taxonomies of wireless IDSs and wireless security attacks from the perspective of the IDS evaluator.},
  doi       = {10.1109/ICNSS.2011.6059954},
  groups    = {First Filtering},
  keywords  = {Communication system security;Taxonomy;Wireless networks;Ad hoc networks;Security;Monitoring;IDSs evaluation;evaluation methodology;wireless networks;wireless attacks},
}

@InProceedings{7502263,
  author    = {Veeramachaneni, Kalyan and Arnaldo, Ignacio and Korrapati, Vamsi and Bassias, Constantinos and Li, Ke},
  booktitle = {2016 IEEE 2nd International Conference on Big Data Security on Cloud (BigDataSecurity), IEEE International Conference on High Performance and Smart Computing (HPSC), and IEEE International Conference on Intelligent Data and Security (IDS)},
  title     = {AI^2: Training a Big Data Machine to Defend},
  year      = {2016},
  month     = {April},
  pages     = {49-54},
  abstract  = {We present AI2, an analyst-in-the-loop security system where Analyst Intuition (AI) is put together with state-of-the-art machine learning to build a complete end-to-end Artificially Intelligent solution (AI). The system presents four key features: a big data behavioral analytics platform, an outlier detection system, a mechanism to obtain feedback from security analysts, and a supervised learning module. We validate our system with a real-world data set consisting of 3.6 billion log lines and 70.2 million entities. The results show that the system is capable of learning to defend against unseen attacks. With respect to unsupervised outlier analysis, our system improves the detection rate in 2.92× and reduces false positives by more than 5×.},
  doi       = {10.1109/BigDataSecurity-HPSC-IDS.2016.79},
  groups    = {First Filtering},
  keywords  = {Analytical models;Big data;Computational modeling;Data models;Security;Feature extraction;Supervised learning;machine learning;human-in-the-loop;anomaly detection;active learning;security;InfoSec;behavioral analytics;big data},
}

@InProceedings{8990342,
  author    = {Rivera, Sean and Lagraa, Sofiane and Iannillo, Antonio Ken and State, Radu},
  booktitle = {2019 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)},
  title     = {Auto-Encoding Robot State Against Sensor Spoofing Attacks},
  year      = {2019},
  month     = {Oct},
  pages     = {252-257},
  abstract  = {In robotic systems, the physical world is highly coupled with cyberspace. New threats affect cyber-physical systems as they rely on several sensors to perform critical operations. The most sensitive targets are their location systems, where spoofing attacks can force robots to behave incorrectly. In this paper, we propose a novel anomaly detection approach for sensor spoofing attacks, based on an auto-encoder architecture. After initial training, the detection algorithm works directly on the compressed data by computing the reconstruction errors. We focus on spoofing attacks on Light Detection and Ranging (LiDAR) systems. We tested our anomaly detection approach against several types of spoofing attacks comparing four different compression rates for the auto-encoder. Our approach has a 99% True Positive rate and a 10% False Negative rate for the 83% compression rate. However, a compression rate of 41% could handle almost all of the same attacks while using half the data.},
  doi       = {10.1109/ISSREW.2019.00080},
  groups    = {First Filtering},
  keywords  = {anomaly detection, benchmark, robotic systems},
}

@Article{9094250,
  author   = {Rakas, Slavica V. Boštjančič and Stojanović, Mirjana D. and Marković-Petrović, Jasna D.},
  journal  = {IEEE Access},
  title    = {A Review of Research Work on Network-Based SCADA Intrusion Detection Systems},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {93083-93108},
  volume   = {8},
  abstract = {Specific intrusion detection systems (IDSs) are needed to secure modern supervisory control and data acquisition (SCADA) systems due to their architecture, stringent real-time requirements, network traffic features and specific application layer protocols. This article aims to contribute to assess the state-of-the-art, identify the open issues and provide an insight for future study areas. To achieve these objectives, we start from the factors that impact the design of dedicated intrusion detection systems in SCADA networks and focus on network-based IDS solutions. We propose a structured evaluation methodology that encompasses detection techniques, protected protocols, implementation tools, test environments and IDS performance. Special attention is focused on assessing implementation maturity as well as the applicability of each surveyed solution in the Future Internet environment. Based on that, we provide a brief description and evaluation of 26 selected research papers, published in the period 2015-2019. Results of our analysis indicate considerable progress regarding the development of machine learning-based detection methods, implementation platforms, and to some extent, sophisticated testbeds. We also identify research gaps and conclude the analysis with a list of the most important directions for further research.},
  doi      = {10.1109/ACCESS.2020.2994961},
  groups   = {First Filtering},
  keywords = {Protocols;SCADA systems;Intrusion detection;Internet;Monitoring;Standards;Anomaly-based detection;network security;SCADA;signature-based detection;specification-based detection},
}

@Article{9296573,
  author   = {Chandwani, Ashwin and Dey, Saikat and Mallik, Ayan},
  journal  = {IEEE Access},
  title    = {Cybersecurity of Onboard Charging Systems for Electric Vehicles—Review, Challenges and Countermeasures},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {226982-226998},
  volume   = {8},
  abstract = {In this paper, the impacts of various data integrity attacks on the power electronic hardware present in an EV charger are comprehensively analyzed in order to provide necessary recommendations to defend against cyberattacks on electric vehicles and their onboard charging (OBC) systems. The adverse scenarios arising due to cyberattacks are carefully reviewed in this study, which includes (a) interfering with the main charger controller (FPGA) logic and its data, (b) establishing fake communication between the charging controller and other electronic control units (ECUs) connected over same controller area network (CAN) bus, and (c) interfering with the battery management system functionalities. A 6.6kW interleaved totem-pole PFC front-end followed by a high frequency DC-DC converter is used as our OBC representative system in this analysis. Possibilities and ways of potential cyberattacks on this model are investigated in detail. Effort is made towards providing software as well as hardware design-level protection mechanisms to mitigate the malicious effects of such cyberattacks on the OBC hardware. This system is simulated in MATLAB/Simulink to verify the fault occurrences under various data integrity attacks as well as to validate the effectiveness of our proposed countermeasure approaches. Quantitative analyses of the obtained results clearly demonstrate that if adequate precautionary measures are properly taken while designing the charging architecture (e.g., implementing intelligence to the main controller), any electrical hazard or deterioration of health of the components can be avoided to the maximum extent under the circumstances of a malicious cyberattack.},
  doi      = {10.1109/ACCESS.2020.3045367},
  groups   = {First Filtering},
  keywords = {Topology;Licenses;Electric vehicles;Computer security;Germanium;6G mobile communication;5G mobile communication;CAN;cybersecurity;electric vehicle;FPGA;onboard charger},
}

@Article{9112234,
  author   = {Saad, Ahmed and Faddel, Samy and Youssef, Tarek and Mohammed, Osama A.},
  journal  = {IEEE Transactions on Smart Grid},
  title    = {On the Implementation of IoT-Based Digital Twin for Networked Microgrids Resiliency Against Cyber Attacks},
  year     = {2020},
  issn     = {1949-3061},
  month    = {Nov},
  number   = {6},
  pages    = {5138-5150},
  volume   = {11},
  abstract = {The increased rate of cyber-attacks on the power system necessitates the need for innovative solutions to ensure its resiliency. This work builds on the advancement in the IoT to provide a practical framework that is able to respond to multiple attacks on a network of interconnected microgrids. This paper provides an IoT-based digital twin (DT) of the cyber-physical system that interacts with the control system to ensure its proper operation. The IoT cloud provision of the energy cyber-physical and the DT are mathematically formulated. Unlike other cybersecurity frameworks in the literature, the proposed one can mitigate an individual as well as coordinated attacks. The framework is tested on a distributed control system and the security measures are implemented using cloud computing. The physical controllers are implemented using single-board computers. The practical results show that the proposed DT is able to mitigate the coordinated false data injection and the denial of service cyber-attacks.},
  doi      = {10.1109/TSG.2020.3000958},
  groups   = {First Filtering},
  keywords = {Microgrids;Cloud computing;Decentralized control;Digital twin;Resilience;Digital twin;networked microgrids;distributed control;industrial Internet of Things;cybersecurity},
}

@Article{9317787,
  author   = {Lee, Kyungroul and Lee, Jaehyuk and Choi, Chang and Yim, Kangbin},
  journal  = {IEEE Access},
  title    = {Offensive Security of Keyboard Data Using Machine Learning for Password Authentication in IoT},
  year     = {2021},
  issn     = {2169-3536},
  pages    = {10925-10939},
  volume   = {9},
  abstract = {In this paper, to increase the attack success rate, we analyzed the distribution of all collected keyboard data based on the distance of time and keyboard scancode data, which presents the crucial data from the previous study. To achieve this, we derived time-distance based features that have higher attack success rates than in previous studies. The proposed attack method defines 6 features, and evaluates the performance based on 18 datasets. For performance evaluation, the accuracy, precision, recall, F1-score, and AUC of Datasets (1 to 3) were compared, and two experiments showed improved overall performance by at least 10.6 % and up to 16.1 % compared to previous studies in terms of the performance evaluation for each feature, comparison of variations in maximum performance, comparison of variations in performance of each feature, and comparison of variations in overall performance. Moreover, the best accuracy, which represents the probability of password exposure, was 96.7 %, which suggests that our proposed attack method has a higher accuracy than the previous study (96.2 %). In conclusion, we demonstrated that password authentication is neutralized by stealing the user password more effectively. For future research, we will focus on improving the attack success rate with respect to accuracy and overall performance numbers, using not only machine learning, but also deep learning.},
  doi      = {10.1109/ACCESS.2021.3050239},
  groups   = {First Filtering},
  keywords = {Keyboards;Authentication;Servers;Password;Smart homes;Tools;Security;Offensive security;vulnerability analysis;password authentication;user authentication;machine learning},
}

@Article{9200713,
  author   = {Wei, Wenqi and Liu, Ling},
  journal  = {IEEE Transactions on Dependable and Secure Computing},
  title    = {Robust Deep Learning Ensemble Against Deception},
  year     = {2021},
  issn     = {1941-0018},
  month    = {July},
  number   = {4},
  pages    = {1513-1527},
  volume   = {18},
  abstract = {Deep neural network (DNN) models are known to be vulnerable to maliciously crafted adversarial examples and to out-of-distribution inputs drawn sufficiently far away from the training data. How to protect a machine learning model against deception of both types of destructive inputs remains an open challenge. This article presents XEnsemble, a diversity ensemble verification methodology for enhancing the adversarial robustness of DNN models against deception caused by either adversarial examples or out-of-distribution inputs. XEnsemble by design has three unique capabilities. First, XEnsemble builds diverse input denoising verifiers by leveraging different data cleaning techniques. Second, XEnsemble develops a disagreement-diversity ensemble learning methodology for guarding the output of the prediction model against deception. Third, XEnsemble provides a suite of algorithms to combine input verification and output verification to protect the DNN prediction models from both adversarial examples and out of distribution inputs. Evaluated using 11 popular adversarial attacks and two representative out-of-distribution datasets, we show that XEnsemble achieves a high defense success rate against adversarial examples and a high detection success rate against out-of-distribution data inputs, and outperforms existing representative defense methods with respect to robustness and defensibility.},
  doi      = {10.1109/TDSC.2020.3024660},
  groups   = {First Filtering},
  keywords = {Predictive models;Robustness;Machine learning;Prediction algorithms;Training;Neural networks;Data models;Robust deep learning;adversarial attack and defense;ensemble method},
}

@InProceedings{9151033,
  author    = {Goel, Akhil and Agarwal, Akshay and Vatsa, Mayank and Singh, Richa and Ratha, Nalini K.},
  booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  title     = {DNDNet: Reconfiguring CNN for Adversarial Robustness},
  year      = {2020},
  month     = {June},
  pages     = {103-110},
  abstract  = {Several successful adversarial attacks have demonstrated the vulnerabilities of deep learning algorithms. These attacks are detrimental in building deep learning based dependable AI applications. Therefore, it is imperative to build a defense mechanism to protect the integrity of deep learning models. In this paper, we present a novel "defense layer" in a network which aims to block the generation of adversarial noise and prevents an adversarial attack in black-box and gray-box settings. The parameter-free defense layer, when applied to any convolutional network, helps in achieving protection against attacks such as FGSM, L2, Elastic-Net, and DeepFool. Experiments are performed with different CNN architectures, including VGG, ResNet, and DenseNet, on three databases, namely, MNIST, CIFAR-10, and PaSC. The results showcase the efficacy of the proposed defense layer without adding any computational overhead. For example, on the CIFAR-10 database, while the attack can reduce the accuracy of the ResNet-50 model to as low as 6.3%, the proposed "defense layer" retains the original accuracy of 81.32%.},
  doi       = {10.1109/CVPRW50498.2020.00019},
  groups    = {First Filtering},
  issn      = {2160-7516},
  keywords  = {Mathematical model;Perturbation methods;Machine learning;Computer architecture;Robustness;Computational modeling;Databases},
}

@Article{8642295,
  author   = {Gadermayr, Michael and Gupta, Laxmi and Appel, Vitus and Boor, Peter and Klinkhammer, Barbara M. and Merhof, Dorit},
  journal  = {IEEE Transactions on Medical Imaging},
  title    = {Generative Adversarial Networks for Facilitating Stain-Independent Supervised and Unsupervised Segmentation: A Study on Kidney Histology},
  year     = {2019},
  issn     = {1558-254X},
  month    = {Oct},
  number   = {10},
  pages    = {2293-2302},
  volume   = {38},
  abstract = {A major challenge in the field of segmentation in digital pathology is given by the high effort for manual data annotations in combination with many sources introducing variability in the image domain. This requires methods that are able to cope with variability without requiring to annotate a large amount of samples for each characteristic. In this paper, we develop approaches based on adversarial models for image-to-image translation relying on unpaired training. Specifically, we propose approaches for stain-independent supervised segmentation relying on image-to-image translation for obtaining an intermediate representation. Furthermore, we develop a fully-unsupervised segmentation approach exploiting image-to-image translation to convert from the image to the label domain. Finally, both approaches are combined to obtain optimum performance in unsupervised segmentation independent of the characteristics of the underlying stain. Experiments on patches showing kidney histology proof that stain-translation can be performed highly effectively and can be used for domain adaptation to obtain independence of the underlying stain. It is even capable of facilitating the underlying segmentation task, thereby boosting the accuracy if an appropriate intermediate stain is selected. Combining domain adaptation with unsupervised segmentation finally showed the most significant improvements.},
  doi      = {10.1109/TMI.2019.2899364},
  groups   = {First Filtering},
  keywords = {Image segmentation;Training;Adaptation models;Training data;Task analysis;Data models;Pipelines;Histology;adversarial networks;segmentation;unsupervised;kidney;image-to-image translation},
}

@InProceedings{6498378,
  author    = {Burstein, Mark and Goldman, Robert and Robertson, Paul and Laddaga, Robert and Balzer, Robert and Goldman, Neil and Geib, Christopher and Kuter, Ugur and Mcdonald, David and Maraist, John and Keller, Peter and Wile, David},
  booktitle = {2012 IEEE Sixth International Conference on Self-Adaptive and Self-Organizing Systems Workshops},
  title     = {STRATUS: Strategic and Tactical Resiliency against Threats to Ubiquitous Systems},
  year      = {2012},
  month     = {Sep.},
  pages     = {47-54},
  abstract  = {We outline our approach to developing, a distributed capability to achieve shared situation awareness of mission status and trust relationships, anticipate and diagnose cyber threats, and respond strategically and tactically to those threats.},
  doi       = {10.1109/SASOW.2012.17},
  groups    = {First Filtering},
  keywords  = {cyber-security;plan-recognition;plan-generation;intrusion-detection;multi-hypothesis-tracking;model-based-diagnosis;middleware.},
}

@InProceedings{8925000,
  author    = {Huang, Yongjie and Qin, Jinghui and Wen, Wushao},
  booktitle = {2019 IEEE 13th International Conference on Anti-counterfeiting, Security, and Identification (ASID)},
  title     = {Phishing URL Detection Via Capsule-Based Neural Network},
  year      = {2019},
  month     = {Oct},
  pages     = {22-26},
  abstract  = {As a cyber attack which leverages social engineering and other sophisticated techniques to steal sensitive information from users, phishing attack has been a critical threat to cyber security for a long time. Although researchers have proposed lots of countermeasures, phishing criminals figure out circumventions eventually since such countermeasures require substantial manual feature engineering and can not detect newly emerging phishing attacks well enough, which makes developing an efficient and effective phishing detection method an urgent need. In this work, we propose a novel phishing website detection approach by detecting the Uniform Resource Locator (URL) of a website, which is proved to be an effective and efficient detection approach. To be specific, our novel capsule-based neural network mainly includes several parallel branches wherein one convolutional layer extracts shallow features from URLs and the subsequent two capsule layers generate accurate feature representations of URLs from the shallow features and discriminate the legitimacy of URLs. The final output of our approach is obtained by averaging the outputs of all branches. Extensive experiments on a validated dataset collected from the Internet demonstrate that our approach can achieve competitive performance against other state-of-the-art detection methods while maintaining a tolerable time overhead.},
  doi       = {10.1109/ICASID.2019.8925000},
  groups    = {First Filtering},
  issn      = {2163-5056},
  keywords  = {Phishing;Feature extraction;Uniform resource locators;Neural networks;Convolution;Machine learning;Heuristic algorithms;phishing detection;cyber security;deep learning;capsule network},
}

@InProceedings{8591079,
  author    = {Deng, Qingyu and Sun, Jian},
  booktitle = {IECON 2018 - 44th Annual Conference of the IEEE Industrial Electronics Society},
  title     = {False Data Injection Attack Detection in a Power Grid Using RNN},
  year      = {2018},
  month     = {Oct},
  pages     = {5983-5988},
  abstract  = {Cyber attacks on Cyber Physical Systems (CPSs), especially on those critical infrastructures poses severe threat on the public security. Among them, a special kind of attack, False Data Injection (FDI), can bypass the surveillance of state-estimation-based bad data detection mechanism silently. In this paper, we exploited the strong ability of Recurrent Neural Network (RNN) on time-series prediction to recognize the potential compromised measurements. It makes our proposed method practicable in real-world scenario that no labeled data is required during all stages of algorithm. An experiment on IEEE-14 bus test system is conducted and shows a promising result that our proposed method is able to detect FDI attack with high precision and high recall.},
  doi       = {10.1109/IECON.2018.8591079},
  groups    = {First Filtering},
  issn      = {2577-1647},
  keywords  = {Recurrent neural networks;Power grids;Prediction algorithms;State estimation;Predictive models;Cyberattack;recurrent neural network;cyber security;false data injection attack;detection},
}

@InProceedings{7107930,
  author    = {Elboukhari, Mohamed and Azizi, Mostafa and Azizi, Abdelmalek},
  booktitle = {2014 5th Workshop on Codes, Cryptography and Communication Systems (WCCCS)},
  title     = {Intrusion Detection Systems in mobile ad hoc networks: A survey},
  year      = {2014},
  month     = {Nov},
  pages     = {136-141},
  abstract  = {Due to its unique characteristics, mobile ad hoc networks (MANETs) are more vulnerable to malicious attack and the absolute security in the mobile ad hoc network is very hard to achieve. Prevention methods as cryptographic techniques alone are not sufficient to make them secure; therefore, efficient intrusion detection must be deployed and elaborated to facilitate the identification of attacks. An Intrusion Detection System (IDS) aims to detect malicious and selfish nodes in a network. The intrusion detection techniques used for wired networks may no longer be effective and sufficient when adapted directly to a wireless ad-hoc network, thus existing methods of intrusion detection have to be modified and new methods have to be defined in order to work effectively and efficiency in this new network architecture. In this paper we give a survey of different architectures and methods of intrusion detection systems (IDSs) for MANETs accordingly to the recent literature.},
  doi       = {10.1109/WCCCS.2014.7107930},
  groups    = {First Filtering},
  keywords  = {Ad hoc networks;Mobile computing;Lead;Intrusion detection;Logic gates;Monitoring;network security;mobile ad hoc networks;MANETs;intrusion detection systems},
}

@InProceedings{7973729,
  author    = {Tahir, Rashid and Raza, Ali and Naqvi, Mazhar and Zaffar, Fareed and Caesar, Matthew},
  booktitle = {2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)},
  title     = {An Anomaly Detection Fabric for Clouds Based on Collaborative VM Communities},
  year      = {2017},
  month     = {May},
  pages     = {431-441},
  abstract  = {The vast attack surface of clouds presents a challenge in deploying scalable and effective defenses. Traditional security mechanisms, which work from inside the VM fail to provide strong protection as attackers can bypass them easily. The only available option is to provide security from the layer below the VM i.e., the hypervisor. Previous works that attempt to secure VMs from "outside" either incur substantial space or compute overheads making them slow and impractical or require modifications to the OS or the application codebase. To address these issues, we propose an anomaly detection fabric for clouds based on system call monitoring, which compresses the stream of system calls at their source making the system scalable and near real-time. Our system requires no modifications to the guest OS or the application making it ideal for the data center setting. Additionally, for robust and early detection of threats, we leverage the notion of VM/container communities that share information about attacks in their early stages to provide immunity to the entire deployment. We make certain aspects of the system flexible so that vendors can tune metrics to offer customized protection to clients based on their workload types. Detailed evaluation on a prototype implementation on KVM substantiates our claims.},
  doi       = {10.1109/CCGRID.2017.61},
  groups    = {First Filtering},
  keywords  = {Monitoring;Training;Fabrics;Cloud computing;Containers;Security;Runtime;clouds;anomaly detection;behavior profiling},
}

@InProceedings{8805036,
  author    = {Bernieri, Giuseppe and Conti, Mauro and Turrin, Federico},
  booktitle = {2019 IEEE International Symposium on Measurements Networking (M N)},
  title     = {Evaluation of Machine Learning Algorithms for Anomaly Detection in Industrial Networks},
  year      = {2019},
  month     = {July},
  pages     = {1-6},
  abstract  = {The cyber-physical security of Industrial Control Systems (ICSs) represents an actual and worthwhile research topic. In this paper, we compare and evaluate different Machine Learning (ML) algorithms for anomaly detection in industrial control networks. We analyze supervised and unsupervised ML-based anomaly detection approaches using datasets extracted from the Secure Water Treatment (SWaT), a testbed developed to emulate a scaled-down real industrial plant. Our experiments show strengths and limitations of the two ML-based anomaly detection approaches for industrial networks.},
  doi       = {10.1109/IWMN.2019.8805036},
  groups    = {First Filtering},
  issn      = {2639-5061},
  keywords  = {Anomaly detection;Sensors;Security;Integrated circuits;Support vector machines;Image reconstruction;Prediction algorithms;Machine Learning;Anomaly Detection;Industrial Control System;Cyber-Physical System;Security},
}

@InProceedings{8952139,
  author    = {Deka, Pratyush Kr. and Bhuyan, Monowar H. and Kadobayashi, Youki and Elmroth, Erik},
  booktitle = {2019 IEEE 24th Pacific Rim International Symposium on Dependable Computing (PRDC)},
  title     = {Adversarial Impact on Anomaly Detection in Cloud Datacenters},
  year      = {2019},
  month     = {Dec},
  pages     = {188-18809},
  abstract  = {Cloud datacenters are engineered to meet the requirements of generalised and specialised workloads including mission-critical applications that not only generate tremendous amounts of data traces but also opens opportunities for attackers. The increasing volume and rapid changing behaviour of metric streams (e.g., CPU, network, latency, memory) in the cloud datacenters create difficulties to ensure high availability, security, and performance to cloud service providers. Several anomaly detection techniques have been developed to combat system anomalies in cloud datacenters. By injecting a fraction of well-crafted malicious samples in cloud datacenter traces, attackers can subvert the learning process and results in unacceptable false alarms. These security issues cause threats to all categories of anomaly detection. Hence, it is crucial to assess these techniques against adversaries to improve scalability and robustness. We propose a linear regression-based optimisation framework with the ability to poison data in the training phase and demonstrate its effectiveness on cloud datacenter traces. Finally, we investigate the worst-case analysis of poisoning attacks on robust statistics-based anomaly detection techniques to quantify and assess the detection accuracy. We validate this framework using benchmark resource traces obtained from Yahoo's service cluster as well as traces collected from an experimental testbed with realistic service composition.},
  doi       = {10.1109/PRDC47002.2019.00049},
  groups    = {First Filtering},
  issn      = {2473-3105},
  keywords  = {Adversarial learning, Anomaly detection, Poisoning attack, Cloud services, Datacenter},
}

@InProceedings{8256035,
  author    = {Rashidi, Bahman and Fung, Carol and Bertino, Elisa},
  booktitle = {2017 13th International Conference on Network and Service Management (CNSM)},
  title     = {Android malicious application detection using support vector machine and active learning},
  year      = {2017},
  month     = {Nov},
  pages     = {1-9},
  abstract  = {The increasing popularity of Android phones and its open app market system have caused the proliferation of malicious Android apps. The increasing sophistication and diversity of the malicious Android apps render the conventional malware detection techniques ineffective, which results in a large number of malicious applications remaining undetected. This calls for more effective techniques for detection and classification of Android malware. Hence, in this paper, we present an Android malicious application detection framework based on the Support Vector Machine (SVM) and Active Learning technologies. In our approach, we extract applications' activities while in execution and map them into a feature set, we then attach timestamps to some features in the set. We show that our novel use of time-dependent behavior tracking can significantly improve the malware detection accuracy. In particular, we build an active learning model using Expected error reduction query strategy to integrate new informative instances of Android malware and retrain the model to be able to do adaptive online learning. We evaluate our model through a set of experiments on the DREBIN benchmark malware dataset. Our evaluation results show that the proposed approach can accurately detect malicious applications and improve updatability against new malware.},
  doi       = {10.23919/CNSM.2017.8256035},
  groups    = {First Filtering},
  issn      = {2165-963X},
  keywords  = {Support vector machines;Training;Kernel;Smart phones;Malware;Data models;Feature extraction},
}

@Article{9469900,
  author   = {Sabeel, Ulya and Heydari, Shahram Shah and Elgazzar, Khalid and El-Khatib, Khalil},
  journal  = {IEEE Access},
  title    = {Building an Intrusion Detection System to Detect Atypical Cyberattack Flows},
  year     = {2021},
  issn     = {2169-3536},
  pages    = {94352-94370},
  volume   = {9},
  abstract = {Artificial Intelligence (AI) techniques provide effective solutions for the detection of many aberrant network traffic patterns and attack flows. However, the validation of these techniques often relies on one training dataset. Recent results show that such training may fail in the face of dynamically-changing cyberattacks. Given the increased sophistication of cyberattacks nowadays, it is imperative to examine and improve the performance of such AI models. This paper proposes a defensive AI engine combined with a twofold feature selection technique and hyperparameter optimization of the AI model. In this work, we utilize the proposed system for binary attack flow identification and the AI models are trained and validated on the CICIDS2017 dataset. The system is then evaluated using synthesized atypical attack flows to mimic real-world scenarios. We demonstrate the effectiveness of the proposed atypical attack flow detection approach using several Deep Learning and Machine Learning models including DNN, Linear-SVC, and Stacked Decision Tree Classifier (S-DTC). Simulation results demonstrate that the proposed defensive AI engine significantly improves the True Positive Rate (TPR) of AI models on multiple atypical attacks.},
  doi      = {10.1109/ACCESS.2021.3093830},
  groups   = {First Filtering},
  keywords = {Artificial intelligence;Feature extraction;Training;Benchmark testing;Data models;Computer crime;Network intrusion detection;Artificial Intelligence (AI);atypical attacks;Denial of Service;feature profile;intrusion detection},
}

@InProceedings{7575848,
  author    = {Gendreau, Audrey A. and Moorman, Michael},
  booktitle = {2016 IEEE 4th International Conference on Future Internet of Things and Cloud (FiCloud)},
  title     = {Survey of Intrusion Detection Systems towards an End to End Secure Internet of Things},
  year      = {2016},
  month     = {Aug},
  pages     = {84-90},
  abstract  = {The Internet of Things (IoT) is one of the largest technological evolutions of computing, by 2022 it is estimated that a trillion IP addresses (objects) will be connected to the Internet. The obscurity and low accessibility of many of these devices in this vast heterogeneous network will make it difficult to holistically monitor information flow. Nonetheless, to safeguard networks, unauthorized intruders must be detected within the constraints of each type of device or subnetwork before any system information can be disseminated. In this paper, a survey of the Intrusion Detection Systems (IDS) using the most recent ideas and methods proposed for the IoT is presented. To understand and illustrate IDS platform differences and the current research trend towards a universal, cross-platform distributed approach, the survey starts with an historical examination of intrusion detection systems. This examination of the foundations of IDS research based on the components that make up the IoT is followed by a look at the current holistic trend and an analysis of these schemes. Finally, guidelines to potential IDS in the IoT are proposed before identifying the open research problems.},
  doi       = {10.1109/FiCloud.2016.20},
  groups    = {First Filtering},
  keywords  = {Internet of things;Ad hoc networks;Wireless sensor networks;Intrusion detection;Wireless communication;Communication system security;Internet of Things;IoT;Cloud;Wireless Sensor Networks;WSN;Intrusion Detection System;IDS;Radio Frequency Identification;RFID;Cell Phone},
}

@InProceedings{6486012,
  author    = {Wei, Jin and Kundur, Deepa and Zourntos, Takis and Butler-Purry, Karen},
  booktitle = {2012 IEEE Third International Conference on Smart Grid Communications (SmartGridComm)},
  title     = {Probing the telltale physics: Towards a cyber-physical protocol to mitigate information corruption in smart grid systems},
  year      = {2012},
  month     = {Nov},
  pages     = {372-377},
  abstract  = {We consider a cyber-physical perspective to the problem of identifying and mitigating information corruption in smart grid systems. We study the problem of transient stability with distributed control using real-time data from geographically distributed phasor measurement units via a flocking-based modeling paradigm. We demonstrate how cyber corruption can be identified through the effective use of telltale physical couplings within the power system.We develop a novel witness-based cyber-physical protocol whereby physical coherence is leveraged to probe and identify phasor measurement unit data corruption and estimate the true information values for attack mitigation.},
  doi       = {10.1109/SmartGridComm.2012.6486012},
  groups    = {First Filtering},
  keywords  = {Phasor measurement units;Generators;Power system stability;Transient analysis;Protocols;Estimation},
}

@InProceedings{9430980,
  author    = {Rathore, Hemant and Sahay, Sanjay K.},
  booktitle = {2021 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops)},
  title     = {Towards Robust Android Malware Detection Models using Adversarial Learning},
  year      = {2021},
  month     = {March},
  pages     = {424-425},
  abstract  = {Malware analysis and detection is an endless competitive battle between malware designers and the anti-malware community. Recently researchers have proposed state-of-the-art malware detection models built using machine learning and deep learning which are necessary to detect advanced metamorphic malware. But these malware detection models are susceptible to adversarial attacks. Therefore we propose to design robust Android malware detection models against adversarial attacks using reinforcement learning. We propose the Single Policy and Multi Policy based Evasion Attacks for Perfect Knowledge and Limited Knowledge scenario respectively against many malware detection models built using four different sets of classifiers (bagging, boosting and deep neural network). The motivation is to identify the adversarial vulnerability in Android malware detection models and then propose defence against them.},
  doi       = {10.1109/PerComWorkshops51409.2021.9430980},
  groups    = {First Filtering},
  keywords  = {Knowledge engineering;Pervasive computing;Deep learning;Conferences;Computational modeling;Neural networks;Reinforcement learning;Android;Adversarial Learning;Machine Learning;Malware Detection;Reinforcement Learning;Smartphone},
}

@InProceedings{8987407,
  author    = {Neal, Tempestt and Woodard, Damon},
  booktitle = {2019 International Conference on Biometrics (ICB)},
  title     = {Mobile Biometrics, Replay Attacks, and Behavior Profiling: An Empirical Analysis of Impostor Detection},
  year      = {2019},
  month     = {June},
  pages     = {1-8},
  abstract  = {The rise of mobile devices has contributed new biometric modalities which reflect behavioral tendencies as users interact with the device's services. In this paper, we explore replay attacks against such systems and how a remote attack might affect authentication performance. There are few efforts that focus on replay attacks in mobile biometric systems, and none to our knowledge related to user-device interactions, such as the use of mobile apps. Instead, previous efforts have mainly considered spoofing attacks, which implicate that the attacker has learned their target's behavior instead of obtaining a direct copy of logged behavior by theft. Here, we explore temporally-derived replay attacks that assume that application, Bluetooth, and Wi-Fi data has been captured remotely and then intelligently combined with some level of noise to avoid the replay of an exact copy of legitimate data. We study several factors that may affect replay attack detection, including the effects of varying the amount of data available during data collection, the number of samples used for training, and supervised and unsupervised learning on attack detection. In our analysis, false positive rates increased from 2.3% when using zero-effort attacks to over 40% as a result of replay attacks. However, our results also show that by contextualizing behavior in the feature representation, false positive rates decrease by over 25%.},
  doi       = {10.1109/ICB45273.2019.8987407},
  groups    = {First Filtering},
  issn      = {2376-4201},
}

@InProceedings{9322322,
  author    = {Niu, Ben and Zhang, Likun and Chen, Yahong and Li, Ang and Du, Wei and Cao, Jin and Li, Fenghua},
  booktitle = {GLOBECOM 2020 - 2020 IEEE Global Communications Conference},
  title     = {A Framework to Preserve User Privacy for Machine Learning as a Service},
  year      = {2020},
  month     = {Dec},
  pages     = {1-6},
  abstract  = {Suffered from the contradiction between the limited capacity of local devices and large size of DNN models, a practical solution is transferring the heavy computational tasks from the local to the server side such as cloud. However, the untrusted server naturally requires all the user data to train neural networks and infer results, which causes the asset loss of the local and raises serious privacy concerns on user's sensitive information. To solve this problem in scenarios of machine learning as a service, we propose a general framework to balance the user privacy, model accuracy and training efficiency, simultaneously. Specifically, our representative subset selection algorithm takes the training value of data into account, selecting the most representative subset from the training data, in order to mitigate the loss of data assets, lower down the transmission overhead from the local to the server and lessen the training burden on the server at the same time. We also design a noisy representation transformation algorithm applying on the features extracted by neural networks to further perturb the data within the selected representative subset. Extensive experiments demonstrate that our framework can run locally with little sacrifice on the computation resource. It can not only protect private data before uploading, but also promote the training efficiency of servers.},
  doi       = {10.1109/GLOBECOM42002.2020.9322322},
  groups    = {First Filtering},
  issn      = {2576-6813},
  keywords  = {Servers;Training;Data models;Task analysis;Privacy;Feature extraction;Computational modeling},
}

@InProceedings{8987389,
  author    = {Soleymani, Sobhan and Dabouei, Ali and Dawson, Jeremy and Nasrabadi, Nasser M.},
  booktitle = {2019 International Conference on Biometrics (ICB)},
  title     = {Adversarial Examples to Fool Iris Recognition Systems},
  year      = {2019},
  month     = {June},
  pages     = {1-8},
  abstract  = {Adversarial examples have recently proven to be able to fool deep learning methods by adding carefully crafted small perturbation to the input space image. In this paper, we study the possibility of generating adversarial examples for code-based iris recognition systems. Since generating adversarial examples requires back-propagation of the adversarial loss, conventional filter bank-based iris-code generation frameworks cannot be employed in such a setup. Therefore, to compensate for this shortcoming, we propose to train a deep auto-encoder surrogate network to mimic the conventional iris code generation procedure. This trained surrogate network is then deployed to generate the adversarial examples using the iterative gradient sign method algorithm [15]. We consider non-targeted and targeted attacks through three attack scenarios. Considering these attacks, we study the possibility of fooling an iris recognition system in white-box and black-box frameworks.},
  doi       = {10.1109/ICB45273.2019.8987389},
  groups    = {First Filtering},
  issn      = {2376-4201},
}

@InProceedings{7805855,
  author    = {Keliris, Anastasis and Salehghaffari, Hossein and Cairl, Brian and Krishnamurthy, Prashanth and Maniatakos, Michail and Khorrami, Farshad},
  booktitle = {2016 IEEE International Test Conference (ITC)},
  title     = {Machine learning-based defense against process-aware attacks on Industrial Control Systems},
  year      = {2016},
  month     = {Nov},
  pages     = {1-10},
  abstract  = {The modernization of Industrial Control Systems (ICS), primarily targeting increased efficiency and controllability through integration of Information Technologies (IT), introduced the unwanted side effect of extending the ICS cyber-security threat landscape. ICS are facing new security challenges and are exposed to the same vulnerabilities that plague IT, as demonstrated by the increasing number of incidents targeting ICS. Due to the criticality and unique nature of these systems, it is important to devise novel defense mechanisms that incorporate knowledge of the underlying physical model, and can detect attacks in early phases. To this end, we study a benchmark chemical process, and enumerate the various categories of attack vectors and their practical applicability on hardware controllers in a Hardware-In-The-Loop testbed. Leveraging the observed implications of the categorized attacks on the process, as well as the profile of typical disturbances, we follow a data-driven approach to detect anomalies that are early indicators of malicious activity.},
  doi       = {10.1109/TEST.2016.7805855},
  groups    = {First Filtering},
  issn      = {2378-2250},
  keywords  = {Integrated circuits;Process control;Security;Mathematical model;Real-time systems;Hardware;Software},
}

@InProceedings{9454214,
  author    = {Alatwi, Huda Ali and Aldweesh, Amjad},
  booktitle = {2021 IEEE World AI IoT Congress (AIIoT)},
  title     = {Adversarial Black-Box Attacks Against Network Intrusion Detection Systems: A Survey},
  year      = {2021},
  month     = {May},
  pages     = {0034-0040},
  abstract  = {Due to their massive success in various domains, deep learning techniques are increasingly used to design network intrusion detection solutions that detect and mitigate unknown and known attacks with high accuracy detection rates and minimal feature engineering. However, it has been found that deep learning models are vulnerable to data instances that can mislead the model to make incorrect classification decisions socalled adversarial examples. Such vulnerability allows attackers to target NIDSs in a black-box setting by adding small crafty perturbations to the malicious traffic to evade detection and disrupt the system's critical functionalities. Yet, little researches have addressed the risks of black-box adversarial attacks against NIDS and proposed mitigation solutions. This survey explores this research problem and identifies open issues and certain areas that demand further research for considerable impacts.},
  doi       = {10.1109/AIIoT52608.2021.9454214},
  groups    = {First Filtering},
  keywords  = {Deep learning;Perturbation methods;Network intrusion detection;Feature extraction;Data models;Security;Communication networks;Network Intrusion Detection;Deep Neural Networks;Adversarial Examples;Black-box Attacks;Adversarial Attacks;Adversarial Machine Learning;Network Security},
}

@InProceedings{6151339,
  author    = {Gupta, Dheeraj and Joshi, P.S. and Bhattacharjee, A.K. and Mundada, R.S.},
  booktitle = {2012 Fourth International Conference on Communication Systems and Networks (COMSNETS 2012)},
  title     = {IDS alerts classification using knowledge-based evaluation},
  year      = {2012},
  month     = {Jan},
  pages     = {1-8},
  abstract  = {Most organizations deploy Signature based Intrusion Detection Systems (IDS) to monitor network activities for signs of security violations and these systems generate alerts whenever a known intrusion signature is detected in the network traffic. However, IDSs are known for generating many alerts, most of them being false. This makes the job of security analyst tougher as he/she has to sift through security events to filter out relevant alerts. In this process, the high priority alerts are not addressed quickly and there is a great risk of a legitimate attack going unnoticed. Many researchers have suggested various means of classifying the IDS alerts. A potentially useful candidate is to use network contextual information to segregate relevant and non-relevant alerts. In this paper we describe PIKE, Post-processor for IDS alerts using Knowledge-based Evaluation, a system that uses background information about the hosts present on the network and the vulnerability exploited to generate a score for each alert. The score is measure of the importance of the alert. A simple binary classifier then classifies the alert as relevant or irrelevant based on value of score threshold. PIKE makes the life of security analyst simpler by presenting the classified alerts which allows him/her to focus solely on the important alerts. We evaluate PIKE for a custom dataset and demonstrate the effectiveness of using contextual sensitivity as a basis of classification.},
  doi       = {10.1109/COMSNETS.2012.6151339},
  groups    = {First Filtering},
  issn      = {2155-2509},
  keywords  = {Context;Knowledge based systems;Security;Accuracy;Databases;Monitoring;Organizations;Signature based intrusion detection;Network security;Context sensitivity;False positives;Alert classification},
}

@Article{8581440,
  author   = {Li, Yuancheng and Wang, Yuanyuan},
  journal  = {IEEE Access},
  title    = {False Data Injection Attacks With Incomplete Network Topology Information in Smart Grid},
  year     = {2019},
  issn     = {2169-3536},
  pages    = {3656-3664},
  volume   = {7},
  abstract = {False data injection (FDI) attack causes a disadvantage to the safety of a power system. In the past, the adversary launching FDI attack mostly needed the complete network topology information of the power system and a large amount of measurements. However, the reality is that the adversary has limited resources and can hardly manipulate massive measurements without being detected. This paper proposes a new method to form attack vector in the condition of incomplete system information. The proposed method first maps the restricted data into a new Jacobian matrix by a kernel-independent component analysis, then constructs the undetectable attack model, and finally, designs a less costly attack vector to accomplish the FDI attack. The experimental results on different IEEE buses with Matpower tool illustrate the validity of the proposed method. Additionally, the proposed method shows a relatively high success rate in the cases of different degrees of incomplete information and various quantities of manipulated data in different power systems.},
  doi      = {10.1109/ACCESS.2018.2888582},
  groups   = {First Filtering},
  keywords = {State estimation;Topology;Transmission line matrix methods;Smart grids;Power measurement;Jacobian matrices;False data injection attack;smart grid;attack vector;incomplete information;state estimation},
}

@InProceedings{6550973,
  author    = {Alserhani, Faeiz},
  booktitle = {2013 Saudi International Electronics, Communications and Photonics Conference},
  title     = {A framework for multi-stage attack detection},
  year      = {2013},
  month     = {April},
  pages     = {1-6},
  abstract  = {Network Intrusion Detection Systems (NIDS) are considered as essential mechanisms to ensure reliable security. In an intrusion detection context, none of the main detection approaches (signature-based and anomaly-based) are fully satisfactory. False positives (detected non-attacks) and false negatives (non-detected attacks) are the major limitations of such systems. The generated alerts are elementary and in huge numbers. Hence, alert correlation techniques are used to provide a complementary analysis to link elementary alerts and provide a more global intrusion view. We propose an alert correlation and aggregation framework based on requires/provides model. The objective is to discover the logical relationships between atomic alerts potentially incorporated in multi-stage attacks. The obtained results illustrate that the proposed system can effectively detect coordinated attack with minimum false positives.},
  doi       = {10.1109/SIECPC.2013.6550973},
  groups    = {First Filtering},
  keywords  = {Correlation;Knowledge based systems;Mars;Security;Engines;IP networks;Abstracts;Network intrusion detection systems;Alerts correlation;multi-stage attack},
}

@InProceedings{7914972,
  author    = {Joshi, Prachi and Jindal, Chani and Chowkwale, Mukti and Shethia, Rohan and Shaikh, Sohail Ahmed and Ved, Dhaval},
  booktitle = {2016 International Conference on Computing, Analytics and Security Trends (CAST)},
  title     = {Protego: A passive intrusion detection system for Android smartphones},
  year      = {2016},
  month     = {Dec},
  pages     = {232-237},
  abstract  = {With the proliferation of smartphones, the security threats have correspondingly increased. Although some form of security mechanisms like authentication and encryption have been provided on platforms such as Android, these alone cannot mitigate all the forms of threats. Thus, the need for an intrusion detection system for smartphones has become immensely important. In this project, we capitalize on earlier approaches of host-based intrusion detection systems and behavior-based intrusion detection systems for Android smartphones to design and implement a host-based, behavior-based passive intrusion detection system, Protego, for Android smartphones. There are two versions - static and dynamic, each with its own novel approach. The static version of Protego improves predictive performance by implementing feature reduction, thus increasing classifier accuracy significantly. The novelty of dynamic approach is that it analyzes live traffic with a minimum delay (in the order of milliseconds). This opens up a variety of use cases for our system, especially in the business world where information security on smartphones is of utmost importance. We have illustrated this by also extending Protego to devise a solution for BYOD (bring your own device), a growing trend in the corporate world, by using the IDS to detect other malicious activities like peer-to-peer traffic from torrent clients.},
  doi       = {10.1109/CAST.2016.7914972},
  groups    = {First Filtering},
  keywords  = {Smart phones;Intrusion detection;Principal component analysis;Classification algorithms;Training;Androids;Intrusion Detection System;Android;Information Security;Machine Learning;Protego},
}

@InProceedings{9458733,
  author    = {Banerjee, Prithu and Chu, Lingyang and Zhang, Yong and Lakshmanan, Laks V.S. and Wang, Lanjun},
  booktitle = {2021 IEEE 37th International Conference on Data Engineering (ICDE)},
  title     = {Stealthy Targeted Data Poisoning Attack on Knowledge Graphs},
  year      = {2021},
  month     = {April},
  pages     = {2069-2074},
  abstract  = {A host of different KG embedding techniques have emerged recently and have been empirically shown to be very effective in accurately predicting missing facts in a KG, thus improving its coverage and quality. Unfortunately, embedding techniques can fall prey to adversarial data poisoning attack. In this form of attack, facts may be added to or deleted from a KG, called performing perturbations, that results in the manipulation of the plausibility of target facts in a KG. While recent works confirm this intuition, the attacks considered there ignore the risk of exposure. Intuitively, an attack is of limited value if it is highly likely to be caught, i.e., exposed. To address this, we introduce a notion of the exposure risk and propose a novel problem of attacking a KG by means of perturbations where the goal is to maximize the manipulation of the target fact’s plausibility while keeping the risk of exposure under a given budget. We design a deep reinforcement learning-based framework, called RATA, that learns to use low-risk perturbations without compromising on the performance, i.e., manipulation of target fact plausibility. We test the performance of RATA against recently proposed strategies for KG attacks, on two different benchmark datasets and on different kinds of target facts. Our experiments show that RATA achieves state-of-the-art performance even while using a fraction of the risk.},
  doi       = {10.1109/ICDE51399.2021.00202},
  groups    = {First Filtering},
  issn      = {2375-026X},
  keywords  = {Knowledge engineering;Perturbation methods;Conferences;Benchmark testing;Data engineering},
}

@InProceedings{9054671,
  author    = {Wang, Yulu and Wu, Kailun and Zhang, Changshui},
  booktitle = {ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Adversarial Attacks on Deep Unfolded Networks for Sparse Coding},
  year      = {2020},
  month     = {May},
  pages     = {5974-5978},
  abstract  = {Previous works have discovered that general DNNs are vulnerable under some subtle and specific perturbations on classification tasks. In recent years, deep neural networks (DNNs) unfolded through sparse coding algorithms have achieved great success in sparse coding problem. Some applications of sparse coding have important strategic significance in many cases, and the security of learned models is vital. However, it has not achieved enough attentions. Our paper is the first work to study the adversarial performance on unfolded DNNs for sparse coding. We first verify the effectiveness of the existing attack or defense strategies, and surprisingly discover the defense strategies are useless. In addition, we propose a special attack strategy to eliminate the element on certain dimension of the sparse output code of DNNs. Furthermore, we propose a succinct black-box attack strategy, which could generate adversarial perturbations without knowing the parameters of DNNs and data.},
  doi       = {10.1109/ICASSP40776.2020.9054671},
  groups    = {First Filtering},
  issn      = {2379-190X},
  keywords  = {Correlation;Perturbation methods;Signal processing algorithms;Encoding;Task analysis;Speech processing;Signal to noise ratio;Deep sparse coding;Adversarial attack;LISTA;Black-box attack;LAMP},
}

@Article{8896955,
  author   = {Zhang, Yuping and Qu, Youyang and Gao, Longxiang and Luan, Tom H. and Zheng, Xi and Chen, Shiping and Xiang, Yong},
  journal  = {IEEE Access},
  title    = {APDP: Attack-Proof Personalized Differential Privacy Model for a Smart Home},
  year     = {2019},
  issn     = {2169-3536},
  pages    = {166593-166605},
  volume   = {7},
  abstract = {The proliferation of smart devices in recent years has led to novel smart home applications that upgrade traditional home appliances to intelligent units and automatically adapt their services without human assistance. In a smart home system, a central gateway is required to coordinate the functions of various smart home devices and allow bidirectional communications. However, the gateway may cause leakage of sensitive information unless proper privacy protections are applied. In this work, we first introduce a smart home model based on fog computing and secured by differential privacy. Then, we apply a personalized differential privacy scheme to provide privacy protection. Furthermore, we consider a collusion attack and propose our differential privacy model called APDP based on a modified Laplace mechanism and a Markov process to strengthen privacy protection, thus resisting the attack. Lastly, we perform extensive experiments based on the real-world datasets to evaluate the proposed APDP model.},
  doi      = {10.1109/ACCESS.2019.2953133},
  groups   = {First Filtering},
  keywords = {Smart homes;Privacy;Computational modeling;Differential privacy;Edge computing;Internet of Things;Cloud computing;Smart home;fog computing;differential privacy;personalized privacy},
}

@Article{7299317,
  author   = {Das, Sanjeev and Liu, Yang and Zhang, Wei and Chandramohan, Mahintham},
  journal  = {IEEE Transactions on Information Forensics and Security},
  title    = {Semantics-Based Online Malware Detection: Towards Efficient Real-Time Protection Against Malware},
  year     = {2016},
  issn     = {1556-6021},
  month    = {Feb},
  number   = {2},
  pages    = {289-302},
  volume   = {11},
  abstract = {Recently, malware has increasingly become a critical threat to embedded systems, while the conventional software solutions, such as antivirus and patches, have not been so successful in defending the ever-evolving and advanced malicious programs. In this paper, we propose a hardware-enhanced architecture, GuardOL, to perform online malware detection. GuardOL is a combined approach using processor and field-programmable gate array (FPGA). Our approach aims to capture the malicious behavior (i.e., high-level semantics) of malware. To this end, we first propose the frequency-centric model for feature construction using system call patterns of known malware and benign samples. We then develop a machine learning approach (using multilayer perceptron) in FPGA to train classifier using these features. At runtime, the trained classifier is used to classify the unknown samples as malware or benign, with early prediction. The experimental results show that our solution can achieve high classification accuracy, fast detection, low power consumption, and flexibility for easy functionality upgrade to adapt to new malware samples. One of the main advantages of our design is the support of early prediction-detecting 46% of malware within first 30% of their execution, while 97% of the samples at 100% of their execution, with <;3% false positives.},
  doi      = {10.1109/TIFS.2015.2491300},
  groups   = {First Filtering},
  keywords = {Malware;Feature extraction;Software;Semantics;Runtime;Field programmable gate arrays;Training;Malware Detection;Hardware-enhanced Architecture;Runtime Security;Early Prediction;Reconfigurable Malware Detection;Malware detection;hardware-enhanced architecture;runtime security;early prediction;reconfigurable malware detection},
}

@InProceedings{8280825,
  author    = {Ludwig, Simone A.},
  booktitle = {2017 IEEE Symposium Series on Computational Intelligence (SSCI)},
  title     = {Intrusion detection of multiple attack classes using a deep neural net ensemble},
  year      = {2017},
  month     = {Nov},
  pages     = {1-7},
  abstract  = {An intrusion detection system (IDS) is a necessity to protect against network attacks. The system monitors the activity within a network of connected computers in order to analyze the activity for intrusive patterns. Should an `attack' event happen, then the system has to respond accordingly. Different machine learning techniques have been proposed in the past roughly falling into two categories namely clustering algorithms and classification algorithms. In this paper, the IDS is designed with a neural network ensemble method to classify the different attacks. The neural network ensemble method comprises autoencoder, deep belief neural network, deep neural network, and an extreme learning machine. The NSL-KDD data set is used to measure the detection rate and false alarm rate of the implemented neural network ensemble method. The detection rate and false alarm rate are the two important measure for IDSs, however, several other measures are also reported on such as confusion matrix, classification accuracy, and AUC (area under curve).},
  doi       = {10.1109/SSCI.2017.8280825},
  groups    = {First Filtering},
  keywords  = {Neural networks;Intrusion detection;Training;Support vector machines;Feature extraction;Machine learning},
}

@Article{7063894,
  author   = {Ozay, Mete and Esnaola, Iñaki and Yarman Vural, Fatos Tunay and Kulkarni, Sanjeev R. and Poor, H. Vincent},
  journal  = {IEEE Transactions on Neural Networks and Learning Systems},
  title    = {Machine Learning Methods for Attack Detection in the Smart Grid},
  year     = {2016},
  issn     = {2162-2388},
  month    = {Aug},
  number   = {8},
  pages    = {1773-1786},
  volume   = {27},
  abstract = {Attack detection problems in the smart grid are posed as statistical learning problems for different attack scenarios in which the measurements are observed in batch or online settings. In this approach, machine learning algorithms are used to classify measurements as being either secure or attacked. An attack detection framework is provided to exploit any available prior knowledge about the system and surmount constraints arising from the sparse structure of the problem in the proposed approach. Well-known batch and online learning algorithms (supervised and semisupervised) are employed with decision- and feature-level fusion to model the attack detection problem. The relationships between statistical and geometric properties of attack vectors employed in the attack scenarios and learning algorithms are analyzed to detect unobservable attacks using statistical learning methods. The proposed algorithms are examined on various IEEE test systems. Experimental analyses show that machine learning algorithms can detect attacks with performances higher than attack detection algorithms that employ state vector estimation methods in the proposed attack detection framework.},
  doi      = {10.1109/TNNLS.2015.2404803},
  groups   = {First Filtering},
  keywords = {Vectors;Smart grids;Prediction algorithms;Kernel;Statistical learning;Machine learning algorithms;Learning systems;Attack detection;classification;phase transition;smart grid security;sparse optimization},
}

@InProceedings{7417501,
  author    = {Alsemairi, Sami and Younis, Mohamed},
  booktitle = {2015 IEEE Global Communications Conference (GLOBECOM)},
  title     = {Clustering-Based Mitigation of Anonymity Attacks in Wireless Sensor Networks},
  year      = {2015},
  month     = {Dec},
  pages     = {1-7},
  abstract  = {The use of wireless sensor networks (WSNs) can be advantageous in applications that serve in hostile environments such as security surveillance and military battlefield. The operation of a WSN typically involves collection of sensor measurements at an in-situ Base-Station (BS) that further processes the data and either takes action or reports findings to a remote command center. Thus the BS plays a vital role and is usually guarded by concealing its identity and location. However, the BS can be susceptible to traffic analysis attack. Given the limited communication range of the individual sensors and the objective of conserving their energy supply, the sensor readings are forwarded to the BS over multi-hop paths. Such a routing topology allows an adversary to correlate intercepted transmissions, even without being able to decode them, and apply attack models such as Evidence Theory (ET) in order to determine the position of the BS. This paper proposes a technique to counter such an attack by reshaping the routing topology. Basically, the nodes in a WSN are grouped in unevenly-sized clusters and each cluster has a designated aggregation node (cluster head). An inter-cluster head routes are then formed so that the BS experiences low traffic volume and does not become distinguishable among the WSN nodes. The simulation results confirm the effectiveness of the proposed technique in boosting the anonymity of the BS.},
  doi       = {10.1109/GLOCOM.2015.7417501},
  groups    = {First Filtering},
  keywords  = {Wireless sensor networks;Routing;Topology;Receivers;Optimized production technology;Measurement;Security},
}

@InProceedings{8852393,
  author    = {Kocián, Matěj and Pilát, Martin},
  booktitle = {2019 International Joint Conference on Neural Networks (IJCNN)},
  title     = {Using Local Convolutional Units to Defend Against Adversarial Examples},
  year      = {2019},
  month     = {July},
  pages     = {1-8},
  abstract  = {Deep neural networks are known to be sensitive to adversarial examples - inputs that are created in such a way that they are similar (if viewed by people) to clean inputs, but the neural network has high confidence that they belong to another class. In this paper, we study a new type of neural network unit similar to the convolutional units, but with a more local behavior. The unit is based on the Gaussian radial basis function. We show that if we replace the first convolutional layer in a convolutional network by the new layer (called RBFolutional), we obtain better robustness towards adversarial samples on the MNIST and CIFAR10 datasets, without sacrificing the performance on the clean examples.},
  doi       = {10.1109/IJCNN.2019.8852393},
  groups    = {First Filtering},
  issn      = {2161-4407},
  keywords  = {Training;Kernel;Robustness;Computer architecture;Perturbation methods;Radial basis function networks},
}

@Article{9119145,
  author   = {Chen, Zheyi and Tian, Pu and Liao, Weixian and Yu, Wei},
  journal  = {IEEE Transactions on Network Science and Engineering},
  title    = {Zero Knowledge Clustering Based Adversarial Mitigation in Heterogeneous Federated Learning},
  year     = {2021},
  issn     = {2327-4697},
  month    = {April},
  number   = {2},
  pages    = {1070-1083},
  volume   = {8},
  abstract = {The simultaneous development of deep learning techniques and Internet of Things (IoT)/Cyber-physical Systems (CPS) technologies has afforded untold possibilities for improving distributed computing, sensing, and data analysis. Among these technologies, federated learning has received increased attention as a privacy-preserving collaborative learning paradigm, and has shown significant potential in IoT/CPS-driven large-scale smart-world systems. At the same time, the vulnerabilities of deep neural networks, especially to adversarial attacks, cannot be overstated and should not be minimized. Moreover, the distributed nature of federated learning makes defense against such adversarial attacks a more challenging problem due to the unavailability of local data and resource heterogeneity. To tackle these challenges, in this paper, we propose ZeKoC, a Zero Knowledge Clustering approach to mitigating adversarial attacks. Particularly, we first formulate the problem of resource-constrained adversarial mitigation. Specifically, noting that a global server has no access to training samples, we reformulate the unsupervised weight clustering problem. Our proposed ZeKoC approach allows the server to automatically split and merge weight clusters for weight selection and aggregation. Theoretical analysis demonstrates that convergence is guaranteed. Further, our experimental results illustrate that, in a non-i.i.d. (i.e., independent and identically distributed) data setting, the proposed ZeKoC approach successfully mitigates general attacks while outperforming state-of-art schemes.},
  doi      = {10.1109/TNSE.2020.3002796},
  groups   = {First Filtering},
  keywords = {Training;Servers;Peer-to-peer computing;Machine learning;Data models;Security;Distributed databases;Non-i.i.d. data;adversarial mitigation;federated learning},
}

@InProceedings{9014929,
  author    = {Rinaldi, Giulia and Adamsky, Florian and Soua, Ridha and Baiocchi, Andrea and Engel, Thomas},
  booktitle = {2019 10th International Conference on Networks of the Future (NoF)},
  title     = {Softwarization of SCADA: Lightweight Statistical SDN-Agents for Anomaly Detection},
  year      = {2019},
  month     = {Oct},
  pages     = {102-109},
  abstract  = {Given the importance of an early anomaly detection, Intrusion Detection Systems (IDSs) are introduced in Supervisory Control And Data Acquisition (SCADA). Agents or probes form the cornerstone of any IDS by capturing network packets and extracting relevant information. However, IDSs are facing unprecedented challenges due to the escalation in the number, scale and diversity of attacks. Software-Defined Network (SDN) then comes into play and can provide the required flexibility and scalability. Building on that, we introduce Traffic Agent Controllers (TACs) that monitor SDN-enabled switches via Open-Flow. By using lightweight statistical metrics such as Kullback-Leibler Divergence (KLD), we are able to detect the slightest anomalies, such as stealth port scans, even in the presence of background traffic. The obtained metrics can also be used to locate the anomalies with precision over 90% inside a hierarchical network topology.},
  doi       = {10.1109/NoF47743.2019.9014929},
  groups    = {First Filtering},
  keywords  = {Message systems;Monitoring;Protocols;SCADA systems;Anomaly detection;Probes},
}

@InProceedings{9445353,
  author    = {Saraswat, Deepti and Bhattacharya, Pronaya and Zuhair, Mohd and Verma, Ashwin and Kumar, Ashwani},
  booktitle = {2021 2nd International Conference on Intelligent Engineering and Management (ICIEM)},
  title     = {AnSMart: A SVM-based anomaly detection scheme via system profiling in Smart Grids},
  year      = {2021},
  month     = {April},
  pages     = {417-422},
  abstract  = {Anomaly detection techniques analyze consumer spend patterns and grid load profiles to predict possible deviations from normal behavior. However, as the measured data is time-varying, profiling the measured drifts becomes complex owing to the amount of raw generated data. Motivated from the aforementioned discussions, in this paper, we propose a scheme, AnSMart, to predict deviations in smart grid (SG) data through obtained profiling operations. The scheme operates in two phases. In the first phase, valuable grid features are extracted from internal system call lists made by grid kernels after load profiling operations are completed over a day. Then, in the second phase, based on data logs, vector differences are computed for call vectors and malign scenarios are identified. The data is fed to the support vector machine (SVM) model for training, and compromised grid behavior is classified. SVM predicts metrics deviation from normal grids. The deviation is measured depending on parameters like-call vector signal, call-sizes, call-list deviations, and call-return values collected from the open-source libiec61850 library that consists of resource-rich (RR) and resource-limited (RL) libraries for both compromised and uncompromised grids. Based on different cases, a total of 50 experiments were conducted. The obtained F-score is 0.926 and the accuracy of 92.5% is obtained based on system-call stacks and grid operating system (OS) behavior that outperforms the conventional anomaly-based approaches on SG.},
  doi       = {10.1109/ICIEM51511.2021.9445353},
  groups    = {First Filtering},
  keywords  = {Support vector machines;Training;Measurement;Feature extraction;Libraries;Smart grids;Kernel;Smart Grids;Anomaly Detection;System Profiling;Stack call traces},
}

@Article{7544613,
  author   = {Jokar, Paria and Leung, Victor C. M.},
  journal  = {IEEE Transactions on Smart Grid},
  title    = {Intrusion Detection and Prevention for ZigBee-Based Home Area Networks in Smart Grids},
  year     = {2018},
  issn     = {1949-3061},
  month    = {May},
  number   = {3},
  pages    = {1800-1811},
  volume   = {9},
  abstract = {In this paper, we present a novel intrusion detection and prevention system for ZigBee-based home area networks in smart grids, HANIDPS. HANIDPS employs a model-based intrusion detection mechanism as well as a machine learning-based intrusion prevention system to protect the network against a wide range of attack types. The detection module extracts network features and analyzes them to decide whether the network is in a normal state. We use smart energy profile 2.0 specification as well as IEEE 802.15.4 standard to precisely characterize the expected normal behavior. A set of defensive actions are defined for the prevention system which are effective in stopping various attack types. HANIDPS uses Q-learning and through interactions with environment learns the best strategy against an attack. Use of model-based approach for intrusion detection and dynamic learning for intrusion prevention, as well as employment of effective mechanisms to stop the attacks, provide a high performance for HANIDPS without the need for prior knowledge of the attacks. Soundness of the proposed method is evaluated through extensive analysis and experiments.},
  doi      = {10.1109/TSG.2016.2600585},
  groups   = {First Filtering},
  keywords = {Intrusion detection;Smart grids;Protocols;Feature extraction;IEEE 802.15 Standard;Automatic generation control;Smart grid;HAN;IDS;IPS},
}

@InProceedings{9199976,
  author    = {Brandao, Andre and Georgieva, Petia},
  booktitle = {2020 IEEE 10th International Conference on Intelligent Systems (IS)},
  title     = {Log Files Analysis For Network Intrusion Detection},
  year      = {2020},
  month     = {Aug},
  pages     = {328-333},
  abstract  = {Information security remains an unsolved challenge for organizations, because every day brings new and sophisticated cyber-attacks. The implementation of network security operation systems is a new trend in the companies, to permanently monitor the logs and, in case of any anomalous traffic, to detect and hopefully prevent any security incident. These systems generate a huge amount of logs per second to be handled, leading to the need of automated ways to identify the cyber-attacks.In this paper we propose an effective Log-based Intrusion Detection System (LIDS), to predict an attack or not, based on carefully selected features. The logs from various sources are aggregated into one dashboard and the most discriminative features are first determined. For the attack prediction, a few machine learning techniques were comparatively tested, with the Decision tree being the winner. The proposed system is illustrated with the largest publicly available labelled log file dataset KDD Cup 1999.},
  doi       = {10.1109/IS48319.2020.9199976},
  groups    = {First Filtering},
  issn      = {1541-1672},
  keywords  = {Intrusion detection;Feature extraction;Protocols;Principal component analysis;Companies;Local area networks;Intrusion detection;Network logs;machine learning classifiers},
}

@InProceedings{6722547,
  author    = {Hsien-De Huang and Chang-Shing Lee and Mei-Hui Wang and Hung-Yu Kao},
  booktitle = {2013 IEEE International Conference on Systems, Man, and Cybernetics},
  title     = {An IT2FLS-Based Malware Analysis Mechanism: Malware Analysis Network in Taiwan (MiT)},
  year      = {2013},
  month     = {Oct},
  pages     = {4652-4657},
  abstract  = {Malware is one of the problems really existing in the modern post-industrial society. Hackers continuously develop novel techniques to intrude into computer systems for various reasons, so many security researchers should analyze and track new malicious program to protect sensitive information for the computer system. In this paper, we integrate the Interval Type-2 Fuzzy Logic System (IT2FLS) with malware behavioral analysis: Malware Analysis Network in Taiwan (MAN in Taiwan, MiT, and http://MiT.TWMAN.ORG). The core techniques of MiT are as follows: (1) automatically collect the logs the difference operation system to extract unknown behavior information. Also, MiT is able to automatically provide and share samples and reports via the cloud storage mechanism, (2) integrate with IT2FLS to construct the malware analysis domain knowledge for the malware behavior. Simulation results show that the proposed approach can effectively execute the malware behavior analysis, and the constructed system has also been released under GNU General Public License version 3.},
  doi       = {10.1109/SMC.2013.792},
  groups    = {First Filtering},
  issn      = {1062-922X},
  keywords  = {Malware;Ontologies;Computers;Fuzzy logic;Accuracy;Semantics;Type-2 Fuzzy Sets;Interval Type-2 Fuzzy Logic System;Web Ontology Language;Malware Behavioral Analysis;MiT},
}

@InProceedings{9412109,
  author    = {Rippel, Oliver and Mertens, Patrick and Merhof, Dorit},
  booktitle = {2020 25th International Conference on Pattern Recognition (ICPR)},
  title     = {Modeling the Distribution of Normal Data in Pre-Trained Deep Features for Anomaly Detection},
  year      = {2021},
  month     = {Jan},
  pages     = {6726-6733},
  abstract  = {Anomaly Detection (AD) in images is a fundamental computer vision problem and refers to identifying images and/or image substructures that deviate significantly from the norm. Popular AD algorithms commonly try to learn a model of normality from scratch using task specific datasets, but are limited to semi-supervised approaches employing mostly normal data due to the inaccessibility of anomalies on a large scale combined with the ambiguous nature of anomaly appearance. We follow an alternative approach and demonstrate that deep feature representations learned by discriminative models on large natural image datasets are well suited to describe normality and detect even subtle anomalies in a transfer learning setting. Our model of normality is established by fitting a multivariate Gaussian (MVG) to deep feature representations of classification networks trained on ImageNet using normal data only. By subsequently applying the Mahalanobis distance as the anomaly score we outperform the current state of the art on the public MVTec AD dataset, achieving an Area Under the Receiver Operating Characteristic curve of 95.8 ± 1.2% (mean ± SEM) over all 15 classes. We further investigate why the learned representations are discriminative to the AD task using Principal Component Analysis. We find that the principal components containing little variance in normal data are the ones crucial for discriminating between normal and anomalous instances. This gives a possible explanation to the often subpar performance of AD approaches trained from scratch using normal data only. By selectively fitting a MVG to these most relevant components only, we are able to further reduce model complexity while retaining AD performance. We also investigate setting the working point by selecting acceptable False Positive Rate thresholds based on the MVG assumption. Code is publicly available at https://github.com/ORippler/gaussian-ad-mvtec.},
  doi       = {10.1109/ICPR48806.2021.9412109},
  groups    = {First Filtering},
  issn      = {1051-4651},
  keywords  = {Training;Computer vision;Fitting;Transfer learning;Receivers;Feature extraction;Data models},
}

@Article{8658084,
  author   = {Xue, Dongbo and Jing, Xiaorong and Liu, Hongqing},
  journal  = {IEEE Access},
  title    = {Detection of False Data Injection Attacks in Smart Grid Utilizing ELM-Based OCON Framework},
  year     = {2019},
  issn     = {2169-3536},
  pages    = {31762-31773},
  volume   = {7},
  abstract = {False data injection (FDI) attacks, as a new class of cyberattacks, bring a severe threat to the security and reliable operation of the smart grid by damaging the state estimation of the power system. To address this issue, an extreme learning machine (ELM)-based one-class-one-network (OCON) framework is proposed for detecting the FDI attacks in this paper. Under this framework, to effectively detect bus-based FDI attacks and identify the bus node being attacked, the subnets of state identification layer in OCON adopt the ELM algorithm to accurately divide the false data and the normal data. After that, a global layer is employed to analyze whether the bus node associated with its corresponding subnet is attacked by false data utilizing the results from the state identification layer. Finally, in order to improve the resilience of the power system, a prediction recovery strategy is proposed to remedy the detected false data by exploiting the spatial correlation of power data. The proposed framework is tested on the IEEE 14 bus system using real load data from New York independent system operator. The simulation results demonstrate that the proposed framework not only accurately recognizes the multiple bus nodes under the FDI attacks but also efficiently recovers the data injected by false data.},
  doi      = {10.1109/ACCESS.2019.2902910},
  groups   = {First Filtering},
  keywords = {State estimation;Smart grids;Transmission line measurements;Meters;Computer crime;Resilience;Smart grid;false data injection (FDI) attacks;extreme learning machine (ELM);one-class-one-network (OCON)},
}

@InProceedings{9014348,
  author    = {Alagrash, Yasamin and Mohan, Nithasha and Gollapalli, Sandhya Rani and Rrushi, Julian},
  booktitle = {2019 First IEEE International Conference on Trust, Privacy and Security in Intelligent Systems and Applications (TPS-ISA)},
  title     = {Machine Learning and Recognition of User Tasks for Malware Detection},
  year      = {2019},
  month     = {Dec},
  pages     = {73-81},
  abstract  = {Malware often act on a compromised machine with the identifier of a legitimate user. We analyzed numerous malware and user tasks, and found subtle differences between how the two operate on a machine. We have developed a machine learning approach that characterizes user tasks through their resource utilization. We have found that many routine user tasks retain their resource utilization patterns, despite the occurrence of new dynamics each time a user carries out those tasks. On the other hand, upon landing on a target machine, malware perform a substantial amount of work to explore the machine and discover resources that are of interest to threat actors. Our approach collects live performance counter data from the operating system kernel, and subsequently pre-processes and analyzes those data to learn and then recognize the resource utilization of a task. We develop decoy process mechanisms that camouflage performance counter data to prevent malware from learning the resource utilization of a user task. We tested our approach against both legitimate users in real-world work settings and malware samples, and discuss our findings in the paper.},
  doi       = {10.1109/TPS-ISA48467.2019.00018},
  groups    = {First Filtering},
  keywords  = {Task analysis;Malware;Resource management;Machine learning;Kernel;Hidden Markov models;Performance evaluation;Malware, compromised computer account, Machine learning;decoy process mechanisms},
}

@InProceedings{9002854,
  author    = {Liu, Jia and Jin, Yaochu},
  booktitle = {2019 IEEE Symposium Series on Computational Intelligence (SSCI)},
  title     = {Evolving Hyperparameters for Training Deep Neural Networks against Adversarial Attacks},
  year      = {2019},
  month     = {Dec},
  pages     = {1778-1785},
  abstract  = {Deep neural networks have been found to be vulnerable to adversarial attacks. To address this challenge, this paper adopts the evolutionary multi-objective approach to the learning process, and manages to achieve a balance between learning accuracy and robustness against adversarial attacks. In addition, we propose to minimize the model complexity together with the adversarial training loss to defend against fast gradient signed method attacks. Our experimental results using two deep neural networks models, LeNet-5 and VGG-11, on MNIST and CIFAR-10 datasets, respectively, confirm that the proposed methods are effective in improving the robustness of deep learning models against adversarial attacks.},
  doi       = {10.1109/SSCI44817.2019.9002854},
  groups    = {First Filtering},
  keywords  = {Robustness;Training;Sociology;Statistics;Complexity theory;Neural networks;Optimization;deep neural networks;adversarial examples;robustness;multi-objective learning;hyperparameters;complexity},
}

@InProceedings{9369591,
  author    = {Sadeghpour, Shadi and Vlajic, Natalija and Madani, Pooria and Stevanovic, Dusan},
  booktitle = {2021 IEEE 18th Annual Consumer Communications Networking Conference (CCNC)},
  title     = {Unsupervised ML Based Detection of Malicious Web Sessions with Automated Feature Selection: Design and Real-World Validation},
  year      = {2021},
  month     = {Jan},
  pages     = {1-9},
  abstract  = {As Web bot technologies continue to evolve, the task of separating human Web sessions from those generated by malicious bots becomes increasingly more challenging. To date, many research studies have proposed the use of advanced ML-based methods as automated means of differentiating between Web bot and genuine human sessions. Unfortunately, most of these studies overlook the importance of adequate feature selection during the dataset preprocessing stage. Namely, instead of making the process of feature selection automated and optimized to each particular dataset, these studies generally resort to the use of the same fixed set of hand-picked Web-session attributes. It is well known, however, that suboptimal approach to feature selection is likely to result in suboptimal performance of the respective ML algorithm and, consequently, of the entire system. The main contributions of our work are as follows: First, we propose the use of Gradient Boosting Technique to automatically identify the most significant Web-session features (out of an extensive list of 119 possible attributes) for any given dataset. Second, we integrate this automated features selection technique into a system for Web-session classification based on the unsupervised Self-Organizing Map (SOM) algorithm. Third, we validate the performance of the integrated system on a recent real-world dataset which has been collected during a confirmed large-scale attack on our home institution. The obtained experimental results not only verify that our proposed system is highly effective in identifying malicious Web-sessions, but they also help us better understand the nature and scale of the conducted attack itself.},
  doi       = {10.1109/CCNC49032.2021.9369591},
  groups    = {First Filtering},
  issn      = {2331-9860},
  keywords  = {Self-organizing feature maps;Predictive models;Feature extraction;Boosting;Web servers;Security;Task analysis;Web server access logs;Apache Spark;Outlier detection;Gradient boosting;SOM algorithm},
}

@InProceedings{9207034,
  author    = {Gandhi, Apurva and Jain, Shomik},
  booktitle = {2020 International Joint Conference on Neural Networks (IJCNN)},
  title     = {Adversarial Perturbations Fool Deepfake Detectors},
  year      = {2020},
  month     = {July},
  pages     = {1-8},
  abstract  = {This work uses adversarial perturbations to enhance deepfake images and fool common deepfake detectors. We created adversarial perturbations using the Fast Gradient Sign Method and the Carlini and Wagner L2 norm attack in both blackbox and whitebox settings. Detectors achieved over 95% accuracy on unperturbed deepfakes, but less than 27% accuracy on perturbed deepfakes. We also explore two improvements to deep-fake detectors: (i) Lipschitz regularization, and (ii) Deep Image Prior (DIP). Lipschitz regularization constrains the gradient of the detector with respect to the input in order to increase robustness to input perturbations. The DIP defense removes perturbations using generative convolutional neural networks in an unsupervised manner. Regularization improved the detection of perturbed deepfakes on average, including a 10% accuracy boost in the blackbox case. The DIP defense achieved 95% accuracy on perturbed deepfakes that fooled the original detector while retaining 98% accuracy in other cases on a 100 image subsample.},
  doi       = {10.1109/IJCNN48605.2020.9207034},
  groups    = {First Filtering},
  issn      = {2161-4407},
  keywords  = {Perturbation methods;Detectors;Faces;Electronics packaging;Training;Neural networks;Generative adversarial networks;Deepfakes;Adversarial perturbations;Lipschitz regularization;Deep Image Prior;Image restoration},
}

@InProceedings{6617840,
  author    = {Cannady, James},
  booktitle = {2013 World Congress on Nature and Biologically Inspired Computing},
  title     = {The detection of temporally distributed network attacks using an adaptive hierarchical neural network},
  year      = {2013},
  month     = {Aug},
  pages     = {5-9},
  abstract  = {The accurate detection of attacks in ad hoc computer networks is made significantly more difficult if the components of the attack sequence are distributed throughout the network data stream. Since current approaches to detecting network intrusions rely on associating individual network actions the temporal distribution of an attack throughout a network makes it extremely difficult to accurately identify the intrusion. This paper describes an approach to detecting temporally distributed attacks based on a modified Hierarchical Quilted Self-Organizing Map (HQSOM). The HQSOM approach emulates some aspects of biological neural networks by distributing the reasoning capability throughout a hierarchical structure. The approach described here combines an adaptive learning parameter with variable spatial and temporal clustering to associate the components of the attack. The results of the evaluation of the approach and opportunities for additional research are also described.},
  doi       = {10.1109/NaBIC.2013.6617840},
  groups    = {First Filtering},
  keywords  = {Vectors;Neural networks;self-organizing maps;intrusion detection;distributed reasoning},
}

@InProceedings{9445946,
  author    = {Wang, Na and Chen, Ruoyan and Xu, Kang},
  booktitle = {2021 International Conference on Communications, Information System and Computer Engineering (CISCE)},
  title     = {A Real-time Object Detection Solution and Its Application in Transportation},
  year      = {2021},
  month     = {May},
  pages     = {486-491},
  abstract  = {Object Detection Algorithms is widely used in transportation. With YOLOv3 however, it is impossible to achieve real-time detection. This paper made some adjustments to YOLOv3, and proposed a new light-scale model named MobileNetv1_yolov3lite. In our MobileNetv1_yolov3lite, we use MobileNetv1 instead of Darknet53 as our backbone network, and we use a newly proposed module yolov3lite for feature fusion. These adjustments achieve significant increases in detecting speed, and can achieve real-time detection. However, it suffers from accuracy loss. In order to improve detecting accuracy, we further modify loss function as well as training methods, which contributes to a higher accuracy.},
  doi       = {10.1109/CISCE52179.2021.9445946},
  groups    = {First Filtering},
  keywords  = {Training;Computational modeling;Transportation;Object detection;Feature extraction;Real-time systems;Computational complexity;Real-time Object Detection;MobileNetv1;Yolov3},
}

@InProceedings{9331106,
  author    = {Tang, Long and Yu, Bin},
  booktitle = {2020 7th International Conference on Dependable Systems and Their Applications (DSA)},
  title     = {Generating Adversarial Examples in Limited Queries with Image Encoding and Noise Decoding},
  year      = {2020},
  month     = {Nov},
  pages     = {285-292},
  abstract  = {Deep neural network (DNN) has been widely used in many application scenarios, but it is easy to be affected by slight disturbance, which is referred to as adversarial examples, and produces wrong decisions endangering system security. It is difficult to obtain the structure and parameter information of the target network in the actual scene. In this paper, we propose an optimization-based method to generate adversarial examples. Inspired by the autoencoder and Conditional Generative Adversarial Net (CGAN), we train the encoder to encode the image into latent vector, of which the specific region (category field) is used to represent the category information of the image, and then train the decoder to generate adversarial examples of the specified category. We perform Natural Evolution Strategy in the low-dimensional latent space to further improve the attack. The result shows that our method can successfully attack the target network within only one or a few queries. We evaluate our method on Sign-Language-Digits (SLD) and Cifar-10 datasets. Compared with other methods, our approach can attack the target model with less queries, and maintain a high success rate.},
  doi       = {10.1109/DSA51864.2020.00051},
  groups    = {First Filtering},
  keywords  = {Image coding;Semantics;Neural networks;Superluminescent diodes;Decoding;Planning;Security;Adversarial examples;DNN security;Autoencoder;optimization-based attack},
}

@InProceedings{9338269,
  author    = {Wang, Chun and Han, Bo and Pan, Shirui and Jiang, Jing and Niu, Gang and Long, Guodong},
  booktitle = {2020 IEEE International Conference on Data Mining (ICDM)},
  title     = {Cross-Graph: Robust and Unsupervised Embedding for Attributed Graphs with Corrupted Structure},
  year      = {2020},
  month     = {Nov},
  pages     = {571-580},
  abstract  = {Graph embedding has shown its effectiveness to represent graph information and capture deep relationships in graph data. Most recent graph embedding methods focus on attributed graphs, since they preserve both structure and content information in the network. However, corruption can exist in the graph structure as well as the node content of the graph, and both can lead to inferior embedding results. Unfortunately, few existing graph embedding algorithms have considered the corruption problem, and to the best of our knowledge, none has studied structural corruption in attributed graphs, including missing and redundant edges. This field is difficult for previous methods, mainly due to two challenges: (1) the existence of various corruption causes has made it difficult to recognize corruptions in graphs, and (2) the complexity of graph-structured data has increased the difficulty of handling corruption therein for graph embedding methods. These facts lead us here to propose a novel autoencoder-based graph embedding approach, which is robust against structural corruption. Our idea comes from the recent discovery of memorization effects in deep learning. Namely, deep neural networks prefer to fit clean data first, before they over-fit corrupted data. Specifically, we train two autoencoders simultaneously and let them learn the reliability of the edges in the graph from each other. The two autoencoders would evaluate the edges according to their reconstructed structure and manipulate this by devaluing those distrusted edges to update the structure information. The updated structure would be used further in the next iteration as the ground-truth of its peer-network. Experiments on different versions of real-world graphs show state-of-the-art results and demonstrate the robustness of our model against structural corruption.},
  doi       = {10.1109/ICDM50108.2020.00066},
  groups    = {First Filtering},
  issn      = {2374-8486},
  keywords  = {Deep learning;Conferences;Neural networks;Filtering algorithms;Robustness;Peer-to-peer computing;Data mining;Graph autoencoder;graph convolutional network;network representation;structural corruption},
}

@Article{7902104,
  author   = {He, Daojing and Chan, Sammy and Ni, Xiejun and Guizani, Mohsen},
  journal  = {IEEE Internet of Things Journal},
  title    = {Software-Defined-Networking-Enabled Traffic Anomaly Detection and Mitigation},
  year     = {2017},
  issn     = {2327-4662},
  month    = {Dec},
  number   = {6},
  pages    = {1890-1898},
  volume   = {4},
  abstract = {Traffic anomaly detection has been a principal direction in the network security field, which aims to identify attacks based on significant deviations from the established normal usage profiles. Recently, a new networking paradigm, software defined networking (SDN), has emerged to facilitate effective network control and management. In this paper, we present the advantages of leveraging SDN to detect traffic anomaly, and review recent progresses in this direction. Despite their effectiveness for traditional traffic, SDN-based traffic anomaly detection methods have to face the challenge of continuously increasing network traffic. To this end, we propose two refined algorithms to be used in an anomaly detection framework which can handle voluminous data, and report some experimental results to demonstrate their performance.},
  doi      = {10.1109/JIOT.2017.2694702},
  groups   = {First Filtering},
  keywords = {Clustering algorithms;Algorithm design and analysis;Feature extraction;Training data;Computer crime;Intrusion detection;Clustering;feature selection;traffic anomaly},
}

@InProceedings{8569911,
  author    = {Bijelic, Mario and Muench, Christian and Ritter, Werner and Kalnishkan, Yuri and Dietmayer, Klaus},
  booktitle = {2018 21st International Conference on Intelligent Transportation Systems (ITSC)},
  title     = {Robustness Against Unknown Noise for Raw Data Fusing Neural Networks},
  year      = {2018},
  month     = {Nov},
  pages     = {2177-2184},
  abstract  = {Adverse weather conditions are extremely challenging for autonomous driving as most state-of-the-art sensors do not function reliably under such circumstances. One method to increase the detection performance is to fuse the raw data signal with neural networks that learn robust features from multiple inputs. Nevertheless noise due to adverse weather is complex, and in addition, automotive sensors fail asymmetrically. Neural networks that perform feature level sensor fusion can be particularly vulnerable if one sensor is corrupted by noise outside the training data distribution compared to decision level fusion. The reason for this is that no built-in mathematical mechanism prevents noise in one sensor channel from corrupting the overall network even though other sensor channels may provide high-quality data. We propose a simple data augmentation scheme that shows a neural network may be able to ignore data from underperforming sensors even though it has never seen that data during training. One can summarize this as a learned “OR” operation at fusion stage. This learned operation is also generally applicable to other noise-types not present during training.},
  doi       = {10.1109/ITSC.2018.8569911},
  groups    = {First Filtering},
  issn      = {2153-0017},
  keywords  = {Neural networks;Training;Laser radar;Cameras;Sensor fusion;Feature extraction},
}

@InProceedings{8637390,
  author    = {Liu, Liu and De Vel, Olivier and Chen, Chao and Zhang, Jun and Xiang, Yang},
  booktitle = {2018 IEEE International Conference on Data Mining Workshops (ICDMW)},
  title     = {Anomaly-Based Insider Threat Detection Using Deep Autoencoders},
  year      = {2018},
  month     = {Nov},
  pages     = {39-48},
  abstract  = {In recent years, the malicious insider threat has become one of the most significant cyber security threats that an organisation can be subject to. Due to an insider's natural ability to evade deployed information security mechanisms such as firewalls and endpoint protections, the detection of an insider threat can be challenging. Moreover, compared to the volume of audit data that an organization collects for the purpose of intrusion/anomaly detection, the digital footprint left by a malicious insider's action can be minuscule. To detect insider threats from large and complex audit data, in this paper, we propose a detection system that implements anomaly detection using an ensemble of deep autoencoders. Each autoencoder in the ensemble is trained using a certain category of audit data, which represents a user's normal behaviour accurately. The reconstruction error obtained between the original and the decoded data is used to measure whether any behaviour is anomalous or not. After the data has been processed by the individually trained autoencoders and the respective reconstruction errors obtained, a joint decision-making mechanism is used to report a user's overall maliciousness score. Numerical experiments are conducted using a benchmark dataset for insider threat detection. Results indicate that the proposed detection system is able to detect all of the malicious insider actions with a reasonable false positive rate.},
  doi       = {10.1109/ICDMW.2018.00014},
  groups    = {First Filtering},
  issn      = {2375-9259},
  keywords  = {Feature extraction;Deep learning;Data mining;Australia;Software;Electrical engineering;Computers;Insider threats, data analytics, deep autoencoder, cyber security},
}

@Article{8611298,
  author   = {Yuan, Xiaoyong and He, Pan and Zhu, Qile and Li, Xiaolin},
  journal  = {IEEE Transactions on Neural Networks and Learning Systems},
  title    = {Adversarial Examples: Attacks and Defenses for Deep Learning},
  year     = {2019},
  issn     = {2162-2388},
  month    = {Sep.},
  number   = {9},
  pages    = {2805-2824},
  volume   = {30},
  abstract = {With rapid progress and significant successes in a wide spectrum of applications, deep learning is being applied in many safety-critical environments. However, deep neural networks (DNNs) have been recently found vulnerable to well-designed input samples called adversarial examples. Adversarial perturbations are imperceptible to human but can easily fool DNNs in the testing/deploying stage. The vulnerability to adversarial examples becomes one of the major risks for applying DNNs in safety-critical environments. Therefore, attacks and defenses on adversarial examples draw great attention. In this paper, we review recent findings on adversarial examples for DNNs, summarize the methods for generating adversarial examples, and propose a taxonomy of these methods. Under the taxonomy, applications for adversarial examples are investigated. We further elaborate on countermeasures for adversarial examples. In addition, three major challenges in adversarial examples and the potential solutions are discussed.},
  doi      = {10.1109/TNNLS.2018.2886017},
  groups   = {First Filtering},
  keywords = {Task analysis;Security;Data models;Deep learning;Feature extraction;Computer architecture;Computational modeling;Adversarial examples;deep learning (DL);deep neural network (DNN);security},
}

@Article{9206141,
  author   = {Li, Haofeng and Zeng, Yirui and Li, Guanbin and Lin, Liang and Yu, Yizhou},
  journal  = {IEEE Transactions on Image Processing},
  title    = {Online Alternate Generator Against Adversarial Attacks},
  year     = {2020},
  issn     = {1941-0042},
  pages    = {9305-9315},
  volume   = {29},
  abstract = {The field of computer vision has witnessed phenomenal progress in recent years partially due to the development of deep convolutional neural networks. However, deep learning models are notoriously sensitive to adversarial examples which are synthesized by adding quasi-perceptible noises on real images. Some existing defense methods require to re-train attacked target networks and augment the train set via known adversarial attacks, which is inefficient and might be unpromising with unknown attack types. To overcome the above issues, we propose a portable defense method, online alternate generator, which does not need to access or modify the parameters of the target networks. The proposed method works by online synthesizing another image from scratch for an input image, instead of removing or destroying adversarial noises. To avoid pretrained parameters exploited by attackers, we alternately update the generator and the synthesized image at the inference stage. Experimental results demonstrate that the proposed defensive scheme and method outperforms a series of state-of-the-art defending models against gray-box adversarial attacks.},
  doi      = {10.1109/TIP.2020.3025404},
  groups   = {First Filtering},
  keywords = {Generators;Training;Perturbation methods;Knowledge engineering;Convolutional neural networks;Deep learning;Computational modeling;Deep neural network;adversarial attack;image classification},
}

@InProceedings{9042544,
  author    = {Singh, Vivek Kumar and Vaughan, Evan and Rivera, Joshua and Hasandka, Adarsh},
  booktitle = {2020 IEEE Texas Power and Energy Conference (TPEC)},
  title     = {HIDES: Hybrid Intrusion Detector for Energy Systems},
  year      = {2020},
  month     = {Feb},
  pages     = {1-6},
  abstract  = {The following topics are dealt with: power grids; distributed power generation; power engineering computing; voltage control; optimisation; load flow; smart power grids; power generation control; power system security; power generation economics.},
  doi       = {10.1109/TPEC48276.2020.9042544},
  groups    = {First Filtering},
}

@InProceedings{7391336,
  author    = {Lee, Jong-Hoon and Kim, Ik Kyun and Han, Ki-Jun},
  booktitle = {2015 IEEE 5th International Conference on Consumer Electronics - Berlin (ICCE-Berlin)},
  title     = {An Abnormal Connection Detection System based on network flow analysis},
  year      = {2015},
  month     = {Sep.},
  pages     = {71-75},
  abstract  = {Recently, cyber-targeted attacks such as APT are rapidly growing as a social and national security threat. For this, our paper aims to cope with the cyber-targeted attack for recognizing the abnormal network connections with the flow data analysis method prior to the attacks being executed. The proposed Abnormal Connection Detection System can detect anomalous network connections by means of a statistical analysis and was evaluated in the experimental testbeds environment where the system was practically deployed.},
  doi       = {10.1109/ICCE-Berlin.2015.7391336},
  groups    = {First Filtering},
  keywords  = {Conferences;Consumer electronics;network flow analysis;APT detection;Abnormal behavior detection;Security intelligence technology},
}

@InProceedings{9469037,
  author    = {Kees, Natasha and Wang, Yaxuan and Jiang, Yiling and Lue, Fang and Chan, Patrick P.K.},
  booktitle = {2020 International Conference on Machine Learning and Cybernetics (ICMLC)},
  title     = {Segmentation Based Backdoor Attack Detection},
  year      = {2020},
  month     = {Dec},
  pages     = {298-302},
  abstract  = {Backdoor attacks have become a serious security concern because of the rising popularity of unverified third party machine learning resources such as datasets, pretrained models, and processors. Pre-trained models and shared datasets have become popular due to the high training requirement of deep learning. This raises a serious security concern since the shared models and datasets may be modified intentionally in order to reduce system efficacy. A backdoor attack is difficult to detect since the embedded adversarial decision rule will only be triggered by a pre-chosen pattern, and the contaminated model behaves normally on benign samples. This paper devises a backdoor attack detection method to identify whether a sample is attacked for image-related applications. The information consistence provided by an image without each segment is considered. The absence of the segment containing a trigger strongly affects the consistence since the trigger dominates the decision. Our proposed method is evaluated empirically to confirm the effectiveness in various settings. As there is no restrictive assumption on the trigger of backdoor attacks, we expect our proposed model is generalizable and can defend against a wider range of modern attacks.},
  doi       = {10.1109/ICMLC51923.2020.9469037},
  groups    = {First Filtering},
  issn      = {2160-1348},
  keywords  = {Training;Deep learning;Image segmentation;Program processors;Feature extraction;Security;Cybernetics;Machine learning;Backdoor attack;Deep neural networks;Segmentation;Adversarial machine learning},
}

@Article{8105800,
  author   = {Meng, Weizhi and Li, Wenjuan and Su, Chunhua and Zhou, Jianying and Lu, Rongxing},
  journal  = {IEEE Access},
  title    = {Enhancing Trust Management for Wireless Intrusion Detection via Traffic Sampling in the Era of Big Data},
  year     = {2018},
  issn     = {2169-3536},
  pages    = {7234-7243},
  volume   = {6},
  abstract = {Internet of Things (IoT) has been widely used in our daily life, which enables various objects to be interconnected for data exchange, including physical devices, vehicles, and other items embedded with network connectivity. Wireless sensor network (WSN) is a vital application of IoT, providing many kinds of information among sensors, whereas such network is vulnerable to a wide range of attacks, especially insider attacks, due to its natural environment and inherent unreliable transmission. To safeguard its security, intrusion detection systems (IDSs) are widely adopted in a WSN to defend against insider attacks through implementing proper trust-based mechanisms. However, in the era of big data, sensors may generate excessive information and data, which could degrade the effectiveness of trust computation. In this paper, we focus on this challenge and propose a way of combining Bayesian-based trust management with traffic sampling for wireless intrusion detection under a hierarchical structure. In the evaluation, we investigate the performance of our approach in both a simulated and a real network environment. Experimental results demonstrate that packet-based trust management would become ineffective in a heavy traffic environment, and that our approach can help lighten the burden of IDSs in handling traffic, while maintaining the detection of insider attacks.},
  doi      = {10.1109/ACCESS.2017.2772294},
  groups   = {First Filtering},
  keywords = {Wireless sensor networks;Sensors;Intrusion detection;Big Data;Bayes methods;Wireless communication;Intrusion detection;traffic sampling;wireless sensor network;trust computation;Bayesian model;big data},
}

@Article{9159905,
  author   = {Li, Weiwei and Su, Zhou and Zhang, Kuan and Benslimane, Abderrahim and Fang, Dongfeng},
  journal  = {IEEE Transactions on Network Science and Engineering},
  title    = {Defending Malicious Check-In Using Big Data Analysis of Indoor Positioning System: An Access Point Selection Approach},
  year     = {2020},
  issn     = {2327-4697},
  month    = {Oct},
  number   = {4},
  pages    = {2642-2655},
  volume   = {7},
  abstract = {The integration of WiFi fingerprint-based indoor positioning technology and big data analysis emerges as a new research prospect. Through the analysis of big data collected from users' submission, we can discover many other applications of fingerprint positioning. A popular application is the check-in to point of interest (POI) for its crowd traffic evaluation according to the volume of received signal strength (RSS) fingerprints submitted by users. However, this crowd traffic evaluation method may be susceptible to the intrusion of malicious check-in behaviors. Attackers who are not at the target POI submit the self-modification RSS fingerprints that can be located at the target POI in order to illegally increase its crowd traffic. To this end, we propose a malicious check-in defense scheme based on the access point (AP) selection to resist attackers who aim to successfully initiate the fingerprint modification. Specifically, the distance between different POIs in fingerprint space is firstly developed for AP selection. Then, in order to increase the robustness of selected AP subset, we propose the mutual information among different classes as a selection condition. Through the multiobjective optimization and Pareto optimality, we can obtain the best AP subset to participate in the computation of positioning algorithm. Furthermore, the optimal modified fingerprint is searched by the level set method (LSM), which can be utilized to measure the costs of attackers and the robustness of the system. In addition, we propose an iterative weight updating method based on classification error to learn the optimal weight in order to balance the positioning accuracy and robustness. We finally carry out extensive simulations to validate that the POI crowd traffic can be assessed in terms of the RSS fingerprint-related information and our proposed scheme can perform high robustness to resist malicious check-in.},
  doi      = {10.1109/TNSE.2020.3014384},
  groups   = {First Filtering},
  keywords = {Wireless fidelity;Robustness;Big Data;Feature extraction;Optimization;Data analysis;Mobile handsets;Fingerprint positioning;big data analytics;AP selection;crowd traffic evaluation;robustness},
}

@Article{8667814,
  author   = {Rasool, Raihan Ur and Ashraf, Usman and Ahmed, Khandakar and Wang, Hua and Rafique, Wajid and Anwar, Zahid},
  journal  = {IEEE Access},
  title    = {Cyberpulse: A Machine Learning Based Link Flooding Attack Mitigation System for Software Defined Networks},
  year     = {2019},
  issn     = {2169-3536},
  pages    = {34885-34899},
  volume   = {7},
  abstract = {Software-defined networking (SDN) offers a novel paradigm for effective network management by decoupling the control plane from the data plane thereby allowing a high level of manageability and programmability. However, the notion of a centralized controller becomes a bottleneck by opening up a host of vulnerabilities to various types of attacks. One of the most harmful, stealthy, and easy to launch attacks against networked systems is the link flooding attack (LFA). In this paper, we demonstrate the vulnerability of the SDN control layer to LFA and how the attack strategy differs when targeting traditional networks which primarily involves attacking the links directly. In LFA, the attacker employs bots to surreptitiously send low rate legitimate traffic on the control channel which ultimately results in disconnecting control plane from the data plane. Mitigating LFA on the control channel remains a challenge in the network security paradigm with the use of network traffic filtering only. To address this challenge, we propose CyberPulse, a novel effective countermeasure, underpinning a machine learning-based classifier to alleviate LFA in SDN. CyberPulse performs network surveillance by classifying network traffic using deep learning techniques and is implemented as an extension module in the Floodlight controller. CyberPulse was evaluated for its accuracy, false positive rate, and effectiveness as compared to competing approaches on realistic networks generated using Mininet. The results show that CyberPulse can classify malicious flows with high accuracy and mitigate them effectively.},
  doi      = {10.1109/ACCESS.2019.2904236},
  groups   = {First Filtering},
  keywords = {Servers;Software;Machine learning algorithms;Switches;Security;Deep learning;Link flooding attacks;SDN security;OpenFlow;deep learning},
}

@InProceedings{9304935,
  author    = {Baweja, Yashasvi and Oza, Poojan and Perera, Pramuditha and Patel, Vishal M.},
  booktitle = {2020 IEEE International Joint Conference on Biometrics (IJCB)},
  title     = {Anomaly Detection-Based Unknown Face Presentation Attack Detection},
  year      = {2020},
  month     = {Sep.},
  pages     = {1-9},
  abstract  = {Anomaly detection-based spoof attack detection is a recent development in face Presentation Attack Detection (fPAD), where a spoof detector is learned using only non-attacked images of users. These detectors are of practical importance as they are shown to generalize well to new attack types. In this paper, we present a deep-learning solution for anomaly detection-based spoof attack detection where both classifier and feature representations are learned together end-to-end. First, we introduce a pseudo-negative class during training in the absence of attacked images. The pseudo-negative class is modeled using a Gaussian distribution whose mean is calculated by a weighted running mean. Secondly, we use pairwise confusion loss to further regularize the training process. The proposed approach benefits from the representation learning power of the CNNs and learns better features for fPAD task as shown in our ablation study. We perform extensive experiments on four publicly available datasets: Replay-Attack, Rose-Youtu, OULU-NPU and Spoof in Wild to show the effectiveness of the proposed approach over the previous methods. Code is available at: https://github.com/yashasvi97/IJCB2020_anomaly.},
  doi       = {10.1109/IJCB48548.2020.9304935},
  groups    = {First Filtering},
  issn      = {2474-9699},
  keywords  = {Feature extraction;Training;Face recognition;Support vector machines;Biological system modeling;Faces;Authentication},
}

@InProceedings{9064243,
  author    = {Jing, Huiyun and Meng, Chengrui and He, Xin and Wei, Wei},
  booktitle = {2019 IEEE 5th International Conference on Computer and Communications (ICCC)},
  title     = {Black Box Explanation Guided Decision-Based Adversarial Attacks},
  year      = {2019},
  month     = {Dec},
  pages     = {1592-1596},
  abstract  = {Adversarial attacks have been the hot research field in artificial intelligence security. Decision-based black-box adversarial attacks are much more appropriate in the real-world scenarios, where only the final decisions of the targeted deep neural networks are accessible. However, since there is no available guidance for searching the imperceptive adversarial perturbation, boundary attack, one of the best performing decision-based black-box attacks, carries out computationally expensive search. For improving attack efficiency, we propose a novel black box explanation guided decision-based black-box adversarial attack. Firstly, the problem of decision-based adversarial attacks is modeled as a derivative-free and constraint optimization problem. To solve this optimization problem, the black box explanation guided constrained random search method is proposed to more quickly find the imperceptible adversarial example. The insights into the targeted deep neural networks explored by the black box explanation are fully used to accelerate the computationally expensive random search. Experimental results demonstrate that our proposed attack improves the attack efficiency by 64% compared with boundary attack.},
  doi       = {10.1109/ICCC47050.2019.9064243},
  groups    = {First Filtering},
  keywords  = {Neural networks;Cats;Perturbation methods;Computational modeling;Training data;Logistics;Constraint optimization;black box explanation;decision-based adversarial attacks;derivative-free and constraint optimization problem;artificial intelligence security},
}

@InProceedings{8953314,
  author    = {Zhao, Jake Junbo and Cho, Kyunghyun},
  booktitle = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Retrieval-Augmented Convolutional Neural Networks Against Adversarial Examples},
  year      = {2019},
  month     = {June},
  pages     = {11555-11563},
  abstract  = {We propose a retrieval-augmented convolutional network (RaCNN) and propose to train it with local mixup, a novel variant of the recently proposed mixup algorithm. The proposed hybrid architecture combining a convolutional network and an off-the-shelf retrieval engine was designed to mitigate the adverse effect of off-manifold adversarial examples, while the proposed local mixup addresses on-manifold ones by explicitly encouraging the classifier to locally behave linearly on the data manifold. Our evaluation of the proposed approach against seven readilyavailable adversarial attacks on three datasets-CIFAR-10, SVHN and ImageNet-demonstrate the improved robustness compared to a vanilla convolutional network, and comparable performance with the state-of-the-art reactive defense approaches.},
  doi       = {10.1109/CVPR.2019.01183},
  groups    = {First Filtering},
  issn      = {2575-7075},
  keywords  = {Recognition: Detection;Categorization;Retrieval;Deep Learning},
}

@InProceedings{9407328,
  author    = {Ghorbani, Mohammad Mahdi and Moghaddam, Fereydoun Farrahi and Zhang, Mengyuan and Pourzandi, Makan and Nguyen, Kim Khoa and Cheriet, Mohamed},
  booktitle = {2020 IEEE International Conference on Cloud Computing Technology and Science (CloudCom)},
  title     = {Malchain: Virtual Application Behaviour Profiling by Aggregated Microservice Data Exchange Graph},
  year      = {2020},
  month     = {Dec},
  pages     = {41-48},
  abstract  = {In the recent literature, Machine Learning (ML) techniques are increasingly used to detect the abnormal behaviour for different applications. Recently, these applications have moved to the cloud and virtualized environments due to the unique benefits such as deployment agility, scalability, flexibility and resiliency. However, those benefits pose a new challenge for classical ML approaches to accurately identify abnormal behaviours due to their highly dynamic and heterogeneous nature. In this paper, we propose a new approach Malchain for profiling virtual applications based on using a new concept: microservice role. The roles are used to provide a consistent view of the virtual application addressing the mentioned new challenges. The microservice data exchange graph built using this consistent view is then used to extract features providing the appropriate measures to profile the aggregated behaviour of the microservices comprising a virtual application. We show the efficiency and feasibility of our approach by implementing several different real-world attacks, and measuring high detection rates (86%-99%) for those attacks.},
  doi       = {10.1109/CloudCom49646.2020.00004},
  groups    = {First Filtering},
  issn      = {2330-2186},
  keywords  = {Computers;Cloud computing;Scalability;Conferences;Machine learning;Feature extraction;Market research;behaviour profiling;anomaly detection;microservice;machine learning;graph vectorization},
}

@InProceedings{9449635,
  author    = {Haque, Nur Imtiazul and Shahriar, Md Hasan and Dastgir, Md Golam and Debnath, Anjan and Parvez, Imtiaz and Sarwat, Arif and Rahman, Mohammad Ashiqur},
  booktitle = {2020 52nd North American Power Symposium (NAPS)},
  title     = {A Survey of Machine Learning-based Cyber-physical Attack Generation, Detection, and Mitigation in Smart-Grid},
  year      = {2021},
  month     = {April},
  pages     = {1-6},
  abstract  = {Cyber-physical (CP) attacks are the principal dangers confronting the usage and advancement of the contemporary smart-grid (SG) system. Advancement of SG has added a wide range of technology, equipment, and tools to make the system more reliable, efficient, and cost-effective. Despite attaining these goals, the threat space for the adversarial attacks has also been expanded because of the addition of the cyber layers. Machine learning (ML) based tools are being used to exploit and defend the system for its massive computational and reasoning capability. In this paper, we perform a comprehensive summary of cyber-physical attack identification and mitigation schemes by reviewing state-of-the-art researches in the SG domain. After that, we address ML assisted attack for facilitating future researchers to get updated about the existing research status. Additionally, we present a tabular form of current researches in a structured way to help the potential forthcoming researchers in deciding their research focus. We also present the shortcomings of the existing works and possible future research direction based on our investigation.},
  doi       = {10.1109/NAPS50074.2021.9449635},
  groups    = {First Filtering},
  keywords  = {Machine learning;Tools;Cyber-physical systems;Cognition;Smart grids;Reliability;Cyber-physical system (CPS);cyberattacks;smart-grid (SG);anomaly detection system;machine learning (ML)},
}

@InProceedings{7810009,
  author    = {Saad, Amna and Amran, Ahmad Roshidi and Afif, Ijlal Ibrahim and Zolkeple, Ahmad Hariri and Said, Aidy Izzuddin Ahmad and Hamzah, Muhammad Fiqri and Salim, Wan Nor Salwani Wan},
  booktitle = {2016 2nd International Symposium on Agent, Multi-Agent Systems and Robotics (ISAMSR)},
  title     = {Privacy and security gaps in mitigating Cyber crime: The review},
  year      = {2016},
  month     = {Aug},
  pages     = {92-99},
  abstract  = {Our motivation for this study is to provide new information to a researcher based on our field of study: Networking Systems. This is because Cyber crime is becoming very widespread and it is imperative to improve measures used to counteract such threats. There are various research gaps based on awareness of cyber security, and different methods used in enhancing and troubleshooting network security. This research area can offer many opportunities in which justice can be served, creating awareness, making cyber space a more secure area and creating a new business niche based on security. Hence, for our study on Network Security, we read through 24 research papers published between 2008 to 2014. These documents were retrieved online from CAIDA and IEEE, along with other computer journals and articles. The 24 research papers were then summarized into 7 different research gaps to help enlighten a researcher in the topic of Network Security. Therefore, researchers can then take the initiatives to come up with solutions to the issues raised in this paper.},
  doi       = {10.1109/ISAMSR.2016.7810009},
  groups    = {First Filtering},
  keywords  = {Communication networks;Internet;Analytical models;Protocols;Mathematical model;Computer security;Information Security;Cyber Security;Network Security;User Privacy;Cybercrime},
}

@InProceedings{9402020,
  author    = {Li, Yuanchun and Hua, Jiayi and Wang, Haoyu and Chen, Chunyang and Liu, Yunxin},
  booktitle = {2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)},
  title     = {DeepPayload: Black-box Backdoor Attack on Deep Learning Models through Neural Payload Injection},
  year      = {2021},
  month     = {May},
  pages     = {263-274},
  abstract  = {Deep learning models are increasingly used in mobile applications as critical components. Unlike the program bytecode whose vulnerabilities and threats have been widely-discussed, whether and how the deep learning models deployed in the applications can be compromised are not well-understood since Neural Networks are usually viewed as a black box. In this paper, we introduce a highly practical backdoor attack achieved with a set of reverse-engineering techniques over compiled deep learning models. The core of the attack is a neural conditional branch constructed with a trigger detector and several operators and injected into the victim model as a malicious payload. The attack is effective as the conditional logic can be flexibly customized by the attacker, and scalable as it does not require any prior knowledge from the original model. We evaluated the attack effectiveness using 5 state-of-the-art deep learning models and real-world samples collected from 30 users. The results demonstrated that the injected backdoor can be triggered with a success rate of 93.5%, while only brought less than 2ms latency overhead and no more than 1.4% accuracy decrease. We further conducted an empirical study on real-world mobile deep learning apps collected from Google Play. We found 54 apps that were vulnerable to our attack, including popular and security-critical ones. The results call for the awareness of deep learning application developers and auditors to enhance the protection of deployed models.},
  doi       = {10.1109/ICSE43902.2021.00035},
  groups    = {First Filtering},
  issn      = {1558-1225},
  keywords  = {Deep learning;Training;Neural networks;Internet;Mobile applications;Payloads;Software engineering;deep learning;backdoor attack;mobile applications;reverse engineering;malicious payload},
}

@InProceedings{9156294,
  author    = {Naseer, Muzammal and Khan, Salman and Hayat, Munawar and Khan, Fahad Shahbaz and Porikli, Fatih},
  booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {A Self-supervised Approach for Adversarial Robustness},
  year      = {2020},
  month     = {June},
  pages     = {259-268},
  abstract  = {Adversarial examples can cause catastrophic mistakes in Deep Neural Network (DNNs) based vision systems e.g., for classification, segmentation and object detection. The vulnerability of DNNs against such attacks can prove a major roadblock towards their real-world deployment. Transferability of adversarial examples demand generalizable defenses that can provide cross-task protection. Adversarial training that enhances robustness by modifying target model's parameters lacks such generalizability. On the other hand, different input processing based defenses fall short in the face of continuously evolving attacks. In this paper, we take the first step to combine the benefits of both approaches and propose a self-supervised adversarial training mechanism in the input space. By design, our defense is a generalizable approach and provides significant robustness against the unseen adversarial attacks (e.g. by reducing the success rate of translation-invariant ensemble attack from 82.6% to 31.9% in comparison to previous stateof-the-art). It can be deployed as a plug-and-play solution to protect a variety of vision systems, as we demonstrate for the case of classification, segmentation and detection. Code is available at: https://github.com/ Muzammal-Naseer/NRP.},
  doi       = {10.1109/CVPR42600.2020.00034},
  groups    = {First Filtering},
  issn      = {2575-7075},
  keywords  = {Perturbation methods;Task analysis;Distortion;Training;Robustness;Feature extraction;Neural networks},
}

@InProceedings{9059509,
  author    = {Li, Huhua and Zhan, Dongyang and Liu, Tianrui and Ye, Lin},
  booktitle = {2019 IEEE 16th International Conference on Mobile Ad Hoc and Sensor Systems Workshops (MASSW)},
  title     = {Using Deep-Learning-Based Memory Analysis for Malware Detection in Cloud},
  year      = {2019},
  month     = {Nov},
  pages     = {1-6},
  abstract  = {Malware is one of the biggest threats in cloud computing. Malware running inside virtual machines or containers could steal critical information or continue to attack other cloud nodes. To detect malware in cloud, especially zero-day malware, signature-and machine-learning-based approaches are proposed to analyze the execution binary. However, malicious binary files may not permanently be stored in the file system of virtual machine or container, periodically scanner may not find the target files. Dynamic analysis approach usually introduce run-time overhead to virtual machines, which is not widely used in cloud. To solve these problems, we propose a memory analysis approach to detect malware, employing the deep learning technology. The system analyzes the memory image periodically during malware execution, which will not introduce run-time overhead. We first extract the memory snapshot from running virtual machines or containers. Then, the snapshot is converted to a grayscale image. Finally, we employ CNN to detect malware. In the learning phase, malicious and benign software are trained. In the testing phase, we test our system with real-world malwares.},
  doi       = {10.1109/MASSW.2019.00008},
  groups    = {First Filtering},
  keywords  = {Malware;Virtual machining;Gray-scale;Feature extraction;Cloud computing;Monitoring;Virtual machine monitors;malware detection, deep learning, memory analysis, cloud computing},
}

@InProceedings{9059404,
  author    = {Tanksale, Vinayak},
  booktitle = {2019 IEEE 16th International Conference on Mobile Ad Hoc and Sensor Systems Workshops (MASSW)},
  title     = {Intrusion Detection For Controller Area Network Using Support Vector Machines},
  year      = {2019},
  month     = {Nov},
  pages     = {121-126},
  abstract  = {Controller Area Network is the most widely adopted communication standard in automobiles. The CAN protocol is robust and is designed to minimize overhead. The light-weight nature of this protocol implies that it can't efficiently process secure communication. With the exponential increase in automobile communications, there is an urgent need for efficient and effective security countermeasures. We propose a support vector machine based intrusion detection system that is able to detect anomalous behavior with high accuracy. We outline a process for parameter selection and feature vector selection. We identify strengths and weaknesses of our system and propose to extend our work for time-series based data.},
  doi       = {10.1109/MASSW.2019.00032},
  groups    = {First Filtering},
  keywords  = {Protocols;Support vector machines;Intrusion detection;Delays;Automobiles;Feature extraction;Controller Area Network;ECU;machine learning;support vector machine},
}

@InProceedings{9463266,
  author    = {Zhao, Rui},
  booktitle = {2021 2nd International Conference on Computing and Data Science (CDS)},
  title     = {The Vulnerability of the Neural Networks Against Adversarial Examples in Deep Learning Algorithms},
  year      = {2021},
  month     = {Jan},
  pages     = {287-295},
  abstract  = {With the further development in the fields of computer vision, network security, natural language processing and so on so forth, deep learning technology gradually exposed certain security risks. The existing deep learning algorithms cannot effectively describe the essential characteristics of data, making the algorithm unable to give the correct result in the face of malicious input. Based on current security threats faced by deep learning, this paper introduces the problem of adversarial examples in deep learning, sorts out the existing attack and defense methods of black box and white box, and classifies them. It briefly describes the application of some adversarial examples in different scenarios in recent years, compares several defense technologies of adversarial examples, and finally summarizes the problems in this research field and prospects its future development. This paper introduces the common white box attack methods in detail, and further compares the similarities and differences between the attack of black and white boxes. Correspondingly, the author also introduces the defense methods, and analyzes the performance of these methods against the black and white box attack.},
  doi       = {10.1109/CDS52072.2021.00057},
  groups    = {First Filtering},
  keywords  = {Deep learning;Computer vision;Neural networks;Data science;Natural language processing;Classification algorithms;Security;Deep Learning;Security;Black box;White box;Adversarial Examples},
}

@Article{9461213,
  author   = {Zoppi, Tommaso and Ceccarelli, Andrea and Bondavalli, Andrea},
  journal  = {IEEE Access},
  title    = {Unsupervised Algorithms to Detect Zero-Day Attacks: Strategy and Application},
  year     = {2021},
  issn     = {2169-3536},
  pages    = {90603-90615},
  volume   = {9},
  abstract = {In the last decade, researchers, practitioners and companies struggled for devising mechanisms to detect cyber-security threats. Among others, those efforts originated rule-based, signature-based or supervised Machine Learning (ML) algorithms that were proven effective for detecting those intrusions that have already been encountered and characterized. Instead, new unknown threats, often referred to as zero-day attacks or zero-days, likely go undetected as they are often misclassified by those techniques. In recent years, unsupervised anomaly detection algorithms showed potential to detect zero-days. However, dedicated support for quantitative analyses of unsupervised anomaly detection algorithms is still scarce and often does not promote meta-learning, which has potential to improve classification performance. To such extent, this paper introduces the problem of zero-days and reviews unsupervised algorithms for their detection. Then, the paper applies a question-answer approach to identify typical issues in conducting quantitative analyses for zero-days detection, and shows how to setup and exercise unsupervised algorithms with appropriate tooling. Using a very recent attack dataset, we debate on i) the impact of features on the detection performance of unsupervised algorithms, ii) the relevant metrics to evaluate intrusion detectors, iii) means to compare multiple unsupervised algorithms, iv) the application of meta-learning to reduce misclassifications. Ultimately, v) we measure detection performance of unsupervised anomaly detection algorithms with respect to zero-days. Overall, the paper exemplifies how to practically orchestrate and apply an appropriate methodology, process and tool, providing even non-experts with means to select appropriate strategies to deal with zero-days.},
  doi      = {10.1109/ACCESS.2021.3090957},
  groups   = {First Filtering},
  keywords = {Classification algorithms;Anomaly detection;Clustering algorithms;Training;Machine learning algorithms;Security;Intrusion detection;Zero-day attacks;intrusion detection;machine learning;anomaly detection;RELOAD;security;unsupervised learning;cyber-attacks},
}

@InProceedings{9355598,
  author    = {Shang, Jiacheng and Wu, Jie},
  booktitle = {2020 IEEE 40th International Conference on Distributed Computing Systems (ICDCS)},
  title     = {Protecting Real-time Video Chat against Fake Facial Videos Generated by Face Reenactment},
  year      = {2020},
  month     = {Nov},
  pages     = {689-699},
  abstract  = {With the rapid popularity of cameras on various devices, video chat has become one of the major ways for communication, such as online meetings. However, the recent progress of face reenactment techniques enables attackers to generate fake facial videos and use others' identities. To protect video chats against fake facial videos, we propose a new defense system to significantly raise the bar for face reenactment-assisted attacks. Compared with existing works, our system has three major strengths. First, our system does not require extra hardware or intense computational resources. Second, it follows the normal video chat process and does not significantly degrade the user experience. Third, our system does not need to collect training data from attackers and new users, which means it can be quickly launched on new devices. We developed a prototype and conducted comprehensive evaluations. Experimental results show that our system can provide an average true acceptance rate of at least 92.5% for legitimate users and reject the attacker with mean accuracy of at least 94.4% for a single detection.},
  doi       = {10.1109/ICDCS47774.2020.00082},
  groups    = {First Filtering},
  issn      = {2575-8411},
  keywords  = {Training data;Prototypes;Streaming media;User experience;Real-time systems;Hardware;Faces;Face forgery;face liveness detection;real-time video chat},
}

@InProceedings{6831937,
  author    = {Wang, Chao and Wu, Zhizhong and Wang, Aili and Li, Xi and Yang, Feng and Zhou, Xuehai},
  booktitle = {2013 IEEE 10th International Conference on High Performance Computing and Communications 2013 IEEE International Conference on Embedded and Ubiquitous Computing},
  title     = {SmartMal: A Service-Oriented Behavioral Malware Detection Framework for Smartphones},
  year      = {2013},
  month     = {Nov},
  pages     = {329-336},
  abstract  = {This paper presents SmartMal-A novel service-oriented behavioral malware detection framework for vehicular and mobile devices. The highlight of SmartMal is to introduce Service Oriented Architecture (SOA) concepts and behavior analysis into the malware detection paradigms. The proposed framework relies on client-server architecture, the client continuously extracts various features and transfers them to the server, and the server's main task is to detect anomalies using state-of-art detection algorithms. Multiple distributed servers simultaneously analyze the feature vector using various detectors and information fusion is used to concatenate the results of detectors. We also propose a cycle-based statistical approach for mobile device anomaly detection. We accomplish this by analyzing the users' regular usage patterns. Empirical results suggest that the proposed framework and novel anomaly detection algorithm are highly effective in detecting malware on Android devices.},
  doi       = {10.1109/HPCC.and.EUC.2013.55},
  groups    = {First Filtering},
  keywords  = {Servers;Malware;Feature extraction;Service-oriented architecture;Smart phones;Detectors;Service-oriented;Smartphones;Malware;Security},
}

@Article{9051677,
  author   = {Huang, Ru and Ma, Lei and Zhai, Guangtao and He, Jianhua and Chu, Xiaoli and Yan, Huaicheng},
  journal  = {IEEE Access},
  title    = {Resilient Routing Mechanism for Wireless Sensor Networks With Deep Learning Link Reliability Prediction},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {64857-64872},
  volume   = {8},
  abstract = {Wireless sensor networks play an important role in Internet of Things systems and services but are prone and vulnerable to poor communication channel quality and network attacks. In this paper we are motivated to propose resilient routing algorithms for wireless sensor networks. The main idea is to exploit the link reliability along with other traditional routing metrics for routing algorithm design. We proposed firstly a novel deep-learning based link prediction model, which jointly exploits Weisfeiler-Lehman kernel and Dual Convolutional Neural Network (WL-DCNN) for lightweight subgraph extraction and labelling. It is leveraged to enhance self-learning ability of mining topological features with strong generality. Experimental results demonstrate that WL-DCNN outperforms all the studied 9 baseline schemes over 6 open complex networks datasets. The performance of AUC (Area Under the receiver operating characteristic Curve) is improved by 16% on average. Furthermore, we apply the WL-DCNN model in the design of resilient routing for wireless sensor networks, which can adaptively capture topological features to determine the reliability of target links, especially under the situations of routing table suffering from attack with varying degrees of damage to local link community. It is observed that, compared with other classical routing baselines, the proposed routing algorithm with link reliability prediction module can effectively improve the resilience of sensor networks while reserving high-energy-efficiency.},
  doi      = {10.1109/ACCESS.2020.2984593},
  groups   = {First Filtering},
  keywords = {Routing;Wireless sensor networks;Prediction algorithms;Complex networks;Deep learning;Reliability engineering;Deep learning;link prediction;routing;wireless sensor networks;reliability},
}

@InProceedings{8443032,
  author    = {O.S., Jannath Nisha and Mary Saira Bhanu, S.},
  booktitle = {2018 8th International Conference on Cloud Computing, Data Science Engineering (Confluence)},
  title     = {A Survey on Code Injection Attacks in Mobile Cloud Computing Environment},
  year      = {2018},
  month     = {Jan},
  pages     = {1-6},
  abstract  = {Mobile Cloud Computing is a combination of Mobile Computing, Cloud Computing and wireless networks to convey rich computational resources to mobile users, network operators, as well as cloud computing providers. Nowadays, the market of mobile devices and its applications are growing at an alarming speed. In general, single application for a specific purpose is not compatible to different operating systems. So the developer has to develop various versions of application which is compatible to different platforms. In order to overcome the drawback of compatibility and interoperability issues, HTML5-based mobile applications are built by using standard web technologies. HTML5-based mobile applications support same version of application in different platforms, but these applications are vulnerable to attacks because of the data and code being fused together. A new form of Code Injection Attack found in this type of mobile applications inherits the property of XSS attack and also uses many channels to inject malicious code such as Contact, SMS, WIFI, NFC, Barcode etc. This allows the attacker to inject malicious code to exhaust all the resources of the victim. Therefore, security is the major issue which impedes the development of Mobile Cloud Computing. This paper surveys the malicious code injection attacks in Mobile Cloud Computing environment and the possible solutions.},
  doi       = {10.1109/CONFLUENCE.2018.8443032},
  groups    = {First Filtering},
  keywords  = {Handheld computers;Cloud computing;Data science;Conferences;Mobile Cloud Computing;Code Injection attack;HTML5-based mobile applications;Cross-site scripting attacks;Sanitization technique},
}

@InProceedings{6980299,
  author    = {Ben Chehida Douss, Aida and Abassi, Ryma and Guemara El Fatmi, Sihem},
  booktitle = {2014 Ninth International Conference on Availability, Reliability and Security},
  title     = {A Trust Management Based Security Mechanism against Collusion Attacks in a MANET Environment},
  year      = {2014},
  month     = {Sep.},
  pages     = {325-332},
  abstract  = {MANETs (Mobile Ad hoc Networks) are self organized networks with mobile and collaborating nodes without any pre-established infrastructure. Because of these characteristics, securing MANETs constitute a hard and challenging task. Consequently, new mechanisms may be of interest to secure such networks. To this end, we have found that trust management can be a support for MANET security. In fact, the reputation concept and the establishment of trustful relation between collaborating nodes can be meaningful to express security aspects in such environment. From there, we proposed in previous works a Mobility-based Clustering Algorithm (MCA) and a Trust management scheme for MCA (TMCA) to secure routing behaviors. MCA organizes nodes into clusters managed by a cluster-head (CH) and TMCA detects malicious routing behavior based on CHs direct observations and exchanged alerts. A delegation based process was also defined on TMCA and was called DTMCA. Although DTMCA meets security objectives, it may unfortunately be faced with various threats from malicious nodes: Several nodes can in fact collude in order to increase or decrease other reputation values to damage the QoS and even the MANET functioning. Our objective in this paper is then to secure DTMCA against collusion attacks. The mechanism proposed here is based on colluding nodes detection through cluster members behavior monitoring and by comparing this behavior with the received reputation value in the alert message. Detected colluder nodes are then discarded from further communication.},
  doi       = {10.1109/ARES.2014.50},
  groups    = {First Filtering},
  keywords  = {Monitoring;Mobile ad hoc networks;Security;Educational institutions;Routing;Quality of service;Topology;MANET;Trust management;Reputation;Collusion attack},
}

@Article{6042389,
  author   = {Cheng, Tsung-Huan and Lin, Ying-Dar and Lai, Yuan-Cheng and Lin, Po-Ching},
  journal  = {IEEE Communications Surveys Tutorials},
  title    = {Evasion Techniques: Sneaking through Your Intrusion Detection/Prevention Systems},
  year     = {2012},
  issn     = {1553-877X},
  month    = {Fourth},
  number   = {4},
  pages    = {1011-1020},
  volume   = {14},
  abstract = {Detecting attacks disguised by evasion techniques is a challenge for signature-based Intrusion Detection Systems (IDSs) and Intrusion Prevention Systems (IPSs). This study examines five common evasion techniques to determine their ability to evade recent systems. The denial-of-service (DoS) attack attempts to disable a system by exhausting its resources. Packet splitting tries to chop data into small packets, so that a system may not completely reassemble the packets for signature matching. Duplicate insertion can mislead a system if the system and the target host discard different TCP/IP packets with a duplicate offset or sequence. Payload mutation fools a system with a mutative payload. Shellcode mutation transforms an attacker's shellcode to escape signature detection. This study assesses the effectiveness of these techniques on three recent signature-based systems, and among them, explains why Snort can be evaded. The results indicate that duplicate insertion becomes less effective on recent systems, but packet splitting, payload mutation and shellcode mutation can be still effective against them.},
  doi      = {10.1109/SURV.2011.092311.00082},
  groups   = {First Filtering},
  keywords = {Payloads;IP networks;Computer crime;Handwriting recognition;Cryptography;Intrusion detection;IDS/IPS;evasion;attacks;signature},
}

@InProceedings{6555301,
  author    = {Creech, Gideon and Hu, Jiankun},
  booktitle = {2013 IEEE Wireless Communications and Networking Conference (WCNC)},
  title     = {Generation of a new IDS test dataset: Time to retire the KDD collection},
  year      = {2013},
  month     = {April},
  pages     = {4487-4492},
  abstract  = {Intrusion detection systems are generally tested using datasets compiled at the end of last century, justified by the need for publicly available test data and the lack of any other alternative datasets. Prominent amongst this legacy group is the KDD project. Whilst a seminal contribution at the time of compilation, these datasets no longer represent relevant architecture or contemporary attack protocols, and are beset by data corruptions and inconsistencies. Hence, testing of new IDS approaches against these datasets does not provide an effective performance metric, and contributes to erroneous efficacy claims. This paper introduces a new publicly available dataset which is representative of modern attack structure and methodology. The new dataset is contrasted with the legacy datasets, and the performance difference of commonly used intrusion detection algorithms is highlighted.},
  doi       = {10.1109/WCNC.2013.6555301},
  groups    = {First Filtering},
  issn      = {1558-2612},
  keywords  = {Clustering algorithms;Intrusion detection;Operating systems;Linux;Payloads;Computers},
}

@InProceedings{6950913,
  author    = {Sinha, Somnath and Paul, Aditi and Pal, Sarit},
  booktitle = {Third International Conference on Computational Intelligence and Information Technology (CIIT 2013)},
  title     = {The sybil attack in Mobile Adhoc Network: Analysis and detection},
  year      = {2013},
  month     = {Oct},
  pages     = {458-466},
  abstract  = {Security is one of the most challenging issues in Mobile Adhoc Network (MANET) due to the lack of centralized authority and limited resources. This paper discusses different types of security attacks in MANET and gives emphasis particularly on the Sybil attack which is one of the most harmful attacks. Taxonomy and threats of Sybil attacks in different environment are presented. Comparative analysis has been performed on several detection approaches to mitigate Sybil attack which provides efficiency, limitations and application domain of each of these approaches. This paper also introduces a new approach to detect Sybil attack based on clustering as well as resource testing.},
  doi       = {10.1049/cp.2013.2629},
  groups    = {First Filtering},
  keywords  = {Sybil attack;Network Security;Mobile Adhoc Network},
}

@InProceedings{9012700,
  author    = {Bian, Haibo and Bai, Tim and Salahuddin, Mohammad A. and Limam, Noura and Daya, Abbas Abou and Boutaba, Raouf},
  booktitle = {2019 15th International Conference on Network and Service Management (CNSM)},
  title     = {Host in Danger? Detecting Network Intrusions from Authentication Logs},
  year      = {2019},
  month     = {Oct},
  pages     = {1-9},
  abstract  = {Recently, network infiltrations due to advanced persistent threats (APTs) have grown significantly, resulting in considerable losses to businesses and organizations. APTs are stealthy attacks with the primary objective of gaining unauthorized access to network assets. They often remain dormant for an extended period of time, which makes their detection challenging. In this paper, we leverage machine learning (ML) to detect hosts in a network that are targeted by an APT attack. We evaluate a number of ML classifiers to detect susceptible hosts in the Los Alamos National Lab dataset. We explore (i) graph-based features extracted from multiple data sources i.e., network flows and host authentication logs, (ii) feature engineering to reduce dimensionality, and (iii) balancing the training dataset using numerous over- and under-sampling techniques. Finally, we compare our model to the state-of-the-art approaches that leverage the same dataset, and show that our model outperforms them with respect to prediction performance and overhead.},
  doi       = {10.23919/CNSM46954.2019.9012700},
  groups    = {First Filtering},
  issn      = {2165-963X},
  keywords  = {Feature extraction;Authentication;Classification algorithms;Tagging;Principal component analysis;Data mining;Training;Machine learning;advanced persistent threat;intrusion detection},
}

@InProceedings{6531064,
  author    = {Poston, Howard E.},
  booktitle = {2012 IEEE National Aerospace and Electronics Conference (NAECON)},
  title     = {A brief taxonomy of intrusion detection strategies},
  year      = {2012},
  month     = {July},
  pages     = {255-263},
  abstract  = {This paper provide a brief taxonomy and literature review regarding intrusion detection. It highlights the two main methods of classifying intrusion detection systems: network-based v. host-based and anomaly detection v. signature/misuse detection. An extensive bibliography is provided as a starting point for research in the field of intrusion detection.},
  doi       = {10.1109/NAECON.2012.6531064},
  groups    = {First Filtering},
  issn      = {0547-3578},
  keywords  = {Intrusion Detection;Network Intrusion Detection System;Host Intrusion Detection System;Signature Detection;Anomaly Detection},
}

@Article{8970564,
  author   = {El Aassal, Ayman and Baki, Shahryar and Das, Avisha and Verma, Rakesh M.},
  journal  = {IEEE Access},
  title    = {An In-Depth Benchmarking and Evaluation of Phishing Detection Research for Security Needs},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {22170-22192},
  volume   = {8},
  abstract = {We perform an in-depth, systematic benchmarking study and evaluation of phishing features on diverse and extensive datasets. We propose a new taxonomy of features based on the interpretation and purpose of each feature. Next, we propose a benchmarking framework called `PhishBench,' which enables us to evaluate and compare the existing features for phishing detection systematically and thoroughly under identical experimental conditions, i.e., unified system specification, datasets, classifiers, and evaluation metrics. PhishBench is a first in the field of benchmarking phishing related research and incorporates thorough and systematic evaluation and feature comparison. We use PhishBench to test methods published in the phishing literature on new and diverse datasets to check their robustness and scalability. We study how dataset characteristics, e.g., varying legitimate to phishing ratios and increasing the size of imbalanced datasets, affect classification performance. Our results show that the imbalanced nature of phishing attacks affects the detection systems' performance and researchers should take this into account when proposing a new method. We also found that retraining alone is not enough to defeat new attacks. New features and techniques are required to stop attackers from fooling detection systems.},
  doi      = {10.1109/ACCESS.2020.2969780},
  groups   = {First Filtering},
  keywords = {Phishing;Benchmark testing;Feature extraction;Electronic mail;Uniform resource locators;Taxonomy;Feature engineering;feature taxonomy;framework;phishing email;phishing URL;phishing website},
}

@InProceedings{9207637,
  author    = {Fidel, Gil and Bitton, Ron and Shabtai, Asaf},
  booktitle = {2020 International Joint Conference on Neural Networks (IJCNN)},
  title     = {When Explainability Meets Adversarial Learning: Detecting Adversarial Examples using SHAP Signatures},
  year      = {2020},
  month     = {July},
  pages     = {1-8},
  abstract  = {State-of-the-art deep neural networks (DNNs) are highly effective in solving many complex real-world problems. However, these models are vulnerable to adversarial perturbation attacks, and despite the plethora of research in this domain, to this day, adversaries still have the upper hand in the cat and mouse game of adversarial example generation methods vs. detection and prevention methods. In this research, we present a novel detection method that uses Shapley Additive Explanations (SHAP) values computed for the internal layers of a DNN classifier to discriminate between normal and adversarial inputs. We evaluate our method by building an extensive dataset of adversarial examples over the popular CIFAR-10 and MNIST datasets, and training a neural network-based detector to distinguish between normal and adversarial inputs. We evaluate our detector against adversarial examples generated by diverse state-of-the-art attacks and demonstrate its high detection accuracy and strong generalization ability to adversarial inputs generated with different attack methods.},
  doi       = {10.1109/IJCNN48605.2020.9207637},
  groups    = {First Filtering},
  issn      = {2161-4407},
  keywords  = {Perturbation methods;Automobiles;Detectors;Cats;Training;Artificial intelligence;Neurons;Adversarial Learning;Explainable AI;SHAP;Deep Learning},
}

@InProceedings{7794324,
  author    = {Yim, Keun Soo},
  booktitle = {2016 IEEE 35th Symposium on Reliable Distributed Systems (SRDS)},
  title     = {The Rowhammer Attack Injection Methodology},
  year      = {2016},
  month     = {Sep.},
  pages     = {1-10},
  abstract  = {This paper presents a systematic methodology to identify and validate security attacks that exploit user influenceable hardware faults (i.e., rowhammer errors). We break down rowhammer attack procedures into nine generalized steps where some steps are designed to increase the attack success probabilities. Our framework can perform those nine operations (e.g., pressuring system memory and spraying landing pages) as well as inject rowhammer errors which are basically modeled as ≥3-bit errors. When one of the injected errors is activated, such can cause control or data flow divergences which can then be caught by a prepared landing page and thus lead to a successful attack. Our experiments conducted against a guest operating system of a typical cloud hypervisor identified multiple reproducible targets for privilege escalation, shell injection, memory and disk corruption, and advanced denial-of-service attacks. Because the presented rowhammer attack injection (RAI) methodology uses error injection and thus statistical sampling, RAI can quantitatively evaluate the modeled rowhammer attack success probabilities of any given target software states.},
  doi       = {10.1109/SRDS.2016.012},
  groups    = {First Filtering},
  issn      = {1060-9857},
  keywords  = {Security;Software;Hardware;DRAM chips;Error correction codes;Reliability;Security evaluation methodology;cloud and hypervisor security;quantitative security analysis;and rowhammer error},
}

@InProceedings{8403674,
  author    = {Papadopoulos, Stavros and Drosou, Anastasios and Kalamaras, Ilias and Tzovaras, Dimitrios},
  booktitle = {2018 IEEE International Conference on Communications Workshops (ICC Workshops)},
  title     = {Behavioural Network Traffic Analytics for Securing 5G Networks},
  year      = {2018},
  month     = {May},
  pages     = {1-6},
  abstract  = {The analysis of the network traffic in 5G networks is of high significance to the network security administrator, since it could allow for the identification of different behavioural groups and the distinction of anomalous from normal activity. The problem is the multi-dimensional nature of the data, e.g. SMS, call, Internet, services etc. that makes it difficult to analyse. This is even more challenging in 5G networks, compared to previous generation networks, since one more dimension is added to the traffic, representing different network slices. In this respect, activity that is normal in one slice can be anomalous in another. This paper presents a graph-based method for network mining and visualization of user activities in a mobile network. The raw multi- dimensional network traffic data are used for the construction of multiple multi-dimensional graph- based features that capture specific behavioural aspects for each user. Within each feature, graph matching techniques are applied in order to identify groups of users with similar behaviour. The dissimilarity results for each feature are combined using a multi-objective visualization method. The outcome is a data visualization in which users with similar behaviour are depicted as points close to each other. The network analyst is able to select the desired trade-off among the multiple features, and visually detect groups of users with similar behaviours, as well as possible anomalous clusters or outliers. Experimental evaluation of the proposed approach in several application scenarios verify its efficiency.},
  doi       = {10.1109/ICCW.2018.8403674},
  groups    = {First Filtering},
  issn      = {2474-9133},
  keywords  = {Data visualization;Feature extraction;Mobile handsets;5G mobile communication;Security;Communication networks;Ontologies},
}

@InProceedings{9151460,
  author    = {Khoshpasand, Mehrgan and Ghorbani, Ali},
  booktitle = {2020 50th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W)},
  title     = {On The Generation of Unrestricted Adversarial Examples},
  year      = {2020},
  month     = {June},
  pages     = {9-15},
  abstract  = {Adversarial examples are inputs designed by an adversary with the goal of fooling the machine learning models. Most of the research about adversarial examples have focused on perturbing the natural inputs with the assumption that the true label remains unchanged. Even in this limited setting and despite extensive studies in recent years, there is no defence against adversarial examples for complex tasks (e.g., ImageNet). However, for simpler tasks like handwritten digit classification, a robust model seems to be within reach. Unlike perturbation-based adversarial examples, the adversary is not limited to small norm-based perturbations in unrestricted adversarial examples. Hence, defending against unrestricted adversarial examples is a more challenging task. In this paper, we show that previous methods for generating unrestricted adversarial examples ignored a large part of the adversarial subspace. In particular, we demonstrate the bias of previous methods towards generating samples that are far inside the decision boundaries of an auxiliary classifier. We also show the similarity of the decision boundaries of an auxiliary classifier and baseline CNNs. By putting these two evidence together, we explain why adversarial examples generated by the previous approaches lack the desired transferability. Additionally, we present an efficient technique to create adversarial examples using generative adversarial networks to address this issue. We demonstrate that even the state-of-the-art MNIST classifiers are vulnerable to the adversarial examples generated with this technique. Additionally, we show that examples generated with our method are transferable. Accordingly, we hope that new proposed defences use this attack to evaluate the robustness of their models against unrestricted attacks.},
  doi       = {10.1109/DSN-W50199.2020.00012},
  groups    = {First Filtering},
  issn      = {2325-6664},
  keywords  = {Robustness;Generators;Gallium nitride;Perturbation methods;Machine learning;Generative adversarial networks;Training;Adversarial Examples;Deep learning;Machine Learning},
}

@InProceedings{9413760,
  author    = {Shamsabadi, Ali Shahin and Teixeira, Francisco Sepúlveda and Abad, Alberto and Raj, Bhiksha and Cavallaro, Andrea and Trancoso, Isabel},
  booktitle = {ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {FoolHD: Fooling Speaker Identification by Highly Imperceptible Adversarial Disturbances},
  year      = {2021},
  month     = {June},
  pages     = {6159-6163},
  abstract  = {Speaker identification models are vulnerable to carefully designed adversarial perturbations of their input signals that induce misclassification. In this work, we propose a white-box steganography-inspired adversarial attack that generates imperceptible adversarial perturbations against a speaker identification model. Our approach, FoolHD, uses a Gated Convolutional Autoencoder that operates in the DCT domain and is trained with a multi-objective loss function, to generate and conceal the adversarial perturbation within the original audio files. In addition to hindering speaker identification performance, this multi-objective loss accounts for human perception through a frame-wise cosine similarity between MFCC feature vectors extracted from the original and adversarial audio files. We validate the effectiveness of FoolHD with a 250-speaker identification x-vector network, trained using VoxCeleb, in terms of accuracy, success rate, and imperceptibility. Our results show that FoolHD generates highly imperceptible adversarial audio files (average PESQ scores above 4.30), while achieving a success rate of 99.6% and 99.2% in misleading the speaker identification model, for untargeted and targeted settings, respectively.},
  doi       = {10.1109/ICASSP39728.2021.9413760},
  groups    = {First Filtering},
  issn      = {2379-190X},
  keywords  = {Privacy;Convolution;Perturbation methods;Watermarking;Logic gates;Feature extraction;Robustness;Adversarial examples;speaker identification;speech},
}

@InProceedings{9428429,
  author    = {Gragnaniello, D. and Cozzolino, D. and Marra, F. and Poggi, G. and Verdoliva, L.},
  booktitle = {2021 IEEE International Conference on Multimedia and Expo (ICME)},
  title     = {Are GAN Generated Images Easy to Detect? A Critical Analysis of the State-Of-The-Art},
  year      = {2021},
  month     = {July},
  pages     = {1-6},
  abstract  = {The advent of deep learning has brought a significant improvement in the quality of generated media. However, with the increased level of photorealism, synthetic media are becoming hardly distinguishable from real ones, raising serious concerns about the spread of fake or manipulated information over the Internet. In this context, it is important to develop automated tools to reliably and timely detect synthetic media. In this work, we analyze the state-of-the-art methods for the detection of synthetic images, highlighting the key ingredients of the most successful approaches, and comparing their performance over existing generative architectures. We will devote special attention to realistic and challenging scenarios, like media uploaded on social networks or generated by new and unseen architectures, analyzing the impact of suitable augmentation and training strategies on the detectors’ generalization ability.},
  doi       = {10.1109/ICME51207.2021.9428429},
  groups    = {First Filtering},
  issn      = {1945-788X},
  keywords  = {Training;Photorealism;Image coding;Image resolution;Social networking (online);Transform coding;Tools;Image forensics;synthetic media;Generative Adversarial Networks},
}

@Article{9410557,
  author   = {Le Jeune, Laurens and Goedemé, Toon and Mentens, Nele},
  journal  = {IEEE Access},
  title    = {Machine Learning for Misuse-Based Network Intrusion Detection: Overview, Unified Evaluation and Feature Choice Comparison Framework},
  year     = {2021},
  issn     = {2169-3536},
  pages    = {63995-64015},
  volume   = {9},
  abstract = {Network Intrusion detection systems are essential for the protection of advanced communication networks. Originally, these systems were hard-coded to identify specific signatures, patterns and rule violations; now artificial intelligence and machine learning algorithms provide promising alternatives. However, in the literature, various outdated datasets as well as a plethora of different evaluation metrics are used to prove algorithm efficacy. To enable a global comparison, this study compiles algorithms for different configurations to create common ground and proposes two new evaluation metrics. These metrics, the detection score and the identification score, together reliably present the performance of a network intrusion detection system to allow for practical comparison on a large scale. Additionally, we present a workflow to process raw packet flows into input features for machine learning. This framework quickly implements different algorithms for the various datasets and allows systematic performance comparison between those algorithms. Our experimental results, matching and surpassing the state-of-the-art, indicate the potential of this approach. As raw traffic input features are much easier and cheaper to extract when compared to traditional features, they show promise for application in real-time deep learning-based systems.},
  doi      = {10.1109/ACCESS.2021.3075066},
  groups   = {First Filtering},
  keywords = {Network intrusion detection;Measurement;Anomaly detection;Machine learning algorithms;Feature extraction;Wireless sensor networks;Hidden Markov models;Intrusion detection;machine learning;neural networks;security},
}

@InProceedings{9320277,
  author    = {Hao, Hanxiang and Güera, David and Horváth, János and Reibman, Amy R. and Delp, Edward J.},
  booktitle = {2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020)},
  title     = {Robustness Analysis of Face Obscuration},
  year      = {2020},
  month     = {Nov},
  pages     = {176-183},
  abstract  = {Face obscuration is needed by law enforcement and mass media outlets to guarantee privacy. Sharing sensitive content where obscuration or redaction techniques have failed to completely remove all identifiable traces can lead to many legal and social issues. Hence, we need to be able to systematically measure the face obscuration performance of a given technique. In this paper we propose to measure the effectiveness of eight obscuration techniques. We do so by attacking the redacted faces in three scenarios: obscured face identification, verification, and reconstruction. Threat modeling is also considered to provide a vulnerability analysis for each studied obscuration technique. Based on our evaluation, we show that the k-same based methods are the most effective.},
  doi       = {10.1109/FG47880.2020.00021},
  groups    = {First Filtering},
  keywords  = {Face recognition;Image reconstruction;Faces;Deep learning;Analytical models;Image recognition;Privacy;Face obscuration analysis;Threat modeling;Face recognition;Face verification;Face reconstruction},
}

@InProceedings{6337673,
  author    = {Lin, Hsiao-Ching and Sun, Ming-Kung and Huang, Han-Wei and Tseng, Chin-Yang Henry and Lin, Hui-Tang},
  booktitle = {2012 Third International Conference on Innovations in Bio-Inspired Computing and Applications},
  title     = {A Specification-Based Intrusion Detection Model for Wireless Ad Hoc Networks},
  year      = {2012},
  month     = {Sep.},
  pages     = {252-257},
  abstract  = {Mobile ad hoc networks (MANET) have the properties of open medium and decentralized structure, so malicious nodes can easily attack MANET nodes. Furthermore, it is more difficult to establish a protection mechanism on a dynamic topology than a fixed one. In this paper, we propose a specification-based intrusion detection model (SIDM) with the concept of previous two forwarders (PTF) which utilizes the previous hop routing messages to assure the integrity of the routing message. As a result, all vulnerable message fields that could be tampered with during transmission are protected by our method. The proposed SIDM is lightweight and deployable in a distributed environment. By employing the designed idea into the AODV routing protocol, the experimental results demonstrate suitable performance in MANET.},
  doi       = {10.1109/IBICA.2012.34},
  groups    = {First Filtering},
  keywords  = {Routing;Routing protocols;Mobile ad hoc networks;Intrusion detection;Receivers;AODV;Intrusion Detection;MANET;Security;Specification},
}

@Article{9448077,
  author   = {Kim, Taehoon and Pak, Wooguil},
  journal  = {IEEE Access},
  title    = {Hybrid Classification for High-Speed and High-Accuracy Network Intrusion Detection System},
  year     = {2021},
  issn     = {2169-3536},
  pages    = {83806-83817},
  volume   = {9},
  abstract = {Cybercrime is growing at a rapid pace, and its techniques are becoming more sophisticated. In order to actively cope with such threats, new approaches based on machine learning and requiring less administrator intervention have been proposed, but there are still many technical difficulties in detecting security attacks in real time. To solve this problem, we propose a new machine learning-based real-time intrusion detection algorithm. Unlike the existing approaches, the one proposed can detect the presence of an attack every time a packet is received, enabling real-time detection. In addition, our algorithm effectively reduces the system load, which may significantly increase from real-time detection, compared to non-real-time detection. In the algorithm, the increase in the number of memory accesses can be minimized (to below 30 %) compared to conventional methods. Since the proposed method is pure software-based approach, it has excellent scalability and flexibility against various attacks. Therefore, the proposed method cannot support the high classification performance of the hardware-based method but also the high flexibility of the software-based method simultaneously, it can effectively detect and prevent various cyber-attacks.},
  doi      = {10.1109/ACCESS.2021.3087201},
  groups   = {First Filtering},
  keywords = {Machine learning algorithms;Real-time systems;Security;Machine learning;Hardware;Scalability;Network intrusion detection;Hybrid classifier;network attack;network intrusion detection;three level;real-time detection},
}

@InProceedings{8509242,
  author    = {Jarovsky, Ariel and Milo, Tova and Novgorodov, Slava and Tan, Wang-Chiew},
  booktitle = {2018 IEEE 34th International Conference on Data Engineering (ICDE)},
  title     = {Rule Sharing for Fraud Detection via Adaptation},
  year      = {2018},
  month     = {April},
  pages     = {125-136},
  abstract  = {Writing rules to capture precisely fraudulent transactions is a challenging task where domain experts spend significant effort and time. A key observation is that much of this difficulty originates from the fact that such experts typically work as "lone rangers" or in isolated groups, or work on detecting frauds in one context in isolation from frauds that occur in another context. However, in practice there is a lot of commonality in what different experts are trying to achieve. In this paper, we present the GOLDRUSH system, which facilitates knowledge sharing via effective adaptation of fraud detection rules from one context to another. GOLDRUSH abstracts the possible semantic interpretations of each of the conditions in the rules at the source context and adapts them to the target context. Efficient algorithms are used to identify the most effective rule adaptations w.r.t a given cost-benefit metric. Our extensive set of experiments, based on real-world financial datasets, demonstrate the efficiency and effectiveness of our solution, both in terms of the accuracy of the fraud detection and the actual money saved.},
  doi       = {10.1109/ICDE.2018.00021},
  groups    = {First Filtering},
  issn      = {2375-026X},
  keywords  = {Semantics;Adaptation models;Companies;Data models;Machine learning;Task analysis;Industries;Rule Sharing;Rule Adaptation;Experts in the loop;Fraud Detection},
}

@InProceedings{8672711,
  author    = {Shahpasand, Maryam and Hamey, Len and Vatsalan, Dinusha and Xue, Minhui},
  booktitle = {2019 IEEE 1st International Workshop on Artificial Intelligence for Mobile (AI4Mobile)},
  title     = {Adversarial Attacks on Mobile Malware Detection},
  year      = {2019},
  month     = {Feb},
  pages     = {17-20},
  abstract  = {In recent years, machine learning approaches have been widely adopted for computer security tasks, including malware detection. Malware is a potent threat and an ongoing issue especially on smartphones which account for more than half of global web traffic. Although detection solutions are improving with the advances in machine learning techniques, they have been shown to be vulnerable to adversarial samples that carefully crafted perturbation enables them to evade detection. We propose a machine learning based model to attack malware classifiers leveraging the expressive capability of generative adversarial networks (GANs). We use GANs to generate effective adversarial samples by implying a threshold on the distortion amount on the generated samples. We show that the generated samples can bypass detection in 99% of attempts using a real Android application dataset.},
  doi       = {10.1109/AI4Mobile.2019.8672711},
  groups    = {First Filtering},
  keywords  = {Malware;Machine learning;Perturbation methods;Feature extraction;Gallium nitride;Detectors;Computational modeling},
}

@InProceedings{7152200,
  author    = {Can, Okan and Sahingoz, Ozgur Koray},
  booktitle = {2015 6th International Conference on Modeling, Simulation, and Applied Optimization (ICMSAO)},
  title     = {A survey of intrusion detection systems in wireless sensor networks},
  year      = {2015},
  month     = {May},
  pages     = {1-6},
  abstract  = {Wireless Sensor Network (WSN) is a large scale network with from dozens to thousands tiny devices. Using fields of WSNs (military, health, smart home e.g.) has a large-scale and its usage areas increasing day by day. Secure issue of WSNs is an important research area and applications of WSN have some big security deficiencies. Intrusion Detection System is a second-line of the security mechanism for networks, and it is very important to integrity, confidentiality and availability. Intrusion Detection in WSNs is somewhat different from wired and non-energy constraint wireless network because WSN has some constraints influencing cyber security approaches and attack types. This paper is a survey describing attack types of WSNs intrusion detection approaches being against to this attack types.},
  doi       = {10.1109/ICMSAO.2015.7152200},
  groups    = {First Filtering},
  keywords  = {Wireless sensor networks;Intrusion detection;Monitoring;Encryption;Computer crime;Wireless networks},
}

@InProceedings{7443752,
  author    = {Vrat, Bhanu and Aggarwal, Nikhil and Venkatesan, S.},
  booktitle = {2015 Annual IEEE India Conference (INDICON)},
  title     = {Anomaly Detection in IPv4 and IPv6 networks using machine learning},
  year      = {2015},
  month     = {Dec},
  pages     = {1-6},
  abstract  = {Anomaly Detection is an important requirement to secure a network against the attackers. Detecting attacks within a network by analysing the behaviour pattern has been a significant field of study for several researchers and application systems in IPv4 as well as IPv6 networks. For precise anomaly detection, it is essential to implement and use an efficient data-mining methodology like machine learning. In this paper, we contemplated an anomaly detection model which uses machine learning algorithms for data mining within a network to detect anomalies present at any time. This proposed model is evaluated against Denial of Service (DOS) attacks in both IPv4 and IPv6 networks while selecting the most common and evident features of IPv6 and IPv4 networks for optimizing the detection. The results also show that the proposed system can detect most of the IPv4 and IPv6 attacks in efficient manner.},
  doi       = {10.1109/INDICON.2015.7443752},
  groups    = {First Filtering},
  issn      = {2325-9418},
  keywords  = {Intrusion detection;Protocols;Training;Feature extraction;Machine learning algorithms;Telecommunication traffic},
}

@InProceedings{8767194,
  author    = {Kumar, Ayush and Lim, Teng Joon},
  booktitle = {2019 IEEE 5th World Forum on Internet of Things (WF-IoT)},
  title     = {EDIMA: Early Detection of IoT Malware Network Activity Using Machine Learning Techniques},
  year      = {2019},
  month     = {April},
  pages     = {289-294},
  abstract  = {The widespread adoption of Internet of Things has led to many security issues. Post the Mirai-based DDoS attack in 2016 which compromised IoT devices, a host of new malware using Mirai's leaked source code and targeting IoT devices have cropped up, e.g. Satori, Reaper, Amnesia, Masuta etc. These malware exploit software vulnerabilities to infect IoT devices instead of open TELNET ports (like Mirai) making them more difficult to block using existing solutions such as firewalls. In this research, we present EDIMA, a distributed modular solution which can be used towards the detection of IoT malware network activity in large-scale networks (e.g. ISP, enterprise networks) during the scanning/infecting phase rather than during an attack. EDIMA employs machine learning algorithms for edge devices' traffic classification, a packet traffic feature vector database, a policy module and an optional packet sub-sampling module. We evaluate the classification performance of EDIMA through testbed experiments and present the results obtained.},
  doi       = {10.1109/WF-IoT.2019.8767194},
  groups    = {First Filtering},
  keywords  = {Malware;Botnet;Logic gates;Feature extraction;Internet of Things;Databases;Computer crime;Internet of Things;IoT;Malware;Mirai;Reaper;Satori;Botnet;Bot Detection;Machine Learning;Anomaly Detection},
}

@InProceedings{8952401,
  author    = {Guo, Qianyu and Chen, Sen and Xie, Xiaofei and Ma, Lei and Hu, Qiang and Liu, Hongtao and Liu, Yang and Zhao, Jianjun and Li, Xiaohong},
  booktitle = {2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  title     = {An Empirical Study Towards Characterizing Deep Learning Development and Deployment Across Different Frameworks and Platforms},
  year      = {2019},
  month     = {Nov},
  pages     = {810-822},
  abstract  = {Deep Learning (DL) has recently achieved tremendous success. A variety of DL frameworks and platforms play a key role to catalyze such progress. However, the differences in architecture designs and implementations of existing frameworks and platforms bring new challenges for DL software development and deployment. Till now, there is no study on how various mainstream frameworks and platforms influence both DL software development and deployment in practice. To fill this gap, we take the first step towards understanding how the most widely-used DL frameworks and platforms support the DL software development and deployment. We conduct a systematic study on these frameworks and platforms by using two types of DNN architectures and three popular datasets. (1) For development process, we investigate the prediction accuracy under the same runtime training configuration or same model weights/biases. We also study the adversarial robustness of trained models by leveraging the existing adversarial attack techniques. The experimental results show that the computing differences across frameworks could result in an obvious prediction accuracy decline, which should draw the attention of DL developers. (2) For deployment process, we investigate the prediction accuracy and performance (refers to time cost and memory consumption) when the trained models are migrated/quantized from PC to real mobile devices and web browsers. The DL platform study unveils that the migration and quantization still suffer from compatibility and reliability issues. Meanwhile, we find several DL software bugs by using the results as a benchmark. We further validate the results through bug confirmation from stakeholders and industrial positive feedback to highlight the implications of our study. Through our study, we summarize practical guidelines, identify challenges and pinpoint new research directions, such as understanding the characteristics of DL frameworks and platforms, avoiding compatibility and reliability issues, detecting DL software bugs, and reducing time cost and memory consumption towards developing and deploying high quality DL systems effectively.},
  doi       = {10.1109/ASE.2019.00080},
  groups    = {First Filtering},
  issn      = {2643-1572},
  keywords  = {Software;Predictive models;Quantization (signal);Training;Mobile handsets;Computational modeling;Runtime;Deep learning frameworks;Deep learning platforms;Deep learning deployment;Empirical study},
}

@InProceedings{9299622,
  author    = {Kalshetty, Rakesh and Parveen, Asma},
  booktitle = {2020 International Conference on Smart Innovations in Design, Environment, Management, Planning and Computing (ICSIDEMPC)},
  title     = {The various surveillance and detection techniques based on wireless sensor networks},
  year      = {2020},
  month     = {Oct},
  pages     = {51-56},
  abstract  = {In this paper, we describe multiple methods used for surveillance and tracking of abnormalities instead of a commercial image processing system, we build an efficient surveillance system in areas of interest by utilizing internet of things and wireless sensors platform. The kinds of cameras and sensors considered that are to be deployed in the area of interest for monitoring suspicious behavior of intruders and conditions such as temperature, humidity, and fire accidents. Then the sensed data is collected and processed locally then transmitted wirelessly to alert an administrator or caretaker about mishappening in the area of interest.},
  doi       = {10.1109/ICSIDEMPC49020.2020.9299622},
  groups    = {First Filtering},
  keywords  = {Sensors;Surveillance;Temperature sensors;Wireless sensor networks;Sensor systems;Intelligent sensors;Humidity;IoT;Real-Time;Context-Aware;Surveillance;Motion-detection;Face-recognition;Wireless Sensor Networks (WSN)},
}

@InProceedings{8802509,
  author    = {Liu, Mengchen and Liu, Shixia and Su, Hang and Cao, Kelei and Zhu, Jun},
  booktitle = {2018 IEEE Conference on Visual Analytics Science and Technology (VAST)},
  title     = {Analyzing the Noise Robustness of Deep Neural Networks},
  year      = {2018},
  month     = {Oct},
  pages     = {60-71},
  abstract  = {Deep neural networks (DNNs) are vulnerable to maliciously generated adversarial examples. These examples are intentionally designed by making imperceptible perturbations and often mislead a DNN into making an incorrect prediction. This phenomenon means that there is significant risk in applying DNNs to safety-critical applications, such as driverless cars. To address this issue, we present a visual analytics approach to explain the primary cause of the wrong predictions introduced by adversarial examples. The key is to analyze the datapaths of the adversarial examples and compare them with those of the normal examples. A datapath is a group of critical neurons and their connections. To this end, we formulate the datapath extraction as a subset selection problem and approximately solve it based on back-propagation. A multi-level visualization consisting of a segmented DAG (layer level), an Euler diagram (feature map level), and a heat map (neuron level), has been designed to help experts investigate datapaths from the high-level layers to the detailed neuron activations. Two case studies are conducted that demonstrate the promise of our approach in support of explaining the working mechanism of adversarial examples.},
  doi       = {10.1109/VAST.2018.8802509},
  groups    = {First Filtering},
  keywords  = {Neurons;Visual analytics;Tools;Feature extraction;Biological neural networks;Machine learning;Deep neural networks;robustness;adversarial examples;back propagation;multi-level visualization.},
}

@InProceedings{6498377,
  author    = {Wagner, Stuart and Berg, Eric Van Den and Giacopelli, Jim and Ghetie, Andrei and Burns, Jim and Tauil, Miriam and Sen, Soumya and Wang, Michael and Chiang, Mung and Lan, Tian and Laddaga, Robert and Robertson, Paul and Manghwani, Prakash},
  booktitle = {2012 IEEE Sixth International Conference on Self-Adaptive and Self-Organizing Systems Workshops},
  title     = {Autonomous, Collaborative Control for Resilient Cyber Defense (ACCORD)},
  year      = {2012},
  month     = {Sep.},
  pages     = {39-46},
  abstract  = {ACCORD addresses the need for robust, rapidly adaptive resource allocation mechanisms in cloud computing. It employs a distributed, game-theoretic approach to apportion computational loads in an efficient, prioritized, Pareto-optimal fashion among geographically dispersed cloud computing infrastructure. This paper describes ACCORD algorithms, software implementation, and initial experimental results. Our results illustrate how a distributed, ACCORD-enabled cloud architecture autonomously adapts to the loss of computing resources (e.g., due to failures, poor network connectivity, or cyber attack) while ensuring that users receive maximal, prioritized utility from available cloud resources.},
  doi       = {10.1109/SASOW.2012.16},
  groups    = {First Filtering},
  keywords  = {cloud computing;game theory;Nash Bargaining;distributed resource allocation},
}

@InProceedings{6212001,
  author    = {Maggi, Federico and Zanero, Stefano},
  booktitle = {2012 IEEE Network Operations and Management Symposium},
  title     = {Integrated detection of anomalous behavior of computer infrastructures},
  year      = {2012},
  month     = {April},
  pages     = {866-871},
  abstract  = {Our research concentrates on anomaly detection techniques, which have both industrial applications such as network monitoring and protection, as well as research applications such as software behavioral analysis or malware classification. During our doctoral research, we worked on anomaly detection from three different perspective, as a complex computer infrastructure has several weak spots that must be protected. We first focused on the operating system, central to any computer, to avoid malicious code to subvert its normal activity. Secondly, we concentrated on web applications, which are the main interface to modern computing: Because of their immense popularity, they have indeed become the most targeted entry point of intrusions. Last, we developed novel techniques with the aim of identifying related events (e.g., alerts reported by intrusion detection systems) to build new and more compact knowledge to detect malicious activity on large-scale systems. During our research we enhanced existing anomaly detection tools and also contributed with new ones. Such tools have been tested over different datasets, both synthetic data and real network traffic, and lead to interesting results that were accepted for publication at main security venues.},
  doi       = {10.1109/NOMS.2012.6212001},
  groups    = {First Filtering},
  issn      = {2374-9709},
  keywords  = {Software;Internet;Accuracy;Computers;Security;Browsers;Training},
}

@InProceedings{6911740,
  author    = {Liang, Shuang and Du, Xiaojiang and Tan, Chiu C. and Yu, Wei},
  booktitle = {2014 23rd International Conference on Computer Communication and Networks (ICCCN)},
  title     = {An effective online scheme for detecting Android malware},
  year      = {2014},
  month     = {Aug},
  pages     = {1-8},
  abstract  = {The growing popularity of Android-based smart-phones have led to the rise of Android based malware. In particular, profit-motivated malware is becoming increasingly popular in Android malware distribution. These malware typically profit by sending premium-rate SMS messages and/or make premium-rate phone calls from infected devices without user consent. In this paper, we investigate the telephony framework of the Android operating system and propose a novel process user-identification (UID) based online detection scheme. Our scheme can effectively detect premium-rate and background SMS messages as well as premium-rate phone calls initiated by malware. We implemented our detection system on a Samsung Google Nexus 4 running Android Jelly Bean and tested the effectiveness of detecting real malware from Android markets. The experimental results show that our scheme is efficient and effective in detecting background messages and premium-rate messages and phone calls. Our scheme can detect and block all the background and premium-rate SMS messages and phone calls initiated by popular malware.},
  doi       = {10.1109/ICCCN.2014.6911740},
  groups    = {First Filtering},
  issn      = {1095-2055},
  keywords  = {Malware;Smart phones;Libraries;Telephony;Linux;Sockets;Mobile communication;Android;smartphone;malware detection;security},
}

@InProceedings{7546253,
  author    = {Soni, Mohit and Ahirwa, Manish and Agrawal, Shikha},
  booktitle = {2015 International Conference on Computational Intelligence and Communication Networks (CICN)},
  title     = {A Survey on Intrusion Detection Techniques in MANET},
  year      = {2015},
  month     = {Dec},
  pages     = {1027-1032},
  abstract  = {The mobile ad-hoc network (MANET) is a new wireless technology, having features like dynamic topology and self-configuring ability of nodes. The self configuring ability of nodes in MANET made it popular among the critical situation such as military use and emergency recovery. But due to open medium and broad distribution of nodes make MANET vulnerable to different attacks. So to protect MANET from various attacks, it is important to develop an efficient and secure system for MANET. Intrusion means any set of actions that attempt to compromise the integrity, confidentiality, or availability of a resource. Intrusion Prevention is the primary defense because it is the first step to make the systems secure from attacks by using passwords, biometrics etc. Even if intrusion prevention methods are used, the system may be subjected to some vulnerability. So we need a second wall of defense known as Intrusion Detection Systems (IDSs), to detect and produce responses whenever necessary. In this article we present a survey of various intrusion detection schemes available for ad hoc networks. We have also described some of the basic attacks present in ad hoc network and discussed their available solution.},
  doi       = {10.1109/CICN.2015.204},
  groups    = {First Filtering},
  issn      = {2472-7555},
  keywords  = {Mobile ad hoc networks;Intrusion detection;Wireless communication;Routing protocols;Mobile nodes;Mobile Ad hoc Network;Intrusion Detection System (IDS);IDS in MANET;Security Issues in MANET},
}

@Article{9076680,
  author   = {Hossain, Mohammad Asif and Noor, Rafidah Md. and Yau, Kok-Lim Alvin and Azzuhri, Saaidal Razalli and Z’aba, Muhammad Reza and Ahmedy, Ismail},
  journal  = {IEEE Access},
  title    = {Comprehensive Survey of Machine Learning Approaches in Cognitive Radio-Based Vehicular Ad Hoc Networks},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {78054-78108},
  volume   = {8},
  abstract = {Nowadays, machine learning (ML), which is one of the most rapidly growing technical tools, is extensively used to solve critical challenges in various domains. Vehicular ad hoc network (VANET) is expected to be the key role player in reducing road casualties and traffic congestion. To ensure this role, a gigantic amount of data should be exchanged. However, current allocated wireless access for VANET is inadequate to handle such massive data amounts. Therefore, VANET faces a spectrum scarcity issue. Cognitive radio (CR) is a promising solution to overcome such an issue. CR-based VANET or CR-VANET must achieve several performance enhancement measures, including ultra-reliable and low-latency communication. ML methods can be integrated with CR-VANET to make CR-VANET highly intelligent, achieve rapid adaptability to the dynamicity of the environment, and improve the quality of service in an energy-efficient manner. This paper presents an overview of ML, CR, VANET, and CR-VANET, including their architectures, functions, challenges, and open issues. The applications and roles of ML methods in CR-VANET scenarios are reviewed. Insights into the use of ML for autonomous or driver-less vehicles are also presented. Current advancements in the amalgamation of these prominent technologies and future research directions are discussed.},
  doi      = {10.1109/ACCESS.2020.2989870},
  groups   = {First Filtering},
  keywords = {Vehicular ad hoc networks;Quality of service;Transportation;Sensors;Road accidents;Bandwidth;Machine learning;Machine learning;VANET;cognitive radio;autonomous vehicles;smart transportation system},
}

@InProceedings{8251130,
  author    = {Kamboj, Priyanka and Trivedi, Munesh Chandra and Yadav, Virendra Kumar and Singh, Vikash Kumar},
  booktitle = {2017 4th IEEE Uttar Pradesh Section International Conference on Electrical, Computer and Electronics (UPCON)},
  title     = {Detection techniques of DDoS attacks: A survey},
  year      = {2017},
  month     = {Oct},
  pages     = {675-679},
  abstract  = {Security is the main confront of internet, Distributed Denial of Service (DDoS) is the major cause of threat. DDoS reduces the network resources, and results in bandwidth depletion. The main aim of DDoS is to prevent legitimate users from assessing the services. There also exists a difficulty to differentiate between flash crowd and DDoS attack traffic. The various existing solutions which are given in order to detect DDoS has been discussed in this paper. The goal of the paper is to review how the different methods are helping in downsizing the effect of DDoS and also how that are being used to detect a DDoS attack.},
  doi       = {10.1109/UPCON.2017.8251130},
  groups    = {First Filtering},
  keywords  = {Computer crime;IP networks;Servers;Entropy;Monitoring;Protocols;Distributed Denial of Service (DDoS);Detection;Flash Crowd;Traceback;Entropy;Intrusion Detection System(IDS);Intrusion Prevention System(IPS)},
}

@InProceedings{9157729,
  author    = {Kong, Zelun and Guo, Junfeng and Li, Ang and Liu, Cong},
  booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {PhysGAN: Generating Physical-World-Resilient Adversarial Examples for Autonomous Driving},
  year      = {2020},
  month     = {June},
  pages     = {14242-14251},
  abstract  = {Although Deep neural networks (DNNs) are being pervasively used in vision-based autonomous driving systems, they are found vulnerable to adversarial attacks where small-magnitude perturbations into the inputs during test time cause dramatic changes to the outputs. While most of the recent attack methods target at digital-world adversarial scenarios, it is unclear how they perform in the physical world, and more importantly, the generated perturbations under such methods would cover a whole driving scene including those fixed background imagery such as the sky, making them inapplicable to physical world implementation. We present PhysGAN, which generates physical-world-resilient adversarial examples for misleading autonomous driving systems in a continuous manner. We show the effectiveness and robustness of PhysGAN via extensive digital- and real-world evaluations. We compare PhysGAN with a set of state-of-the-art baseline methods, which further demonstrate the robustness and efficacy of our approach. We also show that PhysGAN outperforms state-of-the-art baseline methods. To the best of our knowledge, PhysGAN is probably the first technique of generating realistic and physical-world-resilient adversarial examples for attacking common autonomous driving scenarios.},
  doi       = {10.1109/CVPR42600.2020.01426},
  groups    = {First Filtering},
  issn      = {2575-7075},
  keywords  = {Autonomous vehicles;Gallium nitride;Feature extraction;Generators;Tensile stress;Perturbation methods;Three-dimensional displays},
}

@Article{9470919,
  author   = {Zhang, Shudong and Gao, Haichang and Rao, Qingxun},
  journal  = {IEEE Transactions on Image Processing},
  title    = {Defense Against Adversarial Attacks by Reconstructing Images},
  year     = {2021},
  issn     = {1941-0042},
  pages    = {6117-6129},
  volume   = {30},
  abstract = {Convolutional neural networks (CNNs) are vulnerable to being deceived by adversarial examples generated by adding small, human-imperceptible perturbations to a clean image. In this paper, we propose an image reconstruction network that reconstructs an input adversarial example into a clean output image to defend against such adversarial attacks. Due to the powerful learning capabilities of the residual block structure, our model can learn a precise mapping from adversarial examples to reconstructed examples. The use of a perceptual loss greatly suppresses the error amplification effect and improves the performance of our reconstruction network. In addition, by adding randomization layers to the end of the network, the effects of additional noise are further suppressed, especially for iterative attacks. Our model has the following four advantages. 1) It greatly reduces the impact of adversarial perturbations while having little influence on the prediction performance of clean images. 2) During inference phase, it performs better than most existing model-agnostic defense methods. 3) It has better generalization capability. 4) It can be flexibly combined with other methods, such as adversarially trained models.},
  doi      = {10.1109/TIP.2021.3092582},
  groups   = {First Filtering},
  keywords = {Perturbation methods;Image reconstruction;Training;Iterative methods;Computational modeling;Predictive models;Transform coding;CNN;adversarial examples;adversarial attacks;defend;residual block;reconstruction network;perceptual loss},
}

@Article{6189766,
  author   = {Francois, Jérôme and Aib, Issam and Boutaba, Raouf},
  journal  = {IEEE/ACM Transactions on Networking},
  title    = {FireCol: A Collaborative Protection Network for the Detection of Flooding DDoS Attacks},
  year     = {2012},
  issn     = {1558-2566},
  month    = {Dec},
  number   = {6},
  pages    = {1828-1841},
  volume   = {20},
  abstract = {Distributed denial-of-service (DDoS) attacks remain a major security problem, the mitigation of which is very hard especially when it comes to highly distributed botnet-based attacks. The early discovery of these attacks, although challenging, is necessary to protect end-users as well as the expensive network infrastructure resources. In this paper, we address the problem of DDoS attacks and present the theoretical foundation, architecture, and algorithms of FireCol. The core of FireCol is composed of intrusion prevention systems (IPSs) located at the Internet service providers (ISPs) level. The IPSs form virtual protection rings around the hosts to defend and collaborate by exchanging selected traffic information. The evaluation of FireCol using extensive simulations and a real dataset is presented, showing FireCol effectiveness and low overhead, as well as its support for incremental deployment in real networks.},
  doi      = {10.1109/TNET.2012.2194508},
  groups   = {First Filtering},
  keywords = {Fires;Entropy;Computer crime;Collaboration;Time frequency analysis;IP networks;Collaboration;detection;distributed denial-of-service (DDos);flooding;network security},
}

@Article{9405669,
  author   = {Mishra, Nivedita and Pandya, Sharnil},
  journal  = {IEEE Access},
  title    = {Internet of Things Applications, Security Challenges, Attacks, Intrusion Detection, and Future Visions: A Systematic Review},
  year     = {2021},
  issn     = {2169-3536},
  pages    = {59353-59377},
  volume   = {9},
  abstract = {Internet of Things (IoT) technology is prospering and entering every part of our lives, be it education, home, vehicles, or healthcare. With the increase in the number of connected devices, several challenges are also coming up with IoT technology: heterogeneity, scalability, quality of service, security requirements, and many more. Security management takes a back seat in IoT because of cost, size, and power. It poses a significant risk as lack of security makes users skeptical towards using IoT devices. This, in turn, makes IoT vulnerable to security attacks, ultimately causing enormous financial and reputational losses. It makes up for an urgent need to assess present security risks and discuss the upcoming challenges to be ready to face the same. The undertaken study is a multi-fold survey of different security issues present in IoT layers: perception layer, network layer, support layer, application layer, with further focus on Distributed Denial of Service (DDoS) attacks. DDoS attacks are significant threats for the cyber world because of their potential to bring down the victims. Different types of DDoS attacks, DDoS attacks in IoT devices, impacts of DDoS attacks, and solutions for mitigation are discussed in detail. The presented review work compares Intrusion Detection and Prevention models for mitigating DDoS attacks and focuses on Intrusion Detection models. Furthermore, the classification of Intrusion Detection Systems, different anomaly detection techniques, different Intrusion Detection System models based on datasets, various machine learning and deep learning techniques for data pre-processing and malware detection has been discussed. In the end, a broader perspective has been envisioned while discussing research challenges, its proposed solutions, and future visions.},
  doi      = {10.1109/ACCESS.2021.3073408},
  groups   = {First Filtering},
  keywords = {Internet of Things;Security;Intrusion detection;Denial-of-service attack;Systematics;Deep learning;Machine vision;Anomaly detection;DDoS attacks;deep learning;machine learning;Internet of Things;intrusion detection system},
}

@InProceedings{7575364,
  author    = {Laurenza, Giuseppe and Ucci, Daniele and Aniello, Leonardo and Baldoni, Roberto},
  booktitle = {2016 46th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshop (DSN-W)},
  title     = {An Architecture for Semi-Automatic Collaborative Malware Analysis for CIs},
  year      = {2016},
  month     = {June},
  pages     = {137-142},
  abstract  = {Critical Infrastructures (CIs) are among the main targets of activists, cyber terrorists and state sponsored attacks. To protect itself, a CI needs to build and keep updated a domestic knowledge base of cyber threats. It cannot indeed completely rely on external service providers because information on incidents can be so sensible to impact national security. In this paper, we propose an architecture for a malware analysis framework to support CIs in such a challenging task. Given the huge number of new malware produced daily, the architecture is designed so as to automate the analysis to a large extent, leaving to human analysts only a small and manageable part of the whole effort. Such a non-automatic part of the analysis requires a wide range of expertise, usually contributed by more analysts. The architecture enables analysts to work collaboratively to improve the understanding of samples that demand deeper investigations (intra-CI collaboration). Furthermore, the architecture allows to share partial and configurable views of the knowledge base with other interested CIs, in order to collectively obtain a more complete vision of the cyber threat landscape (inter-CI collaboration).},
  doi       = {10.1109/DSN-W.2016.40},
  groups    = {First Filtering},
  keywords  = {Malware;Collaboration;Knowledge based systems;Architecture;Computer architecture;Security;Companies;collaborative analysis;automatic malware analysis;critical infrastructure protection},
}

@InProceedings{7457159,
  author    = {Lyu, Lingjuan and Law, Yee Wei and Erfani, Sarah M. and Leckie, Christopher and Palaniswami, Marimuthu},
  booktitle = {2016 IEEE International Conference on Pervasive Computing and Communication Workshops (PerCom Workshops)},
  title     = {An improved scheme for privacy-preserving collaborative anomaly detection},
  year      = {2016},
  month     = {March},
  pages     = {1-6},
  abstract  = {The ubiquity of mobile sensing devices in the Internet of Things (IoT) enables an emerging data crowdsourcing paradigm called participatory sensing, where multiple individuals collect data and use a cloud service to analyse the union of the collected data. An example of such collaborative analysis is collaborative anomaly detection. Given the possibility that the cloud service is honest but curious, a major challenge is how to protect the participants' privacy. The scheme called Random Multiparty Perturbation (RMP) addresses this challenge by allowing each participant to perturb his/her tabular data by passing the data through a nonlinear function, and projecting the data to a lower dimension using a participant-specific random matrix. Here, we propose an improvement to RMP by introducing a new nonlinear function. The improved scheme is assessed in terms of its recovery resistance to the maximum a priori (MAP) estimation attack. Experimental results and preliminary theoretical analysis indicate that RMP is resistant to collusion attacks and has better recovery resistance to MAP estimation attacks compared to the original scheme. It also achieves a good trade-off between accuracy and privacy.},
  doi       = {10.1109/PERCOMW.2016.7457159},
  groups    = {First Filtering},
  keywords  = {Data privacy;Privacy;Estimation;Logistics;Sensors;Resistance},
}

@InProceedings{6786161,
  author    = {Le, Nam Do-Hoang and Tran, Minh-Triet},
  booktitle = {2013 12th International Conference on Machine Learning and Applications},
  title     = {A Robust Unsupervised Feature Learning Framework Using Spatial Boosting Networks},
  year      = {2013},
  month     = {Dec},
  pages     = {507-512},
  volume    = {2},
  abstract  = {To boost up power of unsupervised feature learning and deep learning, there has been a great effort in optimizing network structure to learn more efficient high level features. It is crucial for a network to have a sufficient amount of learnable parameters yet still be able to capture in variances in data. In this paper, the authors propose spatial boosting networks, which employ convolutional feature learning networks as learning components. Each component in a network is assigned to a certain spatial region. This allows the network learn more adaptive features for each region. In order to make spatial boosting networks to capture relationship between regions of the visual field, we also propose convolutional pooling procedure. By expanding pooling scope into overlapping regions, we expect the features pooled in higher level to be more robust to noises and more invariant to transformation. Experiments show that using spatial boosting networks boosts up accuracy up to 3% from conventional approaches in standard datasets CIFAR and STL. Moreover, these results are competitive in comparison with other methods by using only a basic feature learning algorithm.},
  doi       = {10.1109/ICMLA.2013.168},
  groups    = {First Filtering},
  keywords  = {Boosting;Accuracy;Visualization;Biological neural networks;Vectors;Convolutional codes;Convolution;unsupervised feature learning;deep learning;neural networks},
}

@InProceedings{8535799,
  author    = {Guan, Zhenyu and Bian, Liangxu and Shang, Tao and Liu, Jianwei},
  booktitle = {2018 IEEE International Conference on Intelligence and Safety for Robotics (ISR)},
  title     = {When Machine Learning meets Security Issues: A survey},
  year      = {2018},
  month     = {Aug},
  pages     = {158-165},
  abstract  = {Machine learning is one of the most prevalent techniques in recent decades which has been widely applied in various fields. Among them, the applications that detect and defend potential adversarial attacks using machine learning method provide promising solutions in cybersecurity. At the same time, machine learning algorithms and systems are vulnerable to multiple security threats. In this paper, we revisit certain literatures and present a comprehensive survey from two respects, application of machine learning on cybersecurity and reliability and security of machine learning system. We then overview security issues of mobile AI devices and propose two notable focus, which are worthy in-depth studies in future. Researchers can regard this survey as a navigating reference in both machine learning and cybersecurity fields.},
  doi       = {10.1109/IISR.2018.8535799},
  groups    = {First Filtering},
  keywords  = {Machine learning;Malware;Phishing;Feature extraction;Distributed databases;machine learning;cybersecurity;threats;defense},
}

@InProceedings{9449245,
  author    = {Guan, Zhibin and Wang, Jiajie and Wang, Xiaomeng and Xin, Wei and Cui, Jing and Jing, Xiangping},
  booktitle = {2021 IEEE 6th International Conference on Computer and Communication Systems (ICCCS)},
  title     = {A Comparative Study of RNN-based Methods for Web Malicious Code Detection},
  year      = {2021},
  month     = {April},
  pages     = {769-773},
  abstract  = {Malicious code can be embedded into Web applications in various ways, which will lead to frequent malicious Web attacks. In the deep learning-based Web malicious code detection methods, the effect and applicability of different RNN-based methods are unknown, which needs to be further study. Therefore, a comparative study of RNN-based methods for Web malicious code detection was conducted in this paper. Different from existing research, this paper not only analyzes and discusses the advantages and disadvantages of different RNN-based methods, including LSTM, GRU, SRU, but also utilizes Web malicious code detection as the application target to evaluate the actual performance of these methods. Experiment results show that the recall rates of GRU and SRU are 81.07% and 80.96%, respectively, which are higher than LSTM and minimalRNN. The performance of textCNN is relatively satisfactory, with scores of 90.6%, 85.54%, 87.95%, 94.4% in terms of precision, recall, F1 and AUC respectively. The comparative study displays that the performance of RNN-based Web malicious code detection methods is greatly affected by the preprocessing ways of source code.},
  doi       = {10.1109/ICCCS52626.2021.9449245},
  groups    = {First Filtering},
  keywords  = {Communication systems;Conferences;Malware;Web malicious code;malicious code detection;deep learning;RNN;CNN;comparative study},
}

@Article{9479867,
  author   = {Harford, Samuel and Karim, Fazle and Darabi, Houshang},
  journal  = {IEEE/CAA Journal of Automatica Sinica},
  title    = {Generating Adversarial Samples on Multivariate Time Series using Variational Autoencoders},
  year     = {2021},
  issn     = {2329-9274},
  month    = {Sep.},
  number   = {9},
  pages    = {1523-1538},
  volume   = {8},
  abstract = {Classification models for multivariate time series have drawn the interest of many researchers to the field with the objective of developing accurate and efficient models. However, limited research has been conducted on generating adversarial samples for multivariate time series classification models. Adversarial samples could become a security concern in systems with complex sets of sensors. This study proposes extending the existing gradient adversarial transformation network (GATN) in combination with adversarial autoencoders to attack multivariate time series classification models. The proposed model attacks classification models by utilizing a distilled model to imitate the output of the multivariate time series classification model. In addition, the adversarial generator function is replaced with a variational autoencoder to enhance the adversarial samples. The developed methodology is tested on two multivariate time series classification models: 1-nearest neighbor dynamic time warping (1-NN DTW) and a fully convolutional network (FCN). This study utilizes 30 multivariate time series benchmarks provided by the University of East Anglia (UEA) and University of California Riverside (UCR). The use of adversarial autoencoders shows an increase in the fraction of successful adversaries generated on multivariate time series. To the best of our knowledge, this is the first study to explore adversarial attacks on multivariate time series. Additionally, we recommend future research utilizing the generated latent space from the variational autoencoders.},
  doi      = {10.1109/JAS.2021.1004108},
  groups   = {First Filtering},
  keywords = {Adversarial machine learning;deep learning;multivariate time series;perturbation methods},
}

@InProceedings{6144819,
  author    = {Zargar, Saman Taghavi and Takabi, Hassan and Joshi, James B.D.},
  booktitle = {7th International Conference on Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom)},
  title     = {DCDIDP: A distributed, collaborative, and data-driven intrusion detection and prevention framework for cloud computing environments},
  year      = {2011},
  month     = {Oct},
  pages     = {332-341},
  abstract  = {With the growing popularity of cloud computing, the exploitation of possible vulnerabilities grows at the same pace; the distributed nature of the cloud makes it an attractive target for potential intruders. Despite security issues delaying its adoption, cloud computing has already become an unstoppable force; thus, security mechanisms to ensure its secure adoption are an immediate need. Here, we focus on intrusion detection and prevention systems (IDPSs) to defend against the intruders. In this paper, we propose a Distributed, Collaborative, and Data-driven Intrusion Detection and Prevention system (DCDIDP). Its goal is to make use of the resources in the cloud and provide a holistic IDPS for all cloud service providers which collaborate with other peers in a distributed manner at different architectural levels to respond to attacks. We present the DCDIDP framework, whose infrastructure level is composed of three logical layers: network, host, and global as well as platform and software levels. Then, we review its components and discuss some existing approaches to be used for the modules in our proposed framework. Furthermore, we discuss developing a comprehensive trust management framework to support the establishment and evolution of trust among different cloud service providers.},
  groups    = {First Filtering},
  keywords  = {Indium tin oxide;Computational modeling;Load modeling;Virtual machine monitors;Cloud computing;intrusion detection;collaborative IDPS;distributed IDPS},
}

@InProceedings{7868376,
  author    = {Watkins, Lanier and Beck, Sean and Zook, Jared and Buczak, Anna and Chavis, Jeffery and Robinson, William H. and Morales, Jose A. and Mishra, Samuel},
  booktitle = {2017 IEEE 7th Annual Computing and Communication Workshop and Conference (CCWC)},
  title     = {Using semi-supervised machine learning to address the Big Data problem in DNS networks},
  year      = {2017},
  month     = {Jan},
  pages     = {1-6},
  abstract  = {The problem of Big Data in cyber security (i.e., too much network data to analyze) compounds itself every day. Our approach is based on a fundamental characteristic of Big Data: an overwhelming majority of the network traffic in a traditionally secured enterprise (i.e., using defense-in-depth) is non-malicious. Therefore, one way of eliminating the Big Data problem in cyber security is to ignore the overwhelming majority of an enterprise's non-malicious network traffic and focus only on the smaller amounts of suspicious or malicious network traffic. Our approach uses simple clustering along with a dataset enriched with known malicious domains (i.e., anchors) to accurately and quickly filter out the non-suspicious network traffic. Our algorithm has demonstrated the predictive ability to accurately filter out approximately 97% (depending on the algorithm used) of the non-malicious data in millions of Domain Name Service (DNS) queries in minutes and identify the small percentage of unseen suspicious network traffic. We demonstrate that the resulting network traffic can be analyzed with traditional reputation systems, blacklists, or in-house threat tracking sources (we used virustotal.com) to identify harmful domains that are being accessed from within the enterprise network. Specifically, our results show that the method can reduce a dataset of 400k query-answer domains (with complete malicious domain ground truth) down to only 3% containing 99% of all malicious domains. Further, we demonstrate that this capability scales to 10 million query-answer pairs, which it can reduce by 97% in less than an hour.},
  doi       = {10.1109/CCWC.2017.7868376},
  groups    = {First Filtering},
  keywords  = {Clustering algorithms;Big data;Telecommunication traffic;Semisupervised learning;Computer security;Approximation algorithms;Sensitivity},
}

@InProceedings{8854377,
  author    = {Khalid, Faiq and Ali, Hassan and Tariq, Hammad and Hanif, Muhammad Abdullah and Rehman, Semeen and Ahmed, Rehan and Shafique, Muhammad},
  booktitle = {2019 IEEE 25th International Symposium on On-Line Testing and Robust System Design (IOLTS)},
  title     = {QuSecNets: Quantization-based Defense Mechanism for Securing Deep Neural Network against Adversarial Attacks},
  year      = {2019},
  month     = {July},
  pages     = {182-187},
  abstract  = {Adversarial examples have emerged as a significant threat to machine learning algorithms, especially to the convolutional neural networks (CNNs). In this paper, we propose two quantization-based defense mechanisms, Constant Quantization (CQ) and Trainable Quantization (TQ), to increase the robustness of CNNs against adversarial examples. CQ quantizes input pixel intensities based on a “fixed” number of quantization levels, while in TQ, the quantization levels are “iteratively learned during the training phase”, thereby providing a stronger defense mechanism. We apply the proposed techniques on undefended CNNs against different state-of-the-art adversarial attacks from the open-source Cleverhans library. The experimental results demonstrate 50%-96% and 10%-50% increase in the classification accuracy of the perturbed images generated from the MNIST and the CIFAR-10 datasets, respectively, on commonly used CNN (Conv2D(64, 8×8)-Conv2D(128, 6×6)-Conv2D(128, 5×5) - Dense(10) - Softmax()) available in Cleverhans library.},
  doi       = {10.1109/IOLTS.2019.8854377},
  groups    = {First Filtering},
  issn      = {1942-9401},
  keywords  = {Quantization (signal);Training;Libraries;Perturbation methods;Optimization;Resilience;Convolutional neural networks;Machine Learning;DNN;Quantization;Trainable Quantization;Security;Adversarial Machine Learning;Defense;Adversarial Attacks;Convolutional Neural Networks;CNN;Classification},
}

@InProceedings{9034406,
  author    = {Akhil Sharma, VHS.P and Saravanan, M},
  booktitle = {2018 3rd International Conference on Inventive Computation Technologies (ICICT)},
  title     = {A comprehensive discovery for preventing Denial of service intrusions over Hybrid cloud using Emerging techniques(ROTA)},
  year      = {2018},
  month     = {Nov},
  pages     = {463-468},
  abstract  = {Intrusion Detection Systems (IDS) are the and firewalls standby of network security boundary from decades of the works in analysis and have evolved with increasing of the sophistication and over time and technologies advance for maintaining the protection of the sensitive on hybrid cloud. These nodes are bearing root problems with Dos & DDoS intrusions as of numerous connected clouds over the world. wherever possible up to the date approaches and advanced techniques should in any respect times upgraded to produce[3] [12] Additionally securities to intercept these hosts and the hybrid cloud itself from changing into overcoming throughout those intrusions. The intention of the work is to relinquish an analysis of DoS and DDoS intrusions, prepare a inventory fundamental network intrusion safeguard methods, prepare a fast contrast of present and rising intrusion prevention strategies offered and to relinquish an case development state of affairs victimization one of this merchandise. This work proposes an Emerging Intrusion detection system(EIDS) for general enterprise sensitive clouds. This paper proposed after Rota technique for security purpose on regex model of decryption and encryption with the 6-bit couple making model.},
  doi       = {10.1109/ICICT43934.2018.9034406},
  groups    = {First Filtering},
  keywords  = {DDoS;security;hybrid cloud;regex service},
}

@Article{8440825,
  author   = {Goodall, John R. and Ragan, Eric D. and Steed, Chad A. and Reed, Joel W. and Richardson, G. David and Huffer, Kelly M.T. and Bridges, Robert A. and Laska, Jason A.},
  journal  = {IEEE Transactions on Visualization and Computer Graphics},
  title    = {Situ: Identifying and Explaining Suspicious Behavior in Networks},
  year     = {2019},
  issn     = {1941-0506},
  month    = {Jan},
  number   = {1},
  pages    = {204-214},
  volume   = {25},
  abstract = {Despite the best efforts of cyber security analysts, networked computing assets are routinely compromised, resulting in the loss of intellectual property, the disclosure of state secrets, and major financial damages. Anomaly detection methods are beneficial for detecting new types of attacks and abnormal network activity, but such algorithms can be difficult to understand and trust. Network operators and cyber analysts need fast and scalable tools to help identify suspicious behavior that bypasses automated security systems, but operators do not want another automated tool with algorithms they do not trust. Experts need tools to augment their own domain expertise and to provide a contextual understanding of suspicious behavior to help them make decisions. In this paper we present Situ, a visual analytics system for discovering suspicious behavior in streaming network data. Situ provides a scalable solution that combines anomaly detection with information visualization. The system's visualizations enable operators to identify and investigate the most anomalous events and IP addresses, and the tool provides context to help operators understand why they are anomalous. Finally, operators need tools that can be integrated into their workflow and with their existing tools. This paper describes the Situ platform and its deployment in an operational network setting. We discuss how operators are currently using the tool in a large organization's security operations center and present the results of expert reviews with professionals.},
  doi      = {10.1109/TVCG.2018.2865029},
  groups   = {First Filtering},
  keywords = {Data visualization;Network security;Machine learning;Anomaly detection;Visual analytics;Network security;situational awareness;privacy and security;streaming data;machine learning;visualization},
}

@InProceedings{8588971,
  author    = {Tripathy, Satya Narayan and Kapat, Sisira Kumar and Kumar, D. Anil and Nayak, Mamata and Das, Susanta Kumar},
  booktitle = {2018 2nd International Conference on Data Science and Business Analytics (ICDSBA)},
  title     = {A Survey on Malware Detection Approaches Using EULA Analysis with Text Mining},
  year      = {2018},
  month     = {Sep.},
  pages     = {517-522},
  abstract  = {Malware is a major threat to the computer security. There are so many variants of malware evolving each day which results the loss in economy as well as data and personal information is precious than economy. Malware prevention can be achieved by carefully analyzing the content of the EULA. As EULA analysis deals with analyzing the unstructured text documents, text mining concept plays an important role. This paper analyzes the detection mechanism for malware detection, using text mining over an ample set of existing EULA. The comparison presented in this paper highlights some malware analysis and text mining techniques. Although there are several malware detection systems exist, evolution and revolution is required to fill the gap in malware evolution and detection. In order to achieve the goal or to verify the authenticity of an executable, this paper provides an alternate approach to detect the malware before execution. EULA analysis which acts as gateway can be included in other behavioral or data mining based malware detection system to achieve both external and internal security of the computing system including mobile devices.},
  doi       = {10.1109/ICDSBA.2018.00102},
  groups    = {First Filtering},
  keywords  = {Data science;Business;Component, Malware, EULA Analysis, Text Mining, Malware Detection, Survey, Computer Security},
}

@Article{9146148,
  author   = {Al-Khater, Wadha Abdullah and Al-Maadeed, Somaya and Ahmed, Abdulghani Ali and Sadiq, Ali Safaa and Khan, Muhammad Khurram},
  journal  = {IEEE Access},
  title    = {Comprehensive Review of Cybercrime Detection Techniques},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {137293-137311},
  volume   = {8},
  abstract = {Cybercrimes are cases of indictable offences and misdemeanors that involve computers or communication tools as targets and commission instruments or are associated with the prevalence of computer technology. Common forms of cybercrimes are child pornography, cyberstalking, identity theft, cyber laundering, credit card theft, cyber terrorism, drug sale, data leakage, sexually explicit content, phishing, and other forms of cyber hacking. They mostly lead to a privacy breach, security violation, business loss, financial fraud, or damage in public and government properties. Thus, this study intensively reviews cybercrime detection and prevention techniques. It first explores the different types of cybercrimes and discusses their threats against privacy and security in computer systems. Then, it describes the strategies that cybercriminals may utilize in committing these crimes against individuals, organizations, and societies. It also reviews the existing techniques of cybercrime detection and prevention. It objectively discusses the strengths and critically analyzes the vulnerabilities of each technique. Finally, it provides recommendations for the development of a cybercrime detection model that can detect cybercrimes effectively compared with the existing techniques.},
  doi      = {10.1109/ACCESS.2020.3011259},
  groups   = {First Filtering},
  keywords = {Phishing;Cyber terrorism;Government;Tools;Companies;Security;cybercrime detection techniques;neural network;fuzzy logic;machine learning;data mining},
}

@InProceedings{7311978,
  author    = {Mironeanu, Catalin and Craus, Mitica and Butincu, Cnstian Nicolae},
  booktitle = {2015 14th RoEduNet International Conference - Networking in Education and Research (RoEduNet NER)},
  title     = {Intrusion detection using alert prioritization and multiple minimum supports},
  year      = {2015},
  month     = {Sep.},
  pages     = {109-114},
  abstract  = {Due to increase in traffic volume, current commercial IDSs (Intrusion Detection Systems) usually tend to produce a very large number of alarms. Although these alarms are triggered by actual intrusions, they are often triggered by regular user behavior, thus increasing the false alarm rate and overwhelming the security administrator. Mining algorithms that identify association rules provide an in-depth analysis of security breaches and extend the functionality of IDSs. In this paper we present a potential solution for reducing the false alarm rate. Our approach is based on the prioritization of alerts, a rescoring mechanism and data mining techniques with multiple minimum supports.},
  doi       = {10.1109/RoEduNet.2015.7311978},
  groups    = {First Filtering},
  issn      = {2247-5443},
  keywords  = {Decision support systems;Intrusion detection;Alert correlation;Alert prioritization;Data mining;Multiple minimum supports},
}

@InProceedings{8646335,
  author    = {Clements, Joseph and Lao, Yingjie},
  booktitle = {2018 IEEE Global Conference on Signal and Information Processing (GlobalSIP)},
  title     = {BACKDOOR ATTACKS ON NEURAL NETWORK OPERATIONS},
  year      = {2018},
  month     = {Nov},
  pages     = {1154-1158},
  abstract  = {Machine learning is a rapidly growing field that has been expanding into various aspects of technology and science in recent years. Unfortunately, it has been shown recently that machine learning models are highly vulnerable to well-crafted adversarial attacks. This paper develops a novel method for maliciously inserting a backdoor into a well-trained neural network causing misclassification that is only active under rare input keys. As opposed to the existing backdoor attacks on neural networks that alter the weights of the network, the proposed approach targets the computing operations for malicious behavior injection. Our experiments show that the proposed methodology achieves above 99% success rate on average for altering the neural network into the desired predictions given the selected input keys, while remaining undetectable under normal testing data.},
  doi       = {10.1109/GlobalSIP.2018.8646335},
  groups    = {First Filtering},
  keywords  = {Biological neural networks;Neurons;Computational modeling;Machine learning;Security;Machine learning algorithms;Adversarial Machine Learning;Neural Networks;Backdoor Attack;Security},
}

@InProceedings{9402402,
  author    = {Sudar, K. Muthamil and Nagaraj, P. and Deepalakshmi, P. and Chinnasamy, P.},
  booktitle = {2021 International Conference on Computer Communication and Informatics (ICCCI)},
  title     = {Analysis of Intruder Detection in Big Data Analytics},
  year      = {2021},
  month     = {Jan},
  pages     = {1-5},
  abstract  = {Network security and data security is gaining vital importance as the usage of applications on computer networks evolving now-a-days. Tremendous increase of data usage on real world computer networks leads to analyze/monitor these data for anomalous activity. Analyzing and monitoring these high volumes of data is termed big data analytics, which needs an efficient scheme to handle such big data and to model user behavior. In this study, we provide an overview of network intrusion detection models in big data. This study focuses on surveying large range of network intrusion detection models carried by various techniques including data mining, machine learning and deep learning techniques.},
  doi       = {10.1109/ICCCI50826.2021.9402402},
  groups    = {First Filtering},
  issn      = {2329-7190},
  keywords  = {Deep learning;Network intrusion detection;Big Data;Data models;Computer networks;Data mining;Monitoring;Intrusion detection;Big data analytics;Anomalous activity;Data Mining;Machine Learning;Deep Learning},
}

@InProceedings{8741031,
  author    = {Shi, Qihang and Vashistha, Nidish and Lu, Hangwei and Shen, Haoting and Tehranipoor, Bahar and Woodard, Damon L and Asadizanjani, Navid},
  booktitle = {2019 IEEE International Symposium on Hardware Oriented Security and Trust (HOST)},
  title     = {Golden Gates: A New Hybrid Approach for Rapid Hardware Trojan Detection using Testing and Imaging},
  year      = {2019},
  month     = {May},
  pages     = {61-71},
  abstract  = {Hardware Trojans are malicious modifications on integrated circuits (IC), which pose a grave threat to the security of modern military and commercial systems. Existing methods of detecting hardware Trojans are plagued by the inability of detecting all Trojans, reliance on golden chip that might not be available, high time cost, and low accuracy. In this paper, we present Golden Gates, a novel detection method designed to achieve a comparable level of accuracy to full reverse engineering, yet paying only a fraction of its cost in time. The proposed method inserts golden gate circuits (GGC) to achieve superlative accuracy in the classification of all existing gate footprints using rapid scanning electron microscopy (SEM) and backside ultra thinning. Possible attacks against GGC as well as malicious modifications on interconnect layers are discussed and addressed with secure built-in exhaustive test infrastructure. Evaluation with real SEM images demonstrate high classification accuracy and resistance to attacks of the proposed technique.},
  doi       = {10.1109/HST.2019.8741031},
  groups    = {First Filtering},
  keywords  = {Logic gates;Trojan horses;Integrated circuits;Hardware;Foundries;Imaging;Security;Hardware Trojans;Image Analysis;Logic Test;Microscopy},
}

@InProceedings{9422049,
  author    = {Zou, Ying and Zhao, Chenglong and Mei, Shibin and Ni, Bingbing},
  booktitle = {2020 2nd International Conference on Information Technology and Computer Application (ITCA)},
  title     = {Adversarial Defense via Scatter and Alignment},
  year      = {2020},
  month     = {Dec},
  pages     = {90-96},
  abstract  = {Recently, adversarial examples have imposed a serious threat to the robustness of deep models and raise potential risks in AI-Security areas. To defend adversarial attacks, we develop a novel defense paradigm via embedding scatter and feature alignment to enhance model's robustness. We first propose a margin constraint loss to encourage better discriminative representations of samples, i.e., increasing inter-class distance and reducing intra-class distance simultaneously. Then a novel method is introduced to seek the representation anchors channel-wisely, which quantizes the learned representations into different scatters. During the inference stage, we first align the extracted representation from the input data onto the most similar anchors and use these anchors replace the representations. Finally, we rebuild and feed these aligned representations into the classifier to get the result. This novel paradigm for utilizing representation anchors channel-wisely provides a new viewpoint to understand the CNN's fragility. Extensive experiments on several datasets well demonstrate that the proposed method improves models' robustness without compromising performance.},
  doi       = {10.1109/ITCA52113.2020.00026},
  groups    = {First Filtering},
  keywords  = {Computer applications;Robustness;Feeds;Data mining;Information technology;adversarial examples;AI-Security;robustness},
}

@InProceedings{7890099,
  author    = {Monshizadeh, Mehrnoosh and Khatri, Vikramajeet and Kantola, Raimo},
  booktitle = {2017 19th International Conference on Advanced Communication Technology (ICACT)},
  title     = {Detection as a service: An SDN application},
  year      = {2017},
  month     = {Feb},
  pages     = {285-290},
  abstract  = {In a cloud computing environment, future networks will most probably utilize network functions virtualization (NFV) which is a network architecture concept that proposes virtualizing network node functions into “building blocks” or entities that may be operationally connected or linked together to provide services. However, applying these mechanisms brings security challenges. Due to the programmability of software defined networking (SDN), if attackers gain access to an SDN controller, then the whole network may be exploited by the attackers. The attackers may change forwarding paths and pass malicious traffic to infect the SDN enabled network. To detect the security attacks and malicious traffic early enough and to protect the network, centralized monitoring and intrusion detection system (IDS) monitoring may be used for enhancing SDN, NFV and OpenFlow security. If the network traffic is analysed and the anomalies are detected, the SDN controller may be used to block such traffic from passing through the network by flow control, i.e. forwarding paths in a switch. IDS and intrusion prevention system (IPS) may be deployed at the gateway node to detect a security intrusion. Thus, the data traffic originated from a subscriber passes through each network element until the traffic reaches the gateway node. Such traffic may attack the network elements and may also cause a denial of service (DoS) attack in the network. IDS devices are designed to handle network traffic in real time, yet the cost and high processing time is a challenge for handling the traffic load. Combining dynamicity and programmability of SDN together with traffic filtering of IDS, enables a scalable, redundant and reliable anomaly detection for mobile network operators. In this study, we propose an architecture that combines IDS with programmability features of SDN for detection and mitigation of malicious traffic. Mitigation will be performed by SDN controller using flow control techniques. The proposed architecture can be applied to an SDN enabled mobile network with two different approaches for improved performance in terms of computation power.},
  doi       = {10.23919/ICACT.2017.7890099},
  groups    = {First Filtering},
  keywords  = {Switches;Security;Telecommunication traffic;Mobile communication;Cloud computing;IP networks;Anomaly Detection;Cloud;Controller;DaaS;IDS;OpenFlow;SDN;Security},
}

@InProceedings{8014906,
  author    = {Narodytska, Nina and Kasiviswanathan, Shiva},
  booktitle = {2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  title     = {Simple Black-Box Adversarial Attacks on Deep Neural Networks},
  year      = {2017},
  month     = {July},
  pages     = {1310-1318},
  abstract  = {Deep neural networks are powerful and popular learning models that achieve state-of-the-art pattern recognition performance on many computer vision, speech, and language processing tasks. However, these networks have also been shown susceptible to crafted adversarial perturbations which force misclassification of the inputs. Adversarial examples enable adversaries to subvert the expected system behavior leading to undesired consequences and could pose a security risk when these systems are deployed in the real world. In this work, we focus on deep convolutional neural networks and demonstrate that adversaries can easily craft adversarial examples even without any internal knowledge of the target network. Our attacks treat the network as an oracle (black-box) and only assume that the output of the network can be observed on the probed inputs. Our attacks utilize a novel local-search based technique to construct numerical approximation to the network gradient, which is then carefully used to construct a small set of pixels in an image to perturb. We demonstrate how this underlying idea can be adapted to achieve several strong notions of misclassification. The simplicity and effectiveness of our proposed schemes mean that they could serve as a litmus test for designing robust networks.},
  doi       = {10.1109/CVPRW.2017.172},
  groups    = {First Filtering},
  issn      = {2160-7516},
  keywords  = {Knowledge engineering;Training;Neural networks;Network architecture;Cats;Robustness;Computer vision},
}

@InProceedings{7366188,
  author    = {Garcia-Font, Victor and Garrigues, Carles and Rifà-Pous, Helena},
  booktitle = {2015 IEEE First International Smart Cities Conference (ISC2)},
  title     = {An architecture for the analysis and detection of anomalies in smart city WSNs},
  year      = {2015},
  month     = {Oct},
  pages     = {1-6},
  abstract  = {In the last few years, Wireless Sensor Networks (WSN) are gaining importance as a data collection mechanism for smart city systems. The development, deployment and operation of these networks involve a wide and heterogeneous set of technologies and participants. In many cases, city councils have outsourced the implementations of their WSNs to different external providers. This has resulted in a loss of control and visibility over the security of each individual WSN and, as well, over the entire system as a whole. In this article, we first describe the security problems related to the present model of WSN implementation within smart city systems. Then, we propose a non-intrusive architecture to recover part of the lost visibility, detect attacks on the WSNs operated by third parties, increase control over the providers and, in general, improve the security of the smart city from a holistic perspective.},
  doi       = {10.1109/ISC2.2015.7366188},
  groups    = {First Filtering},
  keywords  = {Wireless sensor networks;Smart cities;Engines;Cities and towns;Intrusion detection;Support vector machines;Information security;Intrusion detection;Security information and event management;Smart cities;Support vector machines;Wireless sensor networks},
}

@InProceedings{8659373,
  author    = {Kim, Danny and Mirsky, Daniel and Majlesi-Kupaei, Amir and Barua, Rajeev},
  booktitle = {2018 13th International Conference on Malicious and Unwanted Software (MALWARE)},
  title     = {A Hybrid Static Tool to Increase the Usability and Scalability of Dynamic Detection of Malware},
  year      = {2018},
  month     = {Oct},
  pages     = {115-123},
  abstract  = {Malware detection is a paramount priority in today's world in order to prevent malware attacks. Malware detection comes in three methods: static analysis, dynamic analysis, and hybrids. Static analysis is fast and effective for detecting previously seen malware where as dynamic analysis can be more accurate and robust against zero-day or polymorphic malware, but at the cost of a high computational load, which results in an often-prohibitive dollar cost for the needed server farm to handle all incoming traffic at an organization's network entry point. Most modern defenses today use a hybrid approach, which uses both static and dynamic analysis to maximize their chances of detecting malware. However, current hybrid approaches are suboptimal. We propose a solution to utilize the strengths of both while minimizing their weaknesses by using a two-phase hybrid detection tool. The first phase is a static tool, which we call a “static-hybrid” tool, that is based on machine learning and static analysis to categorize incoming programs into three buckets: definitely benign, definitely malicious, and needs further analysis. Only the small fraction of programs in the third bucket are run on the dynamic analyzer. Our system approaches the accuracy of the dynamic-only system with only a small fraction of its computational cost, while maintaining a real-time malware detection timeliness similar to a static-only system, thus achieving the best of both approaches.A key feature of our system is that the first (static) phase can run in active mode, i.e. it blocks malware in real time, which is possible because of the low 0.08% rate of mistakenly blocking benign programs as malicious (all results in our salient configuration). The second (dynamic) phase is run in passive mode, i.e. it send alerts for suspected malware without blocking them, and has a higher false positive rate of 0.75%. The first phase blocks 88.98% of malware, whereas the second phase brings up the detection rate to 98.73%. Since only a small fraction of malware missed by the first stage but caught by the second stage generates alerts, our system reduces alerts by 9.5X vs any highly accurate system running by itself in the typical passive mode seen in practice. Since only 3.63% of programs that need further study are sent to the second phase, this reduces the computation load for dynamic analysis by 100/3.63 = 27.5X.},
  doi       = {10.1109/MALWARE.2018.8659373},
  groups    = {First Filtering},
  keywords  = {Malware;Tools;Static analysis;Performance analysis;Real-time systems;Machine learning;Dynamic scheduling},
}

@InProceedings{8276158,
  author    = {Kalpana, S. and Karthikeyan, S.},
  booktitle = {2017 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS)},
  title     = {A survey on rise of mobile malware and detection methods},
  year      = {2017},
  month     = {March},
  pages     = {1-5},
  abstract  = {Mobile phones are indispensable in our day to day live as it allows us to access enormous services. Hence in recent days the mobile devices are otherwise called as smart phones. The wireless communication technology ranges from GSM, GPRS, Bluetooth, Wi-Fi, 3G and the latest is 4G. It offers attractive features which allow internet access, online banking, install any numbers of Apps. These features attract the mobile user community to shift from traditional phone to smart phone and the Malware writers too. In this paper, we have outlined the evolution and wide spread of mobile malwares, attack vectors, various methods to detect malwares.},
  doi       = {10.1109/ICIIECS.2017.8276158},
  groups    = {First Filtering},
  keywords  = {Mobile communication;Smart phones;Trojan horses;Bluetooth;Malware;Mobile devices;Security;Detection methods;Ransomware;Grayware},
}

@Article{8240589,
  author   = {Li, Longjie and Yu, Yang and Bai, Shenshen and Hou, Ying and Chen, Xiaoyun},
  journal  = {IEEE Access},
  title    = {An Effective Two-Step Intrusion Detection Approach Based on Binary Classification and $k$ -NN},
  year     = {2018},
  issn     = {2169-3536},
  pages    = {12060-12073},
  volume   = {6},
  abstract = {Intrusion detection has been an important countermeasure to secure computing infrastructures from malicious attacks. To improve detection performance and reduce bias towards frequent attacks, this paper proposes a two-step hybrid method based on binary classification and k-NN technique. Step 1 employs several binary classifiers and one aggregation module to effectively detect the exact classes of network connections. After step 1, the connections whose classes are uncertain are sent to step 2 to further determine their classes by the k-NN algorithm. Step 2 is based on the outcomes of step 1 and yields a beneficial supplement to step 1. By combining the two steps, the proposed method achieves reliable results on the NSL-KDD data set. The effectiveness of the proposed method is evaluated in comparison with five supervised learning techniques. Experimental results demonstrate that the proposed method outperforms baselines with respect to various evaluation criteria. In particular, for U2R and R2L attacks, the F1-scores of the proposed method are much higher than those of baselines. Furthermore, comparisons with some recent hybrid approaches are also listed. The results illustrate that the proposed method is competitive.},
  doi      = {10.1109/ACCESS.2017.2787719},
  groups   = {First Filtering},
  keywords = {Intrusion detection;Support vector machines;Feature extraction;Training;Principal component analysis;Genetic algorithms;Intrusion detection;hybrid method;binary classification;C4.5;k-nearest neighbors},
}

@InProceedings{9473824,
  author    = {Freas, Christopher B. and Shah, Dhara and Harrison, Robert W.},
  booktitle = {2021 IEEE International Conference on Communications Workshops (ICC Workshops)},
  title     = {Accuracy and Generalization of Deep Learning Applied to Large Scale Attacks},
  year      = {2021},
  month     = {June},
  pages     = {1-6},
  abstract  = {Distributed denial of service attacks threaten the security and health of the Internet. Remediation relies on up-to-date and accurate attack signatures. Signature-based detection is relatively inexpensive computationally. Yet, signatures are inflexible when small variations exist in the attack vector. Attackers exploit this rigidity by altering their attacks to bypass the signatures. Our previous work revealed a critical problem with conventional machine learning models. Conventional models are unable to generalize on the temporal nature of network flow data to classify attacks. We thus explored the use of deep learning techniques on real flow data. We found that a variety of attacks could be identified with high accuracy compared to previous approaches. We show that a convolutional neural network can be implemented for this problem that is suitable for large volumes of data while maintaining useful levels of accuracy.},
  doi       = {10.1109/ICCWorkshops50388.2021.9473824},
  groups    = {First Filtering},
  issn      = {2694-2941},
  keywords  = {Deep learning;Correlation coefficient;Conferences;Computational modeling;Neural networks;Telecommunication traffic;Denial-of-service attack;Networks;Flow analysis;Attack Detection;Machine Learning;Deep Learning},
}

@Article{8835902,
  author   = {Abaimov, Stanislav and Bianchi, Giuseppe},
  journal  = {IEEE Access},
  title    = {CODDLE: Code-Injection Detection With Deep Learning},
  year     = {2019},
  issn     = {2169-3536},
  pages    = {128617-128627},
  volume   = {7},
  abstract = {Code Injection attacks such as SQL Injection and Cross-Site Scripting (XSS) are among the major threats for today's web applications and systems. This paper proposes CODDLE, a deep learning-based intrusion detection systems against web-based code injection attacks. CODDLE's main novelty consists in adopting a Convolutional Deep Neural Network and in improving its effectiveness via a tailored pre-processing stage which encodes SQL/XSS-related symbols into type/value pairs. Numerical experiments performed on real-world datasets for both SQL and XSS attacks show that, with an identical training and with a same neural network shape, CODDLE's type/value encoding improves the detection rate from a baseline of about 75% up to 95% accuracy, 99% precision, and a 92% recall value.},
  doi      = {10.1109/ACCESS.2019.2939870},
  groups   = {First Filtering},
  keywords = {Structured Query Language;SQL injection;Training;Neural networks;Deep learning;Databases;Tools;Deep learning;code injection;intrusion detection;supervised learning;SQL injection;XSS;JavaScript},
}

@InProceedings{8845211,
  author    = {de Bast, Sibren and Torrea-Duran, Rodolfo and Chiumento, Alessandro and Pollin, Sofie and Gacanin, Haris},
  booktitle = {IEEE INFOCOM 2019 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)},
  title     = {Deep Reinforcement Learning for Dynamic Network Slicing in IEEE 802.11 Networks},
  year      = {2019},
  month     = {April},
  pages     = {264-269},
  abstract  = {Network slicing, a key enabler for future wireless networks, divides a physical network into multiple logical networks that can be dynamically created and configured. In current IEEE 802.11 (Wi-Fi) networks, the only form of network configuration is a rule-based optimization of few parameters. Future access points (APs) are expected to have self-organizational capabilities, able to deal with large configuration spaces in order to dynamically configure each slice. Deep Reinforcement Learning (DRL) can achieve promising results in highly dynamic and complex environments without the need for an operating model, by learning the optimal strategy after interacting with the environment. However, since the number of possible slice configurations is huge, achieving the optimal strategy requires an exhaustive learning period that might yield an outdated slice configuration. In this paper, we propose a fast-learning DRL model that can dynamically optimize the slice configuration of unplanned Wi-Fi networks without expert knowledge. Enhanced with an off-line learning step, the proposed approach is able to achieve the optimal slice configuration with a fast convergence, which is attractive for dynamic scenarios.},
  doi       = {10.1109/INFCOMW.2019.8845211},
  groups    = {First Filtering},
  keywords  = {Wireless fidelity;Network slicing;Artificial neural networks;Optimization;Convergence;Reinforcement learning;Knowledge engineering;network slicing;deep reinforcement learning;Wi-Fi networks},
}

@InProceedings{8537852,
  author    = {Narayanan, Sandeep Nair and Ganesan, Ashwinkumar and Joshi, Karuna and Oates, Tim and Joshi, Anupam and Finin, Tim},
  booktitle = {2018 IEEE 4th International Conference on Collaboration and Internet Computing (CIC)},
  title     = {Early Detection of Cybersecurity Threats Using Collaborative Cognition},
  year      = {2018},
  month     = {Oct},
  pages     = {354-363},
  abstract  = {The early detection of cybersecurity events such as attacks is challenging given the constantly evolving threat landscape. Even with advanced monitoring, sophisticated attackers can spend more than 100 days in a system before being detected. This paper describes a novel, collaborative framework that assists a security analyst by exploiting the power of semantically rich knowledge representation and reasoning integrated with different machine learning techniques. Our Cognitive Cybersecurity System ingests information from various textual sources and stores them in a common knowledge graph using terms from an extended version of the Unified Cybersecurity Ontology. The system then reasons over the knowledge graph that combines a variety of collaborative agents representing host and network-based sensors to derive improved actionable intelligence for security administrators, decreasing their cognitive load and increasing their confidence in the result. We describe a proof of concept framework for our approach and demonstrate its capabilities by testing it against a custom-built ransomware similar to WannaCry.},
  doi       = {10.1109/CIC.2018.00054},
  groups    = {First Filtering},
  keywords  = {Ontologies;Monitoring;Tools;Sensors;Collaboration;cybersecurity;network security;cybersecurity attack detection;knowledge representation},
}

@InProceedings{7524507,
  author    = {Liaskos, Christos and Kotronis, Vasileios and Dimitropoulos, Xenofontas},
  booktitle = {IEEE INFOCOM 2016 - The 35th Annual IEEE International Conference on Computer Communications},
  title     = {A novel framework for modeling and mitigating distributed link flooding attacks},
  year      = {2016},
  month     = {April},
  pages     = {1-9},
  abstract  = {Distributed link-flooding attacks constitute a new class of attacks with the potential to segment large areas of the Internet. Their distributed nature makes detection and mitigation very hard. This work proposes a novel framework for the analytical modeling and optimal mitigation of such attacks. The detection is modeled as a problem of relational algebra, representing the association of potential attackers (bots) to potential targets. The analysis seeks to optimally dissolve all but the malevolent associations. The framework is implemented at the level of online Traffic Engineering (TE), which is naturally triggered on link-flooding events. The key idea is to continuously re-route traffic in a manner that makes persistent participation to link-flooding events highly improbable for any benign source. Thus, bots are forced to adopt a suspicious behavior to remain effective, revealing their presence. The load-balancing objective of TE is not affected at all. Extensive simulations on various topologies validate our analytical findings.},
  doi       = {10.1109/INFOCOM.2016.7524507},
  groups    = {First Filtering},
  keywords  = {Routing;Internet;Servers;Nickel;Analytical models;Algebra;IP networks;DDoS;link-flooding;analysis},
}

@Article{9343824,
  author   = {Li, Bing and Zhu, Hong and Xie, Meiyi},
  journal  = {IEEE Access},
  title    = {Quantifying Location Privacy Risks Under Heterogeneous Correlations},
  year     = {2021},
  issn     = {2169-3536},
  pages    = {23876-23893},
  volume   = {9},
  abstract = {Currently, increasingly ubiquitous location-based services are facilitating the activities of people in daily life. However, releasing real locations could lead to serious concerns about privacy. To remedy these issues, a number of location privacy protection mechanisms (LPPMs) have been proposed, e.g., spatial cloaking, dummy location generation, query caching, and perturbation. However, these LPPMs are vulnerable to inference attacks because of the incompleteness of the captured privacy risks caused by heterogeneous correlations in location data, e.g., semantical, temporal, and social correlations. Consequently, they cannot provide sufficient privacy guarantees due to the absence of embedded heterogeneous correlations in the design process of LPPM. To address these issues, we present QUAD, a framework for quantifying location privacy risks under heterogeneous correlations. QUAD has three features: 1) it enables the modeling and seamless fusion of multiple kinds of correlations that are available to adversaries; 2) it provides a probabilistic representation of the privacy risks faced under heterogeneous correlations; and 3) it achieves the quantification of privacy risks for multiple kinds of LPPMs that are widely used in the literature. To mitigate privacy threats, we propose a defense mechanism embedded with the quantified privacy risks. Extensive experiments on two real-world datasets confirm that QUAD can capture more privacy risks than competitors, and the risks can be dramatically reduced by our defense mechanism.},
  doi      = {10.1109/ACCESS.2021.3056152},
  groups   = {First Filtering},
  keywords = {Correlation;Privacy;Hidden Markov models;Trajectory;Data privacy;Semantics;Perturbation methods;Data privacy;heterogeneous data;location-based services;privacy protection},
}

@InProceedings{9260077,
  author    = {Ali, Sheraz and Irfan, Muhammad Maaz and Bomai, Abubakar and Zhao, Chuan},
  booktitle = {2020 IEEE 7th International Conference on Data Science and Advanced Analytics (DSAA)},
  title     = {Towards Privacy-Preserving Deep Learning: Opportunities and Challenges},
  year      = {2020},
  month     = {Oct},
  pages     = {673-682},
  abstract  = {During the past decade, deep learning has achieved excellent results in many classic machine learning problems, such as face recognition, spam detection, and financial prediction, etc. The success of deep learning mainly benefits from training on a large amount of data gathered from different sources. However, the training data may include highly sensitive information that may lead to serious threats to personal privacy. In this paper, we review privacy threats in deep learning and present effective privacy-preserving techniques in the literature against these threats. We give a detailed comparison of different techniques and summarize the performance of the existing solutions. Furthermore, we discuss some open problems and challenges in this research area. In the end, we conclude this paper and point out possible research directions.},
  doi       = {10.1109/DSAA49011.2020.00077},
  groups    = {First Filtering},
  keywords  = {Deep learning;Data models;Data privacy;Privacy;Training;Neural networks;Training data;Machine Learning;Deep Learning;Homomorphic Encryption;Differential Privacy;Secure Multi-Party Computation},
}

@Article{6129369,
  author   = {Fragkiadakis, Alexandros G. and Tragos, Elias Z. and Askoxylakis, Ioannis G.},
  journal  = {IEEE Communications Surveys Tutorials},
  title    = {A Survey on Security Threats and Detection Techniques in Cognitive Radio Networks},
  year     = {2013},
  issn     = {1553-877X},
  month    = {First},
  number   = {1},
  pages    = {428-445},
  volume   = {15},
  abstract = {With the rapid proliferation of new technologies and services in the wireless domain, spectrum scarcity has become a major concern. The allocation of the Industrial, Medical and Scientific (ISM) band has enabled the explosion of new technologies (e.g. Wi-Fi) due to its licence-exempt characteristic. The widespread adoption of Wi-Fi technology, combined with the rapid penetration of smart phones running popular user services (e.g. social online networks) has overcrowded substantially the ISM band. On the other hand, according to a number of recent reports, several parts of the static allocated licensed bands are under-utilized. This has brought up the idea of the opportunistic use of these bands through the, so-called, cognitive radios and cognitive radio networks. Cognitive radios have enabled the opportunity to transmit in several licensed bands without causing harmful interference to licensed users. Along with the realization of cognitive radios, new security threats have been raised. Adversaries can exploit several vulnerabilities of this new technology and cause severe performance degradation. Security threats are mainly related to two fundamental characteristics of cognitive radios: cognitive capability, and reconfigurability. Threats related to the cognitive capability include attacks launched by adversaries that mimic primary transmitters, and transmission of false observations related to spectrum sensing. Reconfiguration can be exploited by attackers through the use of malicious code installed in cognitive radios. Furthermore, as cognitive radio networks are wireless in nature, they face all classic threats present in the conventional wireless networks. The scope of this work is to give an overview of the security threats and challenges that cognitive radios and cognitive radio networks face, along with the current state-of-the-art to detect the corresponding attacks. In addition, future challenges are addressed.},
  doi      = {10.1109/SURV.2011.122211.00162},
  groups   = {First Filtering},
  keywords = {Sensors;Security;Cognitive radio;Communication system security;Wireless sensor networks;Transmitters;cognitive radios;cognitive radio networks;primary user emulation attacks;spectrum sense data falsification attacks;cross layer attacks;software defined radio security;IEEE 802.22},
}

@Article{6612904,
  author   = {Liu, Qiang and Yin, Jianping and Leung, Victor C. M. and Cai, Zhiping},
  journal  = {IEEE Transactions on Wireless Communications},
  title    = {FADE: Forwarding Assessment Based Detection of Collaborative Grey Hole Attacks in WMNs},
  year     = {2013},
  issn     = {1558-2248},
  month    = {October},
  number   = {10},
  pages    = {5124-5137},
  volume   = {12},
  abstract = {Data security, which is concerned with the confidentiality, integrity and availability of data, is still challenging the application of wireless mesh networks (WMNs). In this paper, we focus on a special type of denial-of-service attack, called selective forwarding or grey hole attack. When this attack is launched at the gateways of a WMN where data tend to aggregate, it could lead to severe damages due to loss of sensitive data. Most existing proposals that focus on detecting stand-alone attackers via channel overhearing are ineffective against collusive attackers. In this paper, we propose a forwarding assessment based detection (FADE) scheme to mitigate collaborative grey hole attacks. Specifically, FADE detects sophisticated attacks by means of forwarding assessments aided by two-hop acknowledgement monitoring. Moreover, FADE can coexist with contemporary link security techniques. We analyze the optimal detection threshold that minimizes the sum of false positive rate and false negative rate of FADE, considering the network dynamics due to degraded channel quality or medium access collisions. Extensive simulation results are presented to demonstrate the adaptability of FADE to network dynamics and its effectiveness in detecting collaborative grey hole attacks.},
  doi      = {10.1109/TWC.2013.121906},
  groups   = {First Filtering},
  keywords = {Security;Routing protocols;Collaboration;Peer-to-peer computing;Communication system security;Wireless communication;Wireless mesh network;collaborative grey hole attack;two-hop acknowledgement;forwarding assessment based detection;optimal detection thresholds},
}

@Article{8984216,
  author   = {Ullah, Kaleem and Rashid, Imran and Afzal, Hammad and Iqbal, Mian Muhammad Waseem and Bangash, Yawar Abbas and Abbas, Haider},
  journal  = {IEEE Communications Surveys Tutorials},
  title    = {SS7 Vulnerabilities—A Survey and Implementation of Machine Learning vs Rule Based Filtering for Detection of SS7 Network Attacks},
  year     = {2020},
  issn     = {1553-877X},
  month    = {Secondquarter},
  number   = {2},
  pages    = {1337-1371},
  volume   = {22},
  abstract = {The Signalling System No. 7 (SS7) is used in GSM/UMTS telecommunication technologies for signalling and management of communication. It was designed on the concept of private boundary walled technology having mutual trust between few national/multinational operators with no inherent security controls in 1970s. Deregulation, expansion, and merger of telecommunication technology with data networks have vanquished the concept of boundary walls hence increasing the number of service providers, entry points, and interfaces to the SS7 network, which made it vulnerable to serious attacks. The SS7 exploits can be used by attackers to intercept messages, track a subscriber's location, tape/redirect calls, adversely affect disaster relief operations, drain funds of individuals from banks in combination with other methods and send billions of spam messages. This paper provides a comprehensive review of the SS7 attacks with detailed methods to execute attacks, methods to enter the SS7 core network, and recommends safeguards against the SS7 attacks. It also provides a machine learning based framework to detect anomalies in the SS7 network which is compared with rule based filtering. It further presents a conceptual model for the defense of network.},
  doi      = {10.1109/COMST.2020.2971757},
  groups   = {First Filtering},
  keywords = {Security;Machine learning;Companies;Protocols;Privacy;GSM;SS7 vulnerabilities;SS7 attacks;tracking mobile subscribers;call interception;SMS interception;SMS fraud;machine learning;rule based filtering},
}

@InProceedings{8766574,
  author    = {Yahyaoui, Aymen and Abdellatif, Takoua and Attia, Rabah},
  booktitle = {2019 15th International Wireless Communications Mobile Computing Conference (IWCMC)},
  title     = {Hierarchical anomaly based intrusion detection and localization in IoT},
  year      = {2019},
  month     = {June},
  pages     = {108-113},
  abstract  = {In IoT systems, WSNs and Gateways are exposed to many attacks. WSNs are usually exposed to different types of intrusions like node compromise and denial of service attacks. IoT gateways that connects WSN to the Internet are exposed to all conventional IP attacks. In this paper, we propose an anomaly detection approach using support vector machines (SVM) for WSN intrusion detection, and deep learning technique for gateway intrusion detection. We propose a detection protocol that dynamically executes the on-demand SVM classifier in a hierarchical way whenever an intrusion is suspected. We combine machine learning classification with a statistical approach for malicious node localization. This novel approach allows finding a compromise between intrusion detection efficiency and resource overhead for WSN and gateway security.},
  doi       = {10.1109/IWCMC.2019.8766574},
  groups    = {First Filtering},
  issn      = {2376-6506},
  keywords  = {Wireless sensor networks;Intrusion detection;Support vector machines;Deep learning;Logic gates;Training;intrusion detection;wireless sensor networks;internet of things;support vector machines;selective forwarding attack;deep learning},
}

@InProceedings{9238337,
  author    = {Alani, Mohammed M.},
  booktitle = {2020 International Conference on Software, Telecommunications and Computer Networks (SoftCOM)},
  title     = {On Recent Security Issues in Machine Learning},
  year      = {2020},
  month     = {Sep.},
  pages     = {1-6},
  abstract  = {In recent years, applications of machine learning have grown rapidly in various areas. With the accelerating rate of data generation, and recent developments in big data analytics, machine learning has become a de facto standard in many applications that benefited the society in many areas. However, with the increasing number and types of machine learning applications, it has become a target for an increasing number of malicious actors. Security challenges became more complex and diverse in machine-learning-based systems.In this paper, we present a concise survey and discussion of the mechanisms employed by attackers to exploit vulnerabilities in machine learning algorithms or injecting malicious data. The paper focuses on most recent attacks reported in literature and discusses the methods proposed to counter these attacks and reduce their impact.},
  doi       = {10.23919/SoftCOM50211.2020.9238337},
  groups    = {First Filtering},
  issn      = {1847-358X},
  keywords  = {machine learning;security;threat;attack;ai},
}

@InProceedings{9343244,
  author    = {Li, Wenjuan and Meng, Weizhi and Zhu, Hui},
  booktitle = {2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)},
  title     = {Towards Collaborative Intrusion Detection Enhancement Against Insider Attacks with Multi-level Trust},
  year      = {2020},
  month     = {Dec},
  pages     = {1179-1186},
  abstract  = {With the speedy growth of distributed networks such as Internet of Things (IoT), there is an increasing need to protect network security against various attacks by deploying collaborative intrusion detection systems (CIDSs), which allow different detector nodes to exchange required information and data with each other. While due to the distributed architecture, insider attacks are a big threat for CIDSs, in which an attacker can reside inside the network. To address this issue, designing an appropriate trust management scheme is considered as an effective solution. In this work, we first analyze the development of CIDSs in the past decades and identify the major challenges on building an effective trust management scheme. Then we introduce a generic framework aiming to enhance the security of CIDSs against advanced insider threats by deriving multilevel trust. In the study, our results demonstrate the viability and the effectiveness of our framework.},
  doi       = {10.1109/TrustCom50675.2020.00158},
  groups    = {First Filtering},
  issn      = {2324-9013},
  keywords  = {Privacy;Collaboration;Intrusion detection;Robustness;Security;Internet of Things;Trust management;Collaborative Intrusion Detection;Insider Threat;Trust Management;Multi-Level Trust;Distributed Network},
}

@InProceedings{8258494,
  author    = {Tiwari, Trishita and Turk, Ata and Oprea, Alina and Olcoz, Katzalin and Coskun, Ayse K.},
  booktitle = {2017 IEEE International Conference on Big Data (Big Data)},
  title     = {User-profile-based analytics for detecting cloud security breaches},
  year      = {2017},
  month     = {Dec},
  pages     = {4529-4535},
  abstract  = {While the growth of cloud-based technologies has benefited the society tremendously, it has also increased the surface area for cyber attacks. Given that cloud services are prevalent today, it is critical to devise systems that detect intrusions. One form of security breach in the cloud is when cyber-criminals compromise Virtual Machines (VMs) of unwitting users and, then, utilize user resources to run time-consuming, malicious, or illegal applications for their own benefit. This work proposes a method to detect unusual resource usage trends and alert the user and the administrator in real time. We experiment with three categories of methods: simple statistical techniques, unsupervised classification, and regression. So far, our approach successfully detects anomalous resource usage when experimenting with typical trends synthesized from published real-world web server logs and cluster traces. We observe the best results with unsupervised classification, which gives an average F1-score of 0.83 for web server logs and 0.95 for the cluster traces.},
  doi       = {10.1109/BigData.2017.8258494},
  groups    = {First Filtering},
  keywords  = {Cloud computing;Measurement;Support vector machines;Standards;Anomaly detection;Market research;Cloud Security;Virtual Machine Resource Usage;Machine Learning},
}

@InProceedings{9338327,
  author    = {Zhang, Yanghao and Ruan, Wenjie and Wang, Fu and Huang, Xiaowei},
  booktitle = {2020 IEEE International Conference on Data Mining (ICDM)},
  title     = {Generalizing Universal Adversarial Attacks Beyond Additive Perturbations},
  year      = {2020},
  month     = {Nov},
  pages     = {1412-1417},
  abstract  = {The previous study has shown that universal adversarial attacks can fool deep neural networks over a large set of input images with a single human-invisible perturbation. However, current methods for universal adversarial attacks are based on additive perturbation, which cause misclassification when the perturbation is directly added to the input images. In this paper, for the first time, we show that a universal adversarial attack can also be achieved via non-additive perturbation (e.g., spatial transformation). More importantly, to unify both additive and non-additive perturbations, we propose a novel unified yet flexible framework for universal adversarial attacks, called GUAP, which is able to initiate attacks by additive perturbation, non-additive perturbation, or the combination of both. Extensive experiments are conducted on ImageNet dataset with several deep neural network models including GoogLeNet, VGG and ResNet. The empirical experiments demonstrate that GUAP can obtain up to 99.24% successful attack rate on ImageNet dataset, leading to over 19% improvements than current state-of-the-art universal adversarial attacks. The code for reproducing the experiments in this paper is available at https://github.com/TrustAI/GUAP.},
  doi       = {10.1109/ICDM50108.2020.00186},
  groups    = {First Filtering},
  issn      = {2374-8486},
  keywords  = {Additives;Perturbation methods;Conferences;Neural networks;Robustness;Data mining;Deep Learning, Adversarial Examples, Security, Deep Neural Networks},
}

@InProceedings{7724881,
  author    = {Tyagi, Sanjay and Gopal, Girdhar and Garg, Vikas},
  booktitle = {2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)},
  title     = {Detecting malicious node in network using packet delivery ratio},
  year      = {2016},
  month     = {March},
  pages     = {3313-3318},
  abstract  = {The major function of sensor networks is to gather the data from various sensor nodes which are used to transmit the data at different base stations. Due to fault or presence of malicious node in the network, collected data might be wrong or hijacked. It is important and difficult to detect the unsafe work done by any malicious node. There are many factors involved such as packet delivery ratio, jamming signal, tempering, which help to defend against malicious node or to detect the malicious node. In this paper, malicious node detection based on packet delivery ratio (PDR) has been proposed. The packets in network must reach the destination in order to provide the reliability in network, but the malicious nodes may tamper some of the packets and make the communication fail. Total number of packets sent by the sender may or may not be received by the receiver and it depends on whether there is any malicious node present or not in the network. So one can use this delivered packet information and calculate the packet delivery ratio to find out the malicious node. Simulation in this paper shows that the proposed scheme finds the malicious nodes in the network in efficient and effective manner.},
  groups    = {First Filtering},
  keywords  = {Wireless sensor networks;Handheld computers;Computer science;Jamming;Intrusion detection;Protocols;Monitoring;Malicious node;Networks;Packets;Packet Delivery Ratio},
}

@InProceedings{6569086,
  author    = {Dolgikh, Andrey and Birnbaum, Zachary and Chen, Yu and Skormin, Victor},
  booktitle = {2013 IEEE 14th International Conference on Mobile Data Management},
  title     = {Behavioral Modeling for Suspicious Process Detection in Cloud Computing Environments},
  year      = {2013},
  month     = {June},
  pages     = {177-181},
  volume    = {2},
  abstract  = {One of the defining features of cloud computing, multi-tenancy provides significant benefits to both clients and service providers by supporting elastic on-demand resource provisioning and efficient resource allocation. However, this architecture also introduces additional security implications. Client virtual machine (VM) instances running on the same physical machine are susceptible to side-channel and escape-to-hypervisor attacks. Timely detection/mitigation of intrusive behaviors of malicious processes using signature based intrusion detection technologies or system call level anomaly analysis due to high false alarm rate presents a challenging task. In this work, a behavioral modeling scheme is proposed to detect suspicious processes on the highest semantic level. Our preliminary results have validated the effectiveness and efficiency of this novel approach.},
  doi       = {10.1109/MDM.2013.90},
  groups    = {First Filtering},
  issn      = {2375-0324},
  keywords  = {Monitoring;Servers;Virtual machine monitors;Security;Hardware;Cloud computing;Cloud Computing Security;Multi-Tenancy;Behavioral Modeling;Suspicious Process Detection},
}

@InProceedings{8367639,
  author    = {Kidmose, Egon and Lansing, Erwin and Brandbyge, Søren and Pedersen, Jens Myrup},
  booktitle = {2018 1st International Conference on Data Intelligence and Security (ICDIS)},
  title     = {Detection of Malicious and Abusive Domain Names},
  year      = {2018},
  month     = {April},
  pages     = {49-56},
  abstract  = {The Domain Name System (DNS) is a critical component of the Internet, and as such it is widely relied upon by a large part of the world. Consequently, it can be abused for multiple purposes, with financial gain being perhaps the most obvious, and important. An important countermeasure to such criminal and malicious activity is to identify involved domains, in order to blacklist or otherwise disable them. In this paper we provide the results of studying existing work on detecting malicious domains and analyse the findings. We identify an approach which is promising but has received surprisingly little attention; Pre-registration detection. We identify the following gaps between the problem of domain abuse, and the described state-of-the-art: Existing work on Pre-registration is strictly focused on a single form of abuse, spam, hence it must be explored if Pre-registration detection can be applied to other forms of abuse as well. Existing work, on both Pre- and Post-registration detection, is focused on a few Top-Level domains (TLDs) and Registries, prompting for studies with other TLDs and Registries. There is relevant information, including Registrant-based features, that has not yet been used for Pre-registration detection - which also calls for investigation. Finally, a study of a real-world deployment of Pre- registration detection at a Registry has not yet been presented, despite the potential of the approach. We contribute with an analysis of existing work, by identifying the state-of-the-art, and by identifying important areas of future work.},
  doi       = {10.1109/ICDIS.2018.00015},
  groups    = {First Filtering},
  keywords  = {Internet;IP networks;Malware;Resilience;Electronic mail;Registers;Servers;DNS;Domain;Domain name;Registry;Abuse;Registration;Maliciousness;Detection;Pre registration;Time of registration;Malware;Phishing;Spam},
}

@InProceedings{7036863,
  author    = {Hommes, Stefan and State, Radu and Engel, Thomas},
  booktitle = {2014 IEEE Global Communications Conference},
  title     = {Implications and detection of DoS attacks in OpenFlow-based networks},
  year      = {2014},
  month     = {Dec},
  pages     = {537-543},
  abstract  = {In this paper, we address the potential of centralised network monitoring based on Software-Defined Networking with OpenFlow. Due to the vulnerability of the flow table, which can store only a limited number of entries, we discuss and show the implications for a DoS attack on a testbed consisting of OpenFlow enabled network devices. Such an attack can be detected by analysing variations in the logical topology, using techniques from information theory that can run as a network service on the network controller.},
  doi       = {10.1109/GLOCOM.2014.7036863},
  groups    = {First Filtering},
  issn      = {1930-529X},
  keywords  = {Switches;Monitoring;Computer crime;Network topology;Topology;Ports (Computers)},
}

@Article{6129371,
  author   = {Liu, Jing and Xiao, Yang and Li, Shuhui and Liang, Wei and Chen, C. L. Philip},
  journal  = {IEEE Communications Surveys Tutorials},
  title    = {Cyber Security and Privacy Issues in Smart Grids},
  year     = {2012},
  issn     = {1553-877X},
  month    = {Fourth},
  number   = {4},
  pages    = {981-997},
  volume   = {14},
  abstract = {Smart grid is a promising power delivery infrastructure integrated with communication and information technologies. Its bi-directional communication and electricity flow enable both utilities and customers to monitor, predict, and manage energy usage. It also advances energy and environmental sustainability through the integration of vast distributed energy resources. Deploying such a green electric system has enormous and far-reaching economic and social benefits. Nevertheless, increased interconnection and integration also introduce cyber-vulnerabilities into the grid. Failure to address these problems will hinder the modernization of the existing power system. In order to build a reliable smart grid, an overview of relevant cyber security and privacy issues is presented. Based on current literatures, several potential research fields are discussed at the end of this paper.},
  doi      = {10.1109/SURV.2011.122111.00145},
  groups   = {First Filtering},
  keywords = {Smart grids;Protocols;Computer security;IEC standards;Privacy;smart grid;SCADA;AMI;security;privacy;accountability},
}

@Article{8846678,
  author   = {Xu, Chuanfeng and Lin, Hui and Wu, Yulei and Guo, Xuancheng and Lin, Wenzhong},
  journal  = {IEEE Access},
  title    = {An SDNFV-Based DDoS Defense Technology for Smart Cities},
  year     = {2019},
  issn     = {2169-3536},
  pages    = {137856-137874},
  volume   = {7},
  abstract = {A software defined networking (SDN)-enabled smart city is a new paradigm that can effectively improve the cost efficiency and flexibility of data management through data-control separation. However, it faces significant security threats such as distributed denial of service (DDoS) attacks which jeopardize the security and availability of data and services by overloading the system with excessive traffic from distributed sources. To improve the DDoS defense capability and enhance the security of data management in SDN-enabled smart cities, this paper proposes a DDoS attack Defense strategy based on Traffic Classification (DDTC). We use software defined network function virtualization (SDNFV) architecture and traffic classification strategy, to improve the flexibility and reduce the load of SDN against DDoS attacks. Experimental results show that the proposed DDTC can not only launch DDoS attacks detection quickly, but also accurately track the sources of DDoS attacks. More importantly, it can reduce the risk of attack on the controller of SDN and improve the effectiveness of the system.},
  doi      = {10.1109/ACCESS.2019.2943146},
  groups   = {First Filtering},
  keywords = {Computer crime;Switches;Computer architecture;Smart cities;Software;IP networks;Distributed denial of service;flow classification;smart city;software defined networking;network function virtualization},
}

@InProceedings{6681240,
  author    = {Ficco, Massimo and Tasquier, Luca and Aversa, Rocco},
  booktitle = {2013 Eighth International Conference on P2P, Parallel, Grid, Cloud and Internet Computing},
  title     = {Intrusion Detection in Cloud Computing},
  year      = {2013},
  month     = {Oct},
  pages     = {276-283},
  abstract  = {Cloud Computing represents both a technology for using computing infrastructures in a more efficient way, and a business model for selling computing resources and services. On the other hand, such complex and distributed architectures become an attractive target for intruders. Cyber-attacks represent a serious danger, which can compromise the quality of service delivered to the customers. In this paper, we investigate the key research topics for supporting distributed intrusion detection in Cloud environments. Moreover, we present a distributed architecture for providing intrusion detection in Cloud Computing, which enables Cloud providers to offer security solutions as a service. It is a hierarchical and multi-layer architecture designed to collect information in the Cloud environment, using multiple distributed security components, which can be used to perform complex event correlation analysis.},
  doi       = {10.1109/3PGCIC.2013.47},
  groups    = {First Filtering},
  keywords  = {Engines;Cloud computing;Monitoring;Intrusion detection;Probes;Computer architecture;Cloud computing;intrusion detection;distributed event correlation},
}

@InProceedings{6956919,
  author    = {Lichtman, Marc and Czauski, Thaddeus and Ha, Sean and David, Paul and Reed, Jeffrey H.},
  booktitle = {2014 IEEE Military Communications Conference},
  title     = {Detection and Mitigation of Uplink Control Channel Jamming in LTE},
  year      = {2014},
  month     = {Oct},
  pages     = {1187-1194},
  abstract  = {In 3GPP LTE, the physical layer is divided into data and signaling, where the signaling (or control information) enables efficient data exchange/resource scheduling. The LTE uplink contains a physical channel known as the Physical Uplink Control Channel (PUCCH), which carries uplink control information such as message acknowledgements, scheduling requests, and channel status information from user equipment (UE) to LTE base stations (eNodeB). The PUCCH is located on the edges of the system bandwidth in a static location. The static allocation of the PUCCH presents a dilemma: an adversary can disrupt the uplink channel with minimal effort and only needs to know the PUCCH's spectrum allocation. In this paper we (i) take a closer look at the purpose and specification of the PUCCH, (ii) we propose various strategies to be used for the detection of interference specifically on the PUCCH, and (iii) we outline strategies for mitigating 'protocol-aware' interference on the PUCCH. Some of the mitigation strategies, such as control information duplication, can be implemented with minimal changes to LTE eNodeBs and UEs, while other countermeasures require augmentations to both eNodeB and UE hardware or software.},
  doi       = {10.1109/MILCOM.2014.199},
  groups    = {First Filtering},
  issn      = {2155-7586},
  keywords  = {Jamming;Uplink;Interference;Long Term Evolution;Wireless communication;Protocols;MIMO;Wireless Networks;LTE;High-Availability Networks;Public Safety Networks;Critical Applications;Jamming;PUCCH;Interference;Interference Detection;Interference Mitigation},
}

@Article{8846044,
  author   = {Kulandaivel, Rajkumar and Balasubramaniam, Monica and Al-Turjman, Fadi and Mostarda, Leonardo and Ramachandran, Manikandan and Patan, Rizwan},
  journal  = {IEEE Access},
  title    = {Intelligent Data Delivery Approach for Smart Cities Using Road Side Units},
  year     = {2019},
  issn     = {2169-3536},
  pages    = {139462-139474},
  volume   = {7},
  abstract = {Smart city progress from classical homogenous technologies with limited facility to heterogeneous interconnected network with immense capabilities. Furthermore, there is a good concern in expanding the scope of application in the smart city. The primary objective of the smart city is to achieve optimization and reinforce the Quality of Service (QoS) of applications by cleverer usage of urban resources. The QoS in the network is measured using several factors like end-end delay, energy consumption, packet loss and throughput. Several pitfalls are experienced in the existing routing innovation. In this proposal, a new technology-based routing structure is proposed. Road Side Units (RSU) will allow the planners to deploy the application without unfamiliar tools for data process and gathering. Data forwarding, acquisition and diffusion are simplified by RSU. K-Nearest Neighbor is used for finding the nearest neighbor nodes and it is optimized using Whale optimization Algorithm (WOA). The evaluation outcomes prove that the intended routing plot provides much spectacle than existing protocols for real time applications.},
  doi      = {10.1109/ACCESS.2019.2943013},
  groups   = {First Filtering},
  keywords = {Routing;Smart cities;Quality of service;Routing protocols;Loss measurement;Delays;Smart city;routing;RSU;k-NN;WOA;QoS},
}

@InProceedings{8286550,
  author    = {Mathew, Annie and Terence, J. Sebastian},
  booktitle = {2017 International Conference on Communication and Signal Processing (ICCSP)},
  title     = {A survey on various detection techniques of sinkhole attacks in WSN},
  year      = {2017},
  month     = {April},
  pages     = {1115-1119},
  abstract  = {Wireless Sensor Network (WSN) is a network consists of many sensor nodes that are capable of sensing and communicating with in a shortest range. Security is one of the main issues in WSN due to its communication nature. The sensor nodes been prone to various attack such as sinkhole attack, wormhole attack, gray hole attack etc. Sinkhole attack is one of the attacks in WSN where the sinkhole node showcases itself having the shortest path to sink or destination node. Researchers proposed different methodologies to detect the sinkhole attack. In this paper, we have studied sinkhole attack and we have classified the sinkhole detection method by using various parameters. It also reviewed the threats and challenges in WSN through this attack.},
  doi       = {10.1109/ICCSP.2017.8286550},
  groups    = {First Filtering},
  keywords  = {Wireless sensor networks;Base stations;Mobile agents;Routing;Monitoring;Cryptography;Wireless Sensor Network;Packet dropping;Sinkhole attack},
}

@InProceedings{7229711,
  author    = {Kokila RT and Thamarai Selvi, S. and Govindarajan, Kannan},
  booktitle = {2014 Sixth International Conference on Advanced Computing (ICoAC)},
  title     = {DDoS detection and analysis in SDN-based environment using support vector machine classifier},
  year      = {2014},
  month     = {Dec},
  pages     = {205-210},
  abstract  = {Software Defined Networking (SDN) provides separation of data plane and control plane. The controller has centralized control of the entire network. SDN offers the ability to program the network and allows dynamic creation of flow policies. The controller is vulnerable to Distributed Denial of Service (DDoS) attacks that leads to resource exhaustion which causes non-reachability of services given by the controller. The detection of DDoS requires adaptive and accurate classifier that does decision making from uncertain information. It is critical to detect the attack in the controller at earlier stage. SVM is widely used classifier with high accuracy and less false positive rate. We analyze the SVM classifier and compare it with other classifiers for DDoS detection. The experiments show that SVM performs accurate classification than others.},
  doi       = {10.1109/ICoAC.2014.7229711},
  groups    = {First Filtering},
  issn      = {2377-6927},
  keywords  = {Support vector machines;Probes;Accuracy;Bagging;Floods;Training;Testing;SDN;DDoS;SVM;OpenFlow;DARPA dataset},
}

@InProceedings{8457818,
  author    = {Khorsandroo, Sajad and Tosun, Ali Saman},
  booktitle = {2018 IEEE 11th International Conference on Cloud Computing (CLOUD)},
  title     = {Time Inference Attacks on Software Defined Networks: Challenges and Countermeasures},
  year      = {2018},
  month     = {July},
  pages     = {342-349},
  abstract  = {Through time inference attacks, adversaries fingerprint SDN controllers, estimate switches flow-table size, and perform flow state reconnaissance. In fact, timing a SDN and analyzing its results can expose information which later empowers SDN resource-consumption or saturation attacks. In the real world, however, launching such attacks is not easy. This is due to some challenges attackers may encounter while attacking an actual SDN deployment. These challenges, which are not addressed adequately in the related literature, are investigated in this paper. Accordingly, practical solutions to mitigate such attacks are also proposed. Discussed challenges are clarified by means of conducting extensive experiments on an actual cloud data center testbed. Moreover, mitigation schemes have been implemented and examined in details. Experimental results show that proposed countermeasures effectively block time inference attacks.},
  doi       = {10.1109/CLOUD.2018.00050},
  groups    = {First Filtering},
  issn      = {2159-6190},
  keywords  = {Software;Probes;Reconnaissance;Data centers;Process control;Delays;SDN;Time Inference Attacks;Cloud Datacenter;Countermeasure;SDN Security;Cloud Security;Software Defined Network},
}

@Article{9102392,
  author   = {Hu, Yidan and Zhang, Rui},
  journal  = {IEEE/ACM Transactions on Networking},
  title    = {A Spatiotemporal Approach for Secure Crowdsourced Radio Environment Map Construction},
  year     = {2020},
  issn     = {1558-2566},
  month    = {Aug},
  number   = {4},
  pages    = {1790-1803},
  volume   = {28},
  abstract = {Database-driven Dynamic Spectrum Sharing (DSS) is the de-facto technical paradigm adopted by Federal Communications Commission for increasing spectrum efficiency, which allows licensed spectrum to be opportunistically used by secondary users. In database-driven DSS, a geo-location database administrator (DBA) maintains spectrum availability information over its service region in the form of a Radio Environment Map (REM), where the received signal strength from the primary user at every location is either directly measured via spectrum sensing or estimated via statistical spatial interpolation. Crowdsourcing-based spectrum sensing is a promising approach for periodically collecting spectrum measurements over a large geographic area but is unfortunately vulnerable to false spectrum measurements. Despite a large body of prior work on secure cooperative spectrum sensing, how to construct an accurate REM in the presence of false measurements remains an open challenge. In this paper, we introduce ST-REM, a novel spatiotemporal approach for securely constructing an REM in the presence of false spectrum measurements. Inspired by the self-label techniques developed for semi-supervised learning, ST-REM iteratively constructs an REM from a small number of spectrum measurements from trusted anchor sensors and many more measurements from mobile users. During each iteration, the DBA evaluates the trustworthiness of each measurement by jointly considering its spatial fitness with other trusted measurements and the mobile user's long-term behavior. By gradually incorporating the most trustworthy spectrum measurements, the DBA is able to construct a REM with high accuracy. Extensive simulation studies using a real spectrum measurement dataset confirm the efficacy and efficiency of ST-REM.},
  doi      = {10.1109/TNET.2020.2992939},
  groups   = {First Filtering},
  keywords = {Sensors;Interpolation;Spatiotemporal phenomena;Atmospheric measurements;Particle measurements;Distortion measurement;IEEE transactions;Dynamic spectrum sharing;crowdsourcing;spectrum sensing;radio environment map;security},
}

@Article{9078082,
  author   = {Kim, Aram and Oh, Junhyoung and Ryu, Jinho and Lee, Kyungho},
  journal  = {IEEE Access},
  title    = {A Review of Insider Threat Detection Approaches With IoT Perspective},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {78847-78867},
  volume   = {8},
  abstract = {Security professionals, government agencies, and corporate organizations have found an inherent need to prevent or mitigate attacks from insider threats. Accordingly, active research on insider threat detection has been conducted to prevent and mitigate adverse effects such as leakage of valuable information that may be caused by insiders. Along with the growth of Internet-of-Things (IoT), new security challenges arise in the existing security frameworks. Attack surfaces are significantly enlarged which could cause a severe risk in terms of company insider threat management. In this work, we provide a generalization of aspects of insider threats with IoT and analyze the surveyed literature based on both private and public sources. We then examine data sources considering IoT environments based on the characteristics and the structure of IoT (perceptual, network, and application layers). The result of reviewing the study shows that using the data source of the network and application layer is more suitable than the perceptual layer in the IoT environment. We also categorized each layer's data sources according to their features, and we investigated research objectives and methods for each category. Finally, the potential for utilization and limitations under the IoT environment are presented at the end of each layer examination.},
  doi      = {10.1109/ACCESS.2020.2990195},
  groups   = {First Filtering},
  keywords = {Machine learning;Anomaly detection;Companies;Computer security;Mobile handsets;Insider threat detection;Internet-of-Things;dataset;survey},
}

@Article{8386762,
  author   = {Mishra, Preeti and Varadharajan, Vijay and Tupakula, Uday and Pilli, Emmanuel S.},
  journal  = {IEEE Communications Surveys Tutorials},
  title    = {A Detailed Investigation and Analysis of Using Machine Learning Techniques for Intrusion Detection},
  year     = {2019},
  issn     = {1553-877X},
  month    = {Firstquarter},
  number   = {1},
  pages    = {686-728},
  volume   = {21},
  abstract = {Intrusion detection is one of the important security problems in todays cyber world. A significant number of techniques have been developed which are based on machine learning approaches. However, they are not very successful in identifying all types of intrusions. In this paper, a detailed investigation and analysis of various machine learning techniques have been carried out for finding the cause of problems associated with various machine learning techniques in detecting intrusive activities. Attack classification and mapping of the attack features is provided corresponding to each attack. Issues which are related to detecting low-frequency attacks using network attack dataset are also discussed and viable methods are suggested for improvement. Machine learning techniques have been analyzed and compared in terms of their detection capability for detecting the various category of attacks. Limitations associated with each category of them are also discussed. Various data mining tools for machine learning have also been included in the paper. At the end, future directions are provided for attack detection using machine learning techniques.},
  doi      = {10.1109/COMST.2018.2847722},
  groups   = {First Filtering},
  keywords = {Machine learning;Anomaly detection;Intrusion detection;Databases;Support vector machines;Tutorials;Machine learning;intrusion;attacks;security},
}

@InProceedings{6513876,
  author    = {Jhaveri, Rutvij H. and Patel, Ashish D. and Dangarwala, Kruti J.},
  booktitle = {2012 International Conference on Emerging Trends in Science, Engineering and Technology (INCOSET)},
  title     = {Comprehensive study of various DoS attacks and defense approaches in MANETs},
  year      = {2012},
  month     = {Dec},
  pages     = {25-31},
  abstract  = {A Mobile Ad-hoc Network (MANET) is an independent and self-configurable network without any fixed infrastructure. Compared to traditional network, MANETs have unique characteristics such as wireless shared radio medium, limited communication range, highly dynamic topology, power constraints and lack of trusted centralized authority. When a node wishes to communicate with other node in the network, it invites all available nodes to participate in the routing mechanism; moreover, conventional routing protocols assume trusted co-operative environment. As a result, network layer of MANET is prone to various security attacks and therefore, finding a secure and efficient route becomes a major challenge. In this paper, we briefly introduce routing protocols, examine the behavior of various Denial-of-Service (DoS) attacks at the network layer of MANET and provide comprehensive survey of the existing defense approaches to these attacks.},
  doi       = {10.1109/INCOSET.2012.6513876},
  groups    = {First Filtering},
  keywords  = {MANETs;Routing Protocols;Security;Network Layer DoS Attacks;Defense Approaches},
}

@Article{8861029,
  author   = {Berrueta, Eduardo and Morato, Daniel and Magaña, Eduardo and Izal, Mikel},
  journal  = {IEEE Access},
  title    = {A Survey on Detection Techniques for Cryptographic Ransomware},
  year     = {2019},
  issn     = {2169-3536},
  pages    = {144925-144944},
  volume   = {7},
  abstract = {Crypto-ransomware is a type of malware that encrypts user files, deletes the original data, and asks for a ransom to recover the hijacked documents. It is a cyber threat that targets both companies and residential users, and has spread in recent years because of its lucrative results. Several articles have presented classifications of ransomware families and their typical behaviour. These insights have stimulated the creation of detection techniques for antivirus and firewall software. However, because the ransomware scene evolves quickly and aggressively, these studies quickly become outdated. In this study, we surveyed the detection techniques that the research community has developed in recent years. We compared the different approaches and classified the algorithms based on the input data they obtain from ransomware actions, and the decision procedures they use to reach a classification decision between benign or malign applications. This is a detailed survey that focuses on detection algorithms, compared to most previous studies that offer a survey of ransomware families or isolated proposals of detection algorithms. We also compared the results of these proposals.},
  doi      = {10.1109/ACCESS.2019.2945839},
  groups   = {First Filtering},
  keywords = {Ransomware;Servers;Encryption;Detection algorithms;Proposals;Computer security;malware detection;ransomware},
}

@InProceedings{9162280,
  author    = {Senigagliesi, Linda and Baldi, Marco and Gambi, Ennio},
  booktitle = {2020 IEEE Conference on Communications and Network Security (CNS)},
  title     = {Physical Layer Authentication Techniques based on Machine Learning with Data Compression},
  year      = {2020},
  month     = {June},
  pages     = {1-6},
  abstract  = {Wireless communications employing multi-carrier transmissions, like orthogonal frequency division multiplexing (OFDM) or single-carrier frequency division multiple access (SCFDMA) may involve the use of a large number of subcarriers. In Internet of Things (IoT) contexts, however, the use of such technologies implies the fast management of large amounts of samples on devices with limited memory and computational resources. The adoption of physical layer authentication protocols in IoT may suffer from this fact, especially when they exploit machine learning algorithms yielding a significant computational burden. For instance, the complexity of Nearest Neighbor classifiers strictly depends on the training set dimension, which is directly proportional to the number of used subcarriers. In order to deal with this issue, we start from a naive approach based on random sampling of the input data to extract features, and then consider more advanced data dimension reduction algorithms, such as Principal Component Analysis (PCA) and t-distributed Stochastic Neighbor Embedding (t-SNE). We show that PCA is able to guarantee the best trade-off between authentication performance and complexity, while the application of t-SNE is effective when one wants to reduce data to a very small number of features.},
  doi       = {10.1109/CNS48642.2020.9162280},
  groups    = {First Filtering},
  keywords  = {Training;Authentication;Principal component analysis;Channel estimation;Fading channels;Complexity theory;authentication;compression algorithms;machine learning;physical layer security;wireless networks},
}

@Article{6657497,
  author   = {Suarez-Tangil, Guillermo and Tapiador, Juan E. and Peris-Lopez, Pedro and Ribagorda, Arturo},
  journal  = {IEEE Communications Surveys Tutorials},
  title    = {Evolution, Detection and Analysis of Malware for Smart Devices},
  year     = {2014},
  issn     = {1553-877X},
  month    = {Second},
  number   = {2},
  pages    = {961-987},
  volume   = {16},
  abstract = {Smart devices equipped with powerful sensing, computing and networking capabilities have proliferated lately, ranging from popular smartphones and tablets to Internet appliances, smart TVs, and others that will soon appear (e.g., watches, glasses, and clothes). One key feature of such devices is their ability to incorporate third-party apps from a variety of markets. This poses strong security and privacy issues to users and infrastructure operators, particularly through software of malicious (or dubious) nature that can easily get access to the services provided by the device and collect sensory data and personal information. Malware in current smart devices -mostly smartphones and tablets- have rocketed in the last few years, in some cases supported by sophisticated techniques purposely designed to overcome security architectures currently in use by such devices. Even though important advances have been made on malware detection in traditional personal computers during the last decades, adopting and adapting those techniques to smart devices is a challenging problem. For example, power consumption is one major constraint that makes unaffordable to run traditional detection engines on the device, while externalized (i.e., cloud-based) techniques rise many privacy concerns. This article examines the problem of malware in smart devices and recent progress made in detection techniques. We first present a detailed analysis on how malware has evolved over the last years for the most popular platforms. We identify exhibited behaviors, pursued goals, infection and distribution strategies, etc. and provide numerous examples through case studies of the most relevant specimens. We next survey, classify and discuss efforts made on detecting both malware and other suspicious software (grayware), concentrating on the 20 most relevant techniques proposed between 2010 and 2013. Based on the conclusions extracted from this study, we finally provide constructive discussion on open research problems and areas where we believe that more work is needed.},
  doi      = {10.1109/SURV.2013.101613.00077},
  groups   = {First Filtering},
  keywords = {Malware;Smart phones;Software;Privacy;Androids;Humanoid robots;smart devices;malware;grayware;smartphones;security;privacy},
}

@InProceedings{9257714,
  author    = {Alnuman, Ibrahim Ahmed and Al-Akhras, Mousa},
  booktitle = {2020 2nd International Conference on Computer and Information Sciences (ICCIS)},
  title     = {Machine Learning DDoS Detection for Generated Internet of Things Dataset (IoT Dat)},
  year      = {2020},
  month     = {Oct},
  pages     = {1-6},
  abstract  = {Network infrastructure faces a lot of attacks, including attacks on integrity and confidentiality of the network packets along with their destinations and sources as well as attacks on network availability. Distributed Denial of Service (DDoS) emanates from various attack sources and focuses on the network, services, and hosts' availability. DDoS attacks are difficult to trace back to actual attackers, can lead to catastrophic service loss, and are launched with ease, making them one of the most dangerous attacks. This research simulates an Internet of Things network in-home setting of 100 nodes using OMNeT++ simulation tool, including a DDoS attack. Regular and attack-injected traffic is generated to evaluate the accuracy of detecting DDoS attacks in IoT networks using machine learning technqiues. A new IoT Dataset called IoT Dat is generated with different scenarios of normal traffic and traffic with attacks of different intensities of 5, 10, and 20. The authors will make this dataset publicly available. Moreover, machine learning techniques are used to assess the efficiency of attack detection.},
  doi       = {10.1109/ICCIS49240.2020.9257714},
  groups    = {First Filtering},
  keywords  = {Computer crime;Denial-of-service attack;Internet of Things;Cloud computing;Servers;Machine learning;Virtual machining;Distributed Denial of Service;DDoS;Internet of Things;IoT;Machine Learning;OMNeT++},
}

@InProceedings{8500165,
  author    = {Taleqani, Ali Rahim and Nygard, Kendall E. and Bridgelall, Raj and Hough, Jill},
  booktitle = {2018 IEEE International Conference on Electro/Information Technology (EIT)},
  title     = {Machine Learning Approach to Cyber Security in Aviation},
  year      = {2018},
  month     = {May},
  pages     = {0147-0152},
  abstract  = {This paper describes a set of real-world potential cyber threats in the aviation industry. Various Machine Learning approaches are available to address security issues in this context. Given the growing number of cyber threats, machine learning has become a promising approach to identify and immunize against such threats.},
  doi       = {10.1109/EIT.2018.8500165},
  groups    = {First Filtering},
  issn      = {2154-0373},
  keywords  = {Aircraft;Air traffic control;Phishing;Machine learning;cybersecurity;aviation;machine learning;big data},
}

@InProceedings{7943475,
  author    = {Yi Shi and Sagduyu, Yalin and Grushin, Alexander},
  booktitle = {2017 IEEE International Symposium on Technologies for Homeland Security (HST)},
  title     = {How to steal a machine learning classifier with deep learning},
  year      = {2017},
  month     = {April},
  pages     = {1-5},
  abstract  = {This paper presents an exploratory machine learning attack based on deep learning to infer the functionality of an arbitrary classifier by polling it as a black box, and using returned labels to build a functionally equivalent machine. Typically, it is costly and time consuming to build a classifier, because this requires collecting training data (e.g., through crowdsourcing), selecting a suitable machine learning algorithm (through extensive tests and using domain-specific knowledge), and optimizing the underlying hyperparameters (applying a good understanding of the classifier's structure). In addition, all this information is typically proprietary and should be protected. With the proposed black-box attack approach, an adversary can use deep learning to reliably infer the necessary information by using labels previously obtained from the classifier under attack, and build a functionally equivalent machine learning classifier without knowing the type, structure or underlying parameters of the original classifier. Results for a text classification application demonstrate that deep learning can infer Naive Bayes and SVM classifiers with high accuracy and steal their functionalities. This new attack paradigm with deep learning introduces additional security challenges for online machine learning algorithms and raises the need for novel mitigation strategies to counteract the high fidelity inference capability of deep learning.},
  doi       = {10.1109/THS.2017.7943475},
  groups    = {First Filtering},
  keywords  = {Machine learning;Support vector machines;Training data;Neurons;Machine learning algorithms;Organizations;Security;Machine learning;adversarial machine learning;classifier;deep learning;exploratory attacks},
}

@InProceedings{6151977,
  author    = {Wardman, Brad and Stallings, Tommy and Warner, Gary and Skjellum, Anthony},
  booktitle = {2011 eCrime Researchers Summit},
  title     = {High-performance content-based phishing attack detection},
  year      = {2011},
  month     = {Nov},
  pages     = {1-9},
  abstract  = {Phishers continue to alter the source code of the web pages used in their attacks to mimic changes to legitimate websites of spoofed organizations and to avoid detection by phishing countermeasures. Manipulations can be as subtle as source code changes or as apparent as adding or removing significant content. To appropriately respond to these changes to phishing campaigns, a cadre of file matching algorithms is implemented to detect phishing websites based on their content, employing a custom data set consisting of 17,992 phishing attacks targeting 159 different brands. The results of the experiments using a variety of different content-based approaches demonstrate that some can achieve a detection rate of greater than 90% while maintaining a low false positive rate.},
  doi       = {10.1109/eCrime.2011.6151977},
  groups    = {First Filtering},
  issn      = {2159-1245},
  keywords  = {Indexes;Zinc;Fingerprint recognition;Phishing;Countermeasures;Content-based approaches;Cybercrime},
}

@InProceedings{6755239,
  author    = {Sherif, Ahmed and Elsabrouty, Maha and Shoukry, Amin},
  booktitle = {2013 IEEE 16th International Conference on Computational Science and Engineering},
  title     = {A Novel Taxonomy of Black-Hole Attack Detection Techniques in Mobile Ad-hoc Network (MANET)},
  year      = {2013},
  month     = {Dec},
  pages     = {346-352},
  abstract  = {Mobile Ad-Hoc Networks (MANETs) are characterized by the lack of infrastructure, dynamic topology, and their use of the open wireless medium. Black-hole attack represents a major threat for such type of networks. The purpose of this paper is two folds. First, to present an extensive survey of the known black-hole detection and prevention approaches. Another objective is to present new dimensions for their classification.},
  doi       = {10.1109/CSE.2013.60},
  groups    = {First Filtering},
  keywords  = {Routing protocols;Routing;Taxonomy;Ad hoc networks;Monitoring;Genetic algorithms},
}

@InProceedings{8080397,
  author    = {Joshi, Harshvardhan P. and Bennison, Matthew and Dutta, Rudra},
  booktitle = {2017 IEEE 38th Sarnoff Symposium},
  title     = {Collaborative botnet detection with partial communication graph information},
  year      = {2017},
  month     = {Sep.},
  pages     = {1-6},
  abstract  = {Botnets have long been used for malicious purposes with huge economic costs to the society. With the proliferation of cheap but non-secure Internet-of-Things (IoT) devices generating large amounts of data, the potential for damage from botnets has increased manifold. There are several approaches to detect bots or botnets, though many traditional techniques are becoming less effective as botnets with centralized command & control structure are being replaced by peer-to-peer (P2P) botnets which are harder to detect. Several algorithms have been proposed in literature that use graph analysis or machine learning techniques to detect the overlay structure of P2P networks in communication graphs. Many of these algorithms however, depend on the availability of a universal communication graph or a communication graph aggregated from several ISPs, which is not likely to be available in reality. In real world deployments, significant gaps in communication graphs are expected and any solution proposed should be able to work with partial information. In this paper, we analyze the effectiveness of some community detection algorithms in detecting P2P botnets, especially with partial information. We show that the approach can work with only about half of the nodes reporting their communication graphs, with only small increase in detection errors.},
  doi       = {10.1109/SARNOF.2017.8080397},
  groups    = {First Filtering},
  keywords  = {Detection algorithms;Image edge detection;Computer crime;Error analysis;Algorithm design and analysis},
}

@Article{8567980,
  author   = {Sun, Nan and Zhang, Jun and Rimba, Paul and Gao, Shang and Zhang, Leo Yu and Xiang, Yang},
  journal  = {IEEE Communications Surveys Tutorials},
  title    = {Data-Driven Cybersecurity Incident Prediction: A Survey},
  year     = {2019},
  issn     = {1553-877X},
  month    = {Secondquarter},
  number   = {2},
  pages    = {1744-1772},
  volume   = {21},
  abstract = {Driven by the increasing scale and high profile cybersecurity incidents related public data, recent years we have witnessed a paradigm shift in understanding and defending against the evolving cyber threats, from primarily reactive detection toward proactive prediction. Meanwhile, governments, businesses, and individual Internet users show the growing public appetite to improve cyber resilience that refers to their ability to prepare for, combat and recover from cyber threats and incidents. Undoubtedly, predicting cybersecurity incidents is deemed to have excellent potential for proactively advancing cyber resilience. Research communities and industries have begun proposing cybersecurity incident prediction schemes by utilizing different types of data sources, including organization's reports and datasets, network data, synthetic data, data crawled from webpages, and data retrieved from social media. With a focus on the dataset, this survey paper investigates the emerging research by reviewing recent representative works appeared in the dominant period. We also extract and summarize the data-driven research methodology commonly adopted in this fast-growing area. In consonance with the phases of the methodology, each work that predicts cybersecurity incident is comprehensively studied. Challenges and future directions in this field are also discussed.},
  doi      = {10.1109/COMST.2018.2885561},
  groups   = {First Filtering},
  keywords = {Organizations;Tutorials;Data mining;Australia;Cybersecurity incidents;data mining;data-driven;discovery;machine learning;prediction},
}

@Article{7930501,
  author   = {Mayzaud, Anthéa and Badonnel, Rémi and Chrisment, Isabelle},
  journal  = {IEEE Transactions on Network and Service Management},
  title    = {A Distributed Monitoring Strategy for Detecting Version Number Attacks in RPL-Based Networks},
  year     = {2017},
  issn     = {1932-4537},
  month    = {June},
  number   = {2},
  pages    = {472-486},
  volume   = {14},
  abstract = {The Internet of Things is characterized by the large-scale deployment of low power and lossy networks (LLN), interconnecting pervasive objects. The routing protocol for LLN (RPL) protocol has been standardized by IETF to enable a lightweight and robust routing in these constrained networks. A versioning mechanism is incorporated into RPL in order to maintain an optimized topology. However, an attacker can exploit this mechanism to significantly damage the network and reduce its lifetime. After analyzing and comparing existing work, we propose in this paper a monitoring strategy with dedicated algorithms for detecting such attacks and identifying the involved malicious nodes. The performance of this solution is evaluated through extensive experiments, and its scalability is quantified with the support of a monitoring node placement optimization method.},
  doi      = {10.1109/TNSM.2017.2705290},
  groups   = {First Filtering},
  keywords = {Monitoring;Network topology;Topology;Protocols;Internet of Things;Security;Maintenance engineering;Security management;Internet of Things;RPL},
}

@InProceedings{8757390,
  author    = {Nazarov, Alexey N. and Vaish, Abhishek and Voronkov, Ilia M. and Singh, Sunakshi and Ojha, Nitish Kumar},
  booktitle = {2018 Engineering and Telecommunication (EnT-MIPT)},
  title     = {Methodology for Detecting Traces of Preparation for Cyber Attacks},
  year      = {2018},
  month     = {Nov},
  pages     = {12-15},
  abstract  = {This article proposes the order of description and classification of digital traces of the attacking object and new methodical recommendations for creating a protection function to counter cyber attacks.},
  doi       = {10.1109/EnT-MIPT.2018.00010},
  groups    = {First Filtering},
  keywords  = {Cyberattack;Tools;Linguistics;Task analysis;Intrusion detection;Object recognition;Information technology;cyber attacks traces;protection function;infocommunication},
}

@InProceedings{9275959,
  author    = {Chen, Zhaolin},
  booktitle = {2020 International Conference on Computing and Data Science (CDS)},
  title     = {Deep Learning for Cybersecurity: A Review},
  year      = {2020},
  month     = {Aug},
  pages     = {7-18},
  abstract  = {With the development of Internet technology, the scale of Internet has increased considerably, which brings with a large number of cyber-attacks. Traditional protection techniques are confronted with complex, advanced and ongoing evolvement adversarial situations, which have to be more adaptive and responsive in order to handle future security and privacy problems. Deep Learning (DL), as one of the most currently remarkable machine learning techniques, has a great potential in cybersecurity. In this paper, author is committed to analyze current cyber-attacks, to review recent state-of-the-art deep learning algorithms and Figure out pros and cons of them, and to discuss the feasibility of deep learning technology applied to cybersecurity to defend malware attacks, DDoS attacks and spoofing attacks. This article also analyzes some vulnerabilities of deep learning algorithms and potential security problems which might come out when DL is applied to cybersecurity. Finally, paper discusses some challenges a DL-based defense mechanism has to overcome, and status and future directions of DL-based defense technology.},
  doi       = {10.1109/CDS49703.2020.00009},
  groups    = {First Filtering},
  keywords  = {Hafnium;Three-dimensional displays;Data science;5G mobile communication;cybersecurity;deep learning},
}

@InProceedings{9289504,
  author    = {Ali, Jehad and Roh, Byeong-hee and Lee, Byungkyu and Oh, Jimyung and Adil, Muhammad},
  booktitle = {2020 International Conference on Information and Communication Technology Convergence (ICTC)},
  title     = {A Machine Learning Framework for Prevention of Software-Defined Networking controller from DDoS Attacks and dimensionality reduction of big data},
  year      = {2020},
  month     = {Oct},
  pages     = {515-519},
  abstract  = {The controller is an indispensable entity in software-defined networking (SDN), as it maintains a global view of the underlying network. However, if the controller fails to respond to the network due to a distributed denial of service (DDoS) attacks. Then, the attacker takes charge of the whole network via launching a spoof controller and can also modify the flow tables. Hence, faster, and accurate detection of DDoS attacks against the controller will make the SDN reliable and secure. Moreover, the Internet traffic is drastically increasing due to unprecedented growth of connected devices. Consequently, the processing of large number of requests cause a performance bottleneck regarding SDN controller. In this paper, we propose a hierarchical control plane SDN architecture for multi-domain communication that uses a statistical method called principal component analysis (PCA) to reduce the dimensionality of the big data traffic and the support vector machine (SVM) classifier is employed to detect a DDoS attack. SVM has high accuracy and less false positive rate while the PCA filters attribute drastically. Consequently, the performance of classification and accuracy is improved while the false positive rate is reduced.},
  doi       = {10.1109/ICTC49870.2020.9289504},
  groups    = {First Filtering},
  issn      = {2162-1233},
  keywords  = {Support vector machines;Dimensionality reduction;Big Data;Denial-of-service attack;Prediction algorithms;Classification algorithms;Principal component analysis;software-defined networking;distributed denial of service attack;principal component analysis;machine learning;big data},
}

@InProceedings{10.1145/3366423.3380166,
  author    = {Tian, Sheng and Xiong, Tao},
  booktitle = {Proceedings of The Web Conference 2020},
  title     = {A Generic Solver Combining Unsupervised Learning and Representation Learning for Breaking Text-Based Captchas},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {860–871},
  publisher = {Association for Computing Machinery},
  series    = {WWW '20},
  abstract  = {Although there are many alternative captcha schemes available, text-based captchas
are still one of the most popular security mechanism to maintain Internet security
and prevent malicious attacks, due to the user preferences and ease of design. Over
the past decade, different methods of breaking captchas have been proposed, which
helps captcha keep evolving and become more robust. However, these previous works
generally require heavy expert involvement and gradually become ineffective with the
introduction of new security features. This paper proposes a generic solver combining
unsupervised learning and representation learning to automatically remove the noisy
background of captchas and solve text-based captchas. We introduce a new training
scheme for constructing mini-batches, which contain a large number of unlabeled hard
examples, to improve the efficiency of representation learning. Unlike existing deep
learning algorithms, our method requires significantly fewer labeled samples and surpasses
the recognition performance of a fully-supervised model with the same network architecture.
Moreover, extensive experiments show that the proposed method outperforms state-of-the-art
by delivering a higher accuracy on various captcha schemes. We provide further discussions
of potential applications of the proposed unified framework. We hope that our work
can inspire the community to enhance the security of text-based captchas.},
  doi       = {10.1145/3366423.3380166},
  groups    = {First Filtering},
  isbn      = {9781450370233},
  keywords  = {representation Learning, text-based captchas, unsupervised learning, Internet security},
  location  = {Taipei, Taiwan},
  numpages  = {12},
}

@InProceedings{10.1145/3240508.3240603,
  author    = {Yin, Minghao and Zhang, Yongbing and Li, Xiu and Wang, Shiqi},
  booktitle = {Proceedings of the 26th ACM International Conference on Multimedia},
  title     = {When Deep Fool Meets Deep Prior: Adversarial Attack on Super-Resolution Network},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {1930–1938},
  publisher = {Association for Computing Machinery},
  series    = {MM '18},
  abstract  = {This paper investigates the vulnerability of the deep prior used in deep learning
based image restoration. In particular, the image super-resolution, which relies on
the strong prior information to regularize the solution space and plays important
roles in the image pre-processing for future viewing and analysis, is shown to be
vulnerable to the well-designed adversarial examples. We formulate the adversarial
example generation process as an optimization problem, and given super-resolution
model three different types of attack are designed based on the subsequent tasks:
(i) style transfer attack; (ii) classification attack; (iii) caption attack. Another
interesting property of our design is that the attack is hidden behind the super-resolution
process, such that the utilization of low resolution images is not significantly influenced.
We show that the vulnerability to adversarial examples could bring risks to the pre-processing
modules such as super-resolution deep neural network, which is also of paramount significance
for the security of the whole system. Our results also shed light on the potential
security issues of the pre-processing modules, and raise concerns regarding the corresponding
countermeasures for adversarial examples.},
  doi       = {10.1145/3240508.3240603},
  groups    = {First Filtering},
  isbn      = {9781450356657},
  keywords  = {style transfer, deep prior, super-resolution, adversarial attack, image classification, caption},
  location  = {Seoul, Republic of Korea},
  numpages  = {9},
}

@InProceedings{10.1145/3372278.3390689,
  author    = {Chen, Yanjie and Cai, Likun and Cheng, Wei and Wang, Hao},
  booktitle = {Proceedings of the 2020 International Conference on Multimedia Retrieval},
  title     = {Super-Resolution Coding Defense Against Adversarial Examples},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {189–197},
  publisher = {Association for Computing Machinery},
  series    = {ICMR '20},
  abstract  = {Deep neural networks have achieved state-of-the-art performance in many fields including
image classification. However, recent studies show these models are vulnerable to
adversarial examples formed by adding small but intentional perturbations to clean
examples. In this paper, we introduce a significant defense method against adversarial
examples. The key idea is to leverage a super-resolution coding (SR-coding) network
to eliminate noise from adversarial examples. Furthermore, to boost the effect of
defending noise, we propose a novel hybrid approach that incorporates SR-coding and
adversarial training to train robust neural networks. Experiments on benchmark datasets
demonstrate the effectiveness of our method against both the state-of-the-art white-box
attacks and black-box attacks. The proposed approach significantly improves defense
performance and achieves up to 41.26% improvement based on the accuracy by ResNet18
on PGD white-box attack.},
  doi       = {10.1145/3372278.3390689},
  groups    = {First Filtering},
  isbn      = {9781450370875},
  keywords  = {adversarial attack, super-resolution, deep learning, generative adversarial network},
  location  = {Dublin, Ireland},
  numpages  = {9},
}

@InProceedings{10.1145/2979779.2979848,
  author    = {Kumar, Vimal and Kumar, Satish and Gupta, Avadhesh Kumar},
  booktitle = {Proceedings of the International Conference on Advances in Information Communication Technology &amp; Computing},
  title     = {Real-Time Detection of Botnet Behavior in Cloud Using Domain Generation Algorithm},
  year      = {2016},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {AICTC '16},
  abstract  = {In the last few years, the high acceptability of service computing delivered over
the internet has exponentially created immense security challenges for the services
providers. Cyber criminals are using advanced malware such as polymorphic botnets
for participating in our everyday online activities and trying to access the desired
information in terms of personal details, credit card numbers and banking credentials.
Polymorphic botnet attack is one of the biggest attacks in the history of cybercrime
and currently, millions of computers are infected by the botnet clients over the world.
Botnet attack is an intelligent and highly coordinated distributed attack which consists
of a large number of bots that generates big volumes of spamming e-mails and launching
distributed denial of service (DDoS) attacks on the victim machines in a heterogeneous
network environment. Therefore, it is necessary to detect the malicious bots and prevent
their planned attacks in the cloud environment. A number of techniques have been developed
for detecting the malicious bots in a network in the past literature. This paper recognize
the ineffectiveness exhibited by the singnature based detection technique and networktraffic
based detection such as NetFlow or traffic flow detection and Anomaly based detection.
We proposed a real time malware detection methodology based on Domain Generation Algorithm.
It increasesthe throughput in terms of early detection of malicious bots and high
accuracy of identifying the suspicious behavior.},
  articleno = {69},
  doi       = {10.1145/2979779.2979848},
  groups    = {First Filtering},
  isbn      = {9781450342131},
  keywords  = {Botnet, DGA, Cyber Attack, NetFlow, DNS, C&amp;C Server},
  location  = {Bikaner, India},
  numpages  = {3},
}

@InProceedings{10.1145/3368089.3409754,
  author    = {Harel-Canada, Fabrice and Wang, Lingxiao and Gulzar, Muhammad Ali and Gu, Quanquan and Kim, Miryung},
  booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  title     = {Is Neuron Coverage a Meaningful Measure for Testing Deep Neural Networks?},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {851–862},
  publisher = {Association for Computing Machinery},
  series    = {ESEC/FSE 2020},
  abstract  = {Recent effort to test deep learning systems has produced an intuitive and compelling
test criterion called neuron coverage (NC), which resembles the notion of traditional
code coverage. NC measures the proportion of neurons activated in a neural network
and it is implicitly assumed that increasing NC improves the quality of a test suite.
In an attempt to automatically generate a test suite that increases NC, we design
a novel diversity promoting regularizer that can be plugged into existing adversarial
attack algorithms. We then assess whether such attempts to increase NC could generate
a test suite that (1) detects adversarial attacks successfully, (2) produces natural
inputs, and (3) is unbiased to particular class predictions. Contrary to expectation,
our extensive evaluation finds that increasing NC actually makes it harder to generate
an effective test suite: higher neuron coverage leads to fewer defects detected, less
natural inputs, and more biased prediction preferences. Our results invoke skepticism
that increasing neuron coverage may not be a meaningful objective for generating tests
for deep neural networks and call for a new test generation technique that considers
defect detection, naturalness, and output impartiality in tandem.},
  doi       = {10.1145/3368089.3409754},
  groups    = {First Filtering},
  isbn      = {9781450370431},
  keywords  = {Adversarial Attack, Machine Learning, Software Engineering, Neuron Coverage, Testing},
  location  = {Virtual Event, USA},
  numpages  = {12},
}

@InProceedings{10.1145/3318216.3363338,
  author    = {Roy, Abhishek and Chhabra, Anshuman and Kamhoua, Charles A. and Mohapatra, Prasant},
  booktitle = {Proceedings of the 4th ACM/IEEE Symposium on Edge Computing},
  title     = {A Moving Target Defense against Adversarial Machine Learning},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {383–388},
  publisher = {Association for Computing Machinery},
  series    = {SEC '19},
  abstract  = {Adversarial Machine Learning has become the latest threat with the ubiquitous presence
of machine learning. In this paper we propose a Moving Target Defense approach to
defend against adversarial machine learning, i.e., instead of manipulating the machine
learning algorithms, we suggest a switching scheme among machine learning algorithms
to defend against adversarial attack. We model the problem as a Stackelberg game between
the attacker and the defender. We propose a switching strategy which is the Stackelberg
equilibrium of the game. We test our method against rational, and boundedly rational
attackers. We show that designing a method against a rational attacker is enough in
most scenarios. We show that even under very harsh constraints, e.g., no attack-cost,
and availability of attacks which can bring down the accuracy to 0, it is possible
to achieve reasonable accuracy in the context of classification. This work shows,
that in addition to switching among algorithms, one can think of introducing randomness
in tuning parameters, and model choices to achieve better defense against adversarial
machine learning.},
  doi       = {10.1145/3318216.3363338},
  groups    = {First Filtering},
  isbn      = {9781450367332},
  keywords  = {moving target defense, adversarial machine learning, cybersecurity, bounded rationality},
  location  = {Arlington, Virginia},
  numpages  = {6},
}

@InProceedings{10.1145/3394171.3413546,
  author    = {Zhu, Liuwan and Ning, Rui and Wang, Cong and Xin, Chunsheng and Wu, Hongyi},
  booktitle = {Proceedings of the 28th ACM International Conference on Multimedia},
  title     = {GangSweep: Sweep out Neural Backdoors by GAN},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {3173–3181},
  publisher = {Association for Computing Machinery},
  series    = {MM '20},
  abstract  = {This work proposes GangSweep, a new backdoor detection framework that leverages the
super reconstructive power of Generative Adversarial Networks (GAN) to detect and ''sweep out'' neural backdoors. It is motivated by a series of intriguing empirical
investigations, revealing that the perturbation masks generated by GAN are persistent
and exhibit interesting statistical properties with low shifting variance and large
shifting distance in feature space. Compared with the previous solutions, the proposed
approach eliminates the reliance on the access to training data, and shows a high
degree of robustness and efficiency for detecting and mitigating a wide range of backdoored
models with various settings. Moreover, this is the first work that successfully leverages
generative networks to defend against advanced neural backdoors with multiple triggers
and their polymorphic forms.},
  doi       = {10.1145/3394171.3413546},
  groups    = {First Filtering},
  isbn      = {9781450379885},
  keywords  = {neural backdoor, model verification, deep neural network},
  location  = {Seattle, WA, USA},
  numpages  = {9},
}

@InProceedings{10.1145/3324921.3328789,
  author    = {Doshi, Keval and Mozaffari, Mahsa and Yilmaz, Yasin},
  booktitle = {Proceedings of the ACM Workshop on Wireless Security and Machine Learning},
  title     = {RAPID: Real-Time Anomaly-Based Preventive Intrusion Detection},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {49–54},
  publisher = {Association for Computing Machinery},
  series    = {WiseML 2019},
  abstract  = {Intrusion detection systems (IDSs) today face key limitations with respect to detection
and prevention of challenging IoT-empowered attacks. We address these limitations
by proposing a novel IDS called RAPID, which is based on an online scalable anomaly
detection and localization approach. We show that the anomaly detection algorithm
is asymptotically optimal under certain conditions, and comprehensively analyze its
computational complexity. Considering a real dataset and an IoT testbed we demonstrate
the use of RAPID in two different IoT-empowered cyber-attack scenarios, namely high-rate
DDoS attacks and low-rate DDoS attacks. The experiment results show the quick and
accurate detection and prevention performance of the proposed IDS.},
  doi       = {10.1145/3324921.3328789},
  groups    = {First Filtering},
  isbn      = {9781450367691},
  keywords  = {nonparametric method, sequential detection, IoT networks, anomaly detection, DDoS attacks},
  location  = {Miami, FL, USA},
  numpages  = {6},
}

@InProceedings{10.1145/3372297.3417238,
  author    = {Chen, Dingfan and Yu, Ning and Zhang, Yang and Fritz, Mario},
  booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {GAN-Leaks: A Taxonomy of Membership Inference Attacks against Generative Models},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {343–362},
  publisher = {Association for Computing Machinery},
  series    = {CCS '20},
  abstract  = {Deep learning has achieved overwhelming success, spanning from discriminative models
to generative models. In particular, deep generative models have facilitated a new
level of performance in a myriad of areas, ranging from media manipulation to sanitized
dataset generation. Despite the great success, the potential risks of privacy breach
caused by generative models have not been analyzed systematically. In this paper,
we focus on membership inference attack against deep generative models that reveals
information about the training data used for victim models. Specifically, we present
the first taxonomy of membership inference attacks, encompassing not only existing
attacks but also our novel ones. In addition, we propose the first generic attack
model that can be instantiated in a large range of settings and is applicable to various
kinds of deep generative models. Moreover, we provide a theoretically grounded attack
calibration technique, which consistently boosts the attack performance in all cases,
across different attack settings, data modalities, and training configurations. We
complement the systematic analysis of attack performance by a comprehensive experimental
study, that investigates the effectiveness of various attacks w.r.t. model type and
training configurations, over three diverse application scenarios (i.e., images, medical
data, and location data).},
  doi       = {10.1145/3372297.3417238},
  groups    = {First Filtering},
  isbn      = {9781450370899},
  keywords  = {privacy-preserving, membership inference attacks, deep learning, machine learning, generative models},
  location  = {Virtual Event, USA},
  numpages  = {20},
}

@InProceedings{10.1145/3394171.3413906,
  author    = {Zhang, Jiaming and Sang, Jitao and Zhao, Xian and Huang, Xiaowen and Sun, Yanfeng and Hu, Yongli},
  booktitle = {Proceedings of the 28th ACM International Conference on Multimedia},
  title     = {Adversarial Privacy-Preserving Filter},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {1423–1431},
  publisher = {Association for Computing Machinery},
  series    = {MM '20},
  abstract  = {While widely adopted in practical applications, face recognition has been critically
discussed regarding the malicious use of face images and the potential privacy problems,
e.g., deceiving payment system and causing personal sabotage. Online photo sharing
services unintentionally act as the main repository for malicious crawler and face
recognition applications. This work aims to develop a privacy-preserving solution,
called Adversarial Privacy-preserving Filter (APF), to protect the online shared face
images from being maliciously used. We propose an end-cloud collaborated adversarial
attack solution to satisfy requirements of privacy, utility and non-accessibility.
Specifically, the solutions consist of three modules: (1) image-specific gradient
generation, to extract image-specific gradient in the user end with a compressed probe
model; (2) adversarial gradient transfer, to fine-tune the image-specific gradient
in the server cloud; and (3) universal adversarial perturbation enhancement, to append
image-independent perturbation to derive the final adversarial noise. Extensive experiments
on three datasets validate the effectiveness and efficiency of the proposed solution.
A prototype application is also released for further evaluation. We hope the end-cloud
collaborated attack framework could shed light on addressing the issue of online multimedia
sharing privacy-preserving issues from user side.},
  doi       = {10.1145/3394171.3413906},
  groups    = {First Filtering},
  isbn      = {9781450379885},
  keywords  = {face recognition, adversarial example, privacy-preserving, photo sharing},
  location  = {Seattle, WA, USA},
  numpages  = {9},
}

@InProceedings{10.1145/3407023.3409201,
  author    = {Markiewicz, Robert P. and Sgandurra, Daniele},
  booktitle = {Proceedings of the 15th International Conference on Availability, Reliability and Security},
  title     = {Clust-IT: Clustering-Based Intrusion Detection in IoT Environments},
  year      = {2020},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ARES '20},
  abstract  = {Low-powered and resource-constrained devices are forming a greater part of our smart
networks. For this reason, they have recently been the target of various cyber-attacks.
However, these devices often cannot implement traditional intrusion detection systems
(IDS), or they can not produce or store the audit trails needed for inspection. Therefore,
it is often necessary to adapt existing IDS systems and malware detection approaches
to cope with these constraints.We explore the application of unsupervised learning
techniques, specifically clustering, to develop a novel IDS for networks composed
of low-powered devices. We describe our solution, called Clust-IT (Clustering of IoT),
to manage heterogeneous data collected from cooperative and distributed networks of
connected devices and searching these data for indicators of compromise while remaining
protocol agnostic. We outline a novel application of OPTICS to various available IoT
datasets, composed of both packet and flow captures, to demonstrate the capabilities
of the proposed techniques and evaluate their feasibility in developing an IoT IDS.},
  articleno = {81},
  doi       = {10.1145/3407023.3409201},
  groups    = {First Filtering},
  isbn      = {9781450388337},
  location  = {Virtual Event, Ireland},
  numpages  = {9},
}

@InProceedings{10.1145/3422337.3447836,
  author    = {Li, Jiacheng and Li, Ninghui and Ribeiro, Bruno},
  booktitle = {Proceedings of the Eleventh ACM Conference on Data and Application Security and Privacy},
  title     = {Membership Inference Attacks and Defenses in Classification Models},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {5–16},
  publisher = {Association for Computing Machinery},
  series    = {CODASPY '21},
  abstract  = {We study the membership inference (MI) attack against classifiers, where the attacker's
goal is to determine whether a data instance was used for training the classifier.
Through systematic cataloging of existing MI attacks and extensive experimental evaluations
of them, we find that a model's vulnerability to MI attacks is tightly related to
the generalization gap---the difference between training accuracy and test accuracy.
We then propose a defense against MI attacks that aims to close the gap by intentionally
reduces the training accuracy. More specifically, the training process attempts to
match the training and validation accuracies, by means of a new set regularizer using
the Maximum Mean Discrepancy between the softmax output empirical distributions of
the training and validation sets. Our experimental results show that combining this
approach with another simple defense (mix-up training) significantly improves state-of-the-art
defense against MI attacks, with minimal impact on testing accuracy.},
  doi       = {10.1145/3422337.3447836},
  groups    = {First Filtering},
  isbn      = {9781450381437},
  keywords  = {image classification, neural networks, membership inference},
  location  = {Virtual Event, USA},
  numpages  = {12},
}

@InProceedings{10.1145/3190619.3190637,
  author    = {Madani, Pooria and Vlajic, Natalija},
  booktitle = {Proceedings of the 5th Annual Symposium and Bootcamp on Hot Topics in the Science of Security},
  title     = {Robustness of Deep Autoencoder in Intrusion Detection under Adversarial Contamination},
  year      = {2018},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {HoTSoS '18},
  abstract  = {The existing state-of-the-art in the field of intrusion detection systems (IDSs) generally
involves some use of machine learning algorithms. However, the computer security community
is growing increasingly aware that a sophisticated adversary could target the learning
module of these IDSs in order to circumvent future detections. Consequently, going
forward, robustness of machine-learning based IDSs against adversarial manipulation
(i.e., poisoning) will be the key factor for the overall success of these systems
in the real world. In our work, we focus on adaptive IDSs that use anomaly-based detection
to identify malicious activities in an information system. To be able to evaluate
the susceptibility of these IDSs to deliberate adversarial poisoning, we have developed
a novel framework for their performance testing under adversarial contamination. We
have also studied the viability of using deep autoencoders in the detection of anomalies
in adaptive IDSs, as well as their overall robustness against adversarial poisoning.
Our experimental results show that our proposed autoencoder-based IDS outperforms
a generic PCA-based counterpart by more than 15% in terms of detection accuracy. The
obtained results concerning the detection ability of the deep autoencoder IDS under
adversarial contamination, compared to that of the PCA-based IDS, are also encouraging,
with the deep autoencoder IDS maintaining a more stable detection in parallel to limiting
the contamination of its training dataset to just bellow 2%.},
  articleno = {1},
  doi       = {10.1145/3190619.3190637},
  groups    = {First Filtering},
  isbn      = {9781450364553},
  location  = {Raleigh, North Carolina},
  numpages  = {8},
}

@InProceedings{10.1145/3448300.3467827,
  author    = {Wang, Han and Mu\~{n}oz-Gonz\'{a}lez, Luis and Eklund, David and Raza, Shahid},
  booktitle = {Proceedings of the 14th ACM Conference on Security and Privacy in Wireless and Mobile Networks},
  title     = {Non-IID Data Re-Balancing at IoT Edge with Peer-to-Peer Federated Learning for Anomaly Detection},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {153–163},
  publisher = {Association for Computing Machinery},
  series    = {WiSec '21},
  abstract  = {The increase of the computational power in edge devices has enabled the penetration
of distributed machine learning technologies such as federated learning, which allows
to build collaborative models performing the training locally in the edge devices,
improving the efficiency and the privacy for training of machine learning models,
as the data remains in the edge devices. However, in some IoT networks the connectivity
between devices and system components can be limited, which prevents the use of federated
learning, as it requires a central node to orchestrate the training of the model.
To sidestep this, peer-to-peer learning appears as a promising solution, as it does
not require such an orchestrator. On the other side, the security challenges in IoT
deployments have fostered the use of machine learning for attack and anomaly detection.
In these problems, under supervised learning approaches, the training datasets are
typically imbalanced, i.e. the number of anomalies is very small compared to the number
of benign data points, which requires the use of re-balancing techniques to improve
the algorithms' performance. In this paper, we propose a novel peer-to-peer algorithm,P2PK-SMOTE,
to train supervised anomaly detection machine learning models in non-IID scenarios,
including mechanisms to locally re-balance the training datasets via synthetic generation
of data points from the minority class. To improve the performance in non-IID scenarios,
we also include a mechanism for sharing a small fraction of synthetic data from the
minority class across devices, aiming to reduce the risk of data de-identification.
Our experimental evaluation in real datasets for IoT anomaly detection across a different
set of scenarios validates the benefits of our proposed approach.},
  doi       = {10.1145/3448300.3467827},
  groups    = {First Filtering},
  isbn      = {9781450383493},
  keywords  = {anomaly detection, imbalanced data, non-IID data, federated learning},
  location  = {Abu Dhabi, United Arab Emirates},
  numpages  = {11},
}

@InProceedings{10.1145/3338501.3357372,
  author    = {Sehwag, Vikash and Bhagoji, Arjun Nitin and Song, Liwei and Sitawarin, Chawin and Cullina, Daniel and Chiang, Mung and Mittal, Prateek},
  booktitle = {Proceedings of the 12th ACM Workshop on Artificial Intelligence and Security},
  title     = {Analyzing the Robustness of Open-World Machine Learning},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {105–116},
  publisher = {Association for Computing Machinery},
  series    = {AISec'19},
  abstract  = {When deploying machine learning models in real-world applications, an open-world learning
framework is needed to deal with both normal in-distribution inputs and undesired
out-of-distribution (OOD) inputs. Open-world learning frameworks include OOD detectors
that aim to discard input examples which are not from the same distribution as the
training data of machine learning classifiers. However, our understanding of current
OOD detectors is limited to the setting of benign OOD data, and an open question is
whether they are robust in the presence of adversaries. In this paper, we present
the first analysis of the robustness of open-world learning frameworks in the presence
of adversaries by introducing and designing \o{}odAdvExamples. Our experimental results
show that current OOD detectors can be easily evaded by slightly perturbing benign
OOD inputs, revealing a severe limitation of current open-world learning frameworks.
Furthermore, we find that \o{}odAdvExamples also pose a strong threat to adversarial
training based defense methods in spite of their effectiveness against in-distribution
adversarial attacks. To counteract these threats and ensure the trustworthy detection
of OOD inputs, we outline a preliminary design for a robust open-world machine learning
framework.},
  doi       = {10.1145/3338501.3357372},
  groups    = {First Filtering},
  isbn      = {9781450368339},
  keywords  = {adversarial example, open world recognition, deep learning},
  location  = {London, United Kingdom},
  numpages  = {12},
}

@InProceedings{10.1145/3264888.3264894,
  author    = {Narayanan, Vedanth and Bobba, Rakesh B.},
  booktitle = {Proceedings of the 2018 Workshop on Cyber-Physical Systems Security and PrivaCy},
  title     = {Learning Based Anomaly Detection for Industrial Arm Applications},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {13–23},
  publisher = {Association for Computing Machinery},
  series    = {CPS-SPC '18},
  abstract  = {Smart Manufacturing (SM) is envisioned to make manufacturing processes more efficient
through automation and integration of networked information systems. Robotic arms
are integral to this vision. However the benefits of SM, enabled by automation and
networking, also come with cyber risks. In this work, we propose an anomaly detection
framework for robotic arms in a manufacturing pipeline and integrate it into Robot
Operating System (ROS), a middleware framework whose variants are being considered
for deployment in industrial environments for flexible automation. In particular,
we explore whether the repetitive behavior of an industrial arm can be leveraged to
detect anomalous behaviour that may indicate an intrusion. Based on a learned model,
we classify a robot's actions as anomalous or benign. We introduce the notion of a 'tolerance envelope' to train a supervised learning model. Our empirical evaluation
shows that anomalies that take the robot out of pre-determined tolerance levels can
be detected with high accuracy.},
  doi       = {10.1145/3264888.3264894},
  groups    = {First Filtering},
  isbn      = {9781450359924},
  keywords  = {smart manufacturing, robot operating system, robotics, tolerance envelope, anomaly detection},
  location  = {Toronto, Canada},
  numpages  = {11},
}

@InProceedings{10.1145/3385209.3385216,
  author    = {Kwon, Hyun and Roh, Jungmin and Yoon, Hyunsoo and Park, Ki-Woong},
  booktitle = {Proceedings of the 2020 5th International Conference on Intelligent Information Technology},
  title     = {TargetNet Backdoor: Attack on Deep Neural Network with Use of Different Triggers},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {140–145},
  publisher = {Association for Computing Machinery},
  series    = {ICIIT 2020},
  abstract  = {Deep neural networks (DNNs) provide good performance in image recognition, speech
recognition, and pattern analysis. However, DNNs are vulnerable to backdoor attacks.
Backdoor attacks allow attackers to proactively access DNN training data to train
it on additional data that are malicious, including a specific trigger. Normally,
DNNs correctly classify normal data, but malicious data with a specific trigger trained
by attackers can cause misclassification by DNNs. For example, if an attacker sets
up a road sign that includes a specific trigger, an autonomous vehicle equipped with
a DNN may misidentify the road sign and cause an accident. Thus, an attacker can use
a backdoor attack to threaten the DNN at any time. However, in certain cases, when
an attacker wants to perform a targeted attack, it may be desirable for the data introduced
through the backdoor to be misrecognized as a particular class chosen by the attacker
according to the position of a trigger. For example, if a specific trigger is attached
to the top right side of the road sign, it may be misunderstood as a left-turn sign;
if a specific trigger is attached to the top left side of the road sign, it may be
misunderstood as a right-turn sign; and if a specific trigger is attached to the bottom
left side of the road sign, it may be misunderstood as a U-turn sign. In this paper,
we propose the TargetNet backdoor, which is designed to be misidentified as a particular
target class chosen by the attacker according to a specific trigger location. The
proposed method additionally trains the target classifier on the TargetNet backdoor
data so that data with a trigger at a specific location will be misidentified as the
target class selected by the attacker. We used MNIST and Fashion-MNIST as experimental
datasets and Tensor-flow as a machine learning library. Experimental results show
that the proposed method applied to MNIST and Fashion-MNIST has a 100% attack success
rate for the TargetNet backdoor and 99.17% and 91.4% accuracy rates on normal test
data, respectively.},
  doi       = {10.1145/3385209.3385216},
  groups    = {First Filtering},
  isbn      = {9781450376594},
  keywords  = {adversarial example, poisoning attack, backdoor attack, deep neural network, Machine learning, targeted attack},
  location  = {Hanoi, Viet Nam},
  numpages  = {6},
}

@InProceedings{10.1145/3427228.3427285,
  author    = {Pu, Jiameng and Mangaokar, Neal and Wang, Bolun and Reddy, Chandan K and Viswanath, Bimal},
  booktitle = {Annual Computer Security Applications Conference},
  title     = {NoiseScope: Detecting Deepfake Images in a Blind Setting},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {913–927},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '20},
  abstract  = {Recent advances in Generative Adversarial Networks (GANs) have significantly improved
the quality of synthetic images or deepfakes. Photorealistic images generated by GANs
start to challenge the boundary of human perception of reality, and brings new threats
to many critical domains, e.g., journalism, and online media. Detecting whether an
image is generated by GAN or a real camera has become an important yet under-investigated
area. In this work, we propose a blind detection approach called NoiseScope for discovering
GAN images among other real images. A blind approach requires no a priori access to
GAN images for training, and demonstrably generalizes better than supervised detection
schemes. Our key insight is that, similar to images from cameras, GAN images also
carry unique patterns in the noise space. We extract such patterns in an unsupervised
manner to identify GAN images. We evaluate NoiseScope on 11 diverse datasets containing
GAN images, and achieve up to 99.68% F1 score in detecting GAN images. We test the
limitations of NoiseScope against a variety of countermeasures, observing that NoiseScope
holds robust or is easily adaptable.},
  doi       = {10.1145/3427228.3427285},
  groups    = {First Filtering},
  isbn      = {9781450388580},
  keywords  = {Clustering, Blind Detection, Machine Learning, Deepfakes},
  location  = {Austin, USA},
  numpages  = {15},
}

@InProceedings{10.1145/3386263.3407599,
  author    = {Zhang, Jiliang and Li, Chen and Ye, Jing and Qu, Gang},
  booktitle = {Proceedings of the 2020 on Great Lakes Symposium on VLSI},
  title     = {Privacy Threats and Protection in Machine Learning},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {531–536},
  publisher = {Association for Computing Machinery},
  series    = {GLSVLSI '20},
  abstract  = {With the improvement of computing power and storage level, Machine Learning (ML),
especially Deep Learning (DL), has shown its capabilities beyond humans in areas such
as image recognition, speech processing, and content recommendation. However, the
data collected to build ML models often contains sensitive information, and models
may have high commercial value. Compared with the security problem of model prediction
errors caused by malicious external influences, privacy threats have not attracted
widespread attention, and they have characteristics that are difficult to define and
detect. This article reviews recent research progress on ML privacy. First, the privacy
threats on data and models in different scenarios are described in detail. Then, typical
privacy protection methods are introduced. Finally, the limitations and future development
trends of ML privacy research are discussed.},
  doi       = {10.1145/3386263.3407599},
  groups    = {First Filtering},
  isbn      = {9781450379441},
  keywords  = {privacy protection, machine learning, privacy threats},
  location  = {Virtual Event, China},
  numpages  = {6},
}

@InProceedings{10.1145/3351917.3351987,
  author    = {Jiang, Lingyun and Qiao, Kai and Qin, Ruoxi and Chen, Jian and Bu, Haibing and Yan, Bin},
  booktitle = {Proceedings of the 2019 4th International Conference on Automation, Control and Robotics Engineering},
  title     = {Unsupervised Adversarial Perturbation Eliminating via Disentangled Representations},
  year      = {2019},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {CACRE2019},
  abstract  = {Although deep neural networks (DNNs) could achieve state-of-the-art performance while
recognizing images, they often vulnerable to adversarial examples where input intended
to be added the small magnitude perturbations may mislead them to incorrect results.
It is worth researching on defending against adversarial examples due to the potential
security threats. In this paper, we propose an unsupervised method for eliminating
adversarial perturbation based on disentangled representations. To achieve adversarial
defense, we propose extracting the content and perturbation features of adversarial
examples by content encoders and perturbation encoders. Meanwhile, to handle the unpaired
training data, we introduce a cross-cycle consistency loss based on disentangled representations
and a perturbation branch. We also add an adversarial loss on recovered images to
make DNNs predict right. Qualitative results show that our method can eliminate adversarial
perturbation without paired training data. We perform extensive experiments on two
public datasets MNIST and CIFAR10, which is shown the efficiency of resisting adversarial
examples.},
  articleno = {46},
  doi       = {10.1145/3351917.3351987},
  groups    = {First Filtering},
  isbn      = {9781450371865},
  keywords  = {adversarial example, Deep learning, adversarial perturbation, disentangled representations},
  location  = {Shenzhen, China},
  numpages  = {6},
}

@InProceedings{10.1145/2700171.2791038,
  author    = {Schulz, Axel and Schmidt, Benedikt and Strufe, Thorsten},
  booktitle = {Proceedings of the 26th ACM Conference on Hypertext &amp; Social Media},
  title     = {Small-Scale Incident Detection Based on Microposts},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {3–12},
  publisher = {Association for Computing Machinery},
  series    = {HT '15},
  abstract  = {Detecting large-scale incidents based on microposts has successfully been proposed
and shown. However, the detection of small-scale incidents was not satisfyingly possible
so far, though the information that is shared during such local events could improve
the situational awareness of both citizens and decision makers alike.In this paper,
we propose an approach for small-scale incident detection based on spatial-temporal-type
clustering. In contrast to existing work, (1) we employ three distinct properties
that define an incident, (2) we use a hybrid approach to reduce the computational
overhead, and (3) we extract generalized features to increase robustness towards previously
unseen data. Our evaluation in the domain of emergency first response shows that our
approach identifies 32.14% of all real world incidents recorded for the city of Seattle
just using on tweets. This result greatly outperforms the state of the art, which
only detects about 6% of the real-world incidents. Also, a precision of 77% shows
that we efficiently discard irrelevant information.},
  doi       = {10.1145/2700171.2791038},
  groups    = {First Filtering},
  isbn      = {9781450333955},
  keywords  = {event detection, microblogs},
  location  = {Guzelyurt, Northern Cyprus},
  numpages  = {10},
}

@Article{10.1145/3365573,
  author     = {Edwards, Chris},
  journal    = {Commun. ACM},
  title      = {Malevolent Machine Learning},
  year       = {2019},
  issn       = {0001-0782},
  month      = nov,
  number     = {12},
  pages      = {13–15},
  volume     = {62},
  abstract   = {AI attacks throw light on the nature of deep learning.},
  address    = {New York, NY, USA},
  doi        = {10.1145/3365573},
  groups     = {First Filtering},
  issue_date = {December 2019},
  numpages   = {3},
  publisher  = {Association for Computing Machinery},
}

@InProceedings{10.1145/3442381.3450044,
  author    = {Li, Heng and Zhou, Shiyao and Yuan, Wei and Luo, Xiapu and Gao, Cuiying and Chen, Shuiyan},
  booktitle = {Proceedings of the Web Conference 2021},
  title     = {Robust Android Malware Detection against Adversarial Example Attacks},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {3603–3612},
  publisher = {Association for Computing Machinery},
  series    = {WWW '21},
  abstract  = {Adversarial examples pose severe threats to Android malware detection because they
can render the machine learning based detection systems useless. How to effectively
detect Android malware under various adversarial example attacks becomes an essential
but very challenging issue. Existing adversarial example defense mechanisms usually
rely heavily on the instances or the knowledge of adversarial examples, and thus their
usability and effectiveness are significantly limited because they often cannot resist
the unseen-type adversarial examples. In this paper, we propose a novel robust Android
malware detection approach that can resist adversarial examples without requiring
their instances or knowledge by jointly investigating malware detection and adversarial
example defenses. More precisely, our approach employs a new VAE (variational autoencoder)
and an MLP (multi-layer perceptron) to detect malware, and combines their detection
outcomes to make the final decision. In particular, we share a feature extraction
network between the VAE and the MLP to reduce model complexity and design a new loss
function to disentangle the features of different classes, hence improving detection
performance. Extensive experiments confirm our model’s advantage in accuracy and robustness.
Our method outperforms 11 state-of-the-art robust Android malware detection models
when resisting 7 kinds of adversarial example attacks.},
  doi       = {10.1145/3442381.3450044},
  groups    = {First Filtering},
  isbn      = {9781450383127},
  keywords  = {Android Malware Detection, Mobile Security, Adversarial Example},
  location  = {Ljubljana, Slovenia},
  numpages  = {10},
}

@InProceedings{10.1145/3299874.3318031,
  author    = {Tehranipoor, Fatemeh and Karimian, Nima and Mozaffari Kermani, Mehran and Mahmoodi, Hamid},
  booktitle = {Proceedings of the 2019 on Great Lakes Symposium on VLSI},
  title     = {Deep RNN-Oriented Paradigm Shift through BOCANet: Broken Obfuscated Circuit Attack},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {335–338},
  publisher = {Association for Computing Machinery},
  series    = {GLSVLSI '19},
  abstract  = {Logic encryption obfuscation has been used for thwarting counterfeiting, overproduction,
and reverse engineering but vulnerable to attacks. However, it was recently shown
that satisfiability - checking (SAT) can potentially compromise hardware obfuscation
circuits. In this paper, we develop a novel attack called BOCANet that can be beneficial
from deep learning architecture to compromise hardware obfuscation circuits's key.
Our approach involves exploiting deep recurrent neural network (D-RNN) model, and
developing attack model to compromise the obfuscated hardware at least an order-of
magnitude more efficiently and under resource-constrained scenarios. In our experiments,
the BOCANet approach achieves an average success rate of 100% for 32 bit key size,
93.4% for 64 bit key size, 92.2% and 91.7% for 128 and 256 bit key size, respectively.},
  doi       = {10.1145/3299874.3318031},
  groups    = {First Filtering},
  isbn      = {9781450362528},
  keywords  = {hardware obfuscation, deep recurrent neural network, logic encryption},
  location  = {Tysons Corner, VA, USA},
  numpages  = {4},
}

@Article{10.1145/3417987,
  author     = {Waheed, Nazar and He, Xiangjian and Ikram, Muhammad and Usman, Muhammad and Hashmi, Saad Sajid and Usman, Muhammad},
  journal    = {ACM Comput. Surv.},
  title      = {Security and Privacy in IoT Using Machine Learning and Blockchain: Threats and Countermeasures},
  year       = {2020},
  issn       = {0360-0300},
  month      = dec,
  number     = {6},
  volume     = {53},
  abstract   = {Security and privacy of users have become significant concerns due to the involvement
of the Internet of Things (IoT) devices in numerous applications. Cyber threats are
growing at an explosive pace making the existing security and privacy measures inadequate.
Hence, everyone on the Internet is a product for hackers. Consequently, Machine Learning
(ML) algorithms are used to produce accurate outputs from large complex databases,
where the generated outputs can be used to predict and detect vulnerabilities in IoT-based
systems. Furthermore, Blockchain (BC) techniques are becoming popular in modern IoT
applications to solve security and privacy issues. Several studies have been conducted
on either ML algorithms or BC techniques. However, these studies target either security
or privacy issues using ML algorithms or BC techniques, thus posing a need for a combined
survey on efforts made in recent years addressing both security and privacy issues
using ML algorithms and BC techniques. In this article, we provide a summary of research
efforts made in the past few years, from 2008 to 2019, addressing security and privacy
issues using ML algorithms and BC techniques in the IoT domain. First, we discuss
and categorize various security and privacy threats reported in the past 12 years
in the IoT domain. We then classify the literature on security and privacy efforts
based on ML algorithms and BC techniques in the IoT domain. Finally, we identify and
illuminate several challenges and future research directions using ML algorithms and
BC techniques to address security and privacy issues in the IoT domain.},
  address    = {New York, NY, USA},
  articleno  = {122},
  doi        = {10.1145/3417987},
  groups     = {First Filtering},
  issue_date = {February 2021},
  keywords   = {machine learning, cybersecurity, Internet of Things, Blockchain},
  numpages   = {37},
  publisher  = {Association for Computing Machinery},
}

@InProceedings{10.1145/3411495.3421356,
  author    = {Liu, Yuntao and Srivastava, Ankur},
  booktitle = {Proceedings of the 2020 ACM SIGSAC Conference on Cloud Computing Security Workshop},
  title     = {GANRED: GAN-Based Reverse Engineering of DNNs via Cache Side-Channel},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {41–52},
  publisher = {Association for Computing Machinery},
  series    = {CCSW'20},
  abstract  = {In recent years, deep neural networks (DNN) have become an important type of intellectual
property due to their high performance on various classification tasks. As a result,
DNN stealing attacks have emerged. Many attack surfaces have been exploited, among
which cache timing side-channel attacks are hugely problematic because they do not
need physical probing or direct interaction with the victim to estimate the DNN model.
However, existing cache-side-channel-based DNN reverse engineering attacks rely on
analyzing the binary code of the DNN library that must be shared between the attacker
and the victim in the main memory. In reality, the DNN library code is often inaccessible
because 1) the code is proprietary, or 2) memory sharing has been disabled by the
operating system. In our work, we propose GANRED, an attack approach based on the
generative adversarial nets (GAN) framework which utilizes cache timing side-channel
information to accurately recover the structure of DNNs without memory sharing or
code access. The benefit of GANRED is four-fold. 1) There is no need for DNN library
code analysis. 2) No shared main memory segment between the victim and the attacker
is needed. 3) Our attack locates the exact structure of the victim model, unlike existing
attacks which only narrow down the structure search space. 4) Our attack efficiently
scales to deeper DNNs, exhibiting only linear growth in the number of layers in the
victim DNN.},
  doi       = {10.1145/3411495.3421356},
  groups    = {First Filtering},
  isbn      = {9781450380843},
  keywords  = {prime+probe, deep neural netorks, reverse engineering, cache side-channel, generative adversarial nets},
  location  = {Virtual Event, USA},
  numpages  = {12},
}

@Article{10.1145/2542049,
  author     = {Mitchell, Robert and Chen, Ing-Ray},
  journal    = {ACM Comput. Surv.},
  title      = {A Survey of Intrusion Detection Techniques for Cyber-Physical Systems},
  year       = {2014},
  issn       = {0360-0300},
  month      = mar,
  number     = {4},
  volume     = {46},
  abstract   = {Pervasive healthcare systems, smart grids, and unmanned aircraft systems are examples
of Cyber-Physical Systems (CPSs) that have become highly integrated in the modern
world. As this integration deepens, the importance of securing these systems increases.
In order to identify gaps and propose research directions in CPS intrusion detection
research, we survey the literature of this area. Our approach is to classify modern
CPS Intrusion Detection System (IDS) techniques based on two design dimensions: detection
technique and audit material. We summarize advantages and drawbacks of each dimension’s
options. We also summarize the most and least studied CPS IDS techniques in the literature
and provide insight on the effectiveness of IDS techniques as they apply to CPSs.
Finally, we identify gaps in CPS IDS research and suggest future research areas.},
  address    = {New York, NY, USA},
  articleno  = {55},
  doi        = {10.1145/2542049},
  groups     = {First Filtering},
  issue_date = {April 2014},
  keywords   = {security, intrusion detection, Cyber-physical systems, classification},
  numpages   = {29},
  publisher  = {Association for Computing Machinery},
}

@InProceedings{10.1145/3339252.3340497,
  author    = {Parker, Luke R. and Yoo, Paul D. and Asyhari, Taufiq A. and Chermak, Lounis and Jhi, Yoonchan and Taha, Kamal},
  booktitle = {Proceedings of the 14th International Conference on Availability, Reliability and Security},
  title     = {DEMISe: Interpretable Deep Extraction and Mutual Information Selection Techniques for IoT Intrusion Detection},
  year      = {2019},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ARES '19},
  abstract  = {Recent studies have proposed that traditional security technology -- involving pattern-matching
algorithms that check predefined pattern sets of intrusion signatures -- should be
replaced with sophisticated adaptive approaches that combine machine learning and
behavioural analytics. However, machine learning is performance driven, and the high
computational cost is incompatible with the limited computing power, memory capacity
and energy resources of portable IoT-enabled devices. The convoluted nature of deep-structured
machine learning means that such models also lack transparency and interpretability.
The knowledge obtained by interpretable learners is critical in security software
design. We therefore propose two novel models featuring a common Deep Extraction and
Mutual Information Selection (DEMISe) element which extracts features using a deep-structured
stacked autoencoder, prior to feature selection based on the amount of mutual information
(MI) shared between each feature and the class label. An entropy-based tree wrapper
is used to optimise the feature subsets identified by the DEMISe element, yielding
the DEMISe with Tree Evaluation and Regression Detection (DETEReD) model. This affords 'white box' insight, and achieves a time to build of 603 seconds, a 99.07% detection
rate, and 98.04% model accuracy. When tested against AWID, the best-referenced intrusion
detection dataset, the new models achieved a test error comparable to or better than
state-of-the-art machine-learning models, with a lower computational cost and higher
levels of transparency and interpretability.},
  articleno = {98},
  doi       = {10.1145/3339252.3340497},
  groups    = {First Filtering},
  isbn      = {9781450371643},
  keywords  = {deep learning, mutual information, Security mobility applications, lightweight intrusion detection, IoT, feature engineering, security of resource constrained devices, white-box modelling},
  location  = {Canterbury, CA, United Kingdom},
  numpages  = {10},
}

@InProceedings{10.1145/3240765.3240791,
  author    = {Rouhani, Bita Darvish and Samragh, Mohammad and Javaheripi, Mojan and Javidi, Tara and Koushanfar, Farinaz},
  booktitle = {Proceedings of the International Conference on Computer-Aided Design},
  title     = {DeepFense: Online Accelerated Defense against Adversarial Deep Learning},
  year      = {2018},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ICCAD '18},
  abstract  = {Recent advances in adversarial Deep Learning (DL) have opened up a largely unexplored
surface for malicious attacks jeopardizing the integrity of autonomous DL systems.
With the wide-spread usage of DL in critical and time-sensitive applications, including
unmanned vehicles, drones, and video surveillance systems, online detection of malicious
inputs is of utmost importance. We propose DeepFense, the first end-to-end automated
framework that simultaneously enables efficient and safe execution of DL models. DeepFense
formalizes the goal of thwarting adversarial attacks as an optimization problem that
minimizes the rarely observed regions in the latent feature space spanned by a DL
network. To solve the aforementioned minimization problem, a set of complementary
but disjoint modular redundancies are trained to validate the legitimacy of the input
samples in parallel with the victim DL model. DeepFense leverages hardware/software/algorithm
co-design and customized acceleration to achieve just-in-time performance in resource-constrained
settings. The proposed countermeasure is unsupervised, meaning that no adversarial
sample is leveraged to train modular redundancies. We further provide an accompanying
API to reduce the non-recurring engineering cost and ensure automated adaptation to
various platforms. Extensive evaluations on FPGAs and GPUs demonstrate up to two orders
of magnitude performance improvement while enabling online adversarial sample detection.},
  articleno = {134},
  doi       = {10.1145/3240765.3240791},
  groups    = {First Filtering},
  isbn      = {9781450359504},
  keywords  = {real-time computing, adversarial attacks, model reliability, deep learning, FPGA acceleration},
  location  = {San Diego, California},
  numpages  = {8},
}

@InProceedings{10.1145/3419394.3423643,
  author    = {Lin, Zinan and Jain, Alankar and Wang, Chen and Fanti, Giulia and Sekar, Vyas},
  booktitle = {Proceedings of the ACM Internet Measurement Conference},
  title     = {Using GANs for Sharing Networked Time Series Data: Challenges, Initial Promise, and Open Questions},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {464–483},
  publisher = {Association for Computing Machinery},
  series    = {IMC '20},
  abstract  = {Limited data access is a longstanding barrier to data-driven research and development
in the networked systems community. In this work, we explore if and how generative
adversarial networks (GANs) can be used to incentivize data sharing by enabling a
generic framework for sharing synthetic datasets with minimal expert knowledge. As
a specific target, our focus in this paper is on time series datasets with metadata
(e.g., packet loss rate measurements with corresponding ISPs). We identify key challenges
of existing GAN approaches for such workloads with respect to fidelity (e.g., long-term
dependencies, complex multidimensional relationships, mode collapse) and privacy (i.e.,
existing guarantees are poorly understood and can sacrifice fidelity). To improve
fidelity, we design a custom workflow called DoppelGANger (DG) and demonstrate that
across diverse real-world datasets (e.g., bandwidth measurements, cluster requests,
web sessions) and use cases (e.g., structural characterization, predictive modeling,
algorithm comparison), DG achieves up to 43% better fidelity than baseline models.
Although we do not resolve the privacy problem in this work, we identify fundamental
challenges with both classical notions of privacy and recent advances to improve the
privacy properties of GANs, and suggest a potential roadmap for addressing these challenges.
By shedding light on the promise and challenges, we hope our work can rekindle the
conversation on workflows for data sharing.},
  doi       = {10.1145/3419394.3423643},
  groups    = {First Filtering},
  isbn      = {9781450381383},
  keywords  = {generative adversarial networks, synthetic data generation, time series, privacy},
  location  = {Virtual Event, USA},
  numpages  = {20},
}

@Article{10.1145/3369816,
  author     = {Liu, Sicong and Du, Junzhao and Shrivastava, Anshumali and Zhong, Lin},
  journal    = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
  title      = {Privacy Adversarial Network: Representation Learning for Mobile Data Privacy},
  year       = {2019},
  month      = dec,
  number     = {4},
  volume     = {3},
  abstract   = {The remarkable success of machine learning has fostered a growing number of cloud-based
intelligent services for mobile users. Such a service requires a user to send data,
e.g. image, voice and video, to the provider, which presents a serious challenge to
user privacy. To address this, prior works either obfuscate the data, e.g. add noise
and remove identity information, or send representations extracted from the data,
e.g. anonymized features. They struggle to balance between the service utility and
data privacy because obfuscated data reduces utility and extracted representation
may still reveal sensitive information.This work departs from prior works in methodology:
we leverage adversarial learning to better balance between privacy and utility. We
design a representation encoder that generates the feature representations to optimize
against the privacy disclosure risk of sensitive information (a measure of privacy)
by the privacy adversaries, and concurrently optimize with the task inference accuracy
(a measure of utility) by the utility discriminator. The result is the privacy adversarial
network (PAN), a novel deep model with the new training algorithm, that can automatically
learn representations from the raw data. And the trained encoder can be deployed on
the user side to generate representations that satisfy the task-defined utility requirements
and the user-specified/agnostic privacy budgets.Intuitively, PAN adversarially forces
the extracted representations to only convey information required by the target task.
Surprisingly, this constitutes an implicit regularization that actually improves task
accuracy. As a result, PAN achieves better utility and better privacy at the same
time! We report extensive experiments on six popular datasets, and demonstrate the
superiority of PAN compared with alternative methods reported in prior work.},
  address    = {New York, NY, USA},
  articleno  = {144},
  doi        = {10.1145/3369816},
  groups     = {First Filtering},
  issue_date = {December 2019},
  numpages   = {18},
  publisher  = {Association for Computing Machinery},
}

@InProceedings{Bernieri2019,
  author    = {Bernieri, Giuseppe and Conti, Mauro and Turrin, Federico},
  booktitle = {Proceedings of the 1st Workshop on Machine Learning on Edge in Sensor Systems},
  title     = {KingFisher: An Industrial Security Framework Based on Variational Autoencoders},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {7–12},
  publisher = {Association for Computing Machinery},
  series    = {SenSys-ML 2019},
  abstract  = {The recent evolution of edge computing favored the Industrial Internet of Things (IIoT)
growth, opening dangerous surfaces of vulnerabilities. In this distributed sensor
system scenario, due to the insecure interactions between Information Technology (IT)
and Operational Technology (OT) networks, cyber-physical threats could lead to destructive
consequences for environments and population safety. To deal with industrial cyber-physical
security, modern anomaly detection systems implement innovative Machine Learning (ML)
techniques. Unfortunately, current solutions still fail to provide an effective prevention
to complex industrial threats.In this paper, we present KingFisher, an Intrusion Detection
System (IDS) framework based on ML. KingFisher is, to the best of our knowledge, the
first solution that looks independently at IT and OT traffic, but also from sensors
deployed to capture side-channel physical processes data (e.g., vibrations, background
noise). Thanks to this feature, KingFisher can detect attacks that other systems would
ignore. As our tests report, the correlation of inferred physical processes status
with OT-network and IT-network data can give insights into suspicious and anomalous
activities targeting industrial networks. For our framework, we use the Variational
Autoencoders (VAEs), an unsupervised neural network model, to categorize data without
a priori knowledge of the dataset. We evaluate the detection capabilities and performances
of KingFisher in a proof of concept simulated industrial scenario under cyber-physical
attacks. Our preliminary results show that KingFisher identifies attacks on both network
and physical layers.},
  doi       = {10.1145/3362743.3362961},
  groups    = {First Filtering},
  isbn      = {9781450370110},
  keywords  = {Machine Learning, Industrial Control System, Security, Cyber-Physical System, Anomaly Detection},
  location  = {New York, NY, USA},
  numpages  = {6},
}

@InProceedings{Beaver2013,
  author    = {Beaver, Justin M. and Symons, Christopher T. and Gillen, Robert E.},
  booktitle = {Proceedings of the Eighth Annual Cyber Security and Information Intelligence Research Workshop},
  title     = {A Learning System for Discriminating Variants of Malicious Network Traffic},
  year      = {2013},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {CSIIRW '13},
  abstract  = {Modern computer network defense systems rely primarily on signature-based intrusion
detection tools, which generate alerts when patterns that are pre-determined to be
malicious are encountered in network data streams. Signatures are created reactively,
and only after in-depth manual analysis of a network intrusion. There is little ability
for signature-based detectors to identify intrusions that are new or even variants
of an existing attack, and little ability to adapt the detectors to the patterns unique
to a network environment. Due to these limitations, the need exists for network intrusion
detection techniques that can more comprehensively address both known and unknown
network-based attacks and can be optimized for the target environment.This work describes
a system that leverages machine learning to provide a network intrusion detection
capability that analyzes behaviors in channels of communication between individual
computers. Using examples of malicious and non-malicious traffic in the target environment,
the system can be trained to discriminate between traffic types. The machine learning
provides insight that would be difficult for a human to explicitly code as a signature
because it evaluates many interdependent metrics simultaneously. With this approach,
zero day detection is possible by focusing on similarity to known traffic types rather
than mining for specific bit patterns or conditions. This also reduces the burden
on organizations to account for all possible attack variant combinations through signatures.
The approach is presented along with results from a third-party evaluation of its
performance.},
  articleno = {23},
  doi       = {10.1145/2459976.2460003},
  groups    = {First Filtering},
  isbn      = {9781450316873},
  keywords  = {computer network defense, machine learning, intrusion detection},
  location  = {Oak Ridge, Tennessee, USA},
  numpages  = {4},
}

@InProceedings{Ivanova2021,
  author    = {Ivanova, Malinka and Rozeva, Anna},
  booktitle = {2021 The 5th International Conference on Machine Learning and Soft Computing},
  title     = {Detection of XSS Attack and Defense of REST Web Service – Machine Learning Perspective},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {22–28},
  publisher = {Association for Computing Machinery},
  series    = {ICMLSC'21},
  abstract  = {The paper presents a machine learning approach for detection of stored XSS attack
and for defense of REST web service. For this purpose, a XML-based REST web service
is developed in JAVA, which is tested and attacked in specially created test-bed simulation
environment, consisting of IntelliJ IDEA environment, Postman and web browser. The
obtained data sets are processed resulting in the selection of 30 out of 171 features
for further treatment. Supervised machine learning classifiers: Random Forest, Random
Tree, Decision Tree and Gradient Boosted Tree are used for the detection of known
attacks and clustering algorithm k-Means for the identification of unknown threats.
The efficiency of implementing machine learning algorithms is evaluated and the results
confirm their high accuracy. In addition fuzzy sets and fuzzy logic theory is utilized
for solving multi-criteria task in support of decision making for web service defense.},
  doi       = {10.1145/3453800.3453805},
  groups    = {First Filtering},
  isbn      = {9781450387613},
  keywords  = {XSS stored attack, fuzzy logic, REST web service defense, machine learning},
  location  = {Da Nang, Viet Nam},
  numpages  = {7},
}

@InProceedings{Song2021,
  author    = {Song, Qun and Tan, Rui and Ren, Chao and Xu, Yan},
  booktitle = {Proceedings of the Twelfth ACM International Conference on Future Energy Systems},
  title     = {Understanding Credibility of Adversarial Examples against Smart Grid: A Case Study for Voltage Stability Assessment},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {95–106},
  publisher = {Association for Computing Machinery},
  series    = {e-Energy '21},
  abstract  = {Stability assessment is an important task for maintaining reliable operations of power
grids. With increased system complexity, deep learning-based stability assessment
approaches are promising to address the shortfalls of the traditional time-domain
simulation-based approaches. However, in the field of computer vision, the deep learning
models are shown vulnerable to adversarial examples. Although this vulnerability has
been noticed by the energy informatics research, the domain-specific analysis on the
requirements imposed for implementing effective adversarial examples is still lacking.
These attack requirements, albeit reasonable in computer vision tasks, can be too
stringent in the context of power grids. In this paper, we systematically investigate
the requirements and discuss the credibility of six representative adversarial example
attacks for a case study of voltage stability assessment for the New England 10-machine
39-bus system. We show that (1) compromising the voltage traces of half of transmission
system buses is a rule of thumb requirement; (2) the universal adversarial perturbations
that are independent of the original clean voltage trajectory have the same credibility
as the widely studied false data injection attacks on power grid state estimation,
while other adversarial example attacks are less credible; (3) the universal perturbations
can be effectively defended with strong adversarial training.},
  doi       = {10.1145/3447555.3464859},
  groups    = {First Filtering},
  isbn      = {9781450383332},
  keywords  = {cybersecurity, machine learning, smart grid, voltage stability assessment, Adversarial example},
  location  = {Virtual Event, Italy},
  numpages  = {12},
}

@InProceedings{Cao2018,
  author    = {Cao, Yinzhi and Yu, Alexander Fangxiao and Aday, Andrew and Stahl, Eric and Merwine, Jon and Yang, Junfeng},
  booktitle = {Proceedings of the 2018 on Asia Conference on Computer and Communications Security},
  title     = {Efficient Repair of Polluted Machine Learning Systems via Causal Unlearning},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {735–747},
  publisher = {Association for Computing Machinery},
  series    = {ASIACCS '18},
  abstract  = {Machine learning systems, though being successful in many real-world applications,
are known to remain prone to errors and attacks. A major attack, called data pollution,
injects maliciously crafted training data samples into the training set, causing the
system to learn an incorrect model and subsequently misclassify testing samples. A
natural solution to a data pollution attack is to remove the polluted data from the
training set and relearn a clean model. Unfortunately, the training set of a real-world
machine learning system can contain millions of samples; it is thus hopeless for an
administrator to manually inspect all of them to weed out the polluted ones.This paper
presents an approach called causal unlearning and a corresponding system called KARMA
to efficiently repair a polluted learning system. KARMA dramatically reduces the manual
effort of administrators by automatically detecting the set of polluted training data
samples with high precision and recall. Evaluation on three learning systems show
that KARMA greatly reduces manual effort for repair, and has high precision and recall.},
  doi       = {10.1145/3196494.3196517},
  groups    = {First Filtering},
  isbn      = {9781450355766},
  keywords  = {causality, machine unlearning, data pollution attacks},
  location  = {Incheon, Republic of Korea},
  numpages  = {13},
}

@InProceedings{Wang2021,
  author    = {Wang, Tianhao and Kerschbaum, Florian},
  booktitle = {Proceedings of the Web Conference 2021},
  title     = {RIGA: Covert and Robust White-Box Watermarking of Deep Neural Networks},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {993–1004},
  publisher = {Association for Computing Machinery},
  series    = {WWW '21},
  abstract  = {Watermarking of deep neural networks (DNN) can enable their tracing once released
by a data owner to an online platform. In this paper, we generalize white-box watermarking
algorithms for DNNs, where the data owner needs white-box access to the model to extract
the watermark. White-box watermarking algorithms have the advantage that they do not
impact the accuracy of the watermarked model. We propose Robust whIte-box GAn watermarking
(RIGA), a novel white-box watermarking algorithm that uses adversarial training. Our
extensive experiments demonstrate that the proposed watermarking algorithm not only
does not impact accuracy, but also significantly improves the covertness and robustness
over the current state-of-art.},
  doi       = {10.1145/3442381.3450000},
  groups    = {First Filtering},
  isbn      = {9781450383127},
  location  = {Ljubljana, Slovenia},
  numpages  = {12},
}

@InProceedings{Yan2020,
  author    = {Yan, Wenqing and Hylamia, Sam and Voigt, Thiemo and Rohner, Christian},
  booktitle = {Proceedings of the 6th ACM Workshop on Wearable Systems and Applications},
  title     = {PHY-IDS: A Physical-Layer Spoofing Attack Detection System for Wearable Devices},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {1–6},
  publisher = {Association for Computing Machinery},
  series    = {WearSys '20},
  abstract  = {In modern connected healthcare applications, wearable devices supporting real-time
monitoring and diagnosis have become mainstream. However, wearable systems are exposed
to massive cyberattacks that threaten not only data security but also human safety
and life. One of the fundamental security threats is device impersonation. We therefore
propose PHY-IDS; a lightweight real-time detection system that captures spoofing attacks
leveraging on body motions. Our system utilizes time series of physical layer features
and builds on the fact that it is non-trivial to inject malicious frames that are
indistinguishable with legitimate ones. With the help of statistical learning, our
system characterizes the signal behavior and flags deviations as anomalies. We experimentally
evaluate PHY-IDS's performance using bodyworn devices in real attack scenarios. For
four types of attackers with increasing knowledge of the deployed detection system,
the results show that PHY-IDS detects naive attackers with high accuracy above 99.8%
and maintains good accuracy for stronger attackers at a range from 81.0% to 98.9%.},
  doi       = {10.1145/3396870.3400010},
  groups    = {First Filtering},
  isbn      = {9781450380133},
  keywords  = {wearables, time series analysis, spoofing attacks, physical-layer security, machine learning},
  location  = {Toronto, Ontario, Canada},
  numpages  = {6},
}

@InProceedings{Haghighat2018,
  author    = {Haghighat, Mohammad Hashem and Li, Jun},
  booktitle = {Proceedings of the 8th International Conference on Communication and Network Security},
  title     = {Edmund: Entropy Based Attack Detection and Mitigation Engine Using Netflow Data},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {1–6},
  publisher = {Association for Computing Machinery},
  series    = {ICCNS 2018},
  abstract  = {Dozens of signature and anomaly based solutions have been proposed to detect malicious
activities in computer networks. However, the number of successful attacks are increasing
every day. In this paper, we developed a novel entropy based technique, called Edmund,
to detect and mitigate Network attacks. While analyzing full payload network traffic
was not recommended due to users' privacy, Edmund used netflow data to detect abnormal
behavior.The experimental results showed that Edmund was able to highly accurate detect
(around 95%) different application, transport, and network layers attacks. It could
identify more than 100K malicious flows raised by 1168 different attackers in our
campus. Identifying the attackers, is a great feature, which enables the network administrators
to mitigate DDoS effects during the attack time.},
  doi       = {10.1145/3290480.3290484},
  groups    = {First Filtering},
  isbn      = {9781450365673},
  keywords  = {Network Attacks, Malicious Flows, Entropy, Attack Detection and Mitigation},
  location  = {Qingdao, China},
  numpages  = {6},
}

@InProceedings{Shakya2015,
  author    = {Shakya, Shobhit and Zhang, Jian},
  booktitle = {Proceedings of the 2015 ACM International Workshop on International Workshop on Security and Privacy Analytics},
  title     = {Towards Better Semi-Supervised Classification of Malicious Software},
  year      = {2015},
  address   = {New York, NY, USA},
  pages     = {27–33},
  publisher = {Association for Computing Machinery},
  series    = {IWSPA '15},
  abstract  = {Due to the large number of malicious software (malware) and the large variety among
them, automated detection and analysis using machine learning techniques have become
more and moreimportant for network and computer security.An often encountered scenario
in these security applications is that training examples are scarce but unlabeled
data are abundant. Semi-supervised learning where both labeled and unlabeled data
are used to learn a good model quickly is a natural choice under such condition.We
investigate semi-supervised classification for malware categorization.We observed
that malware data have specific characteristics and that they are noisy. Off-the-shelf
semi-supervised learning may not work well in this case. We proposed a semi supervised
approach that addresses the problems with malware data and can provide better classification.
We conducted a set of experiments to test and compare our method to others. The experimental
results show that semi-supervised classification is a promising direction for malware
classification. Our method achieved more than 90% accuracy when there were only a
few number of training examples. The results also indicates that modifications are
needed to make semi-supervised learning work with malware data. Otherwise, semi-supervised
classification may perform worse than classifiers trained on only the labeled data.},
  doi       = {10.1145/2713579.2713587},
  groups    = {First Filtering},
  isbn      = {9781450333412},
  keywords  = {malware classification, graph spectral, machine learning, graph-based semi-supervised learning},
  location  = {San Antonio, Texas, USA},
  numpages  = {7},
}

@InProceedings{Foruhandeh2019,
  author    = {Foruhandeh, Mahsa and Man, Yanmao and Gerdes, Ryan and Li, Ming and Chantem, Thidapat},
  booktitle = {Proceedings of the 35th Annual Computer Security Applications Conference},
  title     = {SIMPLE: Single-Frame Based Physical Layer Identification for Intrusion Detection and Prevention on in-Vehicle Networks},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {229–244},
  publisher = {Association for Computing Machinery},
  series    = {ACSAC '19},
  abstract  = {The Controller Area Network (CAN) is a bus standard commonly used in the automotive
industry for connecting Electronic Control Units (ECUs) within a vehicle. The broadcast
nature of this protocol, along with the lack of authentication or strong integrity
guarantees for frames, allows for arbitrary data injection/modification and impersonation
of the ECUs. While mitigation strategies have been proposed to counter these attacks,
high implementation costs or violation of backward compatibility hinder their deployment.
In this work, we first examine the shortcomings of state-of-the-art CAN intrusion
detection and identification systems that rely on multiple frames to detect misbehavior
and attribute it to a particular ECU, and show that they are vulnerable to a Hill-Climbing-style
attack. Then we propose SIMPLE, a real-time intrusion detection and identification
system that exploits physical layer features of ECUs, which would not only allow an
attack to be detected using a single frame but also be effectively nullified. SIMPLE
has low computational and data acquisition costs, and its efficacy is demonstrated
by both in-lab experiments with automotive-grade CAN transceivers as well as in-vehicle
experiments, where average equal error rates of close to 0% and 0.8985% are achieved,
respectively.},
  doi       = {10.1145/3359789.3359834},
  groups    = {First Filtering},
  isbn      = {9781450376280},
  keywords  = {electronic control units, physical layer identification, controller area networks, hill-climbing attacks},
  location  = {San Juan, Puerto Rico, USA},
  numpages  = {16},
}

@Article{Angiulli2018,
  author     = {Angiulli, Fabrizio and Argento, Luciano and Furfaro, Angelo},
  journal    = {ACM Trans. Internet Technol.},
  title      = {Exploiting Content Spatial Distribution to Improve Detection of Intrusions},
  year       = {2018},
  issn       = {1533-5399},
  month      = jan,
  number     = {2},
  volume     = {18},
  abstract   = {We present PCkAD, a novel semisupervised anomaly-based IDS (Intrusion Detection System)
technique, detecting application-level content-based attacks. Its peculiarity is to
learn legitimate payloads by splitting packets into chunks and determining the within-packet
distribution of n-grams. This strategy is resistant to evasion techniques as blending.
We prove that finding the right legitimate content is NP-hard in the presence of chunks.
Moreover, it improves the false-positive rate for a given detection rate with respect
to the case where the spatial information is not considered. Comparison with well-known
IDSs using n-grams highlights that PCkAD achieves state-of-the-art performances.},
  address    = {New York, NY, USA},
  articleno  = {25},
  doi        = {10.1145/3143422},
  groups     = {First Filtering},
  issue_date = {March 2018},
  keywords   = {semisupervised learning, Intrusion detection systems, anomaly detection, n-grams},
  numpages   = {21},
  publisher  = {Association for Computing Machinery},
}

@InProceedings{Anton2019,
  author    = {Anton, Simon D. Duque and Fraunholz, Daniel and Schotten, Hans Dieter},
  booktitle = {Proceedings of the 14th International Conference on Availability, Reliability and Security},
  title     = {Using Temporal and Topological Features for Intrusion Detection in Operational Networks},
  year      = {2019},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ARES '19},
  abstract  = {Until two decades ago, industrial networks were deemed secure due to physical separation
from public networks. An abundance of successful attacks proved that assumption wrong.
Intrusion detection solutions for industrial application need to meet certain requirements
that differ from home- and office-environments, such as working without feedback to
the process and compatibility with legacy systems. Industrial systems are commonly
used for several decades, updates are often difficult and expensive. Furthermore,
most industrial protocols do not have inherent authentication or encryption mechanisms,
allowing for easy lateral movement of an intruder once the perimeter is breached.
In this work, an algorithm for motif discovery in time series, Matrix Profiles, is
used to detect outliers in the timing behaviour of an industrial process. This process
was monitored in an experimental environment, containing ground truth labels after
attacks were performed. Furthermore, the graph representations of a different industrial
data set that has been emulated are used to detect malicious activities. These activities
can be derived from anomalous communication patterns, represented as edges in the
graph. Finally, an integration concept for both methods is proposed.},
  articleno = {99},
  doi       = {10.1145/3339252.3341476},
  groups    = {First Filtering},
  isbn      = {9781450371643},
  keywords  = {Time Series, Machine Learning, IT-Security, Graph, Industrial Process},
  location  = {Canterbury, CA, United Kingdom},
  numpages  = {9},
}

@InProceedings{Li2020,
  author    = {Li, Ang and Duan, Yixiao and Yang, Huanrui and Chen, Yiran and Yang, Jianlei},
  booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
  title     = {TIPRDC: Task-Independent Privacy-Respecting Data Crowdsourcing Framework for Deep Learning with Anonymized Intermediate Representations},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {824–832},
  publisher = {Association for Computing Machinery},
  series    = {KDD '20},
  abstract  = {The success of deep learning partially benefits from the availability of various large-scale
datasets. These datasets are often crowdsourced from individual users and contain
private information like gender, age, etc. The emerging privacy concerns from users
on data sharing hinder the generation or use of crowdsourcing datasets and lead to
hunger of training data for new deep learning applications. One naive solution is
to pre-process the raw data to extract features at the user-side, and then only the
extracted features will be sent to the data collector. Unfortunately, attackers can
still exploit these extracted features to train an adversary classifier to infer private
attributes. Some prior arts leveraged game theory to protect private attributes. However,
these defenses are designed for known primary learning tasks, the extracted features
work poorly for unknown learning tasks. To tackle the case where the learning task
may be unknown or changing, we present TIPRDC, a task-independent privacy-respecting
data crowdsourcing framework with anonymized intermediate representation. The goal
of this framework is to learn a feature extractor that can hide the privacy information
from the intermediate representations; while maximally retaining the original information
embedded in the raw data for the data collector to accomplish unknown learning tasks.
We design a hybrid training method to learn the anonymized intermediate representation:
(1) an adversarial training process for hiding private information from features;
(2) maximally retain original information using a neural-network-based mutual information
estimator. We extensively evaluate TIPRDC and compare it with existing methods using
two image datasets and one text dataset. Our results show that TIPRDC substantially
outperforms other existing methods. Our work is the first task-independent privacy-respecting
data crowdsourcing framework.},
  doi       = {10.1145/3394486.3403125},
  groups    = {First Filtering},
  isbn      = {9781450379984},
  keywords  = {anonymized intermediate representations, deep learning, privacy-respecting data crowdsourcing},
  location  = {Virtual Event, CA, USA},
  numpages  = {9},
}

@InProceedings{Baarzi2020,
  author    = {Baarzi, Ataollah Fatahi and Kesidis, George and Fleck, Dan and Stavrou, Angelos},
  booktitle = {Proceedings of the 13th European Workshop on Systems Security},
  title     = {Microservices Made Attack-Resilient Using Unsupervised Service Fissioning},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {31–36},
  publisher = {Association for Computing Machinery},
  series    = {EuroSec '20},
  abstract  = {Application-layer DoS attacks are increasing as the number of cloud-deployed microservice
applications is increasing. The attacker tries to exhaust computing resources and
brings the nominal applications down by exploiting application-layer vulnerabilities.
As traditional solutions for volumetric DoS attacks will not be able to handle these
attacks, new approaches are required to detect and respond to application-layer attacks.
In this work, we propose an unsupervised, non-intrusive and application-agnostic detection
approach and fissioning based response mechanism. We built our prototype on Kubernetes,
the state of the art container orchestrator for microservices, and show its effectiveness
through experimental evaluation. Our preliminary results show that using our detection
and defense mechanism, we are able to a) efficiently identify the attacks and b) reduce
the effect of the attack on legitimate users by 3\texttimes{} compared to a case where there
is no detection/defense in place.},
  doi       = {10.1145/3380786.3391395},
  groups    = {First Filtering},
  isbn      = {9781450375238},
  keywords  = {cloud computing, microservices, systems security, DDoS attack},
  location  = {Heraklion, Greece},
  numpages  = {6},
}

@Article{Zoppi2021,
  author     = {Zoppi, Tommaso and Ceccarelli, Andrea and Capecchi, Tommaso and Bondavalli, Andrea},
  journal    = {ACM/IMS Trans. Data Sci.},
  title      = {Unsupervised Anomaly Detectors to Detect Intrusions in the Current Threat Landscape},
  year       = {2021},
  issn       = {2691-1922},
  month      = apr,
  number     = {2},
  volume     = {2},
  abstract   = {Anomaly detection aims at identifying unexpected fluctuations in the expected behavior
of a given system. It is acknowledged as a reliable answer to the identification of
zero-day attacks to such extent, several ML algorithms that suit for binary classification
have been proposed throughout years. However, the experimental comparison of a wide
pool of unsupervised algorithms for anomaly-based intrusion detection against a comprehensive
set of attacks datasets was not investigated yet. To fill such gap, we exercise 17
unsupervised anomaly detection algorithms on 11 attack datasets. Results allow elaborating
on a wide range of arguments, from the behavior of the individual algorithm to the
suitability of the datasets to anomaly detection. We conclude that algorithms as Isolation
Forests, One-Class Support Vector Machines, and Self-Organizing Maps are more effective
than their counterparts for intrusion detection, while clustering algorithms represent
a good alternative due to their low computational complexity. Further, we detail how
attacks with unstable, distributed, or non-repeatable behavior such as Fuzzing, Worms,
and Botnets are more difficult to detect. Ultimately, we digress on capabilities of
algorithms in detecting anomalies generated by a wide pool of unknown attacks, showing
that achieved metric scores do not vary with respect to identifying single attacks.},
  address    = {New York, NY, USA},
  articleno  = {7},
  doi        = {10.1145/3441140},
  groups     = {First Filtering},
  issue_date = {April 2021},
  keywords   = {unsupervised algorithms, attacks datasets, Anomaly detection, intrusion detection, comparison, machine learning},
  numpages   = {26},
  publisher  = {Association for Computing Machinery},
}

@InProceedings{He2017,
  author    = {He, Liang and Li, Zhixiang and Shen, Chao},
  booktitle = {Proceedings of the ACM Turing 50th Celebration Conference - China},
  title     = {Performance Evaluation of Anomaly-Detection Algorithm for Keystroke-Typing Based Insider Detection},
  year      = {2017},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ACM TUR-C '17},
  abstract  = {Keystroke dynamics is the process to identify or authenticate individuals based on
the typing rhythm behaviors. There are many classifications proposed to check the
user's legitimacy, and therefore we should make it clear how they perform in order
to confirm promising research direction. Nevertheless, these researches provide experiments
in different situations such as datasets, conditions and methodologies as well. This
paper aims to benchmark the algorithms in the same dataset and feature in order to
measure the performance on an equal level. Using dataset containing 51 subjects' typing
rhythm, we implemented and evaluated 13 classifiers measured by F1-measure. We also
develop a way to process the typing data, and test it on these algorithms. Considering
the case that the model should reject outlander, we test the algorithms on open set.
The top-performing classifier achieves F1-measure rates 0.92 when using 50 subjects'
typing normalized data to train and the remaining one to test. The results, along
with the normalization methodology, constitute a benchmark for comparing classifiers
and measuring performance of keystroke dynamics for insider detection.},
  articleno = {32},
  doi       = {10.1145/3063955.3063987},
  groups    = {First Filtering},
  isbn      = {9781450348737},
  keywords  = {F1-measure, normalization, insider identification, keystroke dynamics},
  location  = {Shanghai, China},
  numpages  = {7},
}

@InProceedings{Speicher2019,
  author    = {Speicher, Patrick and Steinmetz, Marcel and Hoffmann, J\"{o}rg and Backes, Michael and K\"{u}nnemann, Robert},
  booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
  title     = {Towards Automated Network Mitigation Analysis},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {1971–1978},
  publisher = {Association for Computing Machinery},
  series    = {SAC '19},
  abstract  = {Penetration testing is a well-established practical concept for the identification
of potentially exploitable security weaknesses and an important component of a security
audit. Providing a holistic security assessment for networks consisting of several
hundreds hosts is hardly feasible though without some sort of mechanization. Mitigation,
prioritizing counter-measures subject to a given budget, currently lacks a solid theoretical
understanding and is hence more art than science. In this work, we propose the first
approach for conducting comprehensive what-if analyses in order to reason about mitigation
in a conceptually well-founded manner. To evaluate and compare mitigation strategies,
we use simulated penetration testing, i.e., automated attack-finding, based on a network
model to which a subset of a given set of mitigation actions, e.g., changes to the
network topology, system updates, configuration changes etc. is applied. Using Stackelberg
planning, we determine optimal combinations that minimize the maximal attacker success
(similar to a Stackelberg game), and thus provide a well-founded basis for a holistic
mitigation strategy. We show that these Stackelberg planning models can largely be
derived from network scan, public vulnerability databases and manual inspection with
various degrees of automation and detail, and we simulate mitigation analysis on networks
of different size and vulnerability.},
  doi       = {10.1145/3297280.3297473},
  groups    = {First Filtering},
  isbn      = {9781450359337},
  keywords  = {planning, network security, simulated penetration testing},
  location  = {Limassol, Cyprus},
  numpages  = {8},
}

@InProceedings{ElRabih2019,
  author    = {ElRabih, Diana},
  booktitle = {Proceedings of the 2019 2nd International Conference on Data Storage and Data Engineering},
  title     = {Cooperative and Distributed Intrusion Detection Using BigData},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {54–58},
  publisher = {Association for Computing Machinery},
  series    = {DSDE 2019},
  abstract  = {Internet infrastructure is vulnerable to various attacks, then security and privacy
are the key issues for Internet applications. Internet requires various security solutions
where the communication is secured with confidentiality, integrity, and authentication
services. Therefore, the challenge of implementing secure and protected communication
in the Internet network must be addressed. The Internet network is secured with encryption
and authentication, but it cannot be protected and secured against cyber-attacks.
Hence, an Intrusion Detection System IDS is needed. Analyzing Internet network flows,
logs, and system events has been used for intrusion detection. Big Data analytics
can correlate multiple information sources into a coherent view, identify anomalies
and suspicious activities, and finally achieve effective and efficient intrusion detection.
One solution is to have an IDS that supervises the situation for all the computers
in the Internet and makes decision regarding possible attacks. This method is not
effective due to large scale of Internet and high speed of Internet. This problem
is resolved in this paper by proposing an approach of a distributed intrusion detection
system that is based on cooperative agents (sensors) using Big Data. Then agents (sensors)
in our approach work together in a distributed and cooperative manner and these agents
(sensors) perform data collection and data analysis using Big Data technology to detect
intrusion in the Internet.},
  doi       = {10.1145/3354153.3354157},
  groups    = {First Filtering},
  isbn      = {9781450372169},
  keywords  = {Internet, BigData, Intrusion Detection},
  location  = {Jeju, Republic of Korea},
  numpages  = {5},
}

@InProceedings{Zhu2020,
  author    = {Zhu, Shitong and Li, Shasha and Wang, Zhongjie and Chen, Xun and Qian, Zhiyun and Krishnamurthy, Srikanth V. and Chan, Kevin S. and Swami, Ananthram},
  booktitle = {Proceedings of the 16th International Conference on Emerging Networking EXperiments and Technologies},
  title     = {You Do (Not) Belong Here: Detecting DPI Evasion Attacks with Context Learning},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {183–197},
  publisher = {Association for Computing Machinery},
  series    = {CoNEXT '20},
  abstract  = {As Deep Packet Inspection (DPI) middleboxes become increasingly popular, a spectrum
of adversarial attacks have emerged with the goal of evading such middleboxes. Many
of these attacks exploit discrepancies between the middlebox network protocol implementations,
and the more rigorous/complete versions implemented at end hosts. These evasion attacks
largely involve subtle manipulations of packets to cause different behaviours at DPI
and end hosts, to cloak malicious network traffic that is otherwise detectable. With
recent automated discovery, it has become prohibitively challenging to manually curate
rules for detecting these manipulations. In this work, we propose CLAP, the first
fully-automated, unsupervised ML solution to accurately detect and localize DPI evasion
attacks. By learning what we call the packet context, which essentially captures inter-relationships
across both (1) different packets in a connection; and (2) different header fields
within each packet, from benign traffic traces only, CLAP can detect and pinpoint
packets that violate the benign packet contexts (which are the ones that are specially
crafted for evasion purposes). Our evaluations with 73 state-of-the-art DPI evasion
attacks show that CLAP achieves an Area Under the Receiver Operating Characteristic
Curve (AUCROC) of <u>0.963</u>, an Equal Error Rate (EER) of only <u>0.061</u> in
detection, and an accuracy of <u>94.6%</u> in localization. These results suggest
that CLAP can be a promising tool for thwarting DPI evasion attacks.},
  doi       = {10.1145/3386367.3431311},
  groups    = {First Filtering},
  isbn      = {9781450379489},
  location  = {Barcelona, Spain},
  numpages  = {15},
}

@InProceedings{Kashyap2012,
  author    = {Kashyap, Hirak Jyoti and Bhattacharyya, D. K.},
  booktitle = {Proceedings of the Second International Conference on Computational Science, Engineering and Information Technology},
  title     = {A DDoS Attack Detection Mechanism Based on Protocol Specific Traffic Features},
  year      = {2012},
  address   = {New York, NY, USA},
  pages     = {194–200},
  publisher = {Association for Computing Machinery},
  series    = {CCSEIT '12},
  abstract  = {This paper focuses on finding the most relevant and smallest possible subset of features
for DDoS attack detection. A generic architecture of victim end DDoS defense mechanisms
is presented and a near real time anomaly detection mechanism with high detection
accuracy is introduced. The method is evaluated based on two real time and one benchmark
dataset.},
  doi       = {10.1145/2393216.2393249},
  groups    = {First Filtering},
  isbn      = {9781450313100},
  keywords  = {linear correlation, dimensionality reduction, intrusion data, LCFS},
  location  = {Coimbatore UNK, India},
  numpages  = {7},
}

@Article{Alharbi2021,
  author     = {Alharbi, Ahmed and Dong, Hai and Yi, Xun and Tari, Zahir and Khalil, Ibrahim},
  journal    = {ACM Comput. Surv.},
  title      = {Social Media Identity Deception Detection: A Survey},
  year       = {2021},
  issn       = {0360-0300},
  month      = apr,
  number     = {3},
  volume     = {54},
  abstract   = {Social media have been growing rapidly and become essential elements of many people’s
lives. Meanwhile, social media have also come to be a popular source for identity
deception. Many social media identity deception cases have arisen over the past few
years. Recent studies have been conducted to prevent and detect identity deception.
This survey analyzes various identity deception attacks, which can be categorized
into fake profile, identity theft, and identity cloning. This survey provides a detailed
review of social media identity deception detection techniques. It also identifies
primary research challenges and issues in the existing detection techniques. This
article is expected to benefit both researchers and social media providers.},
  address    = {New York, NY, USA},
  articleno  = {69},
  doi        = {10.1145/3446372},
  groups     = {First Filtering},
  issue_date = {June 2021},
  keywords   = {sockpuppet, social botnet, Sybil, Identity deception, fake profile, detection techniques, identity cloning, identity theft},
  numpages   = {35},
  publisher  = {Association for Computing Machinery},
}

@InProceedings{Vishnu2014,
  author    = {Vishnu, B. A. and Jevitha, K. P.},
  booktitle = {Proceedings of the 2014 International Conference on Interdisciplinary Advances in Applied Computing},
  title     = {Prediction of Cross-Site Scripting Attack Using Machine Learning Algorithms},
  year      = {2014},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ICONIAAC '14},
  abstract  = {Dynamic web pages are widely used by web applications to provide better user experience
and to attract more web users. The web applications use the client side and server
side scripts to provide dynamic behavior to the web pages. Cross-Site Scripting (XSS)
attack uses malicious scripts and links injected into the trusted web pages to steal
sensitive data from the victims. In this paper, we present the experimental results
obtained using three machine learning algorithms (Na\"{\i}ve Bayes, Support Vector Machine
and J48 Decision Tree) for the prediction of Cross-site scripting attack. This is
done using the features based on normal and malicious URLs and JavaScript. J48 gave
better results than Na\"{\i}ve Bayes and Support Vector Machine based on the features extracted
from URL and Java Script code. All the algorithms gave comparatively better results
with discretized attributes but noticeable difference in performance was seen only
in the case of SVM.},
  articleno = {55},
  doi       = {10.1145/2660859.2660969},
  groups    = {First Filtering},
  isbn      = {9781450329088},
  keywords  = {Machine learning, Web application security, Cross Site Scripting (XSS)},
  location  = {Amritapuri, India},
  numpages  = {5},
}

@InProceedings{Liu2017,
  author    = {Liu, Daiping and Li, Zhou and Du, Kun and Wang, Haining and Liu, Baojun and Duan, Haixin},
  booktitle = {Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {Don't Let One Rotten Apple Spoil the Whole Barrel: Towards Automated Detection of Shadowed Domains},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {537–552},
  publisher = {Association for Computing Machinery},
  series    = {CCS '17},
  abstract  = {Domain names have been exploited for illicit online activities for decades. In the
past, miscreants mostly registered new domains for their attacks. However, the domains
registered for malicious purposes can be deterred by existing reputation and blacklisting
systems. In response to the arms race, miscreants have recently adopted a new strategy,
called domain shadowing, to build their attack infrastructures. Specifically, instead
of registering new domains, miscreants are beginning to compromise legitimate ones
and spawn malicious subdomains under them. This has rendered almost all existing countermeasures
ineffective and fragile because subdomains inherit the trust of their apex domains,
and attackers can virtually spawn an infinite number of shadowed domains.In this paper,
we conduct the first study to understand and detect this emerging threat. Bootstrapped
with a set of manually confirmed shadowed domains, we identify a set of novel features
that uniquely characterize domain shadowing by analyzing the deviation from their
apex domains and the correlation among different apex domains. Building upon these
features, we train a classifier and apply it to detect shadowed domains on the daily
feeds of VirusTotal, a large open security scanning service. Our study highlights
domain shadowing as an increasingly rampant threat. Moreover, while previously confirmed
domain shadowing campaigns are exclusively involved in exploit kits, we reveal that
they are also widely exploited for phishing attacks. Finally, we observe that instead
of algorithmically generating subdomain names, several domain shadowing cases exploit
the wildcard DNS records.},
  doi       = {10.1145/3133956.3134049},
  groups    = {First Filtering},
  isbn      = {9781450349468},
  keywords  = {domain hijacking, domain shadowing, dns},
  location  = {Dallas, Texas, USA},
  numpages  = {16},
}

@Misc{kazdagli2017exploiting,
  author        = {Mkhail Kazdagli and Constantine Caramanis and Sanjay Shakkottai and Mohit Tiwari},
  title         = {Exploiting Latent Attack Semantics for Intelligent Malware Detection},
  year          = {2017},
  archiveprefix = {arXiv},
  eprint        = {1708.01864},
  groups        = {First Filtering},
  primaryclass  = {cs.CR},
}

@Misc{xiao2019generating,
  author        = {Chaowei Xiao and Bo Li and Jun-Yan Zhu and Warren He and Mingyan Liu and Dawn Song},
  title         = {Generating Adversarial Examples with Adversarial Networks},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1801.02610},
  groups        = {First Filtering},
  primaryclass  = {cs.CR},
}

@Misc{santhanam2018defending,
  author        = {Gokula Krishnan Santhanam and Paulina Grnarova},
  title         = {Defending Against Adversarial Attacks by Leveraging an Entire GAN},
  year          = {2018},
  archiveprefix = {arXiv},
  eprint        = {1805.10652},
  groups        = {First Filtering},
  primaryclass  = {stat.ML},
}

@Misc{lin2021idsgan,
  author        = {Zilong Lin and Yong Shi and Zhi Xue},
  title         = {IDSGAN: Generative Adversarial Networks for Attack Generation against Intrusion Detection},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {1809.02077},
  groups        = {First Filtering},
  primaryclass  = {cs.CR},
}

@Misc{biggio2018data,
  author        = {Battista Biggio and Ignazio Pillai and Samuel Rota Bulò and Davide Ariu and Marcello Pelillo and Fabio Roli},
  title         = {Is Data Clustering in Adversarial Settings Secure?},
  year          = {2018},
  archiveprefix = {arXiv},
  eprint        = {1811.09982},
  groups        = {First Filtering},
  primaryclass  = {cs.LG},
}

@Misc{kokaljfilipovic2019mitigation,
  author        = {Silvija Kokalj-Filipovic and Rob Miller and Nicholas Chang and Chi Leung Lau},
  title         = {Mitigation of Adversarial Examples in RF Deep Classifiers Utilizing AutoEncoder Pre-training},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1902.08034},
  groups        = {First Filtering},
  primaryclass  = {eess.SP},
}

@Misc{sadeghi2019physical,
  author        = {Meysam Sadeghi and Erik G. Larsson},
  title         = {Physical Adversarial Attacks Against End-to-End Autoencoder Communication Systems},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1902.08391},
  groups        = {First Filtering},
  primaryclass  = {cs.IT},
}

@Misc{duan2019disentangled,
  author        = {Zhenyu Duan and Martin Renqiang Min and Li Erran Li and Mingbo Cai and Yi Xu and Bingbing Ni},
  title         = {Disentangled Deep Autoencoding Regularization for Robust Image Classification},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1902.11134},
  groups        = {First Filtering},
  primaryclass  = {cs.CV},
}

@Misc{wang2020atgan,
  author        = {Xiaosen Wang and Kun He and Chuanbiao Song and Liwei Wang and John E. Hopcroft},
  title         = {AT-GAN: An Adversarial Generator Model for Non-constrained Adversarial Examples},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {1904.07793},
  groups        = {First Filtering},
  primaryclass  = {cs.CV},
}

@Misc{willetts2021improving,
  author        = {Matthew Willetts and Alexander Camuto and Tom Rainforth and Stephen Roberts and Chris Holmes},
  title         = {Improving VAEs' Robustness to Adversarial Attack},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {1906.00230},
  groups        = {First Filtering},
  primaryclass  = {stat.ML},
}

@Misc{hilprecht2019reconstruction,
  author        = {Benjamin Hilprecht and Martin Härterich and Daniel Bernau},
  title         = {Reconstruction and Membership Inference Attacks against Generative Models},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1906.03006},
  groups        = {First Filtering},
  primaryclass  = {cs.CR},
}

@Misc{taheri2020defending,
  author        = {Rahim Taheri and Reza Javidan and Mohammad Shojafar and Zahra Pooranian and Ali Miri and Mauro Conti},
  title         = {On Defending Against Label Flipping Attacks on Malware Detection Systems},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {1908.04473},
  groups        = {First Filtering},
  primaryclass  = {cs.LG},
}

@Misc{deb2019advfaces,
  author        = {Debayan Deb and Jianbang Zhang and Anil K. Jain},
  title         = {AdvFaces: Adversarial Face Synthesis},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1908.05008},
  groups        = {First Filtering},
  primaryclass  = {cs.CV},
}

@Misc{joe2019learning,
  author        = {Byunggill Joe and Sung Ju Hwang and Insik Shin},
  title         = {Learning to Disentangle Robust and Vulnerable Features for Adversarial Detection},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1909.04311},
  groups        = {First Filtering},
  primaryclass  = {cs.LG},
}

@Misc{shen2019advspade,
  author        = {Guangyu Shen and Chengzhi Mao and Junfeng Yang and Baishakhi Ray},
  title         = {AdvSPADE: Realistic Unrestricted Attacks for Semantic Segmentation},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1910.02354},
  groups        = {First Filtering},
  primaryclass  = {cs.CV},
}

@Misc{schreyer2019adversarial,
  author        = {Marco Schreyer and Timur Sattarov and Bernd Reimer and Damian Borth},
  title         = {Adversarial Learning of Deepfakes in Accounting},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1910.03810},
  groups        = {First Filtering},
  primaryclass  = {cs.LG},
}

@Misc{rozenberg2020madnet,
  author        = {Shai Rozenberg and Gal Elidan and Ran El-Yaniv},
  title         = {MadNet: Using a MAD Optimization for Defending Against Adversarial Attacks},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {1911.00870},
  groups        = {First Filtering},
  primaryclass  = {cs.LG},
}

@Misc{zhang2020secret,
  author        = {Yuheng Zhang and Ruoxi Jia and Hengzhi Pei and Wenxiao Wang and Bo Li and Dawn Song},
  title         = {The Secret Revealer: Generative Model-Inversion Attacks Against Deep Neural Networks},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {1911.07135},
  groups        = {First Filtering},
  primaryclass  = {cs.LG},
}

@Misc{msika2019sigma,
  author        = {Simon Msika and Alejandro Quintero and Foutse Khomh},
  title         = {SIGMA : Strengthening IDS with GAN and Metaheuristics Attacks},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1912.09303},
  groups        = {First Filtering},
  primaryclass  = {cs.CR},
}

@Misc{wang2020t3,
  author        = {Boxin Wang and Hengzhi Pei and Boyuan Pan and Qian Chen and Shuohang Wang and Bo Li},
  title         = {T3: Tree-Autoencoder Constrained Adversarial Text Generation for Targeted Attack},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {1912.10375},
  groups        = {First Filtering},
  primaryclass  = {cs.CL},
}

@Article{Wang_2020,
  author    = {Wang, Shuo and Nepal, Surya and Rudolph, Carsten and Grobler, Marthie and Chen, Shangyu and Chen, Tianle},
  journal   = {IEEE Transactions on Services Computing},
  title     = {Backdoor Attacks against Transfer Learning with Pre-trained Deep Learning Models},
  year      = {2020},
  issn      = {2372-0204},
  pages     = {1–1},
  doi       = {10.1109/tsc.2020.3000900},
  groups    = {First Filtering},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  url       = {http://dx.doi.org/10.1109/TSC.2020.3000900},
}

@Misc{he2020temporal,
  author        = {Ziwen He and Wei Wang and Jing Dong and Tieniu Tan},
  title         = {Temporal Sparse Adversarial Attack on Sequence-based Gait Recognition},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2002.09674},
  groups        = {First Filtering},
  primaryclass  = {cs.CV},
}

@Misc{soremekun2021exposing,
  author        = {Ezekiel Soremekun and Sakshi Udeshi and Sudipta Chattopadhyay},
  title         = {Exposing Backdoors in Robust Machine Learning Models},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2003.00865},
  groups        = {First Filtering},
  primaryclass  = {cs.CV},
}

@Misc{zhou2020adversarial,
  author        = {Mingyi Zhou and Jing Wu and Yipeng Liu and Xiaolin Huang and Shuaicheng Liu and Xiang Zhang and Ce Zhu},
  title         = {Adversarial Imitation Attack},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2003.12760},
  groups        = {First Filtering},
  primaryclass  = {cs.CR},
}

@Misc{shahriar2020gids,
  author        = {Md Hasan Shahriar and Nur Imtiazul Haque and Mohammad Ashiqur Rahman and Miguel Alonso Jr au2},
  title         = {G-IDS: Generative Adversarial Networks Assisted Intrusion Detection System},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2006.00676},
  groups        = {First Filtering},
  primaryclass  = {cs.CR},
}

@Misc{zhang2020defensevgae,
  author        = {Ao Zhang and Jinwen Ma},
  title         = {DefenseVGAE: Defending against Adversarial Attacks on Graph Data via a Variational Graph Autoencoder},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2006.08900},
  groups        = {First Filtering},
  primaryclass  = {cs.LG},
}

@Misc{gittings2020vaxanet,
  author        = {T. Gittings and S. Schneider and J. Collomosse},
  title         = {Vax-a-Net: Training-time Defence Against Adversarial Patch Attacks},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2009.08194},
  groups        = {First Filtering},
  primaryclass  = {cs.CV},
}

@Misc{chan2020poison,
  author        = {Alvin Chan and Yi Tay and Yew-Soon Ong and Aston Zhang},
  title         = {Poison Attacks against Text Datasets with Conditional Adversarially Regularized Autoencoder},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2010.02684},
  groups        = {First Filtering},
  primaryclass  = {cs.CL},
}

@Misc{dai2021evasion,
  author        = {Jiazhu Dai and Siwei Xiong},
  title         = {An Evasion Attack against Stacked Capsule Autoencoder},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2010.07230},
  groups        = {First Filtering},
  primaryclass  = {cs.LG},
}

@Misc{catak2020generative,
  author        = {erhat Ozgur Catak and Samed Sivaslioglu and Kevser Sahinbas},
  title         = {A Generative Model based Adversarial Security of Deep Learning and Linear Classifier Models},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2010.08546},
  groups        = {First Filtering},
  primaryclass  = {cs.LG},
}

@Misc{zhai2021backdoor,
  author        = {Tongqing Zhai and Yiming Li and Ziqi Zhang and Baoyuan Wu and Yong Jiang and Shu-Tao Xia},
  title         = {Backdoor Attack against Speaker Verification},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2010.11607},
  groups        = {First Filtering},
  primaryclass  = {cs.CR},
}

@Misc{goel2020empirical,
  author        = {Ayush Goel},
  title         = {An Empirical Review of Adversarial Defenses},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2012.06332},
  groups        = {First Filtering},
  primaryclass  = {cs.CR},
}

@Misc{hu2021model,
  author        = {Hailong Hu and Jun Pang},
  title         = {Model Extraction and Defenses on Generative Adversarial Networks},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2101.02069},
  groups        = {First Filtering},
  primaryclass  = {cs.CR},
}

@Misc{chen2021deeppoison,
  author        = {Jinyin Chen and Longyuan Zhang and Haibin Zheng and Xueke Wang and Zhaoyan Ming},
  title         = {DeepPoison: Feature Transfer Based Stealthy Poisoning Attack},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2101.02562},
  groups        = {First Filtering},
  primaryclass  = {cs.CR},
}

@Misc{bahramali2021robust,
  author        = {Alireza Bahramali and Milad Nasr and Amir Houmansadr and Dennis Goeckel and Don Towsley},
  title         = {Robust Adversarial Attacks Against DNN-Based Wireless Communication Systems},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2102.00918},
  groups        = {First Filtering},
  primaryclass  = {cs.CR},
}

@Misc{dong2021robust,
  author        = {Yudi Dong and Huaxia Wang and Yu-Dong Yao},
  title         = {A Robust Adversarial Network-Based End-to-End Communications System With Strong Generalization Ability Against Adversarial Attacks},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2103.02654},
  groups        = {First Filtering},
  primaryclass  = {cs.LG},
}

@Misc{paul2021defending,
  author        = {William Paul and Yinzhi Cao and Miaomiao Zhang and Phil Burlina},
  title         = {Defending Medical Image Diagnostics against Privacy Attacks using Generative Methods},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2103.03078},
  groups        = {First Filtering},
  primaryclass  = {cs.CR},
}

@Misc{wang2021improving,
  author        = {Desheng Wang and Weidong Jin and Yunpu Wu and Aamir Khan},
  title         = {Improving Global Adversarial Robustness Generalization With Adversarially Trained GAN},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2103.04513},
  groups        = {First Filtering},
  primaryclass  = {cs.CV},
}

@Misc{liu2021dafar,
  author        = {Haowen Liu and Ping Yi and Hsiao-Ying Lin and Jie Shi and Weidong Qiu},
  title         = {DAFAR: Defending against Adversaries by Feedback-Autoencoder Reconstruction},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2103.06487},
  groups        = {First Filtering},
  primaryclass  = {cs.CV},
}

@Misc{silva2021adaptive,
  author        = {Samuel Henrique Silva and Arun Das and Ian Scarff and Peyman Najafirad},
  title         = {Adaptive Clustering of Robust Semantic Representations for Adversarial Image Purification},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2104.02155},
  groups        = {First Filtering},
  primaryclass  = {cs.CV},
}

@Misc{müller2021defending,
  author        = {Nicolas M. Müller and Simon Roschmann and Konstantin Böttinger},
  title         = {Defending against Adversarial Denial-of-Service Attacks},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2104.06744},
  groups        = {First Filtering},
  primaryclass  = {cs.CR},
}

@Misc{szyller2021good,
  author        = {Sebastian Szyller and Vasisht Duddu and Tommi Gröndahl and N. Asokan},
  title         = {Good Artists Copy, Great Artists Steal: Model Extraction Attacks Against Image Translation Generative Adversarial Networks},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2104.12623},
  groups        = {First Filtering},
  primaryclass  = {cs.LG},
}

@Misc{chen2021salient,
  author        = {Jinyin Chen and Ruoxi Chen and Haibin Zheng and Zhaoyan Ming and Wenrong Jiang and Chen Cui},
  title         = {Salient Feature Extractor for Adversarial Defense on Deep Neural Networks},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2105.06807},
  groups        = {First Filtering},
  primaryclass  = {cs.CV},
}

@Article{Andresini2021108,
  author        = {Andresini, G. and Appice, A. and De Rose, L. and Malerba, D.},
  journal       = {Future Generation Computer Systems},
  title         = {GAN augmentation to deal with imbalance in imaging-based intrusion detection},
  year          = {2021},
  note          = {cited By 0},
  pages         = {108-127},
  volume        = {123},
  abstract      = {Nowadays attacks on computer networks continue to advance at a rate outpacing cyber defenders’ ability to write new attack signatures. This paper illustrates a deep learning methodology for the binary classification of the network traffic. The basic idea is to represent network flows as 2D images and use this imagery representation of the network traffic to train a Generative Adversarial Network (GAN) and a Convolutional Neural Network (CNN). The GAN is trained to produce new images of unforeseen network attacks by augmenting the training data used to learn a CNN-based intrusion detection model. The advantage is that the 2D data mapping technique used builds images of the network flows, which allow us to take advantage of deep learning architectures with convolution layers. In addition, the GAN-based data augmentation allows us to deal with the possible imbalance of malicious traffic that is commonly rarer than the normal traffic in the network traffic. Specifically, it is used to simulate unforeseen attacks to train a robust intrusion detection model. The proposed methodology leads to better predictive accuracy when compared to competitive intrusion detection architectures on four benchmark datasets. © 2021},
  document_type = {Article},
  doi           = {10.1016/j.future.2021.04.017},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105300272&doi=10.1016%2fj.future.2021.04.017&partnerID=40&md5=5cb10b8ca28227aaddbed04dc8c36b78},
}

@Article{Jia2021,
  author        = {Jia, Y. and Wang, J. and Poskitt, C.M. and Chattopadhyay, S. and Sun, J. and Chen, Y.},
  journal       = {International Journal of Critical Infrastructure Protection},
  title         = {Adversarial attacks and mitigation for anomaly detectors of cyber-physical systems},
  year          = {2021},
  note          = {cited By 0},
  volume        = {34},
  abstract      = {The threats faced by cyber-physical systems (CPSs) in critical infrastructure have motivated research into a multitude of attack detection mechanisms, including anomaly detectors based on neural network models. The effectiveness of anomaly detectors can be assessed by subjecting them to test suites of attacks, but less consideration has been given to adversarial attackers that craft noise specifically designed to deceive them. While successfully applied in domains such as images and audio, adversarial attacks are much harder to implement in CPSs due to the presence of other built-in defence mechanisms such as rule checkers (or invariant checkers). In this work, we present an adversarial attack that simultaneously evades the anomaly detectors and rule checkers of a CPS. Inspired by existing gradient-based approaches, our adversarial attack crafts noise over the sensor and actuator values, then uses a genetic algorithm to optimise the latter, ensuring that the neural network and the rule checking system are both deceived. We implemented our approach for two real-world critical infrastructure testbeds, successfully reducing the classification accuracy of their detectors by over 50% on average, while simultaneously avoiding detection by rule checkers. Finally, we explore whether these attacks can be mitigated by training the detectors on adversarial samples. © 2021 Elsevier B.V.},
  art_number    = {100452},
  document_type = {Article},
  doi           = {10.1016/j.ijcip.2021.100452},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107972529&doi=10.1016%2fj.ijcip.2021.100452&partnerID=40&md5=f7f31fdfd9b98a8b598a4ba66714d89e},
}

@Article{Anthi2021,
  author        = {Anthi, E. and Williams, L. and Javed, A. and Burnap, P.},
  journal       = {Computers and Security},
  title         = {Hardening machine learning denial of service (DoS) defences against adversarial attacks in IoT smart home networks},
  year          = {2021},
  note          = {cited By 0},
  volume        = {108},
  abstract      = {Machine learning based Intrusion Detection Systems (IDS) allow flexible and efficient automated detection of cyberattacks in Internet of Things (IoT) networks. However, this has also created an additional attack vector; the machine learning models which support the IDS's decisions may also be subject to cyberattacks known as Adversarial Machine Learning (AML). In the context of IoT, AML can be used to manipulate data and network traffic that traverse through such devices. These perturbations increase the confusion in the decision boundaries of the machine learning classifier, where malicious network packets are often miss-classified as being benign. Consequently, such errors are bypassed by machine learning based detectors, which increases the potential of significantly delaying attack detection and further consequences such as personal information leakage, damaged hardware, and financial loss. Given the impact that these attacks may have, this paper proposes a rule-based approach towards generating AML attack samples and explores how they can be used to target a range of supervised machine learning classifiers used for detecting Denial of Service attacks in an IoT smart home network. The analysis explores which DoS packet features to perturb and how such adversarial samples can support increasing the robustness of supervised models using adversarial training. The results demonstrated that the performance of all the top performing classifiers were affected, decreasing a maximum of 47.2 percentage points when adversarial samples were present. Their performances improved following adversarial training, demonstrating their robustness towards such attacks. © 2021},
  art_number    = {102352},
  document_type = {Article},
  doi           = {10.1016/j.cose.2021.102352},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107799454&doi=10.1016%2fj.cose.2021.102352&partnerID=40&md5=3c2b742e51f58fa70dfc9daed1f8b8ec},
}

@Article{Peng2021,
  author        = {Peng, X. and Xian, H. and Lu, Q. and Lu, X.},
  journal       = {Applied Soft Computing},
  title         = {Semantics aware adversarial malware examples generation for black-box attacks},
  year          = {2021},
  note          = {cited By 0},
  volume        = {109},
  abstract      = {Adversarial pseudo-benign examples can be generated to evade malware detection algorithms based on deep learning. Current works on adversarial examples generation mainly focus on the gradient-based attacks due to their easy-to-implement features. Although the Generative Adversarial Network (GAN) has shown a superior performance on adversarial attacks, there is not much work on applying GAN to malware composition due to its complexity and weakness in processing discrete data. API call sequence is considered as the very representative feature to analyze malware behavioral characteristics. However, it is troublesome to insert API calls into the original sequence to cover the malicious purpose with implementation on GAN. In this paper, we propose an adversarial sequence generating algorithm, which highlights the contextual relationship between API calls by using word embedding. We train a recurrent neural network based substitute detection model to fit the black-box malware detection model. We demonstrate the attack against API call sequence-based malware classifiers, and experimental results show that the proposed scheme is efficient and effective, almost all of the generated pseudo-benign malware examples can fool the detection algorithms. It outruns other GAN based schemes in performance and has a lower overhead of API call inserting. © 2021 Elsevier B.V.},
  art_number    = {107506},
  document_type = {Article},
  doi           = {10.1016/j.asoc.2021.107506},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107090276&doi=10.1016%2fj.asoc.2021.107506&partnerID=40&md5=fd4a67b5cadfbc9a74756bbcf39769e4},
}

@Article{Sahu2021146,
  author        = {Sahu, A.K. and Sharma, S. and Tanveer, M. and Raja, R.},
  journal       = {Computer Communications},
  title         = {Internet of Things attack detection using hybrid Deep Learning Model},
  year          = {2021},
  note          = {cited By 0},
  pages         = {146-154},
  volume        = {176},
  abstract      = {The Internet of Things (IoT) has become a very popular area of research due to its large-scale implementation and challenges. However, security is the key concern while witnessing the rapid growth in its size and applications. It is a tedious task to individually put security mechanisms in each IoT device and update it as per newer threats. Moreover, machine learning models can best utilize the colossal amount of data generated by IoT devices. Therefore, many Deep Learning (DL) based mechanisms have been proposed to detect attacks in IoT. However, the existing security mechanisms addressed limited attacks, and they used limited and outdated datasets for evaluations. This paper presents a novel security framework and an attack detection mechanism using a Deep Learning model to fill in the gap, which will efficiently detect malicious devices. The proposed mechanism uses a Convolution Neural Network (CNN) to extract the accurate feature representation of data and further classifies those by Long Short-Term Memory (LSTM) Model. The dataset used in the experimental evaluation is from twenty Raspberry Pi infected IoT devices. The accuracy of the empirical study for attack detection is 96 percent. In addition, it is observed that the proposed model outperformed various recently proposed DL-based attack detection mechanisms. © 2021 Elsevier B.V.},
  document_type = {Article},
  doi           = {10.1016/j.comcom.2021.05.024},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107620415&doi=10.1016%2fj.comcom.2021.05.024&partnerID=40&md5=970e486143a77e873147df37d2f9f4bb},
}

@Article{Sakhnini2021,
  author        = {Sakhnini, J. and Karimipour, H. and Dehghantanha, A. and Parizi, R.M.},
  journal       = {Physical Communication},
  title         = {Physical layer attack identification and localization in cyber–physical grid: An ensemble deep learning based approach},
  year          = {2021},
  note          = {cited By 0},
  volume        = {47},
  abstract      = {The massive integration of low-cost communication networks and Internet of Things (IoT) in today's cyber–physical grids has been accompanied by significant concerns regarding potential security threats. Specifically, wireless communication technology introduces additional vulnerability in terms of network security. In addition to cyber-security issues that have been investigated extensively, we must consider physical layer security. As such, considerable efforts have been employed toward developing a solution to address cyber-security issues. However, there are limited efforts on developing intrusion detection systems for physical layer security. In this paper, we propose an intelligent attack detection and identification model capable of classifying the attack type in the physical layer based on an ensemble of machine learning methods. Furthermore, the proposed model localizes the attack or fault to specific features or measurements in the system to assist cyber-security professionals in mitigating the effect of the attack in communication networks. The proposed model is evaluated on a smart grids dataset simulated by the Oak Ridge National Laboratories and is compared with traditional machine learning classifiers. The localization of attacks and faults is tested by splitting the data and measuring the correlation of the localization metrics produced by the proposed model. The results demonstrate the effectiveness of the proposed method at classifying and localizing attacks compared to peer approaches. © 2021},
  art_number    = {101394},
  document_type = {Review},
  doi           = {10.1016/j.phycom.2021.101394},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107615414&doi=10.1016%2fj.phycom.2021.101394&partnerID=40&md5=968a592eee6e6bc00f6a4d261362afbf},
}

@Article{Shen2021469,
  author        = {Shen, J. and Robertson, N.},
  journal       = {Information Sciences},
  title         = {BBAS: Towards large scale effective ensemble adversarial attacks against deep neural network learning},
  year          = {2021},
  note          = {cited By 0},
  pages         = {469-478},
  volume        = {569},
  abstract      = {Recent decades have witnessed rapid development of deep neural networks (DNN). As DNN learning is becoming more and more important to numerous intelligent system, ranging from self driving car to video surveillance system, significant research efforts have been devoted to explore how to improve DNN model's robustness and reliability against adversarial example attacks. Distinguish from previous study, we address the problem of adversarial training with ensemble based approach and propose a novel boosting based black-box attack scheme call BBAS to facilitate high diverse adversarial example generation. BBAS not only separates example generation from the settings of the trained model but also enhance the diversity of perturbation over class distribution through seamless integration of stratified sampling and ensemble adversarial training. This leads to reliable and effective training example selection. To validate and evaluate the scheme from different perspectives, a set of comprehensive tests have been carried out based on two large open data sets. Experimental results demonstrate the superiority of our method in terms of effectiveness. © 2020 Elsevier Inc.},
  document_type = {Article},
  doi           = {10.1016/j.ins.2020.11.026},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107052597&doi=10.1016%2fj.ins.2020.11.026&partnerID=40&md5=b9a33656e1afb27213f52e251453ba81},
}

@Article{Navidan2021,
  author        = {Navidan, H. and Moshiri, P.F. and Nabati, M. and Shahbazian, R. and Ghorashi, S.A. and Shah-Mansouri, V. and Windridge, D.},
  journal       = {Computer Networks},
  title         = {Generative Adversarial Networks (GANs) in networking: A comprehensive survey & evaluation},
  year          = {2021},
  note          = {cited By 0},
  volume        = {194},
  abstract      = {Despite the recency of their conception, Generative Adversarial Networks (GANs) constitute an extensively-researched machine learning sub-field for the creation of synthetic data through deep generative modeling. GANs have consequently been applied in a number of domains, most notably computer vision, in which they are typically used to generate or transform synthetic images. Given their relative ease of use, it is therefore natural that researchers in the field of networking (which has seen extensive application of deep learning methods) should take an interest in GAN-based approaches. The need for a comprehensive survey of such activity is therefore urgent. In this paper, we demonstrate how this branch of machine learning can benefit multiple aspects of computer and communication networks, including mobile networks, network analysis, internet of things, physical layer, and cybersecurity. In doing so, we shall provide a novel evaluation framework for comparing the performance of different models in non-image applications, applying this to a number of reference network datasets. © 2021 Elsevier B.V.},
  art_number    = {108149},
  document_type = {Article},
  doi           = {10.1016/j.comnet.2021.108149},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105870509&doi=10.1016%2fj.comnet.2021.108149&partnerID=40&md5=6bfcebb703cf385122ccb213ac7d2318},
}

@Article{Xiao2021,
  author        = {Xiao, Y. and Pun, C.-M. and Liu, B.},
  journal       = {Pattern Recognition},
  title         = {Fooling deep neural detection networks with adaptive object-oriented adversarial perturbation},
  year          = {2021},
  note          = {cited By 1},
  volume        = {115},
  abstract      = {Deep learning has shown superiority in dealing with complicated and professional tasks (e.g., computer vision, audio, and language processing). However, research works have confirmed that Deep Neural Networks (DNNs) are vulnerable to carefully crafted adversarial perturbations, which cause DNNs confusion on specific tasks. In object detection domain, the background has little contributions to object classification, and the crafted adversarial perturbations added to the background do not improve the adversary effect in fooling deep neural detection models yet induce substantial distortions in generated examples. Based on such situation, we introduce an adversarial attack algorithm named Adaptive Object-oriented Adversarial Method (AO2AM). It aims to fool deep neural object detection networks with the adversarial examples by applying the adaptive cumulation of object-based gradients and adding the adaptive object-based adversarial perturbations merely onto objects rather than the whole frame of input images. AO2AM can effectively make the representations of generated adversarial samples close to the decision boundary in the latent space, and force deep neural detection networks to yield inaccurate locations and false classification in the process of object detection. Compared with existing adversarial attack methods which generate adversarial perturbations acting on the global scale of the original inputs, the adversarial examples produced by AO2AM can effectively fool deep neural object detection networks and maintain a high structural similarity with corresponding clean inputs. Performing adversarial attacks on Faster R-CNN, AO2AM gains attack success rate (ASR) over 98.00% on pre-processed Pascal VOC 2007&amp;2012 (Val), and reaches SSIM over 0.870. In Fooling SSD, AO2AM receives SSIM exceeding 0.980 on L2 norm constraint. On SSIM and Mean Attack Ratio, AO2AM outperforms adversarial attack methods based on global scale perturbations. © 2021 Elsevier Ltd},
  art_number    = {107903},
  document_type = {Article},
  doi           = {10.1016/j.patcog.2021.107903},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101503839&doi=10.1016%2fj.patcog.2021.107903&partnerID=40&md5=d6a8626d27b66c597dc07a03d7ad51b8},
}

@Conference{Zhang202115,
  author        = {Zhang, Z. and Jia, J. and Wang, B. and Gong, N.Z.},
  title         = {Backdoor attacks to graph neural networks},
  year          = {2021},
  note          = {cited By 0},
  pages         = {15-26},
  abstract      = {In this work, we propose the first backdoor attack to graph neural networks (GNN). Specifically, we propose a subgraph based backdoor attack to GNN for graph classification. In our backdoor attack, a GNN classifier predicts an attacker-chosen target label for a testing graph once a predefined subgraph is injected to the testing graph. Our empirical results on three real-world graph datasets show that our backdoor attacks are effective with a small impact on a GNN's prediction accuracy for clean testing graphs. Moreover, we generalize a randomized smoothing based certified defense to defend against our backdoor attacks. Our empirical results show that the defense is effective in some cases but ineffective in other cases, highlighting the needs of new defenses for our backdoor attacks. © 2021 ACM.},
  art_number    = {3463560},
  document_type = {Conference Paper},
  doi           = {10.1145/3450569.3463560},
  groups        = {First Filtering},
  journal       = {Proceedings of ACM Symposium on Access Control Models and Technologies, SACMAT},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108145809&doi=10.1145%2f3450569.3463560&partnerID=40&md5=9f3e38217147cfaa68a60db524f1de9f},
}

@Article{Kim2021,
  author        = {Kim, S. and Park, K.-J.},
  journal       = {Applied Sciences (Switzerland)},
  title         = {A survey on machine-learning based security design for cyber-physical systems},
  year          = {2021},
  note          = {cited By 0},
  number        = {12},
  volume        = {11},
  abstract      = {A cyber-physical system (CPS) is the integration of a physical system into the real world and control applications in a computing system, interacting through a communications network. Network technology connecting physical systems and computing systems enables the simultaneous control of many physical systems and provides intelligent applications for them. However, enhancing connectivity leads to extended attack vectors in which attackers can trespass on the network and launch cyber-physical attacks, remotely disrupting the CPS. Therefore, extensive studies into cyber-physical security are being conducted in various domains, such as physical, network, and computing systems. Moreover, large-scale and complex CPSs make it difficult to analyze and detect cyber-physical attacks, and thus, machine learning (ML) techniques have recently been adopted for cyber-physical security. In this survey, we provide an extensive review of the threats and ML-based security designs for CPSs. First, we present a CPS structure that classifies the functions of the CPS into three layers: the physical system, the network, and software applications. Then, we discuss the taxonomy of cyber-physical attacks on each layer, and in particular, we analyze attacks based on the dynamics of the physical system. We review existing studies on detecting cyber-physical attacks with various ML techniques from the perspectives of the physical system, the network, and the computing system. Furthermore, we discuss future research directions for ML-based cyber-physical security research in the context of real-time constraints, resiliency, and dataset generation to learn about the possible attacks. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
  art_number    = {5458},
  document_type = {Review},
  doi           = {10.3390/app11125458},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108609213&doi=10.3390%2fapp11125458&partnerID=40&md5=3e7a9883b6f746d3674125443544e9b2},
}

@Article{Li2021172,
  author        = {Li, Z. and Feng, C. and Wu, M. and Yu, H. and Zheng, J. and Zhu, F.},
  journal       = {Pattern Recognition Letters},
  title         = {Adversarial robustness via attention transfer},
  year          = {2021},
  note          = {cited By 0},
  pages         = {172-178},
  volume        = {146},
  abstract      = {Deep neural networks are known to be vulnerable to adversarial attacks. The empirical analysis in our study suggests that attacks tend to induce diverse network architectures to shift the attention to irrelevant regions. Motivated by this observation, we propose a regularization technique which enforces the attentions to be well aligned via the knowledge transfer mechanism, thereby encouraging the robustness. Resultant model exhibits unprecedented robustness, securing 63.81% adversarial accuracy where the prior art is 51.59% on CIFAR-10 dataset under PGD attacks. In addition, we go beyond performance to analytically investigate the proposed method as an effective defense. Significantly flattened loss landscape can be observed, demonstrating the promise of the proposed method for improving robustness and thus the deployment in security-sensitive settings. © 2021 Elsevier B.V.},
  document_type = {Article},
  doi           = {10.1016/j.patrec.2021.03.011},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103630302&doi=10.1016%2fj.patrec.2021.03.011&partnerID=40&md5=e11594bee370ecd35d64f1ee5f342536},
}

@Article{Pasikhani202112940,
  author        = {Pasikhani, A.M. and Clark, J.A. and Gope, P. and Alshahrani, A.},
  journal       = {IEEE Sensors Journal},
  title         = {Intrusion Detection Systems in RPL-Based 6LoWPAN: A Systematic Literature Review},
  year          = {2021},
  note          = {cited By 0},
  number        = {11},
  pages         = {12940-12968},
  volume        = {21},
  abstract      = {Drastic reduction in the manufacturing cost of sensors and actuators has resulted in considerable growth in the number of smart objects. The so-called Internet of Things (IoT) blends the real and virtual environments and removes time and distance barriers. It is widely perceived as a major enabler for the efficient and effective provision of services across a range of sectors. It has naturally attracted the interest of cyberattackers. Due to the heterogeneity, resource-constraints, scale, and internet connectivity of IoT devices, each IoT layer is prone to various threats. Intruders consider the network layer of IoT as the gateway and leverage vulnerabilities in the routing protocol to compromise the Confidentiality, Integrity, and Availability (CIA) of connected nodes. Researchers have proposed different security infrastructures to mitigate harm to IoT networks. One of these is the Intrusion Detection System (IDS). An IDS is an essential component for the network security layer and is widely adopted to reinforce the security of the IoT network. This systematic literature review explores the IPv6 Routing Protocol for Low Power and Lossy Networks (RPL) and its existing threats, classifies relevant IDS techniques and identifies areas requiring further investigation. We review 103 published papers in this domain. © 2001-2012 IEEE.},
  art_number    = {9383263},
  document_type = {Review},
  doi           = {10.1109/JSEN.2021.3068240},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103291006&doi=10.1109%2fJSEN.2021.3068240&partnerID=40&md5=18db412f0e4e74719a2551b2453c550d},
}

@Article{Wang202115,
  author        = {Wang, Y. and Ding, X. and Yang, Y. and Ding, L. and Ward, R. and Wang, Z.J.},
  journal       = {Pattern Recognition Letters},
  title         = {Perception matters: Exploring imperceptible and transferable anti-forensics for GAN-generated fake face imagery detection},
  year          = {2021},
  note          = {cited By 0},
  pages         = {15-22},
  volume        = {146},
  abstract      = {Recently, generative adversarial networks (GANs) can generate photo-realistic fake facial images which are perceptually indistinguishable from real face photos, promoting research on fake face detection. Though fake face forensics can achieve high detection accuracy, their anti-forensic counterparts are less investigated. Here we explore more imperceptible and transferable anti-forensics for fake face imagery detection based on adversarial attacks. Since facial and background regions are often smooth, even small perturbation could cause noticeable perceptual impairment in fake face images. Therefore it makes existing transfer-based adversarial attacks ineffective as an anti-forensic method. Our perturbation analysis reveals the intuitive reason of the perceptual degradation issue when directly applying such existing attacks. We then propose a novel adversarial attack method, better suitable for image anti-forensics, in the transformed color domain by considering visual perception. Conceptually simple yet effective, the proposed method can fool both deep learning and non-deep learning based forensic detectors, achieving higher adversarial transferability and significantly improved visual quality. Specially, when adversaries consider imperceptibility as a constraint, the proposed anti-forensic method achieves the state-of-the-art attacking performances in the transfer-based black-box setting (i.e. around 30% higher attack transferability than baseline attacks). More imperceptible and more transferable, the proposed method raises new security concerns to fake face imagery detection. We have released our code for public use, and hopefully the proposed method can be further explored in related forensic applications as an anti-forensic benchmark. © 2021 Elsevier B.V.},
  document_type = {Article},
  doi           = {10.1016/j.patrec.2021.03.009},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102974642&doi=10.1016%2fj.patrec.2021.03.009&partnerID=40&md5=2257e0a0a6717b5e27314b20daf77fd6},
}

@Article{Fang20214260,
  author        = {Fang, L. and Li, Y. and Liu, Z. and Yin, C. and Li, M. and Cao, Z.J.},
  journal       = {IEEE Transactions on Industrial Informatics},
  title         = {A Practical Model Based on Anomaly Detection for Protecting Medical IoT Control Services against External Attacks},
  year          = {2021},
  note          = {cited By 1},
  number        = {6},
  pages         = {4260-4269},
  volume        = {17},
  abstract      = {The application of the Internet of Things (IoT) in medical field has brought unprecedented convenience to human beings. However, attackers can use device configuration vulnerabilities to hijack devices, control services, steal medical data, or make devices operate illegally. These restrictions have led to huge security risks for IoT, and have challenged the management of critical infrastructure services. Based on these problems, this article proposes an anomaly detection system for detecting illegal behavior (DIB) in medical IoT environment.The DIB system can analyze data packets transmitted by medical IoT devices, learn operation rules by itself, and remind management personnel that the device is in an abnormal operation state to ensure the safety of control service. We further propose a model that is based on rough set theory and fuzzy core vector machine (FCVM) to improve the accuracy of DIB classification anomalies. Experimental results show that the R-FCVM is effective. © 2005-2012 IEEE.},
  art_number    = {9146676},
  document_type = {Article},
  doi           = {10.1109/TII.2020.3011444},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102376907&doi=10.1109%2fTII.2020.3011444&partnerID=40&md5=a3ca81f03c0f8fd8bfff7311df211509},
}

@Article{Pinhero2021,
  author        = {Pinhero, A. and M L, A. and P, V. and Visaggio, C.A. and N, A. and S, A. and S, A.},
  journal       = {Computers and Security},
  title         = {Malware detection employed by visualization and deep neural network},
  year          = {2021},
  note          = {cited By 0},
  volume        = {105},
  abstract      = {With the fast growth of malware's volume circulating in the wild, to obtain a timely and correct classification is increasingly difficult. Traditional approaches to automatic classification suffer from some limitations. The first one concerns the feature extraction: static approaches are hindered by code obfuscation techniques, while dynamic approaches are time consuming and evasion techniques often impede the correct execution of the code. The second limitation regards the building of the prediction models: the adequateness of a training dataset may degrade over time or can not be sufficient for some malware families or instances. With this paper we investigate the effectiveness of a new approach that uses malware visualization, for overcoming the problems related to the features selection and extraction, along with deep learning classification, whose performances are less sensitive to a small dataset than machine learning. The experiments carried out on twelve different neural network architectures and with a dataset of 20,199 malware, demonstrate that the proposed approach is successful as produced an F-measure of 99.97%. © 2021 Elsevier Ltd},
  art_number    = {102247},
  document_type = {Review},
  doi           = {10.1016/j.cose.2021.102247},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102042791&doi=10.1016%2fj.cose.2021.102247&partnerID=40&md5=2bd4d60268a488efc6bb04ce9c06ac41},
}

@Article{Jagtap202184,
  author        = {Jagtap, S.S. and Shankar Sriram, V.S. and Subramaniyaswamy, V.},
  journal       = {Future Generation Computer Systems},
  title         = {A hypergraph based Kohonen map for detecting intrusions over cyber–physical systems traffic},
  year          = {2021},
  note          = {cited By 1},
  pages         = {84-109},
  volume        = {119},
  abstract      = {Cyber–Physical System acts as a cornerstone in Industry 4.0 by integrating information-technology, electrical, and mechanical engineering under the same crown. This cybernetic–mechatronic augmentation expanded the attack vectors in critical infrastructure's network, which gained the attraction of both cyber-offenders and cybersecurity researchers. Though the recent research works focus on developing proficient cybersecurity mechanisms, they often fail to address the major challenges such as handling the unseen zero-day exploits and detecting data irregularities that result in a poor attack detection rate. Hence to address the aforementioned challenges, this research article proposes an intelligent multi-level intrusion detection system to detect data-abnormalities in process-control network packets. The proposed approach involves the following phases: (i) Bloom-filter based payload level detection, (ii) partition-based Kohonen mapping for learning abnormal data patterns using a deep version of Kohonen neural network enhanced by principal component analysis and partitioning property of Hypergraph, and (iii) BLOSOM – a hybrid anomaly detection model. The impact of the proposed approach has been validated with the high-dimensional and heterogeneous benchmark datasets obtained from Mississippi State University (Gas-pipeline dataset) and Singapore University of Technology and Design (Secure WAter Treatment dataset). The proposed approach outscores the existing State-of-the-art approaches in terms of Precision, Recall, F-Score & Classification Accuracy and found to be robust, scalable & computationally attractive. © 2021 Elsevier B.V.},
  document_type = {Article},
  doi           = {10.1016/j.future.2021.02.001},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101050529&doi=10.1016%2fj.future.2021.02.001&partnerID=40&md5=61d5313a68ab0c958217ec129dcd3e5b},
}

@Article{Chen2021618,
  author        = {Chen, J. and Lin, X. and Xiong, H. and Wu, Y. and Zheng, H. and Xuan, Q.},
  journal       = {IEEE Transactions on Computational Social Systems},
  title         = {Smoothing Adversarial Training for GNN},
  year          = {2021},
  note          = {cited By 0},
  number        = {3},
  pages         = {618-629},
  volume        = {8},
  abstract      = {Recently, a graph neural network (GNN) was proposed to analyze various graphs/networks, which has been proven to outperform many other network analysis methods. However, it is also shown that such state-of-the-art methods suffer from adversarial attacks, i.e., carefully crafted adversarial networks with slight perturbation on clean one may invalid these methods on lots of applications, such as network embedding, node classification, link prediction, and community detection. Adversarial training has been testified as an efficient defense strategy against adversarial attacks in computer vision and graph mining. However, almost all the algorithms based on adversarial training focus on global defense through overall adversarial training. In a more practical scene, certain users would be targeted to attack, i.e., specific labeled users. It is still a challenge to defend against target node attack by existing adversarial training methods. Therefore, we propose smoothing adversarial training (SAT) to improve the robustness of GNNs. In particular, we analytically investigate the robustness of graph convolutional network (GCN), one of the classic GNNs, and propose two smooth defensive strategies: smoothing distillation and smoothing cross-entropy loss function. Both of them smooth the gradients of GCN and, consequently, reduce the amplitude of adversarial gradients, benefiting gradient masking from attackers in both global attack and target label node attack. The comprehensive experiments on five real-world networks testify that the proposed SAT method shows state-of-the-art defensibility against different adversarial attacks on node classification and community detection. Especially, the average attack success rate of different attack methods can be decreased by about 40% by SAT at the cost of tolerable embedding performance decline of the original network. © 2014 IEEE.},
  art_number    = {9305289},
  document_type = {Article},
  doi           = {10.1109/TCSS.2020.3042628},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098773779&doi=10.1109%2fTCSS.2020.3042628&partnerID=40&md5=0d00c1f24f0b140f546812283ed286fc},
}

@Article{Bouyeddou20211435,
  author        = {Bouyeddou, B. and Harrou, F. and Kadri, B. and Sun, Y.},
  journal       = {Cluster Computing},
  title         = {Detecting network cyber-attacks using an integrated statistical approach},
  year          = {2021},
  note          = {cited By 2},
  number        = {2},
  pages         = {1435-1453},
  volume        = {24},
  abstract      = {Anomaly detection in the Internet of Things (IoT) is imperative to improve its reliability and safety. Detecting denial of service (DOS) and distributed DOS (DDOS) is one of the critical security challenges facing network technologies. This paper presents an anomaly detection mechanism using the Kullback–Leibler distance (KLD) to detect DOS and DDOS flooding attacks, including transmission control protocol (TCP) SYN flood, UDP flood, and ICMP-based attacks. This mechanism integrates the desirable properties of KLD, the capacity to quantitatively discriminate between two distributions, with the sensitivity of an exponential smoothing scheme. The primary reason for exponentially smoothing KLD measurements (ES–KLD) is to aggregate all of the information from past and actual samples in the decision rule, making the detector sensitive to small anomalies. Furthermore, a nonparametric approach using kernel density estimation has been used to set a threshold for ES-KLD decision statistic to uncover the presence of attacks. Tests on three publicly available datasets show improved performances of the proposed mechanism in detecting cyber-attacks compared to other conventional monitoring procedures. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.},
  document_type = {Article},
  doi           = {10.1007/s10586-020-03203-1},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095449892&doi=10.1007%2fs10586-020-03203-1&partnerID=40&md5=8cd97311b25441eef18c59f6dfd39493},
}

@Article{Thakkar20213211,
  author        = {Thakkar, A. and Lohiya, R.},
  journal       = {Archives of Computational Methods in Engineering},
  title         = {A Review on Machine Learning and Deep Learning Perspectives of IDS for IoT: Recent Updates, Security Issues, and Challenges},
  year          = {2021},
  note          = {cited By 2},
  number        = {4},
  pages         = {3211-3243},
  volume        = {28},
  abstract      = {Internet of Things (IoT) is widely accepted technology in both industrial as well as academic field. The objective of IoT is to combine the physical environment with the cyber world and create one big intelligent network. This technology has been applied to various application domains such as developing smart home, smart cities, healthcare applications, wireless sensor networks, cloud environment, enterprise network, web applications, and smart grid technologies. These wide emerging applications in variety of domains raise many security issues such as protecting devices and network, attacks in IoT networks, and managing resource-constrained IoT networks. To address the scalability and resource-constrained security issues, many security solutions have been proposed for IoT such as web application firewalls and intrusion detection systems. In this paper, a comprehensive survey on Intrusion Detection System (IDS) for IoT is presented for years 2015–2019. We have discussed various IDS placement strategies and IDS analysis strategies in IoT architecture. The paper discusses various intrusions in IoT, along with Machine Learning (ML) and Deep Learning (DL) techniques for detecting attacks in IoT networks. The paper also discusses security issues and challenges in IoT. © 2020, CIMNE, Barcelona, Spain.},
  document_type = {Article},
  doi           = {10.1007/s11831-020-09496-0},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092920536&doi=10.1007%2fs11831-020-09496-0&partnerID=40&md5=ecded667dd3be003fa483b052b0baf60},
}

@Article{Liu20211244,
  author        = {Liu, K. and Tan, B. and Karri, R. and Garg, S.},
  journal       = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  title         = {Training Data Poisoning in ML-CAD: Backdooring DL-Based Lithographic Hotspot Detectors},
  year          = {2021},
  note          = {cited By 0},
  number        = {6},
  pages         = {1244-1257},
  volume        = {40},
  abstract      = {Recent efforts to enhance computer-aided design (CAD) flows have seen the proliferation of machine learning (ML)-based techniques. However, despite achieving state-of-the-art performance in many domains, techniques, such as deep learning (DL) are susceptible to various adversarial attacks. In this work, we explore the threat posed by training data poisoning attacks where a malicious insider can try to insert backdoors into a deep neural network (DNN) used as part of the CAD flow. Using a case study on lithographic hotspot detection, we explore how an adversary can contaminate training data with specially crafted, yet meaningful, genuinely labeled, and design rule compliant poisoned clips. Our experiments show that very low poisoned/clean data ratio in training data is sufficient to backdoor the DNN; an adversary can 'hide' specific hotspot clips at inference time by including a backdoor trigger shape in the input with 100% success. This attack provides a novel way for adversaries to sabotage and disrupt the distributed design process. After finding that training data poisoning attacks are feasible and stealthy, we explore a potential ensemble defense against possible data contamination, showing promising attack success reduction. Our results raise fundamental questions about the robustness of DL-based systems in CAD, and we provide insights into the implications of these. © 1982-2012 IEEE.},
  art_number    = {9200729},
  document_type = {Article},
  doi           = {10.1109/TCAD.2020.3024780},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091687114&doi=10.1109%2fTCAD.2020.3024780&partnerID=40&md5=9bbf32e5e9b56eb8c1fec7e8d8b8aa13},
}

@Article{Thakur20212897,
  author        = {Thakur, K. and Kumar, G.},
  journal       = {Archives of Computational Methods in Engineering},
  title         = {Nature Inspired Techniques and Applications in Intrusion Detection Systems: Recent Progress and Updated Perspective},
  year          = {2021},
  note          = {cited By 0},
  number        = {4},
  pages         = {2897-2919},
  volume        = {28},
  abstract      = {Nowadays, it has become a necessity for operational and reliable operation of networks due to our increased dependency over the network services. However, intruders are continuously attempting to break into the networks and disturbing the network services using a variety of attack vectors and technologies. This motivates us to develop the techniques that ensure operational and reliable network, even in changing scenarios. Recently, most of the researchers have focused on the employment of techniques inspired by a natural phenomenon to detect the intrusions effectively. Nature-Inspired Techniques (NITs) have the ability to adapt to a constantly changing environment. Thus, they help to provide in-built resiliency to failures and damages, collaborative, survivable, self-organizing and self-healing capabilities to IDSs. The paper presents an analysis of NITs, and their classification based on the source of their inspiration. A comprehensive review of various NITs employed in intrusion detection is presented. Analysis of prominent research indicates that NITs based IDSs offers high detection rate and low false positive rate in comparison to the conventional IDSs. The NITs enables more flexibility in IDSs because of their employability into hybrid IDSs leading to detection on the basis of anomalies as well as signatures, leading in improving detection results of known and unknown attacks. The paper attempts to identify NITs’ advantages, disadvantages and significant challenges to the successful implementation of NITs in the intrusion detection area. The main intention of this paper is to explore and present a comprehensive review of the application of NITs in intrusion detection, covering a variety of NITs, study of the techniques and architectures used and further the contribution of NITs in the field of intrusion detection. Finally, the paper ends with the conclusion and future aspects. © 2020, CIMNE, Barcelona, Spain.},
  document_type = {Article},
  doi           = {10.1007/s11831-020-09481-7},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090066602&doi=10.1007%2fs11831-020-09481-7&partnerID=40&md5=aa4ced585390d4febe13944b3db3429b},
}

@Conference{Piskozub2021774,
  author        = {Piskozub, M. and De Gaspari, F. and Barr-Smith, F. and Mancini, L. and Martinovic, I.},
  title         = {MalPhase: Fine-Grained Malware Detection Using Network Flow Data},
  year          = {2021},
  note          = {cited By 0},
  pages         = {774-786},
  abstract      = {Economic incentives encourage malware authors to constantly develop new, increasingly complex malware to steal sensitive data or blackmail individuals and companies into paying large ransoms. In 2017, the worldwide economic impact of cyberattacks is estimated to be between 445 and 600 billion USD, or 0.8% of global GDP. Traditionally, one of the approaches used to defend against malware is network traffic analysis, which relies on network data to detect the presence of potentially malicious software. However, to keep up with increasing network speeds and amount of traffic, network analysis is generally limited to work on aggregated network data, which is traditionally challenging and yields mixed results. In this paper we present MalPhase, a system that was designed to cope with the limitations of aggregated flows. MalPhase features a multi-phase pipeline for malware detection, type and family classification. The use of an extended set of network flow features and a simultaneous multi-tier architecture facilitates a performance improvement for deep learning models, making them able to detect malicious flows (>98% F1) and categorize them to a respective malware type (>93% F1) and family (>91% F1). Furthermore, the use of robust features and denoising autoencoders allows MalPhase to perform well on samples with varying amounts of benign traffic mixed in. Finally, MalPhase detects unseen malware samples with performance comparable to that of known samples, even when interlaced with benign flows to reflect realistic network environments. © 2021 ACM.},
  document_type = {Conference Paper},
  doi           = {10.1145/3433210.3453101},
  groups        = {First Filtering},
  journal       = {ASIA CCS 2021 - Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106083146&doi=10.1145%2f3433210.3453101&partnerID=40&md5=2fa690aaf0d7b741428e2594ed674741},
}

@Conference{Gohari202171,
  author        = {Gohari, M. and Hashemi, S. and Abdi, L.},
  title         = {Android Malware Detection and Classification Based on Network Traffic Using Deep Learning},
  year          = {2021},
  note          = {cited By 0},
  pages         = {71-77},
  abstract      = {Users of smartphones in the world has grown significantly, and attacks against these devices have increased. Many protection techniques for android malware detection have been proposed; however, most of them lack the early detection of malware. Hence, there is an intense need before to expand a mechanism to identify malicious programs before utilizing the data. Moreover, achieving high accuracy in detecting Android malware traffic is another critical problem. This research proposes a deep learning framework using network traffic features to detect Android malware. Commonly, machine learning algorithms need data preprocessing, but these preprocessing phases are time- consuming. Deep learning techniques remove the need for data preprocessing, and they perform well on malware detection problems. We extract local features from network flows by using the one-dimensional CNN and employ LSTM to detect the sequential relationship between the considerable features. We utilize a real-world dataset CICAndMal2017 with network traffic features to identify Android malware. Our model achieves the accuracy of 99.79, 98.90%, and 97.29%, respectively, in binary, category, and family classifications scenarios. © 2021 IEEE.},
  art_number    = {9443025},
  document_type = {Conference Paper},
  doi           = {10.1109/ICWR51868.2021.9443025},
  groups        = {First Filtering},
  journal       = {2021 7th International Conference on Web Research, ICWR 2021},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107650865&doi=10.1109%2fICWR51868.2021.9443025&partnerID=40&md5=0186e681031ee5434a9fde3950c51982},
}

@Article{Bitton20211164,
  author        = {Bitton, R. and Shabtai, A.},
  journal       = {IEEE Transactions on Dependable and Secure Computing},
  title         = {A Machine Learning-Based Intrusion Detection System for Securing Remote Desktop Connections to Electronic Flight Bag Servers},
  year          = {2021},
  note          = {cited By 1},
  number        = {3},
  pages         = {1164-1181},
  volume        = {18},
  abstract      = {Remote desktop protocols (RDP) are commonly used for connecting and interacting with computers remotely. In this case, a server component runs on the remote computer and shares its desktop (i.e., screen) with the client component which runs on an end user device. In recent years, a number of vulnerabilities have been identified in two widely used remote desktop implementations, Microsoft Remote Desktop and RealVNC. These vulnerabilities may expose the remote server to a new attack vector. This concern is increased when it comes to a cyber-physical system (CPS) in which a client device with a low trust level connects to the critical system via the remote desktop server. In order to mitigate this risk, in this paper we propose a network based intrusion detection system (NIDS) specifically designed for securing the remote desktop connections. The propose method utilizes an innovative anomaly detection technique based on machine learning for detecting malicious TCP packets, which can carry exploits aimed at the RDP server. An empirical evaluation conducted on an avionic system setup consisting of a commercial tablet (Samsung Galaxy Tab) connected through a Virtual Network Computing (VNC) remote desktop implementation to a real electronic flight bag (EFB) server shows that the proposed method can detect malicious packets carrying real exploits (reported in recent years) with a true positive rate of 0.863 and a false positive rate of 0.0001. © 2004-2012 IEEE.},
  art_number    = {8703153},
  document_type = {Article},
  doi           = {10.1109/TDSC.2019.2914035},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106047562&doi=10.1109%2fTDSC.2019.2914035&partnerID=40&md5=dc98f10a5b9609691d1da8afa86624e7},
}

@Article{Gupta20211250,
  author        = {Gupta, P.K. and Singh, N.K. and Mahajan, V.},
  journal       = {International Journal of Engineering, Transactions B: Applications},
  title         = {Intrusion detection in cyber-physical layer of smart grid using intelligent loop based artificial neural network technique},
  year          = {2021},
  note          = {cited By 0},
  number        = {5},
  pages         = {1250-1256},
  volume        = {34},
  abstract      = {This paper, proposes an Intelligent Loop Based Artificial Neural Network (ILANN) based detection technique for the detection of cyber intrusion in a smart grid against False Data Injection Attack (FDIA). This method compares the deviation of a system with the equipment load profile present on the system node(s) and any deviation from predefined values generates an alarm. Every 2 milliseconds (ms) the data obtained by the measurement is passed through the attack detection system, in case if the deviation is continuously for 5 measurement cycles i.e. for 10 ms and it does not match with the load combination the operator will get the first alert alarm. In case the deviation is not fixed after 8 measurement cycles then the system alerts the control centre. FDI attack is used by attackers to affect the healthy operation of the smart grid. Using FDI the hackers can permanently damage many power system equipment's which may lead to higher fixing costs. The result and analysis of the proposed cyber detection approach help operator and control centre to identify cyber intrusion in the smart grid scenario. The method is used to detect a cyberattack on IEEE-9 Bus test system using MATLAB software. © 2021 Materials and Energy Research Center. All rights reserved.},
  document_type = {Article},
  doi           = {10.5829/ije.2021.34.05b.18},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105628905&doi=10.5829%2fije.2021.34.05b.18&partnerID=40&md5=0187d1cf8aab6817d05f85b8f8d2a150},
}

@Article{Popoola2021,
  author        = {Popoola, S.I. and Adebisi, B. and Ande, R. and Hammoudeh, M. and Atayero, A.A.},
  journal       = {Electronics (Switzerland)},
  title         = {Memory-efficient deep learning for botnet attack detection in iot networks},
  year          = {2021},
  note          = {cited By 0},
  number        = {9},
  volume        = {10},
  abstract      = {Cyber attackers exploit a network of compromised computing devices, known as a botnet, to attack Internet-of-Things (IoT) networks. Recent research works have recommended the use of Deep Recurrent Neural Network (DRNN) for botnet attack detection in IoT networks. However, for high feature dimensionality in the training data, high network bandwidth and a large memory space will be needed to transmit and store the data, respectively in IoT back-end server or cloud platform for Deep Learning (DL). Furthermore, given highly imbalanced network traffic data, the DRNN model produces low classification performance in minority classes. In this paper, we exploit the joint advantages of Long Short-Term Memory Autoencoder (LAE), Synthetic Minority Oversampling Technique (SMOTE), and DRNN to develop a memory-efficient DL method, named LS-DRNN. The effectiveness of this method is evaluated with the Bot-IoT dataset. Results show that the LAE method reduced the dimensionality of network traffic features in the training set from 37 to 10, and this consequently reduced the memory space required for data storage by 86.49%. SMOTE method helped the LS-DRNN model to achieve high classification performance in minority classes, and the overall detection rate increased by 10.94%. Furthermore, the LS-DRNN model outperformed state-of-the-art models. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
  art_number    = {1104},
  document_type = {Article},
  doi           = {10.3390/electronics10091104},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105391955&doi=10.3390%2felectronics10091104&partnerID=40&md5=ceb9f5b8060a043d596b2e40ca0e4858},
}

@Conference{Herath202129,
  author        = {Herath, J.D. and Yang, P. and Yan, G.},
  title         = {Real-Time Evasion Attacks against Deep Learning-Based Anomaly Detection from Distributed System Logs},
  year          = {2021},
  note          = {cited By 0},
  pages         = {29-40},
  abstract      = {Distributed system logs, which record states and events that occurred during the execution of a distributed system, provide valuable information for troubleshooting and diagnosis of its operational issues. Due to the complexity of such systems, there have been some recent research efforts on automating anomaly detection from distributed system logs using deep learning models. As these anomaly detection models can also be used to detect malicious activities inside distributed systems, it is important to understand their robustness against evasive manipulations in adversarial environments. Although there are various attacks against deep learning models in domains such as natural language processing and image classification, they cannot be applied directly to evade anomaly detection from distributed system logs. In this work, we explore the adversarial robustness of deep learning-based anomaly detection models on distributed system logs. We propose a real-time attack method called LAM (Log Anomaly Mask) to perturb streaming logs with minimal modifications in an online fashion so that the attacks can evade anomaly detection by even the state-of-the-art deep learning models. To overcome the search space complexity challenge, LAM models the perturber as a reinforcement learning agent that operates in a partially observable environment to predict the best perturbation action. We have evaluated the effectiveness of LAM on two log-based anomaly detection systems for distributed systems: DeepLog and an AutoEncoder-based anomaly detection system. Our experimental results show that LAM significantly reduces the true positive rate of these two models while achieving attack imperceptibility and real-time responsiveness. © 2021 ACM.},
  document_type = {Conference Paper},
  doi           = {10.1145/3422337.3447833},
  groups        = {First Filtering},
  journal       = {CODASPY 2021 - Proceedings of the 11th ACM Conference on Data and Application Security and Privacy},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104999796&doi=10.1145%2f3422337.3447833&partnerID=40&md5=aedc254bc70702e6a6807fee3cc31bb6},
}

@Article{Sudheera20216591,
  author        = {Sudheera, K.L.K. and Divakaran, D.M. and Singh, R.P. and Gurusamy, M.},
  journal       = {IEEE Internet of Things Journal},
  title         = {ADEPT: Detection and Identification of Correlated Attack Stages in IoT Networks},
  year          = {2021},
  note          = {cited By 0},
  number        = {8},
  pages         = {6591-6607},
  volume        = {8},
  abstract      = {The fast-growing Internet-of-Things (IoT) market has opened up a large threat landscape, given the wide deployment of IoT devices in both consumer and commercial spaces. Attacks on IoT devices generally consist of multiple stages and are dispersed spatially and temporally. These characteristics make it challenging to detect and identify the attack stages using solutions that tend to be localized in space and time. In this work, we present Adept, a distributed framework to detect and identify the individual attack stages in a coordinated attack. Adept works in three phases. First, network traffic of IoT devices is processed locally for detecting anomalies with respect to their benign profiles. Any alert corresponding to a potential anomaly is sent to a security manager, where aggregated alerts are mined, using frequent itemset mining (FIM), for detecting patterns correlated across both time and space. Finally, using both alert-level and pattern-level information as features, we employ a machine learning approach to identify individual attack stages in the generated alerts. We carry out extensive experiments, with emulated and realistic network traffic; the results demonstrate the effectiveness of the proposed framework in terms of its ability in attack-stage detection and identification. © 2014 IEEE.},
  art_number    = {9343343},
  document_type = {Article},
  doi           = {10.1109/JIOT.2021.3055937},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100824245&doi=10.1109%2fJIOT.2021.3055937&partnerID=40&md5=a28c972afb50d464f4480d673a5dfb61},
}

@Conference{Mirzaeian2021319,
  author        = {Mirzaeian, A. and Kosecka, J. and Homayoun, H. and Mohsenin, T. and Sasan, A.},
  title         = {Diverse knowledge distillation (dkd): A solution for improving the robustness of ensemble models against adversarial attacks},
  year          = {2021},
  note          = {cited By 0},
  pages         = {319-324},
  volume        = {2021-April},
  abstract      = {This paper proposes an ensemble learning model that is resistant to adversarial attacks. To build resilience, we introduced a training process where each member learns a radically distinct latent space. Member models are added one at a time to the ensemble. Simultaneously, the loss function is regulated by a reverse knowledge distillation, forcing the new member to learn different features and map to a latent space safely distanced from those of existing members. We assessed the security and performance of the proposed solution on image classification tasks using CIFAR10 and MNIST datasets and showed security and performance improvement compared to the state of the art defense methods. © 2021 IEEE.},
  art_number    = {9424353},
  document_type = {Conference Paper},
  doi           = {10.1109/ISQED51717.2021.9424353},
  groups        = {First Filtering},
  journal       = {Proceedings - International Symposium on Quality Electronic Design, ISQED},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106015519&doi=10.1109%2fISQED51717.2021.9424353&partnerID=40&md5=01a33219916bdde5a788cb606a3a7861},
}

@Conference{Irfan202191,
  author        = {Irfan, M.M. and Ali, S. and Yaqoob, I. and Zafar, N.},
  title         = {Towards Deep Learning: A Review on Adversarial Attacks},
  year          = {2021},
  note          = {cited By 0},
  pages         = {91-96},
  abstract      = {Attacker determines their targets strategically and deliberately depend on vulnerabilities they have ascertained. Organization and individuals mostly try to protect themselves from one occurrence or type on an attack. Still, they have to acknowledge that the attacker may easily move focus to advanced uncovered vulnerabilities. Even if someone successfully tackles several attacks, risks remain, and the need to face threats will happen for the predictable future. Machine learning algorithms have earned much popularity in artificial intelligence (A.I) in the modern era. Large organizations like Google, Facebook, and Microsoft use large volumes of user data to train machine learning models. Then they use it for social ads. Like these days, Whatsapp will make a new privacy policy to share their data on Facebook. That data may be used for companies advertisements in future. So, in this way, the privacy of an individual might be breech out. Due to the high probability of attacks and the leakage of sensitive data in deep learning on distributive computation, adversarial examples demonstrated the vulnerability of machine learning techniques in terms of robustness. Besides, this allowed adversaries to make use of the vulnerability to target machine learning systems. Although adversarial attacks on real-world applications did not occur until recently, it is difficult to inject an artificial adversary to the model that is being hosted without infringement of the reliability. Recently few attacks occur in terms of facial recognition, road signs classification by finally, the difference between theoretical methodologies for the generation of adversarial examples and practical schemes of attacks on real-world applications. To direct future studies in the real defence of adversarial examples in real-world applications, For realistic attacks, we integrate the threat model with adversarial examples and give an overview with future direction. © 2021 IEEE.},
  art_number    = {9445247},
  document_type = {Conference Paper},
  doi           = {10.1109/ICAI52203.2021.9445247},
  groups        = {First Filtering},
  journal       = {2021 International Conference on Artificial Intelligence, ICAI 2021},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108101811&doi=10.1109%2fICAI52203.2021.9445247&partnerID=40&md5=eb9126c9b8c4603f3be78be2c8bcec62},
}

@Article{Hongsong20213505,
  author        = {Hongsong, C. and Yongpeng, Z. and Yongrui, C. and Bhargava, B.},
  journal       = {Wireless Personal Communications},
  title         = {Security Threats and Defensive Approaches in Machine Learning System Under Big Data Environment},
  year          = {2021},
  note          = {cited By 0},
  number        = {4},
  pages         = {3505-3525},
  volume        = {117},
  abstract      = {Under big data environment, machine learning has been rapidly developed and widely used. It has been successfully applied in computer vision, natural language processing, computer security and other application fields. However, there are many security problems in machine learning under big data environment. For example, attackers can add “poisoned” sample to the data source, and big data process system will process these “poisoned” sample and use machine learning methods to train model, which will directly lead to wrong prediction results. In this paper, machine learning system and machine learning pipeline are proposed. The security problems that maybe occur in each stage of machine learning system under big data processing pipeline are analyzed comprehensively. We use four different attack methods to compare the attack experimental results.The security problems are classified comprehensively, and the defense approaches to each security problem are analyzed. Drone-deploy MapEngine is selected as a case study, we analyze the security threats and defense approaches in the Drone-Cloud machine learning application envirolment. At last,the future development drections of security issues and challenages in the machine learning system are proposed. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC part of Springer Nature.},
  document_type = {Article},
  doi           = {10.1007/s11277-021-08284-8},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100852779&doi=10.1007%2fs11277-021-08284-8&partnerID=40&md5=aba7ec5d6c3947fd124b31360d4d6798},
}

@Article{Kim2021,
  author        = {Kim, K. and Kim, J.S. and Jeong, S. and Park, J.-H. and Kim, H.K.},
  journal       = {Computers and Security},
  title         = {Cybersecurity for autonomous vehicles: Review of attacks and defense},
  year          = {2021},
  note          = {cited By 2},
  volume        = {103},
  abstract      = {As technology has evolved, cities have become increasingly smart. Smart mobility is a crucial element in smart cities, and autonomous vehicles are an essential part of smart mobility. However, vulnerabilities in autonomous vehicles can be damaging to quality of life and human safety. For this reason, many security researchers have studied attacks and defenses for autonomous vehicles. However, there has not been systematic research on attacks and defenses for autonomous vehicles. In this survey, we analyzed previously conducted attack and defense studies described in 151 papers from 2008 to 2019 for a systematic and comprehensive investigation of autonomous vehicles. We classified autonomous attacks into the three categories of autonomous control system, autonomous driving systems components, and vehicle-to-everything communications. Defense against such attacks was classified into security architecture, intrusion detection, and anomaly detection. Due to the development of big data and communication technologies, techniques for detecting abnormalities using artificial intelligence and machine learning are gradually being developed. Lastly, we provide implications based on our systemic survey that future research on autonomous attacks and defenses is strongly combined with artificial intelligence and major component of smart cities. © 2021},
  art_number    = {102150},
  document_type = {Review},
  doi           = {10.1016/j.cose.2020.102150},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099436265&doi=10.1016%2fj.cose.2020.102150&partnerID=40&md5=8ce949e02c35ceab0ef280d434a6cfac},
}

@Article{Kumar20213749,
  author        = {Kumar, P. and Gupta, G.P. and Tripathi, R.},
  journal       = {Arabian Journal for Science and Engineering},
  title         = {Toward Design of an Intelligent Cyber Attack Detection System using Hybrid Feature Reduced Approach for IoT Networks},
  year          = {2021},
  note          = {cited By 2},
  number        = {4},
  pages         = {3749-3778},
  volume        = {46},
  abstract      = {With simple connectivity and fast-growing demand of smart devices and networks, IoT has become more prone to cyber attacks. In order to detect and prevent cyber attacks in IoT networks, intrusion detection system (IDS) plays a crucial role. However, most of the existing IDS have dimensionality curse that reduces overall IoT systems efficiency. Hence, it is important to remove repetitive and irrelevant features while designing effective IDS. Motivated from aforementioned challenges, this paper presents an intelligent cyber attack detection system for IoT network using a novel hybrid feature reduced approach. This technique first performs feature ranking using correlation coefficient, random forest mean decrease accuracy and gain ratio to obtain three different feature sets. Then, features are combined using a suitably designed mechanism (AND operation), to obtain single optimized feature set. Finally, the obtained reduced feature set is fed to three well-known machine learning algorithms such as random forest, K-nearest neighbor and XGBoost for detection of cyber attacks. The efficiency of the proposed cyber attack detection framework is evaluated using NSL-KDD and two latest IoT-based datasets namely, BoT-IoT and DS2OS. Performance of the proposed framework is evaluated and compared with some recent state-of-the-art techniques found in literature, in terms of accuracy, detection rate (DR), precision and F1 score. Performance analysis using these three datasets shows that the proposed model has achieved DR up to 90%–100%, for most of the attack vectors that has close similarity to normal behaviors and accuracy above 99%. © 2021, King Fahd University of Petroleum & Minerals.},
  document_type = {Article},
  doi           = {10.1007/s13369-020-05181-3},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099398082&doi=10.1007%2fs13369-020-05181-3&partnerID=40&md5=f8731abcdfcb5c1189d9d52798a7ffc8},
}

@Article{Gu2021,
  author        = {Gu, J. and Lu, S.},
  journal       = {Computers and Security},
  title         = {An effective intrusion detection approach using SVM with naïve Bayes feature embedding},
  year          = {2021},
  note          = {cited By 1},
  volume        = {103},
  abstract      = {Network security has become increasingly important in recent decades, while intrusion detection system plays a critical role in protecting it. Various machine learning techniques have been applied to intrusion detection, among which SVM has been considered as an effective method. However, existing studies rarely take the data quality into consideration, which is essential for constructing a well-performed intrusion detection system beyond machine learning techniques. In this paper, we propose an effective intrusion detection framework based on SVM with naïve Bayes feature embedding. Specifically, the naïve Bayes feature transformation technique is implemented on the original features to generate new data with high quality; then, an SVM classifier is trained using the transformed data to build the intrusion detection model. Experiments on multiple datasets in intrusion detection domain validate that the proposed detection method can achieve good and robust performances, with 93.75% accuracy on UNSW-NB15 dataset, 98.92% accuracy on CICIDS2017 dataset, 99.35% accuracy on NSL-KDD dataset and 98.58% accuracy on Kyoto 2006+ dataset. Furthermore, our method possesses huge advantages in terms of accuracy, detection rate and false alarm rate when compared to other methods. © 2020 Elsevier Ltd},
  art_number    = {102158},
  document_type = {Article},
  doi           = {10.1016/j.cose.2020.102158},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099341233&doi=10.1016%2fj.cose.2020.102158&partnerID=40&md5=876f32c3180df6a5953ffb352b1a3184},
}

@Article{ShivaDarshan20211057,
  author        = {Shiva Darshan, S.L. and Jaidhar, C.D.},
  journal       = {IEEE Transactions on Emerging Topics in Computing},
  title         = {Windows malware detector using convolutional neural network based on visualization images},
  year          = {2021},
  note          = {cited By 1},
  number        = {2},
  pages         = {1057-1069},
  volume        = {9},
  abstract      = {The evolution of malware is continuing at an alarming rate, despite the efforts made towards detecting and mitigating them. Malware analysis is needed to defend against its sophisticated behaviour. However, the manual heuristic inspection is no longer effective or efficient. To cope with these critical issues, behaviour-based malware detection approaches with machine learning techniques have been widely adopted as a solution. It involves supervised classifiers to appraise their predictive performance on gaining the most relevant features from the original features' set and the trade-off between high detection rate and low computation overhead. Though machine learning-based malware detection techniques have exhibited success in detecting malware, their shallow learning architecture is still deficient in identifying sophisticated malware. Therefore, in this paper, a Convolutional Neural Network (CNN) based Windows malware detector has been proposed that uses the execution time behavioural features of the Portable Executable (PE) files to detect and classify obscure malware. The 10-fold cross-validation tests were conducted to assess the proficiency of the proposed approach. The experimental results showed that the proposed approach was effective in uncovering malware PE files by utilizing significant behavioural features suggested by the Relief Feature Selection Technique. It attained detection accuracy of 97.968 percent. © 2013 IEEE.},
  art_number    = {8685181},
  document_type = {Article},
  doi           = {10.1109/TETC.2019.2910086},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064682828&doi=10.1109%2fTETC.2019.2910086&partnerID=40&md5=98fe32d8f99697c9b87c1295ec1a20d0},
}

@Article{Kwon2021,
  author        = {Kwon, H. and Lee, J.},
  journal       = {Symmetry},
  title         = {Diversity adversarial training against adversarial attack on deep neural networks},
  year          = {2021},
  note          = {cited By 2},
  number        = {3},
  volume        = {13},
  abstract      = {This paper presents research focusing on visualization and pattern recognition based on computer science. Although deep neural networks demonstrate satisfactory performance regarding image and voice recognition, as well as pattern analysis and intrusion detection, they exhibit inferior performance towards adversarial examples. Noise introduction, to some degree, to the original data could lead adversarial examples to be misclassified by deep neural networks, even though they can still be deemed as normal by humans. In this paper, a robust diversity adversarial training method against adversarial attacks was demonstrated. In this approach, the target model is more robust to unknown adversarial examples, as it trains various adversarial samples. During the experiment, Tensorflow was employed as our deep learning framework, while MNIST and Fashion-MNIST were used as experimental datasets. Results revealed that the diversity training method has lowered the attack success rate by an average of 27.2 and 24.3% for various adversarial examples, while main-taining the 98.7 and 91.5% accuracy rates regarding the original data of MNIST and Fashion-MNIST. © 2021 by the authors. Liensee MDPI, Basel, Switzerland.},
  art_number    = {428},
  document_type = {Article},
  doi           = {10.3390/sym13030428},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102880327&doi=10.3390%2fsym13030428&partnerID=40&md5=0f0db4bd3e25b918299275511fe31cc9},
}

@Article{Chakraborty202125,
  author        = {Chakraborty, A. and Alam, M. and Dey, V. and Chattopadhyay, A. and Mukhopadhyay, D.},
  journal       = {CAAI Transactions on Intelligence Technology},
  title         = {A survey on adversarial attacks and defences},
  year          = {2021},
  note          = {cited By 1},
  number        = {1},
  pages         = {25-45},
  volume        = {6},
  abstract      = {Deep learning has evolved as a strong and efficient framework that can be applied to a broad spectrum of complex learning problems which were difficult to solve using the traditional machine learning techniques in the past. The advancement of deep learning has been so radical that today it can surpass human-level performance. As a consequence, deep learning is being extensively used in most of the recent day-to-day applications. However, efficient deep learning systems can be jeopardised by using crafted adversarial samples, which may be imperceptible to the human eye, but can lead the model to misclassify the output. In recent times, different types of adversaries based on their threat model leverage these vulnerabilities to compromise a deep learning system where adversaries have high incentives. Hence, it is extremely important to provide robustness to deep learning algorithms against these adversaries. However, there are only a few strong countermeasures which can be used in all types of attack scenarios to design a robust deep learning system. Herein, the authors attempt to provide a detailed discussion on different types of adversarial attacks with various threat models and also elaborate on the efficiency and challenges of recent countermeasures against them. © 2021 The Authors. CAAI Transactions on Intelligence Technology published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology and Chongqing University of Technology.},
  document_type = {Review},
  doi           = {10.1049/cit2.12028},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102833837&doi=10.1049%2fcit2.12028&partnerID=40&md5=7f7cf54c71f4c28ae4ceef67f0c6c5c3},
}

@Article{Aivodji2021,
  author        = {Aivodji, U. and Bidet, F. and Gambs, S. and Ngueveu, R.C. and Tapp, A.},
  journal       = {Algorithms},
  title         = {Local data debiasing for fairness based on generative adversarial training},
  year          = {2021},
  note          = {cited By 0},
  number        = {3},
  volume        = {14},
  abstract      = {The widespread use of automated decision processes in many areas of our society raises serious ethical issues with respect to the fairness of the process and the possible resulting discrimination. To solve this issue, we propose a novel adversarial training approach called GANSan for learning a sanitizer whose objective is to prevent the possibility of any discrimination (i.e., direct and indirect) based on a sensitive attribute by removing the attribute itself as well as the existing correlations with the remaining attributes. Our method GANSan is partially inspired by the powerful framework of generative adversarial networks (in particular Cycle-GANs), which offers a flexible way to learn a distribution empirically or to translate between two different distributions. In contrast to prior work, one of the strengths of our approach is that the sanitization is performed in the same space as the original data by only modifying the other attributes as little as possible, thus preserving the interpretability of the sanitized data. Consequently, once the sanitizer is trained, it can be applied to new data locally by an individual on their profile before releasing it. Finally, experiments on real datasets demonstrate the effectiveness of the approach as well as the achievable trade-off between fairness and utility. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
  art_number    = {87},
  document_type = {Article},
  doi           = {10.3390/a14030087},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102798588&doi=10.3390%2fa14030087&partnerID=40&md5=d02e1f2af05afdfea7ded007f28fdf42},
}

@Article{Shi2021294,
  author        = {Shi, Y. and Davaslioglu, K. and Sagduyu, Y.E.},
  journal       = {IEEE Transactions on Cognitive Communications and Networking},
  title         = {Generative Adversarial Network in the Air: Deep Adversarial Learning for Wireless Signal Spoofing},
  year          = {2021},
  note          = {cited By 0},
  number        = {1},
  pages         = {294-303},
  volume        = {7},
  abstract      = {The spoofing attack is critical to bypass physical-layer signal authentication. This paper presents a deep learning-based spoofing attack to generate synthetic wireless signals that cannot be statistically distinguished from intended transmissions. The adversary is modeled as a pair of a transmitter and a receiver that build the generator and discriminator of the generative adversarial network, respectively, by playing a minimax game over the air. The adversary transmitter trains a deep neural network to generate the best spoofing signals and fool the best defense trained as another deep neural network at the adversary receiver. Each node (defender or adversary) may have multiple transmitter or receiver antennas. Signals are spoofed by jointly capturing waveform, channel, and radio hardware effects that are inherent to wireless signals under attack. Compared with spoofing attacks using random or replayed signals, the proposed attack increases the probability of misclassifying spoofing signals as intended signals for different network topology and mobility patterns. The adversary transmitter can increase the spoofing attack success by using multiple antennas, while the attack success decreases when the defender receiver uses multiple antennas. For practical deployment, the attack implementation on embedded platforms demonstrates the low latency of generating or classifying spoofing signals. © 2015 IEEE.},
  art_number    = {9144305},
  document_type = {Article},
  doi           = {10.1109/TCCN.2020.3010330},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102275140&doi=10.1109%2fTCCN.2020.3010330&partnerID=40&md5=c88f2d80bda24826a03cf2d8fe8e2011},
}

@Article{Li2021,
  author        = {Li, Y. and Xue, W. and Wu, T. and Wang, H. and Zhou, B. and Aziz, S. and He, Y.},
  journal       = {Energy},
  title         = {Intrusion detection of cyber physical energy system based on multivariate ensemble classification},
  year          = {2021},
  note          = {cited By 1},
  volume        = {218},
  abstract      = {The tight coupling of information and communication technology and traditional energy system has given birth to a cyber physical energy system (CPES). CPES indeed improves the economic operation and control efficiency of the energy system, but it also brings new cyber risk issues, threatening the secure operation of the energy system. Consequently, this paper proposes a new multivariate ensemble classification (MEC) method to detect intrusions in CPES, thereby enhancing the baseline cybersecurity of CPES. MEC simultaneously takes into account the detection accuracy, stability and computing efficiency. In MEC, extreme gradient boosting, light gradient boosting machine and extreme learning machine are separately designed as individual detectors for intrusion identification. Then, ensemble learning based decision-making is developed to strategically aggregate the results of all individual detectors. Finally, the effectiveness of the proposed MEC is validated on IEEE standard 14-, 57- and 118-bus systems. The obtained results demonstrate that the MEC method has an attractive potential in real applications. © 2020 Elsevier Ltd},
  art_number    = {119505},
  document_type = {Article},
  doi           = {10.1016/j.energy.2020.119505},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097793944&doi=10.1016%2fj.energy.2020.119505&partnerID=40&md5=152ed53ea834b8b73c3bc4b824ec89ec},
}

@Article{Shafee2021,
  author        = {Shafee, A. and Awaad, T.A.},
  journal       = {Journal of Systems Architecture},
  title         = {Privacy attacks against deep learning models and their countermeasures},
  year          = {2021},
  note          = {cited By 1},
  volume        = {114},
  abstract      = {Recently, deep learning is considered an important concept that is used in a lot of important applications, which require accurate models, such as image classification, identification of audio, intrusion detection, and face recognition. However, building a good deep learning model needs a huge amount of data that is not easily provided, especially in the applications that need sensitive information. Accordingly, researchers propose multiple methodologies for sharing the model rather than sharing the dataset itself. Nevertheless, it has been proven that the shared models still could leak a lot of sensitive information about the private data. In this work, we introduce a survey about the attacks that could be launched against the shared models and the countermeasures that could be taken to preserve the privacy of the sensitive data that is used for the training process. © 2020 Elsevier B.V.},
  art_number    = {101940},
  document_type = {Review},
  doi           = {10.1016/j.sysarc.2020.101940},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097039138&doi=10.1016%2fj.sysarc.2020.101940&partnerID=40&md5=1dbdaeb5fa88a05e011b5169415dbf6c},
}

@Article{Zhang202157,
  author        = {Zhang, C. and Tang, Z. and Zuo, Y. and Li, K. and Li, K.},
  journal       = {Information Sciences},
  title         = {A robust generative classifier against transfer attacks based on variational auto-encoders},
  year          = {2021},
  note          = {cited By 1},
  pages         = {57-70},
  volume        = {550},
  abstract      = {Deep neural networks (DNNs) are vulnerable to adversarial examples. Even under black-box setting that is without access to the target model, transfer-based attacks can easily fool the DNNs. To alleviate this problem, we propose a robust classification model against transfer attacks based on the framework of variational Auto-Encoders (VAEs) which are probabilistic generative models and have been successfully used to a large mount of tasks. Specifically, our model simulates the data generative process with several multivariate Gaussian distributions and DNNs: (1) We assume that the latent embedding generated by an encoder (a DNN) of each category corresponds to a multivariate Gaussian distribution. (2) A decoder (a DNN) is proposed to decodes the latent embedding into an observable. (3) Theoretical analysis illustrates that our model can predict data's labels by maximizing the lower bound on the log-likelihood for each category utilizing Bayes’ theorem with excellent robustness against transfer attacks. Inference in our model is done in a variational way so the Stochastic Gradient Variational Bayes (SGVB) estimator and reparamerization trick can be utilized to optimize the evidence lower bound (ELBO). The experiments with quantitative comparisons show that our approach reaches state-of-the-art with significantly better robustness. © 2020 Elsevier Inc.},
  document_type = {Article},
  doi           = {10.1016/j.ins.2020.10.044},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095602989&doi=10.1016%2fj.ins.2020.10.044&partnerID=40&md5=1a01b1f0f3d4a100d0d4ddda13e65f9f},
}

@Article{Protogerou202119,
  author        = {Protogerou, A. and Papadopoulos, S. and Drosou, A. and Tzovaras, D. and Refanidis, I.},
  journal       = {Evolving Systems},
  title         = {A graph neural network method for distributed anomaly detection in IoT},
  year          = {2021},
  note          = {cited By 1},
  number        = {1},
  pages         = {19-36},
  volume        = {12},
  abstract      = {Recent IoT proliferation has undeniably affected the way organizational activities and business procedures take place within several IoT domains such as smart manufacturing, food supply chain, intelligent transportation systems, medical care infrastructures etc. The number of the interconnected edge devices has dramatically increased, creating a huge volume of transferred data susceptible to leakage, modification or disruption, ultimately affecting the security level, robustness and QoS of the attacked IoT ecosystem. In an attempt to prevent or mitigate network abnormalities while accommodating the cohesiveness among the involved entities, modeling their interrelations and incorporating their structural, content and temporal attributes, graph-based anomaly detection solutions have been repeatedly adopted. In this article we propose, a multi-agent system, with each agent implementing a Graph Neural Network, in order to exploit the collaborative and cooperative nature of intelligent agents for anomaly detection. To this end, against the propagating nature of cyber-attacks such as the Distributed Denial-of-Service (DDoS), we propose a distributed detection scheme, which aims to monitor efficiently the entire network infrastructure. To fulfill this task, we consider employing monitors on active network nodes such as IoT devices, SDN forwarders, Fog Nodes, achieving localization of anomaly detection, distribution of allocated resources such as the bandwidth and power consumption and higher accuracy results. In order to facilitate the training, testing and evaluation activities of the Graph Neural Network algorithm, we create simulated datasets of network flows of various normal and abnormal distributions, out of which we extract essential structural and content features to be passed to neighbouring agents. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.},
  document_type = {Article},
  doi           = {10.1007/s12530-020-09347-0},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087056425&doi=10.1007%2fs12530-020-09347-0&partnerID=40&md5=df0e48347d44fdbc9798deacc2ed0b18},
}

@Article{Kumar202147,
  author        = {Kumar, V. and Das, A.K. and Sinha, D.},
  journal       = {Evolutionary Intelligence},
  title         = {UIDS: a unified intrusion detection system for IoT environment},
  year          = {2021},
  note          = {cited By 3},
  number        = {1},
  pages         = {47-59},
  volume        = {14},
  abstract      = {Intrusion detection system (IDS) using machine learning approach is getting popularity as it has an advantage of getting updated by itself to defend against any new type of attack. Another emerging technology, called internet of things (IoT) is taking the responsibility to make automated system by communicating the devices without human intervention. In IoT based systems, the wireless communication between several devices through the internet causes vulnerability for different security threats. This paper proposes a novel unified intrusion detection system for IoT environment (UIDS) to defend the network from four types of attacks such as: exploit, DoS, probe, and generic. The system is also able to detect normal category of network traffic. Most of the related works on IDS are based on KDD99 or NSL-KDD 99 data sets which are unable to detect new type of attacks. In this paper, UNSW-NB15 data set is considered as the benchmark dataset to design UIDS for detecting malicious activities in the network. The performance analysis proves that the attack detection rate of the proposed model is higher compared to two existing approaches ENADS and DENDRON which also worked on UNSW-NB15 data set. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.},
  document_type = {Article},
  doi           = {10.1007/s12065-019-00291-w},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074022230&doi=10.1007%2fs12065-019-00291-w&partnerID=40&md5=70baf73e8ab035a87232fa5efa168af1},
}

@Article{Ge2021,
  author        = {Ge, M. and Syed, N.F. and Fu, X. and Baig, Z. and Robles-Kelly, A.},
  journal       = {Computer Networks},
  title         = {Towards a deep learning-driven intrusion detection approach for Internet of Things},
  year          = {2021},
  note          = {cited By 3},
  volume        = {186},
  abstract      = {Internet of Things (IoT) as a paradigm comes with a range of benefits to humanity. Domains of research for the IoT range from healthcare automation to energy and transport. However, due to their limited resources, IoT devices are vulnerable to various types of cyber attacks as carried out by the adversary. In this paper, we propose a novel intrusion detection approach for the IoT, through the adoption of a customised deep learning technique. We utilise a cutting-edge IoT dataset comprising IoT traces and realistic attack traffic, including denial of service, distributed denial of service, data gathering and data theft attacks. A feed-forward neural networks model with embedding layers (to encode high-dimensional categorical features) for multi-class classification, is developed. The concept of transfer learning is subsequently applied to encode high-dimensional categorical features to build a binary classifier based on a second feed-forward neural networks model. We obtain results through the evaluation of the proposed approach which demonstrate a high classification accuracy for both classifiers, namely, binary and multi-class. © 2021 Elsevier B.V.},
  art_number    = {107784},
  document_type = {Article},
  doi           = {10.1016/j.comnet.2020.107784},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099006810&doi=10.1016%2fj.comnet.2020.107784&partnerID=40&md5=fbc17b4b8e78490c6363101e18e95d03},
}

@Article{Papadogiannaki20211,
  author        = {Papadogiannaki, E. and Ioannidis, S.},
  journal       = {Sensors (Switzerland)},
  title         = {Acceleration of intrusion detection in encrypted network traffic using heterogeneous hardware},
  year          = {2021},
  note          = {cited By 0},
  number        = {4},
  pages         = {1-21},
  volume        = {21},
  abstract      = {More than 75% of Internet traffic is now encrypted, and this percentage is constantly increasing. The majority of communications are secured using common encryption protocols such as SSL/TLS and IPsec to ensure security and protect the privacy of Internet users. However, encryption can be exploited to hide malicious activities, camouflaged into normal network traffic. Traditionally, network traffic inspection is based on techniques like deep packet inspection (DPI). Common applications for DPI include but are not limited to firewalls, intrusion detection and prevention systems, L7 filtering, and packet forwarding. With the widespread adoption of network encryption though, DPI tools that rely on packet payload content are becoming less effective, demanding the development of more sophisticated techniques in order to adapt to current network encryption trends. In this work, we present Header Hunter, a fast signature-based intrusion detection system even for encrypted network traffic. We generate signatures using only network packet metadata extracted from packet headers. In addition, we examine the processing acceleration of the intrusion detection engine using different heterogeneous hardware architectures. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
  art_number    = {1140},
  document_type = {Article},
  doi           = {10.3390/s21041140},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100489900&doi=10.3390%2fs21041140&partnerID=40&md5=bfbe8bcf33dcc1f2654d7a30313513dd},
}

@Article{Keyvanpour20211601,
  author        = {Keyvanpour, M.R. and Barani Shirzad, M. and Mehmandoost, S.},
  journal       = {Journal of Ambient Intelligence and Humanized Computing},
  title         = {CID: a novel clustering-based database intrusion detection algorithm},
  year          = {2021},
  note          = {cited By 0},
  number        = {2},
  pages         = {1601-1612},
  volume        = {12},
  abstract      = {At the same time with the increase in the data volume, attacks against the database are also rising, therefore information security and confidentiality became a critical challenge. One promised solution against malicious attacks is the intrusion detection system. In this paper, anomaly detection concept is used to propose a method for distinguishing between normal and abnormal activities. For this purpose, a new density-based clustering intrusion detection (CID) method is proposed which clusters queries based on a similarity measure and labels them as normal or intrusion. The experiments are conducted on two standard datasets including TPC-C and TPC-E. The results show proposed model outperforms state-of-the-art algorithms as baselines in terms of FN, FP, Precision, Recall and F-score measures. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.},
  document_type = {Article},
  doi           = {10.1007/s12652-020-02231-4},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087135634&doi=10.1007%2fs12652-020-02231-4&partnerID=40&md5=fa0cb2d02eb8a11d76d1472f4d1fa19c},
}

@Conference{Takiddin20211590,
  author        = {Takiddin, A. and Ismail, M. and Zafar, U. and Serpedin, E.},
  title         = {Variational auto-encoder-based detection of electricity stealth cyber-attacks in AMI networks},
  year          = {2021},
  note          = {cited By 0},
  pages         = {1590-1594},
  volume        = {2021-January},
  abstract      = {Current efforts to detect electricity theft cyber-attacks in advanced metering infrastructures (AMIs) are hindered by the lack of malicious electricity theft datasets. Therefore, anomaly detectors trained with the energy consumption profiles of honest customers appear as a plausible solution to overcome the lack of malicious datasets. Taking into account this constraint, this paper examines the performance of two structures of variational auto-encoders (VAEs); fully-connected (FC) VAE and long-short-term-memory (LSTM) VAE in detecting electricity thefts. The proposed structures are promising and exhibit an improvement of 11 - 15% in detection rate, 9 - 22% in false alarm rate, and 27 - 37% in the highest difference compared to existing state-of-the-art anomaly detectors that are shallow and static, such as single-class support vector machine (SVM) and auto-regressive integrated moving average (ARIMA) models. © 2021 European Signal Processing Conference, EUSIPCO. All rights reserved.},
  art_number    = {9287764},
  document_type = {Conference Paper},
  doi           = {10.23919/Eusipco47968.2020.9287764},
  groups        = {First Filtering},
  journal       = {European Signal Processing Conference},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099319671&doi=10.23919%2fEusipco47968.2020.9287764&partnerID=40&md5=651cacf32165426ae52d168c6ef2a4c1},
}

@Article{Esmaeili2021,
  author        = {Esmaeili, B. and Akhavanpour, A. and Sabokrou, M.},
  journal       = {Electronics Letters},
  title         = {Maximising robustness and diversity for improving the deep neural network safety},
  year          = {2021},
  note          = {cited By 0},
  abstract      = {This article proposes a novel yet efficient defence method against adversarial attack(er)s aimed to improve the safety of deep neural networks. Removing the adversarial noise by refining adversarial samples as a defence strategy is widely investigated in previous works. Such methods are simply broken if an attacker has access to both main and refiner networks. To cope with this weakness, the authors propose to refine the input samples relying on a set of encoder–decoders, which are trained in such a way to reconstruct the samples on completely different feature spaces. To this end, the authors learn several encoder–decoder networks and force their latent spaces to have a maximum diversion. In this way, if attacker gets access to one of the refiner networks, other ones can play as a defence network. The evaluation of the proposed method confirms its performance against adversarial samples. © 2021 The Authors. Electronics Letters published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology},
  document_type = {Letter},
  doi           = {10.1049/ell2.12070},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108909117&doi=10.1049%2fell2.12070&partnerID=40&md5=84b862ff2b0c9b95c96c834ce3f393a7},
}

@Conference{Carey2021,
  author        = {Carey, A.N. and Mai, H. and Zhan, J. and Mehmood, A.},
  title         = {Adversarial attacks against image-based malware detection using autoencoders},
  year          = {2021},
  note          = {cited By 0},
  volume        = {11735},
  abstract      = {Over the past decade, deep learning approaches have been applied to the detection of malicious software, otherwise known as malware. Despite their improved performance compared to conventional detection methods such as static and dynamic analysis, however, deep learning-based malware detection systems have been shown to be vulnerable to adversarial attacks. Few image-based malware detection systems have been proposed, especially those that evaluate their performance against adversarial attacks. Furthermore, little research has been done beyond the classification of malware targeted at Windows (PE) or Android systems, leaving entire realms such as Mac (Mach-O), Linux (ELF), and embedded software unexplored and unprotected. These realms, specifically embedded software, are used in critical technology such as avionic systems and special care must be taken to ensure their safety. In this paper, we present an image-based malware detection system on PE, ELF, MachO, and embedded C code files. The system’s architecture incorporates layers of encoders that are taken from independently-trained autoencoders and multi-layer perceptron that returns the output of the network. We evaluate the performance of the system against adversarial attacks, or the misclassification of a malware file as a benign, by adding gradient based perturbations to unused sections of the malware often referred to as the slack bits. The network achieves an accuracy of 96.51% on non-adversarial PE and ELF files, 95.45% on transfer learned non-adversarial Mach-O files, and 99.2% on transfer learned non-adversarial synthetic plane files. For the classification of adversarial examples, the network achieved a 81% success rate of misclassification on adversarial PE and ELF files and a 99% success rate of misclassification on adversarial synthetic plane files. © 2021 SPIE},
  art_number    = {117350A},
  document_type = {Conference Paper},
  doi           = {10.1117/12.2587923},
  groups        = {First Filtering},
  journal       = {Proceedings of SPIE - The International Society for Optical Engineering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108840145&doi=10.1117%2f12.2587923&partnerID=40&md5=57cf557425de7c57d1099a48cd82aa71},
}

@Article{Yin2021,
  author        = {Yin, H. and Zhang, H. and Wang, J. and Dou, R.},
  journal       = {Security and Communication Networks},
  title         = {Boosting Adversarial Attacks on Neural Networks with Better Optimizer},
  year          = {2021},
  note          = {cited By 0},
  volume        = {2021},
  abstract      = {Convolutional neural networks have outperformed humans in image recognition tasks, but they remain vulnerable to attacks from adversarial examples. Since these data are crafted by adding imperceptible noise to normal images, their existence poses potential security threats to deep learning systems. Sophisticated adversarial examples with strong attack performance can also be used as a tool to evaluate the robustness of a model. However, the success rate of adversarial attacks can be further improved in black-box environments. Therefore, this study combines a modified Adam gradient descent algorithm with the iterative gradient-based attack method. The proposed Adam iterative fast gradient method is then used to improve the transferability of adversarial examples. Extensive experiments on ImageNet showed that the proposed method offers a higher attack success rate than existing iterative methods. By extending our method, we achieved a state-of-the-art attack success rate of 95.0% on defense models. © 2021 Heng Yin et al.},
  art_number    = {9983309},
  document_type = {Article},
  doi           = {10.1155/2021/9983309},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108579189&doi=10.1155%2f2021%2f9983309&partnerID=40&md5=2b9cba0290831f0f563211d97e0d41c0},
}

@Article{Enthoven2021173,
  author        = {Enthoven, D. and Al-Ars, Z.},
  journal       = {Studies in Computational Intelligence},
  title         = {An Overview of Federated Deep Learning Privacy Attacks and Defensive Strategies},
  year          = {2021},
  note          = {cited By 0},
  pages         = {173-196},
  volume        = {965},
  abstract      = {With the increased attention and legislation for data-privacy, collaborative machine learning (ML) algorithms are being developed to ensure the protection of private data used for processing. Federated learning (FL) is the most popular of these methods, which provides privacy preservation by facilitating collaborative training of a shared model without the need to exchange any private data with a centralized server. Rather, an abstraction of the data in the form of a machine learning model update is sent. Recent studies showed that such model updates may still very well leak private information and thus a more structured risk assessment is needed. In this chapter, we analyze existing vulnerabilities of FL and subsequently perform a literature review of the possible attack methods targeting FL privacy protection capabilities. These attack methods are then categorized by a basic taxonomy. Additionally, we provide a literature study of the most recent defensive strategies and algorithms for FL aimed to overcome these attacks. These defensive strategies are categorized by their respective underlying defense principle. The chapter advocates that the application of a single defensive strategy is not enough to provide adequate protection against all available attack methods. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
  document_type = {Book Chapter},
  doi           = {10.1007/978-3-030-70604-3_8},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108192475&doi=10.1007%2f978-3-030-70604-3_8&partnerID=40&md5=b893ed60a282c13250704e589a9b1275},
}

@Article{Jatain2021,
  author        = {Jatain, D. and Singh, V. and Dahiya, N.},
  journal       = {Journal of King Saud University - Computer and Information Sciences},
  title         = {A contemplative perspective on federated machine learning: Taxonomy, threats & vulnerability assessment and challenges},
  year          = {2021},
  note          = {cited By 0},
  abstract      = {Today, the rapid growth of the internet and advancements in mobile technology and increased internet connectivity have brought us to a data-driven economy where an enormous amount of data is being used to train machine learning models to make strategic decisions. However, in the aftermath of a data breach by Facebook in 2018, there are some serious concerns over user data privacy and security being used to train the Machine Learning models. In this context, a new approach, Federated Machine Learning is now one of the most talked-about and recent approaches. Current research primarily focuses on Federated Learning's advantages over the traditional methods and/or its classification. However, being in a nascent stage of development as a method, certain challenges need to be addressed. This paper intends to address the totality of federated learning with a complete vulnerability assessment. During the study of the literature, it is found that security being promised as one of the key advantages of federated learning can still not be guaranteed because of some issues inherently present, and this can lead to poisoning, inference attacks and insertion of backdoors, etc. This paper intends to provide a complete picture by giving an in-depth and comprehensive analysis of Federated Learning and its taxonomy. It also provides a detailed vulnerability assessment and highlights the challenges faced in the current setting and future research directions to make federated learning a more functional, robust and secure method to train machine learning models. © 2021 The Authors},
  document_type = {Review},
  doi           = {10.1016/j.jksuci.2021.05.016},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108078935&doi=10.1016%2fj.jksuci.2021.05.016&partnerID=40&md5=4b97c15d8eafdc684023f5a003591f85},
}

@Article{Almaslukh20211343,
  author        = {Almaslukh, B.},
  journal       = {Computers, Materials and Continua},
  title         = {Deep learning and entity embedding-based intrusion detection model for wireless sensor networks},
  year          = {2021},
  note          = {cited By 0},
  number        = {1},
  pages         = {1343-1360},
  volume        = {69},
  abstract      = {Wireless sensor networks (WSNs) are considered promising for applications such as military surveillance and healthcare. The security of these networks must be ensured in order to have reliable applications. Securing such networks requires more attention, as they typically implement no dedicated security appliance. In addition, the sensors have limited computing resources and power and storage, which makes WSNs vulnerable to various attacks, especially denial of service (DoS). The main types of DoS attacks against WSNs are blackhole, grayhole, flooding, and scheduling. There are two primary techniques to build an intrusion detection system (IDS): signature-based and data-driven-based. This study uses the data-driven approach since the signature-based method fails to detect a zero-day attack. Several publications have proposed data-driven approaches to protect WSNs against such attacks. These approaches are based on either the traditional machine learning (ML) method or a deep learning model. The fundamental limitations of these methods include the use of raw features to build an intrusion detection model, which can result in low detection accuracy. This study implements entity embedding to transform the raw features to a more robust representation that can enable more precise detection and demonstrates how the proposed method can outperform state-of-the-art solutions in terms of recognition accuracy. © 2021 Tech Science Press. All rights reserved.},
  document_type = {Article},
  doi           = {10.32604/cmc.2021.017914},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107801395&doi=10.32604%2fcmc.2021.017914&partnerID=40&md5=9ae15b5f4ac9173afbf484317883c6fe},
}

@Article{Yue202159527,
  author        = {Yue, C. and Wang, L. and Wang, D. and Duo, R. and Nie, X.},
  journal       = {IEEE Access},
  title         = {An Ensemble Intrusion Detection Method for Train Ethernet Consist Network Based on CNN and RNN},
  year          = {2021},
  note          = {cited By 0},
  pages         = {59527-59539},
  volume        = {9},
  abstract      = {The train Ethernet Consist Network (ECN) undertakes the task of transmitting critical train control instructions. With the increasing interactions between the train network and the outside environment, masses of network intrusions are threatening the data security of railway vehicles. The intrusion detection system has been proved to be an efficient method to detect network attacks. In this paper, a novel ensemble intrusion detection method is proposed to defense network attacks against the train ECN, in particular IP Scan, Port Scan, Denial of Service (DoS) and Man in the Middle (MITM). Thirty-four features of different protocol contents are extracted from the raw data generated from our ECN testbed to form a specific dataset. A data imaging method and a temporal sequence building method are designed to optimize the dataset. Six base classifiers are built based on several typical convolutional neural networks and recurrent neural networks: LeNet-5, AlexNet, VGGNet, SimpleRNN, LSTM and GRU. A dynamic weight matrix voting method is proposed to integrate all the base classifiers. The proposed method is evaluated based on our dataset. The experiment results show that our method has an outstanding ability to aggregate advantages of all the base classifiers and achieves a superior detection performance with the accuracy of 0.975. © 2013 IEEE.},
  art_number    = {9405676},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2021.3073413},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107228668&doi=10.1109%2fACCESS.2021.3073413&partnerID=40&md5=b36329f1a6f677b6ab3f8021ec0c87ca},
}

@Conference{Gómez2021573,
  author        = {Gómez, Á.L.P. and Maimó, L.F. and Celdrán, A.H. and García Clemente, F.J. and Cleary, F.},
  title         = {Crafting adversarial samples for anomaly detectors in industrial control systems},
  year          = {2021},
  note          = {cited By 0},
  pages         = {573-580},
  volume        = {184},
  abstract      = {The increasing adoption of the Industry 4.0 paradigm encompasses digitally interconnected factories which enables many advantages. However, it is still necessary to dedicate effort towards investigating protection mechanisms against cyberattacks in these scenarios. Despite the power demonstrated by Anomaly Detection-based Intrusion Detection Systems in industrial scenarios, their vulnerabilities to adversarial attacks, especially to evasion attacks, make Machine Learning and Deep Learning models ineffective for real scenarios. These type of attacks craft samples misclassified by the Intrusion Detection System and potentially reach industrial devices, causing potentially damaging impacts to factory workers and industry resources. Adversarial attacks linked to industrial scenarios are currently in early stages of development, hence most of them have the capability to craft samples misclassified by the IDS but not reach industrial devices. In this work, we present a new adversarial attack named Selective and Iterative Gradient Sign Method that overcomes the limitation of the adversarial attacks present in the literature. To complement this work we also detail a study of how the detection rate of an Intrusion Detection System is degraded and the time required by each technique to generate adversarial samples. The experiments were carried out using a dataset named Electra, collected from an Electric Traction Substation, and showed that adversarial attacks evaluated crafted samples misclassified by the IDS. However, only the method we proposed generated samples that can be understood by intermediate network devices and, therefore, reach their destination. Our experiment outputs demonstrate a lower period of time to achieve and craft adversarial samples using out our iterative based process method as opposed to other current iterative methods currently available. © 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)},
  document_type = {Conference Paper},
  doi           = {10.1016/j.procs.2021.03.072},
  groups        = {First Filtering},
  journal       = {Procedia Computer Science},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106726514&doi=10.1016%2fj.procs.2021.03.072&partnerID=40&md5=c2e1686aa96126df66d06c52a42c7507},
}

@Article{Adel2021441,
  author        = {Adel, A. and Sarwar, D. and Hosseinian-Far, A.},
  journal       = {Advanced Sciences and Technologies for Security Applications},
  title         = {Transformation of Cybersecurity Posture in IT Telecommunication: A Case Study of a Telecom Operator},
  year          = {2021},
  note          = {cited By 0},
  pages         = {441-457},
  abstract      = {Organisations are facing sophisticated and advanced persistent threats (APT) that are targeting sensitive information assets. Any form of cyber-presence can be typically attacked by adversaries, and the motives of such attacks are context dependent. Besides, users and organisations are prone to software vulnerabilities, misconfigurations, outdated systems and several other systemic deficiencies which can be leveraged to compromise enterprise assets and gain an initial foothold within an organisation network. The aim of the paper is to develop a flexible and generally comprehensive organisational strategy to defend against the massive increase in cyberattacks, in order to protect the strategic business objectives of an organisation and keep an alignment between business objectives and security. Moreover, this paper reflects on the work undertaken by multiple teams within the chosen case study organisation to enhance the cybersecurity. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
  document_type = {Book Chapter},
  doi           = {10.1007/978-3-030-68534-8_28},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106433077&doi=10.1007%2f978-3-030-68534-8_28&partnerID=40&md5=ddaee5bb9256dd2229b7643ae50e0466},
}

@Article{Munonye2021,
  author        = {Munonye, K. and Péter, M.},
  journal       = {International Journal of Information Security},
  title         = {Machine learning approach to vulnerability detection in OAuth 2.0 authentication and authorization flow},
  year          = {2021},
  note          = {cited By 0},
  abstract      = {Technologies for integrating enterprise web applications have improved rapidly over the years. The OAuth framework provides authentication and authorization using the users’ profile and credentials in an existing identity provider. This makes it possible for attackers to exploit any vulnerability arising from exchange of data with the provider. Vulnerability in OAuth authorization flow allows an attacker to alter the normal flow sequence of the OAuth protocol. In this paper, a machine learning-based approach was applied in the detection of potential vulnerability in the OAuth authentication and authorization flow by analyzing the relationship between changes in the OAuth parameters and the final output. This research models the OAuth protocol as a supervised learning problem where seven classification models were developed, tuned and evaluated. Exploratory Data Analytics (EDA) techniques were applied in the extraction and analysis of specific OAuth features so that each output class could be evaluated to determine the effect of the identified OAuth features. The models developed in this research were trained, tuned and tested. A performance accuracy above 90% was attained for detection of vulnerabilities in the OAuth authentication and authorization flow. Comparison with known vulnerability resulted in a 54% match. © 2021, The Author(s).},
  document_type = {Article},
  doi           = {10.1007/s10207-021-00551-w},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105942433&doi=10.1007%2fs10207-021-00551-w&partnerID=40&md5=c712fd37bfdd00f662f7c9f6ca7a2d34},
}

@Article{Chen20213412,
  author        = {Chen, J. and Zhang, X. and Zhang, R. and Wang, C. and Liu, L.},
  journal       = {IEEE Transactions on Information Forensics and Security},
  title         = {De-Pois: An Attack-Agnostic Defense against Data Poisoning Attacks},
  year          = {2021},
  note          = {cited By 0},
  pages         = {3412-3425},
  volume        = {16},
  abstract      = {Machine learning techniques have been widely applied to various applications. However, they are potentially vulnerable to data poisoning attacks, where sophisticated attackers can disrupt the learning procedure by injecting a fraction of malicious samples into the training dataset. Existing defense techniques against poisoning attacks are largely attack-specific: they are designed for one specific type of attacks but do not work for other types, mainly due to the distinct principles they follow. Yet few general defense strategies have been developed. In this paper, we propose De-Pois, an attack-agnostic defense against poisoning attacks. The key idea of De-Pois is to train a mimic model the purpose of which is to imitate the behavior of the target model trained by clean samples. We take advantage of Generative Adversarial Networks (GANs) to facilitate informative training data augmentation as well as the mimic model construction. By comparing the prediction differences between the mimic model and the target model, De-Pois is thus able to distinguish the poisoned samples from clean ones, without explicit knowledge of any ML algorithms or types of poisoning attacks. We implement four types of poisoning attacks and evaluate De-Pois with five typical defense methods on different realistic datasets. The results demonstrate that De-Pois is effective and efficient for detecting poisoned data against all the four types of poisoning attacks, with both the accuracy and F1-score over 0.9 on average. © 2005-2012 IEEE.},
  art_number    = {9431105},
  document_type = {Article},
  doi           = {10.1109/TIFS.2021.3080522},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105889773&doi=10.1109%2fTIFS.2021.3080522&partnerID=40&md5=f365d684ebfcd581812876b975c56d6b},
}

@Article{Cheong202168302,
  author        = {Cheong, M.-S. and Wu, M.-C. and Huang, S.-H.},
  journal       = {IEEE Access},
  title         = {Interpretable Stock Anomaly Detection Based on Spatio-Temporal Relation Networks with Genetic Algorithm},
  year          = {2021},
  note          = {cited By 0},
  pages         = {68302-68319},
  volume        = {9},
  abstract      = {Instability in financial markets represents a considerable risk to investors; examples of instability include a market crash caused by systematic risks and abnormal stock price volatility caused by artificial hype. The early detection of abnormal behavior can help investors adjust their strategy and reduce investment risks. We proposed a spatiotemporal convolutional neural network-based relational network (STCNN-RN) model that can learn the complex correlations between multiple financial time-series data sets, and we used genetic algorithms with a constrained gene to discover the time points for outlier companies by fitting the STCNN-RN model; we used these outlier points to identify abnormal situations. Most research on identifying anomalous patterns has been unable to sufficiently explain the reason for anomalies to investors. We applied an interpretability model to enable investors to understand these anomalous time points in relation to companies and discover the key factors giving rise to the anomalies. The experiment results revealed that the proposed model can be used to model multiple financial time-series data sets and to capture anomalous situations in relevant companies. Because this study explored the discovery of anomaly phenomena in all transaction data and the explanation of these abnormalities, investors can understand a stock market situation holistically. © 2013 IEEE.},
  art_number    = {9420709},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2021.3077067},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105887511&doi=10.1109%2fACCESS.2021.3077067&partnerID=40&md5=5a63869861cfb13d62bdd6786f228cd5},
}

@Article{Vaiyapuri20213271,
  author        = {Vaiyapuri, T. and Binbusayyis, A.},
  journal       = {Computers, Materials and Continua},
  title         = {Enhanced deep autoencoder based feature representation learning for intelligent intrusion detection system},
  year          = {2021},
  note          = {cited By 0},
  number        = {3},
  pages         = {3271-3288},
  volume        = {68},
  abstract      = {In the era of Big data, learning discriminant feature representation from network traffic is identified has as an invariably essential task for improving the detection ability of an intrusion detection system (IDS). Owing to the lack of accurately labeled network traffic data, many unsupervised feature representation learning models have been proposed with state-of-theart performance.Yet, these models fail to consider the classification error while learning the feature representation. Intuitively, the learnt feature representation may degrade the performance of the classification task. For the first time in the field of intrusion detection, this paper proposes an unsupervised IDS model leveraging the benefits of deep autoencoder (DAE) for learning the robust feature representation and one-class support vector machine (OCSVM) for finding the more compact decision hyperplane for intrusion detection. Specially, the proposed model defines a new unified objective function to minimize the reconstruction and classification error simultaneously. This unique contribution not only enables the model to support joint learning for feature representation and classifier training but also guides to learn the robust feature representation which can improve the discrimination ability of the classifier for intrusion detection. Three set of evaluation experiments are conducted to demonstrate the potential of the proposed model. First, the ablation evaluation on benchmark dataset, NSL-KDD validates the design decision of the proposed model. Next, the performance evaluation on recent intrusion dataset,UNSW-NB15 signifies the stable performance of the proposed model. Finally, the comparative evaluation verifies the efficacy of the proposed model against recently published state-of-the-art methods. © 2021 Tech Science Press. All rights reserved.},
  document_type = {Article},
  doi           = {10.32604/cmc.2021.017665},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105646752&doi=10.32604%2fcmc.2021.017665&partnerID=40&md5=5d18814b9e308a95e1f19f017d921970},
}

@Article{Sivaslioglu202133,
  author        = {Sivaslioglu, S. and Catak, F.O. and Şahinbaş, K.},
  journal       = {Informatica (Slovenia)},
  title         = {A generative model based adversarial security of deep learning and linear classifier models},
  year          = {2021},
  note          = {cited By 0},
  number        = {1},
  pages         = {33-64},
  volume        = {45},
  abstract      = {In recent years, machine learning algorithms have been applied widely in various fields such as health, transportation, and the autonomous car. With the rapid developments of deep learning techniques, it is critical to take the security concern into account for the application of the algorithms. While machine learning offers significant advantages in terms of the application of algorithms, the issue of security is ignored. Since it has many applications in the real world, security is a vital part of the algorithms. In this paper, we have proposed a mitigation method for adversarial attacks against machine learning models with an autoencoder model that is one of the generative ones. The main idea behind adversarial attacks against machine learning models is to produce erroneous results by manipulating trained models. We have also presented the performance of autoencoder models to various attack methods from deep neural networks to traditional algorithms by using different methods such as non-targeted and targeted attacks to multi-class logistic regression, a fast gradient sign method, a targeted fast gradient sign method and a basic iterative method attack to neural networks for the MNIST dataset. © 2021 Slovene Society Informatika. All rights reserved.},
  document_type = {Article},
  doi           = {10.31449/inf.v45i1.3234},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105477697&doi=10.31449%2finf.v45i1.3234&partnerID=40&md5=658d72f2e461241bd00bcf8b2e9d4a93},
}

@Article{Guo2021,
  author        = {Guo, S. and Zhao, J. and Li, X. and Duan, J. and Mu, D. and Jing, X.},
  journal       = {Security and Communication Networks},
  title         = {A Black-Box Attack Method against Machine-Learning-Based Anomaly Network Flow Detection Models},
  year          = {2021},
  note          = {cited By 0},
  volume        = {2021},
  abstract      = {In recent years, machine learning has made tremendous progress in the fields of computer vision, natural language processing, and cybersecurity; however, we cannot ignore that machine learning models are vulnerable to adversarial examples, with some minor malicious input modifications, while appearing unmodified to human observers, the outputs of machine learning-based model can be misled easily. Likewise, attackers can bypass machine-learning-based security defenses model to attack systems in real time by generating adversarial examples. In this paper, we propose a black-box attack method against machine-learning-based anomaly network flow detection algorithms. Our attack strategy consists in training another model to substitute for the target machine learning model. Based on the overall understanding of the substitute model and the migration of the adversarial examples, we use the substitute model to craft adversarial examples. The experiment has shown that our method can attack the target model effectively. We attack several kinds of network flow detection models, which are based on different kinds of machine learning methods, and we find that the adversarial examples crafted by our method can bypass the detection of the target model with high probability. © 2021 Sensen Guo et al.},
  art_number    = {5578335},
  document_type = {Article},
  doi           = {10.1155/2021/5578335},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105421012&doi=10.1155%2f2021%2f5578335&partnerID=40&md5=88706a9829a9726a846b28bb88ea42f2},
}

@Article{Zhang2021107,
  author        = {Zhang, R. and Liu, D. and Zhao, W. and Liu, Q. and Zhu, C.},
  journal       = {Communications in Computer and Information Science},
  title         = {A Simple yet Effective Unsupervised Adversarial Example Generation Framework for Vulnerability Assessment on Deep Learning},
  year          = {2021},
  note          = {cited By 0},
  pages         = {107-122},
  volume        = {1352 CCIS},
  abstract      = {Generating adversarial examples to discover the vulnerability of deep learning model is critical yet challenging. Although adversarial sample generation methods have attracted the attention of lots of recent research, they heavily depend on supervised label information. As a result, they could only work on a specific classification task and fail to evaluate the vulnerability of unsupervised deep learning models. In this paper, we propose a simple yet effective unsupervised adversarial example generation framework for vulnerability assessment of deep learning. This framework achieves an effective unsupervised adversarial example generation by jointly maximizing the distribution divergence of the deep learning model-generated representations of regular examples and adversarial examples and minimizing the dissimilarity between regular examples and adversarial examples in the original space. In this way, the adversarial examples generated by this framework can mislead downstream tasks while camouflaging themselves. We further implement this framework to an adversarial image generation methods to demonstrate the performance of the proposed framework. Extensive experiments on four benchmarks demonstrate that the proposed method can find the vulnerability of the LeNet5 (a widely used deep learning model) much more effective even compared to state-of-the-art supervised competitors. © 2021, Springer Nature Singapore Pte Ltd.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-981-16-1877-2_8},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104764976&doi=10.1007%2f978-981-16-1877-2_8&partnerID=40&md5=575780a1b178a66a12dee0b35fbb8144},
}

@Article{Bostik2021,
  author        = {Bostik, O. and Horak, K. and Kratochvila, L. and Zemcik, T. and Bilik, S.},
  journal       = {Neural Computing and Applications},
  title         = {Semi-supervised deep learning approach to break common CAPTCHAs},
  year          = {2021},
  note          = {cited By 0},
  abstract      = {Manual data annotation is a time consuming activity. A novel strategy for automatic training of the CAPTCHA breaking system with no manual dataset creation is presented in this paper. We demonstrate the feasibility of the attack against a text-based CAPTCHA scheme utilizing similar network infrastructure used for Denial of Service attacks. The main goal of our research is to present a possible vulnerability in CAPTCHA systems when combining the brute-force attack with transfer learning. The classification step utilizes a simple convolutional neural network with 15 layers. Training stage uses automatically prepared dataset created without any human intervention and transfer learning for fine-tuning the deep neural network classifier. The designed system for breaking text-based CAPTCHAs achieved 80% classification accuracy after 6 fine-tuning steps for a 5 digit text-based CAPTCHA system. The results presented in this paper suggest, that even the simple attack with a large number of attacking computers can be an effective alternative to current CAPTCHA breaking systems. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.},
  document_type = {Article},
  doi           = {10.1007/s00521-021-05957-0},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104497839&doi=10.1007%2fs00521-021-05957-0&partnerID=40&md5=d914aac93de0000cfd4437eeafe04cf0},
}

@Article{Wu2021,
  author        = {Wu, Z. and Yin, Y. and Li, G. and Yue, M.},
  journal       = {Security and Communication Networks},
  title         = {Coherent detection of synchronous low-rate DoS attacks},
  year          = {2021},
  note          = {cited By 0},
  volume        = {2021},
  abstract      = {Low-rate denial-of-service (LDoS) attacks are characterized by low average rate and periodicity. Under certain conditions, the high concealment of LDoS attacks enables them to transfer the attack stream to the network without being detected at all before the end. In this article, plenty of LDoS attack traffic is spread to the victim end to detect LDoS attacks. Through experimental analysis, it is found that the attack pulses at the victim end have sequence correlation, so the coherence detection technology in spread spectrum communication is proposed to detect LDoS attacks. Therefore, this paper proposes an attack detection method based on coherent detection, which adopts bivariate cyclic convolution algorithm. Similar to the generation of receiving terminal phase dry detection code in spread spectrum communication, we construct a local detection sequence to complete the extraction of LDoS attack stream from the background traffic of the victim terminal, that is, the coherent detection of LDoS attacks. When predicting the features of an LDoS attack, how to construct the parameters of the detection sequence (such as period, pulse duration, amplitude, and so on) is very important. In this paper, we observe the correlation of LDoS attacks and use coherence detection to detect LDoS attacks. By comparing calculated cross-correlation values with designed double threshold rules, the existence of attacks can be determined. The simulation platform and experiments show that this method has high detection performance. Copyright © 2021 Zhijun Wu et al. This is an open access article distributed under the Creative Commons Attribution License},
  art_number    = {6694264},
  document_type = {Article},
  doi           = {10.1155/2021/6694264},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104484959&doi=10.1155%2f2021%2f6694264&partnerID=40&md5=df868cbc2e49c037f37384e8471e2f6d},
}

@Article{Bozdal202158621,
  author        = {Bozdal, M. and Samie, M. and Jennions, I.K.},
  journal       = {IEEE Access},
  title         = {WINDS: A Wavelet-Based Intrusion Detection System for Controller Area Network (CAN)},
  year          = {2021},
  note          = {cited By 0},
  pages         = {58621-58633},
  volume        = {9},
  abstract      = {Vehicles are equipped with Electronic Control Units (ECUs) to increase their overall system functionality and connectivity. However, the rising connectivity exposes a defenseless internal Controller Area Network (CAN) to cyberattacks. An Intrusion Detection System (IDS) is a supervisory module, proposed for identifying CAN network malicious messages, without modifying legacy ECUs and causing high traffic overhead. The traditional IDS approaches rely on time and frequency thresholding, leading to high false alarm rates, whereas state-of-the-art solutions may suffer from vehicle dependency. This paper presents a wavelet-based approach to locating the behavior change in the CAN traffic by analyzing the CAN network's transmission pattern. The proposed Wavelet-based Intrusion Detection System (WINDS) is tested on various attack scenarios, using real vehicle traffic from two independent research centers, while being expanded toward more comprehensive attack scenarios using synthetic attacks. The technique is evaluated and compared against the state-of-the-art solutions and the baseline frequency method. Experimental results show that WINDS offers a vehicle-independent solution applicable for various vehicles through a unique approach while generating low false alarms. © 2013 IEEE.},
  art_number    = {9402263},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2021.3073057},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104268867&doi=10.1109%2fACCESS.2021.3073057&partnerID=40&md5=505f1be63d0fe502b7cd61f10c843f5a},
}

@Article{Kabaso2021701,
  author        = {Kabaso, B. and Aradeh, S.A. and Abidoye, A.P.},
  journal       = {International Journal of Advanced Computer Science and Applications},
  title         = {Attack Resilient Trust and Signature-based Intrusion Detection Systems},
  year          = {2021},
  note          = {cited By 0},
  number        = {3},
  pages         = {701-707},
  volume        = {12},
  abstract      = {Wireless sensor networks have been widely applied in many areas due to their unique characteristics. These have exposed them to different types of active and passive attacks. In the literature, several solutions have been proposed to mitigate these attacks. Most of the proposed solutions are too complex to be implemented in wireless sensor networks considering the resource-constraint of sensor nodes. In this work, we proposed a hierarchical trust mechanism based on clustering approach to detect and prevent denial of service attacks in wireless sensor networks. The approach was validated through simulation using Network Simulator (NS2). The following metrics were used to evaluation the proposed scheme: packet delivery ratio, network lifetime, routing delay, overhead, and number of nodes. The proposed approach is capable of detecting compromised sensor nodes vulnerable to a denial of service attacks. Moreover, it is able to detect all sensed data that have been compromised during transmission to the base station. The results show that our method can effectively detect and defend against denial of service attacks in sensor wireless sensor networks. © 2021. All Rights Reserved.},
  document_type = {Article},
  doi           = {10.14569/IJACSA.2021.0120381},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104053964&doi=10.14569%2fIJACSA.2021.0120381&partnerID=40&md5=67c8de482aa62cb92cf70455a3a16147},
}

@Conference{Hatua202135,
  author        = {Hatua, A. and Mukherjee, A. and Verma, R.M.},
  title         = {On the feasibility of using GANs for claim verification - Experiments and analysis},
  year          = {2021},
  note          = {cited By 0},
  pages         = {35-46},
  volume        = {2838},
  abstract      = {The research on fact checking and claim verification has been explored using the Fact Extraction and VERification (FEVER) dataset. To supplement this research a Generative Adversarial Network (GAN) based model is used for fact checking on the FEVER dataset. The GAN based model generates synthetic data in an extended feature space of the FEVER dataset and gives leverage to new features. This synthetically generated data is further classified using positive-unlabeled (PU) learning considering supported facts as positive class and are added to the existing training dataset. Bidirectional Encoder Representations from Transformers (BERT) based encoding technique is used for both original and newly generated data to get the text's underline context. Due to the Information Gain in the synthetically generated data features, better performance is achieved in the fact checking and claim verification task. A thorough analysis of the model selection is done by comparing the GAN based model with BERT based classifier and other standard classifiers. © 2021 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
  document_type = {Conference Paper},
  groups        = {First Filtering},
  journal       = {CEUR Workshop Proceedings},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103517205&partnerID=40&md5=b830420c265ac26d4b39060a3a8596b3},
}

@Article{Catak2021280,
  author        = {Catak, F.O. and Yayilgan, S.Y.},
  journal       = {Communications in Computer and Information Science},
  title         = {Deep Neural Network Based Malicious Network Activity Detection Under Adversarial Machine Learning Attacks},
  year          = {2021},
  note          = {cited By 0},
  pages         = {280-291},
  volume        = {1382},
  abstract      = {Machine learning-based computational intelligence methods are used more often recently in the cybersecurity area, especially for malicious network activity detection. ML based solutions have been used and discussed by a significant number of authors in literature. Several methods, including deep learning, are used to develop models for solving this issue. So far, attackers try to generate malicious activities in a network to put down several system services or steal some information from the databases. More recent designs of security components use predictive modeling approach to detect such kind of attacks. Thus, the new target for the attackers is machine learning algorithm itself. Previous studies in cybersecurity have almost exclusively focused on attack detection in a network. Another promising line of attack detection research would be machine learning algorithm protection. There are some attacks against deep learning models in the literature, including fast-gradient sign method (FGSM) attack. This attack is the purest form of the gradient-based evading technique that is used by attackers to evade the classification model. This paper presents a new approach to protect a malicious activity detection model from the FGSM attack. Hence, we explore the power of applying adversarial training to build a robust model against FGSM attacks. Accordingly, (1) dataset enhanced with the adversarial examples; (2) deep neural network-based detection model is trained using the KDDCUP99 dataset to learn the FGSM based attack patterns. We applied this training model to the benchmark cyber security dataset. © 2021, Springer Nature Switzerland AG.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-71711-7_23},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103479801&doi=10.1007%2f978-3-030-71711-7_23&partnerID=40&md5=39f0a86da4869aa44bbb7ff802ceb338},
}

@Article{Wang2021105,
  author        = {Wang, W. and Tang, P. and Xiong, L. and Jiang, X.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {RADAR: Recurrent Autoencoder Based Detector for Adversarial Examples on Temporal EHR},
  year          = {2021},
  note          = {cited By 0},
  pages         = {105-121},
  volume        = {12460 LNAI},
  abstract      = {Leveraging the information-rich and large volume of Electronic Health Records (EHR), deep learning systems have shown great promise in assisting medical diagnosis and regulatory decisions. Although deep learning models have advantages over the traditional machine learning approaches in the medical domain, the discovery of adversarial examples has exposed great threats to the state-of-art deep learning medical systems. While most of the existing studies are focused on the impact of adversarial perturbation on medical images, few works have studied adversarial examples and potential defenses on temporal EHR data. In this work, we propose RADAR, a Recurrent Autoencoder based Detector for Adversarial examples on temporal EHR data, which is the first effort to defend adversarial examples on temporal EHR data. We evaluate RADAR on a mortality classifier using the MIMIC-III dataset. Experiments show that RADAR can filter out more than 90% of adversarial examples and improve the target model accuracy by more than 90 % and F1 score by 60%. Besides, we also propose an enhanced attack by introducing the distribution divergence into the loss function such that the adversarial examples are more realistic and difficult to detect. © 2021, Springer Nature Switzerland AG.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-67667-4_7},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103300260&doi=10.1007%2f978-3-030-67667-4_7&partnerID=40&md5=ab7885e50d71a1f9667c46049376f3e9},
}

@Article{Wang2021,
  author        = {Wang, L. and Yang, J. and Xu, X. and Wan, P.-J.},
  journal       = {Wireless Communications and Mobile Computing},
  title         = {Mining Network Traffic with the k-Means Clustering Algorithm for Stepping-Stone Intrusion Detection},
  year          = {2021},
  note          = {cited By 0},
  volume        = {2021},
  abstract      = {Intruders on the Internet usually launch network attacks through compromised hosts, called stepping stones, in order to reduce the chance of being detected. With stepping-stone intrusions, an attacker uses tools such as SSH to log in several compromised hosts remotely and create an interactive connection chain and then sends attacking packets to a target system. An effective method to detect such an intrusion is to estimate the length of a connection chain. In this paper, we develop an efficient algorithm to detect stepping-stone intrusion by mining network traffic using the k-means clustering. Existing approaches for connection-chain-based stepping-stone intrusion detection either are not effective or require a large number of TCP packets to be captured and processed and, thus, are not efficient. Our proposed detection algorithm can accurately determine the length of a connection chain without requiring a large number of TCP packets being captured and processed, so it is more efficient. Our proposed detection algorithm is also easier to implement than all existing approaches for stepping-stone intrusion detection. The effectiveness, correctness, and efficiency of our proposed detection algorithm are verified through well-designed network experiments. © 2021 Lixin Wang et al.},
  art_number    = {6632671},
  document_type = {Article},
  doi           = {10.1155/2021/6632671},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102743797&doi=10.1155%2f2021%2f6632671&partnerID=40&md5=29b78164d520637dd01f4dab4f3ba0d9},
}

@Article{Merzouk202167,
  author        = {Merzouk, M.A. and Cuppens, F. and Boulahia-Cuppens, N. and Yaich, R.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {A Deeper Analysis of Adversarial Examples in Intrusion Detection},
  year          = {2021},
  note          = {cited By 0},
  pages         = {67-84},
  volume        = {12528 LNCS},
  abstract      = {During the last decade, machine learning algorithms have massively integrated the defense arsenal made available to security professionals, especially for intrusion detection. However, and despite the progress made in this area, machine learning models have been found to be vulnerable to slightly modified data samples called adversarial examples. Thereby, a small and well-computed perturbation may allow adversaries to evade intrusion detection systems. Numerous works have already successfully applied adversarial examples to network intrusion detection datasets. Yet little attention was given so far to the practicality of these examples in the implementation of end-to-end network attacks. In this paper, we study the applicability of network attacks based on adversarial examples in real networks. We minutely analyze adversarial examples generated with state-of-the-art algorithms to evaluate their consistency based on several criteria. Our results show a large proportion of invalid examples that are unlikely to lead to real attacks. © 2021, Springer Nature Switzerland AG.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-68887-5_4},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102650054&doi=10.1007%2f978-3-030-68887-5_4&partnerID=40&md5=fc645b5a52feb9a3b943d7e253644e72},
}

@Article{Meenakshi2021564,
  author        = {Meenakshi, K. and Maragatham, G.},
  journal       = {International Journal of Advanced Computer Science and Applications},
  title         = {A Self Supervised Defending Mechanism Against Adversarial Iris Attacks based on Wavelet Transform},
  year          = {2021},
  note          = {cited By 0},
  number        = {2},
  pages         = {564-569},
  volume        = {12},
  abstract      = {In biometric applications, deep neural networks have presented significant improvements. However, when presenting carefully designed input training data known as adversarial examples, their output is severely reduced. These types of attacks are termed as adversarial attacks, and any biometric security system is greatly affected by these attacks. In the proposed work, an effective defensive mechanism has been developed against adversarial attacks which are introduced in iris images. The proposed defensive mechanism is following the concept of wavelet domain processing and it investigates the mid and high frequency components of wavelet domain components. Based on this, the model reproduces the various denoised copies of input iris images. The proposed strategies are intended to denoise each sub-band of the wavelet domain and assess the sub-bands most likely to be affected by the adversary using the reconstruction error measured for each sub-band. We test the effectiveness of the proposed adversarial protection mechanism against various attack methods and analyzed the results with other state of the art defense approaches. © 2021. All Rights Reserved.},
  document_type = {Article},
  doi           = {10.14569/IJACSA.2021.0120270},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102038491&doi=10.14569%2fIJACSA.2021.0120270&partnerID=40&md5=c9b29f13a749bcb5e13e6cb93ac322a0},
}

@Article{Filus202179,
  author        = {Filus, K. and Domańska, J. and Gelenbe, E.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {Random Neural Network for Lightweight Attack Detection in the IoT},
  year          = {2021},
  note          = {cited By 1},
  pages         = {79-91},
  volume        = {12527 LNCS},
  abstract      = {Cyber-attack detection has become a basic component of all information processing systems, and once an attack is detected it may be possible to block or mitigate its effects. This paper addresses the use of a learning recurrent Random Neural Network (RNN) to build a lightweight detector for certain types of Botnet attacks on IoT systems. Its low computational cost based on a small 12-neuron recurrent architecture makes it particularly attractive for edge devices. The RNN can be trained off-line using a fast simplified gradient descent algorithm, and we show that it can lead to high detection rates of the order of 96%, with false alarm rates of a few percent. © 2021, Springer Nature Switzerland AG.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-68110-4_5},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101812161&doi=10.1007%2f978-3-030-68110-4_5&partnerID=40&md5=7112849ba8961e1fb387e4917fa17038},
}

@Article{Ren20211,
  author        = {Ren, K. and Meng, Q. and Yan, S. and Qin, Z.},
  journal       = {Chinese Journal of Network and Information Security},
  title         = {Survey of artificial intelligence data security and privacy protection},
  year          = {2021},
  note          = {cited By 0},
  number        = {1},
  pages         = {1-10},
  volume        = {7},
  abstract      = {Artificial intelligence and deep learning algorithms are developing rapidly. These emerging techniques have been widely used in audio and video recognition, natural language processing and other fields. However, in recent years, researchers have found that there are many security risks in the current mainstream artificial intelligence model, and these problems will limit the development of AI. Therefore, the data security and privacy protection was studied in AI. For data and privacy leakage, the model output based and model update based problem of data leakage were studied. In the model output based problem of data leakage, the principles and research status of model extraction attack, model inversion attack and membership inference attack were discussed. In the model update based problem of data leakage, how attackers steal private data in the process of distributed training was discussed. For data and privacy protection, three kinds of defense methods, namely model structure defense, information confusion defense and query control defense were studied. In summarize, the theoretical foundations, classic algorithms of data inference attack techniques were introduced. A few research efforts on the defense techniques were described in order to provoke further research efforts in this critical area. © 2021, Beijing Xintong Media Co., Ltd. All rights reserved.},
  document_type = {Article},
  doi           = {10.11959/j.issn.2096-109x.2021001},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101783310&doi=10.11959%2fj.issn.2096-109x.2021001&partnerID=40&md5=6b3cb3c715d0dd8c428eae82342da092},
}

@Article{Ayyarao2021343,
  author        = {Ayyarao, T.S.L.V. and Sureshkumar, L.V. and Vijaya Kumar, D.},
  journal       = {Lecture Notes in Electrical Engineering},
  title         = {Support Vector Machine-Based Dynamic Cyber-Attack Detection in AGC System},
  year          = {2021},
  note          = {cited By 0},
  pages         = {343-355},
  volume        = {702},
  abstract      = {This paper presents novel dynamic cyber-attack detection in automatic generation control (AGC) using support vector machine (SVM). The basic idea of attack detection is based on the pattern recognition of the residual signal of the linear observer designed to estimate the states of the AGC system. Features are extracted from the residual and its derivative signal and are trained using SVM. The proposed idea is tested for various types of attack signals © 2021, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-981-15-8439-8_28},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101515874&doi=10.1007%2f978-981-15-8439-8_28&partnerID=40&md5=abd6ffce8605102b47855d2ef7ff8ef0},
}

@Article{Jaber2021550,
  author        = {Jaber, A.N. and Anwar, S. and Khidzir, N.Z.B. and Anbar, M.},
  journal       = {Communications in Computer and Information Science},
  title         = {A Detailed Analysis on Intrusion Identification Mechanism in Cloud Computing and Datasets},
  year          = {2021},
  note          = {cited By 0},
  pages         = {550-573},
  volume        = {1347},
  abstract      = {Today, rather than utilizing high-powered workstation/desktop to access Internet services, users can use small portable devices for this purpose. As such, the computing power is provided via the innovative cloud computing technology, in which computations are performed in remote huge data centers. Applications are conveyed as services on the web in the field of cloud computing. Despite most organizations show significant interest in cloud computing, many clients are not willing to move their vital information to the clouds due to security concern (hacking). Data storage security is one of the greatest challenges in implementing cloud computing. If this issue is not addressed properly, it would hinder the growth of cloud computing. This research study provides a detailed analysis on intrusion identification mechanism in the cloud computing and datasets on the bases of our in-depth understanding. © 2021, Springer Nature Singapore Pte Ltd.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-981-33-6835-4_37},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101513658&doi=10.1007%2f978-981-33-6835-4_37&partnerID=40&md5=88cd9f6be4892e08990e96da8917bb1e},
}

@Article{Harshvardhan2021,
  author        = {Harshvardhan, G.M. and Gourisaria, M.K. and Rautaray, S.S. and Pandey, M.},
  journal       = {Journal of King Saud University - Computer and Information Sciences},
  title         = {UBMTR: Unsupervised Boltzmann machine-based time-aware recommendation system},
  year          = {2021},
  note          = {cited By 2},
  abstract      = {Visual media, in today's world, has swept across most forms of day to day communication. In the paradigm of generative modelling, restricted Boltzmann machines (RBMs) are used to solve complex tasks such as feature extraction, neuroimaging, collaborative filtering, radar target cognition, etc. In this paper, we implement an unsupervised Boltzmann machine-based time-aware recommendation system (UBMTR) which detects underlying hidden features in user-movie ratings data in connection with the time at which each rating was made (temporal information). The model takes ratings and time as a dual-input and outputs binary values via the contrastive divergence algorithm which samples from a Monte Carlo Markov Chain. Arguably, there exists a correlation between the content requested and the temporal conditions, which is exactly what our model tries to exploit. There is seldom any work in the field of recommender systems built using Boltzmann machines that incorporate temporal information, which necessitates research in this domain. RBMs are adept at pattern completion to tackle missing values, and can deal with imbalanced datasets and unstructured data by encoding raw data into latent variables. Using RBM, the UBMTR outperforms many earlier made attempts made at recommendation systems done through CF and deep learning or their hybridized models. © 2021 The Authors},
  document_type = {Article},
  doi           = {10.1016/j.jksuci.2021.01.017},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101341991&doi=10.1016%2fj.jksuci.2021.01.017&partnerID=40&md5=5ea414c7f964d364775acfdbeaece910},
}

@Article{Zhang2021,
  author        = {Zhang, D. and Wang, Q.-G. and Feng, G. and Shi, Y. and Vasilakos, A.V.},
  journal       = {ISA Transactions},
  title         = {A survey on attack detection, estimation and control of industrial cyber–physical systems},
  year          = {2021},
  note          = {cited By 1},
  abstract      = {Cyber–physical systems (CPSs) are complex systems that involve technologies such as control, communication, and computing. Nowadays, CPSs have a wide range of applications in smart cities, smart grids, smart manufacturing and intelligent transportation. However, with integration of industrial control systems with modern communication technologies, CPSs would be inevitably exposed to increasing security threats, which could lead to severe degradation of the system performance and even destruction of CPSs. This paper presents a survey on recent advances on security issues of industrial cyber–physical systems (ICPSs). We specifically discuss two typical kinds of attacks, i.e., Denial-of-Service (DoS) attack and Deception attack, and present recent results in terms of attack detection, estimation, and control of ICPSs. Classifications of current studies are analyzed and summarized based on different system modeling and analysis methods. In addition, advantages and disadvantage of various methodologies are also discussed. Finally, the paper concludes with some potential future research directions on secure ICPSs. © 2021 ISA},
  document_type = {Article},
  doi           = {10.1016/j.isatra.2021.01.036},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100650822&doi=10.1016%2fj.isatra.2021.01.036&partnerID=40&md5=d50e51df87d630acf628471ad3aa6daf},
}

@Article{Rashid202131892,
  author        = {Rashid, O.F. and Othman, Z.A. and Zainudin, S. and Samsudin, N.A.},
  journal       = {IEEE Access},
  title         = {DNA Encoding and STR Extraction for Anomaly Intrusion Detection Systems},
  year          = {2021},
  note          = {cited By 0},
  pages         = {31892-31907},
  volume        = {9},
  abstract      = {Deoxyribonucleic acid (DNA) can be used to discover the presence of diseases in the human body. Similarly, its functionality can be leveraged in an intrusion detection system (IDS) to detect attacks against computer systems and network traffic. Various approaches have been proposed for using DNA sequences in IDSs. The most popular is the DNA sequence matching method, which is also used in biology. A technique that uses the DNA sequence in an IDS has previously been proposed to generate a normal signature sequence with an alignment threshold value. However, its detection rate is very low. Therefore, this paper considers the two main factors that affect the detection accuracy via the DNA sequence, DNA encoding and the short tandem repeat (STR) (i.e., the DNA keys and their positions). It then proposes two DNA encoding methods, named DEM3sel, and DEMdif, which differ in terms of the length of the DNA sequence and the network traffic representation. DEM3sel uses three characters to represent all 41 network attributes but uses a single fixed character to distinguish between nominal and numerical attributes. DEMdif uses different characters to represent all the network attributes based on the attribute values and uses a single fixed character to distinguish between nominal and numerical attributes. In all these methods, the Teiresias algorithm is used to extract the short tandem repeat (STR), which includes both the keys and their positions in the network traffic, while the Knuth-Morris-Pratt algorithm is used as a matching process to determine whether the network traffic is normal or an attack. An experiment is conducted to assess the proposed methods' performance on two standard datasets: KDDCup 99 and NSL-KDD. The experiment is run 30 times for each DNA encoding method. The results show that DEM3sel obtains the best result compared with DEMdif, where the detection rate, false alarm rate, and accuracy of detection are 99.58%, 35.53%, and 92.74% respectively. The results also show that using more keys and their positions improves the false alarm rate and the accuracy of DEM3sel by up to 26.48% and 1.75%, respectively. Moreover, the performance of the proposed method DEM3sel is comparable to or better than state-of-the-art algorithms. Thus, it can be concluded that the proposed DNA sequence method is suitable for use in an IDS. © 2013 IEEE.},
  art_number    = {2411},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2021.3055431},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100507233&doi=10.1109%2fACCESS.2021.3055431&partnerID=40&md5=744ba1bb6d41019b2e2b982e3c0d34f1},
}

@Article{Ji202141,
  author        = {Ji, S.-L. and Du, T.-Y. and Li, J.-F. and Shen, C. and Li, B.},
  journal       = {Ruan Jian Xue Bao/Journal of Software},
  title         = {Security and Privacy of Machine Learning Models: A Survey [机器学习模型安全与隐私研究综述]},
  year          = {2021},
  note          = {cited By 1},
  number        = {1},
  pages         = {41-67},
  volume        = {32},
  abstract      = {In the era of big data, breakthroughs in theories and technologies of deep learning, reinforcement learning, and distributed learning have provided strong support for machine learning at the data and the algorithm level, as well as have promoted the development of scale and industrialization of machine learning. However, though machine learning models have excellent performance in many real-world applications, they still suffer many security and privacy threats at the data, model, and application levels, which could be characterized by diversity, concealment, and dynamic evolution. The security and privacy issues of machine learning have attracted extensive attention from academia and industry. A large number of researchers have conducted in-depth research on the security and privacy issues of models from the perspective of attack and defense, and proposed a series of attack and defense methods. In this survey, the security and privacy issues of machine learning are reviewed, existing research work is systematically and scientifically summarized, and the advantages and disadvantages of current research are clarified. Finally, the current challenges and future research directions of machine learning model security and privacy research are explored, aiming to provide guidance for follow-up researchers to further promote the development and application of machine learning model security and privacy research. © Copyright 2021, Institute of Software, the Chinese Academy of Sciences. All rights reserved.},
  document_type = {Review},
  doi           = {10.13328/j.cnki.jos.006131},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099098175&doi=10.13328%2fj.cnki.jos.006131&partnerID=40&md5=19ea2dd1eb0ad6a838ca3c7a09c9a262},
}

@Article{Sutanto20211,
  author        = {Sutanto, R.E. and Lee, S.},
  journal       = {Electronics (Switzerland)},
  title         = {Real-time adversarial attack detection with deep image prior initialized as a high-level representation based blurring network},
  year          = {2021},
  note          = {cited By 0},
  number        = {1},
  pages         = {1-17},
  volume        = {10},
  abstract      = {Several recent studies have shown that artificial intelligence (AI) systems can malfunction due to intentionally manipulated data coming through normal channels. Such kinds of manipulated data are called adversarial examples. Adversarial examples can pose a major threat to an AI-led society when an attacker uses them as means to attack an AI system, which is called an adversarial attack. Therefore, major IT companies such as Google are now studying ways to build AI systems which are robust against adversarial attacks by developing effective defense methods. However, one of the reasons why it is difficult to establish an effective defense system is due to the fact that it is difficult to know in advance what kind of adversarial attack method the opponent is using. Therefore, in this paper, we propose a method to detect the adversarial noise without knowledge of the kind of adversarial noise used by the attacker. For this end, we propose a blurring network that is trained only with normal images and also use it as an initial condition of the Deep Image Prior (DIP) network. This is in contrast to other neural network based detection methods, which require the use of many adversarial noisy images for the training of the neural network. Experimental results indicate the validity of the proposed method. © 2020 by the authors. Li-censee MDPI, Basel, Switzerland.},
  art_number    = {52},
  document_type = {Article},
  doi           = {10.3390/electronics10010052},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098854334&doi=10.3390%2felectronics10010052&partnerID=40&md5=d71685968776a62edc3a6f8ee4817a84},
}

@Article{Olowononi2021524,
  author        = {Olowononi, F.O. and Rawat, D.B. and Liu, C.},
  journal       = {IEEE Communications Surveys and Tutorials},
  title         = {Resilient Machine Learning for Networked Cyber Physical Systems: A Survey for Machine Learning Security to Securing Machine Learning for CPS},
  year          = {2021},
  note          = {cited By 5},
  number        = {1},
  pages         = {524-552},
  volume        = {23},
  abstract      = {Cyber Physical Systems (CPS) are characterized by their ability to integrate the physical and information or cyber worlds. Their deployment in critical infrastructure have demonstrated a potential to transform the world. However, harnessing this potential is limited by their critical nature and the far reaching effects of cyber attacks on human, infrastructure and the environment. An attraction for cyber concerns in CPS rises from the process of sending information from sensors to actuators over the wireless communication medium, thereby widening the attack surface. Traditionally, CPS security has been investigated from the perspective of preventing intruders from gaining access to the system using cryptography and other access control techniques. Most research work have therefore focused on the detection of attacks in CPS. However, in a world of increasing adversaries, it is becoming more difficult to totally prevent CPS from adversarial attacks, hence the need to focus on making CPS resilient. Resilient CPS are designed to withstand disruptions and remain functional despite the operation of adversaries. One of the dominant methodologies explored for building resilient CPS is dependent on machine learning (ML) algorithms. However, rising from recent research in adversarial ML, we posit that ML algorithms for securing CPS must themselves be resilient. This article is therefore aimed at comprehensively surveying the interactions between resilient CPS using ML and resilient ML when applied in CPS. The paper concludes with a number of research trends and promising future research directions. Furthermore, with this article, readers can have a thorough understanding of recent advances on ML-based security and securing ML for CPS and countermeasures, as well as research trends in this active research area. © 1998-2012 IEEE.},
  art_number    = {9252851},
  document_type = {Article},
  doi           = {10.1109/COMST.2020.3036778},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098800575&doi=10.1109%2fCOMST.2020.3036778&partnerID=40&md5=bfb0553e19c62ec8d0e92010d2decbbd},
}

@Article{Chen2021,
  author        = {Chen, J. and Wu, D. and Zhao, Y. and Sharma, N. and Blumenstein, M. and Yu, S.},
  journal       = {Digital Communications and Networks},
  title         = {Fooling intrusion detection systems using adversarially autoencoder},
  year          = {2021},
  note          = {cited By 0},
  abstract      = {Due to the increasing cyber-attacks, various Intrusion Detection Systems (IDSs) have been proposed to identify network anomalies. Most existing machine learning-based IDSs learn patterns from the features extracted from network traffic flows, and the deep learning-based approaches can learn data distribution features from the raw data to differentiate normal and anomalous network flows. Although having been used in the real world widely, the above methods are vulnerable to some types of attacks. In this paper, we propose a novel attack framework, Anti-Intrusion Detection AutoEncoder (AIDAE), to generate features to disable the IDS. In the proposed framework, an encoder transforms features into a latent space, and multiple decoders reconstruct the continuous and discrete features, respectively. Additionally, a generative adversarial network is used to learn the flexible prior distribution of the latent space. The correlation between continuous and discrete features can be kept by using the proposed training scheme. Experiments conducted on NSL-KDD, UNSW-NB15, and CICIDS2017 datasets show that the generated features indeed degrade the detection performance of existing IDSs dramatically. © 2020 Chongqing University of Posts and Telecommunications},
  document_type = {Article},
  doi           = {10.1016/j.dcan.2020.11.001},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098686570&doi=10.1016%2fj.dcan.2020.11.001&partnerID=40&md5=ff572f3ee4aafb2128356d613ba593ad},
}

@Article{Zhang2021623,
  author        = {Zhang, Y. and Wang, J. and Chen, B.},
  journal       = {IEEE Transactions on Smart Grid},
  title         = {Detecting False Data Injection Attacks in Smart Grids: A Semi-Supervised Deep Learning Approach},
  year          = {2021},
  note          = {cited By 3},
  number        = {1},
  pages         = {623-634},
  volume        = {12},
  abstract      = {The dependence on advanced information and communication technology increases the vulnerability in smart grids under cyber-attacks. Recent research on unobservable false data injection attacks (FDIAs) reveals the high risk of secure system operation, since these attacks can bypass current bad data detection mechanisms. To mitigate this risk, this paper proposes a data-driven learning-based algorithm for detecting unobservable FDIAs in distribution systems. We use autoencoders for efficient dimension reduction and feature extraction of measurement datasets. Further, we integrate the autoencoders into an advanced generative adversarial network (GAN) framework, which successfully detects anomalies under FDIAs by capturing the unconformity between abnormal and secure measurements. Also, considering that the datasets collected from practical power systems are partially labeled due to expensive labeling costs and missing labels, the proposed method only requires a few labeled measurement data in addition to unlabeled data for training. Numerical simulations in three-phase unbalanced IEEE 13-bus and 123-bus distribution systems validate the detection accuracy and efficiency of this method. © 2010-2012 IEEE.},
  art_number    = {9144530},
  document_type = {Article},
  doi           = {10.1109/TSG.2020.3010510},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098592436&doi=10.1109%2fTSG.2020.3010510&partnerID=40&md5=db82fb75df2754404dc6f9859f913f75},
}

@Article{Nazir20213,
  author        = {Nazir, A. and Khan, R.A.},
  journal       = {Studies in Computational Intelligence},
  title         = {Network Intrusion Detection: Taxonomy and Machine Learning Applications},
  year          = {2021},
  note          = {cited By 0},
  pages         = {3-28},
  volume        = {919},
  abstract      = {Information and Communication Technologies (ICT) has revolutionized our lives and transform it into a knowledge centric world. Where information is available just under few clicks. This advancement introduced different challenges and problems. One big challenge of today’s world is cybersecurity and privacy issues. With every passing day, number of cyber-attacks are increasing. Legacy security solutions like firewalls, antivirus, intrusion detection and prevention systems etc. are not equipped with right technologies to neutralized advance attacks. Recent developments in machine learning, deep learning have shown great potential to deal with modern attack vectors. In this chapter, we will present: (1) Current state of cyber-attacks. (2) Overview of Intrusion Detection Systems and taxonomy. (3) Recent techniques in machine/deep learning being used to detect and defend against novel intrusion. © 2021, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG.},
  document_type = {Book Chapter},
  doi           = {10.1007/978-3-030-57024-8_1},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097904207&doi=10.1007%2f978-3-030-57024-8_1&partnerID=40&md5=61b2d4a188ae8aaaa56e6f57935c2cc9},
}

@Article{Heartfield20211720,
  author        = {Heartfield, R. and Loukas, G. and Bezemskij, A. and Panaousis, E.},
  journal       = {IEEE Transactions on Information Forensics and Security},
  title         = {Self-Configurable Cyber-Physical Intrusion Detection for Smart Homes Using Reinforcement Learning},
  year          = {2021},
  note          = {cited By 0},
  pages         = {1720-1735},
  volume        = {16},
  abstract      = {The modern Internet of Things (IoT)-based smart home is a challenging environment to secure: devices change, new vulnerabilities are discovered and often remain unpatched, and different users interact with their devices differently and have different cyber risk attitudes. A security breach's impact is not limited to cyberspace, as it can also affect or be facilitated in physical space, for example, via voice. In this environment, intrusion detection cannot rely solely on static models that remain the same over time and are the same for all users. We present MAGPIE, the first smart home intrusion detection system that is able to autonomously adjust the decision function of its underlying anomaly classification models to a smart home's changing conditions (e.g., new devices, new automation rules and user interaction with them). The method achieves this goal by applying a novel probabilistic cluster-based reward mechanism to non-stationary multi-armed bandit reinforcement learning. MAGPIE rewards the sets of hyperparameters of its underlying isolation forest unsupervised anomaly classifiers based on the cluster silhouette scores of their output. Experimental evaluation in a real household shows that MAGPIE exhibits high accuracy because of two further innovations: it takes into account both cyber and physical sources of data; and it detects human presence to utilise models that exhibit the highest accuracy in each case. MAGPIE is available in open-source format, together with its evaluation datasets, so it can benefit from future advances in unsupervised and reinforcement learning and be able to be enriched with further sources of data as smart home environments and attacks evolve. © 2005-2012 IEEE.},
  art_number    = {9277640},
  document_type = {Article},
  doi           = {10.1109/TIFS.2020.3042049},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097416784&doi=10.1109%2fTIFS.2020.3042049&partnerID=40&md5=e56e54e54657685379a63e90d2f8ff4f},
}

@Article{Wu2021,
  author        = {Wu, J. and Sun, W.},
  journal       = {Computers and Security},
  title         = {Towards multi-operation image anti-forensics with generative adversarial networks},
  year          = {2021},
  note          = {cited By 3},
  volume        = {100},
  abstract      = {How to conceal or eliminate the traces left by multiple manipulating operations such as JPEG compression and median filtering successively, known as multi-operation anti-forensics, remains challenging in the field of multimedia security. The existing anti-forensic researches concentrate on concealing or eliminating the traces left by a particular manipulation, referred as single-operation anti-forensics. In this work, we investigate multi-operation anti-forensics with generative adversarial networks (GANs). The generator network is trained to automatically learn the visual and statistical features of the original images by applying appropriate loss functions in the process of optimization. The idea of this work is based on the observation that the single-operation anti-forensic models can be used and extended for multi-operation anti-forensics. We then propose and compare two multi-operation anti-forensic strategies: I) directly using multiple optimized generative models, which are trained for single-operation anti-forensics respectively; II) training the whole GANs to obtain the optimized generative models of multi-operation anti-forensics. The experimental results demonstrate that both strategies can deceive the existing forensic methods without loss of image quality, but the image quality of strategy II is better than that of strategy I which is characterized with the modularity. © 2020},
  art_number    = {102083},
  document_type = {Article},
  doi           = {10.1016/j.cose.2020.102083},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096683411&doi=10.1016%2fj.cose.2020.102083&partnerID=40&md5=f9689462448581b5f8767b656bbf10ff},
}

@Article{Xia2021236,
  author        = {Xia, Z. and Tan, J. and Gu, K. and Jia, W.},
  journal       = {Journal of Parallel and Distributed Computing},
  title         = {Detection resource allocation scheme for two-layer cooperative IDSs in smart grids},
  year          = {2021},
  note          = {cited By 0},
  pages         = {236-247},
  volume        = {147},
  abstract      = {Although some existing collaborative intrusion detection schemes can increase the detection performance by dynamically allocating detection resources in smart grids, these related works fail to consider the optimization of resource allocation between IDSs under the condition of resource restriction. In this paper, considering the effect of resource restriction, we propose a resource allocation scheme for two-layer collaborative IDSs based on sharing strategies in smart grids. In the first layer of our scheme, we model the interaction between the IDSs and the attackers through a stochastic game based on sharing strategies, where we provide each IDS with two different options for its strategy updating at each stage in the stochastic game. Then the resource updating strategies of the IDSs are obtained through this proposed model. Further, in the second layer we quantify the effect of detection resource restriction, and we propose a resource allocation method under the condition of detection resource restriction, where each IDS can obtain its detection resources according to the results generated by our proposed stochastic game. Based on our experimental analysis, compared with other resource allocation schemes, our proposed scheme can more quickly achieve the Nash equilibrium between the IDSs and the attackers to make the IDSs obtain more rewards, and then can more rationally promote the IDSs to update their detection resources so that the IDSs obtain the optimal detection strategies under the condition of resource restriction. Our proposed scheme can achieve effective detection resource allocation between IDSs for the security of neighborhood area network in smart grids. © 2020 Elsevier Inc.},
  document_type = {Article},
  doi           = {10.1016/j.jpdc.2020.09.011},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092335087&doi=10.1016%2fj.jpdc.2020.09.011&partnerID=40&md5=afd24be147344a1c660427fb1f09cbc4},
}

@Article{Higgins20211275,
  author        = {Higgins, M. and Teng, F. and Parisini, T.},
  journal       = {IEEE Transactions on Information Forensics and Security},
  title         = {Stealthy MTD against Unsupervised Learning-Based Blind FDI Attacks in Power Systems},
  year          = {2021},
  note          = {cited By 4},
  pages         = {1275-1287},
  volume        = {16},
  abstract      = {This paper examines how moving target defenses (MTD) implemented in power systems can be countered by unsupervised learning-based false data injection (FDI) attack and how MTD can be combined with physical watermarking to enhance the system resilience. A novel intelligent attack, which incorporates dimensionality reduction and density-based spatial clustering, is developed and shown to be effective in maintaining stealth in the presence of traditional MTD strategies. In resisting this new type of attack, a novel implementation of MTD combining with physical watermarking is proposed by adding Gaussian watermark into physical plant parameters to drive detection of traditional and intelligent FDI attacks, while remaining hidden to the attackers and limiting the impact on system operation and stability. © 2005-2012 IEEE.},
  art_number    = {9207760},
  document_type = {Article},
  doi           = {10.1109/TIFS.2020.3027148},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091944871&doi=10.1109%2fTIFS.2020.3027148&partnerID=40&md5=e47e156047018855a87804cfd38912bb},
}

@Article{Yaji202111,
  author        = {Yaji, S. and Bayyapu, N.},
  journal       = {Cyber-Physical Systems},
  title         = {Result attack: a privacy breaching attack for personal data through K-means algorithm},
  year          = {2021},
  note          = {cited By 0},
  number        = {1},
  pages         = {11-40},
  volume        = {7},
  abstract      = {Protecting data privacy concerns the most significant challenge of the present era. This paper is an attempt to demonstrate how machine learning can be used by an attacker to compromise data privacy. To demonstrate, we have chosen an attack on handwritten signatures. The attacker utilizes available signatures for training and appends malicious signatures to be used in the testing process until he gets the desired result. The attacker manipulates the achieved result to perform the malicious attack. We propose, result attack to highlight the need for ensuring the secrecy of the genuine signature. An illustration is performed by applying the K-means algorithm to the MNIST dataset. Differential Privacy (DP) is adopted for defense discussion. The illustration of DP is produced by aggregating red or white noise to the MNIST dataset. Observation shows, the aggregation of noise to personal data successfully delivers defense against the result attack. We get the area under the receiver operating characteristic curve for the original dataset as 0.878719, original dataset vs aggregated red noise as 0.4999901, and original dataset vs white noise as 0.4448475. This concludes for the defense model, aggregating white noise is better than red noise, i.e. white noise aggregation is 11% better than red noise. © 2020 Informa UK Limited, trading as Taylor & Francis Group.},
  document_type = {Article},
  doi           = {10.1080/23335777.2020.1811380},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090007171&doi=10.1080%2f23335777.2020.1811380&partnerID=40&md5=6a1e777b79a38088c5ab5563ac74c2fb},
}

@Article{Meera2021235,
  author        = {Meera, A.J. and Kantipudi, M.V.V.P. and Aluvalu, R.},
  journal       = {Advances in Intelligent Systems and Computing},
  title         = {Intrusion detection system for the iot: A comprehensive review},
  year          = {2021},
  note          = {cited By 0},
  pages         = {235-243},
  volume        = {1182 AISC},
  abstract      = {The IoT has recently been widely used in smart homes and smart cities design. With various services and application domains. (IoT) connects objects with internet to make our life easier, which leads IoT environments vulnerable to different kinds of attacks. Threats to IoT are increasing due to large number of devices with different standards are connected. Intrusion Detection System (IDS) is used to protect from various types of attacks. Intrusion detection system (IDS) works in the network layer of an IoT system. This paper highlights the issues related IoT security, discusses literature on implementation of IDS for IoT using ML algorithms and also makes few suggestions. An IDS designed for IoT should operate under stringent conditions. More IDS have to be designed to detect major attacks to safe guard IoT. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2021.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-49345-5_25},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089723138&doi=10.1007%2f978-3-030-49345-5_25&partnerID=40&md5=0826717a11682fe90a570001ae158586},
}

@Article{Hao2021477,
  author        = {Hao, Y. and Zhang, F.},
  journal       = {Soft Computing},
  title         = {An unsupervised detection method for shilling attacks based on deep learning and community detection},
  year          = {2021},
  note          = {cited By 0},
  number        = {1},
  pages         = {477-494},
  volume        = {25},
  abstract      = {In the detection methods for shilling attacks, the supervised methods require labeled samples to train the classifiers. Due to lack of the labeled sample profiles in real scenarios, the applicability of supervised detection method is restricted. For unsupervised methods, the prior knowledge is often required to guarantee the detection accuracy. To break the traditional limitations, we present an unsupervised method to detect various shilling profiles from reconstructed user–user graph based on deep learning and community detection. Firstly, we construct the user–user graph, whose edge weight is calculated by the similarity of user’s behaviors. Secondly, the stacked denoising autoencoders are used to extract the robust graph features at different scales with different corruption rates. Based on the features at different scales, we generate multiple clustering results and reconstruct the user–user graph by evidence accumulation method. Thirdly, the community detection is carried out by using the persistence optimization algorithm. Extensive experiments on two datasets illustrate that our proposed method has better performance than some baseline detectors for detecting the simulated attacks and actual attacks. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.},
  document_type = {Article},
  doi           = {10.1007/s00500-020-05162-6},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087893984&doi=10.1007%2fs00500-020-05162-6&partnerID=40&md5=7a6e5a2f23c80f2ed17d3f17a361a4bc},
}

@Article{Drewek-Ossowicka2021497,
  author        = {Drewek-Ossowicka, A. and Pietrołaj, M. and Rumiński, J.},
  journal       = {Journal of Ambient Intelligence and Humanized Computing},
  title         = {A survey of neural networks usage for intrusion detection systems},
  year          = {2021},
  note          = {cited By 4},
  number        = {1},
  pages         = {497-514},
  volume        = {12},
  abstract      = {In recent years, advancements in the field of the artificial intelligence (AI) gained a huge momentum due to the worldwide appliance of this technology by the industry. One of the crucial areas of AI are neural networks (NN), which enable commercial utilization of functionalities previously not accessible by usage of computers. Intrusion detection system (IDS) presents one of the domains in which neural networks are widely tested for improving overall computer network security and data privacy. This article gives a thorough overview of recent literature regarding neural networks usage in intrusion detection system area, including surveys and new method proposals. Short tutorial descriptions of neural network architectures, intrusion detection system types and training datasets are also provided. © 2020, The Author(s).},
  document_type = {Article},
  doi           = {10.1007/s12652-020-02014-x},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084641419&doi=10.1007%2fs12652-020-02014-x&partnerID=40&md5=b517091d914549577d155929d6147f8f},
}

@Conference{Meiseles2020464,
  author        = {Meiseles, A. and Rosenberg, I. and Motro, Y. and Rokach, L. and Moran-Gilad, J.},
  title         = {Adversarial Vulnerability of Deep Learning Models in Analyzing Next Generation Sequencing Data},
  year          = {2020},
  note          = {cited By 0},
  pages         = {464-468},
  abstract      = {Deep Neural Networks (DNN) can be effectively used to accurately identify infectious pathogens. Unfortunately, DNNs can be exploited by bioterrorists, using adversarial attacks, to stage a fake super-bug outbreak or to hide the extent of a super-bug outbreak. In this work, we show how a DNN that performs superb classification o f c gMLST p rofiles ca n be exploited using adversarial attacks. To this end, we train a novel DNN model, Methicillin Resistance Classification Network (MRCN), which identifies s trains o f t he S taph b acteria t hat are resistant to an antibiotic named methicillin with 93.8 percent accuracy, using Core Genome Multi-Locus Sequence Typing (cgMLST) profiles. To defend a gainst this kind of exploitation, we train a second DNN model, Synthetic Profile Classifier (SPC), which can differentiate between natural Staph bacteria and generic synthetic Staph bacteria with 92.3 percent accuracy. Our experiments show that the MRCN model is highly susceptible to multiple adversarial attacks and that the defenses we propose are not able to provide effective protection against them. As a result, a bioterrorist would be able to utilize the compromised DNN model to inflict immense damage by s taging a fake epidemic or delaying the detection of an epidemic, allowing it to proliferate undeterred. © 2020 IEEE.},
  art_number    = {9313421},
  document_type = {Conference Paper},
  doi           = {10.1109/BIBM49941.2020.9313421},
  groups        = {First Filtering},
  journal       = {Proceedings - 2020 IEEE International Conference on Bioinformatics and Biomedicine, BIBM 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100352000&doi=10.1109%2fBIBM49941.2020.9313421&partnerID=40&md5=c2588f5961117025576388a8fc715c48},
}

@Conference{Sunny2020,
  author        = {Sunny, J. and Sankaran, S. and Saraswat, V.},
  title         = {A Hybrid Approach for Fast Anomaly Detection in Controller Area Networks},
  year          = {2020},
  note          = {cited By 0},
  volume        = {2020-December},
  abstract      = {Recent advancements in the field of in-vehicle network and wireless communication, has been steadily progressing. Also, the advent of technologies such as Vehicular Adhoc Networks (VANET) and Intelligent Transportation System (ITS), has transformed modern automobiles into a sophisticated cyber-physical system rather than just a isolated mechanical device. Modern automobiles rely on many electronic control units communicating over the Controller Area Network (CAN) bus. Although protecting the car's external interfaces is an vital part of preventing attacks, detecting malicious activity on the CAN bus is an effective second line of defense against attacks. This paper proposes a hybrid anomaly detection system for CAN bus based on patterns of recurring messages and time interval of messages. The proposed method does not require modifications in CAN bus. The proposed system is evaluated on real CAN bus traffic with simulated attack scenarios. Results obtained show that our proposed system achieved a good detection rate with fast response times. © 2020 IEEE.},
  art_number    = {9342791},
  document_type = {Conference Paper},
  doi           = {10.1109/ANTS50601.2020.9342791},
  groups        = {First Filtering},
  journal       = {International Symposium on Advanced Networks and Telecommunication Systems, ANTS},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101286270&doi=10.1109%2fANTS50601.2020.9342791&partnerID=40&md5=a630dd52ea64d5e657621d655359d7a6},
}

@Conference{Mori20201375,
  author        = {Mori, Y. and Nakamura, K. and Nitta, N. and Babaguchi, N.},
  title         = {Detection of Cloned Recognizers: A Defending Method against Recognizer Cloning Attack},
  year          = {2020},
  note          = {cited By 0},
  pages         = {1375-1380},
  abstract      = {With the development of machine learning technologies and the spread of mobile terminals, cloud-based image recognition services are getting popular in recent years. However, these services might suffer from a new type of attack called 'recognizer cloning attack' (RCA), in which an attacker sends a lot of images to a recognition server and receives their recognition results to train a new recognizer that mimics the function of the server's original recognizer. We refer to the recognizers trained by RCA as 'cloned recognizers' (CR). CRs allow attackers to analyze the weakness of their original recognizer and cause serious damage to the providers of the original service. To defend against RCA, we propose a method for detecting CRs in this paper. Our proposed method receives two recognizers as input and discriminates whether one of them is a CR of the other or not. We experimentally analyzed the properties of CRs and got the following two findings. First, CR and its original recognizer have the almost same recognition boundary. Second, CR provides a recognition confidence score that is almost same or quite higher than that provided by the original recognizer. Using these properties as clues, the proposed method was able to detect CRs with an accuracy of more than 80% in our experiments. © 2020 APSIPA.},
  art_number    = {9306283},
  document_type = {Conference Paper},
  groups        = {First Filtering},
  journal       = {2020 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference, APSIPA ASC 2020 - Proceedings},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100915785&partnerID=40&md5=52e780693833a8119641775c4b04ceef},
}

@Conference{Erba2020480,
  author        = {Erba, A. and Taormina, R. and Galelli, S. and Pogliani, M. and Carminati, M. and Zanero, S. and Tippenhauer, N.O.},
  title         = {Constrained Concealment Attacks against Reconstruction-based Anomaly Detectors in Industrial Control Systems},
  year          = {2020},
  note          = {cited By 2},
  pages         = {480-495},
  abstract      = {Recently, reconstruction-based anomaly detection was proposed as an effective technique to detect attacks in dynamic industrial control networks. Unlike classical network anomaly detectors that observe the network traffic, reconstruction-based detectors operate on the measured sensor data, leveraging physical process models learned a priori. In this work, we investigate different approaches to evade prior-work reconstruction-based anomaly detectors by manipulating sensor data so that the attack is concealed. We find that replay attacks (commonly assumed to be very strong) show bad performance (i.e., increasing the number of alarms) if the attacker is constrained to manipulate less than 95% of all features in the system, as hidden correlations between the features are not replicated well. To address this, we propose two novel attacks that manipulate a subset of the sensor readings, leveraging learned physical constraints of the system. Our attacks feature two different attacker models: A white box attacker, which uses an optimization approach with a detection oracle, and a black box attacker, which uses an autoencoder to translate anomalous data into normal data. We evaluate our implementation on two different datasets from the water distribution domain, showing that the detector's Recall drops from 0.68 to 0.12 by manipulating 4 sensors out of 82 in WADI dataset. In addition, we show that our black box attacks are transferable to different detectors: They work against autoencoder-, LSTM-, and CNN-based detectors. Finally, we implement and demonstrate our attacks on a real industrial testbed to demonstrate their feasibility in real-time. © 2020 ACM.},
  art_number    = {3427660},
  document_type = {Conference Paper},
  doi           = {10.1145/3427228.3427660},
  groups        = {First Filtering},
  journal       = {ACM International Conference Proceeding Series},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098066115&doi=10.1145%2f3427228.3427660&partnerID=40&md5=f6c6f6af6620b54ae78450946a14b325},
}

@Article{Ali202064,
  author        = {Ali, W.A. and Manasa, K.N. and Bendechache, M. and Aljunaid, M.F. and Sandhya, P.},
  journal       = {Journal of Telecommunications and the Digital Economy},
  title         = {A review of current machine learning approaches for anomaly detection in network traffic},
  year          = {2020},
  note          = {cited By 2},
  number        = {4},
  pages         = {64-95},
  volume        = {8},
  abstract      = {Due to the advance in network technologies, the number of network users is growing rapidly, which leads to the generation of large network traffic data. This large network traffic data is prone to attacks and intrusions. Therefore, the network needs to be secured and protected by detecting anomalies as well as to prevent intrusions into networks. Network security has gained attention from researchers and network laboratories. In this paper, a comprehensive survey was completed to give a broad perspective of what recently has been done in the area of anomaly detection. Newly published studies in the last five years have been investigated to explore modern techniques with future opportunities. In this regard, the related literature on anomaly detection systems in network traffic has been discussed, with a variety of typical applications such as WSNs, IoT, high-performance computing, industrial control systems (ICS), and software-defined network (SDN) environments. Finally, we underlined diverse open issues to improve the detection of anomaly systems. © 2020 Telecommunications Association Inc.. All Rights Reserved.},
  document_type = {Review},
  doi           = {10.18080/JTDE.V8N4.307},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098329365&doi=10.18080%2fJTDE.V8N4.307&partnerID=40&md5=ee8f58b4572dbc88344ecea296ccc03c},
}

@Conference{Wang2020125,
  author        = {Wang, B. and Zhang, Y. and Zhu, M. and Chen, Y.},
  title         = {The Security Threat of Adversarial Samples to Deep Learning Networks},
  year          = {2020},
  note          = {cited By 0},
  pages         = {125-129},
  abstract      = {With the prosperity of artificial intelligence, research on machine learning becomes a hot issue globally. Generative Adversarial Networks expose the huge security risks of machine learning. After the creation, GAN has achieved good performance in image generation, automatic image coloring, and data enhancement. With the improvement of the ability to generate samples against the deep learning network, generating malicious samples against the target learning model to achieve the deceptive discriminator becomes an effective and harmful attacking method. At present, some efficient attack methods have been proposed for different types of learning networks and different types of sample data. This paper mainly discusses the vulnerability of deep learning networks and several attack methods based on adversarial samples. © 2020 IEEE.},
  art_number    = {9402809},
  document_type = {Conference Paper},
  doi           = {10.1109/ICICAS51530.2020.00033},
  groups        = {First Filtering},
  journal       = {Proceedings - 2020 International Conference on Intelligent Computing, Automation and Systems, ICICAS 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104834105&doi=10.1109%2fICICAS51530.2020.00033&partnerID=40&md5=e260075f62dbedabc1ea380de576e849},
}

@Conference{Zizzo2020899,
  author        = {Zizzo, G. and Hankin, C. and Maffeis, S. and Jones, K.},
  title         = {Adversarial attacks on time-series intrusion detection for industrial control systems},
  year          = {2020},
  note          = {cited By 0},
  pages         = {899-910},
  abstract      = {Neural networks are increasingly used for intrusion detection on industrial control systems (ICS). With neural networks being vulnerable to adversarial examples, attackers who wish to cause damage to an ICS can attempt to hide their attacks from detection by using adversarial example techniques. In this work we address the domain specific challenges of constructing such attacks against autoregressive based intrusion detection systems (IDS) in an ICS setting. We model an attacker that can compromise a subset of sensors in a ICS which has a LSTM based IDS. The attacker manipulates the data sent to the IDS, and seeks to hide the presence of real cyber-physical attacks occurring in the ICS. We evaluate our adversarial attack methodology on the Secure Water Treatment system when examining solely continuous data, and on data containing a mixture of discrete and continuous variables. In the continuous data domain our attack successfully hides the cyber-physical attacks requiring 2.87 out of 12 monitored sensors to be compromised on average. With both discrete and continuous data our attack required, on average, 3.74 out of 26 monitored sensors to be compromised. © 2020 IEEE.},
  art_number    = {9343061},
  document_type = {Conference Paper},
  doi           = {10.1109/TrustCom50675.2020.00121},
  groups        = {First Filtering},
  journal       = {Proceedings - 2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications, TrustCom 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101260831&doi=10.1109%2fTrustCom50675.2020.00121&partnerID=40&md5=89c6eba20a36000d077f0fb09102a755},
}

@Conference{Shuvo20201410,
  author        = {Shuvo, M.S.R. and Alhadidi, D.},
  title         = {Membership inference attacks: Analysis and mitigation},
  year          = {2020},
  note          = {cited By 0},
  pages         = {1410-1419},
  abstract      = {Given a machine learning model and a record, membership attacks determine whether this record was used as part of the model's training dataset. Membership inference can present a risk to private datasets if these datasets are used to train machine learning models and access to the resulting models is open to the public. To construct attack models, multiple shadow models are created that imitate the behaviour of the target model, but for which we know the training datasets and thus the ground truth about membership in these datasets. Attack models are then trained on the labeled inputs and outputs of the shadow models. There is a desideratum to conduct more analysis about this attack and accordingly to provide robust mitigation techniques that will not affect the target model's utility. In this paper, we empirically analyzed this attack from different perspectives related to the number of models and the type of training algorithms. We also proposed and evaluated different mitigation techniques against this type of attack considering different training algorithms of the target model. Our experiments show that the defence strategies mitigate the membership inference attack considerably while preserving the utility of the target model. Finally, we summarized and compared the existing mitigation techniques with our results. © 2020 IEEE.},
  art_number    = {9343081},
  document_type = {Conference Paper},
  doi           = {10.1109/TrustCom50675.2020.00190},
  groups        = {First Filtering},
  journal       = {Proceedings - 2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications, TrustCom 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101214069&doi=10.1109%2fTrustCom50675.2020.00190&partnerID=40&md5=117d02bb1d99ff2a440294e7b5c9ed4f},
}

@Conference{Ching2020,
  author        = {Ching, C.-W. and Lin, T.-C. and Chang, K.-H. and Yao, C.-C. and Kuo, J.-J.},
  title         = {Model Partition Defense against GAN Attacks on Collaborative Learning via Mobile Edge Computing},
  year          = {2020},
  note          = {cited By 0},
  abstract      = {With growing concerns about privacy issues of machine learning, collaborative learning (CL) is developed to offer on-device training. However, adversarial behaviors of model inversion (MI) are undermining privacy of training data. Specifically, adversaries act as ordinary participants in CL and reproduce private data of a class in training data by training generative adversarial networks (GAN) on the fly, unknowingly. To this end, we design a novel model partition defense, PAMPAS, over user devices and trustworthy edge server to resist GAN attack, and formulate a new optimization problem, TENSOR, to optimize training time. To address the challenges that come with PAMPAS, we propose an algorithm TESLA that yields the optimal solution. Experiment and simulation results manifest that PAMPAS effectively defend GAN attack and TESLA reduces training time by 50% compared with other solutions. © 2020 IEEE.},
  art_number    = {9322591},
  document_type = {Conference Paper},
  doi           = {10.1109/GLOBECOM42002.2020.9322591},
  groups        = {First Filtering},
  journal       = {2020 IEEE Global Communications Conference, GLOBECOM 2020 - Proceedings},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100417954&doi=10.1109%2fGLOBECOM42002.2020.9322591&partnerID=40&md5=cff5ab747dc5d775780e30d11819d573},
}

@Article{Molina-Coronado20202451,
  author        = {Molina-Coronado, B. and Mori, U. and Mendiburu, A. and Miguel-Alonso, J.},
  journal       = {IEEE Transactions on Network and Service Management},
  title         = {Survey of Network Intrusion Detection Methods from the Perspective of the Knowledge Discovery in Databases Process},
  year          = {2020},
  note          = {cited By 1},
  number        = {4},
  pages         = {2451-2479},
  volume        = {17},
  abstract      = {The identification of network attacks which target information and communication systems has been a focus of the research community for years. Network intrusion detection is a complex problem which presents a diverse number of challenges. Many attacks currently remain undetected, while newer ones emerge due to the proliferation of connected devices and the evolution of communication technology. In this survey, we review the methods that have been applied to network data with the purpose of developing an intrusion detector, but contrary to previous reviews in the area, we analyze them from the perspective of the Knowledge Discovery in Databases (KDD) process. As such, we discuss the techniques used for the collecion, preprocessing and transformation of the data, as well as the data mining and evaluation methods. We also present the characteristics and motivations behind the use of each of these techniques and propose more adequate and up-to-date taxonomies and definitions for intrusion detectors based on the terminology used in the area of data mining and KDD. Special importance is given to the evaluation procedures followed to assess the detectors, discussing their applicability in current, real networks. Finally, as a result of this literature review, we investigate some open issues which will need to be considered for further research in the area of network security. © 2004-2012 IEEE.},
  art_number    = {9165817},
  document_type = {Article},
  doi           = {10.1109/TNSM.2020.3016246},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097792485&doi=10.1109%2fTNSM.2020.3016246&partnerID=40&md5=80929bfe0401220176e1ecb96a412bd2},
}

@Article{RamanMR2020,
  author        = {Raman MR, G. and Somu, N. and Mathur, A.P.},
  journal       = {International Journal of Critical Infrastructure Protection},
  title         = {A multilayer perceptron model for anomaly detection in water treatment plants},
  year          = {2020},
  note          = {cited By 1},
  volume        = {31},
  abstract      = {Early and accurate anomaly detection in critical infrastructure (CI), such as water treatment plants and electric power grid, is necessary to avoid plant damage and service disruption. Several machine learning techniques have been employed for the design of an effective anomaly detector in such systems. However, threats such as from insiders and state actors, introduce challenges in the design of an effective anomaly detector. This work presents a multi-layer perceptron (MLP) based anomaly detector that uses an unsupervised approach to safeguard CI from the adverse impacts of cyber-attacks. The proposed detector was trained using the data collected under the normal operation of the plant. The model captures the temporal dependencies between the samples and predicts the plant behavior. Further, the well-known CUmulative SUM (CUSUM) approach was used to detect the abnormal deviations between the observed and predicted sensor values for the identification and reporting of anomalies. Experimental validation of the proposed method was carried out using a dataset obtained from Secure Water Treatment (SWaT) an operational water treatment testbed under normal operation as well as under direct and stealthy attacks. The performance of MLP-CUSUM was compared against the state-of-the-art machine learning models in terms of its classification accuracy, precision, recall, F1 score, and the false alarm rate. © 2020 Elsevier B.V.},
  art_number    = {100393},
  document_type = {Article},
  doi           = {10.1016/j.ijcip.2020.100393},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096661340&doi=10.1016%2fj.ijcip.2020.100393&partnerID=40&md5=6fe6f85e104be1fe8a0c0a79c260ddc5},
}

@Article{Singh2020,
  author        = {Singh, I. and Kumar, N. and K.G., S. and Sharma, T. and Kumar, V. and Singhal, S.},
  journal       = {Journal of Information Security and Applications},
  title         = {Database intrusion detection using role and user behavior based risk assessment},
  year          = {2020},
  note          = {cited By 1},
  volume        = {55},
  abstract      = {Present-day organizations continue to expose their critical information infrastructures over the Internet for facilitating accessibility; substantially raising concerns about the security of data from both outsiders and insiders. In this paper, we propose a novel approach for detecting intrusive attacks on databases by assessing the risk for incoming transaction based upon the conflation of multiple behavior-based components for the user. In a database intrusion detection system for a role-based access (RBAC) environment, it is not sufficient to focus on role-based features as every user within the same role has a degree of uniqueness. Moreover, traditional database intrusion detection systems classify the incoming transactions into two classes (Malicious or Non-malicious), taking the same action for all transactions that are labeled as malicious irrespective of the damage it can cause to the system. Our approach, Role and User Behavior-based Risk Assessment (RUBRA) uses both role-behavior and user-behavior based features for detecting an intrusive attack. Further, we also quantify the risk associated with the incoming transaction, streamlining the countermeasure process. Experiments on stochastic datasets show promising results on both detection and labeling of malicious transactions. © 2020},
  art_number    = {102654},
  document_type = {Article},
  doi           = {10.1016/j.jisa.2020.102654},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092701287&doi=10.1016%2fj.jisa.2020.102654&partnerID=40&md5=cf6c1a19a273eb220d3b965c06a81370},
}

@Article{GauthamaRaman2020,
  author        = {Gauthama Raman, M.R. and Dong, W. and Mathur, A.},
  journal       = {Computers and Security},
  title         = {Deep autoencoders as anomaly detectors: Method and case study in a distributed water treatment plant},
  year          = {2020},
  note          = {cited By 2},
  volume        = {99},
  abstract      = {Industrial Control Systems (ICS) are found in critical infrastructure, such as, water treatment plants and oil refineries. ICS are often the target of cyber-attacks leading to undesirable consequences. It is essential to detect process anomalies resulting from such attacks before appropriate defensive actions are considered. In this work, a deep autoencoder-based anomaly detector (DAE) is proposed. DAE is trained using data collected during normal operation of a plant. The detection effectiveness of three variants of DAE was experimentally evaluated on an operational Secure Water Treatment (SWaT) plant. Further, the amount of plant design knowledge needed to design DAE was compared with that needed to create design-centric approaches for anomaly detection. Experimental results indicate that the proposed DAE, constructed with minimal design knowledge, is effective in detecting process anomalies resulting due to single and multi-point coordinated attacks with high detection rate and few false alarms. © 2020 Elsevier Ltd},
  art_number    = {102055},
  document_type = {Article},
  doi           = {10.1016/j.cose.2020.102055},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091602320&doi=10.1016%2fj.cose.2020.102055&partnerID=40&md5=47fa264fd15f5812477a552e6581cb81},
}

@Article{Tan20205329,
  author        = {Tan, S. and Guerrero, J.M. and Xie, P. and Han, R. and Vasquez, J.C.},
  journal       = {IEEE Systems Journal},
  title         = {Brief Survey on Attack Detection Methods for Cyber-Physical Systems},
  year          = {2020},
  note          = {cited By 7},
  number        = {4},
  pages         = {5329-5339},
  volume        = {14},
  abstract      = {In recent years, cyber-physical systems (CPSs) have attracted intense attention due to their potential applications in many areas. However, the strong reliance on communication networks makes CPSs vulnerable to intentional cyberattacks. Therefore, a great number of attack detection methods have been proposed to enforce security of CPSs. In this article, various false data injection attack detection methods presented for CPSs are investigated and reviewed. According to the knowledge of control information, the controllers of CPSs are categorized as centralized and distributed controllers. Existing centralized attack detection approaches are discussed in terms of i) linear time-invariant systems, ii) actuator and sensor attacks, iii) nonlinear systems, and iv) systems with noise. Furthermore, the development of distributed attack detection is reviewed according to different decoupling methods. Some challenges and future research directions in the context of attack detection approaches are provided. © 2007-2012 IEEE.},
  art_number    = {9097420},
  document_type = {Review},
  doi           = {10.1109/JSYST.2020.2991258},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090764783&doi=10.1109%2fJSYST.2020.2991258&partnerID=40&md5=f3f3f21af454a4df1c47d05b9d372fd1},
}

@Article{Kundu2020,
  author        = {Kundu, A. and Sahu, A. and Serpedin, E. and Davis, K.},
  journal       = {Electric Power Systems Research},
  title         = {A3D: Attention-based auto-encoder anomaly detector for false data injection attacks},
  year          = {2020},
  note          = {cited By 2},
  volume        = {189},
  abstract      = {With the influx of more advanced and more connected computing and control devices, the electric power grid has continuously evolved to rely on communication networks for efficient operation and control. A challenge with these new technologies is that they may introduce new and unforeseen avenues of access, making the grid more susceptible to cyber attacks. False Data Injection Attacks (FDIA) are a particular type of attack that aims to cause disruptions in the operation of the power grid by affecting the feedback mechanism to control the grid. This is carried out by modifying the measurements which enable a state estimator to approximate the state of the system. These attacks are designed in such a way that they preserve the system equations on which the state estimator operates; therefore, they cannot be detected by a simple residual-based detection mechanism. In this paper, we propose monotonic attention based auto-encoders, an unsupervised learning technique to detect FDIAs. The auto-encoder is trained under normal operating conditions, and we hypothesize that it will produce outputs which are close to the true system values at normal operation even if the measurements are modified by an adversary. Based on this hypothesis, that high reconstruction error occurs for the attacked conditions, the intrusion detection is performed by a threshold mechanism using Precision-Recall curve. We validate the efficacy of our proposed attention-based auto-encoder anomaly detector (A3D) over other variants of auto-encoders such as ANN and RNN based auto-encoders, and a few supervised learning techniques, by performing FDIAs on a IEEE 14 bus system. © 2020},
  art_number    = {106795},
  document_type = {Article},
  doi           = {10.1016/j.epsr.2020.106795},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089417426&doi=10.1016%2fj.epsr.2020.106795&partnerID=40&md5=d9ecd245ac7659244387daf9490830ef},
}

@Article{Li2020,
  author        = {Li, H. and Wang, B. and Xie, X.},
  journal       = {Eurasip Journal on Wireless Communications and Networking},
  title         = {An improved content-based outlier detection method for ICS intrusion detection},
  year          = {2020},
  note          = {cited By 0},
  number        = {1},
  volume        = {2020},
  abstract      = {Due to the complexity of industrial control systems and the diversity of protocols in networks, it is difficult to build intrusion detection models based on network characteristics and physical modeling. In order to build a better flow model without additional knowledge, we propose an intrusion detection method based on the content of network packets. The construction of the model is based on the idea of ZOE method. The similarity between flows is calculated through the sequential coverage algorithm, the normal flow model is established by multi-layered clustering algorithm, and the Count-Mean-Min Sketch is used to store and count the flow model. By comparing the unknown flow with the constructed normal flow model, we achieve the intrusion detection of industrial control system (ICS). The overall experimental results on 4 ICS datasets show that the improved method can effectively improve the detection rate and reduce the false-positive rate. The detection rate reached 96.7% on average, and the false-positive rate reached 0.7% on average. © 2020, The Author(s).},
  art_number    = {103},
  document_type = {Article},
  doi           = {10.1186/s13638-020-01718-0},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085703377&doi=10.1186%2fs13638-020-01718-0&partnerID=40&md5=14296010c035cc64da074d52e55007b0},
}

@Article{Li20204246,
  author        = {Li, J. and Pan, Z.},
  journal       = {KSII Transactions on Internet and Information Systems},
  title         = {Network Traffic Classification Based on Deep Learning},
  year          = {2020},
  note          = {cited By 2},
  number        = {11},
  pages         = {4246-4267},
  volume        = {14},
  abstract      = {As the network goes deep into all aspects of people's lives, the number and the complexity of network traffic is increasing, and traffic classification becomes more and more important. How to classify them effectively is an important prerequisite for network management and planning, and ensuring network security. With the continuous development of deep learning, more and more traffic classification begins to use it as the main method, which achieves better results than traditional classification methods. In this paper, we provide a comprehensive review of network traffic classification based on deep learning. Firstly, we introduce the research background and progress of network traffic classification. Then, we summarize and compare traffic classification based on deep learning such as stack autoencoder, one-dimensional convolution neural network, two-dimensional convolution neural network, three-dimensional convolution neural network, long short-term memory network and Deep Belief Networks. In addition, we compare traffic classification based on deep learning with other methods such as based on port number, deep packets detection and machine learning. Finally, the future research directions of network traffic classification based on deep learning are prospected. Copyright © 2020 KSII},
  document_type = {Article},
  doi           = {10.3837/tiis.2020.11.001},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097030928&doi=10.3837%2ftiis.2020.11.001&partnerID=40&md5=6fd8cee63b676e1a7d60f0f6f7b21b0e},
}

@Article{Ramezanpour20201626,
  author        = {Ramezanpour, K. and Ampadu, P. and Diehl, W.},
  journal       = {IEEE Transactions on Computers},
  title         = {SCAUL: Power side-channel analysis with unsupervised learning},
  year          = {2020},
  note          = {cited By 0},
  number        = {11},
  pages         = {1626-1638},
  volume        = {69},
  abstract      = {Existing power analysis techniques rely on strong adversary models with prior knowledge of the leakage or training data. We introduce side-channel analysis with unsupervised learning (SCAUL) that can recover the secret key without requiring prior knowledge or profiling (training). We employ an LSTM auto-encoder to extract features from power traces with high mutual information with the data-dependent samples of the measurements.Wedemonstrate that by replacing the rawmeasurements with the auto-encoder features in a classical DPA attack, the efficiency, in terms of required number of measurements for key recovery, improves by 10X. Further, we employ these features to identify a leakagemodel with sensitivity analysis and multi-layer perceptron (MLP) networks. SCAUL uses the auto-encoder features and the leakage model, obtained in an unsupervised approach, to find the correct key. On a lightweight implementation of AES on Artix-7 FPGA, we show that SCAUL is able to recover the correct key with 3, 700 power measurements with random plaintexts, while a DPA attack requires at least 17, 400 measurements. Using misaligned traces, with an uncertainty equal to 20 percent of the hardware clock cycle, SCAUL is able to recover the secret key with 12, 300 measurements while the DPA attack fails to detect the key. © 2020 IEEE.},
  art_number    = {9153159},
  document_type = {Article},
  doi           = {10.1109/TC.2020.3013196},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102801742&doi=10.1109%2fTC.2020.3013196&partnerID=40&md5=8e14fcb614aadc8185aa7a04f95a9a7a},
}

@Article{Naseer20201,
  author        = {Naseer, S. and Ali, R.F. and Dominic, P.D.D. and Saleem, Y.},
  journal       = {Symmetry},
  title         = {Learning representations of network traffic using deep neural networks for network anomaly detection: A perspective towards oil and gas it infrastructures},
  year          = {2020},
  note          = {cited By 4},
  number        = {11},
  pages         = {1-28},
  volume        = {12},
  abstract      = {Oil and Gas organizations are dependent on their IT infrastructure, which is a small part of their industrial automation infrastructure, to function effectively. The oil and gas (O&G) organizations industrial automation infrastructure landscape is complex. To perform focused and effective studies, Industrial systems infrastructure is divided into functional levels by The Instrumentation, Systems and Automation Society (ISA) Standard ANSI/ISA-95:2005. This research focuses on the ISA-95:2005 level-4 IT infrastructure to address network anomaly detection problem for ensuring the security and reliability of Oil and Gas resource planning, process planning and operations management. Anomaly detectors try to recognize patterns of anomalous behaviors from network traffic and their performance is heavily dependent on extraction time and quality of network traffic features or representations used to train the detector. Creating efficient representations from large volumes of network traffic to develop anomaly detection models is a time and resource intensive task. In this study we propose, implement and evaluate use of Deep learning to learn effective Network data representations from raw network traffic to develop data driven anomaly detection systems. Proposed methodology provides an automated and cost effective replacement of feature extraction which is otherwise a time and resource intensive task for developing data driven anomaly detectors. The ISCX-2012 dataset is used to represent ISA-95 level-4 network traffic because the O&G network traffic at this level is not much different than normal internet traffic. We trained four representation learning models using popular deep neural network architectures to extract deep representations from ISCX 2012 traffic flows. A total of sixty anomaly detectors were trained by authors using twelve conventional Machine Learning algorithms to compare the performance of aforementioned deep representations with that of a human-engineered handcrafted network data representation. The comparisons were performed using well known model evaluation parameters. Results showed that deep representations are a promising feature in engineering replacement to develop anomaly detection models for IT infrastructure security. In our future research, we intend to investigate the effectiveness of deep representations, extracted using ISA-95:2005 Level 2-3 traffic comprising of SCADA systems, for anomaly detection in critical O&G systems. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
  art_number    = {1882},
  document_type = {Article},
  doi           = {10.3390/sym12111882},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096374648&doi=10.3390%2fsym12111882&partnerID=40&md5=c421af4e0981ca2a56242fc702d3eb50},
}

@Conference{Alasmary2020888,
  author        = {Alasmary, H. and Abusnaina, A. and Jang, R. and Abuhamad, M. and Anwar, A. and Nyang, D. and Mohaisen, D.},
  title         = {Soteria: Detecting adversarial examples in control flow graph-based malware classifiers},
  year          = {2020},
  note          = {cited By 1},
  pages         = {888-898},
  volume        = {2020-November},
  abstract      = {Deep learning algorithms have been widely used for security applications, including malware detection and classification. Recent results have shown that those algorithms are vulnerable to adversarial examples, whereby a small perturbation in the input sample may result in misclassification. In this paper, we systematically tackle the problem of adversarial examples detection in the control flow graph (CFG) based classifiers for malware detection using Soteria. Unique to Soteria, we use both density-based and level-based labels for CFG labeling to yield a consistent representation, a random walk-based traversal approach for feature extraction, and n-gram based module for feature representation. End-to-end, Soteria’s representation ensures a simple yet powerful randomization property of the used classification features, making it difficult even for a powerful adversary to launch a successful attack. Soteria also employs a deep learning approach, consisting of an auto-encoder for detecting adversarial examples, and a CNN architecture for detecting and classifying malware samples. We evaluate the performance of Soteria, using a large dataset consisting of 16,814 IoT samples, and demonstrate its superiority in comparison with state-of-the-art approaches. In particular, Soteria yields an accuracy rate of 97.79% for detecting AEs, and 99.91% overall accuracy for classification malware families. © 2020 IEEE.},
  art_number    = {09355825},
  document_type = {Conference Paper},
  doi           = {10.1109/ICDCS47774.2020.00089},
  groups        = {First Filtering},
  journal       = {Proceedings - International Conference on Distributed Computing Systems},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094333207&doi=10.1109%2fICDCS47774.2020.00089&partnerID=40&md5=5aed373128da9ba0dd7303ec2a973224},
}

@Article{Ghafouri20205227,
  author        = {Ghafouri, M. and Au, M. and Kassouf, M. and Debbabi, M. and Assi, C. and Yan, J.},
  journal       = {IEEE Transactions on Smart Grid},
  title         = {Detection and Mitigation of Cyber Attacks on Voltage Stability Monitoring of Smart Grids},
  year          = {2020},
  note          = {cited By 6},
  number        = {6},
  pages         = {5227-5238},
  volume        = {11},
  abstract      = {This paper investigates the possible cyber-physical attacks on voltage stability monitoring of a power transmission system. By considering a smart adversary that can launch a vector attack based on power flow equations, conventional voltage stability monitoring systems based on voltage stability indexes will fail to detect the instability issue. This can mislead the Power System Operator (PSO) to take inappropriate corrective action. In order to prevent and to combat such a malicious attack, a new indicator for efficient intrusion detection and a novel mitigation algorithm is proposed. This proposed detection algorithm employs the multi-port equivalent circuit of the power system to calculate the Thevenin Equivalent (TE) parameters. These TE parameters are then used to calculate an indicator, which reveals the attack on Phasor Measurement Unit (PMU) data. The proposed mitigation scheme then helps PSO to detect which PMU is under-attack. Furthermore, the amount of injected attack vectors is computed or estimated depending on the number of compromised PMUs. The effectiveness of the proposed techniques is demonstrated via illustrative case studies. © 2010-2012 IEEE.},
  art_number    = {9122598},
  document_type = {Article},
  doi           = {10.1109/TSG.2020.3004303},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090789867&doi=10.1109%2fTSG.2020.3004303&partnerID=40&md5=a4e2ccd1ea9203b67967aecc2922a039},
}

@Article{Gumaei2020,
  author        = {Gumaei, A. and Hassan, M.M. and Huda, S. and Hassan, M.R. and Camacho, D. and Del Ser, J. and Fortino, G.},
  journal       = {Applied Soft Computing Journal},
  title         = {A robust cyberattack detection approach using optimal features of SCADA power systems in smart grids},
  year          = {2020},
  note          = {cited By 1},
  volume        = {96},
  abstract      = {Smart grids are a type of complex cyber–physical system (CPS) that integrates the communication capabilities of smart devices into the grid to facilitate remote operation and control of power systems. However, this integration exposes many existing vulnerabilities of conventional supervisory control and data acquisition (SCADA) systems, resulting in severe cyber threats to the smart grid and potential violation of security objectives. Stealing sensitive information, modifying firmware, or injecting function codes through compromised devices are examples of possible attacks on the smart grid. Therefore, early detection of cyberattacks on the grid is crucial to protect it from sabotage. Machine learning (ML) methods are conventional approaches for detecting cyberattacks that use features of smart grid networks. However, developing an effective, highly accurate detection method with reduced computational overload, is still a challenging research problem. In this work, an efficient and effective security control approach is proposed to detect cyberattacks on the smart grid. The proposed approach combines both feature reduction and detection techniques to reduce the extremely large number of features and achieve an improved detection rate. A correlation-based feature selection (CFS) method is used to remove irrelevant features, improving detection efficiency. An instance-based learning (IBL) algorithm classifies normal and cyberattack events using the selected optimal features. This study describes a set of experiments conducted on public datasets from a SCADA power system based on a 10-fold cross-validation technique. Experimental results show that the proposed approach achieves a high detection rate based on a small number of features drawn from SCADA power system measurements. © 2020 Elsevier B.V.},
  art_number    = {106658},
  document_type = {Article},
  doi           = {10.1016/j.asoc.2020.106658},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090425637&doi=10.1016%2fj.asoc.2020.106658&partnerID=40&md5=36d397bd4d27a4fe5a85ecc9a6f74c76},
}

@Article{Rose2020124,
  author        = {Rose, T. and Kifayat, K. and Abbas, S. and Asim, M.},
  journal       = {Journal of Parallel and Distributed Computing},
  title         = {A hybrid anomaly-based intrusion detection system to improve time complexity in the Internet of Energy environment},
  year          = {2020},
  note          = {cited By 5},
  pages         = {124-139},
  volume        = {145},
  abstract      = {The technological evolution of the smart grids is going to take its shape in the form of a new paradigm called the Internet of Energy (IoE); which is considered to be the convergence of internet, communication, and energy. Like other evolved technologies, the IoE inherits security vulnerabilities from its constituents that need to be addressed. Intrusion Detection Systems (IDS) have been used to counteract malicious attacks. Among the types of IDS, anomaly-based IDS that employ mostly machine learning algorithms are considered to be the promising one, owing to their capability of detecting zero-day attacks. However, using complex algorithms to detect attacks, the existing anomaly-based IDS designed for IoE require considerable amount of time. It is tempting to reduce the training and testing time in order to make the IDS feasible for the IoE architecture. In this paper, we propose a hybrid anomaly-based IDS that can be installed at any networked site of the IoE architecture, such as Advanced Metering Infrastructure (AMI), to counteract security attacks. Our proposed system reduces the overall classification time of detection compared to the existing hybrid methods. The proposed solution uses a combination of K-means and Support Vector Machine, where the K-means centroids are used in a unique training method that reduces the training and testing times of the Support Vector Machine without compromising classification performance. We choose the best value of “k” and fine-tuned the SVM for best anomaly detection. Our approach achieves the highest accuracy of 99.9% in comparison with the existing approaches. © 2020 Elsevier Inc.},
  document_type = {Article},
  doi           = {10.1016/j.jpdc.2020.06.012},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087496960&doi=10.1016%2fj.jpdc.2020.06.012&partnerID=40&md5=eb66ce01a1cd464e14dc99b65c203944},
}

@Article{Kumar20208938,
  author        = {Kumar, G. and Thakur, K. and Ayyagari, M.R.},
  journal       = {Journal of Supercomputing},
  title         = {MLEsIDSs: machine learning-based ensembles for intrusion detection systems—a review},
  year          = {2020},
  note          = {cited By 8},
  number        = {11},
  pages         = {8938-8971},
  volume        = {76},
  abstract      = {Network security plays an essential role in secure communication and avoids financial loss and crippled services due to network intrusions. Intruders generally exploit the flaws of popular software to mount a variety of attacks against network computer systems. The damage caused in the network attacks may vary from a little disruption in service to on developing financial loss. Recently, intrusion detection systems (IDSs) comprising machine learning techniques have emerged for handling unauthorized usage and access to network resources.With the passage of time, a wide variety of machine learning techniques have been designed and integrated with IDSs. Still, most of the IDSs reported poor intrusion detection results using false positive rate and detection rate. For solving these issues, researchers focused on the development of ensemble classifiers involving the integration of predictions by multiple individual classifiers. The ensemble classifiers enable to compensate for the weakness of individual classifiers and use their combined knowledge to enhance its performance. This study presents motivation and comprehensive review of intrusion detection systems based on ensembles in machine learning as an extension of our previous work in the field. Particularly, different ensemble methods in the field are analysed, taking into consideration different types of ensembles, and various approaches for integrating the predictions of individual classifiers for an ensemble classifier. The representative studies are compared in chronological order for systematic and critical analysis, understanding the current challenges and status of research in the field. Finally, the study presents essential future research directions for the development of effective IDSs. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.},
  document_type = {Article},
  doi           = {10.1007/s11227-020-03196-z},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079488476&doi=10.1007%2fs11227-020-03196-z&partnerID=40&md5=ef9358b469f0c9393da81e4508a94f5e},
}

@Conference{Mhamdi2020,
  author        = {Mhamdi, L. and McLernon, D. and El-Moussa, F. and Raza Zaidi, S.A. and Ghogho, M. and Tang, T.},
  title         = {A Deep Learning Approach Combining Autoencoder with One-class SVM for DDoS Attack Detection in SDNs},
  year          = {2020},
  note          = {cited By 0},
  abstract      = {Software Defined Networking (SDN) provides us with the capability of collecting network traffic information and managing networks proactively. Therefore, SDN facilitates the promotion of more robust and secure networks. Recently, several Machine Learning (ML)/Deep Learning (DL) intrusion detection approaches have been proposed to secure SDN networks. Currently, most of the proposed ML/DL intrusion detection approaches are based on supervised learning approach that required labelled and well-balanced datasets for training. However, this is time intensive and require significant human expertise to curate these datasets. These approaches cannot deal well with imbalanced and unlabeled datasets. In this paper, we propose a hybrid unsupervised DL approach using the stack autoencoder and One-class Support Vector Machine (SAE-1SVM) for Distributed Denial of Service (DDoS) attack detection. The experimental results show that the proposed algorithm can achieve an average accuracy of 99.35 % with a small set of flow features. The SAE-1SVM shows that it can reduce the processing time significantly while maintaining a high detection rate. In summary, the SAE-1SVM can work well with imbalanced and unlabeled datasets and yield a high detection accuracy. © 2020 IEEE.},
  art_number    = {9306073},
  document_type = {Conference Paper},
  doi           = {10.1109/ComNet47917.2020.9306073},
  groups        = {First Filtering},
  journal       = {2020 8th International Conference on Communications and Networking, ComNet2020 - Proceedings},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100025253&doi=10.1109%2fComNet47917.2020.9306073&partnerID=40&md5=889fecf5b46550f5a4ad783d063329db},
}

@Conference{Mohammadpourfard202041,
  author        = {Mohammadpourfard, M. and Ghanaatpishe, F. and Mohammadi, M. and Lakshminarayana, S. and Pechenizkiy, M.},
  title         = {Generation of false data injection attacks using conditional generative adversarial networks},
  year          = {2020},
  note          = {cited By 0},
  pages         = {41-45},
  volume        = {2020-October},
  abstract      = {The growing adoption of information and communication technologies (ICTs) is enabling intelligent power grid applications. However, strong reliance on ICTs makes the grid susceptible to cyber attacks such as false data injection attacks (FDIAs). This paper shows how deep learning approaches can be used to craft FDIAs against power grid state estimation that can circumvent the grid's bad data detector (BDD). In particular, we utilize conditional Generative Adversarial Networks (cGANs) to learn the distribution of the power grid measurement data and produce fake measurements that are identical in distribution to the real ones. Under the proposed algorithm, the attacker needs to have access to the grid's measurement data and know what data types in order to inject into the measurement system. No other prior knowledge about the grid is required. This type of threat model is novel and has not been considered so far. The simulation results on IEEE 14-bus system shows that FDIAs generated by our best performing cGAN implementation trained using real-world load data sets can bypass the BDD with a very high probability. Moreover, the distance between the distributions of the real and fake measurements (with FDIAs), measured in terms of the Jensen-Shannon divergence has a very low value, which shows the effectiveness of the proposed FDIA design approach. © 2020 IEEE.},
  art_number    = {9248967},
  document_type = {Conference Paper},
  doi           = {10.1109/ISGT-Europe47291.2020.9248967},
  groups        = {First Filtering},
  journal       = {IEEE PES Innovative Smart Grid Technologies Conference Europe},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097346088&doi=10.1109%2fISGT-Europe47291.2020.9248967&partnerID=40&md5=7c2b1e32f752f5b92cea8110a79ecdf6},
}

@Conference{Nugroho2020138,
  author        = {Nugroho, E.P. and Djatna, T. and Sitanggang, I.S. and Buono, A. and Hermadi, I.},
  title         = {A Review of Intrusion Detection System in IoT with Machine Learning Approach: Current and Future Research},
  year          = {2020},
  note          = {cited By 0},
  pages         = {138-143},
  abstract      = {Internet of Things (IoT) devices with their network services are often vulnerable to attacks because they are not designed for security. Especially with the rapid technological advances that make data increase exponentially. This is targeted by malicious users to exploit vulnerabilities or interfere with many vulnerability attacks. Therefore, deal with this vulnerability, an intrusion detection system that involves machine learning techniques is needed. Intrusion Detection System (IDS) is targeted to get intrusion in a communication system by looking at the IDS types and methods. This is influenced by the characteristics of the IoT network involved and the reference dataset used in the detection system. This dataset determines the categories or classes of attacks upon which the IDS decides whether or not to intrusion. Reference databases that already exist and are often used, such as KDD Cup 99, NSL KDD, and attack datasets obtained from conditions. In developing IDS in IoT Device, the Machine Learning approach can be used to solve the type of algorithm used consisting of supervised learning, unsupervised learning, or Reinforcement learning. These algorithm methods can be used include SVM, Decision Tree, K-NN, ANN, RNN, and others. From the review analysis of dominant research conducted in 2015-2020, the largest percentage was obtained using the artificial neural network and deep learning algorithm for the intrusion classification process, with details of 16% ANN, 12% RNN, and DNN. © 2020 IEEE.},
  art_number    = {9392075},
  document_type = {Conference Paper},
  doi           = {10.1109/ICSITech49800.2020.9392075},
  groups        = {First Filtering},
  journal       = {2020 6th International Conference on Science in Information Technology: Embracing Industry 4.0: Towards Innovation in Disaster Management, ICSITech 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104553926&doi=10.1109%2fICSITech49800.2020.9392075&partnerID=40&md5=8382ee63107432e65acf3aff55b44221},
}

@Conference{Alrawashdeh2020,
  author        = {Alrawashdeh, K. and Goldsmith, S.},
  title         = {Optimizing deep learning based intrusion detection systems defense against white-box and backdoor adversarial attacks through a genetic algorithm},
  year          = {2020},
  note          = {cited By 0},
  volume        = {2020-October},
  abstract      = {Recent years have witnessed rapid progress and significant success in the use of deep learning neural networks (DLNNs) in a wide range of applications. Recently, DLNN has been integrated with intrusion detection system (IDS) to enhance network security to detect zero-day attacks. However, DLNNs themselves have been recently found vulnerable to attacks called adversarial examples and backdoor attacks for image recognition applications. In this work, we present an effective defense method for DLNN based IDS by using Genetic Algorithm (GA) to optimize the generation of triggers neurons selected based on their response to the features to produce the output. We embed the GA-Trigger-Detection neurons within the model to detect and prevent white-box advertorial examples and backdoor attacks against two DLNNs based IDS: Deep Belief Network (DBN) and Stacked Sparse AutoEncoder Based Extreme Learning Machine (SSAELM). We implement two white-box adversarial examples and backdoor attacks from prior work and use them to investigate the proposed defense method. We show that the defense method is sufficient to defend against sophisticated attackers with 99% success rate and only 1% degrade in accuracy. We then show that it successfully weakens backdoor attacks on the two DNN architectures using two benchmark datasets: KDDCUP'99 and Kyoto. Our work provides an important step toward defenses against white-box advertorial examples and backdoor attacks in DLNNs based IDS. © 2020 IEEE.},
  art_number    = {9425293},
  document_type = {Conference Paper},
  doi           = {10.1109/AIPR50011.2020.9425293},
  groups        = {First Filtering},
  journal       = {Proceedings - Applied Imagery Pattern Recognition Workshop},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106175885&doi=10.1109%2fAIPR50011.2020.9425293&partnerID=40&md5=aeda8c73c10e03d2a73bb3bb240d016a},
}

@Conference{Hosseinzadehtaher2020,
  author        = {Hosseinzadehtaher, M. and Khan, A. and Shadmand, M.B. and Abu-Rub, H.},
  title         = {Anomaly Detection in Distribution Power System based on a Condition Monitoring Vector and Ultra- Short Demand Forecasting},
  year          = {2020},
  note          = {cited By 2},
  abstract      = {This paper presents a proactive intrusion detection system (IDS) for smart distribution power systems. The considered attack scenario is manipulation of the advanced measuring infrastructures (AMIs) readings and/or smart inverters data. These manipulated data from the grid edge devices mislead the grid operator for making proper operational planning decisions. In a stealthy attack model, where the attacker compromises significant number of these smart devices, serious demand-supply unbalance can occur that may result in major blackouts. The proposed IDS is based on a condition monitoring vector (CMV) equipped with a learned ultra-short-term demand forecasting (USTDF) mechanism. This cybersecurity approach is able to verify smart devices readings. In the proposed method, the instantaneous difference of collected AMIs and other smart devices data with the ultra-short term forecasted demand is defined as the CMV. This vector probes a pre-defined error band for identifying the compromised smart devices. The learned USTDF mechanism is based on the distribution grid historical load profile and the temperature data for the goal area. An accurate multi-dimensional regression model is developed and learned for forecasting the load behavior in this area. Finally, the suspicious areas are flagged or become separated from the main grid by the network operator based on the proposed CMV outcomes and the output of decision-making module. The proposed IDS aims to enhance the cybersecurity of the smart devices at the grid-edge that plays major role in ensuring the resiliency of the grid. The theoretical analyses are verified by several case studies. © 2020 IEEE.},
  art_number    = {9311534},
  document_type = {Conference Paper},
  doi           = {10.1109/CyberPELS49534.2020.9311534},
  groups        = {First Filtering},
  journal       = {2020 IEEE CyberPELS, CyberPELS 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096905290&doi=10.1109%2fCyberPELS49534.2020.9311534&partnerID=40&md5=155a6e2897857053fed4a04f1eafde90},
}

@Conference{Ali2020,
  author        = {Ali, M. and Hu, Y.-F. and Luong, D.K. and Oguntala, G. and Li, J.-P. and Abdo, K.},
  title         = {Adversarial attacks on AI based intrusion detection system for heterogeneous wireless communications networks},
  year          = {2020},
  note          = {cited By 0},
  volume        = {2020-October},
  abstract      = {It has been recognized that artificial intelligence (AI) will play an important role in future societies. AI has already been incorporated in many industries to improve business processes and automation. Although the aviation industry has successfully implemented flight management systems or autopilot to automate flight operations, it is expected that full embracement of AI remains a challenge. Given the rigorous validation process and the requirements for the highest level of safety standards and risk management, AI needs to prove itself being safe to operate. This paper addresses the safety issues of AI deployment in an aviation network compatible with the Future Communication Infrastructure that utilizes heterogeneous wireless access technologies for communications between the aircraft and the ground networks. It further considers the exploitation of software defined networking (SDN) technologies in the ground network while the adoption of SDN in the airborne network can be optional. Due to the nature of centralized management in SDN-based network, the SDN controller can become a single point of failure or a target for cyber attacks. To countermeasure such attacks, an intrusion detection system utilises AI techniques, more specifically deep neural network (DNN), is considered. However, an adversary can target the AI-based intrusion detection system. This paper examines the impact of AI security attacks on the performance of the DNN algorithm. Poisoning attacks targeting the DSL-KDD datasets which were used to train the DNN algorithm were launched at the intrusion detection system. Results showed that the performance of the DNN algorithm has been significantly degraded in terms of the mean square error, accuracy rate, precision rate and the recall rate. © 2020 IEEE.},
  art_number    = {9256597},
  document_type = {Conference Paper},
  doi           = {10.1109/DASC50938.2020.9256597},
  groups        = {First Filtering},
  journal       = {AIAA/IEEE Digital Avionics Systems Conference - Proceedings},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097983090&doi=10.1109%2fDASC50938.2020.9256597&partnerID=40&md5=7dc34914aa3d55ca5d17aa4d74b81063},
}

@Conference{Li2020277,
  author        = {Li, T. and Hong, Z. and Yu, L.},
  title         = {Machine Learning-based Intrusion Detection for IoT Devices in Smart Home},
  year          = {2020},
  note          = {cited By 0},
  pages         = {277-282},
  volume        = {2020-October},
  abstract      = {The Internet of Things (IoT) is increasingly providing people with objects to connect with the physical world, which plays an important role in people's daily life. Although it has brought us great convenience, there are also suffered from security vulnerabilities and potential threats. Currently, the lack of protection mechanisms for IoT devices with limited resources makes it easy to be attacked. In this paper, we design an intrusion detection system to protect the IoT security. The system uses supervised learning to achieve two main functions: (1) classify the generated malicious traffic; (2) identify the types of attacks. Besides, we propose a lightweight feature selection method, which uses a small number of features to evaluate the two functions. As a result, in the classification experiments, the proposed method automatically extracts 29 and 9 from 88 features, and then the designed system achieves a high accuracy rate of 98.7% and 98.99%. This means that our method still has great accuracy by taking a small number of features. © 2020 IEEE.},
  art_number    = {9264406},
  document_type = {Conference Paper},
  doi           = {10.1109/ICCA51439.2020.9264406},
  groups        = {First Filtering},
  journal       = {IEEE International Conference on Control and Automation, ICCA},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098093931&doi=10.1109%2fICCA51439.2020.9264406&partnerID=40&md5=d88c48d02fe9701fb29a77d6c11a3679},
}

@Conference{Tong2020241,
  author        = {Tong, L. and Wang, L. and Li, S. and Pengfei, Z. and Xiaoming, J.U. and Tongwei, Y. and Weidong, Y.},
  title         = {Adversarial sample detection framework based on autoencoder},
  year          = {2020},
  note          = {cited By 0},
  pages         = {241-245},
  abstract      = {Despite the great success of deep neural networks (DNN) in many tasks, they are often fooled by examples of confrontation created by adding small and purposeful distortions to natural examples. Previous research has mainly focused on improving DNN models, but either results are limited or expensive calculations are required. This paper studies an integrated feature noise reduction method: by using Gaussian filtering, mean filtering, and median filtering, the automatic encoder integrates a neural network to prevent the generation of adaptive adversarial samples. By comparing the reconstruction error of the autoencoder to detect adversarial samples, these simple strategies are not only low-cost, but also complementary to other defensive measures. In this paper, a new autoencoder is created as a modifier to make the two combine to form an adversarial The joint detection framework of the sample to achieve a high detection rate for the latest attacks. For several methods with high attack success rates, FGSM, BIM, PGD and CW attacks. For larger disturbances, the black box attacks against the MNIST data set the undetected rate of CW non-target attacks is 23%, and the detection rate of other attacks is 100%. The undetected rate of CIFAR-10 black box attacks except CW non-target attacks is 25%, and the undetected rate of other attacks is below 5%. In the case of black box attacks with small disturbances, the classification accuracy of the MNIST protected network has reached more than 90%, and the classification accuracy of the CIFAR-10 protected network has reached more than 80% in addition to the CW attack classification. The accuracy rate has also reached a high level. © 2020 IEEE.},
  art_number    = {9403781},
  document_type = {Conference Paper},
  doi           = {10.1109/ICBASE51474.2020.00058},
  groups        = {First Filtering},
  journal       = {Proceedings - 2020 International Conference on Big Data and Artificial Intelligence and Software Engineering, ICBASE 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105373033&doi=10.1109%2fICBASE51474.2020.00058&partnerID=40&md5=32e0f265f8f28e4ac2d39b905c883741},
}

@Conference{Kim20201856,
  author        = {Kim, B.C. and Kim, J.U. and Lee, H. and Ro, Y.M.},
  title         = {Revisiting Role of Autoencoders in Adversarial Settings},
  year          = {2020},
  note          = {cited By 0},
  pages         = {1856-1860},
  volume        = {2020-October},
  abstract      = {To combat against adversarial attacks, autoencoder structure is widely used to perform denoising which is regarded as gradient masking. In this paper, we revisit the role of autoencoders in adversarial settings. Through the comprehensive experimental results and analysis, this paper presents the inherent property of adversarial robustness in the autoencoders. We also found that autoencoders may use robust features that cause inherent adversarial robustness. We believe that our discovery of the adversarial robustness of the autoencoders can provide clues to the future research and applications for adversarial defense. © 2020 IEEE.},
  art_number    = {9191259},
  document_type = {Conference Paper},
  doi           = {10.1109/ICIP40778.2020.9191259},
  groups        = {First Filtering},
  journal       = {Proceedings - International Conference on Image Processing, ICIP},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098637785&doi=10.1109%2fICIP40778.2020.9191259&partnerID=40&md5=7cc0376bd977532fd21f590db90aa774},
}

@Article{Kim20201,
  author        = {Kim, J. and Shim, M. and Hong, S. and Shin, Y. and Choi, E.},
  journal       = {Applied Sciences (Switzerland)},
  title         = {Intelligent detection of iot botnets using machine learning and deep learning},
  year          = {2020},
  note          = {cited By 1},
  number        = {19},
  pages         = {1-22},
  volume        = {10},
  abstract      = {As the number of Internet of Things (IoT) devices connected to the network rapidly increases, network attacks such as flooding and Denial of Service (DoS) are also increasing. These attacks cause network disruption and denial of service to IoT devices. However, a large number of heterogenous devices deployed in the IoT environment make it difficult to detect IoT attacks using traditional rule-based security solutions. It is challenging to develop optimal security models for each type of the device. Machine learning (ML) is an alternative technique that allows one to develop optimal security models based on empirical data from each device. We employ the ML technique for IoT attack detection. We focus on botnet attacks targeting various IoT devices and develop ML-based models for each type of device. We use the N-BaIoT dataset generated by injecting botnet attacks (Bashlite and Mirai) into various types of IoT devices, including a Doorbell, Baby Monitor, Security Camera, and Webcam. We develop a botnet detection model for each device using numerous ML models, including deep learning (DL) models. We then analyze the effective models with a high detection F1-score by carrying out multiclass classification, as well as binary classification, for each model. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
  art_number    = {7009},
  document_type = {Article},
  doi           = {10.3390/app10197009},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092706264&doi=10.3390%2fapp10197009&partnerID=40&md5=f444b42df844992fc4cc0c145810cea1},
}

@Article{Tian20203162,
  author        = {Tian, Q. and Han, D. and Li, K.-C. and Liu, X. and Duan, L. and Castiglione, A.},
  journal       = {Applied Intelligence},
  title         = {An intrusion detection approach based on improved deep belief network},
  year          = {2020},
  note          = {cited By 16},
  number        = {10},
  pages         = {3162-3178},
  volume        = {50},
  abstract      = {In today’s interconnected society, cyberattacks have become more frequent and sophisticated, and existing intrusion detection systems may not be adequate in the complex cyberthreat landscape. For instance, existing intrusion detection systems may have overfitting, low classification accuracy, and high false positive rate (FPR) when faced with significantly large volume and variety of network data. An intrusion detection approach based on improved deep belief network (DBN) is proposed in this paper to mitigate the above problems, where the dataset is processed by probabilistic mass function (PMF) encoding and Min-Max normalization method to simplify the data preprocessing. Furthermore, a combined sparsity penalty term based on Kullback-Leibler (KL) divergence and non-mean Gaussian distribution is introduced in the likelihood function of the unsupervised training phase of DBN, and sparse constraints retrieve the sparse distribution of the dataset, thus avoiding the problem of feature homogeneity and overfitting. Finally, simulation experiments are performed on the NSL-KDD and UNSW-NB15 public datasets. The proposed method achieves 96.17% and 86.49% accuracy, respectively. Experimental results show that compared with the state-of-the-art methods, the proposed method achieves significant improvement in classification accuracy and FPR. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.},
  document_type = {Article},
  doi           = {10.1007/s10489-020-01694-4},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084966407&doi=10.1007%2fs10489-020-01694-4&partnerID=40&md5=c263dc5365820b99f881c584c6a124d1},
}

@Conference{Joshi2020,
  author        = {Joshi, C. and Khochare, J. and Rathod, J. and Kazi, F.},
  title         = {A Semi-Supervised Approach for Detection of SCADA Attacks in Gas Pipeline Control Systems},
  year          = {2020},
  note          = {cited By 0},
  abstract      = {The imperative role played by Supervisory Control And Data Acquisition (SCADA) systems in providing a centralized control for modern infrastructure have made them into one of the most desired targets for malicious attackers owing to its rapid evolution as well as widespread adoption of these systems. To counter these attacks, it is necessary that more robust approaches be adopted. The advent of Machine Learning has shown great potential for its usage along with existing Intrusion Detection Systems (IDS). This paper presents a novel approach to detect malicious behaviour in SCADA data used to control gas pipeline system. As most of the data available in this industry are unsupervised, this paper uses an approach that makes use of a Semi-Supervised Deep Learning architecture- Autoencoder, that is believed to be most suited for this type of tasks. The effectiveness of this deep learning network is due to the fact that it reconstructs the input as the output and in the training process learns only the most important features of normal observations that are representative of the input data; thus malicious data is easily detected due to a high reconstruction error. The proposed algorithm is validated on gas pipeline control system dataset and found to give excellent results in detection. © 2020 IEEE.},
  art_number    = {9242676},
  document_type = {Conference Paper},
  doi           = {10.1109/HYDCON48903.2020.9242676},
  groups        = {First Filtering},
  journal       = {Proceedings of 2020 IEEE-HYDCON International Conference on Engineering in the 4th Industrial Revolution, HYDCON 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096829592&doi=10.1109%2fHYDCON48903.2020.9242676&partnerID=40&md5=25fca8ec180585ed61e1c6396c5027d2},
}

@Conference{Al-Taleb2020,
  author        = {Al-Taleb, N. and Saqib, N.A.},
  title         = {Attacks Detection and Prevention Systems for IoT Networks: A Survey},
  year          = {2020},
  note          = {cited By 0},
  abstract      = {Internet of Things (IoT) is used in critical fields that need to secure it is network from intrusion and attacks. Therefore, many methods proposed to detect and prevent attacks on IoT network. In this paper, we studied different methods that proposed to detect and prevent IoT network attacks where we highlighted the proposed mechanisms and their limitation. © 2020 IEEE.},
  art_number    = {9213770},
  document_type = {Conference Paper},
  doi           = {10.1109/ICCIT-144147971.2020.9213770},
  groups        = {First Filtering},
  journal       = {2020 International Conference on Computing and Information Technology, ICCIT 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098465111&doi=10.1109%2fICCIT-144147971.2020.9213770&partnerID=40&md5=0dd3e00441b0bc19dbcc76453a14fa67},
}

@Conference{Cao20201234,
  author        = {Cao, M. and Badihi, S. and Ahmed, K. and Xiong, P. and Rubin, J.},
  title         = {On Benign Features in Malware Detection},
  year          = {2020},
  note          = {cited By 0},
  pages         = {1234-1238},
  abstract      = {This paper investigates the problem of classifying Android applications into malicious and benign. We analyze the performance of a popular malware detection tool, Drebin, and show that its correct classification decisions often stem from using benign rather than malicious features for making predictions. That, effectively, turns the classifier into a benign app detector rather than a malware detector. While such behavior allows the classifier to achieve a high detection accuracy, it also makes it vulnerable to attacks, e.g., by a malicious app pretending to be benign by using features similar to those of benign apps. In this paper, we propose an approach for deprioritizing benign features in malware detection, focusing the detection on truly malicious portions of the apps. We show that our proposed approach makes a classifier more resilient to attacks while still allowing it to maintain a high detection accuracy. © 2020 ACM.},
  art_number    = {9286043},
  document_type = {Conference Paper},
  doi           = {10.1145/3324884.3418926},
  groups        = {First Filtering},
  journal       = {Proceedings - 2020 35th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099211236&doi=10.1145%2f3324884.3418926&partnerID=40&md5=37121eecaed16acf6a4713b48b8e9afb},
}

@Conference{Akpinar202079,
  author        = {Akpinar, K.O. and Ozcelik, I.},
  title         = {Anomaly detection on etherCAT based water level control automation},
  year          = {2020},
  note          = {cited By 0},
  pages         = {79-82},
  abstract      = {Cyber attacks on Industrial Control Systems (ICS) are considered to be an extremely dangerous threat as they lead material losses or undermine a process. These attacks are mostly targeted to the field level of the critical systems. EtherCAT, one of the most preferred hard real-time protocol in Europe is also open to both known and zero-day attacks. In this work, EtherCAT based anomaly detection is studied applying machine learning methods. To do this, first, a water level control testbed is developed in laboratory scale. Attack vectors are created, and a dataset is formed considering EtherCAT communication principles. Secondly, attributes related to the running-process are selected and reduced. Finally, anomalies are detected both for supervised and unsupervised methods and an evaluation of the methods are done. Results showed that, SVM and Random Forest can be used for EtherCAT anomaly detection as supervised methods. It is also observed that each algorithm applied in unsupervised learning is successful in detecting a specific attack trace. © 2020 IEEE.},
  art_number    = {9219391},
  document_type = {Conference Paper},
  doi           = {10.1109/UBMK50275.2020.9219391},
  groups        = {First Filtering},
  journal       = {5th International Conference on Computer Science and Engineering, UBMK 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095695130&doi=10.1109%2fUBMK50275.2020.9219391&partnerID=40&md5=2e5a0b9c1fb988ebbb71b43374004b6b},
}

@Article{Zhang2020830,
  author        = {Zhang, G. and Liu, X. and Shao, M.},
  journal       = {Moshi Shibie yu Rengong Zhineng/Pattern Recognition and Artificial Intelligence},
  title         = {Generating Adversarial Example with GAN for White-Box Target Attacks [用于白盒目标攻击的GAN对抗样本生成]},
  year          = {2020},
  note          = {cited By 0},
  number        = {9},
  pages         = {830-838},
  volume        = {33},
  abstract      = {Deep neural networks(DNNs) are easily affected by adversarial examples and consequently generate wrong outputs. Adversarial examples are generated by the traditional methods from an optimization perspective. In this paper, a method for generating adversarial examples is proposed with generative adversarial network(GAN) and GAN is exploited for target attack in the white-box setting. Adversarial perturbations are generated by a trained generator to form adversarial examples. Four kinds of loss functions are utilized to constrain the quality of adversarial examples and improve attack success rates. The effectiveness of the proposed method is testified through extensive experiments on MNIST, CIFAR-10 and ImageNet datasets and the proposed method produces higher attack success rates. © 2020, Science Press. All right reserved.},
  document_type = {Article},
  doi           = {10.16451/j.cnki.issn1003-6059.202009007},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094581257&doi=10.16451%2fj.cnki.issn1003-6059.202009007&partnerID=40&md5=59fdfdf17ab55c94fa14f27888e3a8df},
}

@Article{Dunn2020,
  author        = {Dunn, C. and Moustafa, N. and Turnbull, B.},
  journal       = {Sustainability (Switzerland)},
  title         = {Robustness evaluations of sustainable machine learning models against data poisoning attacks in the internet of things},
  year          = {2020},
  note          = {cited By 2},
  number        = {17},
  volume        = {12},
  abstract      = {With the increasing popularity of the Internet of Things (IoT) platforms, the cyber security of these platforms is a highly active area of research. One key technology underpinning smart IoT systems is machine learning, which classifies and predicts events from large-scale data in IoT networks. Machine learning is susceptible to cyber attacks, particularly data poisoning attacks that inject false data when training machine learning models. Data poisoning attacks degrade the performances of machine learning models. It is an ongoing research challenge to develop trustworthy machine learning models resilient and sustainable against data poisoning attacks in IoT networks. We studied the effects of data poisoning attacks on machine learning models, including the gradient boosting machine, random forest, naive Bayes, and feed-forward deep learning, to determine the levels to which the models should be trusted and said to be reliable in real-world IoT settings. In the training phase, a label modification function is developed to manipulate legitimate input classes. The function is employed at data poisoning rates of 5%, 10%, 20%, and 30% that allow the comparison of the poisoned models and display their performance degradations. The machine learning models have been evaluated using the ToN_IoT and UNSW NB-15 datasets, as they include a wide variety of recent legitimate and attack vectors. The experimental results revealed that the models' performances will be degraded, in terms of accuracy and detection rates, if the number of the trained normal observations is not significantly larger than the poisoned data. At the rate of data poisoning of 30% or greater on input data, machine learning performances are significantly degraded. © 2020 by the authors.},
  art_number    = {6434},
  document_type = {Article},
  doi           = {10.3390/SU12166434},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090401066&doi=10.3390%2fSU12166434&partnerID=40&md5=6f5d67270d887a4171b7d46776286a3a},
}

@Article{Aiyanyo2020,
  author        = {Aiyanyo, I.D. and Samuel, H. and Lim, H.},
  journal       = {Applied Sciences (Switzerland)},
  title         = {A systematic review of defensive and offensive cybersecurity with machine learning},
  year          = {2020},
  note          = {cited By 0},
  number        = {17},
  volume        = {10},
  abstract      = {This is a systematic review of over one hundred research papers about machine learning methods applied to defensive and offensive cybersecurity. In contrast to previous reviews, which focused on several fragments of research topics in this area, this paper systematically and comprehensively combines domain knowledge into a single review. Ultimately, this paper seeks to provide a base for researchers that wish to delve into the field of machine learning for cybersecurity. Our findings identify the frequently used machine learning methods within supervised, unsupervised, and semi-supervised machine learning, the most useful data sets for evaluating intrusion detection methods within supervised learning, and methods from machine learning that have shown promise in tackling various threats in defensive and offensive cybersecurity. © 2020 by the authors.},
  art_number    = {5811},
  document_type = {Review},
  doi           = {10.3390/app10175811},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090019755&doi=10.3390%2fapp10175811&partnerID=40&md5=0695ef795c4fe10dbdde8e7383ad3e5d},
}

@Article{Chen2020141,
  author        = {Chen, Y. and Gong, X. and Wang, Q. and Di, X. and Huang, H.},
  journal       = {IEEE Network},
  title         = {Backdoor Attacks and Defenses for Deep Neural Networks in Outsourced Cloud Environments},
  year          = {2020},
  note          = {cited By 2},
  number        = {5},
  pages         = {141-147},
  volume        = {34},
  abstract      = {Deep neural networks have achieved tremendous success in various fields, especially in recognition and classification applications. However, faced with the difficulty of training millions of parameters of such networks, many users outsource the training procedure of a specific prediction work to the powerful cloud servers that own abundant computation and storage resources. Although such outsourced training can significantly simplify and expedite the development circles, it also introduces many security risks. In recent years, a new type of attack, the so-called backdoor attack, has attracted much attention, where the attacker's goal is to create a maliciously deep neural network to make misclassification on the special inputs with the backdoor trigger. For its concealment, such attacks can potentially cause disastrous consequences. Subsequently, many defense mechanisms against this attack are also appearing. In this article, we conduct a retrospective review on the existing schemes of the backdoor attacks and defenses in outsourced cloud environments. According to the resources the adversary has, and whether the detection time is during run-time or not, we classify the attack and defense approaches into multiple categories. We present a detailed overview of each category, and we provide a comparison of these approaches and evaluate part of the attack schemes by the experiments. We also highlight various future research directions in this field. These views shed light on possible avenues for future research. © 1986-2012 IEEE.},
  art_number    = {9060997},
  document_type = {Article},
  doi           = {10.1109/MNET.011.1900577},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083020019&doi=10.1109%2fMNET.011.1900577&partnerID=40&md5=b0892d9b148d1c10900e6c93e4e1d095},
}

@Article{Rajagopal20202734,
  author        = {Rajagopal, S. and Kundapur, P.P. and Hareesha, K.S.},
  journal       = {International Journal of Electrical and Computer Engineering},
  title         = {A predictive model for network intrusion detection using stacking approach},
  year          = {2020},
  note          = {cited By 4},
  number        = {3},
  pages         = {2734-2741},
  volume        = {10},
  abstract      = {Due to the emerging technological advances, cyber-attacks continue to hamper information systems. The changing dimensionality of cyber threat landscape compel security experts to devise novel approaches to address the problem of network intrusion detection. Machine learning algorithms are extensively used to detect intrusions by dint of their remarkable predictive power. This work presents an ensemble approach for network intrusion detection using a concept called Stacking. As per the popular no free lunch theorem of machine learning, employing single classifier for a problem at hand may not be ideal to achieve generalization. Therefore, the proposed work on network intrusion detection emphasizes upon a combinative approach to improve performance. A robust processing paradigm called Graphlab Create, capable of upholding massive data has been used to implement the proposed methodology. Two benchmark datasets like UNSW NB-15 and UGR' 16 datasets are considered to demonstrate the validity of predictions. Empirical investigation has illustrated that the performance of the proposed approach has been reasonably good. The contribution of the proposed approach lies in its finesse to generate fewer misclassifications pertaining to various attack vectors considered in the study. Copyright © 2020 Institute of Advanced Engineering and Science. All rights reserved.},
  document_type = {Article},
  doi           = {10.11591/ijece.v10i3.pp2734-2741},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077908261&doi=10.11591%2fijece.v10i3.pp2734-2741&partnerID=40&md5=6c3a7d42e0f6a982ab53e2a460f2dc3c},
}

@Conference{Cambiaso2020,
  author        = {Cambiaso, E. and Aiello, M. and Mongelli, M. and Vaccari, I.},
  title         = {Detection and classification of slow DoS attacks targeting network servers},
  year          = {2020},
  note          = {cited By 1},
  abstract      = {Low-rate denial of service attacks are considered a serious threat for network systems. In this paper, we investigate such topic, by proposing a novel anomaly-based intrusion detection system. We validate the proposed system and report the weaknesses we have found. By working from the attacker's perspective, we also try to elude the proposed algorithm. Results show that in order to avoid detection, the attacker would require high-bandwidth to perpetrate the attack. The proposed method should therefore be considered an efficient method to detect running Slow DoS Attacks. © 2020 ACM.},
  document_type = {Conference Paper},
  doi           = {10.1145/3407023.3409198},
  groups        = {First Filtering},
  journal       = {ACM International Conference Proceeding Series},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090338522&doi=10.1145%2f3407023.3409198&partnerID=40&md5=8e9299f1ec2980806af5a060e2a41d69},
}

@Article{Bouyeddou2020870,
  author        = {Bouyeddou, B. and Kadri, B. and Harrou, F. and Sun, Y.},
  journal       = {Engineering Science and Technology, an International Journal},
  title         = {DDOS-attacks detection using an efficient measurement-based statistical mechanism},
  year          = {2020},
  note          = {cited By 2},
  number        = {4},
  pages         = {870-878},
  volume        = {23},
  abstract      = {A monitoring mechanism is vital for detecting malicious attacks against cyber systems. Detecting denial of service (DOS) and distributed DOS (DDOS) is one of the most important security challenges facing network technologies. This paper introduces a reliable detection mechanism based on the continuous ranked probability score (CRPS) statistical metric and exponentially smoothing (ES) scheme for enabling efficient detection of DOS and DDOS attacks. In this regard, the CRPS is used to quantify the dissimilarity between a new observation and the distribution of normal traffic. The ES scheme, which is sensitive in detecting small changes, is applied to CRPS measurements for anomaly detection. Moreover, in CRPS-ES approach, a nonparametric decision threshold computed via kernel density estimation is used to suitably detect anomalies. Tests on three publically available datasets proclaim the efficiency of the proposed mechanism in detecting cyber-attacks. © 2020 Karabuk University},
  document_type = {Article},
  doi           = {10.1016/j.jestch.2020.05.002},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086093684&doi=10.1016%2fj.jestch.2020.05.002&partnerID=40&md5=a3a3a53e827876b2bd37c6fecd74e019},
}

@Article{Apruzzese2020427,
  author        = {Apruzzese, G. and Andreolini, M. and Colajanni, M. and Marchetti, M.},
  journal       = {IEEE Transactions on Emerging Topics in Computational Intelligence},
  title         = {Hardening random forest cyber detectors against adversarial attacks},
  year          = {2020},
  note          = {cited By 1},
  number        = {4},
  pages         = {427-439},
  volume        = {4},
  abstract      = {Machine learning algorithms are effective in several applications, but they are not as much successful when applied to intrusion detection in cyber security. Due to the high sensitivity to their training data, cyber detectors based on machine learning are vulnerable to targeted adversarial attacks that involve the perturbation of initial samples. Existing defenses assume unrealistic scenarios; their results are underwhelming in non-Adversarial settings; or they can be applied only to machine learning algorithms that perform poorly for cyber security. We present an original methodology for countering adversarial perturbations targeting intrusion detection systems based on random forests. As a practical application, we integrate the proposed defense method in a cyber detector analyzing network traffic. The experimental results on millions of labelled network flows show that the new detector has a twofold value: it outperforms state-of-The-Art detectors that are subject to adversarial attacks; it exhibits robust results both in adversarial and non-Adversarial scenarios. © 2017 IEEE.},
  art_number    = {9099383},
  document_type = {Article},
  doi           = {10.1109/TETCI.2019.2961157},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085753098&doi=10.1109%2fTETCI.2019.2961157&partnerID=40&md5=3099aa7985ff046d291c89da70e67e09},
}

@Conference{Shu20201,
  author        = {Shu, D. and Leslie, N.O. and Kamhoua, C.A. and Tucker, C.S.},
  title         = {Generative adversarial attacks against intrusion detection systems using active learning},
  year          = {2020},
  note          = {cited By 0},
  pages         = {1-6},
  abstract      = {Intrusion Detection Systems (IDS) are increasingly adopting machine learning (ML)-based approaches to detect threats in computer networks due to their ability to learn underlying threat patterns/features. However, ML-based models are susceptible to adversarial attacks, attacks wherein slight perturbations of the input features, cause misclassifications. We propose a method that uses active learning and generative adversarial networks to evaluate the threat of adversarial attacks on ML-based IDS. Existing adversarial attack methods require a large amount of training data or assume knowledge of the IDS model itself (e.g., loss function), which may not be possible in real-world settings. Our method overcomes these limitations by demonstrating the ability to compromise an IDS using limited training data and assuming no prior knowledge of the IDS model other than its binary classification (i.e., benign or malicious). Experimental results demonstrate the ability of our proposed model to achieve a 98.86% success rate in bypassing the IDS model using only 25 labeled data points during model training. The knowledge gained by compromising the ML-based IDS, can be integrated into the IDS in order to enhance its robustness against similar ML-based adversarial attacks. © 2020 Owner/Author.},
  document_type = {Conference Paper},
  doi           = {10.1145/3395352.3402618},
  groups        = {First Filtering},
  journal       = {WiseML 2020 - Proceedings of the 2nd ACM Workshop on Wireless Security and Machine Learning},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091963060&doi=10.1145%2f3395352.3402618&partnerID=40&md5=60051b5f92f338d417f84f6b7222d493},
}

@Conference{Rajapkar2020,
  author        = {Rajapkar, A. and Binnar, P. and Kazi, F.},
  title         = {Design of Intrusion Prevention System for OT Networks Using Deep Neural Networks},
  year          = {2020},
  note          = {cited By 0},
  abstract      = {The Automation industries that uses Supervisory Control and Data Acquisition (SCADA) systems are highly vulnerable for Network threats. Systems that are air-gapped and isolated from the internet are highly affected due to insider attacks like Spoofing, DOS and Malware threats that affects confidentiality, integrity and availability of Operational Technology (OT) system elements and degrade its performance even though security measures are taken. In this paper, a behavior-based intrusion prevention system (IPS) is designed for OT networks. The proposed system is implemented on SCADA test bed with two systems replicates automation scenarios in industry. This paper describes 4 main classes of cyber-attacks with their subclasses against SCADA systems and methodology with design of components of IPS system, database creation, Baselines and deployment of system in environment. IPS system identifies not only IT protocols but also Industry Control System (ICS) protocols Modbus and DNP3 with their inside communication fields using deep packet inspection (DPI). The analytical results show 99.89% accuracy on binary classification and 97.95% accuracy on multiclass classification of different attack vectors performed on network with low false positive rate. These results are also validated by actual deployment of IPS in SCADA systems with the prevention of DOS attack. © 2020 IEEE.},
  art_number    = {9225339},
  document_type = {Conference Paper},
  doi           = {10.1109/ICCCNT49239.2020.9225339},
  groups        = {First Filtering},
  journal       = {2020 11th International Conference on Computing, Communication and Networking Technologies, ICCCNT 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096593078&doi=10.1109%2fICCCNT49239.2020.9225339&partnerID=40&md5=33d96f7c1f87e83bad1a219e2cb0c061},
}

@Conference{Patel2020,
  author        = {Patel, D. and Kozma, R.},
  title         = {Unsupervised Features Extracted using Winner-Take-All Mechanism Lead to Robust Image Classification},
  year          = {2020},
  note          = {cited By 0},
  abstract      = {Leading mainstream image processing approaches produce excellent performance using convolutional neural networks trained by backpropagation (BP) learning rules. Unsupervised learning approaches have been popular due to their biological significance, though they typically underperform compared to BP results. In this work, we demonstrate that features extracted in an unsupervised manner using the biologically inspired Hebbian learning rule in a winner-take-all setting, perform competitively with BP on the image classification task. The convolutional filters learned by Hebbian rule are smoother than filters learned using BP. The quality of the two training approaches is compared based on metrics such as the speed of training and classification accuracy. We demonstrate that the extracted features of unsupervised learning are more robust to noise as compared to BP. © 2020 IEEE.},
  art_number    = {9207242},
  document_type = {Conference Paper},
  doi           = {10.1109/IJCNN48605.2020.9207242},
  groups        = {First Filtering},
  journal       = {Proceedings of the International Joint Conference on Neural Networks},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093829853&doi=10.1109%2fIJCNN48605.2020.9207242&partnerID=40&md5=5827204a8818651d2bb81aeb77a1d161},
}

@Conference{Zhang2020,
  author        = {Zhang, Y. and Yan, J.},
  title         = {Semi-Supervised Domain-Adversarial Training for Intrusion Detection against False Data Injection in the Smart Grid},
  year          = {2020},
  note          = {cited By 0},
  abstract      = {The smart grid faces with increasingly sophisticated cyber-physical threats, against which machine learning (ML)-based intrusion detection systems have become a powerful and promising solution to smart grid security monitoring. However, many ML algorithms presume that training and testing data follow the same or similar data distributions, which may not hold in the dynamic time-varying systems like the smart grid. As operating points may change dramatically over time, the resulting data distribution shifts could lead to degraded detection performance and delayed incidence responses. To address this challenge, this paper proposes a semi-supervised framework based on domain-adversarial training to transfer the knowledge of known attack incidences to detect returning threats at different hours and load patterns. Using normal operation data of the ISO New England grids, the proposed framework leverages adversarial training to adapt learned models against new attacks launched at different times of the day. Effectiveness of the proposed detection framework is evaluated against the well-studied false data injection attacks synthesized on the IEEE 30-bus system, and the results demonstrated the superiority of the framework against persistent threats recurring in the highly dynamic smart grid. © 2020 IEEE.},
  art_number    = {9207525},
  document_type = {Conference Paper},
  doi           = {10.1109/IJCNN48605.2020.9207525},
  groups        = {First Filtering},
  journal       = {Proceedings of the International Joint Conference on Neural Networks},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093827047&doi=10.1109%2fIJCNN48605.2020.9207525&partnerID=40&md5=161f063a9d165b9e93331202b61e6473},
}

@Conference{Cho2020,
  author        = {Cho, S. and Jun, T.J. and Oh, B. and Kim, D.},
  title         = {DAPAS : Denoising Autoencoder to Prevent Adversarial attack in Semantic Segmentation},
  year          = {2020},
  note          = {cited By 0},
  abstract      = {Nowadays, deep learning techniques show dramatic performance in computer vision areas, and they even outperform humans on complex tasks such as ImageNet classification. But it turns out a deep learning based model is vulnerable to some small perturbation called an adversarial attack. This is a problem in the view of the safety and security of artificial intelligence, which has recently been studied a lot. These attacks have shown that they can easily fool models of image classification, semantic segmentation, and object detection. We focus on the adversarial attack in semantic segmentation tasks since there is little work in this task. We point out this attack can be protected by denoise autoencoder, which is used for denoising the perturbation and restoring the original images. We build a deep denoise autoencoder model for removing the adversarial perturbation and restoring the clean image. We experiment with various noise distributions and verify the effect of denoise autoencoder against adversarial attack in semantic segmentation task. © 2020 IEEE.},
  art_number    = {9207291},
  document_type = {Conference Paper},
  doi           = {10.1109/IJCNN48605.2020.9207291},
  groups        = {First Filtering},
  journal       = {Proceedings of the International Joint Conference on Neural Networks},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093824150&doi=10.1109%2fIJCNN48605.2020.9207291&partnerID=40&md5=8105f72adce2f4f26ab556017f168ff7},
}

@Conference{Zhu2020257,
  author        = {Zhu, K. and Wu, B. and Wang, B.},
  title         = {Deepfake detection with clustering-based embedding regularization},
  year          = {2020},
  note          = {cited By 0},
  pages         = {257-264},
  abstract      = {In recent months, AI-synthesized face swapping videos referred to as deepfake have become an emerging problem. False video is becoming more and more difficult to distinguish, which brings a series of challenges to social security. Some scholars are devoted to studying how to improve the detection accuracy of deepfake video. At the same time, in order to conduct better research, some datasets for deepfake detection are made. Companies such as Google and Facebook have also spent huge sums of money to produce datasets for deepfake video detection, as well as holding deepfake detection competitions. The continuous advancement of video tampering technology and the improvement of video quality have also brought great challenges to deepfake detection. Some scholars have achieved certain results on existing datasets, while the results on some high-quality datasets are not as good as expected. In this paper, we propose new method with clustering-based embedding regularization for deepfake detection. We use open source algorithms to generate videos which can simulate distinctive artifacts in the deepfake videos. To improve the local smoothness of the representation space, we integrate a clustering-based embedding regularization term into the classification objective, so that the obtained model learns to resist adversarial examples. We evaluate our method on three latest deepfake datasets. Experimental results demonstrate the effectiveness of our method. © 2020 IEEE.},
  art_number    = {9172873},
  document_type = {Conference Paper},
  doi           = {10.1109/DSC50466.2020.00046},
  groups        = {First Filtering},
  journal       = {Proceedings - 2020 IEEE 5th International Conference on Data Science in Cyberspace, DSC 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092053151&doi=10.1109%2fDSC50466.2020.00046&partnerID=40&md5=ea9774ce062fcfd56fbad140d7ae3abb},
}

@Conference{Shahriar2020376,
  author        = {Shahriar, M.H. and Haque, N.I. and Rahman, M.A. and Alonso, M.},
  title         = {G-IDS: Generative Adversarial Networks Assisted Intrusion Detection System},
  year          = {2020},
  note          = {cited By 4},
  pages         = {376-385},
  abstract      = {The boundaries of cyber-physical systems (CPS) and the Internet of Things (IoT) are converging together day by day to introduce a common platform on hybrid systems. Moreover, the combination of artificial intelligence (AI) with CPS creates a new dimension of technological advancement. All these connectivity and dependability are creating massive space for the attackers to launch cyber attacks. To defend against these attacks, intrusion detection system (IDS) has been widely used. However, emerging CPS fields suffer from imbalanced and missing sample data, which makes the training of IDS difficult. In this paper, we propose a generative adversarial network (GAN) based intrusion detection system (G-IDS), where GAN generates synthetic samples, and IDS gets trained on them along with the original ones. G-IDS also fixes the difficulties of imbalanced or missing data problems. We model a network security dataset for an emerging CPS using NSL KDD-99 dataset and evaluate our proposed model's performance using different metrics. We find that our proposed G-IDS model performs much better in attack detection and model stabilization during the training process than a standalone IDS. © 2020 IEEE.},
  art_number    = {9202722},
  document_type = {Conference Paper},
  doi           = {10.1109/COMPSAC48688.2020.0-218},
  groups        = {First Filtering},
  journal       = {Proceedings - 2020 IEEE 44th Annual Computers, Software, and Applications Conference, COMPSAC 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091243268&doi=10.1109%2fCOMPSAC48688.2020.0-218&partnerID=40&md5=c8023c7886e3ac66bd8e896017bb867c},
}

@Article{Alaeiyan2020661,
  author        = {Alaeiyan, M. and Parsa, S. and Vinod, P. and Conti, M.},
  journal       = {Computer Communications},
  title         = {Detection of algorithmically-generated domains: An adversarial machine learning approach},
  year          = {2020},
  note          = {cited By 3},
  pages         = {661-673},
  volume        = {160},
  abstract      = {Domain name detection techniques are widely used to detect Algorithmically Generated Domain names (AGD) applied by Botnets. A major difficulty with these algorithms is to detect those generated names which are meaningful. In this way, Command and Control (C2) servers are detected. Machine learning techniques have been of great use to generalize the attributes of the meaningful names, generated algorithmically. To resist such techniques, the distribution of characters is used as a basis to generate meaningful domain names. Such techniques are called adversarial attacks attempting to fool machine learning methods. However, our experiments with more than 252757 samples show that in addition to character distribution of domain names, randomness property and pronounceability attributes are of great use to detect such meaningful names. Using these additional attributes, we have been able to identify malicious domain names with an accuracy of 98.19%. © 2020 Elsevier B.V.},
  document_type = {Article},
  doi           = {10.1016/j.comcom.2020.04.033},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087886419&doi=10.1016%2fj.comcom.2020.04.033&partnerID=40&md5=31dbc2a2eac0413ad3b6ee7130d38259},
}

@Article{Adewole20204802,
  author        = {Adewole, K.S. and Han, T. and Wu, W. and Song, H. and Sangaiah, A.K.},
  journal       = {Journal of Supercomputing},
  title         = {Twitter spam account detection based on clustering and classification methods},
  year          = {2020},
  note          = {cited By 13},
  number        = {7},
  pages         = {4802-4837},
  volume        = {76},
  abstract      = {Twitter social network has gained more popularity due to the increase in social activities of registered users. Twitter performs dual functions of online social network (OSN), acting as a microblogging OSN, and at the same time as a news update platform. Recently, the growth in Twitter social interactions has attracted the attention of cybercriminals. Spammers have used Twitter to spread malicious messages, post phishing links, flood the network with fake accounts, and engage in other malicious activities. The process of detecting the network of spammers who engage in these activities is an important step toward identifying individual spam account. Researchers have proposed a number of approaches to identify a group of spammers. However, each of these approaches addressed a specific category of spammer. This paper proposes a different approach to detect spammers on Twitter based on the similarities that exist among spam accounts. A number of features were introduced to improve the performance of the three classification algorithms selected in this study. The proposed approach applied principal component analysis and tuned K-means algorithm to cluster over 200,000 accounts, randomly selected from more than 2 million tweets to detect the clusters of spammers. Experimental results show that Random Forest achieved the highest accuracy of 96.30%. This result is followed by multilayer perceptron with 96.00% and support vector machine, which achieved 95.60%. The performance of the selected classifiers based on class imbalance also revealed that Random Forest achieved the highest accuracy, precision, recall, and F-measure. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.},
  document_type = {Article},
  doi           = {10.1007/s11227-018-2641-x},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055354458&doi=10.1007%2fs11227-018-2641-x&partnerID=40&md5=0c8f247a1370f3014e2f03b120795222},
}

@Conference{Friday2020218,
  author        = {Friday, K. and Kfoury, E. and Bou-Harb, E. and Crichigno, J.},
  title         = {Towards a unified in-network DDoS detection and mitigation strategy},
  year          = {2020},
  note          = {cited By 1},
  pages         = {218-226},
  abstract      = {Distributed Denial of Service (DDoS) attacks have terrorized our networks for decades, and with attacks now reaching 1.7 Tbps, even the slightest latency in detection and subsequent remediation is enough to bring an entire network down. Though strides have been made to address such maliciousness within the context of Software Defined Networking (SDN), they have ultimately proven ineffective. Fortunately, P4 has recently emerged as a platform-agnostic language for programming the data plane and in turn allowing for customized protocols and packet processing. To this end, we propose a first-of-a-kind P4-based detection and mitigation scheme that will not only function as intended regardless of the size of the attack, but will also overcome the vulnerabilities of SDN that have characteristically been exploited by DDoS. Moreover, it successfully defends against the broad spectrum of currently relevant attacks while concurrently emphasizing the Quality of Service (QoS) of legitimate end-users and overall SDN functionality. We demonstrate the effectiveness of the proposed scheme using a software programmable P4-switch, namely, the Behavorial Model version 2 (BMv2), showing its ability to withstand a variety of DDoS attacks in real-time via three use cases that can be generalized to most contemporary attack vectors. Specifically, the results substantiate that the mechanism herein is orders of magnitude faster than traditional polling techniques (e.g., NetFlow or sFlow) while minimizing the impact on benign traffic. We concur that the approach's design particularities facilitate seamless and scalable deployments in high-speed networks requiring line-rate functionality, in addition to being generic enough to be integrated into viable network topologies. © 2020 IEEE.},
  art_number    = {9165336},
  document_type = {Conference Paper},
  doi           = {10.1109/NetSoft48620.2020.9165336},
  groups        = {First Filtering},
  journal       = {Proceedings of the 2020 IEEE Conference on Network Softwarization: Bridging the Gap Between AI and Network Softwarization, NetSoft 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091961068&doi=10.1109%2fNetSoft48620.2020.9165336&partnerID=40&md5=3892ab12cc656c40486188ee6df46a69},
}

@Article{Taheri20201,
  author        = {Taheri, S. and Khormali, A. and Salem, M. and Yuan, J.-S.},
  journal       = {Big Data and Cognitive Computing},
  title         = {Developing a robust defensive system against adversarial examples using generative adversarial networks},
  year          = {2020},
  note          = {cited By 0},
  number        = {2},
  pages         = {1-15},
  volume        = {4},
  abstract      = {In this work, we propose a novel defense system against adversarial examples leveraging the unique power of Generative Adversarial Networks (GANs) to generate new adversarial examples for model retraining. To do so, we develop an automated pipeline using combination of pre-trained convolutional neural network and an external GAN, that is, Pix2Pix conditional GAN, to determine the transformations between adversarial examples and clean data, and to automatically synthesize new adversarial examples. These adversarial examples are employed to strengthen the model, attack, and defense in an iterative pipeline. Our simulation results demonstrate the success of the proposed method. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
  art_number    = {11},
  document_type = {Article},
  doi           = {10.3390/bdcc4020011},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089846347&doi=10.3390%2fbdcc4020011&partnerID=40&md5=77b4f04879288d00fe1a6261621175b8},
}

@Conference{Zhang2020,
  author        = {Zhang, J. and Zhang, J. and Chen, J. and Yu, S.},
  title         = {GAN Enhanced Membership Inference: A Passive Local Attack in Federated Learning},
  year          = {2020},
  note          = {cited By 0},
  volume        = {2020-June},
  abstract      = {Federated learning has lately received great attention for its privacy protection feature. However, recent researches found that federated learning models are susceptible to various inference attacks. In this paper, we point out a membership inference attack method that can cause a serious privacy leakage in federated learning. An adversary who is a participant in federated learning can train a classification attack model to launch the membership inference attack, which determines if a data record is in the model's training dataset. The existing membership inference method is dissatisfied due to a lack of attack data since the training data of each participant are independent. To overcome the lack of attack data, an adversary can enrich attack data using the generative adversarial network (GAN), which is a practical method to increase data diversity. We substantiate that this GAN enhanced membership inference attack method has a 98 attack accuracy. We perform experiments to show that data diversity and the overfitting make federated learning models susceptible. © 2020 IEEE.},
  art_number    = {9148790},
  document_type = {Conference Paper},
  doi           = {10.1109/ICC40277.2020.9148790},
  groups        = {First Filtering},
  journal       = {IEEE International Conference on Communications},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089422839&doi=10.1109%2fICC40277.2020.9148790&partnerID=40&md5=311ffa6dba5bd0633bf689cb5590b9d1},
}

@Conference{Surma20201,
  author        = {Surma, J.},
  title         = {Hacking Machine Learning: Towards The Comprehensive Taxonomy of Attacks Against Machine Learning Systems},
  year          = {2020},
  note          = {cited By 0},
  pages         = {1-4},
  abstract      = {The research on machine learning systems in adversarial environments is a relatively new discipline at the intersection between machine learning and cybersecurity. Still, machine learning algorithms that beat human performance in naturally occurring scenarios are often seen as failing dramatically when an adversary is able to influence training and/or usage of machine learning system. Machine learning is already used for many extremely significant applications and will be used on a much greater scale and will have even greater significance in the approaching future. The aim of this article is to provide a comprehensive review of scientific works in the field of cybersecurity of machine learning and to present an original taxonomy of adversarial attacks against machine learning systems in this context. A pertinent taxonomy enables good understanding of full spectrum of threats and development of systems resistant to intentional hackers' attacks. © 2020 ACM.},
  document_type = {Conference Paper},
  doi           = {10.1145/3390557.3394126},
  groups        = {First Filtering},
  journal       = {ACM International Conference Proceeding Series},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086502105&doi=10.1145%2f3390557.3394126&partnerID=40&md5=a0066a9c89119043dd6912fe4d6a86ed},
}

@Conference{Chen20202218,
  author        = {Chen, K. and Chen, Y. and Zhou, H. and Mao, X. and Li, Y. and He, Y. and Xue, H. and Zhang, W. and Yu, N.},
  title         = {Self-supervised adversarial training},
  year          = {2020},
  note          = {cited By 0},
  pages         = {2218-2222},
  volume        = {2020-May},
  abstract      = {Recent work has demonstrated that neural networks are vulnerable to adversarial examples. To escape from the predicament, many works try to harden the model in various ways, in which adversarial training is an effective way which learns robust feature representation so as to resist adversarial attacks. Meanwhile, the self-supervised learning aims to learn robust and semantic embedding from data itself. With these views, we introduce self-supervised learning to against adversarial examples in this paper. Specifically, the self-supervised representation coupled with k-Nearest Neighbour is proposed for classification. To further strengthen the defense ability, self-supervised adversarial training is proposed, which maximizes the mutual information between the representations of original examples and the corresponding adversarial examples. Experimental results show that the self-supervised representation outperforms its supervised version in respect of robustness and self-supervised adversarial training can further improve the defense ability efficiently. © 2020 IEEE},
  art_number    = {9054475},
  document_type = {Conference Paper},
  doi           = {10.1109/ICASSP40776.2020.9054475},
  groups        = {First Filtering},
  journal       = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091149654&doi=10.1109%2fICASSP40776.2020.9054475&partnerID=40&md5=11df57328cacaad803ec1b26b97c9fe3},
}

@Article{Yu2020,
  author        = {Yu, X. and Lu, H. and Yang, X. and Chen, Y. and Song, H. and Li, J. and Shi, W.},
  journal       = {International Journal of Distributed Sensor Networks},
  title         = {An adaptive method based on contextual anomaly detection in Internet of Things through wireless sensor networks},
  year          = {2020},
  note          = {cited By 2},
  number        = {5},
  volume        = {16},
  abstract      = {With the widespread propagation of Internet of Things through wireless sensor networks, massive amounts of sensor data are being generated at an unprecedented rate, resulting in very large quantities of explicit or implicit information. When analyzing such sensor data, it is of particular importance to detect accurately and efficiently not only individual anomalous behaviors but also anomalous events (i.e. patterns of behaviors). However, most previous work has focused only on detecting anomalies while generally ignoring the correlations between them. Even in approaches that take into account correlations between anomalies, most disregard the fact that the anomaly status of sensor data changes over time. In this article, we propose an unsupervised contextual anomaly detection method in Internet of Things through wireless sensor networks. This method accounts for both a dynamic anomaly status and correlations between anomalies based contextually on their spatial and temporal neighbors. We then demonstrate the effectiveness of the proposed method in an anomaly detection model. The experimental results show that this method can accurately and efficiently detect not only individual anomalies but also anomalous events. © The Author(s) 2020.},
  document_type = {Article},
  doi           = {10.1177/1550147720920478},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085257384&doi=10.1177%2f1550147720920478&partnerID=40&md5=f2dc0a1bf7ee080e4819f006d6cdd055},
}

@Article{Musleh20202218,
  author        = {Musleh, A.S. and Chen, G. and Dong, Z.Y.},
  journal       = {IEEE Transactions on Smart Grid},
  title         = {A Survey on the Detection Algorithms for False Data Injection Attacks in Smart Grids},
  year          = {2020},
  note          = {cited By 34},
  number        = {3},
  pages         = {2218-2234},
  volume        = {11},
  abstract      = {Cyber-physical attacks are the main substantial threats facing the utilization and development of the various smart grid technologies. Among these attacks, false data injection attack represents a main category with its widely varied types and impacts that have been extensively reported recently. In addressing this threat, several detection algorithms have been developed in the last few years. These were either model-based or data-driven algorithms. This paper provides an intensive summary of these algorithms by categorizing them and elaborating on the pros and cons of each category. The paper starts by introducing the various cyber-physical attacks along with the main reported incidents in history. The significance and the impacts of the false data injection attacks are then reported. The concluding remarks present the main criteria that should be considered in developing future detection algorithms for the false data injection attacks. © 2010-2012 IEEE.},
  art_number    = {8887286},
  document_type = {Article},
  doi           = {10.1109/TSG.2019.2949998},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083970558&doi=10.1109%2fTSG.2019.2949998&partnerID=40&md5=48f67e4277afbeac52d03bb732d6c93e},
}

@Article{Islabudeen2020193,
  author        = {Islabudeen, M. and Kavitha Devi, M.K.},
  journal       = {Wireless Personal Communications},
  title         = {A Smart Approach for Intrusion Detection and Prevention System in Mobile Ad Hoc Networks Against Security Attacks},
  year          = {2020},
  note          = {cited By 10},
  number        = {1},
  pages         = {193-224},
  volume        = {112},
  abstract      = {Design of intrusion detection and prevention scheme for improving MANET security, with considered energy efficiency, detection rate, delay, and false positive rate are major research issues. Most of the existing solutions have suffered to obtain accurate detection rate in minimal time execution and energy consumption. In this work we proposed a Smart approach for intrusion detection and prevention system (SA-IDPS) to mitigate attacks in MANET by machine learning methods. Initially, mobile users are registered in Trusted Authority using One Way Hash Chain Function. Each mobile user submits their following information to verify authentication: finger vein biometric, user id, and latitude and longitude. Intrusion detection is executed using four entities: Packet Analyzer, Preprocessing Unit, Feature Extraction Unit and Classification Unit. In packet analyzer, we verify whether any attack pattern is found or not. It is implemented using Type 2 Fuzzy Controller which considers information from packet header. In preprocessing unit, logarithmic normalization and encoding schemes are considered, which is time series and suitable for any application. In feature extraction unit, Mutual Information is used where we extracts optimum set of features for packets classification. In classification unit, Bootstrapped Optimistic Algorithm for Tree Construction with Artificial Neural Network is used for packets classification, which classifies packets five classes: DoS, Probe, U2R, R2L, and Anomaly, and then Association Rule Tree are used to classify whether the attack is Frequent or Rare. In this case, historical table is used for packets classification. Finally, experiments are conducted and tested for evaluating the performance of proposed SA-IDPS scheme in terms of Detection Rate (%), False Positive Rate (%), Detection Delay (s), and Energy Consumption (J). © 2020, Springer Science+Business Media, LLC, part of Springer Nature.},
  document_type = {Article},
  doi           = {10.1007/s11277-019-07022-5},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077606323&doi=10.1007%2fs11277-019-07022-5&partnerID=40&md5=7cb5f8637dcd3593d91285055da082cb},
}

@Article{Hang2020,
  author        = {Hang, J. and Han, K. and Chen, H. and Li, Y.},
  journal       = {Pattern Recognition},
  title         = {Ensemble adversarial black-box attacks against deep learning systems},
  year          = {2020},
  note          = {cited By 3},
  volume        = {101},
  abstract      = {Deep learning (DL) models, e.g., state-of-the-art convolutional neural networks (CNNs), have been widely applied into security sensitivity tasks, such as face payment, security monitoring, automated driving, etc. Then their vulnerability analysis is an emergent topic, especially for black-box attacks, where adversaries do not know the model internal architectures or training parameters. In this paper, two types of ensemble-based black-box attack strategies, selective cascade ensemble strategy (SCES) and stack parallel ensemble strategy (SPES), are proposed to explore the vulnerability of DL system and potential factors that contribute to the high-efficiency attacks are explored. SCES adopts a boosting structure of ensemble learning and SPES employs a bagging structure. Moreover, two pairwise and non-pairwise diversity measures are adopted to examine the relationship between the diversity in substitutes ensembles and transferability of generated adversarial examples. Experimental results show that proposed ensemble adversarial black-box attack strategies can successfully attack the DL system with some defense mechanism, such as adversarial training and ensemble adversarial training. The experimental results also show the greater the diversity in substitute ensembles enables stronger transferability. © 2019},
  art_number    = {107184},
  document_type = {Article},
  doi           = {10.1016/j.patcog.2019.107184},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077515017&doi=10.1016%2fj.patcog.2019.107184&partnerID=40&md5=82dbac1f7200a6cba84b7f26c82a9541},
}

@Article{Khan2020,
  author        = {Khan, K. and Mehmood, A. and Khan, S. and Khan, M.A. and Iqbal, Z. and Mashwani, W.K.},
  journal       = {Journal of Systems Architecture},
  title         = {A survey on intrusion detection and prevention in wireless ad-hoc networks},
  year          = {2020},
  note          = {cited By 15},
  volume        = {105},
  abstract      = {Ad hoc networks have been serving us in one way or the other, for two decades, through their vast variety of applications in majority fields. Due to their features such as hostile deployments, high level of mobility, limited resources and physical insecurity, they are in front line to attackers. First line of defense (cryptographic techniques, fire walls etc.) stops these attacks. But what would happen if the attacker break through this defense system? Second of line of defense also called intrusion detection system (IDS), would stop and mitigate these threats before they harm the network or its resources. Various schemes have been proposed to provide quality IDS that could mitigate the latest threats in ad hoc networks. In this review paper, we gave a detailed overview of ad hoc networks in the start. We explored ad hoc networks security followed by description about IDS. Next, we elaborated the taxonomy of IDS, containing types of IDS based on numerous parameters. In the trailing section, we compared wide variety of IDS schemes based on different methodology/techniques, to show their importance and performance in the field of intrusion detection. Finally, we concluded the paper with informative future research directions in the state of the art research fields that would open up ways for researchers in that area. © 2019},
  art_number    = {101701},
  document_type = {Article},
  doi           = {10.1016/j.sysarc.2019.101701},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077078565&doi=10.1016%2fj.sysarc.2019.101701&partnerID=40&md5=d37ca2595f144bd76ccc979e1e3e5e91},
}

@Article{Khasawneh2020620,
  author        = {Khasawneh, K.N. and Ozsoy, M. and Donovick, C. and Abu-Ghazaleh, N. and Ponomarev, D.},
  journal       = {IEEE Transactions on Dependable and Secure Computing},
  title         = {EnsembleHMD: Accurate Hardware Malware Detectors with Specialized Ensemble Classifiers},
  year          = {2020},
  note          = {cited By 5},
  number        = {3},
  pages         = {620-633},
  volume        = {17},
  abstract      = {Hardware-based malware detectors (HMDs) are a promising new approach to defend against malware. HMDs collect low-level architectural features and use them to classify malware from normal programs. With simple hardware support, HMDs can be always on, operating as a first line of defense that prioritizes the application of more expensive and more accurate software-detector. In this paper, our goal is to increase the accuracy of HMDs, to improve detection, and reduce overhead. We use specialized detectors targeted towards a specific type of malware to improve the detection of each type. Next, we use ensemble learning techniques to improve the overall accuracy by combining detectors. We explore detectors based on logistic regression (LR) and neural networks (NN). The proposed detectors reduce the false-positive rate by more than half compared to using a single detector, while increasing their sensitivity. We develop metrics to estimate detection overhead; the proposed detectors achieve more than 16.6x overhead reduction during online detection compared to an idealized software-only detector, with an 8x improvement in relative detection time. NN detectors outperform LR detectors in accuracy, overhead (by 40 percent), and time-to-detection of the hardware component (by 5x). Finally, we characterize the hardware complexity by extending an open-core and synthesizing it on an FPGA platform, showing that the overhead is minimal. © 2004-2012 IEEE.},
  art_number    = {8280556},
  document_type = {Article},
  doi           = {10.1109/TDSC.2018.2801858},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041688118&doi=10.1109%2fTDSC.2018.2801858&partnerID=40&md5=1a542fdfa8177df23ac2d75dff8cc7cc},
}

@Conference{Phillips2020188,
  author        = {Phillips, B. and Gamess, E. and Krishnaprasad, S.},
  title         = {An evaluation of machine learning-based anomaly detection in a scada system using the modbus protocol},
  year          = {2020},
  note          = {cited By 4},
  pages         = {188-196},
  abstract      = {Supervisory Control and Data Acquisition (SCADA) systems have been designed with the assumption that the system would run within a closed environment. They have only generated concerns for security issues that may appear during system deployment, and there are no clear methods to assess security threats when considered. Recent technological and economic trends have driven SCADA systems from serial communication networks to networks based on TCP/IP. This exposes legacy SCADA systems to new security threats they were not designed to defend against. This work examines the viability of machine learning techniques in detecting new security threats specific to SCADA systems and the Modbus protocol. Machine learning-based anomaly detection algorithms were used to detect malicious traffic in a generated dataset of Remote Terminal Unit (RTU) communications using the Modbus protocol. The implemented algorithms are Support Vector Machines, decision trees, k-nearest neighbors, and k-means clustering. While the algorithms performed well overall, Support Vector Machine, Decision Trees, and K-nearest Neighbors algorithms had the best performance with individual attack types. K-means clustering did not perform satisfactorily with specific attack types. © 2020 ACM.},
  art_number    = {3385282},
  document_type = {Conference Paper},
  doi           = {10.1145/3374135.3385282},
  groups        = {First Filtering},
  journal       = {ACMSE 2020 - Proceedings of the 2020 ACM Southeast Conference},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086180735&doi=10.1145%2f3374135.3385282&partnerID=40&md5=a9ecc4d6cf7f50067e929b7492b6816e},
}

@Conference{Gupta2020282,
  author        = {Gupta, A.R.B. and Agrawal, J.},
  title         = {A comprehensive survey on various machine learning methods used for intrusion detection system},
  year          = {2020},
  note          = {cited By 3},
  pages         = {282-289},
  abstract      = {With the advance in technology, now a day's cyber-attack is more sophisticated which is not easily detected by the any intrusion detection system (IDS). Since most of the user store their private and sensitive information into the computer or any other digital media so providing security to these computers from the attacker is the essential requirement of each user. As number of intrusion detection system have been proposed in the last few decades. These IDS are mainly classified in two different types named signature based intrusion detection system and anomaly based intrusion detection system. The main objective of this paper is to compare various existing IDS with their strength and weakness. This paper will also discuss various machine learning approach and data sets which are used to detect intrusion. This paper will also discuss various challenges which makes IDS design more challenging. © 2020 IEEE.},
  art_number    = {9115764},
  document_type = {Conference Paper},
  doi           = {10.1109/CSNT48778.2020.9115764},
  groups        = {First Filtering},
  journal       = {Proceedings - 2020 IEEE 9th International Conference on Communication Systems and Network Technologies, CSNT 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089841967&doi=10.1109%2fCSNT48778.2020.9115764&partnerID=40&md5=729aae981ca65867c4299e44c7f19ad3},
}

@Conference{Mbarek20201156,
  author        = {Mbarek, B. and Ge, M. and Pitner, T.},
  title         = {Enhanced network intrusion detection system protocol for internet of things},
  year          = {2020},
  note          = {cited By 7},
  pages         = {1156-1163},
  abstract      = {With the emergence of the Internet of Things (IoT), different IoT nodes such as 6LoWPAN devices can be connected as a network to provide integrated services. Since security and intrusion detection are becoming crucial among IoT devices, real-time detection of the attacks are critical to protect the IoT networks. However, there exists limited research for efficient network intrusion detection systems (NIDS) in the IoT networks. This paper therefore proposes a new NIDS protocol with an efficient replica detection algorithm to increase the utility and performance of existing NIDS, where a number of replica test nodes are intentionally inserted into the network to test the reliability and response of witness nodes. The proposed protocol, Enhanced NIDS, can address the vulnerability of NIDS and improve IoT network security to detect severe compromise attacks such as clone attacks. The simulation study shows that compared to the state-of-the-art SVELTE protocol, the proposed protocol can significantly increase the detection probability and reduce the energy consumption for detecting clone attacks in IoT networks. © 2020 ACM.},
  document_type = {Conference Paper},
  doi           = {10.1145/3341105.3373867},
  groups        = {First Filtering},
  journal       = {Proceedings of the ACM Symposium on Applied Computing},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083024922&doi=10.1145%2f3341105.3373867&partnerID=40&md5=c2dd4a1bdf608af9e7df35db3ad1a049},
}

@Article{Alshemali2020,
  author        = {Alshemali, B. and Kalita, J.},
  journal       = {Knowledge-Based Systems},
  title         = {Improving the Reliability of Deep Neural Networks in NLP: A Review},
  year          = {2020},
  note          = {cited By 12},
  volume        = {191},
  abstract      = {Deep learning models have achieved great success in solving a variety of natural language processing (NLP) problems. An ever-growing body of research, however, illustrates the vulnerability of deep neural networks (DNNs) to adversarial examples — inputs modified by introducing small perturbations to deliberately fool a target model into outputting incorrect results. The vulnerability to adversarial examples has become one of the main hurdles precluding neural network deployment into safety-critical environments. This paper discusses the contemporary usage of adversarial examples to foil DNNs and presents a comprehensive review of their use to improve the robustness of DNNs in NLP applications. In this paper, we summarize recent approaches for generating adversarial texts and propose a taxonomy to categorize them. We further review various types of defensive strategies against adversarial examples, explore their main challenges, and highlight some future research directions. © 2019 Elsevier B.V.},
  art_number    = {105210},
  document_type = {Article},
  doi           = {10.1016/j.knosys.2019.105210},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076575941&doi=10.1016%2fj.knosys.2019.105210&partnerID=40&md5=6031ff5b8c16bcc73d823d0b2f84c651},
}

@Conference{Folz20203568,
  author        = {Folz, J. and Palacio, S. and Hees, J. and Dengel, A.},
  title         = {Adversarial defense based on structure-to-signal autoencoders},
  year          = {2020},
  note          = {cited By 2},
  pages         = {3568-3577},
  abstract      = {Adversarial attacks have exposed the intricacies of the complex loss surfaces approximated by neural networks. In this paper, we present a defense strategy against gradientbased attacks, on the premise that input gradients need to expose information about the semantic manifold for attacks to be successful. We propose an architecture based on compressive autoencoders (AEs) with a two-stage training scheme, creating not only an architectural bottleneck but also a representational bottleneck. We show that the proposed mechanism yields robust results against a collection of gradient-based attacks under challenging white-box conditions. This defense is attack-agnostic and can, therefore, be used for arbitrary pre-trained models, while not compromising the original performance. These claims are supported by experiments conducted with state-of-the-art image classifiers (ResNet50 and Inception v3), on the full ImageNet validation set. Experiments, including counterfactual analysis, empirically show that the robustness stems from a shift in the distribution of input gradients, which mitigates the effect of tested adversarial attack methods. Gradients propagated through the proposed AEs represent less semantic information and instead point to low-level structural features. © 2020 IEEE.},
  art_number    = {9093310},
  document_type = {Conference Paper},
  doi           = {10.1109/WACV45572.2020.9093310},
  groups        = {First Filtering},
  journal       = {Proceedings - 2020 IEEE Winter Conference on Applications of Computer Vision, WACV 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085491096&doi=10.1109%2fWACV45572.2020.9093310&partnerID=40&md5=fee06748e734b5bdee3d4cb7ae217784},
}

@Conference{Ayub2020,
  author        = {Ayub, M.A. and Johnson, W.A. and Talbert, D.A. and Siraj, A.},
  title         = {Model Evasion Attack on Intrusion Detection Systems using Adversarial Machine Learning},
  year          = {2020},
  note          = {cited By 5},
  abstract      = {Intrusion Detection Systems (IDS) have a long history as an effective network defensive mechanism. The systems alert defenders of suspicious and / or malicious behavior detected on the network. With technological advances in AI over the past decade, machine learning (ML) has been assisting IDS to improve accuracy, perform better analysis, and discover variations of existing or new attacks. However, applications of ML algorithms have some reported weaknesses and in this research, we demonstrate how one of such weaknesses can be exploited against the workings of the IDS. The work presented in this paper is twofold: (1) we develop a ML approach for intrusion detection using Multilayer Perceptron (MLP) network and demonstrate the effectiveness of our model with two different network-based IDS datasets; and (2) we perform a model evasion attack against the built MLP network for IDS using an adversarial machine learning technique known as the Jacobian-based Saliency Map Attack (JSMA) method. Our experimental results show that the model evasion attack is capable of significantly reducing the accuracy of the IDS, i.e., detecting malicious traffic as benign. Our findings support that neural network-based IDS is susceptible to model evasion attack, and attackers can essentially use this technique to evade intrusion detection systems effectively. © 2020 IEEE.},
  art_number    = {9086268},
  document_type = {Conference Paper},
  doi           = {10.1109/CISS48834.2020.1570617116},
  groups        = {First Filtering},
  journal       = {2020 54th Annual Conference on Information Sciences and Systems, CISS 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085263122&doi=10.1109%2fCISS48834.2020.1570617116&partnerID=40&md5=a14f5651def79248811efff3e1d2a5de},
}

@Article{Ullah2020,
  author        = {Ullah, I. and Mahmoud, Q.H.},
  journal       = {Electronics (Switzerland)},
  title         = {A two-level flow-based anomalous activity detection system for IoT networks},
  year          = {2020},
  note          = {cited By 11},
  number        = {3},
  volume        = {9},
  abstract      = {The significant increase of the Internet of Things (IoT) devices in smart homes and other smart infrastructure, and the recent attacks on these IoT devices, are motivating factors to secure and protect IoT networks. The primary security challenge to develop a methodology to identify a malicious activity correctly and mitigate the impact of such activity promptly. In this paper, we propose a two-level anomalous activity detection model for intrusion detection system in IoT networks. The level-1 model categorizes the network flow as normal flow or abnormal flow, while the level-2 model classifies the category or subcategory of detected malicious activity. When the network flow classified as an anomaly by the level-1 model, then the level-1 model forwards the stream to the level-2 model for further investigation to find the category or subcategory of the detected anomaly. Our proposed model constructed on flow-based features of the IoT network. Flow-based detection methodologies only inspect packet headers to classify the network traffic. Flow-based features extracted from the IoT Botnet dataset and various machine learning algorithms were investigated and tested via different cross-fold validation tests to select the best algorithm. The decision tree classifier yielded the highest predictive results for level-1, and the random forest classifier produced the highest predictive results for level-2. Our proposed model Accuracy, Precision, Recall, and F score for level-1 were measured as 99.99% and 99.90% for level-2. A two-level anomalous activity detection system for IoT networks we proposed will provide a robust framework for the development of malicious activity detection system for IoT networks. It would be of interest to researchers in academia and industry. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
  art_number    = {530},
  document_type = {Article},
  doi           = {10.3390/electronics9030530},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084346965&doi=10.3390%2felectronics9030530&partnerID=40&md5=cd9019bf39ea5a12fcf0d419bea57f39},
}

@Article{Miller2020402,
  author        = {Miller, D.J. and Xiang, Z. and Kesidis, G.},
  journal       = {Proceedings of the IEEE},
  title         = {Adversarial Learning Targeting Deep Neural Network Classification: A Comprehensive Review of Defenses against Attacks},
  year          = {2020},
  note          = {cited By 16},
  number        = {3},
  pages         = {402-433},
  volume        = {108},
  abstract      = {With wide deployment of machine learning (ML)-based systems for a variety of applications including medical, military, automotive, genomic, multimedia, and social networking, there is great potential for damage from adversarial learning (AL) attacks. In this article, we provide a contemporary survey of AL, focused particularly on defenses against attacks on deep neural network classifiers. After introducing relevant terminology and the goals and range of possible knowledge of both attackers and defenders, we survey recent work on test-time evasion (TTE), data poisoning (DP), backdoor DP, and reverse engineering (RE) attacks and particularly defenses against the same. In so doing, we distinguish robust classification from anomaly detection (AD), unsupervised from supervised, and statistical hypothesis-based defenses from ones that do not have an explicit null (no attack) hypothesis. We also consider several scenarios for detecting backdoors. We provide a technical assessment for reviewed works, including identifying any issues/limitations, required hyperparameters, needed computational complexity, as well as the performance measures evaluated and the obtained quality. We then delve deeper, providing novel insights that challenge conventional AL wisdom and that target unresolved issues, including: Robust classification versus AD as a defense strategy; the belief that attack success increases with attack strength, which ignores susceptibility to AD; small perturbations for TTE attacks: A fallacy or a requirement; validity of the universal assumption that a TTE attacker knows the ground-truth class for the example to be attacked; black, gray, or white-box attacks as the standard for defense evaluation; and susceptibility of query-based RE to an AD defense. We also discuss attacks on the privacy of training data. We then present benchmark comparisons of several defenses against TTE, RE, and backdoor DP attacks on images. The article concludes with a discussion of continuing research directions, including the supreme challenge of detecting attacks whose goal is not to alter classification decisions, but rather simply to embed, without detection, 'fake news' or other false content. © 2020 IEEE.},
  art_number    = {9013065},
  document_type = {Article},
  doi           = {10.1109/JPROC.2020.2970615},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080115696&doi=10.1109%2fJPROC.2020.2970615&partnerID=40&md5=198c0998f9a28ff4a1c3b0b81da96a03},
}

@Article{Thakkar2020,
  author        = {Thakkar, A. and Lohiya, R.},
  journal       = {Swarm and Evolutionary Computation},
  title         = {Role of swarm and evolutionary algorithms for intrusion detection system: A survey},
  year          = {2020},
  note          = {cited By 16},
  volume        = {53},
  abstract      = {The growth of data and categories of attacks, demand the use of Intrusion Detection System(IDS) effectively using Machine Learning(ML) and Deep Learning(DL) techniques. Apart from the ML and DL techniques, Swarm and Evolutionary (SWEVO) Algorithms have also shown significant performance to improve the efficiency of the IDS models. This survey covers SWEVO-based IDS approaches such as Genetic Algorithm(GA), Ant Colony Optimization(ACO), Particle Swarm Optimization(PSO), Artificial Bee Colony Optimization(ABC), Firefly Algorithm(FA), Bat Algorithm(BA), and Flower Pollination Algorithm(FPA). The paper also discusses applications of the SWEVO in the field of IDS along with challenges and possible future directions. © 2019 Elsevier B.V.},
  art_number    = {100631},
  document_type = {Article},
  doi           = {10.1016/j.swevo.2019.100631},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076840343&doi=10.1016%2fj.swevo.2019.100631&partnerID=40&md5=896da9b2f3be167e7778b8b30e38b29e},
}

@Article{MaestreVidal2020159,
  author        = {Maestre Vidal, J. and Sotelo Monge, M.A. and Monterrubio, S.M.M.},
  journal       = {Future Generation Computer Systems},
  title         = {EsPADA: Enhanced Payload Analyzer for malware Detection robust against Adversarial threats},
  year          = {2020},
  note          = {cited By 3},
  pages         = {159-173},
  volume        = {104},
  abstract      = {The emergent communication technologies landscape has consolidated the anomaly-based intrusion detection paradigm as one of the most prominent solutions able to discover unprecedented malicious traits. It relied on building models of the normal/legitimate activities registered at the protected systems, from them analyzing the incoming observations looking for significant discordances that may reveal misbehaviors. But in the last years, the adversarial machine learning paradigm introduced never-seen-before evasion procedures able to jeopardize the traditional anomaly-based methods, thus entailing one of the major emerging challenges in the cybersecurity landscape. With the aim on contributing to their adaptation against adversarial threats, this paper presents EsPADA (Enhanced Payload Analyzer for malware Detection robust against Adversarial threats), a novel approach built on the grounds of the PAYL sensor family. At the SPARTA Training stage, both normal and adversarial models are constructed according to features extracted by N-gram, which are stored within Counting Bloom Filters (CBF). In this way it is possible to take advantage of both binary-based and spectral-based traffic modeling procedures for malware detection. At Detection stage, the payloads to be analyzed are collected from the protected environment and compared with the usage models previously built at Training. This leads to calculate different scores that allow to discriminate their nature (normal or suspicious) and to assess the labeling coherency, the latest studied for estimating the likelihood of the payload disguising mimicry attacks. The effectiveness of EsPADA was demonstrated on the public datasets DARPA'99 and UCM 2011 by achieving promising preliminarily results. © 2019 Elsevier B.V.},
  document_type = {Article},
  doi           = {10.1016/j.future.2019.10.022},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074374474&doi=10.1016%2fj.future.2019.10.022&partnerID=40&md5=8807a385ca5c78622533bdc02bc9421f},
}

@Article{Yinka-Banjo20201721,
  author        = {Yinka-Banjo, C. and Ugot, O.-A.},
  journal       = {Artificial Intelligence Review},
  title         = {A review of generative adversarial networks and its application in cybersecurity},
  year          = {2020},
  note          = {cited By 7},
  number        = {3},
  pages         = {1721-1736},
  volume        = {53},
  abstract      = {This paper reviews Generative Adversarial Networks (GANs) in detail by discussing the strength of the GAN when compared to other generative models, how GANs works and some of the notable problems with training, tuning and evaluating GANs. The paper also briefly reviews notable GAN architectures like the Deep Convolutional Generative Adversarial Network (DCGAN), and Wasserstein GAN, with the aim of showing how design specifications in these architectures help solve some of the problems with the basic GAN model. All this is done with a view of discussing the application of GANs in cybersecurity studies. Here, the paper reviews notable cybersecurity studies where the GAN plays a key role in the design of a security system or adversarial system. In general, from the review, one can observe two major approaches these cybersecurity studies follow. In the first approach, the GAN is used to improve generalization to unforeseen adversarial attacks, by generating novel samples that resembles adversarial data which can then serve as training data for other machine learning models. In the second approach, the GAN is trained on data that contains authorized features with the goal of generating realistic adversarial data that can thus fool a security system. These two approaches currently guide the scope of modern cybersecurity studies with generative adversarial networks. © 2019, Springer Nature B.V.},
  document_type = {Article},
  doi           = {10.1007/s10462-019-09717-4},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066637511&doi=10.1007%2fs10462-019-09717-4&partnerID=40&md5=b6f48f86f58e6982ac6986896352a5e2},
}

@Article{VanWyk20201264,
  author        = {Van Wyk, F. and Wang, Y. and Khojandi, A. and Masoud, N.},
  journal       = {IEEE Transactions on Intelligent Transportation Systems},
  title         = {Real-time sensor anomaly detection and identification in automated vehicles},
  year          = {2020},
  note          = {cited By 15},
  number        = {3},
  pages         = {1264-1276},
  volume        = {21},
  abstract      = {Connected and automated vehicles (CAVs) are expected to revolutionize the transportation industry, mainly through allowing for a real-time and seamless exchange of information between vehicles and roadside infrastructure. Although connectivity and automation are projected to bring about a vast number of benefits, they can give rise to new challenges in terms of safety, security, and privacy. To navigate roadways, CAVs need to heavily rely on their sensor readings and the information received from other vehicles and roadside units. Hence, anomalous sensor readings caused by either malicious cyber attacks or faulty vehicle sensors can result in disruptive consequences and possibly lead to fatal crashes. As a result, before the mass implementation of CAVs, it is important to develop methodologies that can detect anomalies and identify their sources seamlessly and in real time. In this paper, we develop an anomaly detection approach through combining a deep learning method, namely convolutional neural network (CNN), with a well-established anomaly detection method, and Kalman filtering with a χ2-detector, to detect and identify anomalous behavior in CAVs. Our numerical experiments demonstrate that the developed approach can detect anomalies and identify their sources with high accuracy, sensitivity, and F1 score. In addition, this developed approach outperforms the anomaly detection and identification capabilities of both CNNs and Kalman filtering with a χ2-detector method alone. It is envisioned that this research will contribute to the development of safer and more resilient CAV systems that implement a holistic view toward intelligent transportation system (ITS) concepts. © 2000-2011 IEEE.},
  art_number    = {8684317},
  document_type = {Article},
  doi           = {10.1109/TITS.2019.2906038},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064620660&doi=10.1109%2fTITS.2019.2906038&partnerID=40&md5=3da9af6202d1a7a64969b71c2806cf42},
}

@Conference{Gan202043,
  author        = {Gan, H. and Liu, C.},
  title         = {An Autoencoder Based Approach to Defend against Adversarial Attacks for Autonomous Vehicles},
  year          = {2020},
  note          = {cited By 0},
  pages         = {43-44},
  abstract      = {Boosted by the evolution of machine learning technology, large amount of data and advanced computing system, neural networks have achieved state-of-the-art performance that even exceeds human capability in many applications [1] [2]. However, adversarial attacks targeting neural networks have demonstrated detrimental impact in autonomous driving [3]. The adversarial attacks are capable of arbitrarily manipulating the neural network classification results with different input data which is non-perceivable to human. © 2020 IEEE.},
  art_number    = {9138635},
  document_type = {Conference Paper},
  doi           = {10.1109/MetroCAD48866.2020.00015},
  groups        = {First Filtering},
  journal       = {Proceedings - 2020 International Conference on Connected and Autonomous Driving, MetroCAD 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091964876&doi=10.1109%2fMetroCAD48866.2020.00015&partnerID=40&md5=97d29362b613e6c26df0bbd5895c20c8},
}

@Conference{Albaseer2020177,
  author        = {Albaseer, A. and Ciftler, B.S. and Abdallah, M.M.},
  title         = {Performance Evaluation of Physical Attacks against E2E Autoencoder over Rayleigh Fading Channel},
  year          = {2020},
  note          = {cited By 0},
  pages         = {177-182},
  abstract      = {The use of Deep Learning (DL) in wireless communication systems is becoming very popular. As an example to the use of DL, the end-to-end (E2E) communication system can be implemented as an autoencoder. However, security and robustness are the main challenges due to the weaknesses of the autoencoders against physical adversarial attacks. Some works have been devoted to addressing these issues using only Additive White Gaussian Noise (AWGN) channel model. In this paper, we investigate the vulnerabilities of autoencoder E2E using a more realistic Rayleigh channel model with fast-fading and slow-fading characteristics studied separately. We apply white-box and black-box adversarial attacks to show in which extent this system is weak against adversaries. We use AWGN channel model as a benchmark to analyze our results. The results show that the adversary has more destructive impacts on the system that involves Rayleigh channel than AWGN channels as it causes a larger block error rate. Also, the black-box attack affects the system of Rayleigh model similar to jamming attacks. © 2020 IEEE.},
  art_number    = {9089601},
  document_type = {Conference Paper},
  doi           = {10.1109/ICIoT48696.2020.9089601},
  groups        = {First Filtering},
  journal       = {2020 IEEE International Conference on Informatics, IoT, and Enabling Technologies, ICIoT 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085506408&doi=10.1109%2fICIoT48696.2020.9089601&partnerID=40&md5=9aa8f49052397bca0cedfc198f1d5d3f},
}

@Conference{Liu2020277,
  author        = {Liu, H. and Helu, X. and Jin, C. and Lu, H. and Tian, Z. and Du, X. and Abualsaud, K.},
  title         = {A Malware Detection Method for Health Sensor Data Based on Machine Learning},
  year          = {2020},
  note          = {cited By 1},
  pages         = {277-282},
  abstract      = {Traditional signature-based malware detection approaches are sensitive to small changes in the malware code. Currently, most malware programs are adapted from existing programs. Hence, they share some common patterns but have different signatures. To health sensor data, it is necessary to identify the malware pattern rather than only detect the small changes. However, to detect these health sensor data in malware programs timely, we propose a fast detection strategy to detect the patterns in the code with machine learning-based approaches. In particular, XGBoost, LightGBM and Random Forests will be exploited in order to analyze the code from health sensor data. The codes are fed into them as sequences of bytes/tokens or just as a single byte/token (e.g. 1-, 2-, 3-, or 4-grams). Terabytes of program with labels, including benign and malware programs, have been collected. The challenges of this task are to select and get the features, modify the three models in order to train and test the dataset, which consists of health sensor data, and evaluate the features and models. When a malware program is detected by one model, its pattern will be broadcast to the other models, which will prevent malware program from intrusion effectively. © 2020 IEEE.},
  art_number    = {9089478},
  document_type = {Conference Paper},
  doi           = {10.1109/ICIoT48696.2020.9089478},
  groups        = {First Filtering},
  journal       = {2020 IEEE International Conference on Informatics, IoT, and Enabling Technologies, ICIoT 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085477733&doi=10.1109%2fICIoT48696.2020.9089478&partnerID=40&md5=057dbe3ce112290824bffb93747b270e},
}

@Conference{Reuter2020194,
  author        = {Reuter, L. and Jung, O. and Magin, J.},
  title         = {Neural network based anomaly detection for SCADA systems},
  year          = {2020},
  note          = {cited By 2},
  pages         = {194-201},
  abstract      = {Neural networks are widely used for anomaly detection in order to identify and classify cyber attacks at network level. In particular in critical infrastructures like the electric power grid, the reliable detection and mitigation of attacks is vital as communication infrastructure availability is often indispensable for the proper operation of such systems. We propose a combination of a deep feed forward neural network as a classifier and a deep autoencoder for anomaly detection to gain a high detection rate and at the same time a low error rate. Two different data sets were used to evaluate the applicability and performance of our approach. The aim is to deploy our neural network based anomaly detection in an software-defined network (SDN) that is carrying SCADA traffic and where the controller is providing traffic flow information for anomaly detection. © 2020 IEEE.},
  art_number    = {9059436},
  document_type = {Conference Paper},
  doi           = {10.1109/ICIN48450.2020.9059436},
  groups        = {First Filtering},
  journal       = {2020 23rd Conference on Innovation in Clouds, Internet and Networks and Workshops, ICIN 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084070265&doi=10.1109%2fICIN48450.2020.9059436&partnerID=40&md5=f7b95249241221ca07a4cecac185457c},
}

@Article{Deng2020,
  author        = {Deng, Z. and Sang, Q.},
  journal       = {Electronics (Switzerland)},
  title         = {Harnessing the adversarial perturbation to enhance security in the autoencoder-based communication system},
  year          = {2020},
  note          = {cited By 0},
  number        = {2},
  volume        = {9},
  abstract      = {Given the vulnerability of deep neural network to adversarial attacks, the application of deep learning in the wireless physical layer arouses comprehensive security concerns. In this paper, we consider an autoencoder-based communication system with a full-duplex (FD) legitimate receiver and an external eavesdropper. It is assumed that the system is trained from end-to-end based on the concepts of autoencoder. The FD legitimate receiver transmits a well-designed adversary perturbation signal to jam the eavesdropper while receiving information simultaneously. To defend the self-perturbation from the loop-back channel, the legitimate receiver is re-trained with the adversarial training method. The simulation results show that with the scheme proposed in this paper, the block-error-rate (BLER) of the legitimate receiver almost remains unaffected while the BLER of the eavesdropper is increased by orders of magnitude. This ensures reliable and secure transmission between the transmitter and the legitimate receiver. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
  art_number    = {294},
  document_type = {Article},
  doi           = {10.3390/electronics9020294},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079448657&doi=10.3390%2felectronics9020294&partnerID=40&md5=aae9a8e5d23e5021907d9a8fecf6a35c},
}

@Article{Chen2020,
  author        = {Chen, L. and Wang, Z. and Li, F. and Guo, Y. and Geng, K.},
  journal       = {Sensors (Switzerland)},
  title         = {A stackelberg security game for adversarial outbreak detection in the internet of things},
  year          = {2020},
  note          = {cited By 1},
  number        = {3},
  volume        = {20},
  abstract      = {With limited computing resources and a lack of physical lines of defense, the Internet of Things (IoT) has become a focus of cyberattacks. In recent years, outbreak propagation attacks against the IoT have occurred frequently, and these attacks are often strategical. In order to detect the outbreak propagation as soon as possible, t embedded Intrusion Detection Systems (IDSs) are widely deployed in the IoT. This paper tackles the problem of outbreak detection in adversarial environment in the IoT. A dynamic scheduling strategy based on specific IDSs monitoring of IoT devices is proposed to avoid strategic attacks. Firstly, we formulate the interaction between the defender and attacker as a Stackelberg game in which the defender first chooses a set of device nodes to activate, and then the attacker selects one seed (one device node) to spread the worms. This yields an extremely complex bilevel optimization problem. Our approach is to build a modified Column Generation framework for computing the optimal strategy effectively. The optimal response of the defender’s problem is expressed as mixed-integer linear programming (MILPs). It is proved that the solution of the defender’s optimal response is a NP-hard problem. Moreover, the optimal response of defenders is improved by an approximate algorithm--a greedy algorithm. Finally, the proposed scheme is tested on some randomly generated instances. The experimental results show that the scheme is effective for monitoring optimal scheduling. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
  art_number    = {804},
  document_type = {Article},
  doi           = {10.3390/s20030804},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079052166&doi=10.3390%2fs20030804&partnerID=40&md5=0d4a72d55737cbda169136efa77ec6fc},
}

@Article{Ferrag2020,
  author        = {Ferrag, M.A. and Maglaras, L. and Moschoyiannis, S. and Janicke, H.},
  journal       = {Journal of Information Security and Applications},
  title         = {Deep learning for cyber security intrusion detection: Approaches, datasets, and comparative study},
  year          = {2020},
  note          = {cited By 94},
  volume        = {50},
  abstract      = {In this paper, we present a survey of deep learning approaches for cyber security intrusion detection, the datasets used, and a comparative study. Specifically, we provide a review of intrusion detection systems based on deep learning approaches. The dataset plays an important role in intrusion detection, therefore we describe 35 well-known cyber datasets and provide a classification of these datasets into seven categories; namely, network traffic-based dataset, electrical network-based dataset, internet traffic-based dataset, virtual private network-based dataset, android apps-based dataset, IoT traffic-based dataset, and internet-connected devices-based dataset. We analyze seven deep learning models including recurrent neural networks, deep neural networks, restricted Boltzmann machines, deep belief networks, convolutional neural networks, deep Boltzmann machines, and deep autoencoders. For each model, we study the performance in two categories of classification (binary and multiclass) under two new real traffic datasets, namely, the CSE-CIC-IDS2018 dataset and the Bot-IoT dataset. In addition, we use the most important performance indicators, namely, accuracy, false alarm rate, and detection rate for evaluating the efficiency of several methods. © 2019 Elsevier Ltd},
  art_number    = {102419},
  document_type = {Article},
  doi           = {10.1016/j.jisa.2019.102419},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076848850&doi=10.1016%2fj.jisa.2019.102419&partnerID=40&md5=906855f749daaa4b583980474be8fdc5},
}

@Conference{Narayana20206465,
  author        = {Narayana, K.E. and Jayashree, K.},
  title         = {Survey on cross virtual machine side channel attack detection and properties of cloud computing as sustainable material},
  year          = {2020},
  note          = {cited By 0},
  pages         = {6465-6470},
  volume        = {45},
  abstract      = {Cloud computing dominates all kinds of computing in the network due to the service-oriented and on-demand nature of the model. The customer uses a cloud model for fulfilling the resource needs with minimum cost. Cloud security plays a vital role as it is securing the customer data in a more reliable manner. Various levels of security issues imposed by the cloud provider are still considered to be a problem in the resource level. Virtualization security technique is used to prevent the Virtual Machine (VM) and related information like data, state and shared resources. VM side channel attack leads to severe issues in the cloud because the attacker is performing access of the resources that causes the reliability problem. The main objective of this analysis is to explore various kinds of attacks and its solution model of the cloud. Side channel attacks are detected by using various techniques such as RSA and AES. Infrastructure level attacks are analyzed with various attack levels and rates. Hypervisor level protection is assessed by using the different classes with accurate parameters. The overall analysis provides the complete information about cloud resource level security and its solution. © 2020 Elsevier Ltd. All rights reserved.},
  document_type = {Conference Paper},
  doi           = {10.1016/j.matpr.2020.11.283},
  groups        = {First Filtering},
  journal       = {Materials Today: Proceedings},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108192430&doi=10.1016%2fj.matpr.2020.11.283&partnerID=40&md5=614c37c3bcf5a8ea63411100f998ab7c},
}

@Conference{Sun20209166,
  author        = {Sun, Y. and Wang, X. and Liu, Z. and Miller, J. and Efros, A.A. and Hardt, M.},
  title         = {Test-time training with self-supervision for generalization under distribution shifts},
  year          = {2020},
  note          = {cited By 2},
  pages         = {9166-9185},
  volume        = {PartF168147-12},
  abstract      = {In this paper, we propose Test-Time Training, a general approach for improving the performance of predictive models when training and test data come from different distributions. We turn a single unlabeled test sample into a self-supervised learning problem, on which we update the model parameters before making a prediction. This also extends naturally to data in an online stream. Our simple approach leads to improvements on diverse image classification benchmarks aimed at evaluating robustness to distribution shifts. © 2020 37th International Conference on Machine Learning, ICML 2020. All rights reserved.},
  document_type = {Conference Paper},
  groups        = {First Filtering},
  journal       = {37th International Conference on Machine Learning, ICML 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105285150&partnerID=40&md5=1de6705de169dcd8b1884110e0754689},
}

@Conference{Zhang2020,
  author        = {Zhang, C. and Zhang, K. and Li, Y.},
  title         = {A causal view on robustness of neural networks},
  year          = {2020},
  note          = {cited By 0},
  volume        = {2020-December},
  abstract      = {We present a causal view on the robustness of neural networks against input manipulations, which applies not only to traditional classification tasks but also to general measurement data. Based on this view, we design a deep causal manipulation augmented model (deep CAMA) which explicitly models possible manipulations on certain causes leading to changes in the observed effect. We further develop data augmentation and test-time fine-tuning methods to improve deep CAMA’s robustness. When compared with discriminative deep neural networks, our proposed model shows superior robustness against unseen manipulations. As a by-product, our model achieves disentangled representation which separates the representation of manipulations from those of other latent causes. © 2020 Neural information processing systems foundation. All rights reserved.},
  document_type = {Conference Paper},
  groups        = {First Filtering},
  journal       = {Advances in Neural Information Processing Systems},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104916235&partnerID=40&md5=ce27bf202a337d91b850aa63dd154970},
}

@Article{Liu202036,
  author        = {Liu, X. and Xie, L. and Wang, Y. and Li, X.},
  journal       = {Chinese Journal of Network and Information Security},
  title         = {Adversarial attacks and defenses in deep learning},
  year          = {2020},
  note          = {cited By 0},
  number        = {5},
  pages         = {36-53},
  volume        = {6},
  abstract      = {The adversarial example is a modified image that is added imperceptible perturbations, which can make deep neural networks decide wrongly. The adversarial examples seriously threaten the availability of the system and bring great security risks to the system. Therefore, the representative adversarial attack methods were analyzed, including white-box attacks and black-box attacks. According to the development status of adversarial attacks and de-fenses, the relevant domestic and foreign defense strategies in recent years were described, including pre-processing, improving model robustness, malicious detection. Finally, future research directions in the field of adversarial attacks and adversarial defenses were given. © 2020, Beijing Xintong Media Co., Ltd.. All rights reserved.},
  document_type = {Article},
  doi           = {10.11959/j.issn.2096-109x.2020071},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103334552&doi=10.11959%2fj.issn.2096-109x.2020071&partnerID=40&md5=d8a2ce09b4a9d3fb2a0e70c5294a676a},
}

@Conference{Che20203405,
  author        = {Che, Z. and Borji, A. and Zhai, G. and Ling, S. and Li, J. and Callet, P.L.},
  title         = {A new ensemble adversarial attack powered by long-term gradient memories},
  year          = {2020},
  note          = {cited By 1},
  pages         = {3405-3413},
  abstract      = {Deep neural networks are vulnerable to adversarial attacks. More importantly, some adversarial examples crafted against an ensemble of pre-trained source models can transfer to other new target models, thus pose a security threat to blackbox applications (when the attackers have no access to the target models). Despite adopting diverse architectures and parameters, source and target models often share similar decision boundaries. Therefore, if an adversary is capable of fooling several source models concurrently, it can potentially capture intrinsic transferable adversarial information that may allow it to fool a broad class of other black-box target models. Current ensemble attacks, however, only consider a limited number of source models to craft an adversary, and obtain poor transferability. In this paper, we propose a novel black-box attack, dubbed Serial-Mini-Batch- Ensemble-Attack (SMBEA). SMBEA divides a large number of pre-trained source models into several mini-batches. For each single batch, we design 3 new ensemble strategies to improve the intra-batch transferability. Besides, we propose a new algorithm that recursively accumulates the "long-term"gradient memories of the previous batch to the following batch. This way, the learned adversarial information can be preserved and the inter-batch transferability can be improved. Experiments indicate that our method outperforms state-ofthe- art ensemble attacks over multiple pixel-to-pixel vision tasks including image translation and salient region prediction. Our method successfully fools two online black-box saliency prediction systems including DeepGaze-II (Kummerer 2017) and SALICON (Huang et al. 2017). Finally, we also contribute a new repository to promote the research on adversarial attack and defense over pixel-to-pixel tasks: https://github.com/CZHQuality/AAA-Pix2pix. © 2020, Association for the Advancement of Artificial Intelligence.},
  document_type = {Conference Paper},
  groups        = {First Filtering},
  journal       = {AAAI 2020 - 34th AAAI Conference on Artificial Intelligence},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103164179&partnerID=40&md5=2ddfe29b7c58c6b230bdc227bff78eb4},
}

@Article{Wu2020174679,
  author        = {Wu, D. and Nekovee, M. and Wang, Y.},
  journal       = {IEEE Access},
  title         = {Deep learning-based autoencoder for M-user wireless interference channel physical layer design},
  year          = {2020},
  note          = {cited By 2},
  pages         = {174679-174691},
  volume        = {8},
  abstract      = {Deep learning (DL) based autoencoder (AE) has been proposed recently as a promising, and potentially disruptive approach to design the physical layer of beyond-5G communication systems. Compared to a traditional communication system with a multiple-block structure, the DL based AE approach provides a new paradigm to physical layer design with a pure data-driven and end-to-end learning based solution. In this article, we address the dynamic interference in a multi-user Gaussian interference channel. We show that standard constellation are not optimal for this context, in particular, for a high interference condition. We propose a novel adaptive DL based AE to overcome this problem. With our approach, dynamic interference can be learned and predicted, which updates the learning processing for the decoder. Compared to other machine learning approaches, our method does not rely on a fixed training function, but is adaptive and applicable to practical systems. In comparison with the conventional system using n-psk or n-QAM modulation schemes with zero force (ZF) and minimum mean square error (MMSE) equalizer, the proposed adaptive deep learning (ADL) based AE demonstrates a significant achievable BER in the presence of interference, especially in strong and very strong interference scenarios. The proposed approach has laid the foundation of enabling adaptable constellation for 5G and beyond communication systems, where dynamic and heterogeneous network conditions are envisaged. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2020.3025597},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102818200&doi=10.1109%2fACCESS.2020.3025597&partnerID=40&md5=52fec08b7a897e2d5cd5ffa8e15a4de8},
}

@Article{Wang2020181102,
  author        = {Wang, Z. and Liu, Q. and Chi, Y.},
  journal       = {IEEE Access},
  title         = {Review of android malware detection based on deep learning},
  year          = {2020},
  note          = {cited By 1},
  pages         = {181102-181126},
  volume        = {8},
  abstract      = {At present, smartphones running the Android operating system have occupied the leading market share. However, due to the Android operating system’s open-source nature, Android malware has increased dramatically. Malware can steal user privacy and even maliciously charge fees and steal funds. It has posed a severe threat to cyberspace security because traditional detection methods have many limitations. With the widespread application of deep learning in recent years, the method of detecting Android malware using deep learning has gradually attracted widespread attention from scholars at home and abroad. Although scholars have researched Android malware detection using deep learning, there is currently a lack of a detailed and comprehensive introduction to malware detection’s latest research results based on deep learning. In order to solve this problem, this study analyzes and summarizes the latest research results by investigating a large number of the latest domestic and international academic papers, summarizing malware detection architecture and detection schemes, and analyzing existing problems and challenges. This review will help researchers better understand the research status and future research directions in this field. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.},
  document_type = {Review},
  doi           = {10.1109/ACCESS.2020.3028370},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102549448&doi=10.1109%2fACCESS.2020.3028370&partnerID=40&md5=2fe585853a87f1178f3290c08d5a241d},
}

@Article{Kim20203,
  author        = {Kim, Y. and Kang, H. and Mukaroh, A. and Suryanto, N. and Larasati, H.T. and Kim, H.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {Spatially localized perturbation GAN (SLP-GAN) for generating invisible adversarial patches},
  year          = {2020},
  note          = {cited By 0},
  pages         = {3-15},
  volume        = {12583 LNCS},
  abstract      = {Deep Neural Networks (DNNs) are very vulnerable to adversarial attacks because of the instability and unreliability under the training process. Recently, many studies about adversarial patches have been conducted that aims to misclassify the image classifier model by attaching patches to images. However, most of the previous research employs adversarial patches that are visible to human vision, making them easy to be identified and responded to. In this paper, we propose a new method entitled Spatially Localized Perturbation GAN (SLP-GAN) that can generate visually natural patches while maintaining a high attack success rate. SLP-GAN utilizes a spatially localized perturbation taken from the most representative area of target images (i.e., attention map) as the adversarial patches. The patch region is extracted using the Grad-CAM algorithm to improve the attacking ability against the target model. Our experiment, tested on GTSRB and CIFAR-10 datasets, shows that SLP-GAN outperforms the state-of-the-art adversarial patch attack methods in terms of visual fidelity. © Springer Nature Switzerland AG 2020.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-65299-9_1},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098260086&doi=10.1007%2f978-3-030-65299-9_1&partnerID=40&md5=e5d84c874f4eccd295cf1a407dd759d3},
}

@Article{Dong2020379,
  author        = {Dong, X. and Liu, H. and Ji, R. and Cao, L. and Ye, Q. and Liu, J. and Tian, Q.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {API-Net: Robust Generative Classifier via a Single Discriminator},
  year          = {2020},
  note          = {cited By 0},
  pages         = {379-394},
  volume        = {12358 LNCS},
  abstract      = {Robustness of deep neural network classifiers has been attracting increased attention. As for the robust classification problem, a generative classifier typically models the distribution of inputs and labels, and thus can better handle off-manifold examples at the cost of a concise structure. On the contrary, a discriminative classifier only models the conditional distribution of labels given inputs, but benefits from effective optimization owing to its succinct structure. This work aims for a solution of generative classifiers that can profit from the merits of both. To this end, we propose an Anti-Perturbation Inference (API) method, which searches for anti-perturbations to maximize the lower bound of the joint log-likelihood of inputs and classes. By leveraging the lower bound to approximate Bayes’ rule, we construct a generative classifier Anti-Perturbation Inference Net (API-Net) upon a single discriminator. It takes advantage of the generative properties to tackle off-manifold examples while maintaining a succinct structure for effective optimization. Experiments show that API successfully neutralizes adversarial perturbations, and API-Net consistently outperforms state-of-the-art defenses on prevailing benchmarks, including CIFAR-10, MNIST, and SVHN.(Our code is available at github.com/dongxinshuai/API-Net.). © 2020, Springer Nature Switzerland AG.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-58601-0_23},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097615334&doi=10.1007%2f978-3-030-58601-0_23&partnerID=40&md5=99e8166f7baec029b267b0db76826267},
}

@Article{Chen2020217463,
  author        = {Chen, Z. and Lv, N. and Liu, P. and Fang, Y. and Chen, K. and Pan, W.},
  journal       = {IEEE Access},
  title         = {Intrusion Detection for Wireless Edge Networks Based on Federated Learning},
  year          = {2020},
  note          = {cited By 0},
  pages         = {217463-217472},
  volume        = {8},
  abstract      = {Edge computing provides off-load computing and application services close to end-users, greatly reducing cloud pressure and communication overhead. However, wireless edge networks still face the risk of network attacks. To ensure the security of wireless edge networks, we present Federated Learning-based Attention Gated Recurrent Unit (FedAGRU), an intrusion detection algorithm for wireless edge networks. FedAGRU differs from current centralized learning methods by updating universal learning models rather than directly sharing raw data among edge devices and a central server. We also apply the attention mechanism to increase the weight of important devices, by avoiding the upload of unimportant updates to the server, FedAGRU can greatly reduce communication overhead while ensuring learning convergence. Our experimental results show that, compared with other centralized learning algorithms, FedAGRU improves detection accuracy by approximately 8%. In addition, FedAGRU's communication cost is 70% less than other federated learning algorithms, and it exhibits strong robustness against poisoning attacks. © 2013 IEEE.},
  art_number    = {9274294},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2020.3041793},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097364075&doi=10.1109%2fACCESS.2020.3041793&partnerID=40&md5=cc20866995f3b4d2c276f3889b6cd8e1},
}

@Article{Zhang202012,
  author        = {Zhang, X. and Wang, J. and Sun, M. and Feng, Y.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {AndrOpGAN: An Opcode GAN for Android Malware Obfuscations},
  year          = {2020},
  note          = {cited By 0},
  pages         = {12-25},
  volume        = {12486 LNCS},
  abstract      = {With the rapid development of Android platform, the number of Android malwares is growing rapidly. Due to the limitations of traditional static and runtime Android malware analysis methods, machine learning based approaches are widely adopted recently. Whereas, evading methods are also emerging, e.g. data set pollution, feature modification. Current feature modifications are mainly based on high-level features such as API calls or sensitive permissions. Our contribution is to show it is also feasible to deceive the detectors by modifying underlying features. Through this confusion, detector deceiving can be achieved. An Android malware opcode distribution feature modification system AndrOpGAN was proposed. To adjust the opcode distribution of malware, Deep Convolution Generative Adversarial Networks (DCGAN) was proposed to generate opcodes distribution features, and opcodes would be inserted through an Opcode Frequency Optimal Adjustment algorithm (OFOA). OFOA module can keep the APK running normally after insertion with a low modification cost. Test results against four detectors show that more than 99% APKs processed by AndrOpGAN could bypass detections successfully. Test results against VirusTotal shows that, the number of successful detection engines decreased 20%–44%. AndrOpGAN validates the feasibility of such attacks based on underlying feature modifications and provides a prototype system for researchers to improve detector’s performance. © 2020, Springer Nature Switzerland AG.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-62223-7_2},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097150955&doi=10.1007%2f978-3-030-62223-7_2&partnerID=40&md5=7710725d8de6f58811b02037cd415c60},
}

@Article{Kim2020416,
  author        = {Kim, B. and Chudomelka, B. and Park, J. and Kang, J. and Hong, Y. and Kim, H.J.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {Robust Neural Networks Inspired by Strong Stability Preserving Runge-Kutta Methods},
  year          = {2020},
  note          = {cited By 1},
  pages         = {416-432},
  volume        = {12354 LNCS},
  abstract      = {Deep neural networks have achieved state-of-the-art performance in a variety of fields. Recent works observe that a class of widely used neural networks can be viewed as the Euler method of numerical discretization. From the numerical discretization perspective, Strong Stability Preserving (SSP) methods are more advanced techniques than the explicit Euler method that produce both accurate and stable solutions. Motivated by the SSP property and a generalized Runge-Kutta method, we proposed Strong Stability Preserving networks (SSP networks) which improve robustness against adversarial attacks. We empirically demonstrate that the proposed networks improve the robustness against adversarial examples without any defensive methods. Further, the SSP networks are complementary with a state-of-the-art adversarial training scheme. Lastly, our experiments show that SSP networks suppress the blow-up of adversarial perturbations. Our results open up a way to study robust architectures of neural networks leveraging rich knowledge from numerical discretization literature. © 2020, Springer Nature Switzerland AG.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-58545-7_24},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097079240&doi=10.1007%2f978-3-030-58545-7_24&partnerID=40&md5=84b500f159f3841118737a36ceaed9d9},
}

@Article{Kumar2020,
  author        = {Kumar, P. and Gupta, G.P. and Tripathi, R.},
  journal       = {Journal of Ambient Intelligence and Humanized Computing},
  title         = {A distributed ensemble design based intrusion detection system using fog computing to protect the internet of things networks},
  year          = {2020},
  note          = {cited By 2},
  abstract      = {With the development of internet of things (IoT), capabilities of computing, networking infrastructure, storage of data and management have come very close to the edge of networks. This has accelerated the necessity of Fog computing paradigm. Due to availability of Internet, most of our business operations are integrated with IoT platform. Fog computing has enhanced the strategy of collecting and processing, huge amount of data. On the other hand, attacks and malicious activities has adverse consequences on the development of IoT, Fog, and cloud computing. This has led to development of many security models using fog computing to protect IoT network. Therefore, for dynamic and highly scalable IoT environment, a distributed architecture based intrusion detection system (IDS) is required that can distribute the existing centralized computing to local fog nodes and can efficiently detect modern IoT attacks. This paper proposes a novel distributed ensemble design based IDS using Fog computing, which combines k-nearest neighbors, XGBoost, and Gaussian naive Bayes as first-level individual learners. At second-level, the prediction results obtained from first level is used by Random Forest for final classification. Most of the existing proposals are tested using KDD99 or NSL-KDD dataset. However, these datasets are obsolete and lack modern IoT-based attacks. In this paper, UNSW-NB15 and actual IoT-based dataset namely, DS2OS are used for verifying the effectiveness of the proposed system. The experimental result revealed that the proposed distributed IDS with UNSW-NB15 can achieve higher detection rate upto 71.18% for Backdoor, 68.98% for Analysis, 92.25% for Reconnaissance and 85.42% for DoS attacks. Similarly, with DS2OS dataset, detection rate is upto 99.99% for most of the attack vectors. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.},
  document_type = {Article},
  doi           = {10.1007/s12652-020-02696-3},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096778110&doi=10.1007%2fs12652-020-02696-3&partnerID=40&md5=26328028f501b23b8c43ad3fd93e8eb4},
}

@Conference{Guo2020628,
  author        = {Guo, M. and Yang, Y. and Xu, R. and Liu, Z. and Lin, D.},
  title         = {When NAS Meets Robustness: In Search of Robust Architectures against Adversarial Attacks},
  year          = {2020},
  note          = {cited By 7},
  pages         = {628-637},
  abstract      = {Recent advances in adversarial attacks uncover the intrinsic vulnerability of modern deep neural networks. Since then, extensive efforts have been devoted to enhancing the robustness of deep networks via specialized learning algorithms and loss functions. In this work, we take an architectural perspective and investigate the patterns of network architectures that are resilient to adversarial attacks. To obtain the large number of networks needed for this study, we adopt one-shot neural architecture search, training a large network for once and then finetuning the sub-networks sampled therefrom. The sampled architectures together with the accuracies they achieve provide a rich basis for our study. Our "robust architecture Odyssey"reveals several valuable observations: 1) densely connected patterns result in improved robustness; 2) under computational budget, adding convolution operations to direct connection edge is effective; 3) flow of solution procedure (FSP) matrix is a good indicator of network robustness. Based on these observations, we discover a family of robust architectures (RobNets). On various datasets, including CIFAR, SVHN, Tiny-ImageNet, and ImageNet, RobNets exhibit superior robustness performance to other widely used architectures. Notably, RobNets substantially improve the robust accuracy (∼5% absolute gains) under both white-box and black-box attacks, even with fewer parameter numbers. Code is available at https://github.com/gmh14/RobNets. © 2020 IEEE.},
  art_number    = {9156305},
  document_type = {Conference Paper},
  doi           = {10.1109/CVPR42600.2020.00071},
  groups        = {First Filtering},
  journal       = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094809384&doi=10.1109%2fCVPR42600.2020.00071&partnerID=40&md5=fd09c551d392abefa923ca9d35a8a719},
}

@Article{Cheng202020,
  author        = {Cheng, Z. and Cui, B. and Fu, J.},
  journal       = {Communications in Computer and Information Science},
  title         = {A novel web anomaly detection approach based on semantic structure},
  year          = {2020},
  note          = {cited By 1},
  pages         = {20-33},
  volume        = {1298 CCIS},
  abstract      = {In recent years, various machine learning, deep learning based models have been developed to detect novel web attacks. These models are mostly use NLP methods, like N-gram, word-embedding, to process URLs as the general strings composed of characters. In contrast to natural language which consist of words, the URL is composed of characters and hardly decomposes into several meaning segments. In fact, HTTP requests have its inherent patterns, which so-called semantic structure, such as the request bodies have fixed type, request parameters have fixed structure in names and orders, values of these parameters also have special semantics such as username, password, page id, commodity id. These methods have no mechanism to learn semantic structure. They roughly use NLP techniques like DFA, attention techniques to learn normal patterns from dataset. And, they also need a mount of dataset to train. In this paper, we propose a novel web anomaly detection approach based on semantic structure. Firstly, a hierarchical method is proposed to automatically learn semantic structure from training dataset. Then, we learn normal profile for each parameter. The experimental results showed that our approach achieved a high precision rate of 99.29% while maintaining a low false alarm rate of 0.88%. Moreover, even on a small training dataset composed of hundreds of samples, we also achieved 96.3% accuracy rate. © Springer Nature Singapore Pte Ltd 2020.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-981-15-9031-3_2},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092202781&doi=10.1007%2f978-981-15-9031-3_2&partnerID=40&md5=cc9ae506ef622a45e629dc39529d80f2},
}

@Article{Xiong2020431,
  author        = {Xiong, Y. and Xu, F. and Zhong, S. and Li, Q.},
  journal       = {IFIP Advances in Information and Communication Technology},
  title         = {Escaping Backdoor Attack Detection of Deep Learning},
  year          = {2020},
  note          = {cited By 0},
  pages         = {431-445},
  volume        = {580 IFIP},
  abstract      = {Malicious attacks become a top concern in the field of deep learning (DL) because they have kept threatening the security and safety of applications where DL models are deployed. The backdoor attack, an emerging one among these malicious attacks, attracts a lot of research attentions in detecting it because of its severe consequences. Latest backdoor detections have made great progress by reconstructing backdoor triggers and performing the corresponding outlier detection. Although they are effective on existing triggers, they still fall short of detecting stealthy ones which are proposed in this work. New triggers of our backdoor attack can be generally inserted into DL models through a hidden and reconstruction-resistant manner. We evaluate our attack against two state-of-the-art detections on three different data sets, and demonstrate that our attack is able to successfully insert target backdoors and also escape the detections. We hope our design is able to shed some light on how the backdoor detection should be advanced along this line in future. © 2020, IFIP International Federation for Information Processing.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-58201-2_29},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092106164&doi=10.1007%2f978-3-030-58201-2_29&partnerID=40&md5=8aa370bc17d5dd97407396318df3b68e},
}

@Article{Yu2020,
  author        = {Yu, F. and Wang, L. and Fang, X. and Zhang, Y.},
  journal       = {Security and Communication Networks},
  title         = {The defense of adversarial example with conditional generative adversarial networks},
  year          = {2020},
  note          = {cited By 2},
  volume        = {2020},
  abstract      = {Deep neural network approaches have made remarkable progress in many machine learning tasks. However, the latest research indicates that they are vulnerable to adversarial perturbations. An adversary can easily mislead the network models by adding well-designed perturbations to the input. The cause of the adversarial examples is unclear. Therefore, it is challenging to build a defense mechanism. In this paper, we propose an image-to-image translation model to defend against adversarial examples. The proposed model is based on a conditional generative adversarial network, which consists of a generator and a discriminator. The generator is used to eliminate adversarial perturbations in the input. The discriminator is used to distinguish generated data from original clean data to improve the training process. In other words, our approach can map the adversarial images to the clean images, which are then fed to the target deep learning model. The defense mechanism is independent of the target model, and the structure of the framework is universal. A series of experiments conducted on MNIST and CIFAR10 show that the proposed method can defend against multiple types of attacks while maintaining good performance. © 2020 Fangchao Yu et al.},
  art_number    = {3932584},
  document_type = {Article},
  doi           = {10.1155/2020/3932584},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092005175&doi=10.1155%2f2020%2f3932584&partnerID=40&md5=9f261329a994cebe450ad5180497e614},
}

@Article{Reddy2021,
  author        = {Reddy, D.K. and Behera, H.S. and Nayak, J. and Vijayakumar, P. and Naik, B. and Singh, P.K.},
  journal       = {Transactions on Emerging Telecommunications Technologies},
  title         = {Deep neural network based anomaly detection in Internet of Things network traffic tracking for the applications of future smart cities},
  year          = {2021},
  note          = {cited By 4},
  number        = {7},
  volume        = {32},
  abstract      = {An anomaly exposure system's foremost objective is to categorize the behavior of the system into normal and untruthful actions. To estimate the possible incidents, the administrators of smart cities have to apply anomaly detection engines to avert data from being jeopardized by errors or attacks. This article aims to propose a novel deep learning-based framework with a dense random neural network approach for distinguishing and classifying anomaly from normal behaviors based on the type of attack in the Internet of Things. Machine learning algorithms have the improbability to explore the performance, compared with deep learning models. Distinctively, the examination of deep learning neural network architectures achieved enhanced computation performance and deliver desired results for categorical attacks. This article focuses on the complete study of experimentation performance and evaluations on deep learning neural network architecture for the recognition of seven categorical attacks found in the Distributed Smart Space Orchestration System traffic traces data set. The empirical results of the simulation model report that deep neural network architecture performs well through noticeable improvement in most of the categorical attack. © 2020 John Wiley & Sons Ltd},
  art_number    = {e4121},
  document_type = {Article},
  doi           = {10.1002/ett.4121},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091727413&doi=10.1002%2fett.4121&partnerID=40&md5=249c7b2aa68cbd409f3d1d5f5e64d6fe},
}

@Article{Zhong2020794,
  author        = {Zhong, Y. and Zhu, Y. and Wang, Z. and Yin, X. and Shi, X. and Li, K.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {An Adversarial Learning Model for Intrusion Detection in Real Complex Network Environments},
  year          = {2020},
  note          = {cited By 0},
  pages         = {794-806},
  volume        = {12384 LNCS},
  abstract      = {Network intrusion detection plays an important role in network security. With the deepening of machine learning research, especially the generative adversarial networks (GAN) proposal, the stability of the anomaly detector is put forward for higher requirements. The main focus of this paper is on the security of machine learning based anomaly detectors. In order to detect the robustness of the existing advanced anomaly detection algorithm, we propose an anomaly detector attack framework MACGAN (maintain attack features based on the generative adversarial networks). The MACGAN framework consists of two parts. The first part is used to analyze the attack fields manually. Then, the learning function of GAN in the second part is used to bypass the anomaly detection. Our framework is tested on the latest Kitsune2018 and CICIDS2017 data sets. Experimental results demonstrate the ability to bypass the state-of-the-art machine learning algorithms. This greatly helps the network security researchers to improve the stability of the detector. © 2020, Springer Nature Switzerland AG.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-59016-1_65},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091531501&doi=10.1007%2f978-3-030-59016-1_65&partnerID=40&md5=b6493c41cf67acca0a37d64ca1b246d3},
}

@Article{Dasgupta2020,
  author        = {Dasgupta, D. and Akhtar, Z. and Sen, S.},
  journal       = {Journal of Defense Modeling and Simulation},
  title         = {Machine learning in cybersecurity: a comprehensive survey},
  year          = {2020},
  note          = {cited By 3},
  abstract      = {Today’s world is highly network interconnected owing to the pervasiveness of small personal devices (e.g., smartphones) as well as large computing devices or services (e.g., cloud computing or online banking), and thereby each passing minute millions of data bytes are being generated, processed, exchanged, shared, and utilized to yield outcomes in specific applications. Thus, securing the data, machines (devices), and user’s privacy in cyberspace has become an utmost concern for individuals, business organizations, and national governments. In recent years, machine learning (ML) has been widely employed in cybersecurity, for example, intrusion or malware detection and biometric-based user authentication. However, ML algorithms are vulnerable to attacks both in the training and testing phases, which usually leads to remarkable performance decreases and security breaches. Comparatively, limited studies have been conducted to understand the essence and degree of the vulnerabilities of ML techniques against security threats and their defensive mechanisms. It is imperative to systematize recent works related to cybersecurity using ML to seek the attention of researchers, scientists, and engineers. Therefore, in this paper, we provide a comprehensive survey of the works that have been carried out most recently (from 2013 to 2018) on ML in cybersecurity, describing the basics of cyber-attacks and corresponding defenses, the basics of the most commonly used ML algorithms, and proposed ML and data mining schemes for cybersecurity in terms of features, dimensionality reduction, and classification/detection techniques. In this context, this article also provides an overview of adversarial ML, including the security characteristics of deep learning methods. Finally, open issues and challenges in cybersecurity are highlighted and potential future research directions are discussed. © The Author(s) 2020.},
  document_type = {Article},
  doi           = {10.1177/1548512920951275},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091209612&doi=10.1177%2f1548512920951275&partnerID=40&md5=1efe9410a0c570ec6301a6ea44f7eef7},
}

@Article{Teuffenbach2020301,
  author        = {Teuffenbach, M. and Piatkowska, E. and Smith, P.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {Subverting Network Intrusion Detection: Crafting Adversarial Examples Accounting for Domain-Specific Constraints},
  year          = {2020},
  note          = {cited By 0},
  pages         = {301-320},
  volume        = {12279 LNCS},
  abstract      = {Deep Learning (DL) algorithms are being applied to network intrusion detection, as they can outperform other methods in terms of computational efficiency and accuracy. However, these algorithms have recently been found to be vulnerable to adversarial examples – inputs that are crafted with the intent of causing a Deep Neural Network (DNN) to misclassify with high confidence. Although a significant amount of work has been done to find robust defence techniques against adversarial examples, they still pose a potential risk. The majority of the proposed attack and defence strategies are tailored to the computer vision domain, in which adversarial examples were first found. In this paper, we consider this issue in the Network Intrusion Detection System (NIDS) domain and extend existing adversarial example crafting algorithms to account for the domain-specific constraints in the feature space. We propose to incorporate information about the difficulty of feature manipulation directly in the optimization function. Additionally, we define a novel measure for attack cost and include it in the assessment of the robustness of DL algorithms. We validate our approach on two benchmark datasets and demonstrate successful attacks against state-of-the-art DL network intrusion detection algorithms. © 2020, IFIP International Federation for Information Processing.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-57321-8_17},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090176272&doi=10.1007%2f978-3-030-57321-8_17&partnerID=40&md5=326398dfb1d4f2112ed0a6af082f372b},
}

@Book{Zarpelão2020225,
  author        = {Zarpelão, B.B. and Barbon, S., Jr. and Acarali, D. and Rajarajan, M.},
  title         = {How machine learning can support cyberattack detection in smart grids},
  year          = {2020},
  note          = {cited By 0},
  abstract      = {This chapter addresses the application of machine learning algorithms to detect attacks against smart grids. Smart grids are the result of a long process of transformation that power systems have been through, relying on Information and Communication Technology (ICT) to improve their monitoring and control. Although an objective of this convergence of power systems and ICT is to increase their reliability, the dependency on information technology has brought new cybersecurity vulnerabilities to this scenario. Therefore, developing new cybersecurity measures for smart grids is a key factor in their success. One of these measures is attack detection, which allows the timely mitigation of attacks with the aim of limiting possible damages to the targets. As machine learning algorithms have been widely applied as powerful tools to support the design of cybersecurity solutions in multiple areas, they also have huge potential for addressing the new challenges that smart grids pose. With this as the foundational perspective, this study starts by presenting an overview of smart grids, followed by possible attacks. After this discussion, we examine the background concepts for attack detection and machine learning. Then, we discuss the existing solutions, showing in detail how they address the particularities of smart grids and their attack types using machine learning algorithms. This is supplemented by a discussion of the open issues in the use of machine learning for smart grid attack detection, followed by some future research directions. © Springer Nature Switzerland AG 2020.},
  document_type = {Book Chapter},
  doi           = {10.1007/978-3-030-42726-9_9},
  groups        = {First Filtering},
  journal       = {Artificial Intelligence Techniques for a Scalable Energy Transition: Advanced Methods, Digital Technologies, Decision Support Tools, and Applications},
  pages         = {225-258},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089321105&doi=10.1007%2f978-3-030-42726-9_9&partnerID=40&md5=b5ba1389f918509bd21219a4ae73e3bf},
}

@Article{Kurniabudi2020132911,
  author        = {Kurniabudi and Stiawan, D. and Darmawijoyo and Bin Idris, M.Y.B. and Bamhdi, A.M. and Budiarto, R.},
  journal       = {IEEE Access},
  title         = {CICIDS-2017 Dataset Feature Analysis with Information Gain for Anomaly Detection},
  year          = {2020},
  note          = {cited By 11},
  pages         = {132911-132921},
  volume        = {8},
  abstract      = {Feature selection (FS) is one of the important tasks of data preprocessing in data analytics. The data with a large number of features will affect the computational complexity, increase a huge amount of resource usage and time consumption for data analytics. The objective of this study is to analyze relevant and significant features of huge network traffic to be used to improve the accuracy of traffic anomaly detection and to decrease its execution time. Information Gain is the most feature selection technique used in Intrusion Detection System (IDS) research. This study uses Information Gain, ranking and grouping the features according to the minimum weight values to select relevant and significant features, and then implements Random Forest (RF), Bayes Net (BN), Random Tree (RT), Naive Bayes (NB) and J48 classifier algorithms in experiments on CICIDS-2017 dataset. The experiment results show that the number of relevant and significant features yielded by Information Gain affects significantly the improvement of detection accuracy and execution time. Specifically, the Random Forest algorithm has the highest accuracy of 99.86% using the relevant selected features of 22, whereas the J48 classifier algorithm provides an accuracy of 99.87% using 52 relevant selected features with longer execution time. © 2013 IEEE.},
  art_number    = {9142219},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2020.3009843},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089303928&doi=10.1109%2fACCESS.2020.3009843&partnerID=40&md5=b8bc2179aeacb111e9699cfc3c7c90e8},
}

@Article{Zhao2020,
  author        = {Zhao, G. and Zhang, M. and Liu, J. and Li, Y. and Wen, J.-R.},
  journal       = {GeoInformatica},
  title         = {AP-GAN: Adversarial patch attack on content-based image retrieval systems},
  year          = {2020},
  note          = {cited By 0},
  abstract      = {Key Smart City applications such as traffic management and public security rely heavily on the intelligent processing of video and image data, often in the form of visual retrieval tasks, such as person Re-IDentification (ReID) and vehicle re-identification. For these tasks, Deep Neural Networks (DNNs) have been the dominant solution for the past decade, for their remarkable ability in learning discriminative features from images to boost retrieval performance. However, it is been discovered that DNNs are broadly vulnerable to maliciously constructed adversarial examples. By adding small perturbations to a query image, the returned retrieval results will be completely dissimilar from the query image. This poses serious challenges to vital systems in Smart City applications that depend on the DNN-based visual retrieval technology, as in the physical world, simple camouflage can be added on the subject (a few patches on the body or car), and turn the subject completely untrackable by person or vehicle Re-ID systems. To demonstrate the potential of such threats, this paper proposes a novel adversarial patch generative adversarial network (AP-GAN) to generate adversarial patches instead of modifying the entire image, which also causes the DNNs-based image retrieval models to return incorrect results. AP-GAN is trained in an unsupervised way that requires only a small amount of unlabeled data for training. Once trained, it produces query-specific perturbations for query images to form adversarial queries. Extensive experiments show that the AP-GAN achieves excellent attacking performance with various application scenarios that are based on deep features, including image retrieval, person ReID and vehicle ReID. The results of this study provide a warning that when deploying a DNNs-based image retrieval system, its security and robustness needs to be thoroughly considered. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.},
  document_type = {Article},
  doi           = {10.1007/s10707-020-00418-7},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088833795&doi=10.1007%2fs10707-020-00418-7&partnerID=40&md5=e64df456434eed731373c5883ef9e285},
}

@Article{Liu2020124579,
  author        = {Liu, K. and Xu, S. and Xu, G. and Zhang, M. and Sun, D. and Liu, H.},
  journal       = {IEEE Access},
  title         = {A Review of Android Malware Detection Approaches Based on Machine Learning},
  year          = {2020},
  note          = {cited By 13},
  pages         = {124579-124607},
  volume        = {8},
  abstract      = {Android applications are developing rapidly across the mobile ecosystem, but Android malware is also emerging in an endless stream. Many researchers have studied the problem of Android malware detection and have put forward theories and methods from different perspectives. Existing research suggests that machine learning is an effective and promising way to detect Android malware. Notwithstanding, there exist reviews that have surveyed different issues related to Android malware detection based on machine learning. We believe our work complements the previous reviews by surveying a wider range of aspects of the topic. This paper presents a comprehensive survey of Android malware detection approaches based on machine learning. We briefly introduce some background on Android applications, including the Android system architecture, security mechanisms, and classification of Android malware. Then, taking machine learning as the focus, we analyze and summarize the research status from key perspectives such as sample acquisition, data preprocessing, feature selection, machine learning models, algorithms, and the evaluation of detection effectiveness. Finally, we assess the future prospects for research into Android malware detection based on machine learning. This review will help academics gain a full picture of Android malware detection based on machine learning. It could then serve as a basis for subsequent researchers to start new work and help to guide research in the field more generally. © 2013 IEEE.},
  art_number    = {9130686},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2020.3006143},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088698117&doi=10.1109%2fACCESS.2020.3006143&partnerID=40&md5=343cd911010458064ca7c2ce1bbbac66},
}

@Article{Wang2020124503,
  author        = {Wang, D. and Dong, L. and Wang, R. and Yan, D. and Wang, J.},
  journal       = {IEEE Access},
  title         = {Targeted Speech Adversarial Example Generation with Generative Adversarial Network},
  year          = {2020},
  note          = {cited By 2},
  pages         = {124503-124513},
  volume        = {8},
  abstract      = {Although neural network-based speech recognition models have enjoyed significant success in many acoustic systems, they are susceptible to be attacked by the adversarial examples. In this work, we make first step towards using generative adversarial network (GAN) for constructing the targeted speech adversarial examples. Specifically, we integrate the target speech recognition network with GAN framework, which can then be formulated as a three-party game. The generator in GAN aims at generating perturbation that could make the target network misclassified to a specific target, while simultaneously fooling the discriminator treating the adversarial example as a beguine one. The discriminator is to distinguish the crafted examples from the geniue samples. The classification error of the target network is back-propagated via gradient flow to the generator for updating. The target network is responsible for back-propagating the classification error via gradients to the generator for updating, but the target network itself is freezed. With the carefully designed network architecture, loss function and training strategy, we successfully train a generator that could generate the adversarial perturbation for a given speech clip and a target label. Experiential results show that the generated adversarial examples could effectively fool the state-of-the-art speech classification networks, while attaining an acceptable auditory perception quality. In addition, our proposed method runs much faster than the prevalent optimization-based schemes. To facilitate reproducible research, codes, models and data are publicly available at https://github.com/winterwindwang/SpeechAdvGan. © 2013 IEEE.},
  art_number    = {9129727},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2020.3006130},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088695668&doi=10.1109%2fACCESS.2020.3006130&partnerID=40&md5=1ab2f2aab9b0e3f1bbe9e2432f8c6f94},
}

@Article{Zavrak2020108346,
  author        = {Zavrak, S. and Iskefiyeli, M.},
  journal       = {IEEE Access},
  title         = {Anomaly-Based Intrusion Detection from Network Flow Features Using Variational Autoencoder},
  year          = {2020},
  note          = {cited By 17},
  pages         = {108346-108358},
  volume        = {8},
  abstract      = {The rapid increase in network traffic has recently led to the importance of flow-based intrusion detection systems processing a small amount of traffic data. Furthermore, anomaly-based methods, which can identify unknown attacks are also integrated into these systems. In this study, the focus is concentrated on the detection of anomalous network traffic (or intrusions) from flow-based data using unsupervised deep learning methods with semi-supervised learning approach. More specifically, Autoencoder and Variational Autoencoder methods were employed to identify unknown attacks using flow features. In the experiments carried out, the flow-based features extracted out of network traffic data, including typical and different types of attacks, were used. The Receiver Operating Characteristics (ROC) and the area under ROC curve, resulting from these methods were calculated and compared with One-Class Support Vector Machine. The ROC curves were examined in detail to analyze the performance of the methods in various threshold values. The experimental results show that Variational Autoencoder performs, for the most part, better than Autoencoder and One-Class Support Vector Machine. © 2013 IEEE.},
  art_number    = {9113298},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2020.3001350},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086985318&doi=10.1109%2fACCESS.2020.3001350&partnerID=40&md5=4a8faa2ea6e436f86823ce9973098fd0},
}

@Article{Latif202089337,
  author        = {Latif, S. and Zou, Z. and Idrees, Z. and Ahmad, J.},
  journal       = {IEEE Access},
  title         = {A Novel Attack Detection Scheme for the Industrial Internet of Things Using a Lightweight Random Neural Network},
  year          = {2020},
  note          = {cited By 7},
  pages         = {89337-89350},
  volume        = {8},
  abstract      = {The Industrial Internet of Things (IIoT) brings together many sensors, machines, industrial applications, databases, services, and people at work. The IIoT is improving our lives in several ways including smarter cities, agriculture, and e-healthcare, etc. Although the IIoT shares several characteristics with the consumer IoT, different cybersecurity mechanisms are adopted for both networks. Unlike consumer IoT solutions that are used by an individual user for a single purpose, IIoT solutions tend to be integrated into larger operational systems. As a result, IIoT security solutions require additional planning and awareness to ensure the security and privacy of the system. In this paper, different cybersecurity attacks such as denial of service (DoS), malicious operation, malicious control, data type probing, spying, scan, and wrong setup are predicted by applying machine learning techniques. To predict the aforementioned attacks, a novel lightweight random neural network (RaNN)-based prediction model has been proposed in this article. To investigate the performance of the RaNN-based prediction model, several evaluation parameters such as accuracy, precision, recall, and F1 score were calculated and compared with the traditional artificial neural network (ANN), support vector machine (SVM) and decision tree (DT). The evaluation results show that the proposed RaNN model achieves an accuracy of 99.20% for a learning rate of 0.01, with a prediction time of 34.51 milliseconds. Other performance parameters such as the precision, recall, and F1 score were 99.11%, 99.13%, and 99.20%, respectively. The proposed scheme improves the attack detection accuracy by an average of 5.65% compared to that of state-of-the-art machine learning schemes for IoT security. © 2013 IEEE.},
  art_number    = {9091574},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2020.2994079},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085555907&doi=10.1109%2fACCESS.2020.2994079&partnerID=40&md5=f4c2003fe3981924b984734e54f016a2},
}

@Article{Wu2020342,
  author        = {Wu, D. and Nekovee, M. and Wang, Y.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {An Adaptive Deep Learning Algorithm Based Autoencoder for Interference Channels},
  year          = {2020},
  note          = {cited By 1},
  pages         = {342-354},
  volume        = {12081 LNCS},
  abstract      = {Deep learning (DL) based autoencoder (AE) has been proposed recently as a promising, and potentially disruptive Physical Layer (PHY) design for beyond-5G communication systems. Compared to a traditional communication system with a multiple-block structure, the DL based AE provides a new PHY paradigm with a pure data-driven and end-to-end learning based solution. However, significant challenges are to be overcome before this approach becomes a serious contender for practical beyond-5G systems. One of such challenges is the robustness of AE under interference channels. In this paper, we first evaluate the performance and robustness of an AE in the presence of an interference channel. Our results show that AE performs well under weak and moderate interference condition, while its performance degrades substantially under strong and very strong interference condition. We further propose a novel online adaptive deep learning (ADL) algorithm to tackle the performance issue of AE under strong and very strong interference, where level of interference can be predicted in real time for the decoding process. The performance of the proposed algorithm for different interference scenarios is studied and compared to the existing system using a conventional DL-assist AE through an offline learning method. Our results demonstrate the robustness of the proposed ADL-assist AE over the entire range of interference levels, while existing AE fail to perform in the presence of strong and very strong interference. The work proposed in this paper is an important step towards enabling AE for practical 5G and beyond communication systems with dynamic and heterogeneous interference. © 2020, IFIP International Federation for Information Processing.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-45778-5_23},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084184146&doi=10.1007%2f978-3-030-45778-5_23&partnerID=40&md5=c8c210ae0df3a165aabd3fb21baf6728},
}

@Conference{Vaarandi2020448,
  author        = {Vaarandi, R. and Pihelgas, M.},
  title         = {Netflow based framework for identifying anomalous end user nodes},
  year          = {2020},
  note          = {cited By 0},
  pages         = {448-456},
  abstract      = {During the last two decades, cyber attacks against end users have grown significantly both in terms of number and sophistication. Unfortunately, traditional signature-based technologies such as network IDS/IPS and next generation firewalls are able to detect known attacks only, while new attack types not matching any signatures remain unnoticed. Therefore, the use of machine learning for detecting anomalous network traffic of end user nodes has become an important research problem. In this paper, we present a novel NetFlow based framework for identifying anomalous end user nodes and their network traffic patterns, and describe experiments for evaluating framework performance in an organizational network. © 2020. the authors. All Rights Reserved.},
  document_type = {Conference Paper},
  doi           = {10.34190/ICCWS.20.035},
  groups        = {First Filtering},
  journal       = {Proceedings of the 15th International Conference on Cyber Warfare and Security, ICCWS 2020},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083394962&doi=10.34190%2fICCWS.20.035&partnerID=40&md5=cea99fee7abde72c7154b79a3cb975b0},
}

@Article{Lawal202043355,
  author        = {Lawal, M.A. and Shaikh, R.A. and Hassan, S.R.},
  journal       = {IEEE Access},
  title         = {Security Analysis of Network Anomalies Mitigation Schemes in IoT Networks},
  year          = {2020},
  note          = {cited By 6},
  pages         = {43355-43374},
  volume        = {8},
  abstract      = {The Internet of Things (IoT) is on the rise and it is giving a new shape to several fields such as smart cities, smart homes, smart health, etc. as it facilitates the connection of physical objects to the internet. However, this advancement comes along with new challenges in terms of security of the devices in the IoT networks. Some of these challenges come as network anomalies. Hence, this has prompted the use of network anomaly mitigation schemes as an integral part of the defense mechanisms of IoT networks in order to protect the devices from malicious users. Thus, several schemes have been proposed to mitigate network anomalies. This paper covers a review of different network anomaly mitigation schemes in IoT networks. The schemes' objectives, operational procedures, and strengths are discussed. A comparison table of the reviewed schemes, as well as a taxonomy based on the detection methodology, is provided. In contrast to other surveys that presented qualitative evaluations, our survey provides both qualitative and quantitative evaluations. The UNSW-NB15 dataset was used to conduct a performance evaluation of some classification algorithms used for network anomaly mitigation schemes in IoT. Finally, challenges and open issues in the development of network anomaly mitigation schemes in IoT are discussed. © 2013 IEEE.},
  art_number    = {9016241},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2020.2976624},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082034491&doi=10.1109%2fACCESS.2020.2976624&partnerID=40&md5=d689653cd1795037da344acc6bd0bd18},
}

@Article{Wang20201,
  author        = {Wang, Y. and Yang, X. and Jin, H.},
  journal       = {Communications in Computer and Information Science},
  title         = {Generative Image Steganography Based on GANs},
  year          = {2020},
  note          = {cited By 0},
  pages         = {1-15},
  volume        = {1149 CCIS},
  abstract      = {According to the embedding method of secret information, steganography can be divided into: cover modification, selection and synthesis. In view of the problem that the cover modification will leave the modification trace, the cover selection is difficult and the load is too low, this paper proposes a generative image steganography scheme based on GANs, which combines with cover synthesis. Based on GAN, the scheme uses secret information as the driver and directly generates encrypted images for transmission, which can effectively resist the detection of steganalysis algorithms. The security of the scheme is based on the key of the encryption algorithm. Even if the attacker obtains the transmitted information, only the meaningless result will be obtained without the key. Experiments were carried out on the data set of CelebA, and the results verified the feasibility and security of the scheme. © Springer Nature Singapore Pte Ltd 2020.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-981-15-3418-8_1},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081627139&doi=10.1007%2f978-981-15-3418-8_1&partnerID=40&md5=b1f81c7673525a97b72a7ff7c8f0ab99},
}

@Article{Martins202035403,
  author        = {Martins, N. and Cruz, J.M. and Cruz, T. and Henriques Abreu, P.},
  journal       = {IEEE Access},
  title         = {Adversarial Machine Learning Applied to Intrusion and Malware Scenarios: A Systematic Review},
  year          = {2020},
  note          = {cited By 15},
  pages         = {35403-35419},
  volume        = {8},
  abstract      = {Cyber-security is the practice of protecting computing systems and networks from digital attacks, which are a rising concern in the Information Age. With the growing pace at which new attacks are developed, conventional signature based attack detection methods are often not enough, and machine learning poses as a potential solution. Adversarial machine learning is a research area that examines both the generation and detection of adversarial examples, which are inputs specially crafted to deceive classifiers, and has been extensively studied specifically in the area of image recognition, where minor modifications are performed on images that cause a classifier to produce incorrect predictions. However, in other fields, such as intrusion and malware detection, the exploration of such methods is still growing. The aim of this survey is to explore works that apply adversarial machine learning concepts to intrusion and malware detection scenarios. We concluded that a wide variety of attacks were tested and proven effective in malware and intrusion detection, although their practicality was not tested in intrusion scenarios. Adversarial defenses were substantially less explored, although their effectiveness was also proven at resisting adversarial attacks. We also concluded that, contrarily to malware scenarios, the variety of datasets in intrusion scenarios is still very small, with the most used dataset being greatly outdated. © 2013 IEEE.},
  art_number    = {9001114},
  document_type = {Review},
  doi           = {10.1109/ACCESS.2020.2974752},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081577747&doi=10.1109%2fACCESS.2020.2974752&partnerID=40&md5=90886aefecd44d5d0fc1ee206166252d},
}

@Article{Ohira202042422,
  author        = {Ohira, S. and Desta, A.K. and Arai, I. and Inoue, H. and Fujikawa, K.},
  journal       = {IEEE Access},
  title         = {Normal and Malicious Sliding Windows Similarity Analysis Method for Fast and Accurate IDS against DoS Attacks on In-Vehicle Networks},
  year          = {2020},
  note          = {cited By 2},
  pages         = {42422-42435},
  volume        = {8},
  abstract      = {Controller Area Network (CAN) is a de facto standard of in-vehicle networks. Since CAN employs broadcast communication and a slower network than other general networks (e.g. Ethernet, IEEE802.11), it is inherently vulnerable to Denial-of-Service (DoS) attacks. As a countermeasure against DoS attacks on CAN, a method for detecting a DoS attack using the entropy in a sliding window has been proposed. This method has a good advantage in terms of effectiveness and the small computational overhead. However, this method may only be effective against DoS attacks under naive conditions such as some higher priority messages. In addition, if an adversary can adjust the entropy of the DoS attack to its normal value, the conventional method cannot detect a DoS attack in which the adversary manipulates the entropy. We found this type of DoS attack, which is called an entropy-manipulated attack. In this paper, we propose a method that can detect an entropy-manipulated attack by using the similarity of two sliding windows. We confirmed that the proposed method detected the DoS attack in 100% of the cases in our experiment, and we showed that the detection time is up to 93% ($14~\mu\text{s}$) shorter than the conventional method. © 2013 IEEE.},
  art_number    = {9007444},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2020.2975893},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081559479&doi=10.1109%2fACCESS.2020.2975893&partnerID=40&md5=cae67dc37b01b98fd986d84bf7cd3732},
}

@Article{Cohen202019997,
  author        = {Cohen, A. and Nissim, N. and Elovici, Y.},
  journal       = {IEEE Access},
  title         = {MalJPEG: Machine Learning Based Solution for the Detection of Malicious JPEG Images},
  year          = {2020},
  note          = {cited By 3},
  pages         = {19997-20011},
  volume        = {8},
  abstract      = {In recent years, cyber-attacks against individuals, businesses, and organizations have increased. Cyber criminals are always looking for effective vectors to deliver malware to victims in order to launch an attack. Images are used on a daily basis by millions of people around the world, and most users consider images to be safe for use; however, some types of images can contain a malicious payload and perform harmful actions. JPEG is the most popular image format, primarily due to its lossy compression. It is used by almost everyone, from individuals to large organizations, and can be found on almost every device (on digital cameras and smartphones, websites, social media, etc.). Because of their harmless reputation, massive use, and high potential for misuse, JPEG images are used by cyber criminals as an attack vector. While machine learning methods have been shown to be effective at detecting known and unknown malware in various domains, to the best of our knowledge, machine learning methods have not been used particularly for the detection of malicious JPEG images. In this paper, we present MalJPEG, the first machine learning-based solution tailored specifically at the efficient detection of unknown malicious JPEG images. MalJPEG statically extracts 10 simple yet discriminative features from the JPEG file structure and leverages them with a machine learning classifier, in order to discriminate between benign and malicious JPEG images. We evaluated MalJPEG extensively on a real-world representative collection of 156,818 images which contains 155,013 (98.85%) benign and 1,805 (1.15%) malicious images. The results show that MalJPEG, when used with the LightGBM classifier, demonstrates the highest detection capabilities, with an area under the receiver operating characteristic curve (AUC) of 0.997, true positive rate (TPR) of 0.951, and a very low false positive rate (FPR) of 0.004. © 2020 IEEE.},
  art_number    = {8967109},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2020.2969022},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081110037&doi=10.1109%2fACCESS.2020.2969022&partnerID=40&md5=bea38f0d32136666ebc3764dc0462ec5},
}

@Article{Indira2020551,
  author        = {Indira, K. and Sakthi, U.},
  journal       = {International Journal of Emerging Trends in Engineering Research},
  title         = {A comparative analysis on intrusion detection system for SDWSN using ensemble classifier},
  year          = {2020},
  note          = {cited By 4},
  number        = {2},
  pages         = {551-556},
  volume        = {8},
  abstract      = {Security in Software Defined Wireless Sensor Network (SDWSN) is current and important area of interest amongst researchers because WSN is easily prone to vulnerabilities due to open transmission medium. Software-defined networking was described as a solution for many WSN problems relating to efficiency and reuse of resources. The SDN architecture, on the other hand, is exposed to new security threats such as false flow request attacks, false data flow forwarding attacks and false neighbor information attacks etc. These new security threats cause dramatic changes in performance metrics such as data and control packet delivery ratio, delay, throughput, energy consumption and controlpacket overhea, etc. Very es sential is the development of an efficient intrusion detection and prevention system to protect the network from security threats and improve network performance. In this paper, we proposed an intrusion detection system using ensemble classification to mitigate attacks and we analyzed different ensemble classification approaches and their performance. © 2020, World Academy of Research in Science and Engineering. All rights reserved.},
  art_number    = {45},
  document_type = {Article},
  doi           = {10.30534/ijeter/2020/45822020},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080135556&doi=10.30534%2fijeter%2f2020%2f45822020&partnerID=40&md5=80ccff6d8730686943c4fbe7c813e0c1},
}

@Article{Zhijun202017404,
  author        = {Zhijun, W. and Qing, X. and Jingjie, W. and Meng, Y. and Liang, L.},
  journal       = {IEEE Access},
  title         = {Low-Rate DDoS Attack Detection Based on Factorization Machine in Software Defined Network},
  year          = {2020},
  note          = {cited By 8},
  pages         = {17404-17418},
  volume        = {8},
  abstract      = {As the Software Define Network (SDN) adopts centralized control logic, it is vulnerable to various types of Distributed Denial of Service (DDoS) attacks. At present, almost all the research work focuses on high-rate DDoS attack against the SDN control layer. Moreover, most of the existing detection methods are effective for high-rate DDoS attack detection of the control layer, while a low-rate DDoS attack against the SDN data layer is highly concealed, and the detection accuracy against this kind of attack is low. In order to improve the detection accuracy of the low-rate DDoS attack against the SDN data layer, this paper studies the mechanism of such attacks, and then proposes a multi-feature DDoS attack detection method based on Factorization Machine (FM). The features extracted from the flow rules are used to detect low-rate DDoS attacks, and the detection of low-rate DDoS attacks based on FM machine learning algorithms is implemented. The experimental results show that the method can effectively detect the low-rate DDoS attack against the SDN data layer, and the detection accuracy reaches 95.80 percent. Because FM algorithm can achieve fine-grained detection for low-rate DDoS attack, which provides a reliable condition for defending against such attacks. Finally, this paper proposes a defense method based on dynamic deletion of flow rules, and carries out experimental simulation and analysis to prove the effectiveness of the defense method, and the success rate of forwarding normal packets reached 97.85 percent. © 2013 IEEE.},
  art_number    = {8962081},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2020.2967478},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079788532&doi=10.1109%2fACCESS.2020.2967478&partnerID=40&md5=b88cffb6f482302cb5bd22e892f3190c},
}

@Article{Chaithanya2020921,
  author        = {Chaithanya, P.S. and Priyanga, S. and Pravinraj, S. and Shankar Sriram, V.S.},
  journal       = {Lecture Notes in Networks and Systems},
  title         = {SSO-IF: An outlier detection approach for intrusion detection in SCADA systems},
  year          = {2020},
  note          = {cited By 1},
  pages         = {921-929},
  volume        = {89},
  abstract      = {Supervisory Control and Data Acquisition (SCADA) systems play a prominent role in monitoring and controlling the Critical Infrastructures (CIs) such as water distribution, nuclear plants, and chemical industries. On the other hand, SCADA systems are highly exposed to new vulnerabilities as it highly relies on the internet. Machine learning approaches have been employed to detect the cyberattacks injected by the attackers in CIs. However, those approaches failed to protect the CIs against the ever-advancing nature of cyberattacks. This work presents Salp Swarm Optimization-based Isolation Forest (SSO-IF) to build an efficient SCADA intrusion detection system, and the experiments were carried out using power system dataset from Mississippi State University. The performance of SSO-IF was validated over the state-of-the-art intrusion detection techniques in terms of classification accuracy and detection rate. © Springer Nature Singapore Pte Ltd. 2020.},
  document_type = {Book Chapter},
  doi           = {10.1007/978-981-15-0146-3_89},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079272412&doi=10.1007%2f978-981-15-0146-3_89&partnerID=40&md5=4f38e7695e92399be859e861a8b00912},
}

@Conference{Jahromi202014,
  author        = {Jahromi, A.N. and Karimpour, H. and Sakhnini, J. and Dehghantanha, A.},
  title         = {A deep unsupervised representation learning approach for effective cyber-physical attack detection and identification on highly imbalanced data},
  year          = {2020},
  note          = {cited By 3},
  pages         = {14-23},
  abstract      = {Cyber-Physical Systems (CPS) integrate physical devices with embedded computers and networks for control and monitoring of the physical process. Smart grid is one the most important types of critical CPS which consist of smart meters for data collection coupled with an interconnection of networks of generation and distribution centers aimed to distribute power over large geographical areas. While this intricate communication system has tremendous advantages, by improving energy efficiency and reliability, it significantly increases the system's vulnerabilities to cyber-attacks due to the tremendous number of devices and access points. While the majority of the current solutions rely on raw measurements or human-crafted features for attack detection, this paper proposes a deep unsupervised representation learning technique that learns the new representation automatically from the measurements. An unsupervised stacked autoencoder model is used as a feature (representation) learner that converts the raw features to a low-dimensional new representation. Besides, six classification algorithms, three single and three ensembles, including, multi-layer neural network, decision tree, k-nearest neighbor, random forest, gradient boosting, and Adaboost are analyzed to verify the efficiency of the proposed method. The results show a significant improvement on accuracy, precision, recall, and f-measure in all algorithms using the proposed feature learning technique, especially on the weak algorithms on imbalanced data. © 2019 Copyright held by the owner/author(s).},
  document_type = {Conference Paper},
  groups        = {First Filtering},
  journal       = {CASCON 2019 Proceedings - Conference of the Centre for Advanced Studies on Collaborative Research - Proceedings of the 29th Annual International Conference on Computer Science and Software Engineering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078971801&partnerID=40&md5=fc8771036bf921508f78a6363927df36},
}

@Article{Zhang2020,
  author        = {Zhang, J. and Gao, C. and Gong, L. and Gu, Z. and Man, D. and Yang, W. and Li, W.},
  journal       = {Mobile Networks and Applications},
  title         = {Malware Detection Based on Multi-level and Dynamic Multi-feature Using Ensemble Learning at Hypervisor},
  year          = {2020},
  note          = {cited By 2},
  abstract      = {As more and more applications migrate to clouds, the type and amount of malware attack against virtualized environments are increasing, which is a key factor that restricts the widespread deployment and application of cloud platforms. Traditional in-VM-based security software is not effective against malware attacks, as the security software itself becomes the target of malware attacks and can easily be tampered with or even subverted. In this paper, we propose a new malware detection method to improve virtual machine security performance and ensure the security of the entire cloud platform. This paper uses the virtual machine introspection(VMI) combined with the memory forensics analysis(MFA) technology to extract multiple types of dynamic features from the virtual machine memory, the hypervisor layer and the hardware layer. Furthermore, this paper proposes an adaptive feature selection method. By combining three different search strategies, three types of features are compared and analyzed from three aspects: effectiveness, system load and security. By adjusting the weight of each feature, it meets the detection requirements of different malware in the cloud environment as expected. Finally, the detection method improves the detection accuracy and generalization ability of the overall classifier using the AdaBoost ensemble learning method with Voting’s combination strategy. The experiment used a large number of real malicious samples, and achieved an accuracy of 0.999 (AUC), with a maximum performance overhead of 5.6%. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.},
  document_type = {Article},
  doi           = {10.1007/s11036-019-01503-4},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077546372&doi=10.1007%2fs11036-019-01503-4&partnerID=40&md5=871e98d866ab85169d9bfcfcddb6b025},
}

@Article{Zhan2020,
  author        = {Zhan, S. and Tang, D. and Man, J. and Dai, R. and Wang, X.},
  journal       = {Sensors (Switzerland)},
  title         = {Low-rate DoS attacks detection based on MAF-ADM},
  year          = {2020},
  note          = {cited By 3},
  number        = {1},
  volume        = {20},
  abstract      = {Low-rate denial of service (LDoS) attacks reduce the quality of network service by sending periodical packet bursts to the bottleneck routers. It is difficult to detect by counter-DoS mechanisms due to its stealthy and low average attack traffic behavior. In this paper, we propose an anomaly detection method based on adaptive fusion of multiple features (MAF-ADM) for LDoS attacks. This study is based on the fact that the time-frequency joint distribution of the legitimate transmission control protocol (TCP) traffic would be changed under LDoS attacks. Several statistical metrics of the time-frequency joint distribution are chosen to generate isolation trees, which can simultaneously reflect the anomalies in time domain and frequency domain. Then we calculate anomaly score by fusing the results of all isolation trees according to their ability to isolate samples containing LDoS attacks. Finally, the anomaly score is smoothed by weighted moving average algorithm to avoid errors caused by noise in the network. Experimental results of Network Simulator 2 (NS2), testbed, and public datasets (WIDE2018 and LBNL) demonstrate that this method does detect LDoS attacks effectively with lower false negative rate. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.},
  art_number    = {189},
  document_type = {Article},
  doi           = {10.3390/s20010189},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077357755&doi=10.3390%2fs20010189&partnerID=40&md5=6803c1640d28c3952c4484af194275dd},
}

@Conference{Araujo2019245,
  author        = {Araujo, F. and Ayoade, G. and Al-Naami, K. and Gao, Y. and Hamlen, K.W. and Khan, L.},
  title         = {Improving Intrusion Detectors by Crook-sourcing},
  year          = {2019},
  note          = {cited By 6},
  pages         = {245-256},
  abstract      = {Conventional cyber defenses typically respond to detected attacks by rejecting them as quickly and decisively as possible; but aborted attacks are missed learning opportunities for intrusion detection. A method of reimagining cyber attacks as free sources of live training data for machine learning-based intrusion detection systems (IDSes) is proposed and evaluated. Rather than aborting attacks against legitimate services, adversarial interactions are selectively prolonged to maximize the defender’s harvest of useful threat intelligence. Enhancing web services with deceptive attack-responses in this way is shown to be a powerful and practical strategy for improved detection, addressing several perennial challenges for machine learning-based IDS in the literature, including scarcity of training data, the high labeling burden for (semi-)supervised learning, encryption opacity, and concept differences between honeypot attacks and those against genuine services. By reconceptualizing software security patches as feature extraction engines, the approach conscripts attackers as free penetration testers, and coordinates multiple levels of the software stack to achieve fast, automatic, and accurate labeling of live web data streams. Prototype implementations are showcased for two feature set models to extract security-relevant network- and system-level features from servers hosting enterprise-grade web applications. The evaluation demonstrates that the extracted data can be fed back into a network-level IDS for exceptionally accurate, yet lightweight attack detection. © 2019 Association for Computing Machinery.},
  document_type = {Conference Paper},
  doi           = {10.1145/3359789.3359822},
  groups        = {First Filtering},
  journal       = {ACM International Conference Proceeding Series},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077820211&doi=10.1145%2f3359789.3359822&partnerID=40&md5=a38d1a040ba667d757a0835d4f9bfbd0},
}

@Conference{Truong2019267,
  author        = {Truong, D. and Tran, D. and Nguyen, L. and Mac, H. and Tran, H.A. and Bui, T.},
  title         = {Detecting web attacks using stacked denoising autoencoder and ensemble learning methods},
  year          = {2019},
  note          = {cited By 2},
  pages         = {267-272},
  abstract      = {Web-based anomalies remains a serious security threat on the Internet. This paper proposes the use of Sum Rule and Xgboost to combine the outputs related to various Stacked Denoising Autoencoders (SDAEs) in order to detect abnormal HTTP queries. Sum Rule and Xgboost inherit the distinct advantage of SDAE that does not require handcrafted features to be extracted. Furthermore, these methods can cope with the changing web vulnerabilities, where malicious code is added into different parts of the request header and body. Experiments were carried out on the DVWA dataset and the dataset that obtained from a real-world application. Sum Rule and Xgboost demonstrate to achieve higher F1-score as compared to the state-of-the-art Regularized Deep Autoencoders, Isolation Forest, C4.5 decision tree and Long Short-term Memory network. © 2019 Association for Computing Machinery.},
  document_type = {Conference Paper},
  doi           = {10.1145/3368926.3369715},
  groups        = {First Filtering},
  journal       = {ACM International Conference Proceeding Series},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077814959&doi=10.1145%2f3368926.3369715&partnerID=40&md5=d2212e241894069d629d35017ab62545},
}

@Conference{Park20191283,
  author        = {Park, D. and Khan, H. and Yener, B.},
  title         = {Generation & evaluation of adversarial examples for malware obfuscation},
  year          = {2019},
  note          = {cited By 4},
  pages         = {1283-1290},
  abstract      = {There has been an increased interest in the application of convolutional neural networks for image based malware classification, but the susceptibility of neural networks to adversarial examples allows malicious actors to evade classifiers. Adversarial examples are usually generated by adding small perturbations to the input that are unrecognizable to humans, but the same approach is not effective with malware. In general, these perturbations cause changes in the byte sequences that change the initial functionality or result in un-executable binaries. We present a generative model for executable adversarial malware examples using obfuscation that achieves a high misclassification rate, up to 100% and 98% in white-box and black-box settings respectively, and demonstrates transferability. We further evaluate the effectiveness of the proposed method by reporting insignificant change in the evasion rate of our adversarial examples against popular defense strategies. © 2019 IEEE.},
  art_number    = {8999277},
  document_type = {Conference Paper},
  doi           = {10.1109/ICMLA.2019.00210},
  groups        = {First Filtering},
  journal       = {Proceedings - 18th IEEE International Conference on Machine Learning and Applications, ICMLA 2019},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080936401&doi=10.1109%2fICMLA.2019.00210&partnerID=40&md5=96b9269c3d7dc3948f899f73d636a5ca},
}

@Conference{Ge2019256,
  author        = {Ge, M. and Fu, X. and Syed, N. and Baig, Z. and Teo, G. and Robles-Kelly, A.},
  title         = {Deep learning-based intrusion detection for IoT networks},
  year          = {2019},
  note          = {cited By 22},
  pages         = {256-265},
  volume        = {2019-December},
  abstract      = {Internet of Things (IoT) has an immense potential for a plethora of applications ranging from healthcare automation to defence networks and the power grid. The security of an IoT network is essentially paramount to the security of the underlying computing and communication infrastructure. However, due to constrained resources and limited computational capabilities, IoT networks are prone to various attacks. Thus, safeguarding the IoT network from adversarial attacks is of vital importance and can be realised through planning and deployment of effective security controls; one such control being an intrusion detection system. In this paper, we present a novel intrusion detection scheme for IoT networks that classifies traffic flow through the application of deep learning concepts. We adopt a newly published IoT dataset and generate generic features from the field information in packet level. We develop a feed-forward neural networks model for binary and multi-class classification including denial of service, distributed denial of service, reconnaissance and information theft attacks against IoT devices. Results obtained through the evaluation of the proposed scheme via the processed dataset illustrate a high classification accuracy. © 2019 IEEE.},
  art_number    = {8952154},
  document_type = {Conference Paper},
  doi           = {10.1109/PRDC47002.2019.00056},
  groups        = {First Filtering},
  journal       = {Proceedings of IEEE Pacific Rim International Symposium on Dependable Computing, PRDC},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078471542&doi=10.1109%2fPRDC47002.2019.00056&partnerID=40&md5=4e6e55ecf2a414567e116be63bf750c7},
}

@Conference{Hwang2019,
  author        = {Hwang, R.-H. and Peng, M.-C. and Huang, C.-W.},
  title         = {Detecting IoT malicious traffic based on autoencoder and convolutional neural network},
  year          = {2019},
  note          = {cited By 1},
  abstract      = {Due to the rise of the Internet of Things, a variety of devices have been made intelligent and connected to the Internet. However, the huge number of constantly connected but usually unattended IoT devices have made them one of the major sources of Interent attacks, e.g., a large-scale DDoS attack launching by millions of Mirai-injected compromised IoT devices in 2016. In order to mitigate DDoS attacks against IoT botnets, in this work, we proposed an effective malicious IoT traffic detection mechanism based on deep learning techniques. Specifically, we adopt convolutional neural network (CNN) to extract features of flows, then apply autoencoder to perform unsupervised malicious IoT traffic classification. Our goal is to be able to detect a malicious flow by examining as few of its packets as possible. To validate our proposed mechanism, we evaluate our model using both open data set from previous literature as well as the data set collected from a Mirai botnet we have built. Our experimental results show that the proposed mechanism is effective to detect malicious flows with near 100% accuracy, while only examining the first 2 packets of a flow. © 2019 IEEE.},
  art_number    = {9024425},
  document_type = {Conference Paper},
  doi           = {10.1109/GCWkshps45667.2019.9024425},
  groups        = {First Filtering},
  journal       = {2019 IEEE Globecom Workshops, GC Wkshps 2019 - Proceedings},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071030650&doi=10.1109%2fGCWkshps45667.2019.9024425&partnerID=40&md5=5612142b8bd0db2448c6ca3f9398c931},
}

@Article{Martín2019128,
  author        = {Martín, A. and Lara-Cabrera, R. and Camacho, D.},
  journal       = {Information Fusion},
  title         = {Android malware detection through hybrid features fusion and ensemble classifiers: The AndroPyTool framework and the OmniDroid dataset},
  year          = {2019},
  note          = {cited By 30},
  pages         = {128-142},
  volume        = {52},
  abstract      = {Cybersecurity has become a major concern for society, mainly motivated by the increasing number of cyber attacks and the wide range of targeted objectives. Due to the popularity of smartphones and tablets, Android devices are considered an entry point in many attack vectors. Malware applications are among the most used tactics and tools to perpetrate a cyber attack, so it is critical to study new ways of detecting them. In these detection mechanisms, machine learning has been used to build classifiers that are effective in discerning if an application is malware or benignware. However, training such classifiers require big amounts of labelled data which, in this context, consist of categorised malware and benignware Android applications represented by a set of features able to describe their behaviour. For that purpose, in this paper we present OmniDroid, a large and comprehensive dataset of features extracted from 22,000 real malware and goodware samples, aiming to help anti-malware tools creators and researchers when improving, or developing, new mechanisms and tools for Android malware detection. Furthermore, the characteristics of the dataset make it suitable to be used as a benchmark dataset to test classification and clustering algorithms or new representation techniques, among others. The dataset has been released under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License and was built using AndroPyTool, our automated framework for dynamic and static analysis of Android applications. Finally, we test a set of ensemble classifiers over this dataset and propose a malware detection approach based on the fusion of static and dynamic features through the combination of ensemble classifiers. The experimental results show the feasibility and potential usability (for the machine learning, soft computing and cyber security communities) of our automated framework and the publicly available dataset. © 2018 Elsevier B.V.},
  document_type = {Article},
  doi           = {10.1016/j.inffus.2018.12.006},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060977441&doi=10.1016%2fj.inffus.2018.12.006&partnerID=40&md5=f7dd9e5f8fc3bd87ec366fcb830f682d},
}

@Conference{Jordan201919,
  author        = {Jordan, A. and Gauthier, F. and Hassanshahi, B. and Zhao, D.},
  title         = {Unacceptable behavior: Robust PDF malware detection using abstract interpretation},
  year          = {2019},
  note          = {cited By 1},
  pages         = {19-30},
  abstract      = {The popularity of the PDF format and the rich JavaScript environment that PDF viewers offer make PDF documents an attractive attack vector for malware developers. PDF documents present a serious threat to the security of organizations because most users are unsuspecting of them and thus likely to open documents from untrusted sources. State-of-the-art approaches use machine learning to learn features that characterize PDF malware, which makes them subject to adversarial attacks that mimic the structure of benign documents. In this paper, we instead propose to detect malicious code inside a PDF by statically reasoning about its possible behavior using abstract interpretation. A comparison with state-of-the-art PDF malware detection tools shows that our conservative abstract interpretation approach achieves similar accuracy, is more resilient to evasion attacks, and provides interpretable reports. © 2019 Association for Computing Machinery.},
  document_type = {Conference Paper},
  doi           = {10.1145/3338504.3357341},
  groups        = {First Filtering},
  journal       = {Proceedings of the ACM Conference on Computer and Communications Security},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075892620&doi=10.1145%2f3338504.3357341&partnerID=40&md5=afe0d823a28095cfe18d0aeda39cf454},
}

@Conference{Pan201979,
  author        = {Pan, J.},
  title         = {Physical integrity attack detection of surveillance camera with deep learning based video frame interpolation},
  year          = {2019},
  note          = {cited By 3},
  pages         = {79-85},
  abstract      = {Surveillance cameras, which is a form of Cyber Physical System, are deployed extensively to provide visual surveillance monitoring of activities of interest or anomalies. However, these cameras are at risks of physical security attacks against their physical attributes or configuration like tampering of their recording coverage, camera positions or recording configurations like focus and zoom factors. Such adversarial alteration of physical configuration could also be invoked through cyber security attacks against the camera's software vulnerabilities to administratively change the camera's physical configuration settings. When such Cyber Physical attacks occur, they affect the integrity of the targeted cameras that would in turn render these cameras ineffective in fulfilling the intended security functions. There is a significant measure of research work in detection mechanisms of cyber-attacks against these Cyber Physical devices, however it is understudied area with such mechanisms against integrity attacks on physical configuration. This research proposes the use of the novel use of deep learning algorithms to detect such physical attacks originating from cyber or physical spaces. Additionally, we proposed the novel use of deep learning-based video frame interpolation for such detection that has comparatively better performance to other anomaly detectors in spatiotemporal environments. © 2019 IEEE.},
  art_number    = {8980385},
  document_type = {Conference Paper},
  doi           = {10.1109/IoTaIS47347.2019.8980385},
  groups        = {First Filtering},
  journal       = {Proceedings - 2019 IEEE International Conference on Internet of Things and Intelligence System, IoTaIS 2019},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081103114&doi=10.1109%2fIoTaIS47347.2019.8980385&partnerID=40&md5=6e7dcfce884450e7dbf29de2972b7e6d},
}

@Article{Zhang20192277,
  author        = {Zhang, W.-A. and Hong, Z. and Zhu, J.-W. and Chen, B.},
  journal       = {Kongzhi yu Juece/Control and Decision},
  title         = {A survey of network intrusion detection methods for industrial control systems [工业控制系统网络入侵检测方法综述]},
  year          = {2019},
  note          = {cited By 1},
  number        = {11},
  pages         = {2277-2288},
  volume        = {34},
  abstract      = {With the networking of industrial control systems (ICS), its original closeness has been broken. Various viruses and Trojans have entered ICS with normal information flow, which has seriously threatened the security of ICS. Then, how to protect ICS security becomes an issue of prior importance. Intrusion detection, as an active information security protection technology, can effectively remedy the shortcomings of traditional security protection technologies such as firewalls. It is often considered as the second security line of ICS, and can realize real-time detection of external and internal intrusions of ICS. At present, the research of intrusion detection in industrial control systems is very active. Researchers from different fields, such as computer, automation and communication, have proposed a series of ICS intrusion detection methods from different perspectives, which has become a hot research direction in the field of ICS security. This paper briefly reviews the state-of-art of the ICS intrusion detection, the existing problems and the problems to be further solved. © 2019, Editorial Office of Control and Decision. All right reserved.},
  document_type = {Review},
  doi           = {10.13195/j.kzyjc.2019.1302},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077431559&doi=10.13195%2fj.kzyjc.2019.1302&partnerID=40&md5=5926b5a9e6c13163e14e7a1aeacfd844},
}

@Article{Pitropakis2019,
  author        = {Pitropakis, N. and Panaousis, E. and Giannetsos, T. and Anastasiadis, E. and Loukas, G.},
  journal       = {Computer Science Review},
  title         = {A taxonomy and survey of attacks against machine learning},
  year          = {2019},
  note          = {cited By 27},
  volume        = {34},
  abstract      = {The majority of machine learning methodologies operate with the assumption that their environment is benign. However, this assumption does not always hold, as it is often advantageous to adversaries to maliciously modify the training (poisoning attacks) or test data (evasion attacks). Such attacks can be catastrophic given the growth and the penetration of machine learning applications in society. Therefore, there is a need to secure machine learning enabling the safe adoption of it in adversarial cases, such as spam filtering, malware detection, and biometric recognition. This paper presents a taxonomy and survey of attacks against systems that use machine learning. It organizes the body of knowledge in adversarial machine learning so as to identify the aspects where researchers from different fields can contribute to. The taxonomy identifies attacks which share key characteristics and as such can potentially be addressed by the same defence approaches. Thus, the proposed taxonomy makes it easier to understand the existing attack landscape towards developing defence mechanisms, which are not investigated in this survey. The taxonomy is also leveraged to identify open problems that can lead to new research areas within the field of adversarial machine learning. © 2019 Elsevier Inc.},
  art_number    = {100199},
  document_type = {Review},
  doi           = {10.1016/j.cosrev.2019.100199},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075752333&doi=10.1016%2fj.cosrev.2019.100199&partnerID=40&md5=eace3b9f6e072c2b85512982cbd9a82d},
}

@Article{Kang2019,
  author        = {Kang, A.R. and Jeong, Y.-S. and Kim, S.L. and Woo, J.},
  journal       = {Applied Sciences (Switzerland)},
  title         = {Malicious PDF detection model against adversarial attack built from benign PDF containing javascript},
  year          = {2019},
  note          = {cited By 2},
  number        = {22},
  volume        = {9},
  abstract      = {Intelligent attacks using document-based malware that exploit vulnerabilities in document viewing software programs or document file structure are increasing rapidly. There are many cases of using PDF (portable document format) in proportion to its usage. We provide in-depth analysis on PDF structure and JavaScript content embedded in PDFs. Then, we develop the diverse feature set encompassing the structure and metadata such as file size, version, encoding method and keywords, and the content features such as object names, keywords, and readable strings in JavaScript. When features are diverse, it is hard to develop adversarial examples because small changes are robust for machine-learning algorithms. We develop a detection model using black-box type models with the structure and content features to minimize the risk of adversarial attacks. To validate the proposed model, we design the adversarial attack. We collect benign documents containing multiple JavaScript codes for the base of adversarial samples. We build the adversarial samples by injecting the malware codes into base samples. The proposed model is evaluated against a large collection of malicious and benign PDFs. We found that random forest, an ensemble algorithm of a decision tree, exhibits a good performance on malware detection and is robust for adversarial samples. © 2019 by the authors.},
  art_number    = {4764},
  document_type = {Article},
  doi           = {10.3390/app9224764},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075250648&doi=10.3390%2fapp9224764&partnerID=40&md5=8fb905fabf2f1306b9143e997b7e4aa9},
}

@Conference{Boumiza2019,
  author        = {Boumiza, S. and Braham, R.},
  title         = {An Anomaly Detector for CAN Bus Networks in Autonomous Cars based on Neural Networks},
  year          = {2019},
  note          = {cited By 0},
  volume        = {2019-October},
  abstract      = {The domain of securing in-vehicle networks has attracted both academic and industrial researchers due to high danger of attacks on drivers and passengers. While securing wired and wireless interfaces is important to defend against these threats, detecting attacks is still the critical phase to construct a robust secure system. There are only a few results on securing communication inside vehicles using anomaly-detection techniques despite their efficiencies in systems that need real-Time detection. Therefore, we propose an intrusion detection system (IDS) based on Multi-Layer Perceptron (MLP) neural network for Controller Area Networks (CAN) bus. This IDS divides data according to the ID field of CAN packets using K-means clustering algorithm, then it extracts suitable features and uses them to train and construct the neural network. The proposed IDS works for each ID separately and finally it combines their individual decisions to construct the final score and generates alert in the presence of attack. The strength of our intrusion detection method is that it works simultaneously for two types of attacks which will eliminate the use of several separate IDS and thus reduce the complexity and cost of implementation. © 2019 IEEE.},
  art_number    = {8923315},
  document_type = {Conference Paper},
  doi           = {10.1109/WiMOB.2019.8923315},
  groups        = {First Filtering},
  journal       = {International Conference on Wireless and Mobile Computing, Networking and Communications},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077629205&doi=10.1109%2fWiMOB.2019.8923315&partnerID=40&md5=44e4178b11153b0bbb231e533db2366b},
}

@Article{Tidjon20193639,
  author        = {Tidjon, L.N. and Frappier, M. and Mammar, A.},
  journal       = {IEEE Communications Surveys and Tutorials},
  title         = {Intrusion Detection Systems: A Cross-Domain Overview},
  year          = {2019},
  note          = {cited By 17},
  number        = {4},
  pages         = {3639-3681},
  volume        = {21},
  abstract      = {Nowadays, network technologies are essential for transferring and storing various information of users, companies, and industries. However, the growth of the information transfer rate expands the attack surface, offering a rich environment to intruders. Intrusion detection systems (IDSs) are widespread systems able to passively or actively control intrusive activities in a defined host and network perimeter. Recently, different IDSs have been proposed by integrating various detection techniques, generic or adapted to a specific domain and to the nature of attacks operating on. The cybersecurity landscape deals with tremendous diverse event streams that exponentially increase the attack vectors. Event stream processing (ESP) methods appear to be solutions that leverage event streams to provide actionable insights and faster detection. In this paper, we briefly describe domains (as well as their vulnerabilities) on which recent papers were-based. We also survey standards for vulnerability assessment and attack classification. Afterwards, we carry out a classification of IDSs, evaluation metrics, and datasets. Next, we provide the technical details and an evaluation of the most recent work on IDS techniques and ESP approaches covering different dimensions (axes): domains, architectures, and local communication technologies. Finally, we discuss challenges and strategies to improve IDS in terms of accuracy, performance, and robustness. © 1998-2012 IEEE.},
  art_number    = {8735821},
  document_type = {Article},
  doi           = {10.1109/COMST.2019.2922584},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076363341&doi=10.1109%2fCOMST.2019.2922584&partnerID=40&md5=6251cbd260d100a8577668e991c057b5},
}

@Article{Ahmed20192765,
  author        = {Ahmed, S. and Lee, Y. and Hyun, S.-H. and Koo, I.},
  journal       = {IEEE Transactions on Information Forensics and Security},
  title         = {Unsupervised Machine Learning-Based Detection of Covert Data Integrity Assault in Smart Grid Networks Utilizing Isolation Forest},
  year          = {2019},
  note          = {cited By 39},
  number        = {10},
  pages         = {2765-2777},
  volume        = {14},
  abstract      = {Being one of the most multifaceted cyber-physical systems, smart grids (SGs) are arguably more prone to cyber-threats. A covert data integrity assault (CDIA) on a communications network may be lethal to the reliability and safety of SG operations. They are intelligently designed to sidestep the traditional bad data detector in power control centers, and this type of assault can compromise the integrity of the data, causing a false estimation of the state that further severely distresses the entire power system operation. In this paper, we propose an unsupervised machine learning-based scheme to detect CDIAs in SG communications networks utilizing non-labeled data. The proposed scheme employs a state-of-the-art algorithm, called isolation forest, and detects CDIAs based on the hypothesis that the assault has the shortest average path length in a constructed random forest. To tackle the dimensionality issue from the growth in power systems, we use a principal component analysis-based feature extraction technique. The evaluation of the proposed scheme is carried out through standard IEEE 14-bus, 39-bus, 57-bus, and 118-bus systems. The simulation results show that the proposed scheme is proficient at handling non-labeled historical measurement datasets and results in a significant improvement in attack detection accuracy. © 2005-2012 IEEE.},
  art_number    = {8660426},
  document_type = {Article},
  doi           = {10.1109/TIFS.2019.2902822},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067664188&doi=10.1109%2fTIFS.2019.2902822&partnerID=40&md5=884068e6700900ec903a8e5a5344fad3},
}

@Article{Zuzčák20194706,
  author        = {Zuzčák, M. and Sochor, T. and Zenka, M.},
  journal       = {KSII Transactions on Internet and Information Systems},
  title         = {Intrusion Detection System for Home Windows based Computers},
  year          = {2019},
  note          = {cited By 1},
  number        = {9},
  pages         = {4706-4726},
  volume        = {13},
  abstract      = {The paper is devoted to the detailed description of the distributed system for gathering data from Windows-based workstations and servers. The research presented in the beginning demonstrates that neither a solution for gathering data on attacks against Windows based PCs is available at present nor other security tools and supplementary programs can be combined in order to achieve the required attack data gathering from Windows computers. The design of the newly proposed system named Colander is presented, too. It is based on a client-server architecture while taking much inspiration from previous attempts for designing systems with similar purpose, as well as from IDS systems like Snort. Colander emphasizes its ease of use and minimum demand for system resources. Although the resource usage is usually low, it still requires further optimization, as is noted in the performance testing. Colander’s ability to detect threats has been tested by real malware, and it has undergone a pilot field application. Future prospects and development are also proposed. Copyright © 2019 KSII},
  document_type = {Article},
  doi           = {10.3837/tiis.2019.09.021},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076116112&doi=10.3837%2ftiis.2019.09.021&partnerID=40&md5=e4c1777b26f257fa6850cc0788482be2},
}

@Conference{Kuppa2019,
  author        = {Kuppa, A. and Grzonkowski, S. and Asghar, M.R. and Le-Khac, N.-A.},
  title         = {Black box attacks on deep anomaly detectors},
  year          = {2019},
  note          = {cited By 4},
  abstract      = {The process of identifying the true anomalies from a given set of data instances is known as anomaly detection. It has been applied to address a diverse set of problems in multiple application domains including cybersecurity. Deep learning has recently demonstrated state-of-the-art performance on key anomaly detection applications, such as intrusion detection, Denial of Service (DoS) attack detection, security log analysis, and malware detection. Despite the great successes achieved by neural network architectures, models with very low test error have been shown to be consistently vulnerable to small, adversarially chosen perturbations of the input. The existence of evasion attacks during the test phase of machine learning algorithms represents a significant challenge to both their deployment and understanding. Recent approaches in the literature have focused on three different areas: (a) generating adversarial examples in supervised machine learning in multiple domains; (b) countering the attacks with various defenses; (c) theoretical guarantees on the robustness of machine learning models by understanding their security properties. However, they have not covered, from the perspective of the anomaly detection task in a black box setting. The exploration of black box attack strategies, which reduce the number of queries for finding adversarial examples with high probability, is an important problem. In this paper, we study the security of black box deep anomaly detectors with a realistic threat model. We propose a novel black box attack in query constraint settings. First, we run manifold approximation on samples collected at attacker end for query reduction and understanding various thresholds set by underlying anomaly detector, and use spherical adversarial subspaces to generate attack samples. This method is well suited for attacking anomaly detectors where decision boundaries of nominal and abnormal classes are not very well defined and decision process is done with a set of thresholds on anomaly scores. We validate our attack on state-of-the-art deep anomaly detectors and show that the attacker goal is achieved under constraint settings. Our evaluation of the proposed approach shows promising results and demonstrates that our strategy can be successfully used against other anomaly detectors. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
  art_number    = {3339266},
  document_type = {Conference Paper},
  doi           = {10.1145/3339252.3339266},
  groups        = {First Filtering},
  journal       = {ACM International Conference Proceeding Series},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071716745&doi=10.1145%2f3339252.3339266&partnerID=40&md5=643514879772c35cb768eb9d905ad0a3},
}

@Conference{AL-Hawawreh201983,
  author        = {AL-Hawawreh, M. and Sitnikova, E. and Den Hartog, F.},
  title         = {An efficient intrusion detection model for edge system in brownfield industrial internet of things},
  year          = {2019},
  note          = {cited By 4},
  pages         = {83-87},
  abstract      = {The Industrial Internet of Things (IIoT) is bringing control systems online leading to significant innovation in industry and business. However, this development also comes with new cybersecurity threats. As much of the value of IIoT systems resides at the edge tier, this makes them potentially desired targets for attackers. Protecting edge physical systems by monitoring them and identifying malicious activities based on an efficient detection model is therefore of utmost importance. This paper proposes a detection model based on deep learning techniques that can learn and test using data collected from Remote Telemetry Unit (RTU) streams of gas pipeline system. It utilizes the sparse and denoising auto-encoder methods for unsupervised learning and deep neural networks for supervised learning to produce a high-level data representation from unlabeled and noisy data. Our results show that the proposed model achieves superior performance in identifying malicious activities. © 2019 Association for Computing Machinery.},
  document_type = {Conference Paper},
  doi           = {10.1145/3361758.3361762},
  groups        = {First Filtering},
  journal       = {ACM International Conference Proceeding Series},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076619562&doi=10.1145%2f3361758.3361762&partnerID=40&md5=b0dc8f667036e2d342f43b42bd05f486},
}

@Conference{Zhang2019374,
  author        = {Zhang, J. and Chen, J. and Wu, D. and Chen, B. and Yu, S.},
  title         = {Poisoning attack in federated learning using generative adversarial nets},
  year          = {2019},
  note          = {cited By 17},
  pages         = {374-380},
  abstract      = {Federated learning is a novel distributed learning framework, where the deep learning model is trained in a collaborative manner among thousands of participants. The shares between server and participants are only model parameters, which prevent the server from direct access to the private training data. However, we notice that the federated learning architecture is vulnerable to an active attack from insider participants, called poisoning attack, where the attacker can act as a benign participant in federated learning to upload the poisoned update to the server so that he can easily affect the performance of the global model. In this work, we study and evaluate a poisoning attack in federated learning system based on generative adversarial nets (GAN). That is, an attacker first acts as a benign participant and stealthily trains a GAN to mimic prototypical samples of the other participants' training set which does not belong to the attacker. Then these generated samples will be fully controlled by the attacker to generate the poisoning updates, and the global model will be compromised by the attacker with uploading the scaled poisoning updates to the server. In our evaluation, we show that the attacker in our construction can successfully generate samples of other benign participants using GAN and the global model performs more than 80% accuracy on both poisoning tasks and main tasks. © 2019 IEEE.},
  art_number    = {8887357},
  document_type = {Conference Paper},
  doi           = {10.1109/TrustCom/BigDataSE.2019.00057},
  groups        = {First Filtering},
  journal       = {Proceedings - 2019 18th IEEE International Conference on Trust, Security and Privacy in Computing and Communications/13th IEEE International Conference on Big Data Science and Engineering, TrustCom/BigDataSE 2019},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075142862&doi=10.1109%2fTrustCom%2fBigDataSE.2019.00057&partnerID=40&md5=cec3577946aba1dcd97f6bdf8bcf690d},
}

@Article{Lei20196668,
  author        = {Lei, T. and Qin, Z. and Wang, Z. and Li, Q. and Ye, D.},
  journal       = {IEEE Internet of Things Journal},
  title         = {EveDroid: Event-Aware Android Malware Detection Against Model Degrading for IoT Devices},
  year          = {2019},
  note          = {cited By 14},
  number        = {4},
  pages         = {6668-6680},
  volume        = {6},
  abstract      = {With the proliferation of the smart Internet of Things (IoT) devices based on Android system, malicious Android applications targeting for IoT devices have received more and more attention due to the concern of privacy leakage and property loss. However, existing malware detection approaches based on static or dynamic analysis are not scalable to the evolvement of malware and cannot extract enough valid semantics in application programming interface (API) level, failing to detect new malware. In this paper, we propose EveDroid, a scalable and event-aware Android malware detection system, which exploits the behavioral patterns in different events to effectively detect new malware based on the insight that events can reflect apps' possible running activities. Unlike existing approaches using API calls as features directly, we propose to use event group to describe apps' behaviors in event level, which can capture higher level of semantics than in API level. In event group, we adopt function clusters to represent behaviors in each event so that behaviors hidden in events can still be captured as time goes on, which enables EveDroid to detect new malware in the event level. The function clusters can generalize API calls into vectors based on their API composition to capture new API calls, which makes EveDroid scalable to malware evolving. Moreover, a neural network is specifically designed to aggregate the multiple events and automatically mine the semantic relationship among them. We train the system and evaluate its {F}1 -measure on a dataset of 14 956 benign and 28 848 malicious Android apps released in different years. The experimental results show that EveDroid outperforms other malware detection systems. © 2014 IEEE.},
  art_number    = {8684307},
  document_type = {Article},
  doi           = {10.1109/JIOT.2019.2909745},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070195934&doi=10.1109%2fJIOT.2019.2909745&partnerID=40&md5=ec7e8fc78d3cd0ede50ac9cca1d094d5},
}

@Article{Zerbini2019138,
  author        = {Zerbini, C.B. and Carvalho, L.F. and Abrão, T. and Proença, M.L., Jr.},
  journal       = {Applied Soft Computing Journal},
  title         = {Wavelet against random forest for anomaly mitigation in software-defined networking},
  year          = {2019},
  note          = {cited By 4},
  pages         = {138-153},
  volume        = {80},
  abstract      = {Security and availability of computer networks remain critical issues even with the constant evolution of communication technologies. In this core, traffic anomaly detection mechanisms need to be flexible to detect the growing spectrum of anomalies that may hinder proper network operation. In this paper, we argue that Software-defined Networking (SDN) provides a suitable environment for the design and implementation of more robust and comprehensive anomaly detection approaches. Aiming towards automated management to detect and prevent potential problems, we present an anomaly identification mechanism based on Discrete Wavelet Transform (DWT) and compare it with another detection model based on Random Forest. These methods generate a normal traffic profile, which is compared with actual real network traffic to recognize abnormal events. After a threat is detected, mitigation measures are activated so that the harmful effects of the malicious event are contained. We assess the effectiveness of the proposed anomaly detection methods and mitigation schemes using Distributed Denial of Service (DDoS) and port scan attacks. Our results confirm the effectiveness of both methods as well as the mitigation routines. In particular, the correspondence between the detection rates confirms that both methods enhance the detection of anomalous behavior by maintaining a satisfactory false-alarm rate. © 2019 Elsevier B.V.},
  document_type = {Article},
  doi           = {10.1016/j.asoc.2019.02.046},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063264851&doi=10.1016%2fj.asoc.2019.02.046&partnerID=40&md5=a0990d2d6095335e38e4679b516ce3aa},
}

@Article{Handa2019,
  author        = {Handa, A. and Sharma, A. and Shukla, S.K.},
  journal       = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  title         = {Machine learning in cybersecurity: A review},
  year          = {2019},
  note          = {cited By 11},
  number        = {4},
  volume        = {9},
  abstract      = {Machine learning technology has become mainstream in a large number of domains, and cybersecurity applications of machine learning techniques are plenty. Examples include malware analysis, especially for zero-day malware detection, threat analysis, anomaly based intrusion detection of prevalent attacks on critical infrastructures, and many others. Due to the ineffectiveness of signature-based methods in detecting zero day attacks or even slight variants of known attacks, machine learning-based detection is being used by researchers in many cybersecurity products. In this review, we discuss several areas of cybersecurity where machine learning is used as a tool. We also provide a few glimpses of adversarial attacks on machine learning algorithms to manipulate training and test data of classifiers, to render such tools ineffective. This article is categorized under: Application Areas > Science and Technology Technologies > Machine Learning Technologies > Classification Application Areas > Data Mining Software Tools. © 2019 Wiley Periodicals, Inc.},
  art_number    = {e1306},
  document_type = {Review},
  doi           = {10.1002/widm.1306},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061778025&doi=10.1002%2fwidm.1306&partnerID=40&md5=11adb68e66f04fed76fbc4d55da55bca},
}

@Article{Cai201955,
  author        = {Cai, C. and Mei, S. and Zhong, W.},
  journal       = {Information Technology and Management},
  title         = {Configuration of intrusion prevention systems based on a legal user: the case for using intrusion prevention systems instead of intrusion detection systems},
  year          = {2019},
  note          = {cited By 4},
  number        = {2},
  pages         = {55-71},
  volume        = {20},
  abstract      = {An intrusion prevention system (IPS) acts as a new type of information security technology, the configuration and management of which are currently urgent problems; in particular, debate exists regarding the value of these systems. In this paper, we analyse whether a firm realizes a positive or negative value from using an IPS instead of an intrusion detection system (IDS) in a default configuration and an optimal configuration, respectively. Our results suggest: (a) an IPS could hurt the firm when not configured optimally; (b) the optimal configuration of the IPS depends not only on the cost parameters but also on the external environment (quality of the IDS) in which the firm is operating; (c) whether the IDS is optimally configured or not, the firm will make the same decisions between using the IPS instead of the IDS and continuing to use the IDS; and (d) except for the true positive rate of IDS being in a certain region and the blocking cost being sufficiently high, the firm realizes a strictly nonnegative value if the firm configures the IPS optimally. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.},
  document_type = {Article},
  doi           = {10.1007/s10799-018-0291-6},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053796259&doi=10.1007%2fs10799-018-0291-6&partnerID=40&md5=0dcdde67c49486756234b1f9796d4c49},
}

@Conference{Liu201911226,
  author        = {Liu, X. and Hsieh, C.-J.},
  title         = {Rob-GAN: Generator, discriminator, and adversarial attacker},
  year          = {2019},
  note          = {cited By 11},
  pages         = {11226-11235},
  volume        = {2019-June},
  abstract      = {We study two important concepts in adversarial deep learning-adversarial training and generative adversarial network (GAN). Adversarial training is the technique used to improve the robustness of discriminator by combining adversarial attacker and discriminator in the training phase. GAN is commonly used for image generation by jointly optimizing discriminator and generator. We show these two concepts are indeed closely related and can be used to strengthen each other-adding a generator to the adversarial training procedure can improve the robustness of discriminators, and adding an adversarial attack to GAN training can improve the convergence speed and lead to better generators. Combining these two insights, we develop a framework called Rob-GAN to jointly optimize generator and discriminator in the presence of adversarial attacks-The generator generates fake images to fool discriminator; the adversarial attacker perturbs real images to fool discriminator, and the discriminator wants to minimize loss under fake and adversarial images. Through this end-to-end training procedure, we are able to simultaneously improve the convergence speed of GAN training, the quality of synthetic images, and the robustness of discriminator under strong adversarial attacks. Experimental results demonstrate that the obtained classifier is more robust than the state-of-the-art adversarial training approach (Madry 2017), and the generator outperforms SN-GAN on ImageNet-143. © 2019 IEEE.},
  art_number    = {8953327},
  document_type = {Conference Paper},
  doi           = {10.1109/CVPR.2019.01149},
  groups        = {First Filtering},
  journal       = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077972669&doi=10.1109%2fCVPR.2019.01149&partnerID=40&md5=e53c19af4bc15b38520f10acee0078cb},
}

@Conference{Kabin2019,
  author        = {Kabin, I. and Aftowicz, M. and Varabei, Y. and Klann, D. and Dyka, Z. and Langendoerfer, P.},
  title         = {Horizontal attacks using K-Means: Comparison with traditional analysis methods},
  year          = {2019},
  note          = {cited By 1},
  abstract      = {AI means are widely used to detect correlations in large data sets. This makes them an ideal candidate to improve side channel analysis attacks as the core feature if these attacks is to reveal the correlation between measurement values and the key bits processed. In this paper we present an assessment of AI means, i.e. k-means. We investigated the success rate of attacks against three designs with different levels of vulnerability. The result was that even though counter intuitive approaches such as the Pearson correlation coefficient outperform k-means. The highest success rate of the latter was 68.7 per cent of an uncompressed trace and 88.3 per cent for a compressed trace whereas the Pearson correlation coefficient achieved 91.7 per cent for the uncompressed trace and 89.3 per cent for the compressed trace. © 2019 IEEE.},
  art_number    = {8763777},
  document_type = {Conference Paper},
  doi           = {10.1109/NTMS.2019.8763777},
  groups        = {First Filtering},
  journal       = {2019 10th IFIP International Conference on New Technologies, Mobility and Security, NTMS 2019 - Proceedings and Workshop},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070361961&doi=10.1109%2fNTMS.2019.8763777&partnerID=40&md5=beb2e0927244f3fe7a591b7e07045e1a},
}

@Article{Moustafa20194815,
  author        = {Moustafa, N. and Turnbull, B. and Choo, K.-K.R.},
  journal       = {IEEE Internet of Things Journal},
  title         = {An ensemble intrusion detection technique based on proposed statistical flow features for protecting network traffic of internet of things},
  year          = {2019},
  note          = {cited By 85},
  number        = {3},
  pages         = {4815-4830},
  volume        = {6},
  abstract      = {Internet of Things (IoT) plays an increasingly significant role in our daily activities, connecting physical objects around us into digital services. In other words, IoT is the driving force behind home automation, smart cities, modern health systems, and advanced manufacturing. This also increases the likelihood of cyber threats against IoT devices and services. Attackers may attempt to exploit vulnerabilities in application protocols, including Domain Name System (DNS), Hyper Text Transfer Protocol (HTTP) and Message Queue Telemetry Transport (MQTT) that interact directly with backend database systems and client-server applications to store data of IoT services. Successful exploitation of one or more of these protocols can result in data leakage and security breaches. In this paper, an ensemble intrusion detection technique is proposed to mitigate malicious events, in particular botnet attacks against DNS, HTTP, and MQTT protocols utilized in IoT networks. New statistical flow features are generated from the protocols based on an analysis of their potential properties. Then, an AdaBoost ensemble learning method is developed using three machine learning techniques, namely decision tree, Naive Bayes (NB), and artificial neural network, to evaluate the effect of these features and detect malicious events effectively. The UNSW-NB15 and NIMS botnet datasets with simulated IoT sensors' data are used to extract the proposed features and evaluate the ensemble technique. The experimental results show that the proposed features have the potential characteristics of normal and malicious activity using the correntropy and correlation coefficient measures. Moreover, the proposed ensemble technique provides a higher detection rate and a lower false positive rate compared with each classification technique included in the framework and three other state-of-the-art techniques. © 2014 IEEE.},
  art_number    = {8470090},
  document_type = {Article},
  doi           = {10.1109/JIOT.2018.2871719},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054216613&doi=10.1109%2fJIOT.2018.2871719&partnerID=40&md5=080872082b9921e2491e062bec7e485f},
}

@Conference{Karimipour2019,
  author        = {Karimipour, H. and Geris, S. and Dehghantanha, A. and Leung, H.},
  title         = {Intelligent Anomaly Detection for Large-scale Smart Grids},
  year          = {2019},
  note          = {cited By 8},
  abstract      = {This paper proposes an unsupervised anomaly detection scheme based on statistical correlation between measurements. The goal is to design a scalable anomaly detection engine suitable for large-scale smart grids, which can differentiate an actual fault from a disturbance and an intelligent cyber-attack, and can be implemented in. Simulation results on IEEE 39, 118 and 2848 bus systems verify the efficiency and accuracy of the proposed method under different operation conditions. The results show accuracy of 99%, true positive rate of 98% and false positive rate of less than 2%. © 2019 IEEE.},
  art_number    = {8861995},
  document_type = {Conference Paper},
  doi           = {10.1109/CCECE.2019.8861995},
  groups        = {First Filtering},
  journal       = {2019 IEEE Canadian Conference of Electrical and Computer Engineering, CCECE 2019},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074110661&doi=10.1109%2fCCECE.2019.8861995&partnerID=40&md5=b8e4fa0d166376a747840290844c19f6},
}

@Conference{Sitawarin20191,
  author        = {Sitawarin, C. and Wagner, D.},
  title         = {On the robustness of deep K-nearest neighbors},
  year          = {2019},
  note          = {cited By 8},
  pages         = {1-7},
  abstract      = {Despite a large amount of attention on adversarial examples, very few works have demonstrated an effective defense against this threat. We examine Deep k-Nearest Neighbor (DkNN), a proposed defense that combines k-Nearest Neighbor (kNN) and deep learning to improve the model's robustness to adversarial examples. It is challenging to evaluate the robustness of this scheme due to a lack of efficient algorithm for attacking kNN classifiers with large k and high-dimensional data. We propose a heuristic attack that allows us to use gradient descent to find adversarial examples for kNN classifiers, and then apply it to attack the DkNN defense as well. Results suggest that our attack is moderately stronger than any naive attack on kNN and significantly outperforms other attacks on DkNN. © 2019 IEEE.},
  art_number    = {8844626},
  document_type = {Conference Paper},
  doi           = {10.1109/SPW.2019.00014},
  groups        = {First Filtering},
  journal       = {Proceedings - 2019 IEEE Symposium on Security and Privacy Workshops, SPW 2019},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073150425&doi=10.1109%2fSPW.2019.00014&partnerID=40&md5=5f1115771fdf9a9ec99ba4951ed03d0d},
}

@Article{Sadeghi2019847,
  author        = {Sadeghi, M. and Larsson, E.G.},
  journal       = {IEEE Communications Letters},
  title         = {Physical Adversarial Attacks Against End-to-End Autoencoder Communication Systems},
  year          = {2019},
  note          = {cited By 20},
  number        = {5},
  pages         = {847-850},
  volume        = {23},
  abstract      = {We show that end-to-end learning of communication systems through deep neural network autoencoders can be extremely vulnerable to physical adversarial attacks. Specifically, we elaborate how an attacker can craft effective physical black-box adversarial attacks. Due to the openness (broadcast nature) of the wireless channel, an adversary transmitter can increase the block-error-rate of a communication system by orders of magnitude by transmitting a well-designed perturbation signal over the channel. We reveal that the adversarial attacks are more destructive than the jamming attacks. We also show that classical coding schemes are more robust than the autoencoders against both adversarial and jamming attacks. © 2019 IEEE.},
  art_number    = {8651357},
  document_type = {Article},
  doi           = {10.1109/LCOMM.2019.2901469},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065565354&doi=10.1109%2fLCOMM.2019.2901469&partnerID=40&md5=600d9efa666f7b9edcb72a33342ecf50},
}

@Conference{Last2003,
  author        = {Last, M. and Shapira, B. and Elovici, Y. and Zaafrany, O. and Kandel, A.},
  title         = {Content-based methodology for anomaly detection on the web},
  year          = {2003},
  note          = {cited By 15},
  pages         = {113-123},
  volume        = {2663},
  abstract      = {As became apparent after the tragic events of September 11, 2001, terrorist organizations and other criminal groups are increasingly using the legitimate ways of Internet access to conduct their malicious activities. Such actions cannot be detected by existing intrusion detection systems that are generally aimed at protecting computer systems and networks from some kind of "cyber attacks". Preparation of an attack against the human society itself can only be detected through analysis of the content accessed by the users. The proposed study aims at developing an innovative methodology for abnormal activity detection, which uses web content as the audit information provided to the detection system. The new behavior-based detection method learns the normal behavior by applying an unsupervised clustering algorithm to the contents of publicly available web pages viewed by a group of similar users. In this paper, we represent page content by the well-known vector space model. The content models of normal behavior are used in real-time to reveal deviation from normal behavior at a specific location on the net. The detection algorithm sensitivity is controlled by a threshold parameter. The method is evaluated by the tradeoff between the detection rate (TP) and the false positive rate (FP). © 2003 Springer-Verlag Berlin Heidelberg.},
  document_type = {Conference Paper},
  doi           = {10.1007/3-540-44831-4_13},
  groups        = {First Filtering},
  journal       = {Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-4544330446&doi=10.1007%2f3-540-44831-4_13&partnerID=40&md5=fab4725fdc150503291ebf311d00b9b5},
}

@Article{Pogossian2005,
  author        = {Pogossian, E. and Javadyan, A. and Ivanyan, E.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {Effective discovery of intrusion protection strategies},
  year          = {2005},
  note          = {cited By 7},
  pages         = {263-276},
  volume        = {3505 LNAI},
  abstract      = {Effectiveness of discovery of strategy knowledge is studied for problems where the space of hypothesis of solutions is specified by game trees and target solutions are discovered by methods capable of systematic acquisition of expert knowledge about them. A version of Botvinnik's Intermediate Goals At First algorithm is developed for strategy formation based on common knowledge planning and dynamic testing of the plans in the corresponding game tree. Applied to the intrusion protection problem the algorithm for a range of types of knowledge in form of goals and rules demonstrates strong tendency to increasing the efficiency of strategy formation with an increase in the amount of knowledge available to the system. © Springer-Verlag Berlin Heidelberg 2005.},
  document_type = {Conference Paper},
  doi           = {10.1007/11492870_21},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-26944469028&doi=10.1007%2f11492870_21&partnerID=40&md5=e7b5e1a5b388425626f7d9c20cb353b0},
}

@Conference{Kurosawa2005,
  author        = {Kurosawa, S. and Nakayama, H. and Kato, N. and Jamalipour, A. and Nomoto, Y.},
  title         = {A self-adaptive intrusion detection method for AODV-based mobile ad hoc networks},
  year          = {2005},
  note          = {cited By 12},
  pages         = {773-780},
  volume        = {2005},
  abstract      = {Mobile ad hoc networks (MANET) are usually formed without any major infrastructure. As a result, they are relatively vulnerable to malicious network attacks and therefore the security is a more significant issue than in infrastructure-type wireless networks. In these networks, it is difficult to identify malicious hosts, as the topology of the network changes dynamically. A malicious host can easily interrupt a route for which the malicious host is one of the forming nodes in the communication path. In the literature, there are several proposals to detect such malicious host inside the network. In those methods usually a baseline profile is defined in accordance to static training data and then they are used to verify the identity and the topology of the network, thus avoiding any malicious host to be joined in the network. Since the topology of a MANET is dynamically changing, use of a static profile is not efficient. In this paper, we propose a new intrusion detection scheme based on a learning process, so that the training data can be updated at particular time intervals. The simulation results show the effectiveness of the proposed technique compared to conventional schemes. © 2005 IEEE.},
  art_number    = {1542870},
  document_type = {Conference Paper},
  doi           = {10.1109/MAHSS.2005.1542870},
  groups        = {First Filtering},
  journal       = {2nd IEEE International Conference on Mobile Ad-hoc and Sensor Systems, MASS 2005},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750355498&doi=10.1109%2fMAHSS.2005.1542870&partnerID=40&md5=f687e76ca0cc725a28e455903466d2fa},
}

@Conference{DeLaTorre2008,
  author        = {De La Torre, F. and Minh, H.N.},
  title         = {Parameterized kernel principal component analysis: Theory and applications to supervised and unsupervised image alignment},
  year          = {2008},
  note          = {cited By 32},
  abstract      = {Parameterized Appearance Models (PAMs) (e.g. eigen-tracking, active appearance models, morphable models) use Principal Component Analysis (PCA) to model the shape and appearance of objects in images. Given a new image with an unknown appearance/shape configuration, PAMs can detect and track the object by optimizing the model's parameters that best match the image. While PAMs have numerous advantages for image registration relative to alternative approaches, they suffer from two major limitations: First, PCA cannot model non-linear structure in the data. Second, learning PAMs requires precise manually labeled training data. This paper proposes Parameterized Kernel Principal Component Analysis (PKPCA), an extension of PAMs that uses Kernel PCA (KPCA) for learning a non-linear appearance model invariant to rigid and/or non-rigid deformations. We demonstrate improved performance in supervised and unsupervised image registration, and present a novel application to improve the quality of manual landmarks in faces. In addition, we suggest a clean and effective matrix formulation for PKPCA. ©2008 IEEE.},
  art_number    = {4587523},
  document_type = {Conference Paper},
  doi           = {10.1109/CVPR.2008.4587523},
  groups        = {First Filtering},
  journal       = {26th IEEE Conference on Computer Vision and Pattern Recognition, CVPR},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-51949111955&doi=10.1109%2fCVPR.2008.4587523&partnerID=40&md5=67479dab23269c9835a5f8e9f1b75750},
}

@Article{Viinikka2009,
  author        = {Viinikka, J. and Debar, H. and Mé, L. and Lehikoinen, A. and Tarvainen, M.},
  journal       = {Information Fusion},
  title         = {Processing intrusion detection alert aggregates with time series modeling},
  year          = {2009},
  note          = {cited By 47},
  number        = {4},
  pages         = {312-324},
  volume        = {10},
  abstract      = {The main use of intrusion detection systems (IDS) is to detect attacks against information systems and networks. Normal use of the network and its functioning can also be monitored with an IDS. It can be used to control, for example, the use of management and signaling protocols, or the network traffic related to some less critical aspects of system policies. These complementary usages can generate large numbers of alerts, but still, in operational environment, the collection of such data may be mandated by the security policy. Processing this type of alerts presents a different problem than correlating alerts directly related to attacks or filtering incorrectly issued alerts. We aggregate individual alerts to alert flows, and then process the flows instead of individual alerts for two reasons. First, this is necessary to cope with the large quantity of alerts - a common problem among all alert correlation approaches. Second, individual alert's relevancy is often indeterminable, but irrelevant alerts and interesting phenomena can be identified at the flow level. This is the particularity of the alerts created by the complementary uses of IDSes. Flows consisting of alerts related to normal system behavior can contain strong regularities. We propose to model these regularities using non-stationary autoregressive models. Once modeled, the regularities can be filtered out to relieve the security operator from manual analysis of true, but low impact alerts. We present experimental results using these models to process voluminous alert flows from an operational network. © 2009 Elsevier B.V. All rights reserved.},
  document_type = {Article},
  doi           = {10.1016/j.inffus.2009.01.003},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-67349164787&doi=10.1016%2fj.inffus.2009.01.003&partnerID=40&md5=99f382be324f6fa921184efa4d871409},
}

@Article{Nakayama2009,
  author        = {Nakayama, H. and Kurosawa, S. and Jamalipour, A. and Nemoto, Y. and Kato, N.},
  journal       = {IEEE Transactions on Vehicular Technology},
  title         = {A dynamic anomaly detection scheme for AODV-based mobile ad hoc networks},
  year          = {2009},
  note          = {cited By 94},
  number        = {5},
  pages         = {2471-2481},
  volume        = {58},
  abstract      = {Mobile ad hoc networks (MANETs) are usually formed without any major infrastructure. As a result, they are relatively vulnerable to malicious network attacks, and therefore, security is a more significant issue than infrastructure-based wireless networks. In MANETs, it is difficult to identify malicious hosts as the topology of the network dynamically changes. A malicious host can easily interrupt a route for which it is one of the forming nodes in the communication path. In the literature, there are several proposals to detect such malicious hosts inside the network. In those methods, a baseline profile, which is defined as per static training data, is usually used to verify the identity and the topology of the network, thus preventing any malicious host from joining the network. Since the topology of a MANET dynamically changes, the mere use of a static baseline profile is not efficient. In this paper, we propose a new anomaly-detection scheme based on a dynamic learning process that allows the training data to be updated at particular time intervals. Our dynamic learning process involves calculating the projection distances based on multidimensional statistics using weighted coefficients and a forgetting curve. We use the network simulator 2 (ns-2) system to conduct the MANET simulations and consider scenarios for detecting five types of attacks. The simulation results involving two different networks in size show the effectiveness of the proposed techniques. © 2009 IEEE.},
  document_type = {Article},
  doi           = {10.1109/TVT.2008.2010049},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-66449085294&doi=10.1109%2fTVT.2008.2010049&partnerID=40&md5=5de7c568d9c697c8964491be7af214ba},
}

@Conference{Salamat2009,
  author        = {Salamat, B. and Jackson, T. and Gal, A. and Franz, M.},
  title         = {Orchestra: Intrusion detection using parallel Execution and monitoring of program variants in user-space},
  year          = {2009},
  note          = {cited By 81},
  pages         = {33-46},
  abstract      = {In a Multi-Variant Execution Environment (MVEE), several slightly different versions of the same program are executed in lockstep. While this is done, a monitor compares the behavior of the versions at certain synchronization points with the aim of detecting discrepancies which may indicate attacks. As we show, the monitor can be implemented entirely in user space, eliminating the need for kernel modifications. As a result, the monitor is not a part of the trusted code base. We have built a fully functioning MVEE, named Orchestra, and evaluated its effectiveness. We obtained benchmark results on a quad-core system, using two variants which grow the stack in opposite directions. The results show that the overall penalty of simultaneous execution and monitoring of two variants on a multi-core system averages about 15% relative to unprotected conventional execution. Copyright © 2009 ACM.},
  document_type = {Conference Paper},
  doi           = {10.1145/1519065.1519071},
  groups        = {First Filtering},
  journal       = {Proceedings of the 4th ACM European Conference on Computer Systems, EuroSys'09},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349127596&doi=10.1145%2f1519065.1519071&partnerID=40&md5=9aa31515752a83e675bb9b9932627e10},
}

@Conference{Li2009,
  author        = {Li, Y. and Lu, T.-B. and Guo, L. and Tian, Z.-H. and Qi, L.},
  title         = {Optimizing network anomaly detection scheme using instance selection mechanism},
  year          = {2009},
  note          = {cited By 3},
  abstract      = {Network anomaly detection is a classically difficult research topic in intrusion detection. However, existing research has been solely focused on the detection algorithm. An important issue that has not been well studied so far is the selection of normal training data for network anomaly detection algorithm, which is highly related to the detection performance and computational complexity. Based on our previous proposed TCM-KNN (Transductive Confidence Machines for K-Nearest Neighbors) anomaly detection method, which can detect anomalies with high detection rate and low false positive rate, we develop an instance selection mechanism for TCM-KNN based on EFCM (Extended Fuzzy C-Means) clustering algorithm in this paper, aiming at limiting the size of training dataset, thus reducing the computational cost of TCM-KNN and boosting its detection performance. We report the experimental results over real network traffic. The results demonstrate the instance selection method presented in this paper is effective for TCM-KNN and thus optimizing it as an effectively lightweight network anomaly detection scheme.},
  art_number    = {5425547},
  document_type = {Conference Paper},
  doi           = {10.1109/GLOCOM.2009.5425547},
  groups        = {First Filtering},
  journal       = {GLOBECOM - IEEE Global Telecommunications Conference},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951563176&doi=10.1109%2fGLOCOM.2009.5425547&partnerID=40&md5=cb4ec2314932dbb580b7e8d9f4d9d455},
}

@Conference{Kirchner2010,
  author        = {Kirchner, M.},
  title         = {A framework for detecting anomalies in HTTP traffic using instance-based learning and k-nearest neighbor classification},
  year          = {2010},
  note          = {cited By 8},
  abstract      = {Attacks against web applications and web-based services that use HTTP as a communication protocol pose a serious threat to today's information technology infrastructures. A common countermeasure is to apply misuse detection and prevention systems that compare the contents of HTTP traffic against signatures of known attacks, as it is for example done by web application firewalls. A serious drawback of these systems is the fact that the used signatures often are not tailored for the individual web applications to be protected. Furthermore, signatures can often be circumvented by rewriting attacks into different forms, resulting in successful exploitation and circumvention of a misuse detection or prevention system. This paper presents the design and implementation of an anomaly detection framework for HTTP traffic that operates without signatures of known attacks. It rather learns normal usage patterns of web-based applications by inspecting full HTTP request and response contents. The results are then used for anomaly detection. The framework automatically adjusts to the applications to be monitored, derives normal usage patterns and compares subsequent HTTP traffic to the built knowledge base. © 2010 IEEE.},
  art_number    = {5497997},
  document_type = {Conference Paper},
  doi           = {10.1109/IWSCN.2010.5497997},
  groups        = {First Filtering},
  journal       = {2010 2nd International Workshop on Security and Communication Networks, IWSCN 2010},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956072082&doi=10.1109%2fIWSCN.2010.5497997&partnerID=40&md5=237b0b5cd130740e7f13ac49af420135},
}

@Conference{Shao2010,
  author        = {Shao, M.-H. and Lin, J.-B. and Lee, Y.-P.},
  title         = {Cluster-based cooperative back propagation network approach for intrusion detection in MANET},
  year          = {2010},
  note          = {cited By 11},
  pages         = {1627-1632},
  abstract      = {Mobile ad-hoc networks (MANET) are particularly vulnerable on account of its intrinsic characteristics of open medium, dynamic topology, absence of central authorities, distributed cooperation and constrained capability. These vulnerabilities create significant challenges for routing protocols operating in the entire network. In which, the reactive routing, i.e. AODV, bears the brunt of various kinds of attacks. In this paper, we try to build an efficient defense system based on a cooperative scheme to detect intrusions in AODV-based ad hoc networks using clustering technique and Back Propagation Network (BPN). A clustering architecture provides network scalability and fault tolerance, and results in more efficient use of network resources. Back-propagation neural networks is used for the purpose of anomaly detection and the feature is selected from the packets. The effectiveness of the proposed scheme is illustrated by means of extensive simulations using NS-2 simulator. Specifically, the comparison between BPN and finite state machine (FSM) is given. © 2010 IEEE.},
  art_number    = {5577946},
  document_type = {Conference Paper},
  doi           = {10.1109/CIT.2010.288},
  groups        = {First Filtering},
  journal       = {Proceedings - 10th IEEE International Conference on Computer and Information Technology, CIT-2010, 7th IEEE International Conference on Embedded Software and Systems, ICESS-2010, ScalCom-2010},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78249285592&doi=10.1109%2fCIT.2010.288&partnerID=40&md5=f3018361f98ec1c4587f4698e854ec78},
}

@Article{Davis2011,
  author        = {Davis, J.J. and Clark, A.J.},
  journal       = {Computers and Security},
  title         = {Data preprocessing for anomaly based network intrusion detection: A review},
  year          = {2011},
  note          = {cited By 163},
  number        = {6-7},
  pages         = {353-375},
  volume        = {30},
  abstract      = {Data preprocessing is widely recognized as an important stage in anomaly detection. This paper reviews the data preprocessing techniques used by anomaly-based network intrusion detection systems (NIDS), concentrating on which aspects of the network traffic are analyzed, and what feature construction and selection methods have been used. Motivation for the paper comes from the large impact data preprocessing has on the accuracy and capability of anomaly-based NIDS. The review finds that many NIDS limit their view of network traffic to the TCP/IP packet headers. Time-based statistics can be derived from these headers to detect network scans, network worm behavior, and denial of service attacks. A number of other NIDS perform deeper inspection of request packets to detect attacks against network services and network applications. More recent approaches analyze full service responses to detect attacks targeting clients. The review covers a wide range of NIDS, highlighting which classes of attack are detectable by each of these approaches. Data preprocessing is found to predominantly rely on expert domain knowledge for identifying the most relevant parts of network traffic and for constructing the initial candidate set of traffic features. On the other hand, automated methods have been widely used for feature extraction to reduce data dimensionality, and feature selection to find the most relevant subset of features from this candidate set. The review shows a trend toward deeper packet inspection to construct more relevant features through targeted content parsing. These context sensitive features are required to detect current attacks. © 2011 Elsevier Ltd. All rights reserved.},
  document_type = {Review},
  doi           = {10.1016/j.cose.2011.05.008},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051793908&doi=10.1016%2fj.cose.2011.05.008&partnerID=40&md5=bfe97ff5c0d5646f97b80777f0c45fbc},
}

@Article{Long2011,
  author        = {Long, J. and Zhao, W. and Zhu, F. and Cai, Z.},
  journal       = {International Journal of Uncertainty, Fuzziness and Knowlege-Based Systems},
  title         = {Active learning to defend poisoning attack against semi-supervised intrusion detection classifier},
  year          = {2011},
  note          = {cited By 0},
  number        = {SUPPL. 1},
  pages         = {93-106},
  volume        = {19},
  abstract      = {Intrusion detection systems play an important role in computer security. To make intrusion detection systems adaptive to changing environments, supervised learning techniques had been applied in intrusion detection. However, supervised learning needs a large amount of training instances to obtain classifiers with high accuracy. Limited to lack of high quality labeled instances, some researchers focused on semi-supervised learning to utilize unlabeled instances enhancing classification. But involving the unlabeled instances into the learning process also introduces vulnerability: attackers can generate fake unlabeled instances to mislead the final classifier so that a few intrusions can not be detected. In this paper we show that the attacker could mislead the semi-supervised intrusion detection classifier by poisoning the unlabeled instances. And we propose a defend method based on active learning to defeat the poisoning attack. Experiments show that the poisoning attack can reduce the accuracy of the semi-supervised learning classifier and the proposed defending method based on active learning can obtain higher accuracy than the original semi-supervised learner under the presented poisoning attack. © 2011 World Scientific Publishing Company.},
  document_type = {Conference Paper},
  doi           = {10.1142/S0218488511007362},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-81455154763&doi=10.1142%2fS0218488511007362&partnerID=40&md5=32e32e41b577532fbe63674f6aaf2dbd},
}

@Article{Baig2012,
  author        = {Baig, Z.A.},
  journal       = {International Journal of Security and Networks},
  title         = {Rapid anomaly detection for smart grid infrastructures through hierarchical pattern matching},
  year          = {2012},
  note          = {cited By 8},
  number        = {2},
  pages         = {83-94},
  volume        = {7},
  abstract      = {The Smart Grid Infrastructure has emerged as a necessary and critical platform for provisioning intelligent and accurate services to consumers of the electric grid, in recent times. The need for securing the same from malicious attempts by the adversary class to disrupt routine operations cannot be understated. In this paper, a brief description of various types of malicious attacks against the SGI is presented. Secondly, two light-weighted pattern matching techniques for detecting anomalous behaviour of the smart grid devices are elaborated upon. The singlelayer pattern matching scheme operates as one module within each level of the SGI hierarchy, with bottom-up communications taking place for pattern exchange, reconstruction and holistic visualisation of the SGI state. The multi group-based scheme operates as c clusters individually reconstructing patterns, and communicating with corresponding SGI devices one level above. The proposed schemes were found to impose minimal overhead in terms of communication and storage needed. Copyright © 2012 Inderscience Enterprises Ltd.},
  document_type = {Article},
  doi           = {10.1504/IJSN.2012.050025},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868234476&doi=10.1504%2fIJSN.2012.050025&partnerID=40&md5=09c085dae17126607252f98268319254},
}

@Article{Wu2012a,
  author        = {Wu, Z.-A. and Zhuang, Y. and Wang, Y.-Q. and Cao, J.},
  journal       = {Tien Tzu Hsueh Pao/Acta Electronica Sinica},
  title         = {Shilling attack detection based on feature selection for recommendation systems},
  year          = {2012},
  note          = {cited By 18},
  number        = {8},
  pages         = {1687-1693},
  volume        = {40},
  abstract      = {Most of the e-business recommender systems are based upon collaborative filtering (CF) algorithms. Since such systems have been shown to be vulnerable to shilling attacks in which malicious user profiles are inserted into the system in order to push or nuke the predictions of some targeted items, shilling attack detection has recently become a hot research topic in recommender systems. Firstly, the effectiveness of five types of attacks against different CF algorithms is analyzed. Secondly, a feature selection algorithm is presented. Two kinds of shilling attack detection algorithms based on supervised learning are then proposed: the first one is based on naïve Bayesian classifier, and the second one is based on k nearest neighbor (kNN) classifier. At last, experimental results show the effectiveness of the feature selection algorithm and the sensitivity and specificity of these two kinds of detection algorithms.},
  document_type = {Article},
  doi           = {10.3969/j.issn.0372-2112.2012.08.031},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867425780&doi=10.3969%2fj.issn.0372-2112.2012.08.031&partnerID=40&md5=d21644fb6bed7698dcdc1615ecd49d1d},
}

@Article{Vatamanu2012,
  author        = {Vatamanu, C. and Gavriluţ, D. and Benchea, R.},
  journal       = {Journal in Computer Virology},
  title         = {A practical approach on clustering malicious PDF documents},
  year          = {2012},
  note          = {cited By 24},
  number        = {4},
  pages         = {151-163},
  volume        = {8},
  abstract      = {Starting with 2009, the number of advanced persistent threat attacks has increased. In all of the researched cases, this kind of attacks use a zero-day exploit usually found in a frequently used application. Most of the times, the user has to visit a malicious page or open an infected document sent via e-mail. Even though the attack vector can be found in many forms, this paper addresses the case in which the attack relies on PDF files to deliver the payload. We chose PDF format both because of the high number of attacks it was used in and the key advantages it offers to the attacker. From an attackers perspective, the advantage of this attack is clear in that the PDF-files can be opened by an application on the users computer or in a browser, as most of the browsers support plug-ins that can render PDF files. The use of JavaScript inside PDF files offers two further advantages. The first is that code can be executed on the victims computer while the attack avoids different protection methods. The second benefit is that the JavaScript code can be polymorphic in that two files with the same functionality may look very different. This paper unveils a clustering method based on tokenization of the JavaScript code inside PDF files resistant to most of the obfuscation techniques used in script-based malware pieces. Our clustering method is based on the fact that most of the infected PDF-files (over 93 %) are using JavaScript code. By tokenizing the JavaScript code, describing it in an abstract manner and eliminating different operators used in polymorphism, we are able to obtain classes of files, very similar syntax-wise that can be easily clustered using different methods. Given the fact that virus analysts would likely analyse classes of files rather than isolated files, their work will be significantly reduced. The method of abstraction can be taken one step further and used as a detection mechanism-a technique to evaluate prevalent data or to obtain a subset from a large set without losing data variability. © 2012 Springer-Verlag France.},
  document_type = {Article},
  doi           = {10.1007/s11416-012-0166-z},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868366844&doi=10.1007%2fs11416-012-0166-z&partnerID=40&md5=d5c385a1f77ec32572ba95bef0e3296d},
}

@Article{Kloft2012,
  author        = {Kloft, M. and Laskov, P.},
  journal       = {Journal of Machine Learning Research},
  title         = {Security analysis of online centroid anomaly detection},
  year          = {2012},
  note          = {cited By 39},
  pages         = {3681-3724},
  volume        = {13},
  abstract      = {Security issues are crucial in a number of machine learning applications, especially in scenarios dealing with human activity rather than natural phenomena (e.g., information ranking, spam detection, malware detection, etc.). In such cases, learning algorithms may have to cope with manipulated data aimed at hampering decision making. Although some previous work addressed the issue of handling malicious data in the context of supervised learning, very little is known about the behavior of anomaly detection methods in such scenarios. In this contribution,1 we analyze the performance of a particular method-online centroid anomaly detection-in the presence of adversarial noise. Our analysis addresses the following security-related issues: formalization of learning and attack processes, derivation of an optimal attack, and analysis of attack efficiency and limitations. We derive bounds on the effectiveness of a poisoning attack against centroid anomaly detection under different conditions: attacker's full or limited control over the traffic and bounded false positive rate. Our bounds show that whereas a poisoning attack can be effectively staged in the unconstrained case, it can be made arbitrarily difficult (a strict upper bound on the attacker's gain) if external constraints are properly used. Our experimental evaluation, carried out on real traces of HTTP and exploit traffic, confirms the tightness of our theoretical bounds and the practicality of our protection mechanisms. © 2012 Marius Kloft and Pavel Laskov.},
  document_type = {Article},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873445143&partnerID=40&md5=7a32bb016c27e2d76c0070f28c46db01},
}

@Book{Bhattacharyya2013,
  author        = {Bhattacharyya, D.K. and Kalita, J.K.},
  title         = {Network anomaly detection: A machine learning perspective},
  year          = {2013},
  note          = {cited By 75},
  abstract      = {With the rapid rise in the ubiquity and sophistication of Internet technology and the accompanying growth in the number of network attacks, network intrusion detection has become increasingly important. Anomaly-based network intrusion detection refers to finding exceptional or nonconforming patterns in network traffic data compared to normal behavior. Finding these anomalies has extensive applications in areas such as cyber security, credit card and insurance fraud detection, and military surveillance for enemy activities. Network Anomaly Detection: A Machine Learning Perspective presents machine learning techniques in depth to help you more effectively detect and counter network intrusion. In this book, you'll learn about: #x2022; Network anomalies and vulnerabilities at various layers • The pros and cons of various machine learning techniques and algorithms • A taxonomy of attacks based on their characteristics and behavior • Feature selection algorithmsy • How to assess the accuracy, performance, completeness, timeliness, stability, interoperability, reliability, and other dynamic aspects of a network anomaly detection system • Practical tools for launching attacks, capturing packet or flow traffic, extracting features, detecting attacks, and evaluating detection performance • Important unresolved issues and research challenges that need to be overcome to provide better protection for networks Examining numerous attacks in detail, the authors look at the tools that intruders use and show how to use this knowledge to protect networks. The book also provides material for hands-on development, so that you can code on a testbed to implement detection methods toward the development of your own intrusion detection system. It offers a thorough introduction to the state of the art in network anomaly detection using machine learning approaches and systems. © 2014 by Taylor & Francis Group, LLC.},
  document_type = {Book},
  groups        = {First Filtering},
  journal       = {Network Anomaly Detection: A Machine Learning Perspective},
  pages         = {1-337},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053983816&partnerID=40&md5=d08c13eb685e592ea4d6bac426f6b1f0},
}

@Article{Kheir2013,
  author        = {Kheir, N.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {Analyzing HTTP user agent anomalies for malware detection},
  year          = {2013},
  note          = {cited By 11},
  pages         = {187-200},
  volume        = {7731 LNCS},
  abstract      = {This paper analyzes User Agent (UA) anomalies within malware HTTP traffic and extracts signatures for malware detection. We observe, within a large set of malware HTTP traffic provided by a local AV company, that almost one malware out of eight uses a suspicious UA header in at least one HTTP request. Such anomalies include typos, information leakage, outdated versions, and attack vectors such as XSS and SQL injection. Nowadays UA anomalies are still manually analyzed, whereas thousands of new malware samples are collected daily. On the other hand, just blacklisting unusual UA strings is not viable because malware developers may use random values or encode variable patterns. This paper automatically classifies UA anomalies and extracts signatures for malware detection. Our approach is implemented on top of network-based detection systems. We extracted signatures from an overall set of 100 thousand malware samples, and we tested these signatures on real-world malware traffic. Experimental results show that our solution detects unknown malware by the time of extracting our signatures. © 2013 Springer-Verlag.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-642-35890-6_14},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872732568&doi=10.1007%2f978-3-642-35890-6_14&partnerID=40&md5=fcb88520c08de5c5db16194ad21f32bf},
}

@Article{Corona2013,
  author        = {Corona, I. and Giacinto, G. and Roli, F.},
  journal       = {Information Sciences},
  title         = {Adversarial attacks against intrusion detection systems: Taxonomy, solutions and open issues},
  year          = {2013},
  note          = {cited By 94},
  pages         = {201-225},
  volume        = {239},
  abstract      = {Intrusion Detection Systems (IDSs) are one of the key components for securing computing infrastructures. Their objective is to protect against attempts to violate defense mechanisms. Indeed, IDSs themselves are part of the computing infrastructure, and thus they may be attacked by the same adversaries they are designed to detect. This is a relevant aspect, especially in safety-critical environments, such as hospitals, aircrafts, nuclear power plants, etc. To the best of our knowledge, this survey is the first work to present an overview on adversarial attacks against IDSs. In particular, this paper will provide the following original contributions: (a) a general taxonomy of attack tactics against IDSs; (b) an extensive description of how such attacks can be implemented by exploiting IDS weaknesses at different abstraction levels; (c) for each attack implementation, a critical investigation of proposed solutions and open points. Finally, this paper will highlight the most promising research directions for the design of adversary-aware, harder-to-defeat IDS solutions. To this end, we leverage on our research experience in the field of intrusion detection, as well as on a thorough investigation of the relevant related works published so far. © 2013 Elsevier Inc. All rights reserved.},
  document_type = {Article},
  doi           = {10.1016/j.ins.2013.03.022},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876939080&doi=10.1016%2fj.ins.2013.03.022&partnerID=40&md5=c2ef16c7cb863ece9237614f9dc8d239},
}

@Conference{Baig2013,
  author        = {Baig, Z.A. and Ahmad, S. and Sait, S.M.},
  title         = {Detecting intrusive activity in the smart grid communications infrastructure using self-organizing maps},
  year          = {2013},
  note          = {cited By 4},
  pages         = {1594-1599},
  abstract      = {The Smart Grid Infrastructure (SGI) provides for sustainable, affordable and uninterrupted electricity supply to consumers. The communications infrastructure of the SGI is prone to several malicious attacks identified in the recent past. Customer-specific electricity readings are communicated up the SGI hierarchy from consumer devices to centralized servers through intermediary devices such as smart meters and data concentrators/aggregators. In this paper, we model the attacks against the home area network of the SGI, through definition and generation of routine device behaviors. Any observed deviation from the defined normal profile is labeled as a malicious attack. Subsequently, we propose a Self-Organizing Map (SOM)-based approach towards training and testing of centralized SGI devices to qualify them for identifying anomalies accurately. The proposed scheme is capable of detecting anomalous readings within a consumer's household, with reasonable accuracies. © 2013 IEEE.},
  art_number    = {6681021},
  document_type = {Conference Paper},
  doi           = {10.1109/TrustCom.2013.196},
  groups        = {First Filtering},
  journal       = {Proceedings - 12th IEEE International Conference on Trust, Security and Privacy in Computing and Communications, TrustCom 2013},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893477109&doi=10.1109%2fTrustCom.2013.196&partnerID=40&md5=1e040521e1db8a2dd08895a26c1909b2},
}

@Conference{Biggio2013,
  author        = {Biggio, B. and Pillai, I. and Rota Bulò, S. and Ariu, D. and Pelillo, M. and Roli, F.},
  title         = {Is data clustering in adversarial settings secure?},
  year          = {2013},
  note          = {cited By 59},
  pages         = {87-97},
  abstract      = {Clustering algorithms have been increasingly adopted in security applications to spot dangerous or illicit activities. However, they have not been originally devised to deal with deliberate attack attempts that may aim to subvert the clustering process itself. Whether clustering can be safely adopted in such settings remains thus questionable. In this work we propose a general framework that allows one to identify potential attacks against clustering algorithms, and to evaluate their impact, by making specific assumptions on the adversary's goal, knowledge of the attacked system, and capabilities of manipulating the input data. We show that an attacker may significantly poison the whole clustering process by adding a relatively small percentage of attack samples to the input data, and that some attack samples may be obfuscated to be hidden within some existing clusters. We present a case study on single-linkage hierarchical clustering, and report experiments on clustering of malware samples and handwritten digits. © 2013 ACM.},
  document_type = {Conference Paper},
  doi           = {10.1145/2517312.2517321},
  groups        = {First Filtering},
  journal       = {Proceedings of the ACM Conference on Computer and Communications Security},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888997884&doi=10.1145%2f2517312.2517321&partnerID=40&md5=5db9cebc81772533d3dd0e11f159bcb9},
}

@Conference{Darra2013,
  author        = {Darra, E. and Katsikas, S.K.},
  title         = {Attack detection capabilities of intrusion detection systems for Wireless Sensor Networks},
  year          = {2013},
  note          = {cited By 3},
  pages         = {225-230},
  abstract      = {Wireless Sensor Networks (WSN) are large systems that consist of low-cost, and resource-constrained sensor nodes. These networks are susceptible to many kinds of attacks as they have limited memory, battery life and computational power. Intrusion Detection is a solution to secure WSNs against several kinds of attacks. In this paper, we review types of attacks against WSNs and relevant intrusion detection approaches so that the attack detection capabilities of the latter are identified. © 2013 IEEE.},
  art_number    = {6623718},
  document_type = {Conference Paper},
  doi           = {10.1109/IISA.2013.6623718},
  groups        = {First Filtering},
  journal       = {IISA 2013 - 4th International Conference on Information, Intelligence, Systems and Applications},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888997678&doi=10.1109%2fIISA.2013.6623718&partnerID=40&md5=de6aa9c37459972de1333f2f005ffee1},
}

@Article{Biggio2014,
  author        = {Biggio, B. and Fumera, G. and Roli, F.},
  journal       = {International Journal of Pattern Recognition and Artificial Intelligence},
  title         = {Pattern recognition systems under attack: Design issues and research challenges},
  year          = {2014},
  note          = {cited By 56},
  number        = {7},
  volume        = {28},
  abstract      = {We analyze the problem of designing pattern recognition systems in adversarial settings, under an engineering viewpoint, motivated by their increasing exploitation in security-sensitive applications like spam and malware detection, despite their vulnerability to potential attacks has not yet been deeply understood. We first review previous work and report examples of how a complex system may be evaded either by leveraging on trivial vulnerabilities of its untrained components, e.g. parsing errors in the pre-processing steps, or by exploiting more subtle vulnerabilities of learning algorithms. We then discuss the need of exploiting both reactive and proactive security paradigms complementarily to improve the security by design. Our ultimate goal is to provide some useful guidelines for improving the security of pattern recognition in adversarial settings, and to suggest related open issues to foster research in this area. ©World Scientific Publishing Company.},
  art_number    = {1460002},
  document_type = {Article},
  doi           = {10.1142/S0218001414600027},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988423255&doi=10.1142%2fS0218001414600027&partnerID=40&md5=73739c08abb80da9b270dbd142a59b3e},
}

@Conference{Paudice2014,
  author        = {Paudice, A. and Sarkar, S. and Cotroneo, D.},
  title         = {An experiment with conceptual clustering for the analysis of security alerts},
  year          = {2014},
  note          = {cited By 1},
  pages         = {335-340},
  abstract      = {In response to attack against corporative and enterprise networks, administrators deploy intrusion detection systems, monitors, vulnerability scans and log systems. These systems monitor and record host and network device activities searching for signs of anomalies and security incidents. Doing that, these systems generally produce a huge number of alerts that overwhelms security analysts. This paper proposes the application of a conceptual clustering technique for filtering alerts and shows the results obtained for seven months of security alerts generated in a real large scale SaaS Cloud system. The technique has been useful to support manual analysis activities conducted by the operations team of the reference Cloud system. © 2014 IEEE.},
  art_number    = {6983863},
  document_type = {Conference Paper},
  doi           = {10.1109/ISSREW.2014.82},
  groups        = {First Filtering},
  journal       = {Proceedings - IEEE 25th International Symposium on Software Reliability Engineering Workshops, ISSREW 2014},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922591045&doi=10.1109%2fISSREW.2014.82&partnerID=40&md5=c414079cdb46140b58f4eb64933c5c64},
}

@Article{Alazab2014,
  author        = {Alazab, A. and Hobbs, M. and Abawajy, J. and Khraisat, A. and Alazab, M.},
  journal       = {Information Management and Computer Security},
  title         = {Using response action with Intelligent Intrusion detection and prevention System against web application malware},
  year          = {2014},
  note          = {cited By 10},
  number        = {5},
  pages         = {431-449},
  volume        = {22},
  abstract      = {Findings: After evaluating the new system, a better result was generated in line with detection efficiency and the false alarm rate. This demonstrates the value of direct response action in an intrusion detection system.
Purpose: The purpose of this paper is to mitigate vulnerabilities in web applications, security detection and prevention are the most important mechanisms for security. However, most existing research focuses on how to prevent an attack at the web application layer, with less work dedicated to setting up a response action if a possible attack happened.
Design/methodology/approach: A combination of a Signature-based Intrusion Detection System (SIDS) and an Anomaly-based Intrusion Detection System (AIDS), namely, the Intelligent Intrusion Detection and Prevention System (IIDPS).
Research limitations/implications: Data limitation.
Originality/value: The contributions of this paper are to first address the problem of web application vulnerabilities. Second, to propose a combination of an SIDS and an AIDS, namely, the IIDPS. Third, this paper presents a novel approach by connecting the IIDPS with a response action using fuzzy logic. Fourth, use the risk assessment to determine an appropriate response action against each attack event. Combining the system provides a better performance for the Intrusion Detection System, and makes the detection and prevention more effective. © Emerald Group Publishing Limited.},
  document_type = {Article},
  doi           = {10.1108/IMCS-02-2013-0007},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84915760589&doi=10.1108%2fIMCS-02-2013-0007&partnerID=40&md5=a3e47f611641ee4ffcf8326055750d84},
}

@Article{Shamshirband2014,
  author        = {Shamshirband, S. and Anuar, N.B. and Kiah, M.L.M. and Misra, S.},
  journal       = {Acta Polytechnica Hungarica},
  title         = {Anomaly detection using fuzzy Q-learning algorithm},
  year          = {2014},
  note          = {cited By 18},
  number        = {8},
  pages         = {5-28},
  volume        = {11},
  abstract      = {Wireless networks are increasingly overwhelmed by Distributed Denial of Service (DDoS) attacks by generating flooding packets that exhaust critical computing and communication resources of a victim's mobile device within a very short period of time. This must be protected. Effective detection of DDoS attacks requires an adaptive learning classifier, with less computational complexity, and an accurate decision making to stunt such attacks. In this paper, we propose an intrusion detection system called Fuzzy Q-learning (FQL) algorithm to protect wireless nodes within the network and target nodes from DDoS attacks to identify the attack patterns and take appropriate countermeasures. The FQL algorithm was trained and tested to establish its performance by generating attacks from the NSL-KDD and CAIDA DDoS Attack datasets during the simulation experiments. Experimental results show that the proposed FQL IDS has higher accuracy of detection rate than Fuzzy Logic Controller and Q-learning algorithm alone. © 2014 Instituto de Pesquisas Economicas da FEA-USP. All rights reserved.},
  document_type = {Article},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908498737&partnerID=40&md5=ed6312e2a498807c5333af1644d08f79},
}

@Article{Biggio2014a,
  author        = {Biggio, B. and Bulò, S.R. and Pillai, I. and Mura, M. and Mequanint, E.Z. and Pelillo, M. and Roli, F.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {Poisoning complete-linkage hierarchical clustering},
  year          = {2014},
  note          = {cited By 24},
  pages         = {42-52},
  volume        = {8621 LNCS},
  abstract      = {Clustering algorithms are largely adopted in security applications as a vehicle to detect malicious activities, although few attention has been paid on preventing deliberate attacks from subverting the clustering process itself. Recent work has introduced a methodology for the security analysis of data clustering in adversarial settings, aimed to identify potential attacks against clustering algorithms and to evaluate their impact. The authors have shown that single-linkage hierarchical clustering can be severely affected by the presence of a very small fraction of carefully-crafted poisoning attacks into the input data, highlighting that the clustering algorithm may be itself the weakest link in a security system. In this paper, we extend this analysis to the case of complete-linkage hierarchical clustering by devising an ad hoc poisoning attack. We verify its effectiveness on artificial data and on application examples related to the clustering of malware and handwritten digits. © 2014 Springer-Verlag Berlin Heidelberg.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-662-44415-3_5},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906311280&doi=10.1007%2f978-3-662-44415-3_5&partnerID=40&md5=c83e1fed0a51060ff630cbe91d366928},
}

@Article{Qassim2014,
  author        = {Qassim, Q. and Patel, A. and Zin, A.M.},
  journal       = {International Arab Journal of Information Technology},
  title         = {Strategy to reduce false alarms in intrusion detection and prevention systems},
  year          = {2014},
  note          = {cited By 9},
  number        = {5},
  volume        = {11},
  abstract      = {Pervasive and sustained cyber attacks against information systems continue to pose a potentially devastating impact. Security of information systems and the networks that connect them is becoming increasingly significant nowadays than before as the number of security incidents steadily climbs. The traditional ways of protection with firewall and encryption software are no longer sufficient and effective. In this struggle to secure the data and the systems on which it is stored, Intrusion Detection and Prevention System (IDPS) can prove to be an invaluable tool. IDPS can also, be a very useful tool for recording forensic evidence that may be used in legal proceeding. The intrusion detection and prevention system have provided a high detection rate in detecting attack attempts. However, IDPS performance is hindered by the high false alarm rates it produces. This is a serious concern in information security because every false alarm can onset a severe impact to the system such as the disruption of information availability because of IDPS blockage in suspecting the information to be an attack attempt. The aim of this paper is to propose a strategy to reduce these false alarm rates to an acceptable level to maintain the total security against serious attacks by implementing a fuzzy logic-risk analysis technique for analyzing the generated alarms.},
  document_type = {Article},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903954065&partnerID=40&md5=acfa055663305ccaf35bd700713a07c8},
}

@Conference{Genge2014,
  author        = {Genge, B. and Rusu, D.A. and Haller, P.},
  title         = {A connection pattern-based approach to detect network traffic anomalies in critical infrastructures},
  year          = {2014},
  note          = {cited By 17},
  abstract      = {Recent trends in Critical Infrastructures (CIs), e.g., power plants and energy smart grids, showed an increased use of commodity, o-the-shelf Information and Communication Technologies (ICT) hardware and software. Although this enabled the implementation of a broad palette of new fea- Tures, the pervasive use of ICT, especially within the core of CIs, i.e., in Industrial Control Systems (ICSs), attracted a new class of attacks in which cyber disturbances propagate to the physical dimension of CIs. To ensure a more effective detection of cyber attacks against the ICS of CIs, we have de- veloped SPEAR, a systematic approach that automatically configures anomaly detection engines to detect attacks that violate connection patterns specific to ICSs. The approach is validated by experimental scenarios including trafic traces from real industrial equipment and real malware (Stuxnet). Copyright © 2007 by the Association for Computing Machinery, Inc.},
  art_number    = {1},
  document_type = {Conference Paper},
  doi           = {10.1145/2592791.2592792},
  groups        = {First Filtering},
  journal       = {Proceedings of the 7th European Workshop on System Security, EuroSec 2014},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900397521&doi=10.1145%2f2592791.2592792&partnerID=40&md5=e875ac23738fd1b39694122f252c0cfd},
}

@Article{Sheikhan2014,
  author        = {Sheikhan, M. and Jadidi, Z.},
  journal       = {Neural Computing and Applications},
  title         = {Flow-based anomaly detection in high-speed links using modified GSA-optimized neural network},
  year          = {2014},
  note          = {cited By 37},
  number        = {3-4},
  pages         = {599-611},
  volume        = {24},
  abstract      = {Ever growing Internet causes the availability of information. However, it also provides a suitable space for malicious activities, so security is crucial in this virtual environment. The network intrusion detection system (NIDS) is a popular tool to counter attacks against computer networks. This valuable tool can be realized using machine learning methods and intrusion datasets. Traditional datasets are usually packet-based in which all network packets are analyzed for intrusion detection in a time-consuming process. On the other hand, the recent spread of 1-10-Gbps-technologies have clearly pointed out that scalability is a growing problem. In this way, flow-based solutions can help to solve the problem by reduction of data and processing time, opening the way to high-speed detection on large infrastructures. Besides, NIDS should be capable of detecting new malicious activities. Artificial neural network-based NIDSs can detect unseen attacks, so a multi-layer perceptron (MLP) neural classifier is used in this study to distinguish benign and malicious traffic in a flow-based NIDS. In this way, a modified gravitational search algorithm (MGSA), as a modern heuristic technique, is employed to optimize the interconnection weights of the neural anomaly detector. The proposed scheme is trained using an enhanced version of the first labeled flow-based dataset for intrusion detection introduced in 2009. In addition, the particle swarm optimization (PSO) algorithm and traditional error back-propagation (EBP) algorithm are employed to train MLP, so performance comparison becomes possible. The experimental results based on the actual network data show that the MGSA-optimized neural anomaly detector is effective for monitoring abnormal traffic flows in the gigabytes traffic environment, and the accuracy is about 97.8 %. © 2012 Springer-Verlag London.},
  document_type = {Article},
  doi           = {10.1007/s00521-012-1263-0},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893963744&doi=10.1007%2fs00521-012-1263-0&partnerID=40&md5=8b38a712b259a5dd54e573c47cbd03d1},
}

@Conference{Ficco2014,
  author        = {Ficco, M. and Tasquier, L. and Aversa, R.},
  title         = {Agent-based intrusion detection for federated clouds},
  year          = {2014},
  note          = {cited By 2},
  pages         = {586-591},
  abstract      = {In the last years, the cloud services market has experienced an extremely rapid growth, as reported in several market research reports, which may lead to severe scalability problems. Therefore, federating multiple clouds is enjoying a lot of attention from the academic and commercial point of views. In this context, publish-subscribe is a widely used paradigm to support the interoperability of federated clouds. In this paper, we describe some potential vulnerabilities of a publish-subscribe based federated cloud system. In particular, we propose an agent-based system that aims at monitoring security vulnerabilities that affect such kind of inter-cloud cooperation solutions. © 2014 IEEE.},
  art_number    = {7057154},
  document_type = {Conference Paper},
  doi           = {10.1109/INCoS.2014.93},
  groups        = {First Filtering},
  journal       = {Proceedings - 2014 International Conference on Intelligent Networking and Collaborative Systems, IEEE INCoS 2014},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946689209&doi=10.1109%2fINCoS.2014.93&partnerID=40&md5=d8c6bc679667fc8d80177d3d7aa8a61e},
}

@Article{Mitchell2014,
  author        = {Mitchell, R. and Chen, I.-R.},
  journal       = {Computer Communications},
  title         = {A survey of intrusion detection in wireless network applications},
  year          = {2014},
  note          = {cited By 125},
  pages         = {1-23},
  volume        = {42},
  abstract      = {Information systems are becoming more integrated into our lives. As this integration deepens, the importance of securing these systems increases. Because of lower installation and maintenance costs, many of these systems are largely networked by wireless means. In order to identify gaps and propose research directions in wireless network intrusion detection research, we survey the literature of this area. Our approach is to classify existing contemporary wireless intrusion detection system (IDS) techniques based on target wireless network, detection technique, collection process, trust model and analysis technique. We summarize pros and cons of the same or different types of concerns and considerations for wireless intrusion detection with respect to specific attributes of target wireless networks including wireless local area networks (WLANs), wireless personal area networks (WPANs), wireless sensor networks (WSNs), ad hoc networks, mobile telephony, wireless mesh networks (WMNs) and cyber physical systems (CPSs). Next, we summarize the most and least studied wireless IDS techniques in the literature, identify research gaps, and analyze the rationale for the degree of their treatment. Finally, we identify worthy but little explored topics and provide suggestions for ways to conduct research. © 2014 Elsevier B.V. All rights reserved.},
  document_type = {Review},
  doi           = {10.1016/j.comcom.2014.01.012},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900637145&doi=10.1016%2fj.comcom.2014.01.012&partnerID=40&md5=c8f437479dccba90e8175f8c64d943df},
}

@Conference{Biggio2014b,
  author        = {Biggio, B. and Rieck, K. and Ariu, D. and Wressnegger, C. and Corona, I. and Giacinto, G. and Roli, F.},
  title         = {Poisoning behavioral malware clustering},
  year          = {2014},
  note          = {cited By 63},
  number        = {November},
  pages         = {27-36},
  volume        = {2014-November},
  abstract      = {Clustering algorithms have become a popular tool in computer security to analyze the behavior of malware variants, identify novel malware families, and generate signatures for antivirus systems. However, the suitability of clustering algorithms for security-sensitive settings has been recently questioned by showing that they can be significantly compromised if an attacker can exercise some control over the input data. In this paper, we revisit this problem by focusing on behavioral malware clustering approaches, and investigate whether and to what extent an attacker may be able to subvert these approaches through a careful injection of samples with poisoning behavior. To this end, we present a case study on Malheur, an open-source tool for behavioral malware clustering. Our experiments not only demonstrate that this tool is vulnerable to poisoning attacks, but also that it can be significantly compromised even if the attacker can only inject a very small percentage of attacks into the input data. As a remedy, we discuss possible countermeasures and highlight the need for more secure clustering algorithms. © 2014 by the Association for Computing Machinery, Inc. (ACM).},
  document_type = {Conference Paper},
  doi           = {10.1145/2666652.2666666},
  groups        = {First Filtering},
  journal       = {Proceedings of the ACM Conference on Computer and Communications Security},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937712787&doi=10.1145%2f2666652.2666666&partnerID=40&md5=57900f095f1afe86a44916e6f8778496},
}

@Conference{Xiao2015a,
  author        = {Xiao, H. and Biggio, B. and Brown, G. and Fumera, G. and Eckert, C. and Roli, F.},
  title         = {Is feature selection secure against training data poisoning?},
  year          = {2015},
  note          = {cited By 130},
  pages         = {1689-1698},
  volume        = {2},
  abstract      = {Learning in adversarial settings is becoming an important task for application domains where attackers may inject malicious data into the training set to subvert normal operation of data-driven technologies. Feature selection has been widely used in machine learning for security applications to improve generalization and computational efficiency, although it is not clear whether its use may be beneficial or even counterproductive when training data are poisoned by intelligent attackers. In this work, we shed light on this issue by providing a framework to investigate the robustness of popular feature selection methods, including LASSO, ridge regression and the elastic net. Our results on malware detection show that feature selection methods can be significantly compromised under attack (we can reduce LASSO to almost random choices of feature sets by careful insertion of less than 5% poisoned training samples), highlighting the need for specific countermeasures. Copyright © 2015 by the author(s).},
  document_type = {Conference Paper},
  groups        = {First Filtering},
  journal       = {32nd International Conference on Machine Learning, ICML 2015},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969900476&partnerID=40&md5=4db3a19b5a7af6b854639d11201064b3},
}

@Article{Kakavand2015,
  author        = {Kakavand, M. and Mustapha, N. and Mustapha, A. and Abdullah, M.T. and Riahi, H.},
  journal       = {Journal of Computer Science},
  title         = {Issues and challenges in anomaly intrusion detection for HTTP web services},
  year          = {2015},
  note          = {cited By 4},
  number        = {11},
  pages         = {1041-1053},
  volume        = {11},
  abstract      = {In recent years, the development of Web-based applications has made possible novel online activities, such as banking and electronic shopping. This implies significant use of the Hypertext Transfer Protocol (HTTP) as the standard communication protocol enabler for Web services. Due to this role, HTTP has become an essential middle target of bound attacks for intruders. This paper is set to address various problems in anomaly-based intrusion detection for HTTP Web services. We seek to identify common essential methods and solutions, as well as the gaps, limitations and challenges in anomaly intrusion detection in terms of used experimental datasets, features and techniques. © 2015 Mohsen Kakavand, Norwati Mustapha, Aida Mustapha, Mohd Taufik Abdullah and Hamed Riahi.},
  document_type = {Review},
  doi           = {10.3844/jcssp.2015.1041.1053},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958971744&doi=10.3844%2fjcssp.2015.1041.1053&partnerID=40&md5=7d6ee8cbe4421b7fdfddd4973a9565bb},
}

@Article{Li2015,
  author        = {Li, W.-T. and Gao, M. and Li, H. and Xiong, Q.-Y. and Wen, J.-H. and Ling, B.},
  journal       = {Zidonghua Xuebao/Acta Automatica Sinica},
  title         = {An shilling attack detection algorithm based on popularity degree features},
  year          = {2015},
  note          = {cited By 17},
  number        = {9},
  pages         = {1563-1576},
  volume        = {41},
  abstract      = {Recommendation systems based on collaborative filtering are vulnerable to shilling attacks, so how to detect attacks becomes crucial to ensure the reliability of these systems. Because the current shilling attack detection methods based on features extracted from rating patterns are susceptible to obfuscation technologies, this paper starts from a statistics analysis of the way users choose items to rate, thus getting the corresponding results of different rated items popularity degree (rated times) distributions in normal users's profiles and spam users' profile. Then classification features based on popularity degree are proposed to distinguish these two types of users. Finally, a shilling attack detection algorithm based on popularity features is developed. Experiments show that the detection performance of the algorithm is superior in attack detection precision and interference resistance. Copyright © 2015 Acta Automatica Sinica. All rights reserved.},
  document_type = {Article},
  doi           = {10.16383/j.aas.2015.c150040},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943628680&doi=10.16383%2fj.aas.2015.c150040&partnerID=40&md5=5bc955c22cb290ce34bd8fc998588160},
}

@Conference{Moustafa2015,
  author        = {Moustafa, N. and Slay, J.},
  title         = {Creating novel features to anomaly network Detection using DARPA-2009 data set},
  year          = {2015},
  note          = {cited By 15},
  pages         = {204-212},
  volume        = {2015-January},
  abstract      = {The increased usage of Internet, E-business, and social network enables attack behaviour with diverse fashions. A Network Intrusion Detection System (NIDS) is software which can protect the network from both internal and external attacks/intrusions. NIDSs detect the known attacks by using signature-based systems and discover novel attacks by using anomaly based systems. In order to represent modern low foot print attack environments, there is a need to generate new data set. In evaluating IDSs, KDDCUP99 and NSLKDD data sets were generated a decade ago, however for current network threat environment these data sets are not comprehensive reflection. Developing IDSs with a comprehensive low foot print attack dataset, in this paper DARPA-2009 is utilised. A novel statistical based feature extraction strategy is applied to construct the new features from DARPA-2009 Data set that consists of different style of attacks. A TCP trace tool is used to construct the features from the Pcap files and describe the new attacks behaviours. Finally, this data set is labelled and applied multiple machine learning (ML) algorithms to empirically observe the performance. The ML algorithms utilised were Naive Bayes classifier (NB), Decision Tree learning (DT), Artificial Neural Network classifier (ANN), and EM Clustering algorithm. The decision tree proved the better performance for this data set with suggested feature extraction strategy. The results show that these classifiers are not able to detect zero-day attacks, because of the two issues. Firstly, no payload for packets of DDoS which cause biased learning classifiers. Secondly, there is an unbalancing between attack records as well as normal records which cause highly false alarm rates. Future work includes establishing new methods to tackle the problem of imbalance between attack vectors and normal information. These methods will be applied to online network traffic and non-linear data of inter-arrival time and inter-packet length of flow-based features.},
  document_type = {Conference Paper},
  groups        = {First Filtering},
  journal       = {European Conference on Information Warfare and Security, ECCWS},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940746539&partnerID=40&md5=4591495b6ca62fb31c7c15a6cb9dfd99},
}

@Conference{Maiorca2015a,
  author        = {Maiorca, D. and Ariu, D. and Corona, I. and Giacinto, G.},
  title         = {A structural and content-based approach for a precise and robust detection of malicious PDF files},
  year          = {2015},
  note          = {cited By 28},
  pages         = {27-36},
  abstract      = {During the past years, malicious PDF files have become a serious threat for the security of modern computer systems. They are characterized by a complex structure and their variety is considerably high. Several solutions have been academically developed to mitigate such attacks. However, they leveraged on information that were extracted from either only the structure or the content of the PDF file. This creates problems when trying to detect non-Javascript or targeted attacks. In this paper, we present a novel machine learning system for the automatic detection of malicious PDF documents. It extracts information from both the structure and the content of the PDF file, and it features an advanced parsing mechanism. In this way, it is possible to detect a wide variety of attacks, including non-Javascript and parsing-based ones. Moreover, with a careful choice of the learning algorithm, our approach provides a significantly higher accuracy compared to other static analysis techniques, especially in the presence of adversarial malware manipulation.},
  document_type = {Conference Paper},
  doi           = {10.5220/0005264400270036},
  groups        = {First Filtering},
  journal       = {ICISSP 2015 - 1st International Conference on Information Systems Security and Privacy, Proceedings},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938789343&doi=10.5220%2f0005264400270036&partnerID=40&md5=dddd0a88ec55084db6d4afa0fa2fc741},
}

@Article{LaftahAlYaseen2015,
  author        = {Laftah Al-Yaseen, W. and Ali Othman, Z. and Ahmad Nazri, M.Z.},
  journal       = {Scientific World Journal},
  title         = {Hybrid Modified K -Means with C4.5 for Intrusion Detection Systems in Multiagent Systems},
  year          = {2015},
  note          = {cited By 20},
  volume        = {2015},
  abstract      = {Presently, the processing time and performance of intrusion detection systems are of great importance due to the increased speed of traffic data networks and a growing number of attacks on networks and computers. Several approaches have been proposed to address this issue, including hybridizing with several algorithms. However, this paper aims at proposing a hybrid of modified K-means with C4.5 intrusion detection system in a multiagent system (MAS-IDS). The MAS-IDS consists of three agents, namely, coordinator, analysis, and communication agent. The basic concept underpinning the utilized MAS is dividing the large captured network dataset into a number of subsets and distributing these to a number of agents depending on the data network size and core CPU availability. KDD Cup 1999 dataset is used for evaluation. The proposed hybrid modified K-means with C4.5 classification in MAS is developed in JADE platform. The results show that compared to the current methods, the MAS-IDS reduces the IDS processing time by up to 70%, while improving the detection accuracy. © 2015 Wathiq Laftah Al-Yaseen et al.},
  art_number    = {294761},
  document_type = {Article},
  doi           = {10.1155/2015/294761},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934344071&doi=10.1155%2f2015%2f294761&partnerID=40&md5=4e140533e6ac72976ece67d22789664d},
}

@Conference{Do2015,
  author        = {Do, H.G. and Ng, W.K.},
  title         = {Privacy-preserving approach for sharing and processing intrusion alert data},
  year          = {2015},
  note          = {cited By 8},
  abstract      = {Amplified and disrupting cyber-attacks might lead to severe security incidents with drastic consequences such as large property damage, sensitive information breach, or even disruption of the national economy. While traditional intrusion detection and prevention system might successfully detect low or moderate levels of attack, the cooperation among different organizations is necessary to defend against multi-stage and large-scale cyber-attacks. Correlating intrusion alerts from a shared database of multiple sources provides security analysts with succinct and high-level patterns of cyber-attacks-a powerful tool to combat with sophisticate attacks. However, sharing intrusion alert data raises a significant privacy concern among data holders, since publishing this information means a risk of exposing other sensitive information such as intranet topology, network services, and the security infrastructure. This paper discusses possible cryptographic approaches to tackle this issue. Organizers can encrypt their intrusion alert data to protect data confidentiality and outsource them to a shared server to reduce the cost of storage and maintenance, while, at the same time, benefit from a larger source of information for alert correlation process. Two privacy preserving alert correlation techniques are proposed under semi-honest model. These methods are based on attribute similarity and prerequisite/consequence conditions of cyber-attacks. © 2015 IEEE.},
  art_number    = {7106911},
  document_type = {Conference Paper},
  doi           = {10.1109/ISSNIP.2015.7106911},
  groups        = {First Filtering},
  journal       = {2015 IEEE 10th International Conference on Intelligent Sensors, Sensor Networks and Information Processing, ISSNIP 2015},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933575208&doi=10.1109%2fISSNIP.2015.7106911&partnerID=40&md5=8d24b182553076f2b953c3faadfb2333},
}

@Article{Pan2015,
  author        = {Pan, S. and Morris, T. and Adhikari, U.},
  journal       = {International Journal of Network Security},
  title         = {A specification-based intrusion detection framework for cyber-physical environment in electric power system},
  year          = {2015},
  note          = {cited By 32},
  number        = {2},
  pages         = {174-188},
  volume        = {17},
  abstract      = {The emergence of high-speed networks in electric power systems creates a tight interaction of cyber infrastructure with the physical infrastructure and makes the power system susceptible to cyber penetration and attacks. To address this problem, this paper proposes an innovative approach to develop a specification-based intrusion detection framework that leverages available information provided by components in a contemporary power system. A Bayesian network is used to graphically encode the causal relations among the available information to create patterns with temporal state transitions, which are used as rules in the proposed intrusion detection framework. This allows the proposed framework to detect cyber attacks and classify different substation scenarios. A case study is provided for the non-pilot directional over current relay protection scheme for a modified 2-bus 2-generator system taken from a section of the IEEE 9-bus 3-generator system. Nine power system scenarios were developed and implemented as part of the case study. Each scenario was implemented on a test bed and all scenarios were correctly classified by the IDS built using the proposed methodology.},
  document_type = {Article},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929876525&partnerID=40&md5=984eeb479d7356dc7f9e82d92c456c90},
}

@Article{Xia2015,
  author        = {Xia, H. and Fang, B. and Gao, M. and Ma, H. and Tang, Y. and Wen, J.},
  journal       = {Information Sciences},
  title         = {A novel item anomaly detection approach against shilling attacks in collaborative recommendation systems using the dynamic time interval segmentation technique},
  year          = {2015},
  note          = {cited By 42},
  pages         = {150-165},
  volume        = {306},
  abstract      = {Various types of web applications have gained both higher customer satisfaction and more benefits since being successfully armed with personalized recommendation. However, the increasingly rampant shilling attackers apply biased rating profiles to systems to manipulate item recommendations, which not just lower the recommending precision and user satisfaction but also damage the trustworthiness of intermediated transaction platforms and participants. Many studies have offered methods against shilling attacks, especially user profile based-detection. However, this detection suffers from the extraction of the universal feature of attackers, which directly results in poor performance when facing the improved shilling attack types. This paper presents a novel dynamic time interval segmentation technique based item anomaly detection approach to address these problems. In particular, this study is inspired by the common attack features from the standpoint of the item profile, and can detect attacks regardless of the specific attack types. The proposed segmentation technique could confirm the size of the time interval dynamically to group as many consecutive attack ratings together as possible. In addition, apart from effectiveness metrics, little attention has been paid to the robustness of detection methods, which includes measuring both the accuracy and the stability of results. Hence, we introduced a stability metric as a complement for estimating the robustness. Thorough experiments on the MovieLens dataset illustrate the performance of the proposed approach, and justify the value of the proposed approach for online applications. © 2015 Elsevier Inc. All rights reserved.},
  document_type = {Article},
  doi           = {10.1016/j.ins.2015.02.019},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926158397&doi=10.1016%2fj.ins.2015.02.019&partnerID=40&md5=280758e4260632447a6ad38c2e71945d},
}

@Article{WellerFahy2015,
  author        = {Weller-Fahy, D.J. and Borghetti, B.J. and Sodemann, A.A.},
  journal       = {IEEE Communications Surveys and Tutorials},
  title         = {A Survey of Distance and Similarity Measures Used Within Network Intrusion Anomaly Detection},
  year          = {2015},
  note          = {cited By 107},
  number        = {1},
  pages         = {70-91},
  volume        = {17},
  abstract      = {Anomaly detection (AD) use within the network intrusion detection field of research, or network intrusion AD (NIAD), is dependent on the proper use of similarity and distance measures, but the measures used are often not documented in published research. As a result, while the body of NIAD research has grown extensively, knowledge of the utility of similarity and distance measures within the field has not grown correspondingly. NIAD research covers a myriad of domains and employs a diverse array of techniques from simple k-means clustering through advanced multiagent distributed AD systems. This review presents an overview of the use of similarity and distance measures within NIAD research. The analysis provides a theoretical background in distance measures and a discussion of various types of distance measures and their uses. Exemplary uses of distance measures in published research are presented, as is the overall state of the distance measure rigor in the field. Finally, areas that require further focus on improving the distance measure rigor in the NIAD field are presented. © 1998-2012 IEEE.},
  art_number    = {6853338},
  document_type = {Review},
  doi           = {10.1109/COMST.2014.2336610},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925843430&doi=10.1109%2fCOMST.2014.2336610&partnerID=40&md5=c0772a1fa3724c7aba88e80365c2ba80},
}

@Article{Sallay2015,
  author        = {Sallay, H. and Bourouis, S. and Bouguila, N.},
  journal       = {Advances in Intelligent Systems and Computing},
  title         = {Web Service Intrusion Detection Using a Probabilistic Framework},
  year          = {2015},
  note          = {cited By 2},
  pages         = {161-166},
  volume        = {1089},
  abstract      = {In this paper, we propose an anomaly-based approach to detect intrusions attempts that may target web services. These intrusions (or attacks) are modeled as outliers (or noise) within a principled probabilistic framework. The proposed framework is based on finite Gaussian mixtures and allows the detection of both previously seen and unknown attacks against web services. The main idea of our framework is based on the consideration of malicious requests as outliers within our finite mixture model. Using this idea the intrusion detection problem is reduced to an adversarial classification problem. The merits of the proposed approach are shown using a data set containing both normal and intrusive requests, which were collected from a large real-life web service. © Springer International Publishing Switzerland 2015.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-319-08422-0_24},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906545861&doi=10.1007%2f978-3-319-08422-0_24&partnerID=40&md5=fb2a6c099956d5e7269d0942c813641a},
}

@Book{Sen2015,
  author        = {Sen, S.},
  title         = {A Survey of Intrusion Detection Systems Using Evolutionary Computation},
  year          = {2015},
  note          = {cited By 18},
  abstract      = {Intrusion detection is an indispensable part of a security system. Because new attacks are emerging every day, intrusion detection systems (IDSs) play a key role in identifying possible attacks to the system and giving proper responses. IDSs should adapt to these new attacks and attack strategies, and continuously improve. How to develop effective, efficient, and adaptive IDSs is a question that researchers have been working on for decades. Researchers have been exploring the suitability of different techniques to this research domain. The evolutionary computation (EC) inspired from natural evolution is one of the approaches increasingly studied. Some characteristics, such as producing readable outputs for security experts, producing lightweight solutions, and providing a set of solutions with different trade-offs between conflict objectives, make these techniques a promising candidate for the problem. In this study, we survey the proposed intrusion detection approaches based on EC techniques found in the literature. Each major research area on intrusion detection is investigated thoroughly from the EC point of view. Possible future research directions are also summarized for researchers. © 2015 Elsevier Inc. All rights reserved..},
  document_type = {Book Chapter},
  doi           = {10.1016/B978-0-12-801538-4.00004-5},
  groups        = {First Filtering},
  journal       = {Bio-Inspired Computation in Telecommunications},
  pages         = {73-94},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934967653&doi=10.1016%2fB978-0-12-801538-4.00004-5&partnerID=40&md5=66d1d39c141a8be9d7d4b79f55b344bb},
}

@Article{Mohaisen2015,
  author        = {Mohaisen, A. and Alrawi, O. and Mohaisen, M.},
  journal       = {Computers and Security},
  title         = {AMAL: High-fidelity, behavior-based automated malware analysis and classification},
  year          = {2015},
  note          = {cited By 95},
  pages         = {251-266},
  volume        = {52},
  abstract      = {This paper introduces AMAL, an automated and behavior-based malware analysis and labeling system that addresses shortcomings of the existing systems. AMAL consists of two sub-systems, AutoMal and MaLabel. AutoMal provides tools to collect low granularity behavioral artifacts that characterize malware usage of the file system, memory, network, and registry, and does that by running malware samples in virtualized environments. On the other hand, MaLabel uses those artifacts to create representative features, use them for building classifiers trained by manually vetted training samples, and use those classifiers to classify malware samples into families similar in behavior. AutoMal also enables unsupervised learning, by implementing multiple clustering algorithms for samples grouping. An evaluation of both AutoMal and MaLabel based on medium-scale (4000 samples) and large-scale datasets (more than 115,000 samples)—collected and analyzed by AutoMal over 13 months—shows AMAL's effectiveness in accurately characterizing, classifying, and grouping malware samples. MaLabel achieves a precision of 99.5% and recall of 99.6% for certain families' classification, and more than 98% of precision and recall for unsupervised clustering. Several benchmarks, cost estimates and measurements highlight the merits of AMAL. © 2015 Elsevier Ltd},
  document_type = {Article},
  doi           = {10.1016/j.cose.2015.04.001},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928709825&doi=10.1016%2fj.cose.2015.04.001&partnerID=40&md5=5ec30994865db0288fda0b764a31f0a1},
}

@Conference{Zolotukhin2015,
  author        = {Zolotukhin, M. and Hamalainen, T. and Kokkonen, T. and Siltanen, J.},
  title         = {Online detection of anomalous network flows with soft clustering},
  year          = {2015},
  note          = {cited By 2},
  abstract      = {In this study, we apply an anomaly-based approach to analyze traffic flows transferred over a network to detect the flows related to different types of attacks. Based on the information extracted from network flows a model of normal user behavior is discovered with the help of several clustering techniques. This model is then used to detect anomalies within recent time intervals. Since this approach is based on normal user behavior, it can potentially detect zero-day intrusions. Moreover, such a flow-based intrusion detection approach can be used in high speeds since it is based on information in packet headers, and, therefore, has to handle a considerably lesser amount of data. The proposed framework is tested on the data obtained with the help of a realistic cyber environment (RGCE) that enables one to construct real attack vectors. The simulations show that the proposed method results in a higher accuracy rate when compared to other intrusion detection techniques. © 2015 IEEE.},
  art_number    = {7266510},
  document_type = {Conference Paper},
  doi           = {10.1109/NTMS.2015.7266510},
  groups        = {First Filtering},
  journal       = {2015 7th International Conference on New Technologies, Mobility and Security - Proceedings of NTMS 2015 Conference and Workshops},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960917628&doi=10.1109%2fNTMS.2015.7266510&partnerID=40&md5=192953b119070c9f650b200e9625bdf0},
}

@Conference{Kiss2015,
  author        = {Kiss, I. and Genge, B. and Haller, P.},
  title         = {A clustering-based approach to detect cyber attacks in process control systems},
  year          = {2015},
  note          = {cited By 38},
  pages         = {142-148},
  abstract      = {Modern Process Control Systems (PCS) exhibit an increasing trend towards the pervasive adoption of commodity, off-the-shelf Information and Communication Technologies (ICT). This has brought significant economical and operational benefits, but it also shifted the architecture of PCS from a completely isolated environment to an open, 'system of systems' integration with traditional ICT systems, susceptible to traditional computer attacks. In this paper we present a novel approach to detect cyber attacks targeting measurements sent to control hardware, i.e., typically to Programmable Logical Controllers (PLC). The approach builds on the Gaussian mixture model to cluster sensor measurement values and a cluster assessment technique known as silhouette. We experimentally demonstrate that in this particular problem the Gaussian mixture clustering outperforms the k-means clustering algorithm. The effectiveness of the proposed technique is tested in a scenario involving the simulated Tennessee-Eastman chemical process and three different cyber attacks. © 2015 IEEE.},
  art_number    = {7281725},
  document_type = {Conference Paper},
  doi           = {10.1109/INDIN.2015.7281725},
  groups        = {First Filtering},
  journal       = {Proceeding - 2015 IEEE International Conference on Industrial Informatics, INDIN 2015},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949526633&doi=10.1109%2fINDIN.2015.7281725&partnerID=40&md5=0a445fc16c7f22d87a323d6b7f400c04},
}

@Article{Zhou2015,
  author        = {Zhou, C. and Huang, S. and Xiong, N. and Yang, S.-H. and Li, H. and Qin, Y. and Li, X.},
  journal       = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
  title         = {Design and Analysis of Multimodel-Based Anomaly Intrusion Detection Systems in Industrial Process Automation},
  year          = {2015},
  note          = {cited By 88},
  number        = {10},
  pages         = {1345-1360},
  volume        = {45},
  abstract      = {Industrial process automation is undergoing an increased use of information communication technologies due to high flexibility interoperability and easy administration. But it also induces new security risks to existing and future systems. Intrusion detection is a key technology for security protection. However, traditional intrusion detection systems for the IT domain are not entirely suitable for industrial process automation. In this paper, multiple models are constructed by comprehensively analyzing the multidomain knowledge of field control layers in industrial process automation, with consideration of two aspects: physics and information. And then, a novel multimodel-based anomaly intrusion detection system with embedded intelligence and resilient coordination for the field control system in industrial process automation is designed. In the system, an anomaly detection based on multimodel is proposed, and the corresponding intelligent detection algorithms are designed. Furthermore, to overcome the disadvantages of anomaly detection, a classifier based on an intelligent hidden Markov model, is designed to differentiate the actual attacks from faults. Finally, based on a combination simulation platform using optimized performance network engineering tool, the detection accuracy and the real-Time performance of the proposed intrusion detection system are analyzed in detail. Experimental results clearly demonstrate that the proposed system has good performance in terms of high precision and good real-Time capability. © 2015 IEEE.},
  art_number    = {7081762},
  document_type = {Article},
  doi           = {10.1109/TSMC.2015.2415763},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942246686&doi=10.1109%2fTSMC.2015.2415763&partnerID=40&md5=de3d6a74abdc9433737618ae8801b532},
}

@Conference{Kantchelian2015,
  author        = {Kantchelian, A. and Tschantz, M.C. and Afroz, S. and Miller, B. and Shankar, V. and Bachwani, R. and Joseph, A.D. and Tygar, J.D.},
  title         = {Better malware ground truth: Techniques for weighting anti-virus vendor labels},
  year          = {2015},
  note          = {cited By 35},
  pages         = {45-56},
  abstract      = {We examine the problem of aggregating the results of multiple anti-virus (AV) vendors' detectors into a single authoritative ground-truth label for every binary. To do so, we adapt a well-known generative Bayesian model that postulates the existence of a hidden ground truth upon which the AV labels depend. We use training based on Expectation Maximization for this fully unsupervised technique. We evaluate our method using 279,327 distinct binaries from VirusTotal, each of which appeared for the first time between January 2012 and June 2014. Our evaluation shows that our statistical model is consistently more accurate at predicting the future-derived ground truth than all unweighted rules of the form \k out of n" AV detections. In addition, we evaluate the scenario where partial ground truth is available for model building. We train a logistic regression predictor on the partial label information. Our results show that as few as a 100 randomly selected training instances with ground truth are enough to achieve 80% true positive rate for 0.1% false positive rate. In comparison, the best unweighted threshold rule provides only 60% true positive rate at the same false positive rate. © 2015 ACM.},
  document_type = {Conference Paper},
  doi           = {10.1145/2808769.2808780},
  groups        = {First Filtering},
  journal       = {AISec 2015 - Proceedings of the 8th ACM Workshop on Artificial Intelligence and Security, co-located with CCS 2015},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960480174&doi=10.1145%2f2808769.2808780&partnerID=40&md5=c238a0ca702b8922f3a8b2633aa66605},
}

@Article{Meng2015,
  author        = {Meng, W. and Li, W. and Kwok, L.-F.},
  journal       = {Security and Communication Networks},
  title         = {Design of intelligent KNN-based alarm filter using knowledge-based alert verification in intrusion detection},
  year          = {2015},
  note          = {cited By 43},
  number        = {18},
  pages         = {3883-3895},
  volume        = {8},
  abstract      = {Network intrusion detection systems (NIDSs) have been widely deployed in various network environments to defend against different kinds of network attacks. However, a large number of alarms especially unwanted alarms such as false alarms and non-critical alarms could be generated during the detection, which can greatly decrease the efficiency of the detection and increase the burden of analysis. To address this issue, we advocate that constructing an alarm filter in terms of expert knowledge is a promising solution. In this paper, we develop a method of knowledge-based alert verification and design an intelligent alarm filter based on a multi-class k-nearest-neighbor classifier to filter out unwanted alarms. In particular, the alarm filter employs a rating mechanism by means of expert knowledge to classify incoming alarms to proper clusters for labeling. We further analyze the effect of different classifier settings on classification accuracy with two alarm datasets. In the evaluation, we investigate the performance of the alarm filter with a real dataset and in a network environment, respectively. Experimental results indicate that our alarm filter can effectively filter out a number of NIDS alarms and can achieve a better outcome under the advanced mode. © 2015 John Wiley & Sons, Ltd.},
  document_type = {Article},
  doi           = {10.1002/sec.1307},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973565862&doi=10.1002%2fsec.1307&partnerID=40&md5=7e021282c6a66b9e29ade80c215b3e40},
}

@Conference{Vuong2015a,
  author        = {Vuong, T.P. and Loukas, G. and Gan, D.},
  title         = {Performance evaluation of cyber-physical intrusion detection on a robotic vehicle},
  year          = {2015},
  note          = {cited By 24},
  pages         = {2106-2113},
  abstract      = {Intrusion detection systems designed for conventional computer systems and networks are not necessarily suitable for mobile cyber-physical systems, such as robots, drones and automobiles. They tend to be geared towards attacks of different nature and do not take into account mobility, energy consumption and other physical aspects that are vital to a mobile cyber-physical system. We have developed a decision tree-based method for detecting cyber attacks on a small-scale robotic vehicle using both cyber and physical features that can be measured by its on-board systems and processes. We evaluate it experimentally against a variety of scenarios involving denial of service, command injection and two types of malware attacks. We observe that the addition of physical features noticeably improves the detection accuracy for two of the four attack types and reduces the detection latency for all four. © 2015 IEEE.},
  art_number    = {7363359},
  document_type = {Conference Paper},
  doi           = {10.1109/CIT/IUCC/DASC/PICOM.2015.313},
  groups        = {First Filtering},
  journal       = {Proceedings - 15th IEEE International Conference on Computer and Information Technology, CIT 2015, 14th IEEE International Conference on Ubiquitous Computing and Communications, IUCC 2015, 13th IEEE International Conference on Dependable, Autonomic and Secure Computing, DASC 2015 and 13th IEEE International Conference on Pervasive Intelligence and Computing, PICom 2015},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964257923&doi=10.1109%2fCIT%2fIUCC%2fDASC%2fPICOM.2015.313&partnerID=40&md5=39037b703e9dead76bd5eca16badc0fa},
}

@Conference{Vuong2015,
  author        = {Vuong, T.P. and Loukas, G. and Gan, D. and Bezemskij, A.},
  title         = {Decision tree-based detection of denial of service and command injection attacks on robotic vehicles},
  year          = {2015},
  note          = {cited By 36},
  abstract      = {Mobile cyber-physical systems, such as automobiles, drones and robotic vehicles, are gradually becoming attractive targets for cyber attacks. This is a challenge because intrusion detection systems built for conventional computer systems tend to be unsuitable. They can be too demanding for resource-restricted cyber-physical systems or too inaccurate due to the lack of real-world data on actual attack behaviours. Here, we focus on the security of a small remote-controlled robotic vehicle. Having observed that certain types of cyber attacks against it exhibit physical impact, we have developed an intrusion detection system that takes into account not only cyber input features, such as network traffic and disk data, but also physical input features, such as speed, physical jittering and power consumption. As the system is resource-restricted, we have opted for a decision tree-based approach for generating simple detection rules, which we evaluate against denial of service and command injection attacks. We observe that the addition of physical input features can markedly reduce the false positive rate and increase the overall accuracy of the detection. © 2015 IEEE.},
  art_number    = {7368559},
  document_type = {Conference Paper},
  doi           = {10.1109/WIFS.2015.7368559},
  groups        = {First Filtering},
  journal       = {2015 IEEE International Workshop on Information Forensics and Security, WIFS 2015 - Proceedings},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964751096&doi=10.1109%2fWIFS.2015.7368559&partnerID=40&md5=03180db66f7bb502e6991b1488f2fc0e},
}

@Article{Azhagiri2016,
  author        = {Azhagiri, M. and Rajesh, A.},
  journal       = {International Journal of Control Theory and Applications},
  title         = {A survey on intrusion detection system using fuzzy logic},
  year          = {2016},
  note          = {cited By 0},
  number        = {15},
  pages         = {7517-7522},
  volume        = {9},
  abstract      = {Network security is used to monitor and prevent unauthorized access, exploitation, alteration, or denial of a computer network and network-handy resources. Network security is main issue of computing because many varieties of attacks are growing day by day. Network Security Situational Awareness (NSSA) has been a hot analysis within the network security domain. As a result of the big quantity of Intrusion Detection System (IDS), if clustering is used in KDD Cup 1999 knowledge sets which are grouped into several clusters and the integration of two IDS methods such as C4.5 and ID3 are applied into each clusters as experimental knowledge and comes to a conclusion that our planned methodology is practicable, reliable and economical. © International Science Press.},
  document_type = {Article},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85005939385&partnerID=40&md5=fcb30d5f6a1ce4c58995b94524b49535},
}

@Article{Ceccato2016,
  author        = {Ceccato, M. and Falcarin, P. and Cabutto, A. and Frezghi, Y.W. and Staicu, C.-A.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {Search based clustering for protecting software with diversified updates},
  year          = {2016},
  note          = {cited By 5},
  pages         = {159-175},
  volume        = {9962 LNCS},
  abstract      = {Reverse engineering is usually the stepping stone of a variety of attacks aiming at identifying sensitive information (keys, credentials, data, algorithms) or vulnerabilities and flaws for broader exploitation. Software applications are usually deployed as identical binary code installed on millions of computers, enabling an adversary to develop a generic reverse-engineering strategy that, if working on one code instance, could be applied to crack all the other instances. A solution to mitigate this problem is represented by Software Diversity, which aims at creating several structurally different (but functionally equivalent) binary code versions out of the same source code, so that even if a successful attack can be elaborated for one version, it should not work on a diversified version. In this paper, we address the problem of maximizing software diversity from a search-based optimization point of view. The program to protect is subject to a catalogue of transformations to generate many candidate versions. The problem of selecting the subset of most diversified versions to be deployed is formulated as an optimisation problem, that we tackle with different search heuristics. We show the applicability of this approach on some popular Android apps. © Springer International Publishing AG 2016.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-319-47106-8_11},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989930903&doi=10.1007%2f978-3-319-47106-8_11&partnerID=40&md5=4c72772eae3db6f00b3d28fbb0063e33},
}

@Article{Tsikoudis2016,
  author        = {Tsikoudis, N. and Papadogiannakis, A. and Markatos, E.P.},
  journal       = {IEEE Transactions on Emerging Topics in Computing},
  title         = {LEoNIDS: A Low-Latency and Energy-Efficient Network-Level Intrusion Detection System},
  year          = {2016},
  note          = {cited By 17},
  number        = {1},
  pages         = {142-155},
  volume        = {4},
  abstract      = {Over the past decade, design and implementation of low-power systems has received significant attention. While it started with data centers and battery-operated mobile devices, it has recently branched to core network devices such as routers. However, this emerging need for low-power system design has not been studied for security systems, which are becoming increasingly important today. Toward this direction, we aim to reduce the power consumption of network-level intrusion detection systems (NIDS), which are used to improve the secure operation of modern computer networks. Unfortunately, traditional approaches to low-power system design, such as frequency scaling, lead to a disproportionate increase in packet processing and queuing times. In this paper, we show that this increase has a negative impact on the detection latency and impedes a timely reaction. To address this issue, we present a low-latency and energy-efficient NIDS (LEoNIDS): an architecture that resolves the energy-latency tradeoff by providing both low power consumption and low detection latency at the same time. The key idea is to identify the packets that are more likely to carry an attack and give them higher priority so as to achieve low attack detection latency. Our results indicate that LEoNIDS consumes power comparable to a state-of-the-art low-power design, while, at the same time, achieving up to an order of magnitude faster attack detection. © 2013 IEEE.},
  art_number    = {6977945},
  document_type = {Article},
  doi           = {10.1109/TETC.2014.2369958},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963778729&doi=10.1109%2fTETC.2014.2369958&partnerID=40&md5=7aa2d650bec05b4ea9dccff63fc1eefa},
}

@Article{Amudhavel2016,
  author        = {Amudhavel, J. and Brindha, V. and Anantharaj, B. and Karthikeyan, P. and Bhuvaneswari, B. and Vasanthi, M. and Nivetha, D. and Vinodha, D.},
  journal       = {Indian Journal of Science and Technology},
  title         = {A survey on Intrusion Detection System: State of the art review},
  year          = {2016},
  note          = {cited By 11},
  number        = {11},
  volume        = {9},
  abstract      = {Background/Objectives: To analyze and monitoring the activity of nodes using an IDS Intrusion Detection System which provide security to the system. Findings: In this research, a network building was made with simple node formation with a fitting technique. So that it is easy for a user or beginner to understand the asymptotic dominion factors, due to the wide growth of nodes on network. Intrusion detection system is made of several nodes. These nodes are grouped and combined as a network. Since each node in a network has unique characteristics they may have high chance of attack from malware during the communication between systems. Applications/Improvements: Network of topology is done by creating and connecting various sub networks. Sub networks traffic is cleared and monitored with the package of IDS. It works on synchronous message transfer mode which provides acknowledgement to sender and receiver. All sub networks is managed by its corresponding system and further provide update to the master node on the network. Due to this broadcast of messages all other nodes may be in safe state of avoidance from attacker.},
  art_number    = {89264},
  document_type = {Article},
  doi           = {10.17485/ijst/2016/v9i11/89264},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962836357&doi=10.17485%2fijst%2f2016%2fv9i11%2f89264&partnerID=40&md5=2760db29e4a7f300fdb81cbd81372934},
}

@Conference{Ahmadi2016,
  author        = {Ahmadi, M. and Ulyanov, D. and Semenov, S. and Trofimov, M. and Giacinto, G.},
  title         = {Novel feature extraction, selection and fusion for effective malware family classification},
  year          = {2016},
  note          = {cited By 140},
  pages         = {183-194},
  abstract      = {Modern malware is designed with mutation characteristics, namely polymorphism and metamorphism, which causes an enormous growth in the number of variants of malware samples. Categorization of malware samples on the basis of their behaviors is essential for the computer security community, because they receive huge number of malware everyday, and the signature extraction process is usually based on malicious parts characterizing malware families. Microsoft released a malware classification challenge in 2015 with a huge dataset of near 0.5 terabytes of data, containing more than 20K malware samples. The analysis of this dataset inspired the development of a novel paradigm that is effective in categorizing malware variants into their actual family groups. This paradigm is presented and discussed in the present paper, where emphasis has been given to the phases related to the extraction, and selection of a set of novel features for the effective representation of malware samples. Features can be grouped according to different characteristics of malware behavior, and their fusion is performed according to a perclass weighting paradigm. The proposed method achieved a very high accuracy (≈ 0.998) on the Microsoft Malware Challenge dataset. Copyright 2016 ACM.},
  document_type = {Conference Paper},
  doi           = {10.1145/2857705.2857713},
  groups        = {First Filtering},
  journal       = {CODASPY 2016 - Proceedings of the 6th ACM Conference on Data and Application Security and Privacy},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964884361&doi=10.1145%2f2857705.2857713&partnerID=40&md5=42e5fbc93109fa1add8f4197913ae24c},
}

@Article{Anwar2016b,
  author        = {Anwar, A. and Mahmood, A.N.},
  journal       = {Electric Power Systems Research},
  title         = {Anomaly detection in electric network database of smart grid: Graph matching approach},
  year          = {2016},
  note          = {cited By 11},
  pages         = {51-62},
  volume        = {133},
  abstract      = {Recent studies have shown that the operational modules of an Energy Management System (EMS) are vulnerable to the anomalies that exist in an electric topological and configuration database (DB). In this paper, we focus on the security of EMS modules by detecting anomalies in an electric network DB. Firstly, we explain how an EMS's Optimal Power Flow (OPF) module can be exploited by accidental or deliberate changes in a power system model. As a defense mechanism, for the first time, we propose a graph comparison-based approach for identifying anomalies in an electric network DB. In this study, we formulate the problem as a Quadratic Assignment Problem (QAP) and use the Graduated Assignment algorithm to perform graph matching. To evaluate the effectiveness of the proposed method, we consider different test scenarios considering the IEEE benchmark 24-bus, 30-bus and 118-bus test systems. The results obtained from this analysis show that the proposed method successfully captures DB anomalies at very high detection rates with a smaller time complexity than those obtained from studies published in relevant literature. © 2015 Elsevier B.V. All rights reserved.},
  document_type = {Article},
  doi           = {10.1016/j.epsr.2015.12.006},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952877598&doi=10.1016%2fj.epsr.2015.12.006&partnerID=40&md5=9ab018738d8bc2914af8e79dfaedeb39},
}

@Article{Martinasek2016,
  author        = {Martinasek, Z. and Zeman, V. and Malina, L. and Martinasek, J.},
  journal       = {Radioengineering},
  title         = {k-Nearest Neighbors algorithm in profiling power analysis attacks},
  year          = {2016},
  note          = {cited By 11},
  number        = {2},
  pages         = {365-382},
  volume        = {25},
  abstract      = {Power analysis presents the typical example of successful attacks against trusted cryptographic devices such as RFID (Radio-Frequency IDentifications) and contact smart cards. In recent years, the cryptographic community has explored new approaches in power analysis based on machine learning models such as Support Vector Machine (SVM), RF (Random Forest) and Multi-Layer Perceptron (MLP). In this paper, we made an extensive comparison of machine learning algorithms in the power analysis. For this purpose, we implemented a verification program that always chooses the optimal settings of individual machine learning models in order to obtain the best classification accuracy. In our research, we used three datasets, the first contains the power traces of an unprotected AES (Advanced Encryption Standard) implementation. The second and third datasets are created independently from public available power traces corresponding to a masked AES implementation (DPA Contest v4). The obtained results revealed some interesting facts, namely, an elementary k-NN (k-Nearest Neighbors) algorithm, which has not been commonly used in power analysis yet, shows great application potential in practice.},
  document_type = {Article},
  doi           = {10.13164/re.2016.0365},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015616068&doi=10.13164%2fre.2016.0365&partnerID=40&md5=25cf956aa72525fe9fa8bdcfb2d95e94},
}

@Article{Subba2016,
  author        = {Subba, B. and Biswas, S. and Karmakar, S.},
  journal       = {Engineering Science and Technology, an International Journal},
  title         = {Intrusion detection in Mobile Ad-hoc Networks: Bayesian game formulation},
  year          = {2016},
  note          = {cited By 46},
  number        = {2},
  pages         = {782-799},
  volume        = {19},
  abstract      = {Present Intrusion Detection Systems (IDSs) for MANETs require continuous monitoring which leads to rapid depletion of a node's battery life. To address this issue, we propose a new IDS scheme comprising a novel cluster leader election process and a hybrid IDS. The cluster leader election process uses the Vickrey–Clarke–Groves mechanism to elect the cluster leader which provides the intrusion detection service. The hybrid IDS comprises a threshold based lightweight module and a powerful anomaly based heavyweight module. Initially, only the lightweight module is activated. The decision to activate the heavyweight module is taken by modeling the intrusion detection process as an incomplete information non-cooperative game between the elected leader node and the potential malicious node. Simulation results show that the proposed scheme significantly reduces the IDS traffic and overall power consumption in addition to maintaining a high detection rate and accuracy. © 2016 Karabuk University},
  document_type = {Article},
  doi           = {10.1016/j.jestch.2015.11.001},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010811466&doi=10.1016%2fj.jestch.2015.11.001&partnerID=40&md5=550a3af72a773077c7c8b4d868d668c9},
}

@Conference{Liang2016a,
  author        = {Liang, H. and Ge, Y. and Wang, W. and Chen, L.},
  title         = {Collaborative intrusion detection as a service in cloud computing environment},
  year          = {2016},
  note          = {cited By 5},
  pages         = {476-480},
  abstract      = {With the growing trends of cloud computing, the security issues in this area are growing at the same speed as its development. Some malicious intruders and other malware activities tend to find the inner vulnerabilities and spare no effort to control the administration or conduct the pure break-down service with curiosity or on purpose. Traditional defense systems such as firewall, intrusion detection and malware code system are still utilized in nowadays network scenes, but they may not support enough in cloud computing environment with old-fashioned architectures. Here we focus on intrusion detection system (IDS) to defend against intruders and other attacks. In this paper, we proposed a collaborative intrusion detection service and our goal is to make use of the state-of-the-art computing framework in cloud environment and to provide a rounded IDS service for both cloud providers and cloud tenants, while the collaborative architecture will help to respond to the attacks promptly. We set up our system prototype and discuss the empirical results on the preference. The experimental results demonstrate that our system does enhance the security when some network-based attacks happen and ensure that both cloud service providers and tenants are protected with satisfaction. © 2015 IEEE.},
  art_number    = {7489893},
  document_type = {Conference Paper},
  doi           = {10.1109/PIC.2015.7489893},
  groups        = {First Filtering},
  journal       = {Proceedings of 2015 IEEE International Conference on Progress in Informatics and Computing, PIC 2015},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979658402&doi=10.1109%2fPIC.2015.7489893&partnerID=40&md5=13e1b5c65815176530fc83e2751792e3},
}

@Article{Kudlacik2016,
  author        = {Kudłacik, P. and Porwik, P. and Wesołowski, T.},
  journal       = {Soft Computing},
  title         = {Fuzzy approach for intrusion detection based on user’s commands},
  year          = {2016},
  note          = {cited By 24},
  number        = {7},
  pages         = {2705-2719},
  volume        = {20},
  abstract      = {The article concerns the problem of detecting masqueraders in computer systems. A masquerader in a computer system is an intruder who pretends to be a legitimate user in order to gain access to protected resources. The article presents an intrusion detection method based on a fuzzy approach. Two types of user’s activity profiles are proposed along with the corresponding data structures. The solution analyzes the activity of the computer user in a relatively short period of time, building a user’s profile. The profile is based on the most recent activity of the user, therefore, it is named the local profile. Further analysis involves creating a more general structure based on a defined number of local profiles of one user, called the fuzzy profile. It represents a generalized behavior of the computer system user. The fuzzy profiles are used directly to detect abnormalities in users’ behavior, and thus possible intrusions. The proposed solution is prepared to be able to create user’s profiles based on any countable features derived from user’s actions in computer system (i.e., used commands, mouse and keyboard data, requested network resources). The presented method was tested using one of the commonly available standard intrusion data sets containing command names executed by users of a Unix system. Therefore, the obtained results can be compared with other approaches. The results of the experiments have shown that the method presented in this article is comparable with the best intrusion detection methods, tested with the same data set, in the matter of the obtained results. The proposed solution is characterized by a very low computational complexity, which has been confirmed by experimental results. © 2015, Springer-Verlag Berlin Heidelberg.},
  document_type = {Article},
  doi           = {10.1007/s00500-015-1669-6},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926197606&doi=10.1007%2fs00500-015-1669-6&partnerID=40&md5=fae796a752d152d04865c008dc7d6242},
}

@Article{Vasudevan2016,
  author        = {Vasudevan, A.R. and Selvakumar, S.},
  journal       = {Frontiers of Computer Science},
  title         = {Local outlier factor and stronger one class classifier based hierarchical model for detection of attacks in network intrusion detection dataset},
  year          = {2016},
  note          = {cited By 8},
  number        = {4},
  pages         = {755-766},
  volume        = {10},
  abstract      = {Identification of attacks by a network intrusion detection system (NIDS) is an important task. In signature or rule based detection, the previously encountered attacks are modeled, and signatures/rules are extracted. These rules are used to detect such attacks in future, but in anomaly or outlier detection system, the normal network traffic is modeled. Any deviation from the normal model is deemed to be an outlier/ attack. Data mining and machine learning techniques are widely used in offline NIDS. Unsupervised and supervised learning techniques differ the way NIDS dataset is treated. The characteristic features of unsupervised and supervised learning are finding patterns in data, detecting outliers, and determining a learned function for input features, generalizing the data instances respectively. The intuition is that if these two techniques are combined, better performance may be obtained. Hence, in this paper the advantages of unsupervised and supervised techniques are inherited in the proposed hierarchical model and devised into three stages to detect attacks in NIDS dataset. NIDS dataset is clustered using Dirichlet process (DP) clustering based on the underlying data distribution. Iteratively on each cluster, local denser areas are identified using local outlier factor (LOF) which in turn is discretized into four bins of separation based on LOF score. Further, in each bin the normal data instances are modeled using one class classifier (OCC). A combination of Density Estimation method, Reconstruction method, and Boundary methods are used for OCC model. A product rule combination of the threemethods takes into consideration the strengths of each method in building a stronger OCC model. Any deviation from this model is considered as an attack. Experiments are conducted on KDD CUP’99 and SSENet-2011 datasets. The results show that the proposed model is able to identify attacks with higher detection rate and low false alarms. © 2016, Higher Education Press and Springer-Verlag Berlin Heidelberg.},
  document_type = {Article},
  doi           = {10.1007/s11704-015-5116-8},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964389331&doi=10.1007%2fs11704-015-5116-8&partnerID=40&md5=18846d5645aef116e8d51a0df5fcf6d4},
}

@Conference{Kumar2016,
  author        = {Kumar, P. and Singh, K. and Singh, N. and Tomar, D.S.},
  title         = {An Unsupervised Signature Generation Approach to Detect Email Bombing Using DBSCAN Clustering},
  year          = {2016},
  note          = {cited By 0},
  pages         = {1038-1045},
  abstract      = {Network attack is a form of intelligent and sophisticated crimes in the web environment. Network based attacks are increasing at fast speed to hamper the smooth working of web resources. New style of Network attacks is a growing amount of indirect attacks that exploit network traffic, instead of directly manipulating a network resource. In recent time, damages from indirect attack are estimated to be more severe. In addition, the bandwidth utilization by these attacks manipulates the whole network performance. In proposed work, a novel Email bombing signature is generated and furthers the generated signature is used for detecting mass mailing attack in the network traffic. The proposed approach deployed Rule Based Filtering and DBSCAN Clustering technique for filtering out enormous unwanted network traffic and group the similar data instances respectively. The proposed approach may restrain and prevent circulation of mass-mailing attacks in the network. © 2015 IEEE.},
  art_number    = {7546255},
  document_type = {Conference Paper},
  doi           = {10.1109/CICN.2015.206},
  groups        = {First Filtering},
  journal       = {Proceedings - 2015 International Conference on Computational Intelligence and Communication Networks, CICN 2015},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985943471&doi=10.1109%2fCICN.2015.206&partnerID=40&md5=6b58e31df67954930d268fc0ce760575},
}

@Conference{Yang2016,
  author        = {Yang, X. and Zhang, X. and Lin, J. and Yu, W. and Zhao, P.},
  title         = {A Gaussian-mixture model based detection scheme against data integrity attacks in the smart grid},
  year          = {2016},
  note          = {cited By 12},
  abstract      = {In the smart grid, the Advanced Metering Infrastructure (AMI) will be deployed to monitor and control the power grid by integrating both computing and networking components to achieve stable and efficient operation. The AMI is vulnerable to cyber attacks, especially in the form of data integrity attacks. A number of research efforts have been devoted to detecting such attacks. Nonetheless, the majority of existing schemes either rely on a pre-defined threshold, or require external knowledge. This leaves open the possibility for low detection accuracy when the threshold is improperly defined, and where there is a lack of the requisite external knowledge. To address this issue, in this paper we propose a Gaussian-Mixture Model-based Detection (GMMD) scheme to combat data integrity attacks. Not relying upon the pre-defined threshold or external knowledge, our scheme operates by narrowing the range of normal data that can be obtained by clustering the historical data and learning the minimum and maximum values of individual clusters. To validate the effectiveness of our scheme, we conduct performance evaluation based on the ElectricityLoadDiagrams20112014 data set, and analyze the effectiveness of the proposed scheme with respect to detection accuracy.The results of our investigation demonstrate that our scheme can achieve a higher detection rate, and lower error rate, in comparison with existing schemes based on the Min-Max model. © 2016 IEEE.},
  art_number    = {7568478},
  document_type = {Conference Paper},
  doi           = {10.1109/ICCCN.2016.7568478},
  groups        = {First Filtering},
  journal       = {2016 25th International Conference on Computer Communications and Networks, ICCCN 2016},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991764305&doi=10.1109%2fICCCN.2016.7568478&partnerID=40&md5=bcfdbdf0859eaae64c2715e099143597},
}

@Conference{Kirchler2016,
  author        = {Kirchler, M. and Herrmann, D. and Lindemann, J. and Kloft, M.},
  title         = {Tracked without a trace: Linking sessions of users by unsupervised learning of patterns in their DNS traffic},
  year          = {2016},
  note          = {cited By 15},
  pages         = {23-34},
  abstract      = {Behavior-based tracking is an unobtrusive technique that allows observers to monitor user activities on the Internet over long periods of time - in spite of changing IP addresses. Previous work has employed supervised classifiers in order to link the sessions of individual users. However, classifiers need labeled training sessions, which are difficult to obtain for observers. In this paper we show how this limitation can be overcome with an unsupervised learning technique. We present a modified k-means algorithm and evaluate it on a realistic dataset that contains the Domain Name System (DNS) queries of 3,862 users. For this purpose, we simulate an observer that tries to track all users, and an Internet Service Provider that assigns a different IP address to every user on every day. The highest tracking accuracy is achieved within the subgroup of highly active users. Almost all sessions of 73% of the users in this subgroup can be linked over a period of 56 days. 19% of the highly active users can be traced completely, i. e., all their sessions are assigned to a single cluster. This fraction increases to 40% for shorter periods of seven days. As service providers may engage in behavior-based tracking to complement their existing profiling efforts, it constitutes a severe privacy threat for users of online services. Users can defend against behavior-based tracking by changing their IP address frequently, but this is cumbersome at the moment.},
  document_type = {Conference Paper},
  doi           = {10.1145/2996758:2996770},
  groups        = {First Filtering},
  journal       = {AISec 2016 - Proceedings of the 2016 ACM Workshop on Artificial Intelligence and Security, co-located with CCS 2016},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002410876&doi=10.1145%2f2996758%3a2996770&partnerID=40&md5=95f25c08a3ce01de4528401ce9957741},
}

@Conference{Schindler2017,
  author        = {Schindler, T.},
  title         = {Anomaly detection in log data using graph databases and machine learning to defend advanced persistent threats},
  year          = {2017},
  note          = {cited By 3},
  pages         = {2371-2378},
  volume        = {275},
  abstract      = {Advanced Persistent Threats (APTs) are a main impendence in cyber security of computer networks. In 2015, a successful breach remains undetected 146 days on average, reported by [Fi16]. With our work we demonstrate a feasible and fast way to analyse real world log data to detect breaches or breach attempts. By adapting well-known kill chain mechanisms and a combine of a time series database and an abstracted graph approach, it is possible to create flexible attack profiles. Using this approach, it can be demonstrated that the graph analysis successfully detects simulated attacks by analysing the log data of a simulated computer network. Considering another source for log data, the framework is capable to deliver sufficient performance for analysing real-world data in short time. By using the computing power of the graph database it is possible to identify the attacker and furthermore it is feasible to detect other affected system components. We believe to significantly reduce the detection time of breaches with this approach and react fast to new attack vectors. © 2017 Gesellschaft fur Informatik (GI). All rights reserved.},
  document_type = {Conference Paper},
  doi           = {10.18420/in2017_241},
  groups        = {First Filtering},
  journal       = {Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062496709&doi=10.18420%2fin2017_241&partnerID=40&md5=fdc6a402bb52ca3a7bdf03c37c2f3b1a},
}

@Conference{Rigaki2017,
  author        = {Rigaki, M. and Elragal, A.},
  title         = {Adversarial deep learning against intrusion detection classifiers},
  year          = {2017},
  note          = {cited By 0},
  pages         = {35-48},
  volume        = {2057},
  abstract      = {Traditional approaches in network intrusion detection follow a signature-based approach, however the use of anomaly detection approaches and machine learning techniques have been studied heavily for the past twenty years. The continuous change in the way attacks are appearing, the volume of attacks, as well as the improvements in the big data analytics space, make machine learning approaches more alluringthan ever. The intention of this paper is to show that using machine learning in the intrusion detection domain should be accompanied with an evaluation of its robustness against adversaries. Several adversarial techniques have emerged lately from the deep learning research, largely in the area of image classification. These techniques are based on the idea of introducing small changes in the original input data in order to make a machine learning model to misclassify it. This paper follows a big data analytics methodology and explores adversarial machine learning techniques that have emerged from the deep learning domain, against machine learning classifiers used for network intrusion detection. We look at several well-known classifiers and study their performance under attack over several metrics, such as accuracy, F1-score and receiver operating characteristic. The approach used assumes no knowledge of the original classifier and examines both general and targeted misclassification. The results showthat using relatively simple methods for generating adversarial samples it is possible to lower the detection accuracy of intrusion detection classifiers as much as 27%. Performance degradation is achieved using a methodology that is simpler than previous approaches and it requires only 6.14% change between the original and the adversarial sample, making it a candidate for a practical adversarial approach. © 2017 CEUR-WS. All rights reserved.},
  document_type = {Conference Paper},
  groups        = {First Filtering},
  journal       = {CEUR Workshop Proceedings},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042448945&partnerID=40&md5=c7ea7fd1211fcda88ed3241242271206},
}

@Article{Iturbe2017,
  author        = {Iturbe, M. and Garitano, I. and Zurutuza, U. and Uribeetxeberria, R.},
  journal       = {Security and Communication Networks},
  title         = {Towards Large-Scale, Heterogeneous Anomaly Detection Systems in Industrial Networks: A Survey of Current Trends},
  year          = {2017},
  note          = {cited By 7},
  volume        = {2017},
  abstract      = {Industrial Networks (INs) are widespread environments where heterogeneous devices collaborate to control and monitor physical processes. Some of the controlled processes belong to Critical Infrastructures (CIs), and, as such, IN protection is an active research field. Among different types of security solutions, IN Anomaly Detection Systems (ADSs) have received wide attention from the scientific community. While INs have grown in size and in complexity, requiring the development of novel, Big Data solutions for data processing, IN ADSs have not evolved at the same pace. In parallel, the development of Big Data frameworks such as Hadoop or Spark has led the way for applying Big Data Analytics to the field of cyber-security, mainly focusing on the Information Technology (IT) domain. However, due to the particularities of INs, it is not feasible to directly apply IT security mechanisms in INs, as IN ADSs face unique characteristics. In this work we introduce three main contributions. First, we survey the area of Big Data ADSs that could be applicable to INs and compare the surveyed works. Second, we develop a novel taxonomy to classify existing IN-based ADSs. And, finally, we present a discussion of open problems in the field of Big Data ADSs for INs that can lead to further development. © 2017 Mikel Iturbe et al.},
  art_number    = {9150965},
  document_type = {Review},
  doi           = {10.1155/2017/9150965},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039172403&doi=10.1155%2f2017%2f9150965&partnerID=40&md5=ee35c9774bdb1b20e91cb8d830636c79},
}

@Article{Barriga2017,
  author        = {Barriga, J.J.A. and Yoo, S.G.},
  journal       = {International Journal of Applied Engineering Research},
  title         = {Malware detection and evasion with machine learning techniques: A survey},
  year          = {2017},
  note          = {cited By 8},
  number        = {18},
  pages         = {7207-7214},
  volume        = {12},
  abstract      = {Malware has become a powerful and sophisticated tool used by malicious users to compromise and harm systems, and its evasion ability has improved considerably, getting to the point of becoming completely undetectable. On the other hand, machine learning has evolved tremendously in last years and it has become a standard in many IT solutions including the data processing field. Likewise, cryptography also has growth in popularity in providing confidentiality and integrity to important information. Even though those technologies are being widely used for trustable IT solutions, they also are used by malicious applications such as ransomware, which uses the cryptography as its infecting mechanism and the machine learning as its evasion technique. In this aspect, this paper makes a survey of existing researches regarding to malware detection and evasion by examining possible scenarios where malware could take advantage of machine learning and cryptography to improve its evasion techniques and infection impact. © Research India Publications.},
  document_type = {Article},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036655096&partnerID=40&md5=7fbdb8ef8f9363a2326f79fe560a7375},
}

@Conference{Sailor2017,
  author        = {Sailor, H.B. and Kamble, M.R. and Patil, H.A.},
  title         = {Unsupervised representation learning using convolutional restricted boltzmann machine for spoof speech detection},
  year          = {2017},
  note          = {cited By 3},
  pages         = {2601-2605},
  volume        = {2017-August},
  abstract      = {Speech Synthesis (SS) and Voice Conversion (VC) presents a genuine risk of attacks for Automatic Speaker Verification (ASV) technology. In this paper, we use our recently proposed unsupervised filterbank learning technique using Convolutional Restricted Boltzmann Machine (ConvRBM) as a frontend feature representation. ConvRBM is trained on training subset of ASV spoof 2015 challenge database. Analyzing the filterbank trained on this dataset shows that ConvRBM learned more low-frequency subband filters compared to training on natural speech database such as TIMIT. The spoofing detection experiments were performed using Gaussian Mixture Models (GMM) as a back-end classifier. ConvRBM-based cepstral coefficients (ConvRBM-CC) perform better than hand crafted Mel Frequency Cepstral Coefficients (MFCC). On the evaluation set, ConvRBM-CC features give an absolute reduction of 4.76 % in Equal Error Rate (EER) compared to MFCC features. Specifically, ConvRBM-CC features significantly perform better in both known attacks (1.93 %) and unknown attacks (5.87 %) compared to MFCC features. Copyright © 2017 ISCA.},
  document_type = {Conference Paper},
  doi           = {10.21437/Interspeech.2017-1393},
  groups        = {First Filtering},
  journal       = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036478334&doi=10.21437%2fInterspeech.2017-1393&partnerID=40&md5=eb057558304c28c5d380ad89c2f74511},
}

@Article{AlJanabi2017,
  author        = {Al-Janabi, S.},
  journal       = {Communications in Computer and Information Science},
  title         = {Pragmatic miner to risk analysis for intrusion detection (PMRA-ID)},
  year          = {2017},
  note          = {cited By 29},
  pages         = {263-277},
  volume        = {788},
  abstract      = {Security of information systems and their connecting networks has become a primary focus given that pervasive cyber-attacks against information systems are geometrically increasing. Intrusion Detection and Prevention Systems (IDPS) effectively secure the data, storage devices and the systems holding them. We will build system consist of five steps: (a) description the orders that required to archives the event by five fuzzy concepts as input and three fuzzy concepts as output, then save it in temporal bank of orders, (b) Pre-processing that order by convert from the description to numerical values and compute the Membership function for that values. (c) applied the association data mining techniques on these database after compute the correlation among their features, this lead to generation thirty two rules but not all this rules is salsify the confidence measures (i.e., we take only the rules that satisfy the purity 100%) (d) Building the Confusion matrix for all the samples using in training processing (e) Testing the Pragmatic Miner to Risk Analysis (PMRA) model and verification from the accuracy of their results by press new samples to model not used in training stage then compute the values of error and accuracy measures, in addition of correct. The existing systems employing firewalls and encryptions for data protection are getting outdated. IDPS provides a much improved detection system that can prevent the intrusions to attack the system. However, as effective as it is in preventing intrusions, which can disrupt the retrieval of desired information as the system sometimes perceives it as an attack. The base aim of this work is to determine a way to risk analysis of IDPS to an acceptable level while detecting the intrusions and maintaining effective security of a system. Experimental results clearly show the superficiality of the proposed model against the conventional IDPS system. © Springer Nature Singapore Pte Ltd. 2017.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-981-10-7242-0_23},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036454862&doi=10.1007%2f978-981-10-7242-0_23&partnerID=40&md5=c93f9866caefbd27c4026fe79076446a},
}

@Article{Tran2017,
  author        = {Tran, B. and Picek, S. and Xue, B.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {Automatic feature construction for network intrusion detection},
  year          = {2017},
  note          = {cited By 2},
  pages         = {569-580},
  volume        = {10593 LNCS},
  abstract      = {The notion of cyberspace became impossible to separate from the notions of cyber threat and cyberattack. Since cyberattacks are getting easier to run, they are also becoming more serious threats from the economic damage perspective. Consequently, we are evident of a continuous adversarial relationship between the attackers trying to mount as powerful as possible attacks and defenders trying to stop the attackers in their goals. To defend against such attacks, defenders have at their disposal a plethora of techniques but they are often falling behind the attackers due to the fact that they need to protect the whole system while the attacker needs to find only a single weakness to exploit. In this paper, we consider one type of a cyberattack – network intrusion – and investigate how to use feature construction via genetic programming in order to improve the intrusion detection accuracy. The obtained results show that feature construction offers improvements in a number of tested scenarios and therefore should be considered as an important step in defense efforts. Such improvements are especially apparent in scenario with the highly unbalanced data, which also represents the most interesting case from the defensive perspective. © Springer International Publishing AG 2017.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-319-68759-9_46},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034219055&doi=10.1007%2f978-3-319-68759-9_46&partnerID=40&md5=86775f3cd7ff65af4a04077c3f68e8d1},
}

@Article{Demertzis2017,
  author        = {Demertzis, K. and Iliadis, L. and Spartalis, S.},
  journal       = {Communications in Computer and Information Science},
  title         = {A spiking one-class anomaly detection framework for cyber-security on industrial control systems},
  year          = {2017},
  note          = {cited By 15},
  pages         = {122-134},
  volume        = {744},
  abstract      = {Developments and upgrades in the field of industrial information technology, particularly those relating to information systems’ technologies for the collection and processing of real-time data, have introduced a large number of new threats. These threats are primarily related to the specific tasks these applications perform, such as their distinct design specifications, the specialized communication protocols they use and the heterogeneous devices they are required to interconnect. In particular, specialized attacks can undertake mechanical control, dynamic rearrangement of centrifugation or reprogramming of devices in order to accelerate or slow down their operations. This may result in total industrial equipment being destroyed or permanently damaged. Cyber-attacks against Industrial Control Systems which mainly use Supervisory Control and Data Acquisition (SCADA) combined with Distributed Control Systems are implemented with Programmable Logic Controllers. They are characterized as Advanced Persistent Threats. This paper presents an advanced Spiking One-Class Anomaly Detection Framework (SOCCADF) based on the evolving Spiking Neural Network algorithm. This algorithm implements an innovative application of the One-class classification methodology since it is trained exclusively with data that characterize the normal operation of ICS and it is able to detect divergent behaviors and abnormalities associated with APT attacks. © Springer International Publishing AG 2017.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-319-65172-9_11},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028325048&doi=10.1007%2f978-3-319-65172-9_11&partnerID=40&md5=e95b1ddd01e935eed2a603a03d8ad5eb},
}

@Conference{Dang2017,
  author        = {Dang, Y. and Wang, B. and Brant, R. and Zhang, Z. and Alqallaf, M. and Wu, Z.},
  title         = {Anomaly detection for data streams in large-scale distributed heterogeneous computing environments},
  year          = {2017},
  note          = {cited By 5},
  pages         = {121-130},
  abstract      = {Counteracting cyber threats to ensure secure cyberspace faces great challenges as cyber-attacks are increasingly stealthy and sophisticated; the protected cyber domains exhibit rapidly growing complexity and scale. It is important to design big data-driven cyber security solutions that effectively and efficiently derive actionable intelligence from available heterogeneous sources of information using principled data analytic methods to defend against cyber threats. In this work, we present a scalable distributed framework to collect and process extreme-scale networking and computing system traffic and status data from multiple sources that collectively represent the system under study, and develop and apply real-time adaptive data analytics for anomaly detection to monitor, understand, maintain, and improve cybersecurity. The data analytics will integrate multiple sophisticated machine learning algorithms and human-in-the-loop for iterative ensemble learning. Given the volume, speed, and complex nature of the data gathered, plus the need of real-time data analytics, a scalable data processing framework needs to handle big data with low latency. Our proposed big-data analytics will be implemented using an Apache Spark computing cluster. The analytics developed will offer significant improvements over existing methods of anomaly detection in real time. Our preliminary evaluation studies have shown that the developed techniques achieve better capabilities of defending against cyber threats.},
  document_type = {Conference Paper},
  groups        = {First Filtering},
  journal       = {Proceedings of the 12th International Conference on Cyber Warfare and Security, ICCWS 2017},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018961044&partnerID=40&md5=76c86fd0dcdb8e6020ec3240aa026156},
}

@Article{Aminanto2017,
  author        = {Aminanto, M.E. and Kim, H. and Kim, K.-M. and Kim, K.},
  journal       = {IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences},
  title         = {Another fuzzy anomaly detection system based on ant clustering algorithm},
  year          = {2017},
  note          = {cited By 18},
  number        = {1},
  pages         = {176-183},
  volume        = {E100A},
  abstract      = {Attacks against computer networks are evolving rapidly. Conventional intrusion detection system based on pattern matching and static signatures have a significant limitation since the signature database should be updated frequently. The unsupervised learning algorithm can overcome this limitation. Ant Clustering Algorithm (ACA) is a popular unsupervised learning algorithm to classify data into different categories. However, ACA needs to be complemented with other algorithms for the classification process. In this paper, we present a fuzzy anomaly detection system that works in two phases. In the first phase, the training phase, we propose ACA to determine clusters. In the second phase, the classification phase, we exploit a fuzzy approach by the combination of two distance- based methods to detect anomalies in new monitored data. We validate our hybrid approach using the KDD Cup'99 dataset. The results indicate that, compared to several traditional and new techniques, the proposed hybrid approach achieves higher detection rate and lower false positive rate. © Copyright 2017 The Institute of Electronics, Information and Communication Engineers.},
  document_type = {Conference Paper},
  doi           = {10.1587/transfun.E100.A.176},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008343612&doi=10.1587%2ftransfun.E100.A.176&partnerID=40&md5=435ae5b76431fef174fdf136d975190a},
}

@Article{Viegas2017,
  author        = {Viegas, E. and Santin, A.O. and Franca, A. and Jasinski, R. and Pedroni, V.A. and Oliveira, L.S.},
  journal       = {IEEE Transactions on Computers},
  title         = {Towards an energy-efficient anomaly-based intrusion detection engine for embedded systems},
  year          = {2017},
  note          = {cited By 51},
  number        = {1},
  pages         = {163-177},
  volume        = {66},
  abstract      = {Nowadays, a significant part of all network accesses comes from embedded and battery-powered devices, which must be energy efficient. This paper demonstrates that a hardware (HW) implementation of network security algorithms can significantly reduce their energy consumption compared to an equivalent software (SW) version. The paper has four main contributions: (i) a new feature extraction algorithm, with low processing demands and suitable for hardware implementation; (ii) a feature selection method with two objectives - accuracy and energy consumption; (iii) detailed energy measurements of the feature extraction engine and three machine learning (ML) classifiers implemented in SW and HW - Decision Tree (DT), Naive-Bayes (NB), and k-Nearest Neighbors (kNN); and (iv) a detailed analysis of the tradeoffs in implementing the feature extractor and ML classifiers in SW and HW. The new feature extractor demands significantly less computational power, memory, and energy. Its SW implementation consumes only 22 percent of the energy used by a commercial product and its HW implementation only 12 percent. The dual-objective feature selection enabled an energy saving of up to 93 percent. Comparing the most energy-efficient SW implementation (new extractor and DT classifier) with an equivalent HW implementation, the HW version consumes only 5.7 percent of the energy used by the SW version. © 1968-2012 IEEE.},
  art_number    = {7463065},
  document_type = {Article},
  doi           = {10.1109/TC.2016.2560839},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007018423&doi=10.1109%2fTC.2016.2560839&partnerID=40&md5=eb4262a66e1fce5046fd80700ba1eabb},
}

@Article{Genge2017,
  author        = {Genge, B. and Haller, P. and Kiss, I.},
  journal       = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
  title         = {Big data processing to detect abnormal behavior in smart grids},
  year          = {2017},
  note          = {cited By 0},
  pages         = {214-221},
  volume        = {175},
  abstract      = {This paper proposes a methodology to effectively detect abnormal behavior in Smart Grids. The approach uses a cyber attack impact assessment technique to rank different assets, a cross-association decomposition technique for grouping assets and ultimately to reduce the number of monitored parameters, and an anomaly detection system based on the Gaussian clustering technique. The developed methodology is evaluated in the context of the IEEE 14-bus electricity grid model and three distinct classes of cyber attacks: bus fault attacks, line breaker attacks, and integrity attacks. © ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2017.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-319-47729-9_22},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997531321&doi=10.1007%2f978-3-319-47729-9_22&partnerID=40&md5=ed147cc181bc29aac3ec136175d8a3a0},
}

@Article{Mishra2017,
  author        = {Mishra, P. and Pilli, E.S. and Varadharajan, V. and Tupakula, U.},
  journal       = {Journal of Network and Computer Applications},
  title         = {Intrusion detection techniques in cloud environment: A survey},
  year          = {2017},
  note          = {cited By 95},
  pages         = {18-47},
  volume        = {77},
  abstract      = {Security is of paramount importance in this new era of on-demand Cloud Computing. Researchers have provided a survey on several intrusion detection techniques for detecting intrusions in the cloud computing environment. Most of them provide a discussion over traditional misuse and anomaly detection techniques. Virtual Machine Introspection (VMI) techniques are very helpful in detecting various stealth attacks targeting user-level and kernel-level processes running in virtual machines (VMs) by placing the analyzing component outside the VM generally at hypervisor. Hypervisor Introspection (HVI) techniques ensure the hypervisor security and prevent a compromised hypervisor to launch further attacks on VMs running over it. Introspection techniques introspect the hypervisor by using hardware-assisted virtualization-enabled technologies. The main focus of our paper is to provide an exhaustive literature survey of various Intrusion Detection techniques proposed for cloud environment with an analysis of their attack detection capability. We propose a threat model and attack taxonomy in cloud environment to elucidate the vulnerabilities in cloud. Our taxonomy of IDS techniques represent the state of the art classification and provides a detailed study of techniques with their distinctive features. We have provided a deep insight into Virtual Machine Introspection (VMI) and Hypervisor Introspection (HVI) based techniques in the survey. Specific research challenges are identified to give future direction to researchers. We hope that our work will enable researchers to launch and dive deep into intrusion detection approaches in a cloud environment. © 2016 Elsevier Ltd},
  document_type = {Review},
  doi           = {10.1016/j.jnca.2016.10.015},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995427026&doi=10.1016%2fj.jnca.2016.10.015&partnerID=40&md5=4de6a842c695c7159009f1e58516f148},
}

@Conference{Bezemskij2017,
  author        = {Bezemskij, A. and Loukas, G. and Anthony, R.J. and Gan, D.},
  title         = {Behaviour-Based Anomaly Detection of Cyber-Physical Attacks on a Robotic Vehicle},
  year          = {2017},
  note          = {cited By 17},
  pages         = {61-68},
  abstract      = {Security is one of the key challenges in cyberphysical systems, because by their nature, any cyber attack against them can have physical repercussions. This is a critical issue for autonomous vehicles; if compromised in terms of their communications or computation they can cause considerable physical damage due to their mobility. Our aim here is to facilitate the automatic detection of cyber attacks on a robotic vehicle. For this purpose, we have developed a detection mechanism, which monitors real-time data from a large number of sources onboard the vehicle, including its sensors, networks and processing. Following a learning phase, where the vehicle is trained in a non-attack state on what values are considered normal, it is then subjected to a series of different cyber-physical and physical-cyber attacks. We approach the problem as a binary classification problem of whether the robot is able to self-detect when and whether it is under attack. Our experimental results show that the approach is promising for most attacks that the vehicle is subjected to. We further improve its performance by using weights that accentuate the anomalies that are less common thus improving overall performance of the detection mechanism for unknown attacks. © 2016 IEEE.},
  art_number    = {7828584},
  document_type = {Conference Paper},
  doi           = {10.1109/IUCC-CSS.2016.017},
  groups        = {First Filtering},
  journal       = {Proceedings - 2016 15th International Conference on Ubiquitous Computing and Communications and 2016 8th International Symposium on Cyberspace and Security, IUCC-CSS 2016},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015154069&doi=10.1109%2fIUCC-CSS.2016.017&partnerID=40&md5=9bfdfc51a7914615fcdafcd4a2d7d219},
}

@Article{Inayat2017,
  author        = {Inayat, Z. and Gani, A. and Anuar, N.B. and Anwar, S. and Khan, M.K.},
  journal       = {Arabian Journal for Science and Engineering},
  title         = {Cloud-Based Intrusion Detection and Response System: Open Research Issues, and Solutions},
  year          = {2017},
  note          = {cited By 17},
  number        = {2},
  pages         = {399-423},
  volume        = {42},
  abstract      = {Mobile cloud computing (MCC) allows smart mobile devices (SMD) to access the cloud resources in order to offload data from smartphones and to acquire computational services for application processing. A distinctive factor in accessing cloud resources is the communication link. However, the communication links between SMD and cloud resources are weak, which allows intruders to perform malicious activities by exploiting their vulnerabilities. This makes security a key challenge in the MCC environment. Several intrusion detection and response systems (IDRSs) are adapted to address the exploitation of vulnerabilities that affect smartphones, communication links between cloud resources and smartphones, as well as cloud resources. In this article, we discuss the cloud-based IDRS in the context of SMD and cloud resources in the MCC infrastructure. The stringent security requirements are provided as open issues along with possible solutions. The article aims at providing motivations for researchers, academicians, security administrators, and cloud service providers to discover mechanisms, frameworks, standards, and protocols to address the challenges faced by cloud-based IDRS for SMD. © 2017, King Fahd University of Petroleum & Minerals.},
  document_type = {Review},
  doi           = {10.1007/s13369-016-2400-3},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012201636&doi=10.1007%2fs13369-016-2400-3&partnerID=40&md5=01682c181433f64a232a34ccdd4bec7f},
}

@Article{Huda2017,
  author        = {Huda, S. and Miah, S. and Mehedi Hassan, M. and Islam, R. and Yearwood, J. and Alrubaian, M. and Almogren, A.},
  journal       = {Information Sciences},
  title         = {Defending unknown attacks on cyber-physical systems by semi-supervised approach and available unlabeled data},
  year          = {2017},
  note          = {cited By 44},
  pages         = {211-228},
  volume        = {379},
  abstract      = {Cyber-physical systems (CPS) are used increasingly in modern industrial systems. These systems currently encounter a significant threat of malicious activities created by malicious software intent on exploiting the fact that the software of such industrial systems is integrated with hardware and network systems. Malicious codes dynamically and continuously change their internal structure and attack patterns using obfuscation techniques, such as polymorphism and metamorphism, in order to bypass and hide from conventional malware detection engines. This requires continuously updating the database of the malware detection engine, which requires periodic effort from manual experts. This could limit the real-time protection of CPS. In addition, this also makes preserving the availability and integrity of the services provided by CPS against malicious code challenging because there is a demand for the development of specialized malware detection techniques for CPS. In this paper, we propose a semi-supervised approach that automatically integrates the knowledge about unknown malware from already available and cheap unlabeled data into the detection system. The novelty of the proposed approach is that it does not require expert effort to update the database of the detection engine. Instead, the dynamic changes in malware attack patterns are extracted by unsupervised clustering from already available unlabeled data. Then the extracted geometric information about the intrinsic attack characteristics of the clusters is integrated into the classification systems of the detection engine, which updates the detection system automatically. The proposed approach uses global K-means clustering with term-frequency (TF), inverse document frequency (IDF), and cosine similarity as a distance measure for extracting the cluster information and adding it to a support vector machine (SVM) classification system. The proposed approach has been tested extensively on a real malware data set for both static and dynamic malware features. The experiment results show that the proposed semi-supervised approach achieves higher accuracy over the existing supervised approaches for all classifiers. We note that the static feature-based semi-supervised approach can improve detection accuracy significantly. While applying the proposed semi-supervised approach with the run-time characteristics of dynamic feature analysis, the combined effect of dynamic analysis and the proposed approach further increases the detection accuracy of all classifiers by up to a 100% for the SVM and the random forest classifiers, thus exceeding the existing supervised approaches with similar features. © 2016 Elsevier Inc.},
  document_type = {Article},
  doi           = {10.1016/j.ins.2016.09.041},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996526106&doi=10.1016%2fj.ins.2016.09.041&partnerID=40&md5=d352ebdd9a332f3a6748cc75b5d1f0a1},
}

@Article{Modi2017,
  author        = {Modi, C.N. and Acha, K.},
  journal       = {Journal of Supercomputing},
  title         = {Virtualization layer security challenges and intrusion detection/prevention systems in cloud computing: a comprehensive review},
  year          = {2017},
  note          = {cited By 34},
  number        = {3},
  pages         = {1192-1234},
  volume        = {73},
  abstract      = {Virtualization plays a vital role in the construction of cloud computing. However, various vulnerabilities are existing in current virtualization implementations, and thus there are various security challenges at virtualization layer. In this paper, we investigate different vulnerabilities and attacks at virtualization layer of cloud computing. We examine the proposals of cloud intrusion detection system (IDS) and intrusion detection and prevention system frameworks. We recommend the cloud IDS requirements and research scope to achieve desired level of security at virtualization layer of cloud computing. © 2016, Springer Science+Business Media New York.},
  document_type = {Article},
  doi           = {10.1007/s11227-016-1805-9},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978884505&doi=10.1007%2fs11227-016-1805-9&partnerID=40&md5=3818337312aef0e7fa8f3c3dd7c636b0},
}

@Article{Loukas2017,
  author        = {Loukas, G. and Yoon, Y. and Sakellari, G. and Vuong, T. and Heartfield, R.},
  journal       = {Simulation Modelling Practice and Theory},
  title         = {Computation offloading of a vehicle's continuous intrusion detection workload for energy efficiency and performance},
  year          = {2017},
  note          = {cited By 10},
  pages         = {83-94},
  volume        = {73},
  abstract      = {Computation offloading has been used and studied extensively in relation to mobile devices. That is because their relatively limited processing power and reliance on a battery render the concept of offloading any processing/energy-hungry tasks to a remote server, cloudlet or cloud infrastructure particularly attractive. However, the mobile device's tasks that are typically offloaded are not time-critical and tend to be one-off. We argue that the concept can be practical also for continuous tasks run on more powerful cyber-physical systems where timeliness is a priority. As case study, we use the process of real-time intrusion detection on a robotic vehicle. Typically, such detection would employ lightweight statistical learning techniques that can run onboard the vehicle without severely affecting its energy consumption. We show that by offloading this task to a remote server, we can utilse approaches of much greater complexity and detection strength based on deep learning. We show both mathematically and experimentally that this allows not only greater detection accuracy, but also significant energy savings, which improve the operational autonomy of the vehicle. In addition, the overall detection latency is reduced in most of our experiments. This can be very important for vehicles and other cyber-physical systems where cyber attacks can directly affect physical safety. In fact, in some cases, the reduction in detection latency thanks to offloading is not only beneficial but necessary. An example is when detection latency onboard the vehicle would be higher than the detection period, and as a result a detection run cannot complete before the next one is scheduled, increasingly delaying consecutive detection decisions. Offloading to a remote server is an effective and energy-efficient solution to this problem too. © 2016 Elsevier B.V.},
  document_type = {Article},
  doi           = {10.1016/j.simpat.2016.08.005},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995376610&doi=10.1016%2fj.simpat.2016.08.005&partnerID=40&md5=b32f798df67f901e7c1030f4ef5a4131},
}

@Conference{Chaipa2017,
  author        = {Chaipa, S. and Eloff, M.M.},
  title         = {Towards the development of an effective intrusion detection model},
  year          = {2017},
  note          = {cited By 2},
  pages         = {32-39},
  volume        = {2018-January},
  abstract      = {Intrusion detection systems (IDSs) are an important component of information security. The challenge with current versions has be en the high numb er of fa lse positive and f alse negative alerts they generate. The aim of this paper is the analysis of current intrusion detection systems and the Common Intrusion Detection Framework (CIDF) model for any weaknesses through a detailed literature review. The result is a proposed model which addresses these weaknesses. The weaknesses are ad dressed through the inclusion of data r eduction algorithms in e very component which is seen as key to reducing the amount of data being processed or analysed by the proposed IDS model, thereby increasing the processing speed. The introduction of a parallel analysis process which employs misuse-, anomaly-and specification-based detection approaches may also e nhance the detection accuracy of the proposed model. The paper concludes with a call to the IDS develo pment community to try out the proposed model. © 2017 IEEE.},
  document_type = {Conference Paper},
  doi           = {10.1109/ISSA.2017.8251772},
  groups        = {First Filtering},
  journal       = {2017 Information Security for South Africa - Proceedings of the 2017 ISSA Conference},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049649925&doi=10.1109%2fISSA.2017.8251772&partnerID=40&md5=945915fb76c86ce1bef0c3d79b116933},
}

@Article{Zhang2017,
  author        = {Zhang, H. and Zhu, S. and Ma, X. and Zhao, J. and Shou, Z.},
  journal       = {IEICE Transactions on Information and Systems},
  title         = {A novel RNN-GBRBM based feature decoder for anomaly detection technology in industrial control network},
  year          = {2017},
  note          = {cited By 7},
  number        = {8},
  pages         = {1780-1789},
  volume        = {E100D},
  abstract      = {As advances in networking technology help to connect industrial control networks with the Internet, the threat from spammers, attackers and criminal enterprises has also grown accordingly. However, traditional Network Intrusion Detection System makes significant use of pattern matching to identify malicious behaviors and have bad performance on detecting zero-day exploits in which a new attack is employed. In this paper, a novel method of anomaly detection in industrial control network is proposed based on RNN-GBRBM feature decoder. The method employ network packets and extract high-quality features from raw features which is selected manually. A modified RNN-RBM is trained using the normal traffic in order to learn feature patterns of the normal network behaviors. Then the test traffic is analyzed against the learned normal feature pattern by using osPCA to measure the extent to which the test traffic resembles the learned feature pattern. Moreover, we design a semi-supervised incremental updating algorithm in order to improve the performance of the model continuously. Experiments show that our method is more efficient in anomaly detection than other traditional approaches for industrial control network. Copyright © 2017 The Institute of Electronics, Information and Communication Engineers.},
  document_type = {Conference Paper},
  doi           = {10.1587/transinf.2016ICP0005},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026544875&doi=10.1587%2ftransinf.2016ICP0005&partnerID=40&md5=4727983e24e7a61cdebd85900de3d3d3},
}

@Article{Ming2017,
  author        = {Ming, J. and Xin, Z. and Lan, P. and Wu, D. and Liu, P. and Mao, B.},
  journal       = {Journal of Computer Virology and Hacking Techniques},
  title         = {Impeding behavior-based malware analysis via replacement attacks to malware specifications},
  year          = {2017},
  note          = {cited By 11},
  number        = {3},
  pages         = {193-207},
  volume        = {13},
  abstract      = {As the underground market of malware flourishes, there is an exponential increase in the number and diversity of malware. A crucial question in malware analysis research is how to define malware specifications or signatures that faithfully describe similar malicious intent and also clearly stand out from other programs. Although the traditional malware specifications based on syntactic signatures are efficient, they can be easily defeated by various obfuscation techniques. Since the malicious behavior is often stable across similar malware instances, behavior-based specifications which capture real malicious characteristics during run time, have become more prevalent in anti-malware tasks, such as malware detection and malware clustering. This kind of specification is typically extracted from the system call dependence graph that a malware sample invokes. In this paper, we present replacement attacks to camouflage similar behaviors by poisoning behavior-based specifications. The key method of our attacks is to replace a system call dependence graph to its semantically equivalent variants so that the similar malware samples within one family turn out to be different. As a result, malware analysts have to put more efforts into reexamining the similar samples which may have been investigated before. We distil general attacking strategies by mining more than 5200 malware samples’ behavior specifications and implement a compiler-level prototype to automate replacement attacks. Experiments on 960 real malware samples demonstrate the effectiveness of our approach to impede various behavior-based malware analysis tasks, such as similarity comparison and malware clustering. In the end, we also discuss possible countermeasures in order to strengthen existing malware defense. © 2016, Springer-Verlag France.},
  document_type = {Article},
  doi           = {10.1007/s11416-016-0281-3},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973626395&doi=10.1007%2fs11416-016-0281-3&partnerID=40&md5=ef670bed015ef0f54926217cf3084ae4},
}

@Conference{Rigatos2017a,
  author        = {Rigatos, G. and Serpanos, D. and Zervos, N. and Siano, P.},
  title         = {Kalman filtering and statistical decision making for detection of attacks against power grid sensors},
  year          = {2017},
  note          = {cited By 0},
  pages         = {1921-1926},
  abstract      = {Kalman Filtering and statistical decision making criteria are used to develop a systematic method for the detection of attacks against sensors of the power grid. To emulate the functioning of the grid's sensors in the fault-free mode, the Kalman Filter is used as a virtual sensor. By comparing the output of the Kalman Filter against the output of the real sensors, the resulting differences generate the residuals' sequence. By weighting the square of the residuals' vector with the inverse of the associated covariance matrix a random variable is defined which is shown to follow the χ2 distribution. This variable provides a statistical test about the deviation of the sensors functioning from the normal mode. Moreover, by exploiting the properties of the χ2 distribution and by using the confidence intervals approach, one can define thresholds against which the value of the statistical test is compared. In case that these thresholds are exceeded by the value of the statistical test then it can be inferred that the sensors' functioning is abnormal. Additionally, sections of the power grid which have been exposed to the attack can be identified by applying the statistical test on clusters of sensors. Actually, by applying the statistical test at each individual sensor one can isolate the compromised sensors. Finally, one can estimate the additive disturbance inputs that affect the sensors by redesigning the Kalman Filter as a disturbance observer. This may provide an indication on whether the deviation of the sensors functioning from normal has been the result of an attack to the grid by intruders. © 2017 IEEE.},
  art_number    = {8001544},
  document_type = {Conference Paper},
  doi           = {10.1109/ISIE.2017.8001544},
  groups        = {First Filtering},
  journal       = {IEEE International Symposium on Industrial Electronics},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029900881&doi=10.1109%2fISIE.2017.8001544&partnerID=40&md5=0421ea82600f9e2572153c2e3a0738b6},
}

@Article{Rosenberg2017,
  author        = {Rosenberg, I. and Gudes, E.},
  journal       = {Concurrency Computation},
  title         = {Bypassing system calls–based intrusion detection systems},
  year          = {2017},
  note          = {cited By 7},
  number        = {16},
  volume        = {29},
  abstract      = {Machine learning augments today's intrusion detection system (IDS) capability to cope with unknown malware. However, if an attacker gains partial knowledge about the IDS' classifier, he can create a modified version of his malware, which can evade detection. In this article we present an IDS on the basis of various classifiers using system calls, executed by the inspected code as features. We then present a camouflage algorithm that is used to modify malicious code to be classified as benign, while preserving the code's functionality, for decision tree and random forest classifiers. We also present transformations to the classifier's input, to prevent this camouflage - and a modified camouflage algorithm that overcomes those transformations. Our research shows that it is not enough to provide a decision tree based classifier with a large training set to counter malware. One must also be aware of the possibility that the classifier would be fooled by a camouflage algorithm, and try to counter such an attempt with techniques such as input transformation or training set updates. Copyright © 2016 John Wiley & Sons, Ltd.},
  art_number    = {e4023},
  document_type = {Conference Paper},
  doi           = {10.1002/cpe.4023},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85004109103&doi=10.1002%2fcpe.4023&partnerID=40&md5=b1a2e5953ab7bab457409b513d0abc90},
}

@Conference{Kreimel2017,
  author        = {Kreimel, P. and Eigner, O.},
  title         = {Anomaly-based detection & classification of attacks in cyber-physical systems},
  year          = {2017},
  note          = {cited By 4},
  volume        = {Part F130521},
  abstract      = {Cyber-physical systems are found in industrial and production systems, as well as critical infrastructures. Due to the increasing integration of IP-based technology and standard computing devices, the threat of cyber-attacks on cyber-physical systems has vastly increased. Furthermore, traditional intrusion defense strategies for IT systems are often not applicable in operational environments. In this paper we present an anomaly-based approach for detection and classification of attacks in cyber-physical systems. To test our approach, we set up a test environment with sensors, actuators and controllers widely used in industry, thus, providing system data as close as possible to reality. First, anomaly detection is used to define a model of normal svstem behavior by calculating outlier scores from normal system operations. This valid behavior model is then compared with new data in order to detect anomalies. Further, we trained an attack model, based on supervised attacks against the test setup, using the naive Bayes classifier. If an anomaly is detected, the classification process tries to classify the anomaly by applying the attack model and calculating prediction confidences for trained classes. To evaluate the statistical performance of our approach, we tested the model by applying an unlabeled dataset, which contains valid and anomalous data. The results show that this approach was able to detect and classify such attacks with satisfactory accuracy. © 2017 ACM.},
  art_number    = {a40},
  document_type = {Conference Paper},
  doi           = {10.1145/3098954.3103155},
  groups        = {First Filtering},
  journal       = {ACM International Conference Proceeding Series},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030324049&doi=10.1145%2f3098954.3103155&partnerID=40&md5=36c81c0e52b6ca400be67f5fc67c3b9f},
}

@Conference{Viegas2017a,
  author        = {Viegas, E. and Santin, A. and Abreu, V. and Oliveira, L.S.},
  title         = {Stream learning and anomaly-based intrusion detection in the adversarial settings},
  year          = {2017},
  note          = {cited By 6},
  pages         = {773-778},
  abstract      = {Despite existing many anomaly-based intrusion detection studies in the literature, they are not frequently adopted by the industry in production environments (products). Such a usage gap occurs mainly due to the difficulty to maintain the detection rate in acceptable level, given the occurrence of false alarms. In general, the literature does not consider the adversarial settings, when an opponent attempt to evade the detection system, thus possibly rendering the system unreliable over time. In this paper, we propose and evaluate a new approach to reliably perform real time stream learning for anomaly-based intrusion detection. We employ a class-specific stream outlier detector to automatically update the intrusion detection engine over the time, and a rejection mechanism, which makes it possible to obtain indications that an evasion attempt might being happening. Furthermore, the proposal is resilient to causative attacks, providing a secure intrusion detection mechanism even when the attacker can inject misclassified instances in the training dataset. The evaluation tests show that the proposed approach is resilient to exploratory attacks, allowing the system administrator to know when an evasion attempt might be occurring. © 2017 IEEE.},
  art_number    = {8024621},
  document_type = {Conference Paper},
  doi           = {10.1109/ISCC.2017.8024621},
  groups        = {First Filtering},
  journal       = {Proceedings - IEEE Symposium on Computers and Communications},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030571271&doi=10.1109%2fISCC.2017.8024621&partnerID=40&md5=c77fe63fe95e6eb0c618aa06138893e8},
}

@Article{Umer2017,
  author        = {Umer, M.F. and Sher, M. and Bi, Y.},
  journal       = {Computers and Security},
  title         = {Flow-based intrusion detection: Techniques and challenges},
  year          = {2017},
  note          = {cited By 62},
  pages         = {238-254},
  volume        = {70},
  abstract      = {Flow-based intrusion detection is an innovative way of detecting intrusions in high-speed networks. Flow-based intrusion detection only inspects the packet header and does not analyze the packet payload. This paper provides a comprehensive survey of current state of the art in flow-based intrusion detection. It also describes the available flow-based datasets used for evaluation of flow-based intrusion detection systems. The paper proposes a taxonomy for flow-based intrusion detection systems on the basis of the technique used for detection of maliciousness in flow records. We review the architecture and evaluation results of available flow-based intrusion detection systems. We also identify important research challenges for future research in the area of flow-based intrusion detection. © 2017 Elsevier Ltd},
  document_type = {Review},
  doi           = {10.1016/j.cose.2017.05.009},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021098423&doi=10.1016%2fj.cose.2017.05.009&partnerID=40&md5=b16c4b5ee9de23cf614f8ff65c684dbc},
}

@Conference{Siadati2017,
  author        = {Siadati, H. and Memon, N.},
  title         = {Detecting structurally anomalous logins within enterprise networks},
  year          = {2017},
  note          = {cited By 14},
  pages         = {1273-1284},
  abstract      = {Many network intrusion detection systems use byte sequences to detect lateral movements that exploit remote vulnerabilities. Attackers bypass such detection by stealing valid credentials and using them to transmit from one computer to another without creating abnormal network traffic. We call this method Credential-based Lateral Movement. To detect this type of lateral movement, we develop the concept of a Network Login Structure that specifies normal logins within a given network. Our method models a network login structure by automatically extracting a collection of login patterns by using a variation of the market-basket analysis algorithm. We then employ an anomaly detection approach to detect malicious logins that are inconsistent with the enterprise network's login structure. Evaluations show that the proposed method is able to detect malicious logins in a real setting. In a simulated attack, our system was able to detect 82% of malicious logins, with a 0.3% false positive rate. We used a real dataset of millions of logins over the course of five months within a global financial company for evaluation of this work. © 2017 author(s).},
  document_type = {Conference Paper},
  doi           = {10.1145/3133956.3134003},
  groups        = {First Filtering},
  journal       = {Proceedings of the ACM Conference on Computer and Communications Security},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041441305&doi=10.1145%2f3133956.3134003&partnerID=40&md5=03d1e5ca4412054aaa5e40ef544c01d4},
}

@Conference{Hitaj2017,
  author        = {Hitaj, B. and Ateniese, G. and Perez-Cruz, F.},
  title         = {Deep Models under the GAN: Information leakage from collaborative deep learning},
  year          = {2017},
  note          = {cited By 216},
  pages         = {603-618},
  abstract      = {Deep Learning has recently become hugely popular in machine learning for its ability to solve end-to-end learning systems, in which the features and the classifiers are learned simultaneously, providing significant improvements in classification accuracy in the presence of highly-structured and large databases. Its success is due to a combination of recent algorithmic breakthroughs, increasingly powerful computers, and access to significant amounts of data. Researchers have also considered privacy implications of deep learning. Models are typically trained in a centralized manner with all the data being processed by the same training algorithm. If the data is a collection of users' private data, including habits, personal pictures, geographical positions, interests, and more, the centralized server will have access to sensitive information that could potentially be mishandled. To tackle this problem, collaborative deep learning models have recently been proposed where parties locally train their deep learning structures and only share a subset of the parameters in the attempt to keep their respective training sets private. Parameters can also be obfuscated via differential privacy (DP) to make information extraction even more challenging, as proposed by Shokri and Shmatikov at CCS'15. Unfortunately, we show that any privacy-preserving collaborative deep learning is susceptible to a powerful attack that we devise in this paper. In particular, we show that a distributed, federated, or decentralized deep learning approach is fundamentally broken and does not protect the training sets of honest participants. The attack we developed exploits the real-time nature of the learning process that allows the adversary to train a Generative Adversarial Network (GAN) that generates prototypical samples of the targeted training set that was meant to be private (the samples generated by the GAN are intended to come from the same distribution as the training data). Interestingly, we show that record-level differential privacy applied to the shared parameters of the model, as suggested in previous work, is ineffective (i.e., record-level DP is not designed to address our attack). © 2017 author(s).},
  document_type = {Conference Paper},
  doi           = {10.1145/3133956.3134012},
  groups        = {First Filtering},
  journal       = {Proceedings of the ACM Conference on Computer and Communications Security},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041437863&doi=10.1145%2f3133956.3134012&partnerID=40&md5=4b0a269b0460b84279de891ac936ddef},
}

@Article{Mohammadpourfard2017,
  author        = {Mohammadpourfard, M. and Sami, A. and Seifi, A.},
  journal       = {Expert Systems with Applications},
  title         = {A statistical unsupervised method against false data injection attacks: A visualization-based approach},
  year          = {2017},
  note          = {cited By 27},
  pages         = {242-261},
  volume        = {84},
  abstract      = {To achieve intelligence in the future grid, a highly accurate state estimation is necessary as it is a prerequisite for many key functionalities in the successful operation of the power grid. Recent studies show that a new type of cyber-attack called False Data Injection (FDI) attack can bypass bad data detection mechanisms in the power system state estimation. Existing countermeasures might not be able to manage topology changes and integration of distributed generations because they are designed for a specific system configuration. To address this issue, an unsupervised method to distinguish between attack and normal patterns is proposed in this paper. This method can detect FDI attacks even after topology changes and integration of renewable energy sources. In this method, we assume that injecting false data into the power systems will lead to a deviation in the probability distribution of the state vector from the normal trend. The main phases of the proposed algorithm are: (1) Normalizing the dataset, (2) Adding several statistical measures as the new features to the dataset to quantify the probability distribution of the state vectors, (3) Employing principal component analysis to reduce the dimensionality of the dataset, (4) Visualizing the reduced data for humans and exploiting their creativity to detect attacks, and (5) Locating the attacks using Fuzzy C-means clustering algorithm. The proposed method is tested on both the IEEE 14-bus and IEEE 9-bus systems using real load data from the New York independent system operator with the following attack scenarios: (1) attacks without any topology change, (2) attacks after a contingency, and (3) attacks after integration of distributed generations. Experimental results show that our proposed method is superior to the state-of-the-art classification algorithms in dealing with changes. In addition, the reduced data which is helpful in distinguishing between attack and normal patterns can be fed into an expert system for further improvement of the security of the power grid. © 2017 Elsevier Ltd},
  document_type = {Article},
  doi           = {10.1016/j.eswa.2017.05.013},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019112492&doi=10.1016%2fj.eswa.2017.05.013&partnerID=40&md5=03e94e6100edd1903a61bd49f195802f},
}

@Conference{Sandor2017,
  author        = {Sandor, H. and Genge, B. and Haller, P. and Duka, A.-V. and Crainicu, B.},
  title         = {Cross-layer anomaly detection in industrial cyber-physical systems},
  year          = {2017},
  note          = {cited By 4},
  abstract      = {Within the frame of the fourth industrial revolution, also known as Industry 4.0, industrial cyber-physical production systems (ICPS) have experienced a significant progress. To this end, Industry 4.0 has brought upon an improved, flexible, and cost-efficient system architecture that can sustain the development of innovative applications and services. Nonetheless, this technological advancement also exposed ICPS to significant cyber threats. This paper contributes to the development of a cross-layer anomaly detection system (ADS) for ICPS by defining a lightweight detection methodology that leverages Dempster-Shafer's 'Theory of Evidence' in order to: infer the system's state; fuse evidence from a wide range of monitored parameters; and deliver a comprehensive and scalable detection system. The proposed approach is validated in the context of a real natural gas transportation installation. © 2017 University of Split, FESB.},
  art_number    = {8115523},
  document_type = {Conference Paper},
  doi           = {10.23919/SOFTCOM.2017.8115523},
  groups        = {First Filtering},
  journal       = {2017 25th International Conference on Software, Telecommunications and Computer Networks, SoftCOM 2017},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041310163&doi=10.23919%2fSOFTCOM.2017.8115523&partnerID=40&md5=52b98027c28d8a9dcde1d9b2d6debbac},
}

@Conference{Keshk2017,
  author        = {Keshk, M. and Moustafa, N. and Sitnikova, E. and Creech, G.},
  title         = {Privacy preservation intrusion detection technique for SCADA systems},
  year          = {2017},
  note          = {cited By 19},
  pages         = {1-6},
  volume        = {2017-December},
  abstract      = {Supervisory Control and Data Acquisition (SCADA) systems face the absence of a protection technique that can beat different types of intrusions and protect the data from disclosure while handling this data using other applications, specifically Intrusion Detection System (IDS). The SCADA system can manage the critical infrastructure of industrial control environments. Protecting sensitive information is a difficult task to achieve in reality with the connection of physical and digital systems. Hence, privacy preservation techniques have become effective in order to protect sensitive/private information and to detect malicious activities, but they are not accurate in terms of error detection, sensitivity percentage of data disclosure. In this paper, we propose a new Privacy Preservation Intrusion Detection (PPID) technique based on the correlation coefficient and Expectation Maximisation (EM) clustering mechanisms for selecting important portions of data and recognizing intrusive events. This technique is evaluated on the power system datasets for multiclass attacks to measure its reliability for detecting suspicious activities. The experimental results outperform three techniques in the above terms, showing the efficiency and effectiveness of the proposed technique to be utilized for current SCADA systems. © 2017 IEEE.},
  document_type = {Conference Paper},
  doi           = {10.1109/MilCIS.2017.8190422},
  groups        = {First Filtering},
  journal       = {2017 Military Communications and Information Systems Conference, MilCIS 2017 - Proceedings},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047227020&doi=10.1109%2fMilCIS.2017.8190422&partnerID=40&md5=5edbb867c6526c78c631500504b591c8},
}

@Conference{Zhang2017a,
  author        = {Zhang, N. and Zhang, R. and Yan, Q. and Lou, W. and Hou, Y.T. and Yao, D.},
  title         = {Black penguin: On the feasibility of detecting intrusion with homogeneous memory},
  year          = {2017},
  note          = {cited By 0},
  pages         = {586-594},
  volume        = {2017-January},
  abstract      = {Growing complexity in modern software is making signature-based intrusion detection an increasing challenge. Many recent intrusion detection systems rely on accurate recovery of application semantics from memory. In this paper, we approach the problem from a different angle. We observe that the user applications in corporate network often run in identical system environments due to standardized IT deployment procedure. The same applications share similar runtime statistics across different workstations through out the time, despite different uses by the end users. When an application is compromised on one workstation, its runtime profile would be different from the rest, similar to how a black penguin would look distinctly different from the rest of the colony. In this work, we present our preliminary study on Black Penguin, a compare-view based intrusion detection system leveraging homogeneity of application-level memory statistics in corporate environment. The detection system follows a three-step process that includes memory analysis, unsupervised learning and risk mitigation. To explore the feasibility of Black Penguin, we conduct two types of experiments using Internet Explorer and Firefox as target applications. First, we examine the statistical differences of the same application under different user usage. To this end, we collect and analyze memory statistics of browser when visiting the top 500 websites ranked by Moz. Second, we examine the difference when the application is under attack. Several browser attacks are used to generate the intrusion samples. Our preliminary evaluation demonstrates the feasibility of the approach. Lastly, we also provide discussions on the limitations of the proposed system as well as future directions. © 2017 IEEE.},
  document_type = {Conference Paper},
  doi           = {10.1109/CNS.2017.8228671},
  groups        = {First Filtering},
  journal       = {2017 IEEE Conference on Communications and Network Security, CNS 2017},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046680565&doi=10.1109%2fCNS.2017.8228671&partnerID=40&md5=47a7b6634cd4b1cd1cf29460c769eb0e},
}

@Conference{Han2018,
  author        = {Han, X. and Pasquier, T. and Seltzer, M.},
  title         = {Provenance-based intrusion detection: Opportunities and challenges},
  year          = {2018},
  note          = {cited By 11},
  abstract      = {Intrusion detection is an arms race; attackers evade intrusion detection systems by developing new attack vectors to sidestep known defense mechanisms. Provenance provides a detailed, structured history of the interactions of digital objects within a system. It is ideal for intrusion detection, because it offers a holistic, attack-vector-agnostic view of system execution. As such, provenance graph analysis fundamentally strengthens detection robustness. We discuss the opportunities and challenges associated with provenance-based intrusion detection and provide insights based on our experience building such systems. © 2018 Copyright held by the owner/author(s).},
  document_type = {Conference Paper},
  groups        = {First Filtering},
  journal       = {TaPP 2018 - 10th USENIX Workshop on the Theory and Practice of Provenance},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081159835&partnerID=40&md5=83d1f3a870a565d084276f74be67672c},
}

@Conference{Zheng2018,
  author        = {Zheng, Z. and Hong, P.},
  title         = {Robust detection of adversarial attacks by modeling the intrinsic properties of deep neural networks},
  year          = {2018},
  note          = {cited By 11},
  pages         = {7913-7922},
  volume        = {2018-December},
  abstract      = {It has been shown that deep neural network (DNN) based classifiers are vulnerable to human-imperceptive adversarial perturbations which can cause DNN classifiers to output wrong predictions with high confidence. We propose an unsupervised learning approach to detect adversarial inputs without any knowledge of attackers. Our approach tries to capture the intrinsic properties of a DNN classifier and uses them to detect adversarial inputs. The intrinsic properties used in this study are the output distributions of the hidden neurons in a DNN classifier presented with natural images. Our approach can be easily applied to any DNN classifiers or combined with other defense strategies to improve robustness. Experimental results show that our approach demonstrates state-of-the-art robustness in defending black-box and gray-box attacks. © 2018 Curran Associates Inc.All rights reserved.},
  document_type = {Conference Paper},
  groups        = {First Filtering},
  journal       = {Advances in Neural Information Processing Systems},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064804649&partnerID=40&md5=f390fb99b96103d6e7bd08953a0ad071},
}

@Conference{DiazRedondo2018,
  author        = {Diaz Redondo, R.P. and Fernandez Vilas, A.},
  title         = {Smart grids monitoring: A fog-computing strategy to detect anomalies},
  year          = {2018},
  note          = {cited By 1},
  abstract      = {Smart meters with enhanced capabilities of communication and control will contribute to adapt and tune energy delivery more efficiently. However, this opens the door to new threats that should be early detected in order to execute the countermeasure processes as soon as possible. According to this, unexpected changes in the energy consumption (among other aspects) must be monitorized since they also be the evidence that something wrong is happening. In this paper, we introduce a fog computing approach that supports a distributed analysis of the consumption data and also establishes the bases for a location certification mechanism that avoid the injection of false data in the smart grid monitoring system. © 2018 IEEE.},
  art_number    = {8659884},
  document_type = {Conference Paper},
  doi           = {10.1109/RTUCON.2018.8659884},
  groups        = {First Filtering},
  journal       = {2018 IEEE 59th Annual International Scientific Conference on Power and Electrical Engineering of Riga Technical University, RTUCON 2018 - Proceedings},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063487970&doi=10.1109%2fRTUCON.2018.8659884&partnerID=40&md5=5d26520a578b97d5cc251b207257c72d},
}

@Article{Bravo2018,
  author        = {Bravo, S. and Mauricio, D.},
  journal       = {International Journal of Online Engineering},
  title         = {New features of user's behavior to distributed denial of service attacks detection in application layer},
  year          = {2018},
  note          = {cited By 0},
  number        = {12},
  pages         = {164-178},
  volume        = {14},
  abstract      = {Distributed Denial of Service (DDoS) attacks are a threat to the security of red. In recent years, these attacks have been directed especially towards the application layer. This phenomenon is mainly due to the large number of existing tools for the generation of this type of attack. The highest detection rate achieved by a method in the application capacity is 98.5%. Therefore, the problem of detecting DDoS attacks persists. In this work an alternative of detection based on the dynamism of the web user is proposed. To do this, evaluate the user's characteristics, mouse functions and right click. For the evaluation, a data set of 11055 requests was used, from which the characteristics were extracted and entered into a classification algorithm. To that end, it can be applied once in Java for the classification of real users and DDoS attacks. The results showed that the evaluated characteristics achieved an efficiency of 100%. Therefore, it is concluded that these characteristics show the dynamism of the user and can be used in a detection method of DDoS attacks. © 2018 Kassel University Press GmbH.},
  document_type = {Article},
  doi           = {10.3991/ijoe.v14i12.9439},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059542714&doi=10.3991%2fijoe.v14i12.9439&partnerID=40&md5=cefc057ac420bc56f720eb9d3ceb09da},
}

@Article{Joelle2018,
  author        = {Joëlle, M.M. and Park, Y.-H.},
  journal       = {Journal of Intelligent and Fuzzy Systems},
  title         = {Strategies for detecting and mitigating DDoS attacks in SDN: A survey},
  year          = {2018},
  note          = {cited By 3},
  number        = {6},
  pages         = {5913-5925},
  volume        = {35},
  abstract      = {Software Defined Networking (SDN) is an emerging paradigm, which brings the network innovation and attracts both the industries and researchers. SDN is a programmable network model that separates the control logic from the forwarding plane. The centralize control plane takes care of all networking resources. The attackers target the SDN controller, to paralyze the logic plane that is considered as the brain of the network which provides a lot of benefits. However, due to the characteristics the control plane becomes the attractive target of security attacks for the adversaries. One of the most known threats is Distributed Denial-of-Service (DDoS) attacks with the goal to exhausting network resources by sending heavy traffic to them, causing network congestion. Since SDN was proposed, DDoS attack has become a popular research field in SDN security and many researchers have been presented DDoS attacks detection, prevention and mitigation solutions in SDN environment using different methods. This paper surveys the previous researches in DDoS attacks detection and mitigation based methods available in SDN environment. © 2018 - IOS Press and the authors. All rights reserved.},
  document_type = {Conference Paper},
  doi           = {10.3233/JIFS-169833},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059443122&doi=10.3233%2fJIFS-169833&partnerID=40&md5=922260182325b1d6599991a5266edd4e},
}

@Article{Preuveneers2018,
  author        = {Preuveneers, D. and Rimmer, V. and Tsingenopoulos, I. and Spooren, J. and Joosen, W. and Ilie-Zudor, E.},
  journal       = {Applied Sciences (Switzerland)},
  title         = {Chained anomaly detection models for federated learning: An intrusion detection case study},
  year          = {2018},
  note          = {cited By 29},
  number        = {12},
  volume        = {8},
  abstract      = {The adoption of machine learning and deep learning is on the rise in the cybersecurity domain where these AI methods help strengthen traditional system monitoring and threat detection solutions. However, adversaries too are becoming more effective in concealing malicious behavior amongst large amounts of benign behavior data. To address the increasing time-to-detection of these stealthy attacks, interconnected and federated learning systems can improve the detection of malicious behavior by joining forces and pooling together monitoring data. The major challenge that we address in this work is that in a federated learning setup, an adversary has many more opportunities to poison one of the local machine learning models with malicious training samples, thereby influencing the outcome of the federated learning and evading detection. We present a solution where contributing parties in federated learning can be held accountable and have their model updates audited. We describe a permissioned blockchain-based federated learning method where incremental updates to an anomaly detection machine learning model are chained together on the distributed ledger. By integrating federated learning with blockchain technology, our solution supports the auditing of machine learning models without the necessity to centralize the training data. Experiments with a realistic intrusion detection use case and an autoencoder for anomaly detection illustrate that the increased complexity caused by blockchain technology has a limited performance impact on the federated learning, varying between 5 and 15%, while providing full transparency over the distributed training process of the neural network. Furthermore, our blockchain-based federated learning solution can be generalized and applied to more sophisticated neural network architectures and other use cases. © 2018 by the authors.},
  art_number    = {2663},
  document_type = {Article},
  doi           = {10.3390/app8122663},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058632406&doi=10.3390%2fapp8122663&partnerID=40&md5=074488b426934db018229f1f3afba68d},
}

@Conference{Ros2018,
  author        = {Ros, A.S. and Doshi-Velez, F.},
  title         = {Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients},
  year          = {2018},
  note          = {cited By 100},
  pages         = {1660-1669},
  abstract      = {Deep neural networks have proven remarkably effective at solving many classification problems, but have been criticized recently for two major weaknesses: the reasons behind their predictions are uninterpretable, and the predictions themselves can often be fooled by small adversarial perturbations. These problems pose major obstacles for the adoption of neural networks in domains that require security or transparency. In this work, we evaluate the effectiveness of defenses that differentiably penalize the degree to which small changes in inputs can alter model predictions. Across multiple attacks, architectures, defenses, and datasets, we find that neural networks trained with this input gradient regularization exhibit robustness to transferred adversarial examples generated to fool all of the other models. We also find that adversarial examples generated to fool gradient-regularized models fool all other models equally well, and actually lead to more “legitimate,” interpretable misclassifications as rated by people (which we confirm in a human subject experiment). Finally, we demonstrate that regularizing input gradients makes them more naturally interpretable as rationales for model predictions. We conclude by discussing this relationship between interpretability and robustness in deep neural networks. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
  document_type = {Conference Paper},
  groups        = {First Filtering},
  journal       = {32nd AAAI Conference on Artificial Intelligence, AAAI 2018},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057345011&partnerID=40&md5=eb82fab92d99b8e2bc2b2ad755e5d01a},
}

@Conference{Wang2018,
  author        = {Wang, Y. and Jha, S. and Chaudhuri, K.},
  title         = {Analyzing the robustness of nearest neighbors to adversarial examples},
  year          = {2018},
  note          = {cited By 15},
  pages         = {8132-8147},
  volume        = {11},
  abstract      = {Motivated by safety-critical applications, test-time attacks on classifiers via adversarial examples has recently received a great deal of attention. However, there is a general lack of understanding on why adversarial examples arise; whether they originate due to inherent properties of data or due to lack of training samples remains ill-understood. In this work, we introduce a theoretical framework analogous to bias-variance theory for understanding these effects. We use our framework to analyze the robustness of a canonical non-parametric classifier - the k-nearest neighbors. Our analysis shows that its robustness properties depend critically on the value of k - the classifier may be inherently non-robust for small k, but its robustness approaches that of the Bayes Optimal classifier for fast-growing k. We propose a novel modified 1-nearest neighbor classifier, and guarantee its robustness in the large sample limit. Our experiments suggest that this classifier may have good robustness properties even for reasonable data set sizes. Copyright 2018 by the author(s). © 2018 by the Authors All rights reserved.},
  document_type = {Conference Paper},
  groups        = {First Filtering},
  journal       = {35th International Conference on Machine Learning, ICML 2018},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057321166&partnerID=40&md5=8b9115a7359e72ce02ccc27b57f9c154},
}

@Article{Besharati2018,
  author        = {Besharati, E. and Naderan, M. and Namjoo, E.},
  journal       = {Journal of Ambient Intelligence and Humanized Computing},
  title         = {LR-HIDS: logistic regression host-based intrusion detection system for cloud environments},
  year          = {2018},
  note          = {cited By 14; Article in Press},
  abstract      = {Cloud computing is an Internet based computing environment, where storage and computing resources are assigned dynamically among users according to their needs, using the virtualization technology. Virtualization is an underlying infrastructure of cloud computing, and has led to certain security problems during the development of cloud computing. One essential but formidable task in cloud computing is to detect malicious attacks and their types. Due to increasing incidents of cyber-attacks, design and implementation of effective intrusion detection systems to protect the security of information systems is crucial. In this paper, a host-based intrusion detection system (H-IDS) for protecting virtual machines in the cloud environment is proposed. To this end, first, important features of each class are selected using logistic regression and next, these values are improved using the regularization technique. Then, various attacks are classified using a combination of three different classifiers: neural network, decision tree and linear discriminate analysis with the bagging algorithm for each class. The proposed model has been trained and tested using the NSL-KDD data set with an implementation in the Cloudsim software. Simulation results compared to other methods shows acceptable accuracy of about 97.51 for detecting attacks against normal states. © 2018, Springer-Verlag GmbH Germany, part of Springer Nature.},
  document_type = {Article in Press},
  doi           = {10.1007/s12652-018-1093-8},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055353753&doi=10.1007%2fs12652-018-1093-8&partnerID=40&md5=4b6e990e7da69a704b574abaf97e5906},
}

@Article{Gore2018,
  author        = {Gore, R. and Diallo, S.Y. and Padilla, J. and Ezell, B.},
  journal       = {International Journal of Information and Computer Security},
  title         = {Assessing cyber-incidents using machine learning},
  year          = {2018},
  note          = {cited By 1},
  number        = {4},
  pages         = {341-360},
  volume        = {10},
  abstract      = {One of the difficulties in effectively analysing and combating cyber attacks is an inability to identify when, why and how they occur. Victim organisations do not reveal this data for fear of disclosing vulnerabilities and attackers do not reveal themselves for fear of being prosecuted. In this paper, we employ two machine-learning algorithms to identify: 1) if a text-based report is related to a cyber-incident; 2) the topic within the field of cyber-security the incident report addresses. First, we evaluate the effectiveness of our approach using a benchmark set of cyber-incident reports from 2006. Then, we assess the current state of cyber-security by applying our approach to a 2014 set of cyber-incident reports we gathered. Ultimately, our results show that the combination of automatically gathering and organising cyber-security reports in close to real-time yields an assessment technology with actionable results for intelligence and security analysts. © 2018 Inderscience Enterprises Ltd.},
  document_type = {Article},
  doi           = {10.1504/IJICS.2018.095298},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054499009&doi=10.1504%2fIJICS.2018.095298&partnerID=40&md5=6b64d6eee9400daafbc6565b814fa0c9},
}

@Article{Zeng2018,
  author        = {Zeng, P. and Zhou, P.},
  journal       = {Communications in Computer and Information Science},
  title         = {Intrusion Detection in SCADA System: A Survey},
  year          = {2018},
  note          = {cited By 2},
  pages         = {342-351},
  volume        = {924},
  abstract      = {Nowadays, the industrial systems are more and more interconnected with the outside world. However, the interconnection of Supervisory Control and Data Acquisition (SCADA) systems with the outside world using Internet-based standards introduce numerous vulnerabilities to these systems. Although awareness is constantly rising, the SCADA systems are still exposed to serious threats. In this paper, a review of Intrusion Detection and report results is conducted in the surveyed works. In the end, we also discuss the potential research directions on this topic. © 2018, Springer Nature Singapore Pte Ltd.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-981-13-2384-3_32},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053935515&doi=10.1007%2f978-981-13-2384-3_32&partnerID=40&md5=75b6d7bf200e82c160f3075fd2276ada},
}

@Article{Liu2018a,
  author        = {Liu, K. and Dolan-Gavitt, B. and Garg, S.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {Fine-pruning: Defending against backdooring attacks on deep neural networks},
  year          = {2018},
  note          = {cited By 51},
  pages         = {273-294},
  volume        = {11050 LNCS},
  abstract      = {Deep neural networks (DNNs) provide excellent performance across a wide range of classification tasks, but their training requires high computational resources and is often outsourced to third parties. Recent work has shown that outsourced training introduces the risk that a malicious trainer will return a backdoored DNN that behaves normally on most inputs but causes targeted misclassifications or degrades the accuracy of the network when a trigger known only to the attacker is present. In this paper, we provide the first effective defenses against backdoor attacks on DNNs. We implement three backdoor attacks from prior work and use them to investigate two promising defenses, pruning and fine-tuning. We show that neither, by itself, is sufficient to defend against sophisticated attackers. We then evaluate fine-pruning, a combination of pruning and fine-tuning, and show that it successfully weakens or even eliminates the backdoors, i.e., in some cases reducing the attack success rate to 0% with only a 0.4% drop in accuracy for clean (non-triggering) inputs. Our work provides the first step toward defenses against backdoor attacks in deep neural networks. © Springer Nature Switzerland AG 2018.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-00470-5_13},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053888479&doi=10.1007%2f978-3-030-00470-5_13&partnerID=40&md5=33773c7890e8d925452e7213d461d5f7},
}

@Article{Rosenberg2018,
  author        = {Rosenberg, I. and Shabtai, A. and Rokach, L. and Elovici, Y.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {Generic black-box end-to-end attack against state of the art API call based malware classifiers},
  year          = {2018},
  note          = {cited By 34},
  pages         = {490-510},
  volume        = {11050 LNCS},
  abstract      = {In this paper, we present a black-box attack against API call based machine learning malware classifiers, focusing on generating adversarial sequences combining API calls and static features (e.g., printable strings) that will be misclassified by the classifier without affecting the malware functionality. We show that this attack is effective against many classifiers due to the transferability principle between RNN variants, feed forward DNNs, and traditional machine learning classifiers such as SVM. We also implement GADGET, a software framework to convert any malware binary to a binary undetected by malware classifiers, using the proposed attack, without access to the malware source code. © Springer Nature Switzerland AG 2018.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-00470-5_23},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053870606&doi=10.1007%2f978-3-030-00470-5_23&partnerID=40&md5=5edb4703c0bada3de6f59e5c535914f4},
}

@Conference{Eigner2018,
  author        = {Eigner, O. and Kreimel, P. and Tavolato, P.},
  title         = {Attacks on industrial control systems modeling and anomaly detection},
  year          = {2018},
  note          = {cited By 2},
  pages         = {581-588},
  volume        = {2018-January},
  abstract      = {Industrial control systems play a crucial role in a digital society, particularly when they are part of critical infrastructures. Unfortunately traditional intrusion defense strategies for IT systems are often not applicable in industrial environments. A continuous monitoring of the operation is necessary to detect abnormal behavior of a system. This paper presents an anomaly-based approach for detection and classification of attacks against industrial control systems. In order to stay close to practice we set up a test plant with sensors, actuators and controllers widely used in industry, thus, providing a test environment as close as possible to reality. First, we defined a formal model of normal system behavior, determining the essential parameters through machine learning algorithms. The goal was the definition of outlier scores to differentiate between normal and abnormal system operations. This model of valid behavior is then used to detect anomalies. Further, we launched cyber-attacks against the test setup in order to create an attack model by using naive Bayes classifiers. We applied the model to data from a real industrial plant. The test showed that the model could be transferred to different industrial control systems with reasonable adaption and training effort. Copyright © 2018 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.},
  document_type = {Conference Paper},
  doi           = {10.5220/0006755405810588},
  groups        = {First Filtering},
  journal       = {ICISSP 2018 - Proceedings of the 4th International Conference on Information Systems Security and Privacy},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052018072&doi=10.5220%2f0006755405810588&partnerID=40&md5=27bbec885dfc1bcc7180926fe49c2106},
}

@Article{Vorobeychik2018,
  author        = {Vorobeychik, Y. and Kantarcioglu, M.},
  journal       = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
  title         = {Adversarial machine learning},
  year          = {2018},
  note          = {cited By 48},
  number        = {3},
  pages         = {1-169},
  volume        = {12},
  abstract      = {The increasing abundance of large high-quality datasets, combined with significant technical advances over the last several decades have made machine learning into a major tool employed across a broad array of tasks including vision, language, finance, and security. However, success has been accompanied with important new challenges: many applications of machine learning are adversarial in nature. Some are adversarial because they are safety critical, such as autonomous driving. An adversary in these applications can be a malicious party aimed at causing congestion or accidents, or may even model unusual situations that expose vulnerabilities in the prediction engine. Other applications are adversarial because their task and/or the data they use are. For example, an important class of problems in security involves detection, such as malware, spam, and intrusion detection. The use of machine learning for detecting malicious entities creates an incentive among adversaries to evade detection by changing their behavior or the content of malicius objects they develop. The field of adversarial machine learning has emerged to study vulnerabilities of machine learning approaches in adversarial settings and to develop techniques to make learning robust to adversarial manipulation. This book provides a technical overview of this field. After reviewing machine learning concepts and approaches, as well as common use cases of these in adversarial settings, we present a general categorization of attacks on machine learning. We then address two major categories of attacks and associated defenses: decision-time attacks, in which an adversary changes the nature of instances seen by a learned model at the time of prediction in order to cause errors, and poisoning or training time attacks, in which the actual training dataset is maliciously modified. In our final chapter devoted to technical content, we discuss recent techniques for attacks on deep learning, as well as approaches for improving robustness of deep neural networks. We conclude with a discussion of several important issues in the area of adversarial learning that in our view warrant further research. Given the increasing interest in the area of adversarial machine learning, we hope this book provides readers with the tools necessary to successfully engage in research and practice of machine learning in adversarial settings. Copyright © 2018 by Morgan & Claypool.},
  document_type = {Article},
  doi           = {10.2200/S00861ED1V01Y201806AIM039},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051535921&doi=10.2200%2fS00861ED1V01Y201806AIM039&partnerID=40&md5=7b6be75583c6d7e876d9ecddb96b070f},
}

@Article{Li2018b,
  author        = {Li, P. and Zhao, W. and Liu, Q. and Liu, X. and Yu, L.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {Poisoning machine learning based wireless IDSs via stealing learning model},
  year          = {2018},
  note          = {cited By 4},
  pages         = {261-273},
  volume        = {10874 LNCS},
  abstract      = {Recently, machine learning-based wireless intrusion detection systems (IDSs) have been demonstrated to have high detection accuracy in malicious traffic detection. However, many researchers argue that a variety of attacks are significantly challenging the security of machine learning techniques themselves. In this paper, we study two different types of security threats which can effectively degrade the performance of machine learning based wireless IDSs. First, we propose an Adaptive SMOTE (A-SMOTE) algorithm which can adaptively generate new training data points based on few existing ones with labels. Then, we introduce a stealing model attack by training a substitute model using deep neural networks (DNNs) based on the augmented training data in order to imitate the machine learning model embedded in targeted systems. After that, we present a novel poisoning strategy to attack against the substitute machine learning model, resulting in a set of adversarial samples that can be used to degrade the performance of targeted systems. Experiments on three real data sets collected from wired and wireless networks have demonstrated that the proposed stealing model and poisoning attacks can effectively degrade the performance of IDSs using different machine learning algorithms. © 2018, Springer International Publishing AG, part of Springer Nature.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-319-94268-1_22},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049012916&doi=10.1007%2f978-3-319-94268-1_22&partnerID=40&md5=db4a01463fd2695f67a132005d45bad7},
}

@Article{Henningsen2018,
  author        = {Henningsen, S. and Dietzel, S. and Scheuermann, B.},
  journal       = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
  title         = {Challenges of misbehavior detection in industrial wireless networks},
  year          = {2018},
  note          = {cited By 4},
  pages         = {37-46},
  volume        = {223 LNICST},
  abstract      = {In recent years, wireless technologies are increasingly adopted in many application domains that were either unconnected before or exclusively used cable networks. This paradigm shift towards – often ad-hoc – wireless communication has led to significant benefits in terms of flexibility and mobility. Alongside with these benefits, however, arise new attack vectors, which cannot be mitigated by traditional security measures. Hence, mechanisms that are orthogonal to cryptographic security techniques are necessary in order to detect adversaries. In traditional networks, such mechanisms are subsumed under the term “intrusion detection system,” and many proposals have been implemented for different application domains. More recently, the term “misbehavior detection” has been coined to encompass detection mechanisms especially for attacks in wireless networks. In this paper, we use industrial wireless networks as an exemplary application domain to discuss new directions and future challenges in detecting insider attacks. To that end, we review existing work on intrusion detection in mobile ad-hoc networks. We focus on physical-layer-based detection mechanisms as these are a particularly interesting research direction that had not been reasonable before widespread use of wireless technology. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-319-74439-1_4},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045265851&doi=10.1007%2f978-3-319-74439-1_4&partnerID=40&md5=f1b205bff742e7a951db9cd1ba2904e0},
}

@Article{Yan2018,
  author        = {Yan, J. and Qi, Y. and Rao, Q.},
  journal       = {Security and Communication Networks},
  title         = {Detecting Malware with an Ensemble Method Based on Deep Neural Network},
  year          = {2018},
  note          = {cited By 59},
  volume        = {2018},
  abstract      = {Malware detection plays a crucial role in computer security. Recent researches mainly use machine learning based methods heavily relying on domain knowledge for manually extracting malicious features. In this paper, we propose MalNet, a novel malware detection method that learns features automatically from the raw data. Concretely, we first generate a grayscale image from malware file, meanwhile extracting its opcode sequences with the decompilation tool IDA. Then MalNet uses CNN and LSTM networks to learn from grayscale image and opcode sequence, respectively, and takes a stacking ensemble for malware classification. We perform experiments on more than 40,000 samples including 20,650 benign files collected from online software providers and 21,736 malwares provided by Microsoft. The evaluation result shows that MalNet achieves 99.88% validation accuracy for malware detection. In addition, we also take malware family classification experiment on 9 malware families to compare MalNet with other related works, in which MalNet outperforms most of related works with 99.36% detection accuracy and achieves a considerable speed-up on detecting efficiency comparing with two state-of-the-art results on Microsoft malware dataset. © 2018 Jinpei Yan et al.},
  art_number    = {7247095},
  document_type = {Article},
  doi           = {10.1155/2018/7247095},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045029483&doi=10.1155%2f2018%2f7247095&partnerID=40&md5=c0a905cd6118c258fec6af2584ada0e3},
}

@Article{Umer2018,
  author        = {Umer, M.F. and Sher, M. and Bi, Y.},
  journal       = {PLoS ONE},
  title         = {A two-stage flow-based intrusion detection model for next-generation networks},
  year          = {2018},
  note          = {cited By 18},
  number        = {1},
  volume        = {13},
  abstract      = {The next-generation network provides state-of-the-art access-independent services over converged mobile and fixed networks. Security in the converged network environment is a major challenge. Traditional packet and protocol-based intrusion detection techniques cannot be used in next-generation networks due to slow throughput, low accuracy and their inability to inspect encrypted payload. An alternative solution for protection of next-generation networks is to use network flow records for detection of malicious activity in the network traffic. The network flow records are independent of access networks and user applications. In this paper, we propose a two-stage flow-based intrusion detection system for next-generation networks. The first stage uses an enhanced unsupervised one-class support vector machine which separates malicious flows from normal network traffic. The second stage uses a self-organizing map which automatically groups malicious flows into different alert clusters. We validated the proposed approach on two flow-based datasets and obtained promising results. © 2018 Umer et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
  art_number    = {e0180945},
  document_type = {Article},
  doi           = {10.1371/journal.pone.0180945},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040510523&doi=10.1371%2fjournal.pone.0180945&partnerID=40&md5=1476faa85f9f63353f849c7012dce4c7},
}

@Article{Katzir2018,
  author        = {Katzir, Z. and Elovici, Y.},
  journal       = {Expert Systems with Applications},
  title         = {Quantifying the resilience of machine learning classifiers used for cyber security},
  year          = {2018},
  note          = {cited By 25},
  pages         = {419-429},
  volume        = {92},
  abstract      = {The use of machine learning algorithms for cyber security purposes gives rise to questions of adversarial resilience, namely: Can we quantify the effort required of an adversary to manipulate a system that is based on machine learning techniques? Can the adversarial resilience of such systems be formally modeled and evaluated? Can we quantify this resilience such that different systems can be compared using empiric metrics? Past works have demonstrated how an adversary can manipulate a system based on machine learning techniques by changing some of its inputs. However, comparatively little work has emphasized the creation of a formal method for measuring and comparing the adversarial resilience of different machine learning models to these changes. In this work we study the adversarial resilience of detection systems based on supervised machine learning models. We provide a formal definition for adversarial resilience while focusing on multisensory fusion systems. We define the model robustness (MRB) score, a metric for evaluating the relative resilience of different models, and suggest two novel feature selection algorithms for constructing adversary aware classifiers. The first algorithm selects only features that cannot realistically be modified by the adversary, while the second algorithm allows control over the resilience versus accuracy tradeoff. Finally, we evaluate our approach with a real-life use case of dynamic malware classification using an extensive, up-to-date corpus of benign and malware executables. We demonstrate the potential of using adversary aware feature selection for building more resilient classifiers and provide empirical evidence supporting the inherent resilience of ensemble algorithms compared to single model algorithms. © 2017 Elsevier Ltd},
  document_type = {Article},
  doi           = {10.1016/j.eswa.2017.09.053},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030724887&doi=10.1016%2fj.eswa.2017.09.053&partnerID=40&md5=34556dd676a2d62924a88f3f7035ebf3},
}

@Article{Hamamoto2018,
  author        = {Hamamoto, A.H. and Carvalho, L.F. and Sampaio, L.D.H. and Abrão, T. and Proença, M.L., Jr.},
  journal       = {Expert Systems with Applications},
  title         = {Network Anomaly Detection System using Genetic Algorithm and Fuzzy Logic},
  year          = {2018},
  note          = {cited By 103},
  pages         = {390-402},
  volume        = {92},
  abstract      = {Due to the sheer number of applications that uses computer networks, in which some are crucial to users and enterprises, network management is essential. Therefore, integrity and availability of computer networks become priorities, making it a fundamental resource to be managed. In this work, a scheme combining Genetic Algorithm and a Fuzzy Logic for network anomaly detection is discussed. The Genetic Algorithm is used to generate a Digital Signature of Network Segment using Flow Analysis, where information extracted from network flows data is used to predict the networks traffic behavior for a given time interval. Furthermore, a Fuzzy Logic scheme is applied to decide whether an instance represents an anomaly or not, differing from some approaches present in the literature. Indeed, it is proposed an expert system with the capability to monitor the network's traffic with IP flows while expected behaviors are generated in a regular time interval basis, issuing alarms when a possible problem is present. The proposed anomaly detection system exposes network problems autonomously. The results acquired from applying the proposed approach in a real network traffic flows achieve an accuracy of 96.53% and false positive rate of 0.56%. Moreover, our method succeeds in achieving higher performance compared to several other approaches. © 2017 Elsevier Ltd},
  document_type = {Article},
  doi           = {10.1016/j.eswa.2017.09.013},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030706780&doi=10.1016%2fj.eswa.2017.09.013&partnerID=40&md5=154a59286fbbb5b42a5f9fbac5588b63},
}

@Article{A.K.2018,
  author        = {M.A., A.K. and C.D., J.},
  journal       = {Future Generation Computer Systems},
  title         = {Automated multi-level malware detection system based on reconstructed semantic view of executables using machine learning techniques at VMM},
  year          = {2018},
  note          = {cited By 16},
  pages         = {431-446},
  volume        = {79},
  abstract      = {In order to fulfill the requirements like stringent timing restraints and demand on resources, Cyber–Physical System (CPS) must deploy on the virtualized environment such as cloud computing. To protect Virtual Machines (VMs) in which CPSs are functioning against malware-based attacks, malware detection and mitigation technique is emerging as a highly crucial concern. The traditional VM-based anti-malware software themselves a potential target for malware-based attack since they are easily subverted by sophisticated malware. Thus, a reliable and robust malware monitoring and detection systems are needed to detect and mitigate rapidly the malware based cyber-attacks in real time particularly for virtualized environment. The Virtual Machine Introspection (VMI) has emerged as a fine-grained out-of-VM security solution to detect malware by introspecting and reconstructing the volatile memory state of the live guest Operating System (OS) by functioning at the Virtual Machine Monitor (VMM) or hypervisor. However, the reconstructed semantic details by the VMI are available in a combination of benign and malicious states at the hypervisor. In order to distinguish between these two states, extensive manual analysis is required by the existing out-of-VM security solutions. To address the foremost issue, in this paper, we propose an advanced VMM-based guest-assisted Automated Multilevel Malware Detection System (AMMDS) that leverages both VMI and Memory Forensic Analysis (MFA) techniques to predict early symptoms of malware execution by detecting stealthy hidden processes on a live guest OS. More specifically, the AMMDS system detects and classifies the actual running malicious executables from the semantically reconstructed process view of the guest OS. The two sub-components of the AMMDS are: Online Malware Detector (OMD) and Offline Malware Classifier (OFMC). The OMD recognizes whether the running processes are benign or malicious using its Local Malware Signature Database (LMSD) and online malware scanner and the OFMC classify unknown malware by adopting machine learning techniques at the hypervisor. The AMMDS has been evaluated by executing large real-world malware and benign executables on to the live guest OSs. The evaluation results achieved 100% of accuracy and zero False Positive Rate (FPR) on the 10-fold cross-validation in classifying unknown malware with maximum performance overhead of 5.8%. © 2017 Elsevier B.V.},
  document_type = {Article},
  doi           = {10.1016/j.future.2017.06.002},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023600868&doi=10.1016%2fj.future.2017.06.002&partnerID=40&md5=f9622699c1dbfa9f9ae8a514c851a361},
}

@Article{Liu2018b,
  author        = {Liu, Q. and Li, P. and Zhao, W. and Cai, W. and Yu, S. and Leung, V.C.M.},
  journal       = {IEEE Access},
  title         = {A survey on security threats and defensive techniques of machine learning: A data driven view},
  year          = {2018},
  note          = {cited By 137},
  pages         = {12103-12117},
  volume        = {6},
  abstract      = {Machine learning is one of the most prevailing techniques in computer science, and it has been widely applied in image processing, natural language processing, pattern recognition, cybersecurity, and other fields. Regardless of successful applications of machine learning algorithms in many scenarios, e.g., facial recognition, malware detection, automatic driving, and intrusion detection, these algorithms and corresponding training data are vulnerable to a variety of security threats, inducing a significant performance decrease. Hence, it is vital to call for further attention regarding security threats and corresponding defensive techniques of machine learning, which motivates a comprehensive survey in this paper. Until now, researchers from academia and industry have found out many security threats against a variety of learning algorithms, including naive Bayes, logistic regression, decision tree, support vector machine (SVM), principle component analysis, clustering, and prevailing deep neural networks. Thus, we revisit existing security threats and give a systematic survey on them from two aspects, the training phase and the testing/inferring phase. After that, we categorize current defensive techniques of machine learning into four groups: security assessment mechanisms, countermeasures in the training phase, those in the testing or inferring phase, data security, and privacy. Finally, we provide five notable trends in the research on security threats and defensive techniques of machine learning, which are worth doing in-depth studies in future. © 2013 IEEE.},
  document_type = {Review},
  doi           = {10.1109/ACCESS.2018.2805680},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042091433&doi=10.1109%2fACCESS.2018.2805680&partnerID=40&md5=870a27fa22e38d2d2579991a70242871},
}

@Article{Sharma2018,
  author        = {Sharma, S. and Kaul, A.},
  journal       = {Vehicular Communications},
  title         = {A survey on Intrusion Detection Systems and Honeypot based proactive security mechanisms in VANETs and VANET Cloud},
  year          = {2018},
  note          = {cited By 56},
  pages         = {138-164},
  volume        = {12},
  abstract      = {Vehicular ad-hoc Network (VANET) is an emerging type of Mobile ad-hoc Networks (MANETs) with excellent applications in the intelligent traffic system. Applications in VANETs are life critical since human lives are at stake and therefore, interaction among nodes (vehicles) must be established in the most secure manner. To provide security for VANETs, various security measures are designed, the most popular of which is Intrusion Detection Systems (IDSs). IDS has already proved its worth in detection of malicious nodes in traditional networks but applying the IDS in VANET like networks is somehow different and difficult due to its peculiar characteristics such as resource-constrained nodes, high mobility of nodes, specific protocols stacks, and standards. This paper presents a brief introduction about the various IDSs, in general, to get the readers well acquainted with the concept of IDS after which an in-depth survey of various IDSs that are propounded for VANETs is put forward followed by analyzing and comparing each technique along with merits and demerits. Some basic instructions have also been presented for developing IDSs that have a potential application in VANET and VANET Cloud. Our aim is to identify leading trends, open challenges, and future research directions in the deployment of IDS in VANET. In order to bridge the research gaps in terms of performance, detection rate and overhead, and also to overcome the challenges of existing IDS in literature, a proactive bait based Honeypot optimized IDS system is also proposed with the aim to detect existing and zero-day attacks with minimal overhead. Finally, some open research works being carried out in the field is also proposed. © 2018 Elsevier Inc.},
  document_type = {Review},
  doi           = {10.1016/j.vehcom.2018.04.005},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046450858&doi=10.1016%2fj.vehcom.2018.04.005&partnerID=40&md5=f36560721a41caa907aea777f0b87c55},
}

@Conference{Ghaeini2018,
  author        = {Ghaeini, H.R. and Antonioli, D. and Brasser, F. and Sadeghi, A.-R. and Tippenhauer, N.O.},
  title         = {State-aware anomaly detection for industrial control systems},
  year          = {2018},
  note          = {cited By 16},
  pages         = {1620-1628},
  abstract      = {Anomaly detection for industrial control systems (ICS) can leverage process data to detect malicious derivations from expected process behavior. We propose state-aware anomaly detection that uses state dependent detection thresholds, which provide tighter constraints for an attacker trying to manipulate the process. In particular, our system provides: (i) estimation of system state from the knowledge of the network and the physical process (ii) a state-aware cumulative sum of residuals for monitoring the industrial control system (iii) and a novel state-aware anomaly detection technique. We implement and evaluate our anomaly detection technique on a real-world ICS. We pre-compute the process-state parameters using a big data framework for ICS and train the detector leveraging more than 120 GB of historical data from the ICS. The results show that the proposed method improves prior works by providing less time-to-detect of attacks while generating fewer false alarms. © 2018 ACM.},
  document_type = {Conference Paper},
  doi           = {10.1145/3167132.3167305},
  groups        = {First Filtering},
  journal       = {Proceedings of the ACM Symposium on Applied Computing},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050521063&doi=10.1145%2f3167132.3167305&partnerID=40&md5=3ebfba992aaa477ca1024fbc42a1b695},
}

@Article{Li2018e,
  author        = {Li, L. and Xie, L. and Li, W. and Liu, Z. and Wang, Z.},
  journal       = {Applied Sciences (Switzerland)},
  title         = {Improved deep belief networks (IDBN) dynamic model-based detection and mitigation for targeted attacks on heavy-duty robots},
  year          = {2018},
  note          = {cited By 4},
  number        = {5},
  volume        = {8},
  abstract      = {In recent years, the robots, especially heavy-duty robots, have become the hardest-hit areas for targeted attacks. These attacks come from both the cyber-domain and the physical-domain. In order to improve the security of heavy-duty robots, this paper proposes a detection and mitigation mechanismwhich based on improved deep belief networks (IDBN) and dynamicmodel. The detection mechanism consists of two parts: (1) IDBN security checks, which can detect targeted attacks from the cyber-domain; (2) Dynamicmodel and security detection, used to detect the targeted attacks which can possibly lead to a physical-domain damage. The mitigation mechanism was established on the base of the detection mechanism and could mitigate transient and discontinuous attacks. Moreover, a test platform was established to carry out the performance evaluation test for the proposed mechanism. The results show that, the detection accuracy for the attack of the cyber-domain of IDBN reaches 96.2%, and the detection accuracy for the attack of physical-domain control commands reaches 94%. The performance evaluation test has verified the reliability and high efficiency of the proposed detection and mitigation mechanism for heavy-duty robots. © 2018 by the authors.},
  art_number    = {676},
  document_type = {Article},
  doi           = {10.3390/app8050676},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046136863&doi=10.3390%2fapp8050676&partnerID=40&md5=a5691dc4bebaee51e7fc0eb7acf2e700},
}

@Article{Lin2018a,
  author        = {Lin, Z. and Xiao, F. and Sun, Y. and Ma, Y. and Xing, C.-C. and Huang, J.},
  journal       = {KSII Transactions on Internet and Information Systems},
  title         = {A secure encryption-based malware detection system},
  year          = {2018},
  note          = {cited By 8},
  number        = {4},
  pages         = {1799-1818},
  volume        = {12},
  abstract      = {Malware detections continue to be a challenging task as attackers may be aware of the rules used in malware detection mechanisms and constantly generate new breeds of malware to evade the current malware detection mechanisms. Consequently, novel and innovated malware detection techniques need to be investigated to deal with this circumstance. In this paper, we propose a new secure malware detection system in which API call fragments are used to recognize potential malware instances, and these API call fragments together with the homomorphic encryption technique are used to construct a privacy-preserving Naive Bayes classifier (PP-NBC). Experimental results demonstrate that the proposed PP-NBC can successfully classify instances of malware with a hit-rate as high as 94.93%. © 2018 KSII.},
  document_type = {Article},
  doi           = {10.3837/tiis.2018.04.022},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046906311&doi=10.3837%2ftiis.2018.04.022&partnerID=40&md5=946ce3144073a793acfe907d41864c04},
}

@Article{Sadiq2018,
  author        = {Sadiq, A.S. and Alkazemi, B. and Mirjalili, S. and Ahmed, N. and Khan, S. and Ali, I. and Pathan, A.-S.K. and Ghafoor, K.Z.},
  journal       = {IEEE Access},
  title         = {An Efficient IDS Using Hybrid Magnetic Swarm Optimization in WANETs},
  year          = {2018},
  note          = {cited By 12},
  pages         = {29041-29053},
  volume        = {6},
  abstract      = {Sophisticated Intrusion attacks against various types of networks are ever increasing today with the exploitation of modern technologies which often severely affect wireless networks. In order to improve the effectiveness of intrusion detection systems (IDSs), data analysis methods such as data mining and classification methods are often integrated with IDSs. Though, numerous studies have contributed in various ways to improve the utilization of data mining for IDS, effective solution often depends on the network setting where the IDS is deployed. In this paper, we propose an efficient IDS based on hybrid heuristic optimization algorithm which is inspired by magnetic field theory in physics that deals with attraction between particles scattered in the search space. Our developed algorithm works in extracting the most relevant features that can assist in accurately detecting the network attacks. These features are extracted by tagged index values that represent the information gain out of the training course of the classifier to be used as a base for our developed IDS. In order to improve the accuracy of artificial neural network (ANN) classifier, we have integrated our proposed hybrid magnetic optimization algorithm-particle swarm optimization (MOA-PSO) technique. Experimental results show that using our proposed IDS based on hybrid MOA-PSO technique provides more accuracy level compared to the use of ANN based on MOA, PSO and genetic algorithm. Updated KDD CUP data set is formed and used during the training and testing phases, where this data set consists of mixed data traffics between attacks and normal activities. Our results show significant gain in terms of efficiency compared to other alternative mechanisms. © 2013 IEEE.},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2018.2835166},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046828624&doi=10.1109%2fACCESS.2018.2835166&partnerID=40&md5=43f1177f5545f6b8549e605e393e07f1},
}

@Article{Peng2018,
  author        = {Peng, H. and Sun, Z. and Zhao, X. and Tan, S. and Sun, Z.},
  journal       = {IEEE Access},
  title         = {A Detection Method for Anomaly Flow in Software Defined Network},
  year          = {2018},
  note          = {cited By 27},
  pages         = {27809-27817},
  volume        = {6},
  abstract      = {As a new type of network structure, the Software Defined Network (SDN) provides a new solution for network flow management and optimization, which has made the accurate detection of anomaly SDN flows a hot research topic. This paper presents an SDN-based flow detection method, builds structures for detecting anomaly SDN flows and performs classification detection on the flows using the double P-value of transductive confidence machines for K-nearest neighbors algorithm. The experimental results show that the algorithm proposed achieves a lower false positive rate, higher precision, and better adaptation to the SDN environment than do other algorithms of the same type. © 2013 IEEE.},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2018.2839684},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047616229&doi=10.1109%2fACCESS.2018.2839684&partnerID=40&md5=7294c932a7c7ea5867758ce94274411f},
}

@Article{Giraldo2018,
  author        = {Giraldo, J. and Urbina, D. and Cardenas, A. and Valente, J. and Faisal, M. and Ruths, J. and Tippenhauer, N.O. and Sandberg, H. and Candell, R.},
  journal       = {ACM Computing Surveys},
  title         = {A survey of physics-based attack detection in cyber-physical systems},
  year          = {2018},
  note          = {cited By 91},
  number        = {4},
  volume        = {51},
  abstract      = {Monitoring the "physics" of cyber-physical systems to detect attacks is a growing area of research. In its basic form, a security monitor creates time-series models of sensor readings for an industrial control system and identifies anomalies in these measurements to identify potentially false control commands or false sensor readings. In this article, we review previous work on physics-based anomaly detection based on a unified taxonomy that allows us to identify limitations and unexplored challenges and to propose new solutions. © 2018 ACM.},
  art_number    = {3203245},
  document_type = {Review},
  doi           = {10.1145/3203245},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053229533&doi=10.1145%2f3203245&partnerID=40&md5=8f20f4ae8b446cd53d5751dc1141ff72},
}

@Article{Duddu2018,
  author        = {Duddu, V.},
  journal       = {Defence Science Journal},
  title         = {A survey of adversarial machine learning in cyber warfare},
  year          = {2018},
  note          = {cited By 13},
  number        = {4},
  pages         = {356-366},
  volume        = {68},
  abstract      = {The changing nature of warfare has seen a paradigm shift from the conventional to asymmetric, contactless warfare such as information and cyber warfare. Excessive dependence on information and communication technologies, cloud infrastructures, big data analytics, data-mining and automation in decision making poses grave threats to business and economy in adversarial environments. Adversarial machine learning is a fast growing area of research which studies the design of Machine Learning algorithms that are robust in adversarial environments. This paper presents a comprehensive survey of this emerging area and the various techniques of adversary modelling. We explore the threat models for Machine Learning systems and describe the various techniques to attack and defend them. We present privacy issues in these models and describe a cyber-warfare test-bed to test the effectiveness of the various attack-defence strategies and conclude with some open problems in this area of research. © 2018 DESIDOC.},
  document_type = {Article},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049580491&partnerID=40&md5=e3880809e92c62f0c680e4a76d8d2aae},
}

@Conference{Karande2018,
  author        = {Karande, J.B. and Joshi, S.A.},
  title         = {Comprehensive Assessment of Security Attack Detection Algorithms in Internet of Things},
  year          = {2018},
  note          = {cited By 3},
  abstract      = {The Internet of Things (IoT) is becoming an important part of every business domain including health, education, industrial manufacturing, agriculture and domestic products. These applications of IoT raise concerns over security of IoT system. Several security attacks on IoT systems have been demonstrated in the state of the art. Further multiple attackers attacking IoT system collaboratively is more hazardous and stealthy. This paper reviews and evaluates the state of the art for security attack detection mechanisms on IoT protocol stack. Evaluation of the effectiveness of attack detection mechanism through an extensive simulation study is presented in the paper. Results of simulation study highlight the failure of attack detection mechanisms presented in the state of the art in case of multiple attackers attacking IoT system collaboratively. Simulation study also shows considerable deviations in network parameters in IoT system under attack of multiple collaborative attackers from normal operation. These deviations in parameters can be used for early and effective detection of security attacks on IoT system. This paper highlights need for the design of an early detection algorithm for security attacks on IoT system. © 2018 IEEE.},
  art_number    = {8697406},
  document_type = {Conference Paper},
  doi           = {10.1109/ICCUBEA.2018.8697406},
  groups        = {First Filtering},
  journal       = {Proceedings - 2018 4th International Conference on Computing, Communication Control and Automation, ICCUBEA 2018},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065209500&doi=10.1109%2fICCUBEA.2018.8697406&partnerID=40&md5=e6bf3ae42551c62ddf006eac9ab6840b},
}

@Conference{Li2018,
  author        = {Li, P. and Liu, Q. and Zhao, W. and Wang, D. and Wang, S.},
  title         = {Chronic poisoning against machine learning based IDSs using edge pattern detection},
  year          = {2018},
  note          = {cited By 2},
  volume        = {2018-May},
  abstract      = {In big data era, machine learning is one of fundamental techniques in intrusion detection systems (IDSs). Poisoning attack, which is one of the most recognized security threats towards machine learning- based IDSs, injects some adversarial samples into the training phase, inducing data drifting of training data and a significant performance decrease of target IDSs over testing data. In this paper, we adopt the Edge Pattern Detection (EPD) algorithm to design a novel poisoning method that attack against several machine learning algorithms used in IDSs. Specifically, we propose a boundary pattern detection algorithm to efficiently generate the points that are near to abnormal data but considered to be normal ones by current classifiers. Then, we introduce a Batch-EPD Boundary Pattern (BEBP) detection algorithm to overcome the limitation of the number of edge pattern points generated by EPD and to obtain more useful adversarial samples. Based on BEBP, we further present a moderate but effective poisoning method called chronic poisoning attack. Extensive experiments on synthetic and three real network data sets demonstrate the performance of the proposed poisoning method against several well-known machine learning algorithms and a practical intrusion detection method named FMIFS-LSSVM-IDS. © 2018 IEEE.},
  art_number    = {8422328},
  document_type = {Conference Paper},
  doi           = {10.1109/ICC.2018.8422328},
  groups        = {First Filtering},
  journal       = {IEEE International Conference on Communications},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051441602&doi=10.1109%2fICC.2018.8422328&partnerID=40&md5=d9ef197d721c6e1035a22db4d61a5f84},
}

@Article{Hu2018,
  author        = {Hu, Y. and Yang, A. and Li, H. and Sun, Y. and Sun, L.},
  journal       = {International Journal of Distributed Sensor Networks},
  title         = {A survey of intrusion detection on industrial control systems},
  year          = {2018},
  note          = {cited By 27},
  number        = {8},
  volume        = {14},
  abstract      = {The modern industrial control systems now exhibit an increasing connectivity to the corporate Internet technology networks so as to make full use of the rich resource on the Internet. The increasing interaction between industrial control systems and the outside Internet world, however, has made them an attractive target for a variety of cyber attacks, raising a great need to secure industrial control systems. Intrusion detection technology is one of the most important security precautions for industrial control systems. It can effectively detect potential attacks against industrial control systems. In this survey, we elaborate on the characteristics and the new security requirements of industrial control systems. After that, we present a new taxonomy of intrusion detection systems for industrial control systems based on different techniques: protocol analysis based, traffic mining based, and control process analysis based. In addition, we analyze the advantages and disadvantages of different categories of intrusion detection systems and discuss some future developments of intrusion detection systems for industrial control systems, in order to promote further research on intrusion detection technology for industrial control systems. © The Author(s) 2018.},
  document_type = {Article},
  doi           = {10.1177/1550147718794615},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052680490&doi=10.1177%2f1550147718794615&partnerID=40&md5=34fc71ce20ef93345716feba31a8d540},
}

@Conference{Anindya2018,
  author        = {Anindya, I.C. and Kantarcioglu, M.},
  title         = {Adversarial anomaly detection using centroid-based clustering},
  year          = {2018},
  note          = {cited By 5},
  pages         = {1-8},
  abstract      = {As cyber attacks are growing with an unprecedented rate in the recent years, organizations are seeking an efficient and scalable solution towards a holistic protection system. As the adversaries are becoming more skilled and organized, traditional rule based detection systems have been proved to be quite ineffective against the continuously evolving cyber attacks. Consequently, security researchers are focusing on applying machine learning techniques and big data analytics to defend against cyber attacks. Over the recent years, several anomaly detection systems have been claimed to be quite successful against the sophisticated cyber attacks including the previously unseen zero-day attacks. But often, these systems do not consider the adversary's adaptive attacking behavior for bypassing the detection procedure. As a result, deploying these systems in active real-world scenarios fails to provide significant benefits in the presence of intelligent adversaries that are carefully manipulating the attack vectors. In this work, we analyze the adversarial impact on anomaly detection models that are built upon centroid-based clustering from game-theoretic aspect and propose adversarial anomaly detection technique for these models. The experimental results show that our game-theoretic anomaly detection models can withstand attacks more effectively compared to the traditional models. © 2018 IEEE.},
  art_number    = {8424680},
  document_type = {Conference Paper},
  doi           = {10.1109/IRI.2018.00009},
  groups        = {First Filtering},
  journal       = {Proceedings - 2018 IEEE 19th International Conference on Information Reuse and Integration for Data Science, IRI 2018},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052294397&doi=10.1109%2fIRI.2018.00009&partnerID=40&md5=a051c5fbc0036b101ad6cd57474704b9},
}

@Conference{AlDujaili2018,
  author        = {Al-Dujaili, A. and Huang, A. and Hemberg, E. and O'Reilly, U.-M.},
  title         = {Adversarial deep learning for robust detection of binary encoded malware},
  year          = {2018},
  note          = {cited By 35},
  pages         = {76-82},
  abstract      = {Malware is constantly adapting in order to avoid detection. Model-based malware detectors, such as SVM and neural networks, are vulnerable to so-called adversarial examples which are modest changes to detectable malware that allows the resulting malware to evade detection. Continuous-valued methods that are robust to adversarial examples of images have been developed using saddle-point optimization formulations. We are inspired by them to develop similar methods for the discrete, e.g. binary, domain which characterizes the features of malware. A specific extra challenge of malware is that the adversarial examples must be generated in a way that preserves their malicious functionality. We introduce methods capable of generating functionally preserved adversarial malware examples in the binary domain. Using the saddle-point formulation, we incorporate the adversarial examples into the training of models that are robust to them. We evaluate the effectiveness of the methods and others in the literature on a set of Portable Execution (PE) files. Comparison prompts our introduction of an online measure computed during training to assess general expectation of robustness. © 2018 IEEE.},
  art_number    = {8424636},
  document_type = {Conference Paper},
  doi           = {10.1109/SPW.2018.00020},
  groups        = {First Filtering},
  journal       = {Proceedings - 2018 IEEE Symposium on Security and Privacy Workshops, SPW 2018},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052222151&doi=10.1109%2fSPW.2018.00020&partnerID=40&md5=d07e194f6b59ba164fae20f620468250},
}

@Conference{Amullen2018,
  author        = {Amullen, E.M. and Keel, L.H.},
  title         = {Consensus-Based Intrusion Detection for the Electric Power Grid Control System},
  year          = {2018},
  note          = {cited By 0},
  pages         = {80-85},
  volume        = {2018-June},
  abstract      = {We study false data injection attacks that affect state estimation in the power grid. We consider a class of false data injection attacks that cannot be detected by conventional bad data detection schemes employed in the power grid and propose a distributed agent-based system for detecting and mitigating these attacks. In the agent-based framework, software-based agents are deployed at substations within the power grid to carry out (1) distributed state estimation (2)Ensure secure state estimation by detecting maliciously injected data and (3) Communicate with adjacent agents to coordinate detection efforts. To coordinate results among agents in a time bound fashion, we propose a consensus-based information exchange strategy in which agents share data with neighboring agents and arrive at a consensus value. To detect attacks, the consensus value is evaluated against a threshold. To demonstrate the effectiveness of the agent-based detection strategy, we simulate 1000 attack scenarios against the IEEE 9-bus, 14-bus, and 30-bus test power networks using MATPOWER and show that agents successfully detect at least 98% of the attacks. © 2018 TSI Press.},
  art_number    = {8430423},
  document_type = {Conference Paper},
  doi           = {10.23919/WAC.2018.8430423},
  groups        = {First Filtering},
  journal       = {World Automation Congress Proceedings},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052088396&doi=10.23919%2fWAC.2018.8430423&partnerID=40&md5=20986f4d4596f38fe307b2bf4fa1f23e},
}

@Article{Adhikari2018,
  author        = {Adhikari, U. and Morris, T.H. and Pan, S.},
  journal       = {IEEE Transactions on Smart Grid},
  title         = {Applying Hoeffding Adaptive Trees for Real-Time Cyber-Power Event and Intrusion Classification},
  year          = {2018},
  note          = {cited By 21},
  number        = {5},
  pages         = {4049-4060},
  volume        = {9},
  abstract      = {Electricity transmission systems are networked cyber physical systems that are subject to many well-known control, weather, and equipment failure related contingencies which can disrupt power delivery. Cyber-Attacks against electric transmission systems are another class of contingency which can disrupt power delivery. Wide area monitoring systems (WAMSs) enhanced with phasor measurement units provide high volume and high velocity power system sensor data which can be combined with traditional power system data sources and cyber data sources to enable real time detection of both types of contingencies. This paper describes research toward a cyber-power event and intrusion detection system (EIDS) which can be used for multiclass or binary-class classification of traditional power system contingencies and cyber-Attacks. The continuous streams of high speed data from WAMS pose significant challenges in data storage, management, and handling. Data stream mining addresses the continuous data problem and can deal with very large data sizes. Hoeffding adaptive trees (HAT) augmented with the drift detection method (DDM) and adaptive windowing (ADWIN) can effectively be used to classify traditional and cyber contingencies in real time. Experiments performed for this paper demonstrate HAT + DDM + ADWIN provides classification accuracy of greater than 94% for multiclass and greater than 98% for binary class classification for a dataset with artifacts from 45 classes of cyber-power contingencies. Results also show that HAT + DDM + ADWIN has a small memory foot print and a fast evaluation time which enables real time EIDS. © 2010-2012 IEEE.},
  art_number    = {7805317},
  document_type = {Article},
  doi           = {10.1109/TSG.2017.2647778},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048222227&doi=10.1109%2fTSG.2017.2647778&partnerID=40&md5=4a0ba430487c89bea4dcea847252f6d0},
}

@Article{Yang2018,
  author        = {Yang, Z. and Sun, Q. and Zhang, B.},
  journal       = {IEEE Access},
  title         = {Evaluating prediction error for anomaly detection by exploiting matrix factorization in rating systems},
  year          = {2018},
  note          = {cited By 4},
  pages         = {50014-50029},
  volume        = {6},
  abstract      = {A rating system provides rating data about products or services, which is a key feature of e-commerce websites such as Amazon, TripAdvisor, and so on. In reality, rating systems generally suffer from threats of profile injection attacks or anomalous ratings due to the integration of collaborative recommendation techniques. To reduce these risks, a number of detection methods have been developed for defending such potential threats. However, they either directly calculate similarity between users or items to recognize attack profiles and genuine profiles, or utilize supervised learning methods by extracting features from user profiles for anomaly detection. In this paper, we propose a stepwise detection method to spot anomalous ratings or attacks, which bypasses the hard problems of similarity calculation and feature extraction. First, a part of samples are randomly selected from original user profiles for constructing a sub-matrix (rating matrix). A fast max-margin matrix factorization is then employed to make rating prediction. After that, suspected items can be captured by comprehensively analyzing both the distributions of mean prediction errors of items and users. Finally, anomalous ratings and potential attackers can be directly returned. Extensive experiments on MovieLens-100K data set demonstrate the effectiveness of the proposed approach compared with benchmarked methods. It is noteworthy that suspected items on a large-scale real-world data set, Amazon data, are detected by the proposed method and further analyzed from diverse perspectives, including rating distribution, rating intention, and time series analysis. © 2013 IEEE.},
  art_number    = {8458109},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2018.2869271},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053148234&doi=10.1109%2fACCESS.2018.2869271&partnerID=40&md5=5c6752bf49643ab9ec9e96d804a0e419},
}

@Conference{Warzynski2018,
  author        = {Warzynski, A. and Kolaczek, G.},
  title         = {Intrusion detection systems vulnerability on adversarial examples},
  year          = {2018},
  note          = {cited By 7},
  abstract      = {Intrusion detection systems define an important and dynamic research area for cybersecurity. The role of Intrusion Detection System within security architecture is to improve a security level by identification of all malicious and also suspicious events that could be observed in computer or network system. One of the more specific research areas related to intrusion detection is anomaly detection. Anomaly-based intrusion detection in networks refers to the problem of finding untypical events in the observed network traffic that do not conform to the expected normal patterns. It is assumed that everything that is untypical/anomalous could be dangerous and related to some security events. To detect anomalies many security systems implements a classification or clustering algorithms. However, recent research proved that machine learning models might misclassify adversarial events, e.g. observations which were created by applying intentionally non-random perturbations to the dataset. Such weakness could increase of false negative rate which implies undetected attacks. This fact can lead to one of the most dangerous vulnerabilities of intrusion detection systems. The goal of the research performed was verification of the anomaly detection systems ability to resist this type of attack. This paper presents the preliminary results of tests taken to investigate existence of attack vector, which can use adversarial examples to conceal a real attack from being detected by intrusion detection systems. © 2018 IEEE.},
  art_number    = {8466271},
  document_type = {Conference Paper},
  doi           = {10.1109/INISTA.2018.8466271},
  groups        = {First Filtering},
  journal       = {2018 IEEE (SMC) International Conference on Innovations in Intelligent Systems and Applications, INISTA 2018},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055544788&doi=10.1109%2fINISTA.2018.8466271&partnerID=40&md5=51486b6bbb3318f4108de36ec88460aa},
}

@Article{Yi2018,
  author        = {Yi, P. and Wang, K. and Huang, C. and Gu, S. and Zou, F. and Li, J.},
  journal       = {Shanghai Jiaotong Daxue Xuebao/Journal of Shanghai Jiaotong University},
  title         = {Adversarial Attacks in Artificial Intelligence: A Survey [人工智能对抗攻击研究综述]},
  year          = {2018},
  note          = {cited By 4},
  number        = {10},
  pages         = {1298-1306},
  volume        = {52},
  abstract      = {With the widespread use of artificial intelligence, artificial intelligence security has drawn public attention. The research on adversarial attacks in artificial intelligence has become a hotspot of artificial intelligence security. This paper first introduces the concept of adversarial attacks and the causes of adversarial attacks. The main reason is that the inconsistency between the model boundary and the real boundary leads to the existence of adversarial space. This paper review the works that design adversarial attacks, detect methods and defense methods agaisnt the attacks. The adversarial attacks including FGSM and JSMA attacks, the main idea of the attacks is to find the fast gradient direction of the model, adding perturbation according the direction and causing model misjudgment. Finally, some future research directions are proposed. © 2018, Shanghai Jiao Tong University Press. All right reserved.},
  document_type = {Review},
  doi           = {10.16183/j.cnki.jsjtu.2018.10.019},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059514258&doi=10.16183%2fj.cnki.jsjtu.2018.10.019&partnerID=40&md5=f68e6b560f199326e9d8d072fc011948},
}

@Conference{Banerjee2018,
  author        = {Banerjee, N. and Giannetsos, T. and Panaousis, E. and Took, C.C.},
  title         = {Unsupervised learning for trustworthy IoT},
  year          = {2018},
  note          = {cited By 10},
  volume        = {2018-July},
  abstract      = {The advancement of Internet-of-Things (IoT) edge devices with various types of sensors enables us to harness diverse information with Mobile Crowd-Sensing applications (MCS). This highly dynamic setting entails the collection of ubiquitous data traces, originating from sensors carried by people, introducing new information security challenges; one of them being the preservation of data trustworthiness. What is needed in these settings is the timely analysis of these large datasets to produce accurate insights on the correctness of user reports. Existing data mining and other artificial intelligence methods are the most popular to gain hidden insights from IoT data, albeit with many challenges. In this paper, we first model the cyber trustworthiness of MCS reports in the presence of intelligent and colluding adversaries. We then rigorously assess, using real IoT datasets, the effectiveness and accuracy of well-known data mining algorithms when employed towards IoT security and privacy. By taking into account the spatio-temporal changes of the underlying phenomena, we demonstrate how concept drifts can masquerade the existence of attackers and their impact on the accuracy of both the clustering and classification processes. Our initial set of results clearly show that these unsupervised learning algorithms are prone to adversarial infection, thus, magnifying the need for further research in the field by leveraging a mix of advanced machine learning models and mathematical optimization techniques. © 2018 IEEE.},
  art_number    = {8491672},
  document_type = {Conference Paper},
  doi           = {10.1109/FUZZ-IEEE.2018.8491672},
  groups        = {First Filtering},
  journal       = {IEEE International Conference on Fuzzy Systems},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052848901&doi=10.1109%2fFUZZ-IEEE.2018.8491672&partnerID=40&md5=8b83c61e64dba5ca0062bd4ffe679c0e},
}

@Conference{Schneider2018,
  author        = {Schneider, P. and Böttinger, K.},
  title         = {High-performance unsupervised anomaly detection for cyber-physical system networks},
  year          = {2018},
  note          = {cited By 27},
  pages         = {1-12},
  abstract      = {While the ever-increasing connectivity of cyber-physical systems enlarges their attack surface, existing anomaly detection frameworks often do not incorporate the rising heterogeneity of involved systems. Existing frameworks focus on a single fieldbus protocol or require more detailed knowledge of the cyber-physical system itself. Thus, we introduce a uniform method and framework for applying anomaly detection to a variety of fieldbus protocols. We use stacked denoising autoencoders to derive a feature learning and packet classification method in one step. As the approach is based on the raw byte stream of the network traffic, neither specific protocols nor detailed knowledge of the application is needed. Additionally, we pay attention on creating an efficient framework which can also handle the increased amount of communication in cyber-physical systems. Our evaluation on a Secure Water Treatment dataset using EtherNet/IP and a Modbus dataset shows that we can acquire network packets up to 100 times faster than packet parsing based methods. However, we still achieve precision and recall metrics for longer lasting attacks of over 99%. © 2018 Association for Computing Machinery.},
  document_type = {Conference Paper},
  doi           = {10.1145/3264888.3264890},
  groups        = {First Filtering},
  journal       = {Proceedings of the ACM Conference on Computer and Communications Security},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056721492&doi=10.1145%2f3264888.3264890&partnerID=40&md5=292256b0b9438e49c48b5f3afc970164},
}

@Conference{Xing2018a,
  author        = {Xing, B. and Cao, S. and Chen, X.},
  title         = {Risk Data Analysis Based Anomaly Detection of Ship Information System (SIS)},
  year          = {2018},
  note          = {cited By 0},
  abstract      = {Due to the vulnerability and high-risk of ship environment, ship information system (SIS) should be protected from cyber-attack around the clock. Therefore, in this paper, according to the cooperative control structure of SIS, a risk data analysis based anomaly detection mode is proposed. The risk data are determined by all the related data even in different subsystems which are formulated in Industrial State Modeling Language (ISML). Meanwhile, a typical kind of signal attack is designed in the analysis procedure. The simulation results show that the proposed algorithm can ingeniously and efficiently detect the signal attack with a high percentage of accuracy. © 2018 IEEE.},
  art_number    = {8494233},
  document_type = {Conference Paper},
  doi           = {10.1109/EEEIC.2018.8494233},
  groups        = {First Filtering},
  journal       = {Proceedings - 2018 IEEE International Conference on Environment and Electrical Engineering and 2018 IEEE Industrial and Commercial Power Systems Europe, EEEIC/I and CPS Europe 2018},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056549946&doi=10.1109%2fEEEIC.2018.8494233&partnerID=40&md5=7832fd1aa9b8a80251e061bced6c1e35},
}

@Conference{Viegas2018,
  author        = {Viegas, E. and Santin, A. and Abreu, V. and Oliveira, L.S.},
  title         = {Enabling Anomaly-based Intrusion Detection Through Model Generalization},
  year          = {2018},
  note          = {cited By 4},
  pages         = {934-939},
  volume        = {2018-June},
  abstract      = {Anomaly-based intrusion detection by the means of machine learning techniques is extensively studied in the literature mainly due to its promise to detect new attacks. However, despite the promising reported results, it is hardly deployed to real world environments. The main challenge in its adoption is the discrepancy between the accuracy rates obtained during the classifier development process and the rates obtained during its use in production environments. Such a discrepancy is mainly caused by non-representative training databases and nongeneralizable (scenario-specific) classifier's model. This paper presents a method to create intrusion databases, which aims at mimicking the production environments characteristics by using well-known tools. Moreover, we present and evaluate a new validation technique, which aims at ensuring the generalization capacity of the obtained models, reached using cross-validating with different intrusion databases. The evaluation tests showed the feasibility of the proposed method. The feature selection technique ensured the model generalization capacity, improving its accuracy rate by 13%, while testing in different intrusion databases. Finally, the proposed anomaly-based approach was compared with Snort, reaching an accuracy rate of 99% against 27% of Snort for detecting DoS attacks. © 2018 IEEE.},
  art_number    = {8538524},
  document_type = {Conference Paper},
  doi           = {10.1109/ISCC.2018.8538524},
  groups        = {First Filtering},
  journal       = {Proceedings - IEEE Symposium on Computers and Communications},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059212609&doi=10.1109%2fISCC.2018.8538524&partnerID=40&md5=dae5d5e8332490f67a885be900f7a697},
}

@Conference{Poursaeed2018,
  author        = {Poursaeed, O. and Katsman, I. and Gao, B. and Belongie, S.},
  title         = {Generative Adversarial Perturbations},
  year          = {2018},
  note          = {cited By 57},
  pages         = {4422-4431},
  abstract      = {In this paper, we propose novel generative models for creating adversarial examples, slightly perturbed images resembling natural images but maliciously crafted to fool pre-trained models. We present trainable deep neural networks for transforming images to adversarial perturbations. Our proposed models can produce image-agnostic and image-dependent perturbations for targeted and non-targeted attacks. We also demonstrate that similar architectures can achieve impressive results in fooling both classification and semantic segmentation models, obviating the need for hand-crafting attack methods for each task. Using extensive experiments on challenging high-resolution datasets such as ImageNet and Cityscapes, we show that our perturbations achieve high fooling rates with small perturbation norms. Moreover, our attacks are considerably faster than current iterative methods at inference time. © 2018 IEEE.},
  art_number    = {8578563},
  document_type = {Conference Paper},
  doi           = {10.1109/CVPR.2018.00465},
  groups        = {First Filtering},
  journal       = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062857493&doi=10.1109%2fCVPR.2018.00465&partnerID=40&md5=41a554bcd0c34b408907b50cfeb6e7f5},
}

@Conference{Subramanya2018,
  author        = {Subramanya, A. and Mopuri, K.R. and Babu, R.V.},
  title         = {BatchOut: Batch-level feature augmentation to improve robustness to adversarial examples},
  year          = {2018},
  note          = {cited By 0},
  abstract      = {Machine Learning models are known to be susceptible to small but structured changes to their inputs that can result in wrong inferences. It has been shown that such samples, called adversarial samples, can be created rather easily for standard neural network architectures. These adversarial samples pose a serious threat for deploying state-of-the-art deep neural network models in the real world. We propose a feature augmentation technique called BatchOut to learn robust models towards such examples. The proposed approach is a generic feature augmentation technique that is not specific to any adversary and handles multiple attacks. We evaluate our algorithm on benchmark datasets and architectures to show that models trained using our method are less susceptible to adversaries created using multiple methods. © 2018 ACM.},
  art_number    = {3293387},
  document_type = {Conference Paper},
  doi           = {10.1145/3293353.3293387},
  groups        = {First Filtering},
  journal       = {ACM International Conference Proceeding Series},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098116407&doi=10.1145%2f3293353.3293387&partnerID=40&md5=e424ee5d69a957df02381fa7907de2b4},
}

@Article{Wiebe2018,
  author        = {Wiebe, N. and Kumar, R.S.S.},
  journal       = {New Journal of Physics},
  title         = {Hardening quantum machine learning against adversaries},
  year          = {2018},
  note          = {cited By 3},
  number        = {12},
  volume        = {20},
  abstract      = {Security of machine learning has begun to become a serious issue for present day applications. An important question remaining is whether emerging quantum technologies will help or hinder the security of machine learning. Here we discuss a number of ways that quantum information can be used to help make quantum classifiers more secure or private. In particular, we demonstrate a form of robust principal component analysis that, under some circumstances, can provide an exponential speedup relative to robust methods used at present. To demonstrate this approach we introduce a linear combinations of unitaries Hamiltonian simulation method that we show functions when given an imprecise Hamiltonian oracle, which may be of independent interest. We also introduce a new quantum approach for bagging and boosting that can use quantum superposition over the classifiers or splits of the training set to aggragate over many more models than would be possible classically. Finally, we provide a private form of k-means clustering that can be used to prevent an all powerful adversary from learning more than a small fraction of a bit from any user. These examples show the role that quantum technologies can play in the security of ML and vice versa. This illustrates that quantum computing can provide useful advantages to machine learning apart from speedups. © 2018 The Author(s). Published by IOP Publishing Ltd on behalf of Deutsche Physikalische Gesellschaft.},
  art_number    = {123019},
  document_type = {Article},
  doi           = {10.1088/1367-2630/aae71a},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059890080&doi=10.1088%2f1367-2630%2faae71a&partnerID=40&md5=611e4dacb94a30d811faa7e8e6b8066e},
}

@Conference{Marino2018,
  author        = {Marino, D.L. and Wickramasinghe, C.S. and Manic, M.},
  title         = {An adversarial approach for explainable AI in intrusion detection systems},
  year          = {2018},
  note          = {cited By 19},
  pages         = {3237-3243},
  abstract      = {Despite the growing popularity of modern machine learning techniques (e.g. Deep Neural Networks) in cyber-security applications, most of these models are perceived as a black-box for the user. Adversarial machine learning offers an approach to increase our understanding of these models. In this paper we present an approach to generate explanations for incorrect classifications made by data-driven Intrusion Detection Systems (IDSs) An adversarial approach is used to find the minimum modifications (of the input features) required to correctly classify a given set of misclassified samples. The magnitude of such modifications is used to visualize the most relevant features that explain the reason for the misclassification. The presented methodology generated satisfactory explanations that describe the reasoning behind the mis-classifications, with descriptions that match expert knowledge. The advantages of the presented methodology are: 1) applicable to any classifier with defined gradients. 2) does not require any modification of the classifier model. 3) can be extended to perform further diagnosis (e.g. vulnerability assessment) and gain further understanding of the system. Experimental evaluation was conducted on the NSL-KDD99 benchmark dataset using Linear and Multilayer perceptron classifiers. The results are shown using intuitive visualizations in order to improve the interpretability of the results. © 2018 IEEE.},
  art_number    = {8591457},
  document_type = {Conference Paper},
  doi           = {10.1109/IECON.2018.8591457},
  groups        = {First Filtering},
  journal       = {Proceedings: IECON 2018 - 44th Annual Conference of the IEEE Industrial Electronics Society},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061527938&doi=10.1109%2fIECON.2018.8591457&partnerID=40&md5=007492c0052718d629f83cf92c19f271},
}

@Conference{Lin2019a,
  author        = {Lin, C.-Y. and Nadjm-Tehrani, S.},
  title         = {Timing patterns and correlations in spontaneous SCADA traffic for anomaly detection},
  year          = {2019},
  note          = {cited By 4},
  pages         = {73-88},
  abstract      = {Supervisory Control and Data Acquisition (SCADA) systems operate critical infrastructures in our modern society despite their vulnerability to attacks and misuse. There are several anomaly detection systems based on the cycles of polling mechanisms used in SCADA systems, but the feasibility of anomaly detection systems based on non-polling traffic, so called spontaneous events, is not well-studied. This paper presents a novel approach to modeling the timing characteristics of spontaneous events in an IEC-60870-5-104 network and exploits the model for anomaly detection. The system is tested with a dataset from a real power utility with injected timing effects from two attack scenarios. One attack causes timing anomalies due to persistent malfunctioning in the field devices, and the other generates intermittent anomalies caused by malware on the field devices, which is considered as stealthy. The detection accuracy and timing performance are promising for all the experiments with persistent anomalies. With intermittent anomalies, we found that our approach is effective for anomalies in low-volume traffic or attacks lasting over 1 hour. © 2019 RAID 2019 Proceedings - 22nd International Symposium on Research in Attacks, Intrusions and Defenses. All rights reserved.},
  document_type = {Conference Paper},
  groups        = {First Filtering},
  journal       = {RAID 2019 Proceedings - 22nd International Symposium on Research in Attacks, Intrusions and Defenses},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102740410&partnerID=40&md5=2e5c94d84ccbca9012432233493969b7},
}

@Book{Joseph2019,
  author        = {Joseph, A.D. and Nelson, B. and Nelson, B. and Tygar, J.D.},
  title         = {Adversarial machine learning},
  year          = {2019},
  note          = {cited By 13},
  abstract      = {Written by leading researchers, this complete introduction brings together all the theory and tools needed for building robust machine learning in adversarial environments. Discover how machine learning systems can adapt when an adversary actively poisons data to manipulate statistical inference, learn the latest practical techniques for investigating system security and performing robust data analysis, and gain insight into new approaches for designing effective countermeasures against the latest wave of cyber-attacks. Privacy-preserving mechanisms and the near-optimal evasion of classifiers are discussed in detail, and in-depth case studies on email spam and network security highlight successful attacks on traditional machine learning algorithms. Providing a thorough overview of the current state of the art in the field, and possible future directions, this groundbreaking work is essential reading for researchers, practitioners and students in computer security and machine learning, and those wanting to learn about the next stage of the cybersecurity arms race. © Cambridge University Press 2019.},
  document_type = {Book},
  doi           = {10.1017/9781107338548},
  groups        = {First Filtering},
  journal       = {Adversarial Machine Learning},
  pages         = {1-325},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098024328&doi=10.1017%2f9781107338548&partnerID=40&md5=ab92764e63d83edffb47d97846f3678d},
}

@Conference{Ghosh2019,
  author        = {Ghosh, P. and Losalka, A. and Black, M.J.},
  title         = {Resisting adversarial attacks using Gaussian mixture variational autoencoders},
  year          = {2019},
  note          = {cited By 2},
  pages         = {541-548},
  abstract      = {Susceptibility of deep neural networks to adversarial attacks poses a major theoretical and practical challenge. All efforts to harden classifiers against such attacks have seen limited success till now. Two distinct categories of samples against which deep neural networks are vulnerable, “adversarial samples” and “fooling samples”, have been tackled separately so far due to the difficulty posed when considered together. In this work, we show how one can defend against them both under a unified framework. Our model has the form of a variational autoencoder with a Gaussian mixture prior on the latent variable, such that each mixture component corresponds to a single class. We show how selective classification can be performed using this model, thereby causing the adversarial objective to entail a conflict. The proposed method leads to the rejection of adversarial samples instead of misclassification, while maintaining high precision and recall on test data. It also inherently provides a way of learning a selective classifier in a semi-supervised scenario, which can similarly resist adversarial attacks. We further show how one can reclassify the detected adversarial samples by iterative optimization. © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
  document_type = {Conference Paper},
  groups        = {First Filtering},
  journal       = {33rd AAAI Conference on Artificial Intelligence, AAAI 2019, 31st Innovative Applications of Artificial Intelligence Conference, IAAI 2019 and the 9th AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090801688&partnerID=40&md5=b715f07f7d480eca2e5c2c3c8d2e1fe1},
}

@Conference{Liu2019a,
  author        = {Liu, X. and Si, S. and Zhu, X. and Li, Y. and Hsieh, C.-J.},
  title         = {A unified framework for data poisoning attack to graph-based semi-supervised learning},
  year          = {2019},
  note          = {cited By 7},
  volume        = {32},
  abstract      = {In this paper, we proposed a general framework for data poisoning attacks to graph-based semi-supervised learning (G-SSL). In this framework, we first unify different tasks, goals and constraints into a single formula for data poisoning attack in G-SSL, then we propose two specialized algorithms to efficiently solve two important cases - poisoning regression tasks under 2 -norm constraint and classification tasks under o_norm constraint. In the former case, we transform it into a non-convex trust region problem and show that our gradient-based algorithm with delicate initialization and update scheme finds the (globally) optimal perturbation. For the latter case, although it is an NP-hard integer programming problem, we propose a probabilistic solver that works much better than the classical greedy method. Lastly, we test our framework on real datasets and evaluate the robustness of G-SSL algorithms. For instance, on the MNIST binary classification problem (50000 training data with 50 labeled), flipping two labeled data is enough to make the model perform like random guess (around 50% error). © 2019 Neural information processing systems foundation. All rights reserved.},
  document_type = {Conference Paper},
  groups        = {First Filtering},
  journal       = {Advances in Neural Information Processing Systems},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090177402&partnerID=40&md5=822ad4ae07ad681e8edc2d61d060ab96},
}

@Conference{Wang2019b,
  author        = {Wang, H. and Yu, C.-N.},
  title         = {A direct approach to robust deep learning using adversarial networks},
  year          = {2019},
  note          = {cited By 12},
  abstract      = {Deep neural networks have been shown to perform well in many classical machine learning problems, especially in image classification tasks. However, researchers have found that neural networks can be easily fooled, and they are surprisingly sensitive to small perturbations imperceptible to humans. Carefully crafted input images (adversarial examples) can force a well-trained neural network to provide arbitrary outputs. Including adversarial examples during training is a popular defense mechanism against adversarial attacks. In this paper we propose a new defensive mechanism under the generative adversarial network (GAN) framework. We model the adversarial noise using a generative network, trained jointly with a classification discriminative network as a minimax game. We show empirically that our adversarial network approach works well against black box attacks, with performance on par with state-of-art methods such as ensemble adversarial training and adversarial training with projected gradient descent. © 7th International Conference on Learning Representations, ICLR 2019. All Rights Reserved.},
  document_type = {Conference Paper},
  groups        = {First Filtering},
  journal       = {7th International Conference on Learning Representations, ICLR 2019},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083954043&partnerID=40&md5=05dcc3461b7b8ed9d1e3f92457b3460b},
}

@Article{Bakhti2019,
  author        = {Bakhti, Y. and Fezza, S.A. and Hamidouche, W. and Deforges, O.},
  journal       = {IEEE Access},
  title         = {DDSA: A Defense against Adversarial Attacks Using Deep Denoising Sparse Autoencoder},
  year          = {2019},
  note          = {cited By 8},
  pages         = {160397-160407},
  volume        = {7},
  abstract      = {Given their outstanding performance, the Deep Neural Networks (DNNs) models have been deployed in many real-world applications. However, recent studies have demonstrated that they are vulnerable to small carefully crafted perturbations, i.e., adversarial examples, which considerably decrease their performance and can lead to devastating consequences, especially for safety-critical applications, such as autonomous vehicles, healthcare and face recognition. Therefore, it is of paramount importance to offer defense solutions that increase the robustness of DNNs against adversarial attacks. In this paper, we propose a novel defense solution based on a Deep Denoising Sparse Autoencoder (DDSA). The proposed method is performed as a pre-processing step, where the adversarial noise of the input samples is removed before feeding the classifier. The pre-processing defense block can be associated with any classifier, without any change to their architecture or training procedure. In addition, the proposed method is a universal defense, since it does not require any knowledge about the attack, making it usable against any type of attack. The experimental results on MNIST and CIFAR-10 datasets have shown that the proposed DDSA defense provides a high robustness against a set of prominent attacks under white-, gray-and black-box settings, and outperforms state-of-The-Art defense methods. © 2013 IEEE.},
  art_number    = {8890816},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2019.2951526},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078224003&doi=10.1109%2fACCESS.2019.2951526&partnerID=40&md5=898c67a6e4ce06bea351310fd272c084},
}

@Conference{Zhang2019e,
  author        = {Zhang, H. and Yu, Y. and Jiao, J. and Xing, E.P. and Ghaoui, L.E. and Jordan, M.I.},
  title         = {Theoretically principled trade-off between robustness and accuracy},
  year          = {2019},
  note          = {cited By 50},
  pages         = {12907-12929},
  volume        = {2019-June},
  abstract      = {We identify a trade-off between robustness and accuracy that serves as a guiding principle in the design of defenses against adversarial examples. Although this problem has been widely studied empirically, much remains unknown concerning the theory underlying this trade-off. In this work, we decompose the prediction error for adversarial examples (robust error) as the sum of the natural (classification) error and boundary error, and provide a differentiable upper bound using the theory of classification-calibrated loss, which is shown to be the tightest possible upper bound uniform over all probability distributions and measurable predictors. Inspired by our theoretical analysis, we also design a new defense method, TRADES, to trade adversarial robustness off against accuracy. Our proposed algorithm performs well experimentally in real-world datasets. The methodology is the foundation of our entry to the NeurIPS 2018 Adversarial Vision Challenge in which wc won the 1st place out of -2,000 submissions, surpassing the runner-up approach by 11.41% in terms of mean £2 perturbation distance. © 36th International Conference on Machine Learning, ICML 2019. All rights reserved.},
  document_type = {Conference Paper},
  groups        = {First Filtering},
  journal       = {36th International Conference on Machine Learning, ICML 2019},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078072688&partnerID=40&md5=a5ae5514d2a2d41312bc7d372a4f4e66},
}

@Article{Liang2019b,
  author        = {Liang, F. and Hatcher, W.G. and Liao, W. and Gao, W. and Yu, W.},
  journal       = {IEEE Access},
  title         = {Machine Learning for Security and the Internet of Things: The Good, the Bad, and the Ugly},
  year          = {2019},
  note          = {cited By 20},
  pages         = {158126-158147},
  volume        = {7},
  abstract      = {The advancement of the Internet of Things (IoT) has allowed for unprecedented data collection, automation, and remote sensing and actuation, transforming autonomous systems and bringing smart command and control into numerous cyber physical systems (CPS) that our daily lives depend on. Simultaneously, dramatic improvements in machine learning and deep neural network architectures have enabled unprecedented analytical capabilities, which we see in increasingly common applications and production technologies, such as self-driving vehicles and intelligent mobile applications. Predictably, these technologies have seen rapid adoption, which has left many implementations vulnerable to threats unforeseen or undefended against. Moreover, such technologies can be used by malicious actors, and the potential for cyber threats, attacks, intrusions, and obfuscation that are only just being considered, applied, and countered. In this paper, we consider the good, the bad, and the ugly use of machine learning for cybersecurity and CPS/IoT. In detail, we consider the numerous benefits (good use) that machine learning has brought, both in general, and specifically for security and CPS/IoT, such as the improvement of intrusion detection mechanisms and decision accuracy in CPS/IoT. More pressing, we consider the vulnerabilities of machine learning (bad use) from the perspectives of security and CPS/IoT, including the ways in which machine learning systems can be compromised, misled, and subverted at all stages of the machine learning life-cycle (data collection, pre-processing, training, validation, implementation, etc.). Finally, the most concerning, a growing trend has been the utilization of machine learning in the execution of cyberattacks and intrusions (ugly use). Thus, we consider existing mechanisms with the potential to improve target acquisition and existing threat patterns, as well as those that can enable novel attacks yet to be seen. © 2013 IEEE.},
  art_number    = {8879591},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2019.2948912},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078057564&doi=10.1109%2fACCESS.2019.2948912&partnerID=40&md5=bb4230ef416c50d64363ee015c39a626},
}

@Article{Poongodi2019,
  author        = {Poongodi, M. and Vijayakumar, V. and Al-Turjman, F. and Hamdi, M. and Ma, M.},
  journal       = {IEEE Access},
  title         = {Intrusion Prevention System for DDoS Attack on VANET with reCAPTCHA Controller Using Information Based Metrics},
  year          = {2019},
  note          = {cited By 6},
  pages         = {158481-158491},
  volume        = {7},
  abstract      = {Due to the dynamic in nature, the vulnerabilities that exist in VANET are much higher when compared with that of the wired network infrastructure. In DoS attacks, the legitimate users are prohibited from accessing the services or network resource. The primary goal of the attack to make the desired destination vehicle unavailable or relegate the message all the way through the network affects the reachability. The proposed reCAPTCHA controller mechanism prevents the automated attacks similarly like botnet zombies. The reCAPTCHA controller is used to check and prohibit most of the automated DDoS attacks. For implementing this technique, the information theory based metric is used to analyze the deviation in users request in terms of entropy. Frequency and entropy are the metrics used to measure the vulnerability of the attack. The stochastic model based reCAPTCHA controller is used as a prevention mechanism for the large botnet based attackers. To inspect the efficiency of the proposed method, various network parameters are considered such as Packet Delivery Ratio (PDR), Average Latency (AL), Detection Rate (DR) and Energy Consumption (EC). In the proposed research work, the metric PDR is used to know successful delivery of data packets to the destination vehicle without any interrruption. These parameters are used to measure how effectively the data is delivered to the destination from source vehicle. © 2019 IEEE.},
  art_number    = {8859299},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2019.2945682},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077967062&doi=10.1109%2fACCESS.2019.2945682&partnerID=40&md5=9e5ae7408848086435a1a35eb92af6ae},
}

@Article{Boughaci2019,
  author        = {Boughaci, D.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {Stochastic Local Search Based Feature Selection for Intrusion Detection},
  year          = {2019},
  note          = {cited By 1},
  pages         = {404-417},
  volume        = {11927 LNAI},
  abstract      = {Intrusion detection is the ability to mitigate attacks and block new threats. In this paper, we deal with intrusion detection as a pattern classification problem where a connection is defined as a set of attributes. The latter forms a pattern that should be assigned to one of existing classes. The problem is to identify the given connection as a normal event or attack. We propose a stochastic local search method for feature selection where the aim is to select the set of significant attributes to be used in the classification task. The proposed approach is validated on the well-known NLS-KDD dataset and compared with some existing techniques. The results are interesting and show the efficiency of the proposed approach for intrusion detection. © 2019, Springer Nature Switzerland AG.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-34885-4_31},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076998468&doi=10.1007%2f978-3-030-34885-4_31&partnerID=40&md5=f21b6aeb3c756f764cd49ca794e068a1},
}

@Article{Podschwadt2019,
  author        = {Podschwadt, R. and Takabi, H.},
  journal       = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
  title         = {On Effectiveness of Adversarial Examples and Defenses for Malware Classification},
  year          = {2019},
  note          = {cited By 0},
  pages         = {380-393},
  volume        = {305 LNICST},
  abstract      = {Artificial neural networks have been successfully used for many different classification tasks including malware detection and distinguishing between malicious and non-malicious programs. Although artificial neural networks perform very well on these tasks, they are also vulnerable to adversarial examples. An adversarial example is a sample that has minor modifications made to it so that the neural network misclassifies it. Many techniques have been proposed, both for crafting adversarial examples and for hardening neural networks against them. Most previous work was done in the image domain. Some of the attacks have been adopted to work in the malware domain which typically deals with binary feature vectors. In order to better understand the space of adversarial examples in malware classification, we study different approaches of crafting adversarial examples and defense techniques in the malware domain and compare their effectiveness on multiple data sets. © ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2019.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-37231-6_22},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076930416&doi=10.1007%2f978-3-030-37231-6_22&partnerID=40&md5=adf0117f39adf1be6b151c8fa3674a2a},
}

@Article{GauthamaRaman2019,
  author        = {Gauthama Raman, M.R. and Somu, N. and Mathur, A.P.},
  journal       = {Communications in Computer and Information Science},
  title         = {Anomaly Detection in Critical Infrastructure Using Probabilistic Neural Network},
  year          = {2019},
  note          = {cited By 5},
  pages         = {129-141},
  volume        = {1116 CCIS},
  abstract      = {Supervisory Control and Data Acquisition (SCADA) systems forms a vital part of any critical infrastructure. Such systems are network integrated for remote monitoring and control making them vulnerable to intrusions by malicious actors. Such intrusions may lead to anomalous behavior of the underlying physical process. This work presents a Probabilistic Neural Network (PNN) based anomaly detector to detect anomalies arising consequent to a cyber attack. Experimental validation was conducted using the dataset obtained from an operational water treatment testbed, namely Secure Water Treatment (SWaT). The impact of the smoothening parameter on the performance of the PNN-based anomaly detector was analyzed. Experimental evaluations indicate the significance of the PNN-based anomaly detector, compared with several competing detectors, in terms of precision, F-score, false alarm rate, and detection rate. © 2019, Springer Nature Singapore Pte Ltd.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-981-15-0871-4_10},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076720437&doi=10.1007%2f978-981-15-0871-4_10&partnerID=40&md5=b631cbf97b68228c4cdd07e51ccf3020},
}

@Conference{Li2019e,
  author        = {Li, P. and Yi, J. and Zhou, B. and Zhang, L.},
  title         = {Improving the robustness of deep neural networks via adversarial training with triplet loss},
  year          = {2019},
  note          = {cited By 3},
  pages         = {2909-2915},
  volume        = {2019-August},
  abstract      = {Recent studies have highlighted that deep neural networks (DNNs) are vulnerable to adversarial examples. In this paper, we improve the robustness of DNNs by utilizing techniques of Distance Metric Learning. Specifically, we incorporate Triplet Loss, one of the most popular Distance Metric Learning methods, into the framework of adversarial training. Our proposed algorithm, Adversarial Training with Triplet Loss (AT2L), substitutes the adversarial example against the current model for the anchor of triplet loss to effectively smooth the classification boundary. Furthermore, we propose an ensemble version of AT2L, which aggregates different attack methods and model structures for better defense effects. Our empirical studies verify that the proposed approach can significantly improve the robustness of DNNs without sacrificing accuracy. Finally, we demonstrate that our specially designed triplet loss can also be used as a regularization term to enhance other defense methods. © 2019 International Joint Conferences on Artificial Intelligence. All rights reserved.},
  document_type = {Conference Paper},
  doi           = {10.24963/ijcai.2019/403},
  groups        = {First Filtering},
  journal       = {IJCAI International Joint Conference on Artificial Intelligence},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074934907&doi=10.24963%2fijcai.2019%2f403&partnerID=40&md5=e0cfdf51c6ca6ce8f808b6a8ef659e07},
}

@Article{Wang2019e,
  author        = {Wang, S.-W. and Zhou, G. and Lu, J.-C. and Zhang, F.-J.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {A Novel Malware Detection and Classification Method Based on Capsule Network},
  year          = {2019},
  note          = {cited By 3},
  pages         = {573-584},
  volume        = {11632 LNCS},
  abstract      = {By using camouflage technologies such as code confusion, packing and signature, malware could escape the killing of anti-virus software with a high probability. To detect malware efficiently, traditional machine learning methods usually require complex feature extraction work in advance, CNN and other deep learning methods usually need a large number of labeled samples, all of these will affect the detection performance. For these problems, an improved deep learning method (ColCaps) based on malware color image visualization technology and capsule network is proposed in this paper to detect malware. Firstly, the malware is transformed into a color image. Then, the dynamic routing-based capsule network is used to detect and classify the color image. Without advanced feature extraction and with only a small number of labeled samples, ColCaps has better performances in cross-platform detection and classification. The experimental results show that, the detection accuracy of the proposed method on Android and Windows platforms is 99.3% and 96.5% respectively, which is 20% higher than that of the existing method. Meanwhile, the classification task in Drebin dataset has an accuracy of 98.2%, which is a significant improvement over the prior DREBIN. © 2019, Springer Nature Switzerland AG.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-24274-9_52},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073894979&doi=10.1007%2f978-3-030-24274-9_52&partnerID=40&md5=8641f462575bb07ce6031e6ea2a20b5e},
}

@Article{Lai2019,
  author        = {Lai, Y. and Zhang, J. and Liu, Z.},
  journal       = {Security and Communication Networks},
  title         = {Industrial Anomaly Detection and Attack Classification Method Based on Convolutional Neural Network},
  year          = {2019},
  note          = {cited By 6},
  volume        = {2019},
  abstract      = {The massive use of information technology has brought certain security risks to the industrial production process. In recent years, cyber-physical attacks against industrial control systems have occurred frequently. Anomaly detection technology is an essential technical means to ensure the safety of industrial control systems. Considering the shortcomings of traditional methods and to facilitate the timely analysis and location of anomalies, this study proposes a solution based on the deep learning method for industrial traffic anomaly detection and attack classification. We use a convolutional neural network deep learning representation model as the detection model. The original one-dimensional data are mapped using the feature mapping method to make them suitable for model processing. The deep learning method can automatically extract critical features and achieve accurate attack classification. We performed a model evaluation using real network attack data from a supervisory control and data acquisition (SCADA) system. The experimental results showed that the proposed method met the anomaly detection and attack classification needs of a SCADA system. The proposed method also promotes the application of deep learning methods in industrial anomaly detection. © 2019 Yingxu Lai et al.},
  art_number    = {8124254},
  document_type = {Article},
  doi           = {10.1155/2019/8124254},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073608655&doi=10.1155%2f2019%2f8124254&partnerID=40&md5=da847da089c32d5619282ca722ed4a4b},
}

@Article{Yi2019,
  author        = {Yi, Z. and Yu, J. and Li, S. and Tan, Y. and Wu, Q.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {Incremental learning of GAN for detecting multiple adversarial attacks},
  year          = {2019},
  note          = {cited By 1},
  pages         = {673-684},
  volume        = {11729 LNCS},
  abstract      = {Neural networks are vulnerable to adversarial attack. Carefully crafted small perturbations can cause misclassification of neural network classifiers. As adversarial attack is a serious potential problem in many neural network based applications and new attacks always come up, it’s urgent to explore the detection strategies that can adapt new attacks quickly. Moreover, the detector is hard to train with limited samples. To solve these problems, we propose a GAN based incremental learning framework with Jacobian-based data augmentation to detect adversarial samples. To prove the proposed framework works on multiple adversarial attacks, we implement FGSM, LocSearchAdv, PSO-based attack on MNIST and CIFAR-10 dataset. The experiments show that our detection framework performs well on these adversarial attacks. © Springer Nature Switzerland AG 2019.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-30508-6_53},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072863713&doi=10.1007%2f978-3-030-30508-6_53&partnerID=40&md5=d9f84134c6bbfb14ef349f476de10fe6},
}

@Article{Hwang2019a,
  author        = {Hwang, U. and Park, J. and Jang, H. and Yoon, S. and Cho, N.I.},
  journal       = {IEEE Access},
  title         = {PuVAE: A Variational Autoencoder to Purify Adversarial Examples},
  year          = {2019},
  note          = {cited By 7},
  pages         = {126582-126593},
  volume        = {7},
  abstract      = {Deep neural networks are widely used and exhibit excellent performance in many areas. However, they are vulnerable to adversarial attacks that compromise networks at inference time by applying elaborately designed perturbations to input data. Although several defense methods have been proposed to address specific attacks, other types of attacks can circumvent these defense mechanisms. Therefore, we propose Purifying Variational AutoEncoder (PuVAE), a method to purify adversarial examples. The proposed method eliminates an adversarial perturbation by projecting an adversarial example on the manifold of each class and determining the closest projection as a purified sample. We experimentally illustrate the robustness of PuVAE against various attack methods without any prior knowledge about the attacks. In our experiments, the proposed method exhibits performances that are competitive with state-of-the-art defense methods, and the inference time is approximately 130 times faster than that of Defense-GAN which is a state-of-the art purifier method. © 2013 IEEE.},
  art_number    = {8824108},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2019.2939352},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072579111&doi=10.1109%2fACCESS.2019.2939352&partnerID=40&md5=034919fd7a0b7fddfe29064368145add},
}

@Conference{Tu2019,
  author        = {Tu, C.-C. and Ting, P. and Chen, P.-Y. and Liu, S. and Zhang, H. and Yi, J. and Hsieh, C.-J. and Cheng, S.-M.},
  title         = {AutoZOOM: Autoencoder-based zeroth order optimization method for attacking black-box neural networks},
  year          = {2019},
  note          = {cited By 45},
  pages         = {742-749},
  abstract      = {Recent studies have shown that adversarial examples in state-of-the-art image classifiers trained by deep neural networks (DNN) can be easily generated when the target model is transparent to an attacker, known as the white-box setting. However, when attacking a deployed machine learning service, one can only acquire the input-output correspondences of the target model; this is the so-called black-box attack setting. The major drawback of existing black-box attacks is the need for excessive model queries, which may give a false sense of model robustness due to inefficient query designs. To bridge this gap, we propose a generic framework for query-efficient black-box attacks. Our framework, AutoZOOM, which is short for Autoencoder-based Zeroth Order Optimization Method, has two novel building blocks towards efficient black-box attacks: (i) an adaptive random gradient estimation strategy to balance query counts and distortion, and (ii) an autoencoder that is either trained offline with unlabeled data or a bilinear resizing operation for attack acceleration. Experimental results suggest that, by applying AutoZOOM to a state-of-the-art black-box attack (ZOO), a significant reduction in model queries can be achieved without sacrificing the attack success rate and the visual quality of the resulting adversarial examples. In particular, when compared to the standard ZOO method, AutoZOOM can consistently reduce the mean query counts in finding successful adversarial examples (or reaching the same distortion level) by at least 93% on MNIST, CIFAR-10 and ImageNet datasets, leading to novel insights on adversarial robustness. © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
  document_type = {Conference Paper},
  groups        = {First Filtering},
  journal       = {33rd AAAI Conference on Artificial Intelligence, AAAI 2019, 31st Innovative Applications of Artificial Intelligence Conference, IAAI 2019 and the 9th AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071155612&partnerID=40&md5=3896f9019648529cb887048ab740c523},
}

@Conference{Anton2019a,
  author        = {Antón, S.D. and Schotten, H.D.},
  title         = {Putting together the pieces: A concept for holistic industrial intrusion detection},
  year          = {2019},
  note          = {cited By 3},
  pages         = {178-186},
  volume        = {2019-July},
  abstract      = {The fourth industrial revolution, resulting in Industry 4.0, provides a variety of novel business cases. These business cases provide benefits with respect to cost, effort, customer satisfaction and production time. Progress in production can be monitored in real-time by the customer, maintenance can be performed in a remote fashion, time-and cost-efficient production of customer specific products is enabled. These business cases are founded on characteristics of digitisation, namely an increase in intercommunication and embedded computational capacities. Besides the advantages derived from the ever present communication properties, it increases the attack surface of a network as well. As industrial protocols and systems were not designed with security in mind, spectacular attacks on industrial systems occurred over the last years. Most industrial communication protocols do not provide means to ensure authentication or encryption. This means attackers with access to a network can read and write information. Originally not meant to be connected to public networks, the use cases of Industry 4.0 require interconnectivity, often through insecure public networks. This lead to an increasing interest in information security products for industrial applications. In this work, the concept for holistic intrusion detection methods in an industrial context is presented. It is based on different works considering several aspects of industrial environments and their capabilities to identify intrusions as an anomaly in network or process data. These capabilities are based on preceding experiments on real and synthetic data. In order to justify the concept, an overview of potential and actual attack vectors and attacks on industrial systems is provided. It is shown that different aspects of industrial facilities, e.g. office IT, shop floor OT, firewalled connections to customers and partners are analysed as well as the different layers of the automation pyramid require different methods to detect attacks. Additionally, the singular steps of an attack on industrial applications are characterised. Finally, a resulting concept for integration of these methods is proposed, providing the means to detect the different stages of an attack by different means. © 2019, Curran Associates Inc. All rights reserved.},
  document_type = {Conference Paper},
  groups        = {First Filtering},
  journal       = {European Conference on Information Warfare and Security, ECCWS},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070020038&partnerID=40&md5=9aca948fd3b6248ba6861e0eb8fa7beb},
}

@Article{Khan2019,
  author        = {Khan, I.A. and Pi, D. and Khan, Z.U. and Hussain, Y. and Nawaz, A.},
  journal       = {IEEE Access},
  title         = {Hml-ids: A hybrid-multilevel anomaly prediction approach for intrusion detection in scada systems},
  year          = {2019},
  note          = {cited By 29},
  pages         = {89507-89521},
  volume        = {7},
  abstract      = {Critical infrastructures, e.g., electricity generation and dispersal networks, chemical processing plants, and gas distribution, are governed and monitored by supervisory control and data acquisition systems (SCADA). Detecting intrusion is a prevalent area of study for numerous years, and several intrusion detection systems have been suggested in the literature for cyber-physical systems and industrial control system (ICS). In recent years, the viruses seismic net, duqu, and flame against ICS attacks have caused tremendous damage to nuclear facilities and critical infrastructure in some countries. These intensified attacks have sounded the alarm for the security of the ICS in many countries. The challenge in constructing an intrusion detection framework is to deal with unbalanced intrusion datasets, i.e. when one class is signified by a lesser amount of instances (minority class). To this end, we outline an approach to deal with this issue and propose an anomaly detection method for the ICS. Our proposed approach uses a hybrid model that takes advantage of the anticipated and consistent nature of communication patterns that occur among ground devices in ICS setups. First, we applied some preprocessing techniques to standardize and scale the data. Second, the dimensionality reduction algorithms are applied to improve the process of anomaly detection. Third, we employed an edited nearest-neighbor rule algorithm to balance the dataset. Fourth, by using the Bloom filter, a signature database is created by noting the system for a specific period lacking the occurrence of abnormalities. Finally, to detect new attacks, we combined our package contents-level detection with another instance-based learner to make a hybrid method for anomaly detection. The experimental results with a real large-scale dataset generated from a gas pipeline SCADA system show that the proposed approach HML-IDS outperforms the benchmark models with an accuracy rate of 97%. © 2013 IEEE.},
  art_number    = {8751972},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2019.2925838},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069760403&doi=10.1109%2fACCESS.2019.2925838&partnerID=40&md5=469a64f0b4cd40b3292fb7ca33462e4d},
}

@Article{Genge2019,
  author        = {Genge, B. and Haller, P. and Enachescu, C.},
  journal       = {IEEE Access},
  title         = {Anomaly Detection in Aging Industrial Internet of Things},
  year          = {2019},
  note          = {cited By 3},
  pages         = {74217-74230},
  volume        = {7},
  abstract      = {The Industrial Internet of Things (IIoT) have been designed to perform a more agile and efficient automation, control, and orchestration of future industrial systems while improving the energy efficiency in smart factories. Unfortunately, while the benefits of the IIoT are undeniable, their pervasive adoption as key enablers for future industries also paved the way for new security risks. In fact, the damaging effects of exploiting vulnerable IIoT have been repeatedly demonstrated and publicly reported. The Mirai botnet, various reports on hackable and invasive devices, alongside the infamous Stuxnet malware, constitute significant proof on the undisputed and disruptive effect of the malware-targeting IIoT systems. As a response, a plethora of solutions has been developed to address the issue of securing IIoT systems in specific sectors. Nevertheless, we believe that the gradual decay of the IIoT's physical dimension (e.g., the physical process), also called aging, is a natural component of the IIoT's life cycle, which has not received sufficient attention from the scientific community. This paper develops a methodology for detecting abnormal behavior in the context of aging IIoT. The approach leverages multivariate statistical analysis [e.g., principle component analysis (PCA)], alongside the Hotelling's $T^{2}$ statistics, and the univariate cumulative sum in order to detect abnormal process events. An innovative feature of the developed approach is the detection of stealth attacks attempting to influence the dataset in each age. The extensive experimental results on a continuous stirred-tank reactor (CSTR) model demonstrate its applicability to the IIoT and its superior performance to the recently reported techniques. © 2013 IEEE.},
  art_number    = {8730334},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2019.2920699},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068323376&doi=10.1109%2fACCESS.2019.2920699&partnerID=40&md5=4a6877d0f88204a5ffacb6fd6afd2034},
}

@Article{Liu2019g,
  author        = {Liu, G. and Khalil, I. and Khreishah, A.},
  journal       = {IFIP Advances in Information and Communication Technology},
  title         = {GanDef: A GAN based adversarial training defense for neural network classifier},
  year          = {2019},
  note          = {cited By 2},
  pages         = {19-32},
  volume        = {562},
  abstract      = {Machine learning models, especially neural network (NN) classifiers, are widely used in many applications including natural language processing, computer vision and cybersecurity. They provide high accuracy under the assumption of attack-free scenarios. However, this assumption has been defied by the introduction of adversarial examples – carefully perturbed samples of input that are usually misclassified. Many researchers have tried to develop a defense against adversarial examples; however, we are still far from achieving that goal. In this paper, we design a Generative Adversarial Net (GAN) based adversarial training defense, dubbed GanDef, which utilizes a competition game to regulate the feature selection during the training. We analytically show that GanDef can train a classifier so it can defend against adversarial examples. Through extensive evaluation on different white-box adversarial examples, the classifier trained by GanDef shows the same level of test accuracy as those trained by state-of-the-art adversarial training defenses. More importantly, GanDef-Comb, a variant of GanDef, could utilize the discriminator to achieve a dynamic trade-off between correctly classifying original and adversarial examples. As a result, it achieves the highest overall test accuracy when the ratio of adversarial examples exceeds 41.7%. © IFIP International Federation for Information Processing 2019.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-22312-0_2},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068206491&doi=10.1007%2f978-3-030-22312-0_2&partnerID=40&md5=87f1ab71dc6b981b6a269f653d736242},
}

@Article{Lu2019,
  author        = {Lu, J. and Lv, F. and Zhuo, Z. and Zhang, X. and Liu, X. and Hu, T. and Deng, W.},
  journal       = {Security and Communication Networks},
  title         = {Integrating traffics with network device logs for anomaly detection},
  year          = {2019},
  note          = {cited By 2},
  volume        = {2019},
  abstract      = {Advanced cyberattacks are often featured by multiple types, layers, and stages, with the goal of cheating the monitors. Existing anomaly detection systems usually search logs or traffics alone for evidence of attacks but ignore further analysis about attack processes. For instance, the traffic detection methods can only detect the attack flows roughly but fail to reconstruct the attack event process and reveal the current network node status. As a result, they cannot fully model the complex multistage attack. To address these problems, we present Traffic-Log Combined Detection (TLCD), which is a multistage intrusion analysis system. Inspired by multiplatform intrusion detection techniques, we integrate traffics with network device logs through association rules. TLCD correlates log data with traffic characteristics to reflect the attack process and construct a federated detection platform. Specifically, TLCD can discover the process steps of a cyberattack attack, reflect the current network status, and reveal the behaviors of normal users. Our experimental results over different cyberattacks demonstrate that TLCD works well with high accuracy and low false positive rate. © 2019 Jiazhong Lu et al.},
  art_number    = {5695021},
  document_type = {Article},
  doi           = {10.1155/2019/5695021},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068170810&doi=10.1155%2f2019%2f5695021&partnerID=40&md5=e3493a0901be9c06ea8bc8d406f84bbb},
}

@Article{Chen2019g,
  author        = {Chen, B. and Ren, Z. and Yu, C. and Hussain, I. and Liu, J.},
  journal       = {IEEE Access},
  title         = {Adversarial examples for cnn-based malware detectors},
  year          = {2019},
  note          = {cited By 8},
  pages         = {54360-54371},
  volume        = {7},
  abstract      = {The convolutional neural network (CNN)-based models have achieved tremendous breakthroughs in many end-To-end applications, such as image identification, text classification, and speech recognition. By replicating these successes to the field of malware detection, several CNN-based malware detectors have achieved encouraging performance without significant feature engineering effort in recent years. Unfortunately, by analyzing their robustness using gradient-based algorithms, several studies have shown that some of these malware detectors are vulnerable to the evasion attacks (also known as adversarial examples). However, the existing attack methods can only achieve quite low attack success rates. In this paper, we propose two novel white-box methods and one novel black-box method to attack a recently proposed malware detector. By incorporating the gradient-based algorithm, one of our white-box methods can achieve a success rate of over 99%. Without prior knowledge of the exact structure and internal parameters of the detector, the proposed black-box method can also achieve a success rate of over 70%. In addition, we consider adversarial training as a defensive mechanism in order to resist evasion attacks. While proving the effectiveness of adversarial training, we also analyze its security risk, that is, a large number of adversarial examples can poison the training dataset of the detector. Therefore, we propose a pre-detection mechanism to reject adversarial examples. The experiments show that this mechanism can effectively improve the safety and efficiency of malware detection. © 2013 IEEE.},
  art_number    = {8703786},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2019.2913439},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066849191&doi=10.1109%2fACCESS.2019.2913439&partnerID=40&md5=34a994ed1348e23af3ec8b918b7c723f},
}

@Article{Gu2019,
  author        = {Gu, Y. and Li, K. and Guo, Z. and Wang, Y.},
  journal       = {IEEE Access},
  title         = {Semi-supervised k-means ddos detection method using hybrid feature selection algorithm},
  year          = {2019},
  note          = {cited By 27},
  pages         = {64351-64365},
  volume        = {7},
  abstract      = {Distributed denial of service (DDoS) attack is an attempt to make an online service unavailable by overwhelming it with traffic from multiple sources. Therefore, it is necessary to propose an effective method to detect DDoS attack from massive data traffics. However, the existing schemes have some limitations, including that supervised learning methods, need large numbers of labeled data and unsupervised learning algorithms have relatively low detection rate and high false positive rate. In order to tackle these issues, this paper presents a semi-supervised weighted k-means detection method. Specifically, we firstly present a Hadoop-based hybrid feature selection algorithm to find the most effective feature sets and propose an improved density-based initial cluster centers selection algorithm to solve the problem of outliers and local optimal. Then, we provide the Semi-supervised K-means algorithm using hybrid feature selection (SKM-HFS) to detect attacks. Finally, we exploit DARPA DDoS dataset, CAIDA 'DDoS attack 2007' dataset, CICIDS 'DDoS attack 2017' dataset and real-world dataset to carry out the verification experiment. The experiment results have demonstrated that the proposed method outperforms the benchmark in the respect of detection performance and technique for order preference by similarity to an ideal solution (TOPSIS) evaluation factor. © 2013 IEEE.},
  art_number    = {8717648},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2019.2917532},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066734794&doi=10.1109%2fACCESS.2019.2917532&partnerID=40&md5=3f97d677382aeed003be8739be2c4d20},
}

@Article{Kumar2019,
  author        = {Kumar, R. and Zhang, X. and Wang, W. and Khan, R.U. and Kumar, J. and Sharif, A.},
  journal       = {IEEE Access},
  title         = {A Multimodal Malware Detection Technique for Android IoT Devices Using Various Features},
  year          = {2019},
  note          = {cited By 28},
  pages         = {64411-64430},
  volume        = {7},
  abstract      = {Internet of things (IoT) is revolutionizing this world with its evolving applications in various aspects of life such as sensing, healthcare, remote monitoring, and so on. Android devices and applications are working hand to hand to realize dreams of the IoT. Recently, there is a rapid increase in threats and malware attacks on Android-based devices. Moreover, due to extensive exploitation of the Android platform in the IoT devices creates a task challenging of securing such kind of malware activities. This paper presents a novel framework that combines the advantages of both machine learning techniques and blockchain technology to improve the malware detection for Android IoT devices. The proposed technique is implemented using a sequential approach, which includes clustering, classification, and blockchain. Machine learning automatically extracts the malware information using clustering and classification technique and store the information into the blockchain. Thereby, all malware information stored in the blockchain history can be communicated through the network, and therefore any latest malware can be detected effectively. The implementation of the clustering technique includes calculation of weights for each feature set, the development of parametric study for optimization and simultaneously iterative reduction of unnecessary features having small weights. The classification algorithm is implemented to extract the various features of Android malware using naive Bayes classifier. Moreover, the naive Bayes classifier is based on decision trees for extracting more important features to provide classification and regression for achieving high accuracy and robustness. Finally, our proposed framework uses the permissioned blockchain to store authentic information of extracted features in a distributed malware database blocks to increase the run-time detection of malware with more speed and accuracy, and further to announce malware information for all users. © 2019 IEEE.},
  art_number    = {8721053},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2019.2916886},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066625960&doi=10.1109%2fACCESS.2019.2916886&partnerID=40&md5=397adfa5ef4bb64d8f2745870d9737e1},
}

@Article{Chohra2019,
  author        = {Chohra, A. and Debbabi, M. and Shirani, P.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {Daedalus: Network Anomaly Detection on IDS Stream Logs},
  year          = {2019},
  note          = {cited By 0},
  pages         = {95-111},
  volume        = {11358 LNCS},
  abstract      = {In this paper, we propose a scalable framework, called Daedalus, to analyze streams of NIDS (network-based intrusion detection system) logs in near real-time and to extract useful threat security intelligence. The proposed system pre-processes huge amounts of BRO NIDS logs received from different participating organizations and applies an elaborated anomaly detection technique in order to distinguish between normal and abnormal or anomalous network behaviors. As such, Daedalus detects network traffic anomalies by extracting a set of features of interest from the connection logs and then applying a time series-based technique in order to detect abnormal behavior in near real-time. Moreover, we correlate IP blocks extracted from the logs with some external security signature-based feeds that detect factual malicious activities (e.g., malware families and hashes, ransomware distribution, and command and control centers) in order to validate the proposed approach. Performed experiments demonstrate that Daedalus accurately identifies the malicious activities with an average score of. We further compare our proposed approach with existing K-Means approaches and demonstrate the accuracy and efficiency of our system. © 2019, Springer Nature Switzerland AG.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-18419-3_7},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066038716&doi=10.1007%2f978-3-030-18419-3_7&partnerID=40&md5=dfe662abc494499165058c4562f8ec2b},
}

@Article{Karray2019,
  author        = {Karray, K. and Danger, J.-L. and Guilley, S. and Elaabid, M.A.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {Prediction-based intrusion detection system for in-vehicle networks using supervised learning and outlier-detection},
  year          = {2019},
  note          = {cited By 0},
  pages         = {109-128},
  volume        = {11469 LNCS},
  abstract      = {Modern connected vehicles are composed of multiple electronic control units (ECUs) holding sensors, actuators but also wired and wireless connection interfaces, all communicating over shared internal communication buses. The cyber-physical architecture based on this ECU network has been proven vulnerable to multiple types of attacks leveraging remote, direct and indirect physical access. Attacks initiated from these access vectors go through the internal communication buses and spread over the whole network of ECUs. For this reason it is important to detect, and if possible to mitigate, attacks on the internal buses of the vehicle. In this article, a novel intrusion detection system is developed to monitor vehicle state from information collected on internal buses. Based on supervised machine learning techniques, a normal behavior is learned and used as a reference to detect deviations. The principle is to learn how to predict the next state of the vehicle based on information and sensor values sent over communication buses. Experimental validation is conducted using data collected from different drivers. Results show that the approach is able to learn the nominal behavior with high accuracy for a single driver as well as for a set of different drivers. Results also demonstrate its ability to predict attacks with low false negative rate. This motivates the approach to be used for indirect and remote attacks intrusion detection as well as for safety purposes to detect sensor failures, lost connection with the sensor, etc. © IFIP International Federation for Information Processing 2019.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-20074-9_9},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065881486&doi=10.1007%2f978-3-030-20074-9_9&partnerID=40&md5=f39c69fdb372b1100d67579657908322},
}

@Article{Priyanga2019,
  author        = {Priyanga, S. and Gauthama Raman, M.R. and Jagtap, S.S. and Aswin, N. and Kirthivasan, K. and Shankar Sriram, V.S.},
  journal       = {Journal of Intelligent and Fuzzy Systems},
  title         = {An improved rough set theory based feature selection approach for intrusion detection in SCADA systems},
  year          = {2019},
  note          = {cited By 7},
  number        = {5},
  pages         = {3993-4003},
  volume        = {36},
  abstract      = {Despite the increasing awareness of cyber-Attacks against Critical Infrastructure (CI), safeguarding the Supervisory Control and Data Acquisition (SCADA) systems remains inadequate. For this purpose, designing an efficient SCADA Intrusion Detection System (IDS) becomes a significant research topic of the researchers to counter cyber-Attacks. Most of the existing works present several statistical and machine learning approaches to prevent the SCADA network from the cyber-Attacks. Whereas, these approaches failed to concern the most common challenge, "Curse of dimensionality". This scenario accentuates the necessity of an efficient feature selection algorithm in SCADA IDS where it identifies the relevant features and eliminates the redundant features without any loss of information. Hence, this paper proposes a novel filter-based feature selection approach for the identification of informative features based on Rough Set Theory and Hyper-clique based Binary Whale Optimization Algorithm (RST-HCBWoA). Experiments were carried out by Power system attack dataset and the performance of RST-HCBWoA was evaluated in terms of reduct size, precision, recall, classification accuracy, and time complexity. © 2019 - IOS Press and the authors.},
  document_type = {Article},
  doi           = {10.3233/JIFS-169960},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065853262&doi=10.3233%2fJIFS-169960&partnerID=40&md5=6e75dedfcd22e39a0eaacefdf203931e},
}

@Article{RadoglouGrammatikis2019,
  author        = {Radoglou-Grammatikis, P.I. and Sarigiannidis, P.G.},
  journal       = {IEEE Access},
  title         = {Securing the Smart Grid: A Comprehensive Compilation of Intrusion Detection and Prevention Systems},
  year          = {2019},
  note          = {cited By 39},
  pages         = {46595-46620},
  volume        = {7},
  abstract      = {The smart grid (SG) paradigm is the next technological leap of the conventional electrical grid, contributing to the protection of the physical environment and providing multiple advantages such as increased reliability, better service quality, and the efficient utilization of the existing infrastructure and the renewable energy resources. However, despite the fact that it brings beneficial environmental, economic, and social changes, the existence of such a system possesses important security and privacy challenges, since it includes a combination of heterogeneous, co-existing smart, and legacy technologies. Based on the rapid evolution of the cyber-physical systems (CPS), both academia and industry have developed appropriate measures for enhancing the security surface of the SG paradigm using, for example, integrating efficient, lightweight encryption and authorization mechanisms. Nevertheless, these mechanisms may not prevent various security threats, such as denial of service (DoS) attacks that target on the availability of the underlying systems. An efficient countermeasure against several cyberattacks is the intrusion detection and prevention system (IDPS). In this paper, we examine the contribution of the IDPSs in the SG paradigm, providing an analysis of 37 cases. More detailed, these systems can be considered as a secondary defense mechanism, which enhances the cryptographic processes, by timely detecting or/and preventing potential security violations. For instance, if a cyberattack bypasses the essential encryption and authorization mechanisms, then the IDPS systems can act as a secondary protection service, informing the system operator for the presence of the specific attack or enabling appropriate preventive countermeasures. The cases we study focused on the advanced metering infrastructure (AMI), supervisory control and data acquisition (SCADA) systems, substations, and synchrophasors. Based on our comparative analysis, the limitations and the shortcomings of the current IDPS systems are identified, whereas appropriate recommendations are provided for future research efforts. © 2013 IEEE.},
  art_number    = {8684225},
  document_type = {Article},
  doi           = {10.1109/ACCESS.2019.2909807},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065088345&doi=10.1109%2fACCESS.2019.2909807&partnerID=40&md5=6f165ac86706663804ec1b272f69ecd1},
}

@Article{Puuska2019,
  author        = {Puuska, S. and Kokkonen, T. and Alatalo, J. and Heilimo, E.},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {Anomaly-based network intrusion detection using wavelets and adversarial autoencoders},
  year          = {2019},
  note          = {cited By 4},
  pages         = {234-246},
  volume        = {11359 LNCS},
  abstract      = {The number of intrusions and attacks against data networks and networked systems increases constantly, while encryption has made it more difficult to inspect network traffic and classify it as malicious. In this paper, an anomaly-based intrusion detection system using Haar wavelet transforms in combination with an adversarial autoencoder was developed for detecting malicious TLS-encrypted Internet traffic. Data containing legitimate, as well as advanced malicious traffic was collected from a large-scale cyber exercise and used in the analysis. Based on the findings and domain expertise, a set of features for distinguishing modern malware from packet timing analysis were chosen and evaluated. Performance of the adversarial autoencoder was compared with a traditional autoencoder. The results indicate that the adversarial model performs better than the traditional autoencoder. In addition, a machine learning pipeline capable of analyzing traffic in near real time was developed for data analysis. © Springer Nature Switzerland AG 2019.},
  document_type = {Conference Paper},
  doi           = {10.1007/978-3-030-12942-2_18},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062943123&doi=10.1007%2f978-3-030-12942-2_18&partnerID=40&md5=c35614b0d0c05ebc68d897c6009f16db},
}

@Conference{Auernhammer2019,
  author        = {Auernhammer, K. and Kolagari, R.T. and Zoppelt, M.},
  title         = {Attacks on machine learning: Lurking danger for accountability},
  year          = {2019},
  note          = {cited By 0},
  volume        = {2301},
  abstract      = {It is well-known that there is no safety without security. That being said, a sound investigation of security breaches on Machine Learning (ML) is a prerequisite for any safety concerns. Since attacks on ML systems and their impact on the security goals threaten the safety of an ML system, we discuss the impact attacks have on the ML models’ security goals, which are rarely considered in published scientific papers. The contribution of this paper is a non-exhaustive list of published attacks on ML models and a categorization of attacks according to their phase (training, after-training) and their impact on security goals. Based on our categorization we show that not all security goals have yet been considered in the literature, either because they were ignored or there are no publications on attacks targeting those goals specifically, and that some are difficult to assess, such as accountability. This is probably due to some ML models being a black box. © 2019 CEUR-WS. All rights reserved.},
  document_type = {Conference Paper},
  groups        = {First Filtering},
  journal       = {CEUR Workshop Proceedings},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060595287&partnerID=40&md5=8470529fab84c34eb61dcaa923c452fe},
}

@Conference{Kurniabudi2019,
  author        = {Kurniabudi and Purnama, B. and Sharipuddin and Stiawan, D. and Darmawijoyo and Budiarto, R.},
  title         = {Preprocessing and Framework for Unsupervised Anomaly Detection in IoT: Work on Progress},
  year          = {2019},
  note          = {cited By 3},
  pages         = {345-350},
  abstract      = {A robust increasing on smart sensors in Internet of Thing (IoT) results huge and heterogenous data and becomes a challenge in data prepocessing and analysis for anomaly detection. The lack of IoT publicly available dataset is one issue in anomaly detection research. To resolve that problem, a testbed topology is proposed in this research. In addition, a high-dimensionality data analysis faces a computational complexity. The purpose of this study is to presents a global framework for anomaly detection in IoT and proposes a distributed preprocessing framework. Unsupervised learning approach has been chosen to reduce dimensionality of IoT data traffic. © 2018 IEEE.},
  art_number    = {8605231},
  document_type = {Conference Paper},
  doi           = {10.1109/ICECOS.2018.8605231},
  groups        = {First Filtering},
  journal       = {Proceedings of 2018 International Conference on Electrical Engineering and Computer Science, ICECOS 2018},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061921692&doi=10.1109%2fICECOS.2018.8605231&partnerID=40&md5=8032d26465af3df00eba143b906ef8f9},
}

@Conference{Nomm2019,
  author        = {Nomm, S. and Bahsi, H.},
  title         = {Unsupervised Anomaly Based Botnet Detection in IoT Networks},
  year          = {2019},
  note          = {cited By 24},
  pages         = {1048-1053},
  abstract      = {Anomaly-based detection of the IoT botnets with emphasis on feature selection is elaborated in this paper. Due to the rapid growth of the Internet of Things technology, the number of vulnerable devices that become a part of a botnet has grown significantly. The detection of such malicious traffic is essential for taking timely countermeasures. While the idea of anomaly-based attack detection is not new and has been extensively studied, much less attention has been paid to dimensionality reduction in learning models induced for IoT networks. In this paper, we showed that it is possible to induce high accurate unsupervised learning models with reduced feature set sizes, which enables to decrease the required computational resources. Training one common model for all IoT devices, instead of dedicated model for each device, is another design option that is evaluated for resource optimization. © 2018 IEEE.},
  art_number    = {8614196},
  document_type = {Conference Paper},
  doi           = {10.1109/ICMLA.2018.00171},
  groups        = {First Filtering},
  journal       = {Proceedings - 17th IEEE International Conference on Machine Learning and Applications, ICMLA 2018},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062236840&doi=10.1109%2fICMLA.2018.00171&partnerID=40&md5=2f2decf25f179a71017ddc47928baa06},
}

@Article{Kim2019,
  author        = {Kim, H. and Kim, J. and Kim, Y. and Kim, I. and Kim, K.J. and Kim, H.},
  journal       = {Cluster Computing},
  title         = {Improvement of malware detection and classification using API call sequence alignment and visualization},
  year          = {2019},
  note          = {cited By 15},
  pages         = {921-929},
  volume        = {22},
  abstract      = {Conventional malware detection technologies have the limitation to detect malware because recent malware uses a variety of the avoidance techniques such as obfuscation, packing, anti-virtualization, anti-emulation, encapsulation technology in order to evade the detection of malware. To overcome this limitation, it is necessary to obtain new detection technology which is able to quickly analyze massive malware and its variants, and take the rapid response to cyber intrusion. Therefore in this paper, we proposed the malware detection and classification method and implementation of our system based on the dynamic analysis using the behavioral sequence of malware (API call sequence) and sequence alignment algorithm (MSA). Also we evaluated the effectiveness of our proposed method through the experiment. © 2017, Springer Science+Business Media, LLC.},
  document_type = {Article},
  doi           = {10.1007/s10586-017-1110-2},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029151924&doi=10.1007%2fs10586-017-1110-2&partnerID=40&md5=6b83a73be3b1b5447d6b751a18eee9cc},
}

@Article{Zhao2019c,
  author        = {Zhao, P. and Jiang, H. and Wang, C. and Huang, H. and Liu, G. and Yang, Y.},
  journal       = {IEEE Internet of Things Journal},
  title         = {On the Performance of k-Anonymity Against Inference Attacks with Background Information},
  year          = {2019},
  note          = {cited By 8},
  number        = {1},
  pages         = {808-819},
  volume        = {6},
  abstract      = {Internet of Things (IoT) applications bring in a great convenience for human's life, but users' data privacy concern is the major barrier toward the development of IoT. k -anonymity is a method to protect users' data privacy, but it is presently known to suffer from inference attacks. Thus far, existing work only relies on a number of experimental examples to validate k -anonymity's performance against inference attacks, and thereby lacks of a theoretical guarantee. To tackle this issue, in this paper we propose the first theoretical foundation that gives a nonasymptotic bound on the performance of k -anonymity against inference attacks, taking into consideration of adversaries' background information. The main idea is to first quantify adversaries' background information, and from the point of the view of adversaries, classify users' data into four kinds: 1) independent with unknown data values; 2) local dependent with unknown data values; 3) independent with certain known data values; and 4) local dependent with certain known data values. We then move one step further, theoretically proving the bound on the performance of k -anonymity corresponding to each of the four kinds of users' data through cooperating with the noiseless privacy. We argue that such a theoretical foundation links k -anonymity with noiseless privacy, theoretically proving k -anonymity provides noiseless privacy. Additionally, this paper theoretically explains why k -anonymity is vulnerable to inference attacks using the modified Stein method. Simulations on real check-in dataset from the location-based social network have validated our results. We believe that this paper can bridge the gap between design and evaluation, enabling a designer to construct a more practical k -anonymity technique in real-life scenarios to resist inference attacks. © 2014 IEEE.},
  art_number    = {8417921},
  document_type = {Article},
  doi           = {10.1109/JIOT.2018.2858240},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050386742&doi=10.1109%2fJIOT.2018.2858240&partnerID=40&md5=b10c6ed6fdeb31b48b72c973eea4f3fc},
}

@Article{Moustafa2019,
  author        = {Moustafa, N. and Hu, J. and Slay, J.},
  journal       = {Journal of Network and Computer Applications},
  title         = {A holistic review of Network Anomaly Detection Systems: A comprehensive survey},
  year          = {2019},
  note          = {cited By 79},
  pages         = {33-55},
  volume        = {128},
  abstract      = {Network Anomaly Detection Systems (NADSs) are gaining a more important role in most network defense systems for detecting and preventing potential threats. The paper discusses various aspects of anomaly-based Network Intrusion Detection Systems (NIDSs). The paper explains cyber kill chain models and cyber-attacks that compromise network systems. Moreover, the paper describes various Decision Engine (DE) approaches, including new ensemble learning and deep learning approaches. The paper also provides more details about benchmark datasets for training and validating DE approaches. Most of NADSs’ applications, such as Data Centers, Internet of Things (IoT), as well as Fog and Cloud Computing, are also discussed. Finally, we present several experimental explanations which we follow by revealing various promising research directions. © 2018 Elsevier Ltd},
  document_type = {Article},
  doi           = {10.1016/j.jnca.2018.12.006},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058942201&doi=10.1016%2fj.jnca.2018.12.006&partnerID=40&md5=2136700845a47b4c85a89aa3f4c92e94},
}

@Conference{Straub2019,
  author        = {Straub, J.},
  title         = {An Interdiction Detection and Prevention System (IDPS) for Anti-Autonomy Attack Repulsion},
  year          = {2019},
  note          = {cited By 1},
  volume        = {2019-March},
  abstract      = {Unmanned vehicles, such as spacecraft and aircraft, are potentially susceptible to attacks that seek to compromise their operations or cause damage or destruction through the use of attacks that target their autonomous decision making capabilities. These attacks may be used for both offensive and defensive purposes. So-called 'anti-drone' or 'anti-autonomy' technologies are gaining attention in the aviation sector as a way to prevent UAV entrance into controlled areas or combat a UAV attack. Like with most warfighting technologies, superiority requires both a way to assure your own attacks while denying enemy attack capabilities. Thus, a mechanism for effective prevention of attacks that seek to exploit vulnerabilities in or the confusion of autonomous command and control systems must be able to be effectively repelled. This paper builds on the concept of network and computing system intrusion detection system (IDS) technology to present an Interdiction Detection and Prevention System (IDPS) that serves to identify and respond to attacks on autonomous control systems and software. The use of multiple IDS technologies for the detection component of the IDPS is discussed and the efficacy of each is considered. Then preventative and responsive actions are discussed. An architecture and implementation of the IDPS are presented and evaluated. The paper concludes with a discussion of the efficacy of the IDPS for multiple applications and the 'spy versus spy' nature of autonomy, anti-autonomy and autonomous system assurance. © 2019 IEEE.},
  art_number    = {8741884},
  document_type = {Conference Paper},
  doi           = {10.1109/AERO.2019.8741884},
  groups        = {First Filtering},
  journal       = {IEEE Aerospace Conference Proceedings},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068347913&doi=10.1109%2fAERO.2019.8741884&partnerID=40&md5=9929fb8af5b7fd64c8b080903c5ef195},
}

@Article{Jebur2019,
  author        = {Jebur, H.H. and Al-Nidawi, W.J. and Khorsheed, O.K. and Jaafar, S.K.},
  journal       = {Journal of Computational and Theoretical Nanoscience},
  title         = {Intrusion detection system: Principles, taxonomy, challenges and generic model},
  year          = {2019},
  note          = {cited By 0},
  number        = {3},
  pages         = {907-913},
  volume        = {16},
  abstract      = {Intrusion detection systems are being received a growing interest by researchers to develop different methods and techniques to overcome their problems and improve the efficiency in detecting various attacks against computer systems and networks. The overall performance of IDSs is a result of the efficiency and effectiveness of the main functions of IDS and any performance deterioration is significantly due to defects in these functions. Therefore, a theoretical foundation of IDSs is required to realize the boundaries, functions and capabilities of IDs and enhance the related research. This paper introduces an overview of the IDS principles, taxonomy, and functions. It also gives a brief on the intrusion detection systems common challenges. Furthermore, a generic intrusion detection system model is developed. Copyright © 2019 American Scientific Publishers All rights reserved.},
  document_type = {Article},
  doi           = {10.1166/jctn.2019.7973},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066974536&doi=10.1166%2fjctn.2019.7973&partnerID=40&md5=bad199b44274f693d0a412aad65893f7},
}

@Article{DarvishRouani2019,
  author        = {Darvish Rouani, B. and Samragh, M. and Javidi, T. and Koushanfar, F.},
  journal       = {IEEE Security and Privacy},
  title         = {Safe Machine Learning and Defeating Adversarial Attacks},
  year          = {2019},
  note          = {cited By 8},
  number        = {2},
  pages         = {31-38},
  volume        = {17},
  abstract      = {Adversarial attacks have exposed the unreliability of machine-learning (ML) models for decision making in autonomous agents. This article discusses recent research for ML model assurance in the face of adversarial attacks. © 2003-2012 IEEE.},
  art_number    = {8677311},
  document_type = {Article},
  doi           = {10.1109/MSEC.2018.2888779},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063890457&doi=10.1109%2fMSEC.2018.2888779&partnerID=40&md5=cd800d73f6774dfe0cdafc1163db160e},
}

@Article{Haller2019,
  author        = {Haller, P. and Genge, B. and Duka, A.-V.},
  journal       = {International Journal of Critical Infrastructure Protection},
  title         = {On the practical integration of anomaly detection techniques in industrial control applications},
  year          = {2019},
  note          = {cited By 5},
  pages         = {48-68},
  volume        = {24},
  abstract      = {Despite significant advances made on anomaly detection systems, few reports are found documenting their practical integration into the industrial realm. Furthermore, the literature reports a wide range of complex detection strategies, which may require hardware changes/updates in order to be supported by critical industrial equipment such as industrial controllers (e.g., Programmable Logic Controllers). To address these issues, this paper documents a systematic methodology for the practical integration of lightweight anomaly detection algorithms into industrial control applications. It shows that industrial controllers, and in particular the scheduling rate of user programs, are sensitive to network traffic-based disturbances. Therefore, the methodology embraces the task scheduling rates found in control applications, and their deviation from the “normal” behavior. It designs a “monitoring” task, and an innovative algorithm for detecting abnormal task scheduling rates by leveraging the cumulative sum model (CUSUM) and a regression strategy applied on a specific time interval. Essentially, the approach enhances the industrial controller with a “security module” that can trigger alerts to identify early cyber attacks. The approach is extensively analyzed in the context of two industrial controllers: a Phoenix Contact ILC 350-PN controller, and a Siemens SIMATIC S7-1200 Programmable controller. © 2018 Elsevier B.V.},
  document_type = {Article},
  doi           = {10.1016/j.ijcip.2018.10.008},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060306454&doi=10.1016%2fj.ijcip.2018.10.008&partnerID=40&md5=537f0aab80f67a25acc65f3a0324e773},
}

@Article{Loukas2019,
  author        = {Loukas, G. and Karapistoli, E. and Panaousis, E. and Sarigiannidis, P. and Bezemskij, A. and Vuong, T.},
  journal       = {Ad Hoc Networks},
  title         = {A taxonomy and survey of cyber-physical intrusion detection approaches for vehicles},
  year          = {2019},
  note          = {cited By 28},
  pages         = {124-147},
  volume        = {84},
  abstract      = {With the growing threat of cyber and cyber-physical attacks against automobiles, drones, ships, driverless pods and other vehicles, there is also a growing need for intrusion detection approaches that can facilitate defence against such threats. Vehicles tend to have limited processing resources and are energy-constrained. So, any security provision needs to abide by these limitations. At the same time, attacks against vehicles are very rare, often making knowledge-based intrusion detection systems less practical than behaviour-based ones, which is the reverse of what is seen in conventional computing systems. Furthermore, vehicle design and implementation can differ wildly between different types or different manufacturers, which can lead to intrusion detection designs that are vehicle-specific. Equally importantly, vehicles are practically defined by their ability to move, autonomously or not. Movement, as well as other physical manifestations of their operation may allow cyber security breaches to lead to physical damage, but can also be an opportunity for detection. For example, physical sensing can contribute to more accurate or more rapid intrusion detection through observation and analysis of physical manifestations of a security breach. This paper presents a classification and survey of intrusion detection systems designed and evaluated specifically on vehicles and networks of vehicles. Its aim is to help identify existing techniques that can be adopted in the industry, along with their advantages and disadvantages, as well as to identify gaps in the literature, which are attractive and highly meaningful areas of future research. © 2018 Elsevier B.V.},
  document_type = {Short Survey},
  doi           = {10.1016/j.adhoc.2018.10.002},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054715147&doi=10.1016%2fj.adhoc.2018.10.002&partnerID=40&md5=b2bb067a65e2e4b249f35ac135bf23c8},
}

@Conference{Uddin2019,
  author        = {Uddin, M.S. and Kuh, A.},
  title         = {Online Unsupervised Kernel Affine Projection Algorithms},
  year          = {2019},
  note          = {cited By 0},
  pages         = {229-234},
  abstract      = {In recent years, the application of unsupervised learning techniques has become of growing importance in a number of fields, e.g., feature selection, clustering etc. While an array of fast supervised learning algorithms have been developed over the years, the number of fast unsupervised learning algorithms is lacking. In this paper, we present a fast unsupervised kernel affine projection algorithm using a least-squares one-class support vector machine framework and coherence sparsification criterion. A kernel NLMS type algorithm is then developed as a special case. To validate the efficacy of the proposed algorithms, we then perform simulations to detect outliers in datasets. © 2018 APSIPA organization.},
  art_number    = {8659616},
  document_type = {Conference Paper},
  doi           = {10.23919/APSIPA.2018.8659616},
  groups        = {First Filtering},
  journal       = {2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference, APSIPA ASC 2018 - Proceedings},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063543715&doi=10.23919%2fAPSIPA.2018.8659616&partnerID=40&md5=382921c091a3553d375c87f3156a21af},
}

@Conference{Yang2019c,
  author        = {Yang, F. and Chen, Z. and Gangopadhyay, A.},
  title         = {Using randomness to improve robustness of tree-based models against evasion attacks},
  year          = {2019},
  note          = {cited By 0},
  pages         = {25-35},
  abstract      = {Machine learning models have been widely used in security applications. However, it is well-known that adversaries can adapt their attacks to evade detection. There has been some work on making machine learning models more robust to such attacks. However, one simple but promising approach called randomization is underexplored. In addition, most existing works focus on models with differentiable error functions while tree-based models do not have such error functions but are quite popular because they are easy to interpret. This paper proposes a novel randomization-based approach to improve robustness of tree-based models against evasion attacks. The proposed approach incorporates randomization into both model training time and model application time (meaning when the model is used to detect attacks). We also apply this approach to random forest, an existing ML method which already has incorporated randomness at training time but still often fails to generate robust models. We proposed a novel weighted-random-forest method to generate more robust models and a clustering method to add randomness at model application time. Experiments on intrusion detection and spam filtering data show that our approach further improves robustness of random-forest method. © 2019 Association for Computing Machinery.},
  art_number    = {3309186},
  document_type = {Conference Paper},
  doi           = {10.1145/3309182.3309186},
  groups        = {First Filtering},
  journal       = {IWSPA 2019 - Proceedings of the ACM International Workshop on Security and Privacy Analytics, co-located with CODASPY 2019},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066138517&doi=10.1145%2f3309182.3309186&partnerID=40&md5=6473a185ff0f22d54ba8cf08d4796e9f},
}

@Conference{Qureshi2019,
  author        = {Qureshi, A.-U.-H. and Larijani, H. and Ahmad, J. and Mtetwa, N.},
  title         = {A Novel Random Neural Network Based Approach for Intrusion Detection Systems},
  year          = {2019},
  note          = {cited By 9},
  pages         = {50-55},
  abstract      = {Computer security and privacy of user specific data is a prime concern in day to day communication. The mass use of internet connected systems has given rise to many vulnerabilities which includes attacks on smart devices. Regular occurrence of such events has made the availability of scalable Intrusion Detection System (IDS) a perilous challenge. An intelligent IDS should be able to stop the malicious activity before it destabilizes the core network and to achieve this goal we propose a novel Random Neural Network based Intrusion Detection System (RNN-IDS) in this paper. The performance is evaluated by training different numbers of input and hidden layer neurons with learning rates on benchmark NSL-KDD dataset for binary classification. To validate the feasibility of proposed scheme, results were compared with existing systems and its performance was evaluated by the detection of novel attacks while obtaining an accuracy of 94.50%. © 2018 IEEE.},
  art_number    = {8674228},
  document_type = {Conference Paper},
  doi           = {10.1109/CEEC.2018.8674228},
  groups        = {First Filtering},
  journal       = {2018 10th Computer Science and Electronic Engineering Conference, CEEC 2018 - Proceedings},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064395799&doi=10.1109%2fCEEC.2018.8674228&partnerID=40&md5=e2995d2df8eee7b837c615d315cef53c},
}

@Conference{Kaouk2019,
  author        = {Kaouk, M. and Flaus, J.-M. and Potet, M.-L. and Groz, R.},
  title         = {A review of intrusion detection systems for industrial control systems},
  year          = {2019},
  note          = {cited By 1},
  pages         = {1699-1704},
  abstract      = {Industrial Control Systems are found often in industrial sectors and critical infrastructures to monitor and control industrial processes. Recently, the security of industrial control systems has gained much attention as these systems now exhibit an increased interaction with the Internet. In fact, classical SCADA systems are already lacking with security problems, and with the increased interconnectivity to the Internet, they are now exposed to new types of threats and cyber-attacks. Intrusion detection technology is one of the most important security solutions used today in industrial control systems to detect potential attacks and malicious activities. This paper summarizes previous work for Intrusion Detection Systems approaches in Industrial Control Systems and highlights challenges and opportunities in implementing such solutions. We believe that such insights are valuable for further research in the industrial security context. © 2019 IEEE.},
  art_number    = {8820602},
  document_type = {Conference Paper},
  doi           = {10.1109/CoDIT.2019.8820602},
  groups        = {First Filtering},
  journal       = {2019 6th International Conference on Control, Decision and Information Technologies, CoDIT 2019},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072833604&doi=10.1109%2fCoDIT.2019.8820602&partnerID=40&md5=7285d72b07c3684fd7098d7d3f758ba1},
}

@Article{SahayaSakila2019,
  author        = {Sahaya Sakila, V. and Sandeep, M. and Praveen Hari Krishna, N.},
  journal       = {International Journal of Innovative Technology and Exploring Engineering},
  title         = {Adversarial attack on machine learning models},
  year          = {2019},
  note          = {cited By 0},
  number        = {6 Special Issue 4},
  pages         = {431-434},
  volume        = {8},
  abstract      = {Machine Learning (ML) models are applied in a variety of tasks such as network intrusion detection or malware classification. Yet, these models are vulnerable to a class of malicious inputs known as adversarial examples. These are slightly perturbed inputs that are classified incorrectly by the ML model. The mitigation of these adversarial inputs remains an open problem. As a step towards understanding adversarial examples, we show that they are not drawn from the same distribution than the original data, and can thus be detected using statistical tests. Using this knowledge, we introduce a complimentary approach to identify specific inputs that are adversarial. Specifically, we augment our ML model with an additional output, in which the model is trained to classify all adversarial inputs. © BEIESP.},
  document_type = {Article},
  doi           = {10.35940/ijitee.F1088.0486S419},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071325584&doi=10.35940%2fijitee.F1088.0486S419&partnerID=40&md5=4e2822d7f08e2f05fe27f5c205075b4b},
}

@Article{Tao2019,
  author        = {Tao, F. and Votion, J. and Cao, Y.},
  journal       = {IEEE Transactions on Industrial Informatics},
  title         = {An Iterative Multilayer Unsupervised Learning Approach for Sensory Data Reliability Evaluation},
  year          = {2019},
  note          = {cited By 0},
  number        = {4},
  pages         = {2199-2209},
  volume        = {15},
  abstract      = {This paper investigates the problem of extracting actionable patterns/models from unlabeled and potentially erroneous datasets in an unsupervised way. To address the need for both model extraction and data reliability evaluation, we propose a novel iterative multilayer micro-macro (IM3) method that defines data reliability, learns micro-macro models, and iteratively refines learned models. The IM3 method includes a general data reliability definition to evaluate the reliability level of each sample, a micro-macro model complexity determination, and an iterative data reliability and model complexity update mechanism to overcome the underfitting and overfitting issue. In particular, we propose a consistency-index-based approach to address underfitting and overfitting in an unsupervised way. The refinement of the learned models is enabled via dropping the most unreliable data until the data reliability is above a given threshold. The sensitivity of the proposed IM3 method with respect to the reliability threshold selection is further quantified via false alarm and missdetection to facilitate the selection of an appropriate reliability threshold. Evaluation of the proposed method and quantitative analysis of its sensitivity are provided on a polynomial regression problem via Monte Carlo simulations. © 2005-2012 IEEE.},
  art_number    = {8432111},
  document_type = {Article},
  doi           = {10.1109/TII.2018.2864742},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052600712&doi=10.1109%2fTII.2018.2864742&partnerID=40&md5=cf3e9f5abc63acad8ba76f1d41fe399a},
}

@Article{Gümüşbaş20211717,
  author        = {Gümüşbaş, D. and Yıldırım, T. and Genovese, A. and Scotti, F.},
  journal       = {IEEE Systems Journal},
  title         = {A comprehensive survey of databases and deep learning methods for cybersecurity and intrusion detection systems},
  year          = {2021},
  note          = {cited By 6},
  number        = {2},
  pages         = {1717-1731},
  volume        = {15},
  abstract      = {This survey presents a comprehensive overview of machine learning methods for cybersecurity intrusion detection systems, with a specific focus on recent approaches based on deep learning (DL). The review analyzes recent methods with respect to their intrusion detection mechanisms, performance results, and limitations as well as whether they use benchmark databases to ensure a fair evaluation. In addition, a detailed investigation of benchmark datasets for cybersecurity is presented. This article is intended to provide a road map for readers who would like to understand the potential of DL methods for cybersecurity and intrusion detection systems, along with a detailed analysis of the benchmark datasets used in the literature to train DL models. © 2020 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.},
  art_number    = {9099844},
  document_type = {Review},
  doi           = {10.1109/JSYST.2020.2992966},
  groups        = {First Filtering},
  source        = {Scopus},
  url           = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108528570&doi=10.1109%2fJSYST.2020.2992966&partnerID=40&md5=ab800856ae3f14280216b96011b20cef},
}

@Comment{jabref-meta: databaseType:bibtex;}
